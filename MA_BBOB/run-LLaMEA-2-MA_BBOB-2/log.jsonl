{"id": "94043383-e47d-490c-aabe-09d9efa8d2f1", "fitness": -Infinity, "name": "CMAES", "description": "Covariance matrix adaptation evolution strategy with restarts and adaptive step size control, tailored for handling budget constraints efficiently.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, mu_factor=0.25, cs=0.08, dsigma=0.2, c_cov=2/3, c_cov_mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(budget * mu_factor) if int(budget * mu_factor) > 0 else 1\n        self.lambda_ = int(4 + 3 * np.log(self.dim))\n        self.mu = min(self.mu, self.lambda_)\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = cs\n        self.dsigma = dsigma\n        self.c_cov = c_cov\n        self.c_cov_mu = min(1 - self.c_cov, (self.mueff / (self.dim + 13)) * self.c_cov) if c_cov_mu is None else c_cov_mu\n        self.chiN = self.dim**0.5 * (1 - (1/(4*self.dim)) + 1/(21*self.dim**2))\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize variables\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = 0.5  # Initial step size\n        C = np.eye(self.dim) # Covariance matrix\n        p_sigma = np.zeros(self.dim) # Evolution path for sigma\n        p_c = np.zeros(self.dim) # Evolution path for C\n        \n        used_budget = 0\n        \n        while used_budget < self.budget:\n            # Sample lambda candidate solutions\n            z = np.random.normal(0, 1, size=(self.dim, self.lambda_))\n            A = np.linalg.cholesky(C)\n            x = mean[:, np.newaxis] + sigma * A @ z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate solutions\n            f = np.array([func(xi) for xi in x.T])\n            used_budget += self.lambda_\n            \n            # Sort solutions\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n            \n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n                \n            # Update mean\n            mean_diff = x[:, :self.mu] - mean[:, np.newaxis]\n            mean = np.sum(self.weights[np.newaxis, :] * x[:, :self.mu], axis=1)\n\n            # Update evolution paths\n            B = A @ z[:, :self.mu]\n            mean_diff_weighted = np.sum(self.weights[np.newaxis, :] * B, axis=1) / sigma\n            p_sigma = (1 - self.cs) * p_sigma + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (A @ mean_diff_weighted)\n            \n            hsig = (np.linalg.norm(p_sigma) / np.sqrt(1 - (1 - self.cs)**(2*(used_budget/self.lambda_))) / self.chiN) < (1.4 + 2/(self.dim + 1))\n            p_c = (1 - self.c_cov) * p_c + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * self.mueff) * (mean_diff / sigma)\n            \n            # Update covariance matrix\n            C = (1 - self.c_cov - self.c_cov_mu) * C + self.c_cov * (p_c[:, np.newaxis] @ p_c[np.newaxis, :]) + self.c_cov_mu * (B @ np.diag(self.weights) @ B.T) / sigma**2\n            \n            # Update step size\n            sigma = sigma * np.exp((self.cs/self.dsigma) * (np.linalg.norm(p_sigma)/self.chiN - 1))\n\n            C = np.triu(C) + np.triu(C, 1).T # enforce symmetry\n            C = C / np.linalg.norm(C, ord='fro') * self.dim # normalize\n            \n            try:\n                np.linalg.cholesky(C) # check for positive definiteness\n            except np.linalg.LinAlgError:\n                C = np.eye(self.dim) # restart covariance matrix\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 38, in __call__\n  File \"<__array_function__ internals>\", line 200, in clip\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 2180, in clip\n    return _wrapfunc(a, 'clip', a_min, a_max, out=out, **kwargs)\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 57, in _wrapfunc\n    return bound(*args, **kwds)\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py\", line 161, in _clip\n    return _clip_dep_invoke_with_casting(\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py\", line 115, in _clip_dep_invoke_with_casting\n    return ufunc(*args, out=out, **kwargs)\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) \n.", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "31b355ab-8b81-4f4c-9eed-2ff52673fca8", "fitness": -Infinity, "name": "AdaptiveCMAES", "description": "A population-based algorithm with adaptive step size and covariance matrix adaptation, coupled with a restart strategy to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=1, ccov1=0.0, ccovmu=0.0, cma_decay = 0.99):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.cs = cs\n        self.damps = damps\n        self.ccov1 = ccov1\n        self.ccovmu = ccovmu\n        self.cma_decay = cma_decay\n\n    def __call__(self, func):\n        # Initialization\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.mean = np.random.uniform(lb, ub, self.dim)\n        self.sigma = 0.1 * (ub - lb)\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.restart_iter = 0\n        self.mu = self.popsize // 2\n\n        # Weights for recombination\n        weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        weights = weights / np.sum(weights)\n        self.weights = weights\n\n        # Parameters update\n        self.mu_eff = np.sum(weights)**2 / np.sum(weights**2)\n        self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mu_eff)\n        self.ccovmu = 2 * (self.mu_eff - 2 + 1/self.mu_eff) / ((self.dim + 2)**2 + self.mu_eff)\n        self.cs = (self.mu_eff + 2) / (self.dim + self.mu_eff + 5)\n        self.damps = 1 + 2*np.max([0, np.sqrt((self.mu_eff-1)/(self.dim+1)) - 1]) + self.cs\n\n        while self.eval_count < self.budget:\n            # Generate and evaluate population\n            z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            try:\n                C_sqrt = np.linalg.cholesky(self.C)\n                x = self.mean[:, np.newaxis] + self.sigma * C_sqrt @ z\n            except np.linalg.LinAlgError:\n                # Covariance matrix not positive definite, add a small value to the diagonal\n                self.C = self.C + 1e-6 * np.eye(self.dim)\n                C_sqrt = np.linalg.cholesky(self.C)\n                x = self.mean[:, np.newaxis] + self.sigma * C_sqrt @ z\n                \n            x = np.clip(x, lb, ub)\n\n            f = np.array([func(xi) for xi in x.T])\n            self.eval_count += self.popsize\n\n            # Sort population\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n\n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n\n            # Update mean\n            xmean = np.sum(x[:, :self.mu] * self.weights, axis=1)\n            y = xmean - self.mean\n            self.mean = xmean\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mu_eff) * (C_sqrt @ z[:, :self.mu] @ self.weights)\n            hsig = (np.linalg.norm(self.ps)/np.sqrt(1-(1-self.cs)**(2*(self.eval_count/self.popsize)))/np.sqrt(self.dim+0.1) < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.ccov1) * self.pc + hsig * np.sqrt(self.ccov1 * (2 - self.ccov1) * self.mu_eff) * y\n\n            # Update covariance matrix\n            artmp = (1/self.sigma) * (x[:, :self.mu] - self.mean[:, np.newaxis])\n            self.C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * (1-hsig) * self.ccov1) * self.C + self.ccov1 * np.outer(self.pc, self.pc) + self.ccovmu * artmp @ np.diag(self.weights) @ artmp.T\n\n            # Update step size\n            self.sigma *= np.exp((self.cs/self.damps)*(np.linalg.norm(self.ps)/np.sqrt(self.dim)-1))\n            self.sigma = max(self.sigma, 1e-10 * (ub-lb))\n\n            # Restart strategy (simplified, based on stagnation)\n            if self.eval_count > (self.restart_iter+1)*self.budget//5:\n               if np.std(f[:self.mu]) < 1e-8:\n                    self.mean = np.random.uniform(lb, ub, self.dim)\n                    self.sigma = 0.1 * (ub - lb)\n                    self.C = np.eye(self.dim)\n                    self.pc = np.zeros(self.dim)\n                    self.ps = np.zeros(self.dim)\n                    self.restart_iter += 1\n\n            # Decay CMA-ES parameters over time\n            self.ccov1 *= self.cma_decay\n            self.ccovmu *= self.cma_decay\n            self.cs *= self.cma_decay\n            self.damps *= self.cma_decay\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 53, in __call__\n  File \"<__array_function__ internals>\", line 200, in clip\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 2180, in clip\n    return _wrapfunc(a, 'clip', a_min, a_max, out=out, **kwargs)\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 57, in _wrapfunc\n    return bound(*args, **kwds)\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py\", line 161, in _clip\n    return _clip_dep_invoke_with_casting(\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py\", line 115, in _clip_dep_invoke_with_casting\n    return ufunc(*args, out=out, **kwargs)\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) \n.", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "7e92a2dd-0bdc-4ba7-a00d-ac955ffd666b", "fitness": 0.38612253245473527, "name": "AdaptiveSearch", "description": "A population-based algorithm that combines exploration and exploitation by using a combination of global search and local refinement, adaptively adjusting the search strategy based on the fitness landscape.", "code": "import numpy as np\n\nclass AdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations\n        self.exploration_rate = 0.7  # Initial exploration rate\n        self.exploration_decay = 0.995 # Decay rate for exploration\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            # Exploration phase: Generate new solutions using a global search strategy\n            if np.random.rand() < self.exploration_rate:\n                new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                new_fitness = np.array([func(x) for x in new_population])\n                self.budget -= self.pop_size\n            else:  # Exploitation phase: Refine existing solutions using local search\n                new_population = np.copy(self.population)\n                new_fitness = np.copy(self.fitness)\n\n                for i in range(self.pop_size):\n                    for _ in range(self.local_search_iterations):\n                        if self.budget <=0:\n                            break\n\n                        # Create a small perturbation around the current solution\n                        perturbation = np.random.normal(0, 0.1, size=self.dim)\n                        new_x = self.population[i] + perturbation\n                        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n                        \n                        new_f = func(new_x)\n                        self.budget -= 1\n                        if new_f < new_fitness[i]:\n                            new_population[i] = new_x\n                            new_fitness[i] = new_f\n            \n\n            # Update the population by selecting the best solutions from the old and new populations\n            combined_population = np.concatenate((self.population, new_population))\n            combined_fitness = np.concatenate((self.fitness, new_fitness))\n            \n            indices = np.argsort(combined_fitness)[:self.pop_size]\n            self.population = combined_population[indices]\n            self.fitness = combined_fitness[indices]\n\n            # Update the best solution found so far\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index]\n            \n            self.exploration_rate *= self.exploration_decay # Reduce exploration over time\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSearch scored 0.386 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.11751106956928703, 0.16893098276051732, 0.4294367313062215, 0.5757711466844202, 0.34089690706442644, 0.3978873331089212, 0.2697593792526295, 0.3175886046088836, 0.3234808779390007, 0.18659072383410835, 0.532044218546031, 0.9810799091043574, 0.29659494510208306, 0.20363063128604075, 0.745813331870769, 0.33342698206655585, 0.28613676613452643, 0.5039957448295772, 0.24423340415235884, 0.46764095987399057]}}
{"id": "28f45127-4db2-499b-b31d-96e76435d562", "fitness": 0.25012264495428094, "name": "CMAES", "description": "Covariance Matrix Adaptation Evolution Strategy with a simplified update rule and adaptive step size control.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize = None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.p_sigma = np.zeros(self.dim)\n        self.p_c = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu + 2) / (self.dim + self.mu + 5)\n        self.c_c = (4 + self.mu/self.dim) / (self.dim + 4 + 2*self.mu/self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.d_sigma = 1 + 2*max(0, np.sqrt((self.mu-1)/(self.dim+1)) - 1) + self.c_sigma\n        self.D = None\n        self.B = None\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        used_budget = 0\n\n        while used_budget < self.budget:\n            \n            # Sample population\n            z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            if self.D is None or self.B is None:\n                 self.D, self.B = np.linalg.eigh(self.C)\n                 self.D = np.sqrt(np.maximum(self.D, 1e-16))\n            y = self.B @ np.diag(self.D) @ z.T\n            x = self.m + self.sigma * y.T\n            \n            # Evaluate population, ensuring bounds are respected and budget is not exceeded.\n            f = np.zeros(self.popsize)\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], func.bounds.lb, func.bounds.ub)\n                if used_budget < self.budget:\n                    f[i] = func(x[i])\n                    used_budget += 1\n                    if f[i] < self.f_opt:\n                        self.f_opt = f[i]\n                        self.x_opt = x[i]\n                else:\n                    f[i] = np.inf\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            z = z[idx]\n            f = f[idx]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            y_mean = np.mean(z[:self.mu], axis=0) # Simplified: Directly use mean of z\n            self.p_sigma = (1 - self.c_sigma) * self.p_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (self.B @ y_mean)\n            hsig = np.linalg.norm(self.p_sigma) / np.sqrt(1 - (1 - self.c_sigma)**(2*used_budget/self.popsize))/self.chiN < 1.4 + 2/(self.dim+1)\n            self.p_c = (1 - self.c_c) * self.p_c + hsig * np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma\n            \n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.p_c[:, None] @ self.p_c[None, :]) + self.c_mu * np.sum(self.weights[:, None, None] * (z[:self.mu, :, None] @ z[:self.mu, None, :]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.p_sigma)/self.chiN - 1))\n\n            self.D = None # invalidate cached B and D\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CMAES scored 0.250 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.08370040572678827, 0.18213916361336746, 0.4680496307673926, 0.15558181697325035, 0.22852906843165566, 0.1532823985565176, 0.22642523912261447, 0.20746026671329687, 0.18122620252732147, 0.14523512826898732, 0.1669327513157537, 0.21479076079898574, 0.2486936983494309, 0.18365239580834158, 0.6949564315207222, 0.2665783012142, 0.20987264071738942, 0.36708658393778226, 0.1704518167773944, 0.44780819794442606]}}
{"id": "3361ca6f-81df-4d1c-935c-5cbb27f7639e", "fitness": -Infinity, "name": "MirroredCMAES", "description": "An enhanced CMA-ES variant incorporating a mirrored sampling strategy to boost exploration, particularly beneficial in complex landscapes.", "code": "import numpy as np\n\nclass MirroredCMAES:\n    def __init__(self, budget=10000, dim=10, mu_factor=0.25, cs=0.08, dsigma=0.2, c_cov=2/3, c_cov_mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(budget * mu_factor) if int(budget * mu_factor) > 0 else 1\n        self.lambda_ = int(4 + 3 * np.log(self.dim))\n        self.mu = min(self.mu, self.lambda_)\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = cs\n        self.dsigma = dsigma\n        self.c_cov = c_cov\n        self.c_cov_mu = min(1 - self.c_cov, (self.mueff / (self.dim + 13)) * self.c_cov) if c_cov_mu is None else c_cov_mu\n        self.chiN = self.dim**0.5 * (1 - (1/(4*self.dim)) + 1/(21*self.dim**2))\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize variables\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = 0.5  # Initial step size\n        C = np.eye(self.dim) # Covariance matrix\n        p_sigma = np.zeros(self.dim) # Evolution path for sigma\n        p_c = np.zeros(self.dim) # Evolution path for C\n        \n        used_budget = 0\n        \n        while used_budget < self.budget:\n            # Sample lambda candidate solutions\n            z = np.random.normal(0, 1, size=(self.dim, self.lambda_))\n            A = np.linalg.cholesky(C)\n            x = mean[:, np.newaxis] + sigma * A @ z\n            x_mirrored = mean[:, np.newaxis] - sigma * A @ z  # Mirrored samples\n            \n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            x_mirrored = np.clip(x_mirrored, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate solutions\n            f = np.array([func(xi) for xi in x.T])\n            f_mirrored = np.array([func(xi) for xi in x_mirrored.T])\n            used_budget += 2 * self.lambda_\n            \n            # Combine original and mirrored samples\n            x_combined = np.concatenate((x, x_mirrored), axis=1)\n            f_combined = np.concatenate((f, f_mirrored))\n            \n            # Sort solutions\n            idx = np.argsort(f_combined)\n            x_sorted = x_combined[:, idx]\n            f_sorted = f_combined[idx]\n            \n            # Update optimal solution\n            if f_sorted[0] < self.f_opt:\n                self.f_opt = f_sorted[0]\n                self.x_opt = x_sorted[:, 0]\n                \n            # Update mean\n            mean_diff = x_sorted[:, :self.mu] - mean[:, np.newaxis]\n            mean = np.sum(self.weights[np.newaxis, :] * x_sorted[:, :self.mu], axis=1)\n\n            # Update evolution paths\n            B = A @ z[:, :self.mu]\n            mean_diff_weighted = np.sum(self.weights[np.newaxis, :] * B, axis=1) / sigma\n            p_sigma = (1 - self.cs) * p_sigma + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (A @ mean_diff_weighted)\n            \n            hsig = (np.linalg.norm(p_sigma) / np.sqrt(1 - (1 - self.cs)**(2*(used_budget/(2*self.lambda_)))) / self.chiN) < (1.4 + 2/(self.dim + 1))\n            p_c = (1 - self.c_cov) * p_c + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * self.mueff) * (mean_diff / sigma)\n            \n            # Update covariance matrix\n            C = (1 - self.c_cov - self.c_cov_mu) * C + self.c_cov * (p_c[:, np.newaxis] @ p_c[np.newaxis, :]) + self.c_cov_mu * (B @ np.diag(self.weights) @ B.T) / sigma**2\n            \n            # Update step size\n            sigma = sigma * np.exp((self.cs/self.dsigma) * (np.linalg.norm(p_sigma)/self.chiN - 1))\n\n            C = np.triu(C) + np.triu(C, 1).T # enforce symmetry\n            C = C / np.linalg.norm(C, ord='fro') * self.dim # normalize\n            \n            try:\n                np.linalg.cholesky(C) # check for positive definiteness\n            except np.linalg.LinAlgError:\n                C = np.eye(self.dim) # restart covariance matrix\n\n            if used_budget > self.budget:\n                used_budget = self.budget\n\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 40, in __call__\n  File \"<__array_function__ internals>\", line 200, in clip\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 2180, in clip\n    return _wrapfunc(a, 'clip', a_min, a_max, out=out, **kwargs)\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 57, in _wrapfunc\n    return bound(*args, **kwds)\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py\", line 161, in _clip\n    return _clip_dep_invoke_with_casting(\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py\", line 115, in _clip_dep_invoke_with_casting\n    return ufunc(*args, out=out, **kwargs)\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) \n.", "error": "", "parent_ids": ["94043383-e47d-490c-aabe-09d9efa8d2f1"], "operator": null, "metadata": {}}
{"id": "b61637b4-6fe3-4f07-aa87-5a69982be7b5", "fitness": 0.0, "name": "OrthogonalDifferentialEvolution", "description": "A population-based algorithm that balances exploration and exploitation using orthogonal learning and differential evolution.", "code": "import numpy as np\n\nclass OrthogonalDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, orthogonal_components=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.orthogonal_components = orthogonal_components\n        self.F = 0.7  # Differential evolution scaling factor\n        self.CR = 0.7  # Crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                mask = np.random.rand(self.dim) < self.CR\n                trial[mask] = mutant[mask]\n\n                # Orthogonal Learning: Sample around the trial vector\n                orthogonal_samples = np.random.normal(trial, 0.05, size=(self.orthogonal_components, self.dim)) # Reduced std\n                orthogonal_samples = np.clip(orthogonal_samples, func.bounds.lb, func.bounds.ub)\n                orthogonal_fitness = np.array([func(x) for x in orthogonal_samples])\n                self.budget -= self.orthogonal_components\n\n                best_orthogonal_index = np.argmin(orthogonal_fitness)\n                if orthogonal_fitness[best_orthogonal_index] < func(trial):\n                    trial = orthogonal_samples[best_orthogonal_index]\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1  # Increment the budget counter after the evaluation\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.population[i]\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm OrthogonalDifferentialEvolution scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7e92a2dd-0bdc-4ba7-a00d-ac955ffd666b"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "e5022637-c9c0-42c1-a579-9c20db87fdef", "fitness": 0.40190126696149464, "name": "AdaptiveDE", "description": "An adaptive differential evolution strategy that adjusts mutation and crossover rates based on the fitness landscape.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr # Crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        # Track best solution\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n                mutant = population[i] + self.F * (x2 - x3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.Cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Selection\n                f = func(trial)\n                eval_count += 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    # Update best solution\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                # Adaptive parameter adjustment (example)\n                if eval_count % self.pop_size == 0:\n                    if np.random.rand() < 0.1:\n                        self.F = np.random.uniform(0.1, 0.9)\n                    if np.random.rand() < 0.1:\n                        self.Cr = np.random.uniform(0.1, 0.9)\n                \n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.402 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["94043383-e47d-490c-aabe-09d9efa8d2f1"], "operator": null, "metadata": {"aucs": [0.14264704308816167, 0.2866597731876691, 0.44212671194990705, 0.431736887959033, 0.3230907920704841, 0.39810337511656724, 0.30019847116497733, 0.32521219494248477, 0.30437754280007234, 0.23030051268260399, 0.6090298759336009, 0.9779781234192958, 0.3327124505040182, 0.2948162679333747, 0.7266750152279118, 0.4093317156891668, 0.3361048648414723, 0.4602813188681083, 0.21760122134515936, 0.4890411805058247]}}
{"id": "48a1b0cd-3634-4253-ad7c-6a0d37274741", "fitness": 0.608157545423355, "name": "SelfAdaptiveDE", "description": "Implement a Differential Evolution strategy with self-adaptive parameters and population diversity maintenance.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, F_adaptive=True, CR_adaptive=True):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.F_adaptive = F_adaptive\n        self.CR_adaptive = CR_adaptive\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        memory_F = np.ones(self.popsize) * self.F\n        memory_CR = np.ones(self.popsize) * self.CR\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n\n                if self.F_adaptive:\n                     F = memory_F[i]\n                else:\n                     F = self.F\n                \n                mutant = x1 + F * (x2 - x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                if self.CR_adaptive:\n                    CR = memory_CR[i]\n                else:\n                    CR = self.CR\n                \n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n                    if self.F_adaptive:\n                        memory_F[i] = np.random.normal(self.F, 0.1)\n                        memory_F[i] = np.clip(memory_F[i], 0.1, 1.0)\n                    if self.CR_adaptive:\n                        memory_CR[i] = np.random.normal(self.CR, 0.1)\n                        memory_CR[i] = np.clip(memory_CR[i], 0.1, 1.0)\n\n            # Population diversity maintenance (optional)\n            if np.std(self.fitness) < 1e-8:  # Stagnation\n                self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.eval_count += self.popsize\n                best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.population[best_idx]\n                memory_F = np.ones(self.popsize) * self.F\n                memory_CR = np.ones(self.popsize) * self.CR\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm SelfAdaptiveDE scored 0.608 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["31b355ab-8b81-4f4c-9eed-2ff52673fca8"], "operator": null, "metadata": {"aucs": [0.19704289348502158, 0.3831457911720938, 0.589924233263255, 0.8184408598300033, 0.7101225692032657, 0.7664121267999557, 0.47850878422188514, 0.5569040611600106, 0.6900819050400755, 0.5143278470234836, 0.779956917900261, 0.9905231504862116, 0.32363097573059063, 0.6726412377933064, 0.8812329942052305, 0.7720531750652282, 0.5136189908176325, 0.7833484465142071, 0.2244925096960716, 0.5167414390593086]}}
{"id": "0b7b6fd7-388d-4f85-93cf-7473ef7263ca", "fitness": 0.2913292683104546, "name": "AdaptiveCMAES", "description": "An adaptive CMA-ES variant that dynamically adjusts its population size and learning rates based on the progress of optimization.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, initial_popsize = None, min_popsize = 4):\n        self.budget = budget\n        self.dim = dim\n        self.initial_popsize = initial_popsize if initial_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.min_popsize = min_popsize\n        self.popsize = self.initial_popsize\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.p_sigma = np.zeros(self.dim)\n        self.p_c = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu + 2) / (self.dim + self.mu + 5)\n        self.c_c = (4 + self.mu/self.dim) / (self.dim + 4 + 2*self.mu/self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.d_sigma = 1 + 2*max(0, np.sqrt((self.mu-1)/(self.dim+1)) - 1) + self.c_sigma\n        self.D = None\n        self.B = None\n        self.function_evals = 0\n        self.success_history = []\n        self.learning_rate_scaling = 1.0\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        while self.function_evals < self.budget:\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            if self.D is None or self.B is None:\n                 self.D, self.B = np.linalg.eigh(self.C)\n                 self.D = np.sqrt(np.maximum(self.D, 1e-16))\n            y = self.B @ np.diag(self.D) @ z.T\n            x = self.m + self.sigma * y.T\n\n            # Evaluate population, ensuring bounds are respected and budget is not exceeded.\n            f = np.zeros(self.popsize)\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], func.bounds.lb, func.bounds.ub)\n                if self.function_evals < self.budget:\n                    f[i] = func(x[i])\n                    self.function_evals += 1\n                    if f[i] < self.f_opt:\n                        self.f_opt = f[i]\n                        self.x_opt = x[i]\n                else:\n                    f[i] = np.inf\n\n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            z = z[idx]\n            f = f[idx]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            y_mean = np.mean(z[:self.mu], axis=0)\n            self.p_sigma = (1 - self.c_sigma) * self.p_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (self.B @ y_mean)\n            hsig = np.linalg.norm(self.p_sigma) / np.sqrt(1 - (1 - self.c_sigma)**(2*self.function_evals/self.popsize))/self.chiN < 1.4 + 2/(self.dim+1)\n            self.p_c = (1 - self.c_c) * self.p_c + hsig * np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.p_c[:, None] @ self.p_c[None, :]) + self.c_mu * np.sum(self.weights[:, None, None] * (z[:self.mu, :, None] @ z[:self.mu, None, :]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.p_sigma)/self.chiN - 1)) * self.learning_rate_scaling\n\n            self.D = None # invalidate cached B and D\n\n            # Adaptive Pop Size and Learning Rate\n            if len(self.success_history) > 10:\n                success_rate = np.mean(self.success_history[-10:])\n                if success_rate > 0.8 and self.popsize > self.min_popsize:\n                    self.popsize = max(self.min_popsize, self.popsize // 2)\n                    self.mu = self.popsize // 2\n                    self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n                    self.weights = self.weights / np.sum(self.weights)\n                    self.c_sigma = (self.mu + 2) / (self.dim + self.mu + 5)\n                    self.c_c = (4 + self.mu/self.dim) / (self.dim + 4 + 2*self.mu/self.dim)\n                    self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n                    self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n                    self.d_sigma = 1 + 2*max(0, np.sqrt((self.mu-1)/(self.dim+1)) - 1) + self.c_sigma\n                    self.learning_rate_scaling *= 0.9  # Reduce learning rate when shrinking popsize\n                    \n                elif success_rate < 0.2 and self.popsize < self.initial_popsize:\n                    self.popsize = min(self.initial_popsize, self.popsize * 2)\n                    self.mu = self.popsize // 2\n                    self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n                    self.weights = self.weights / np.sum(self.weights)\n                    self.c_sigma = (self.mu + 2) / (self.dim + self.mu + 5)\n                    self.c_c = (4 + self.mu/self.dim) / (self.dim + 4 + 2*self.mu/self.dim)\n                    self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n                    self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n                    self.d_sigma = 1 + 2*max(0, np.sqrt((self.mu-1)/(self.dim+1)) - 1) + self.c_sigma\n                    self.learning_rate_scaling *= 1.1  # Increase learning rate when expanding popsize\n            \n            self.success_history.append(int(f[0] < self.f_opt)) #Record success if the best in pop is better than global best\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveCMAES scored 0.291 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["28f45127-4db2-499b-b31d-96e76435d562"], "operator": null, "metadata": {"aucs": [0.07821368720135247, 0.18597947941778725, 0.5194368121158515, 0.16110665274350644, 0.14513622995338393, 0.1547099717995476, 0.23537601957651355, 0.2470092864072413, 0.1608728518464, 0.16022722089719155, 0.16298500119540493, 0.9859504483985171, 0.2564181179300702, 0.17179482021506498, 0.265857186185978, 0.27349865994827394, 0.22543759648997086, 0.9735945991826745, 0.2699952689572531, 0.19298545574710924]}}
{"id": "90627713-fbf7-40fc-a4a5-99a11978eaf3", "fitness": 0.6392254540574409, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Archive and Elitism, adjusting mutation and crossover rates based on population diversity and fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7 # Initial crossover rate\n        self.F_adapt = 0.1 # Adaptation rate for F\n        self.CR_adapt = 0.1 # Adaptation rate for CR\n        self.archive = []\n        self.archive_fitness = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                if f < self.fitness[i]:\n                    # Update population\n                    self.population[i] = trial\n                    self.fitness[i] = f\n\n                    # Add replaced individual to archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(np.copy(self.population[i]))\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        idx_worst = np.argmax(self.archive_fitness)\n                        self.archive[idx_worst] = np.copy(self.population[i])\n                        self.archive_fitness[idx_worst] = self.fitness[i]\n\n                # Update best solution\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = trial\n\n            # Adaptive F and CR (simple adaptation)\n            if len(self.archive) > 0:\n                diversity = np.std(self.fitness)\n                improvement = self.f_opt - np.min(self.fitness)\n                if diversity > 0:\n                  self.F = np.clip(self.F + self.F_adapt * (1 - diversity), 0.1, 0.9)\n                if improvement < 0: #negative improvement\n                  self.CR = np.clip(self.CR + self.CR_adapt * improvement, 0.1, 0.9)\n\n\n            # Elitism: Keep the best solution from the previous generation\n            best_index = np.argmin(self.fitness)\n            if self.f_opt < self.fitness[best_index]:\n                self.population[best_index] = self.x_opt\n                self.fitness[best_index] = self.f_opt\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.639 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7e92a2dd-0bdc-4ba7-a00d-ac955ffd666b"], "operator": null, "metadata": {"aucs": [0.23565009337259157, 0.23466630629131036, 0.6491772309167376, 0.8795755506211724, 0.6268356846477285, 0.8673622952626451, 0.4237764128183602, 0.6525389895952924, 0.7318923280775019, 0.2965155713688231, 0.8875854288344879, 0.9918216798521294, 0.4681494758873499, 0.6925312149637375, 0.918968467234856, 0.7932287047401633, 0.569033882216343, 0.8536976079048231, 0.48543813548864123, 0.5260640210541223]}}
{"id": "d74418b7-94a1-4f54-9fb1-4a61740ad9ee", "fitness": 0.44338291158576437, "name": "PSOCMA", "description": "A population-based algorithm that combines the strengths of particle swarm optimization (PSO) with covariance matrix adaptation (CMA) for improved exploration and exploitation.", "code": "import numpy as np\n\nclass PSOCMA:\n    def __init__(self, budget=10000, dim=10, popsize=None, w=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.particles = np.random.uniform(-5, 5, size=(self.popsize, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.popsize, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = np.full(self.popsize, np.inf)\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n        # CMA-ES related parameters\n        self.m = np.zeros(self.dim)  # Mean\n        self.sigma = 0.5  # Step size\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.p_sigma = np.zeros(self.dim)  # Evolution path for sigma\n        self.p_c = np.zeros(self.dim)  # Evolution path for C\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.chiN = np.sqrt(self.dim) * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu + 2) / (self.dim + self.mu + 5)\n        self.c_c = (4 + self.mu/self.dim) / (self.dim + 4 + 2*self.mu/self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.d_sigma = 1 + 2*max(0, np.sqrt((self.mu-1)/(self.dim+1)) - 1) + self.c_sigma\n        self.D = None\n        self.B = None\n        self.used_budget = 0\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        while self.used_budget < self.budget:\n            # Evaluate particles\n            fitness = np.zeros(self.popsize)\n            for i in range(self.popsize):\n                if self.used_budget < self.budget:\n                    fitness[i] = func(self.particles[i])\n                    self.used_budget += 1\n                else:\n                    fitness[i] = np.inf\n\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = fitness[i]\n                    self.personal_best_positions[i] = self.particles[i].copy()\n\n                if fitness[i] < self.global_best_fitness:\n                    self.global_best_fitness = fitness[i]\n                    self.global_best_position = self.particles[i].copy()\n                    self.f_opt = self.global_best_fitness\n                    self.x_opt = self.global_best_position\n\n            # Update velocities and positions (PSO)\n            for i in range(self.popsize):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i]\n                                      + self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                                      + self.c2 * r2 * (self.global_best_position - self.particles[i]))\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i], func.bounds.lb, func.bounds.ub)\n\n            # CMA-ES update\n            idx = np.argsort(fitness)\n            sorted_particles = self.particles[idx]\n\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * sorted_particles[:self.mu], axis=0)\n\n            # Sample population using CMA-ES strategy for generating search directions\n            z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            if self.D is None or self.B is None:\n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(np.maximum(self.D, 1e-16))\n            y = self.B @ np.diag(self.D) @ z.T\n            # Update particles using the CMA-ES directions, instead of purely random PSO updates\n            self.particles = self.m + self.sigma * y.T\n            self.particles = np.clip(self.particles, func.bounds.lb, func.bounds.ub) # ensure bounds\n\n            y_mean = np.mean(z[:self.mu], axis=0)\n            self.p_sigma = (1 - self.c_sigma) * self.p_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (self.B @ y_mean)\n            hsig = np.linalg.norm(self.p_sigma) / np.sqrt(1 - (1 - self.c_sigma)**(2*self.used_budget/self.popsize))/self.chiN < 1.4 + 2/(self.dim+1)\n            self.p_c = (1 - self.c_c) * self.p_c + hsig * np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.p_c[:, None] @ self.p_c[None, :]) + self.c_mu * np.sum(self.weights[:, None, None] * (z[:self.mu, :, None] @ z[:self.mu, None, :]), axis=0)\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.p_sigma)/self.chiN - 1))\n            self.D = None # invalidate cached B and D\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm PSOCMA scored 0.443 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["28f45127-4db2-499b-b31d-96e76435d562"], "operator": null, "metadata": {"aucs": [0.1636743334598173, 0.24421764015697933, 0.36480644540772744, 0.8194697044486257, 0.27619288284196586, 0.6388397058809085, 0.31933374931274816, 0.38330685041287216, 0.4315505184043995, 0.32122064310640885, 0.34117759472513565, 0.9992442822151149, 0.22427536861281772, 0.3160704987435754, 0.7787777712222362, 0.5147311954412157, 0.3255376640883827, 0.7165132331041097, 0.21290055759152293, 0.475817592538725]}}
{"id": "3753b066-43af-4c2e-9f8c-88e35b2b71b1", "fitness": 0.21889696192734287, "name": "RankCMAES", "description": "A CMA-ES variant that incorporates a rank-based fitness transformation and dynamic population size adjustment to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass RankCMAES:\n    def __init__(self, budget=10000, dim=10, popsize = None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.p_sigma = np.zeros(self.dim)\n        self.p_c = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu + 2) / (self.dim + self.mu + 5)\n        self.c_c = (4 + self.mu/self.dim) / (self.dim + 4 + 2*self.mu/self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.d_sigma = 1 + 2*max(0, np.sqrt((self.mu-1)/(self.dim+1)) - 1) + self.c_sigma\n        self.D = None\n        self.B = None\n        self.generation = 0\n        self.popsize_factor = 1.0\n\n    def __rank_transform(self, f):\n        \"\"\"Transforms fitness values to ranks.\"\"\"\n        ranks = np.argsort(np.argsort(f)) + 1\n        transformed_f = ranks / len(f)\n        return transformed_f\n\n    def __adjust_popsize(self):\n         \"\"\"Dynamically adjusts population size based on performance.\"\"\"\n         if self.generation > 50 and self.f_opt_history[-1] == self.f_opt_history[-50]:\n             self.popsize_factor = max(0.5, self.popsize_factor * 0.9)  # Reduce popsize if stagnation\n         elif self.generation > 50 and self.f_opt < np.min(self.f_opt_history[-50:]):\n             self.popsize_factor = min(2.0, self.popsize_factor * 1.1)  # Increase popsize if improving\n\n         self.popsize = int(self.popsize_factor * (4 + int(3 * np.log(self.dim))))\n         self.mu = self.popsize // 2\n         self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n         self.weights = self.weights / np.sum(self.weights)\n         self.c_sigma = (self.mu + 2) / (self.dim + self.mu + 5)\n         self.c_c = (4 + self.mu/self.dim) / (self.dim + 4 + 2*self.mu/self.dim)\n         self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n         self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n         self.d_sigma = 1 + 2*max(0, np.sqrt((self.mu-1)/(self.dim+1)) - 1) + self.c_sigma\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        used_budget = 0\n        self.f_opt_history = []\n        self.generation = 0\n\n        while used_budget < self.budget:\n            self.generation += 1\n            self.__adjust_popsize()\n\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            if self.D is None or self.B is None:\n                 self.D, self.B = np.linalg.eigh(self.C)\n                 self.D = np.sqrt(np.maximum(self.D, 1e-16))\n            y = self.B @ np.diag(self.D) @ z.T\n            x = self.m + self.sigma * y.T\n            \n            # Evaluate population, ensuring bounds are respected and budget is not exceeded.\n            f = np.zeros(self.popsize)\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], func.bounds.lb, func.bounds.ub)\n                if used_budget < self.budget:\n                    f[i] = func(x[i])\n                    used_budget += 1\n                    if f[i] < self.f_opt:\n                        self.f_opt = f[i]\n                        self.x_opt = x[i]\n                else:\n                    f[i] = np.inf\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            z = z[idx]\n            f = f[idx]\n\n            # Rank transformation\n            transformed_f = self.__rank_transform(f)\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            y_mean = np.mean(z[:self.mu], axis=0) # Simplified: Directly use mean of z\n            self.p_sigma = (1 - self.c_sigma) * self.p_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (self.B @ y_mean)\n            hsig = np.linalg.norm(self.p_sigma) / np.sqrt(1 - (1 - self.c_sigma)**(2*used_budget/self.popsize))/self.chiN < 1.4 + 2/(self.dim+1)\n            self.p_c = (1 - self.c_c) * self.p_c + hsig * np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma\n            \n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.p_c[:, None] @ self.p_c[None, :]) + self.c_mu * np.sum(self.weights[:, None, None] * (z[:self.mu, :, None] @ z[:self.mu, None, :]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.p_sigma)/self.chiN - 1))\n\n            self.D = None # invalidate cached B and D\n            self.f_opt_history.append(self.f_opt)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm RankCMAES scored 0.219 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["28f45127-4db2-499b-b31d-96e76435d562"], "operator": null, "metadata": {"aucs": [0.07033523138658326, 0.2041928054337554, 0.4731504243441689, 0.17974956607669923, 0.19128232231043407, 0.15302976827260972, 0.2325968223329038, 0.19417923402456339, 0.1762550607847494, 0.15652300459827673, 0.18748576324352884, 0.22309766236638628, 0.2486161913741629, 0.19111661498791754, 0.17704110544439078, 0.27922912712190795, 0.2567040365083174, 0.16839063862554082, 0.17138984887125475, 0.44357401043870626]}}
{"id": "3cb2c985-e774-4f28-9aeb-5483a8a97d4d", "fitness": 0.26397740687671845, "name": "AdaptivePopulationCMAES", "description": "A CMA-ES variant that dynamically adjusts its population size based on the observed fitness variance in the population.", "code": "import numpy as np\n\nclass AdaptivePopulationCMAES:\n    def __init__(self, budget=10000, dim=10, initial_popsize=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = initial_popsize if initial_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.p_sigma = np.zeros(self.dim)\n        self.p_c = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu + 2) / (self.dim + self.mu + 5)\n        self.c_c = (4 + self.mu/self.dim) / (self.dim + 4 + 2*self.mu/self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.d_sigma = 1 + 2*max(0, np.sqrt((self.mu-1)/(self.dim+1)) - 1) + self.c_sigma\n        self.D = None\n        self.B = None\n        self.min_popsize = 4 # minimum population size\n        self.max_popsize = 4 + int(10 * np.log(self.dim)) # maximum population size\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        used_budget = 0\n\n        while used_budget < self.budget:\n            \n            # Sample population\n            z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            if self.D is None or self.B is None:\n                 self.D, self.B = np.linalg.eigh(self.C)\n                 self.D = np.sqrt(np.maximum(self.D, 1e-16))\n            y = self.B @ np.diag(self.D) @ z.T\n            x = self.m + self.sigma * y.T\n            \n            # Evaluate population, ensuring bounds are respected and budget is not exceeded.\n            f = np.zeros(self.popsize)\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], func.bounds.lb, func.bounds.ub)\n                if used_budget < self.budget:\n                    f[i] = func(x[i])\n                    used_budget += 1\n                    if f[i] < self.f_opt:\n                        self.f_opt = f[i]\n                        self.x_opt = x[i]\n                else:\n                    f[i] = np.inf\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            z = z[idx]\n            f = f[idx]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            y_mean = np.mean(z[:self.mu], axis=0) # Simplified: Directly use mean of z\n            self.p_sigma = (1 - self.c_sigma) * self.p_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (self.B @ y_mean)\n            hsig = np.linalg.norm(self.p_sigma) / np.sqrt(1 - (1 - self.c_sigma)**(2*used_budget/self.popsize))/self.chiN < 1.4 + 2/(self.dim+1)\n            self.p_c = (1 - self.c_c) * self.p_c + hsig * np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma\n            \n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.p_c[:, None] @ self.p_c[None, :]) + self.c_mu * np.sum(self.weights[:, None, None] * (z[:self.mu, :, None] @ z[:self.mu, None, :]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.p_sigma)/self.chiN - 1))\n\n            self.D = None # invalidate cached B and D\n\n            # Dynamically adjust population size\n            fitness_variance = np.var(f)\n            if fitness_variance > 1e-6: # threshold can be tuned\n                self.popsize = min(self.max_popsize, int(self.popsize * 1.1)) # increase popsize\n            else:\n                self.popsize = max(self.min_popsize, int(self.popsize * 0.9)) # decrease popsize\n            self.popsize = int(self.popsize)\n            self.mu = self.popsize // 2\n            self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n            self.weights = self.weights / np.sum(self.weights)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptivePopulationCMAES scored 0.264 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["28f45127-4db2-499b-b31d-96e76435d562"], "operator": null, "metadata": {"aucs": [0.0801333516005559, 0.18158541663600403, 0.5075503042843883, 0.19677874761176417, 0.17350977139910229, 0.152095919959232, 0.17372964790809897, 0.21463541051821844, 0.824112295772147, 0.13862376167306478, 0.20666048136826554, 0.22028582125531293, 0.25913555041591996, 0.28805281447005726, 0.37559681625169883, 0.2758874199107473, 0.23140272403049789, 0.16921444577563838, 0.16070778669590313, 0.44984964999775123]}}
{"id": "f5beeb7d-c335-4823-9fc6-570cfe9afc42", "fitness": 0.790454800265928, "name": "SOMDE", "description": "An adaptive population-based algorithm that uses a combination of differential evolution and a self-organizing map to guide the search process.", "code": "import numpy as np\n\nclass SOMDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, som_grid_size=5, de_mutation_factor=0.5, de_crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.som_grid_size = som_grid_size  # Size of the SOM grid (som_grid_size x som_grid_size)\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.som = None\n        self.learning_rate = 0.1\n        self.neighborhood_radius = som_grid_size // 2\n\n    def initialize_som(self):\n        \"\"\"Initializes the Self-Organizing Map (SOM).\"\"\"\n        self.som = np.random.uniform(-1, 1, size=(self.som_grid_size, self.som_grid_size, self.dim))\n\n    def find_best_matching_unit(self, x):\n        \"\"\"Finds the best matching unit (BMU) in the SOM for a given input vector x.\"\"\"\n        distances = np.sum((self.som - x)**2, axis=2)  # Euclidean distance\n        bmu_index = np.unravel_index(np.argmin(distances), distances.shape)\n        return bmu_index\n\n    def update_som(self, x, bmu_index):\n        \"\"\"Updates the SOM weights based on the input vector x and the BMU.\"\"\"\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                distance = np.sqrt((i - bmu_index[0])**2 + (j - bmu_index[1])**2)\n                if distance <= self.neighborhood_radius:\n                    influence = np.exp(-distance**2 / (2 * self.neighborhood_radius**2))\n                    self.som[i, j] += self.learning_rate * influence * (x - self.som[i, j])\n\n    def differential_evolution(self, func):\n        \"\"\"Applies Differential Evolution to the population.\"\"\"\n        for i in range(self.pop_size):\n            # Choose three random individuals (excluding the current one)\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            if i in indices:\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    \n            x_r1, x_r2, x_r3 = self.population[indices]\n\n            # Mutation\n            x_mutated = x_r1 + self.de_mutation_factor * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = np.copy(self.population[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.de_crossover_rate:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.budget -= 1\n            if f_trial < self.fitness[i]:\n                self.population[i] = x_trial\n                self.fitness[i] = f_trial\n                \n                # Update SOM with new better solution\n                bmu_index = self.find_best_matching_unit(x_trial)\n                self.update_som(x_trial, bmu_index)\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.initialize_som()\n        # Initialize SOM with random vectors from the search space\n        for i in range(self.som_grid_size):\n          for j in range(self.som_grid_size):\n            self.som[i,j] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim))\n        \n        \n        while self.budget > 0:\n            self.differential_evolution(func)\n\n            # Update the best solution found so far\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index]\n\n            # Adapt learning rate and neighborhood radius (optional)\n            self.learning_rate = 0.95 * self.learning_rate\n            self.neighborhood_radius = max(1, int(0.95 * self.neighborhood_radius))\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm SOMDE scored 0.790 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7e92a2dd-0bdc-4ba7-a00d-ac955ffd666b"], "operator": null, "metadata": {"aucs": [0.3898076663224477, 0.6844120312852404, 0.7013889163188687, 0.9239220443658769, 0.8825210037106994, 0.901731211663844, 0.7605569883386598, 0.8265936195617983, 0.8964736971392876, 0.875790464603495, 0.9328331429072068, 0.9969200006276466, 0.281244015980443, 0.854416644577386, 0.9138939893500544, 0.9024398911712842, 0.801871514182021, 0.9280208086368233, 0.6387604454402718, 0.7154979091352016]}}
{"id": "ce708f84-36b8-44d0-a9e7-858e653fc1cc", "fitness": 0.7878929250983573, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Ensemble Mutation Strategies, utilizing multiple mutation operators and adaptively selecting them based on their success.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.mutation_strategies = [self._mutation_rand1, self._mutation_current_to_best_1, self._mutation_best1]\n        self.success_counts = [1] * len(self.mutation_strategies)\n        self.total_counts = [1] * len(self.mutation_strategies)\n        self.epsilon = 1e-6\n\n    def _mutation_rand1(self, population, best_idx):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        return population[idxs[0]] + self.F * (population[idxs[1]] - population[idxs[2]])\n\n    def _mutation_current_to_best_1(self, population, best_idx, i):\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        return population[i] + self.F * (population[best_idx] - population[i]) + self.F * (population[idxs[0]] - population[idxs[1]])\n\n    def _mutation_best1(self, population, best_idx):\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        return population[best_idx] + self.F * (population[idxs[0]] - population[idxs[1]])\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        used_budget = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        \n        while used_budget < self.budget:\n            for i in range(self.pop_size):\n                # Adaptive mutation strategy selection\n                probabilities = np.array(self.success_counts) / np.array(self.total_counts)\n                probabilities /= np.sum(probabilities)\n                mutation_idx = np.random.choice(len(self.mutation_strategies), p=probabilities)\n                \n                if mutation_idx == 0:\n                    mutant = self._mutation_rand1(population, best_idx)\n                elif mutation_idx == 1:\n                    mutant = self._mutation_current_to_best_1(population, best_idx, i)\n                else:\n                    mutant = self._mutation_best1(population, best_idx)\n                    \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Evaluation\n                f = func(trial_vector)\n                used_budget += 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    self.success_counts[mutation_idx] += 1\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                \n                self.total_counts[mutation_idx] += 1\n            \n            best_idx = np.argmin(fitness)\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.788 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["94043383-e47d-490c-aabe-09d9efa8d2f1"], "operator": null, "metadata": {"aucs": [0.5103870783326003, 0.8773967542080346, 0.8702119290377641, 0.9431055102949912, 0.8928371335977832, 0.9078237065969758, 0.37504007625818025, 0.8499558047322648, 0.898356765704721, 0.4692555795673041, 0.936168803898151, 0.999579864762748, 0.814826854014296, 0.8817315283621736, 0.9683524400318902, 0.8957511063062944, 0.45230077309701433, 0.9315121807590174, 0.7848475889783466, 0.49841702342659555]}}
{"id": "f5a08fc9-28c2-485e-b52e-db7e93e47efd", "fitness": 0.47705525659327586, "name": "SelfAdaptiveDE", "description": "Implement a differential evolution strategy with self-adaptive parameters and a restart mechanism.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.9, F_decay=0.99, CR_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 * self.dim\n        self.F = F\n        self.CR = CR\n        self.F_decay = F_decay\n        self.CR_decay = CR_decay\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.restart_iter = 0\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = self.population[i] + self.F * (x2 - x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Update F and CR (self-adaptive) - Decay over time\n            self.F *= self.F_decay\n            self.CR *= self.CR_decay\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.CR = np.clip(self.CR, 0.1, 0.9)\n\n            # Restart strategy (if stagnating)\n            if self.eval_count > (self.restart_iter+1)*self.budget//5:\n               if np.std(self.fitness) < 1e-8:\n                    self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n                    self.fitness = np.array([func(x) for x in self.population])\n                    self.eval_count += self.popsize\n                    best_idx = np.argmin(self.fitness)\n                    self.f_opt = self.fitness[best_idx]\n                    self.x_opt = self.population[best_idx]\n                    self.restart_iter += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm SelfAdaptiveDE scored 0.477 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["31b355ab-8b81-4f4c-9eed-2ff52673fca8"], "operator": null, "metadata": {"aucs": [0.17530572304740766, 0.27937594131510324, 0.46465937468488183, 0.7547114585239147, 0.4053095545140901, 0.615591212695525, 0.33404346575910737, 0.41239207243325704, 0.3986534064944368, 0.1994244199984847, 0.6794146811123649, 0.9954247616199322, 0.2580136158699906, 0.34126023977240605, 0.7662158455340861, 0.6309548884027463, 0.38008161650363703, 0.7392120448129164, 0.20353193063387987, 0.5075288781373524]}}
{"id": "ed0ee27d-53c1-4767-b0c7-a4dc97ca0b46", "fitness": 0.0, "name": "AgingRestartDE", "description": "A DE variant with a restart mechanism based on the fitness variance and an aging mechanism to replace old solutions.", "code": "import numpy as np\n\nclass AgingRestartDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, age_limit=50):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.age_limit = age_limit\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.ages = np.zeros(self.popsize, dtype=int)\n\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    self.ages[i] = 0 # Reset age\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                else:\n                    self.ages[i] += 1\n\n            # Aging mechanism: replace old solutions\n            for i in range(self.popsize):\n                if self.ages[i] > self.age_limit:\n                    self.population[i] = np.random.uniform(lb, ub, size=self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    self.eval_count += 1\n                    self.ages[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n\n            # Population diversity maintenance (restart)\n            if np.std(self.fitness) < 1e-8:  # Stagnation\n                self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.eval_count += self.popsize\n                best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.population[best_idx]\n                self.ages = np.zeros(self.popsize, dtype=int)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AgingRestartDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["48a1b0cd-3634-4253-ad7c-6a0d37274741"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "d57c0542-0ea1-4410-ab23-d39212e8f159", "fitness": -Infinity, "name": "SOMNelderMead", "description": "A population-based algorithm that combines the exploration of a Self-Organizing Map with the exploitation of a Nelder-Mead simplex method, using the SOM to initialize and restart Nelder-Mead searches.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SOMNelderMead:\n    def __init__(self, budget=10000, dim=10, pop_size=10, som_grid_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.som_grid_size = som_grid_size\n        self.som = None\n        self.learning_rate = 0.1\n        self.neighborhood_radius = som_grid_size // 2\n        self.min_inner_budget = 100  # Minimum function evaluations for Nelder-Mead\n\n    def initialize_som(self):\n        \"\"\"Initializes the Self-Organizing Map (SOM).\"\"\"\n        self.som = np.random.uniform(-1, 1, size=(self.som_grid_size, self.som_grid_size, self.dim))\n\n    def find_best_matching_unit(self, x):\n        \"\"\"Finds the best matching unit (BMU) in the SOM for a given input vector x.\"\"\"\n        distances = np.sum((self.som - x)**2, axis=2)  # Euclidean distance\n        bmu_index = np.unravel_index(np.argmin(distances), distances.shape)\n        return bmu_index\n\n    def update_som(self, x, bmu_index):\n        \"\"\"Updates the SOM weights based on the input vector x and the BMU.\"\"\"\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                distance = np.sqrt((i - bmu_index[0])**2 + (j - bmu_index[1])**2)\n                if distance <= self.neighborhood_radius:\n                    influence = np.exp(-distance**2 / (2 * self.neighborhood_radius**2))\n                    self.som[i, j] += self.learning_rate * influence * (x - self.som[i, j])\n\n    def nelder_mead(self, func, x0, inner_budget):\n        \"\"\"Applies the Nelder-Mead optimization algorithm.\"\"\"\n        if inner_budget <= 0:\n             return func(x0), x0\n\n        bounds = func.bounds\n        \n        def constrained_func(x):\n            # Clip the solution within the bounds\n            x_clipped = np.clip(x, bounds.lb, bounds.ub)\n            return func(x_clipped) # Evaluate the original function within the bounds\n\n        result = minimize(constrained_func, x0, method='Nelder-Mead', options={'maxfev': inner_budget, 'adaptive': True})\n\n        return result.fun, result.x\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        # Initialize population with random samples\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.initialize_som()\n\n        # Initialize SOM with random vectors from the search space\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                self.som[i, j] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim))\n        \n        while self.budget > self.min_inner_budget:\n            # Select individuals from population and SOM for Nelder-Mead\n            candidates = []\n            \n            # Add individuals from population\n            selected_indices = np.random.choice(self.pop_size, size=min(self.pop_size, 3), replace=False)\n            candidates.extend(population[selected_indices])\n\n            # Add individuals from SOM\n            som_indices = np.random.choice(self.som_grid_size * self.som_grid_size, size=min(self.som_grid_size * self.som_grid_size, 3), replace=False)\n            som_coords = np.unravel_index(som_indices, (self.som_grid_size, self.som_grid_size))\n            for k in range(len(som_indices)):\n                candidates.append(self.som[som_coords[0][k], som_coords[1][k]])\n\n\n            for x0 in candidates:\n                inner_budget = min(self.budget, self.min_inner_budget + int(self.budget / (len(candidates) + 1)))\n                f_val, x_new = self.nelder_mead(func, x0, inner_budget)\n                self.budget -= inner_budget\n                \n                # Update SOM\n                bmu_index = self.find_best_matching_unit(x_new)\n                self.update_som(x_new, bmu_index)\n\n\n                if f_val < self.f_opt:\n                    self.f_opt = f_val\n                    self.x_opt = x_new\n\n                #Update population if it is better than the worst\n                if f_val < np.max(fitness):\n                  worst_index = np.argmax(fitness)\n                  population[worst_index] = x_new\n                  fitness[worst_index] = f_val\n        \n            # Adapt learning rate and neighborhood radius (optional)\n            self.learning_rate = 0.95 * self.learning_rate\n            self.neighborhood_radius = max(1, int(0.95 * self.neighborhood_radius))\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 83, in __call__\n  File \"<string>\", line 46, in nelder_mead\nNameError: name 'minimize' is not defined\n.", "error": "", "parent_ids": ["f5beeb7d-c335-4823-9fc6-570cfe9afc42"], "operator": null, "metadata": {}}
{"id": "77352965-bb38-4e88-a6c6-b0dfed7582e5", "fitness": 0.0, "name": "DynPopCMAESDE", "description": "Differential Evolution with a dynamically adjusted population size based on success rate and a covariance matrix adaptation mutation.", "code": "import numpy as np\n\nclass DynPopCMAESDE:\n    def __init__(self, budget=10000, dim=10, popsize_init=None, F=0.5, CR=0.7, target_success_rate=0.25, popsize_reduction_factor=0.5, popsize_increase_factor=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize_init if popsize_init is not None else 10 * self.dim\n        self.popsize = int(self.popsize)\n        self.F = F\n        self.CR = CR\n        self.target_success_rate = target_success_rate\n        self.popsize_reduction_factor = popsize_reduction_factor\n        self.popsize_increase_factor = popsize_increase_factor\n        self.success_history = []\n        self.success_history_length = 10\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        C = np.eye(self.dim)  # Covariance matrix\n        learning_rate = 0.1\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover\n            trial_population = np.zeros_like(self.population)\n            trial_fitness = np.zeros_like(self.fitness)\n            successful_count = 0\n\n            for i in range(self.popsize):\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n\n                # CMA-ES inspired mutation\n                z = np.random.multivariate_normal(np.zeros(self.dim), C)\n                mutant = x1 + self.F * z\n                mutant = np.clip(mutant, lb, ub)\n                \n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n                trial_population[i] = trial\n                trial_fitness[i] = f_trial\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                    successful_count += 1\n\n            # Update Covariance Matrix (simplified)\n            diff = self.population - np.mean(self.population, axis=0)\n            C = (1 - learning_rate) * C + learning_rate * np.cov(diff.T)\n            \n            # Adjust population size\n            success_rate = successful_count / self.popsize\n            self.success_history.append(success_rate)\n            if len(self.success_history) > self.success_history_length:\n                self.success_history.pop(0)\n            \n            avg_success_rate = np.mean(self.success_history)\n\n            if avg_success_rate < self.target_success_rate / 2 and self.popsize > 4:\n                self.popsize = int(self.popsize * self.popsize_reduction_factor)\n                self.population = self.population[np.argsort(self.fitness)[:self.popsize]]\n                self.fitness = self.fitness[np.argsort(self.fitness)[:self.popsize]]\n                print(f\"Reducing popsize to {self.popsize}\")\n\n            elif avg_success_rate > self.target_success_rate * 2 and self.eval_count < self.budget // 2:\n                self.popsize = int(self.popsize * self.popsize_increase_factor)\n                self.popsize = min(self.popsize, self.budget // 2)\n                new_population = np.random.uniform(lb, ub, size=(self.popsize - len(self.population), self.dim))\n                new_fitness = np.array([func(x) for x in new_population])\n                self.eval_count += len(new_population)\n                self.population = np.vstack((self.population, new_population))\n                self.fitness = np.concatenate((self.fitness, new_fitness))\n                print(f\"Increasing popsize to {self.popsize}\")\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm DynPopCMAESDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["48a1b0cd-3634-4253-ad7c-6a0d37274741"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "648fb854-d4b7-4e5f-8923-eadd4b221ef9", "fitness": 0.4460156197410309, "name": "PSO_SA", "description": "A hybrid algorithm combining Particle Swarm Optimization with Simulated Annealing to balance exploration and exploitation.", "code": "import numpy as np\n\nclass PSO_SA:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, c1=1.5, c2=1.5, temp_init=100.0, temp_decay=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.temp_init = temp_init\n        self.temp_decay = temp_decay\n\n    def __call__(self, func):\n        # Initialize particles and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n\n        # Initialize personal best positions and values\n        pbest_positions = particles.copy()\n        pbest_values = np.array([func(x) for x in particles])\n        self.budget -= self.pop_size\n\n        # Initialize global best position and value\n        gbest_index = np.argmin(pbest_values)\n        gbest_position = pbest_positions[gbest_index].copy()\n        gbest_value = pbest_values[gbest_index]\n\n        # Simulated Annealing parameters\n        temperature = self.temp_init\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.c1 * r1 * (pbest_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (gbest_position - particles[i]))\n\n                # Update particle position\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                # Evaluate new position\n                current_value = func(particles[i])\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Update personal best\n                if current_value < pbest_values[i]:\n                    pbest_values[i] = current_value\n                    pbest_positions[i] = particles[i].copy()\n\n                    # Update global best\n                    if current_value < gbest_value:\n                        gbest_value = current_value\n                        gbest_position = particles[i].copy()\n\n                else:\n                    # Simulated Annealing acceptance criterion\n                    delta = current_value - pbest_values[i]\n                    if delta > 0 and np.random.rand() < np.exp(-delta / temperature):\n                        pbest_values[i] = current_value\n                        pbest_positions[i] = particles[i].copy()\n            \n            if self.budget <= 0:\n                break\n\n\n            # Cool down the temperature\n            temperature *= self.temp_decay\n\n        self.f_opt = gbest_value\n        self.x_opt = gbest_position\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm PSO_SA scored 0.446 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f5beeb7d-c335-4823-9fc6-570cfe9afc42"], "operator": null, "metadata": {"aucs": [0.16740353540081576, 0.21670612036680037, 0.8062423265169845, 0.18450225673178544, 0.27212288296782483, 0.8690345188801815, 0.32467900988198894, 0.23261258597741374, 0.8171869297054367, 0.1899170075202321, 0.9023443923346373, 0.9996572284758128, 0.22414395783063024, 0.26440594417455543, 0.5870664843314262, 0.35392969007221364, 0.4455390238491619, 0.29057808193477275, 0.27119805405548336, 0.5010423638124588]}}
{"id": "74850d2f-9615-4066-87fe-eea22bcdcc92", "fitness": 0.35384002407098913, "name": "PSO_CMAES", "description": "A hybrid algorithm combining Particle Swarm Optimization (PSO) with Covariance Matrix Adaptation Evolution Strategy (CMA-ES) to leverage exploration and exploitation strengths.", "code": "import numpy as np\n\nclass PSO_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, pso_inertia=0.7, pso_cognitive=1.4, pso_social=1.4, cmaes_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pso_inertia = pso_inertia\n        self.pso_cognitive = pso_cognitive\n        self.pso_social = pso_social\n        self.cmaes_sigma = cmaes_sigma\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.pbest_positions = None\n        self.pbest_fitness = None\n        self.gbest_position = None\n        self.gbest_fitness = np.inf\n        self.cmaes_mean = None\n        self.cmaes_covariance = None\n\n    def initialize(self, func):\n        \"\"\"Initializes the population, velocities, and other parameters.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_fitness = np.copy(self.fitness)\n        self.gbest_position = self.population[np.argmin(self.fitness)]\n        self.gbest_fitness = np.min(self.fitness)\n        self.cmaes_mean = np.copy(self.gbest_position)\n        self.cmaes_covariance = np.eye(self.dim)\n\n    def pso_step(self, func):\n        \"\"\"Performs a PSO update step.\"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n        \n        cognitive_component = self.pso_cognitive * r1 * (self.pbest_positions - self.population)\n        social_component = self.pso_social * r2 * (self.gbest_position - self.population)\n        \n        self.velocities = self.pso_inertia * self.velocities + cognitive_component + social_component\n        self.population += self.velocities\n        self.population = np.clip(self.population, func.bounds.lb, func.bounds.ub)\n        \n        new_fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if new_fitness[i] < self.pbest_fitness[i]:\n                self.pbest_fitness[i] = new_fitness[i]\n                self.pbest_positions[i] = np.copy(self.population[i])\n\n            if new_fitness[i] < self.gbest_fitness:\n                self.gbest_fitness = new_fitness[i]\n                self.gbest_position = np.copy(self.population[i])\n\n        self.fitness = new_fitness\n\n    def cmaes_step(self, func):\n        \"\"\"Performs a CMA-ES update step.\"\"\"\n        z = np.random.multivariate_normal(np.zeros(self.dim), self.cmaes_covariance, size=self.pop_size)\n        new_population = self.cmaes_mean + self.cmaes_sigma * z\n        new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n\n        new_fitness = np.array([func(x) for x in new_population])\n        self.budget -= self.pop_size\n\n        # Selection (e.g., (mu, lambda) selection)\n        combined_population = np.concatenate((self.population, new_population))\n        combined_fitness = np.concatenate((self.fitness, new_fitness))\n        \n        sorted_indices = np.argsort(combined_fitness)\n        self.population = combined_population[sorted_indices[:self.pop_size]]\n        self.fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n        # Update CMA-ES parameters (simplified)\n        self.cmaes_mean = np.mean(self.population, axis=0)\n        self.cmaes_covariance = np.cov(self.population.T) + 1e-8 * np.eye(self.dim) # Adding small value for numerical stability\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.gbest_fitness:\n            self.gbest_fitness = self.fitness[best_index]\n            self.gbest_position = self.population[best_index]\n        \n        self.pbest_fitness = np.minimum(self.pbest_fitness, self.fitness)\n        for i in range(self.pop_size):\n          if self.fitness[i] < self.pbest_fitness[i]:\n            self.pbest_positions[i] = self.population[i]\n        \n\n    def __call__(self, func):\n        self.initialize(func)\n        \n        while self.budget > 0:\n            if np.random.rand() < 0.5:\n                self.pso_step(func)\n            else:\n                self.cmaes_step(func)\n\n        return self.gbest_fitness, self.gbest_position", "configspace": "", "generation": 2, "feedback": "The algorithm PSO_CMAES scored 0.354 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f5beeb7d-c335-4823-9fc6-570cfe9afc42"], "operator": null, "metadata": {"aucs": [0.16449779614547455, 0.18577855505617136, 0.38275246250651984, 0.3392635560246632, 0.2112960308498828, 0.39868479063529383, 0.2786762704738469, 0.3549841885984617, 0.25893210170273984, 0.17944915078763424, 0.3547327693589072, 0.9984970301291831, 0.24589697156834922, 0.2824865092400227, 0.663138388842778, 0.492719623919573, 0.22887027328062604, 0.40294936141547355, 0.1943621571499793, 0.458832493734202]}}
{"id": "377bdc91-b549-4f84-ae17-f5c3a3ddb458", "fitness": 0.31986023298157007, "name": "CauchyDE", "description": "Implement a Differential Evolution strategy with a Cauchy mutation operator and a periodic restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass CauchyDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, restart_interval=1000):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.restart_interval = restart_interval\n        self.eval_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.generation = 0\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation (Cauchy)\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                \n                mutant = x1 + self.F * np.random.standard_cauchy(size=self.dim) * (x2 - x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n            self.generation += 1\n            if self.generation * self.popsize % self.restart_interval == 0:\n                 # Restart the population\n                self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.eval_count += self.popsize\n                best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.population[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm CauchyDE scored 0.320 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["48a1b0cd-3634-4253-ad7c-6a0d37274741"], "operator": null, "metadata": {"aucs": [0.13439321218720524, 0.19920934275140612, 0.29141228817815323, 0.24803153529987187, 0.25265834106134344, 0.27434402315255435, 0.27365647147743444, 0.25354658588198853, 0.23008514763503418, 0.1939329856109674, 0.2603821596286543, 0.9972906523215253, 0.2550895561914346, 0.26434455245198474, 0.7051531984360506, 0.321961713153905, 0.2710761603124111, 0.31608056421117625, 0.17784655958414064, 0.4767096101041597]}}
{"id": "f1080e44-c810-4694-a285-8c6101b67069", "fitness": 0.3355689268612374, "name": "SelfAdaptiveDEArchiveRestart", "description": "A differential evolution strategy with self-adaptive parameters, archive, and a restart mechanism based on fitness concentration to escape local optima.", "code": "import numpy as np\n\nclass SelfAdaptiveDEArchiveRestart:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, archive_size=50, restart_threshold=1e-9):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.archive_size = archive_size\n        self.restart_threshold = restart_threshold\n        self.archive = []\n        self.archive_fitness = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        memory_F = np.ones(self.popsize) * self.F\n        memory_CR = np.ones(self.popsize) * self.CR\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n\n                F = np.random.normal(memory_F[i], 0.1)\n                F = np.clip(F, 0.1, 1.0)\n                \n                mutant = x1 + F * (x2 - x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                CR = np.random.normal(memory_CR[i], 0.1)\n                CR = np.clip(CR, 0.1, 1.0)\n                \n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    # Update individual\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    # Update memory\n                    memory_F[i] = F\n                    memory_CR[i] = CR\n                    \n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        # Replace the worst element in the archive\n                        max_archive_idx = np.argmax(self.archive_fitness) # Higher fitness is worse!\n                        if self.fitness[i] < self.archive_fitness[max_archive_idx]:\n                            self.archive[max_archive_idx] = self.population[i].copy()\n                            self.archive_fitness[max_archive_idx] = self.fitness[i]\n                            \n                    # Update best\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                else:\n                    # Add parent to archive if trial is worse\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        # Replace the worst element in the archive\n                        max_archive_idx = np.argmax(self.archive_fitness) # Higher fitness is worse!\n                        if self.fitness[i] < self.archive_fitness[max_archive_idx]:\n                            self.archive[max_archive_idx] = self.population[i].copy()\n                            self.archive_fitness[max_archive_idx] = self.fitness[i]\n\n            # Restart mechanism based on fitness concentration\n            if np.std(self.fitness) < self.restart_threshold:\n                # Replace a portion of the population with individuals from the archive and some random individuals\n                num_archive = int(0.5 * self.popsize)\n                num_random = self.popsize - num_archive\n\n                if self.archive:\n                    archive_indices = np.random.choice(len(self.archive), min(num_archive, len(self.archive)), replace=False)\n                    self.population[:min(num_archive, len(self.archive))] = np.array(self.archive)[archive_indices]\n                \n                self.population[min(num_archive, len(self.archive)):] = np.random.uniform(lb, ub, size=(num_random, self.dim))\n\n                self.fitness = np.array([func(x) for x in self.population])\n                self.eval_count += num_random\n                best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.population[best_idx]\n                memory_F = np.ones(self.popsize) * self.F\n                memory_CR = np.ones(self.popsize) * self.CR\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm SelfAdaptiveDEArchiveRestart scored 0.336 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["48a1b0cd-3634-4253-ad7c-6a0d37274741"], "operator": null, "metadata": {"aucs": [0.21209615922268765, 0.5246268029357191, 0.605552745286543, 0]}}
{"id": "2d22ab48-e76a-459b-a9f8-0a09d4a9e9f3", "fitness": 0.5771242494900863, "name": "DynamicDESrestart", "description": "Differential Evolution with a dynamically adjusted population size and a restart mechanism based on stagnation detection and an information-theoretic measure.", "code": "import numpy as np\n\nclass DynamicDESrestart:\n    def __init__(self, budget=10000, dim=10, initial_popsize=None, F=0.5, CR=0.7, popsize_factor=2, stagnation_threshold=1e-6, entropy_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_popsize = initial_popsize if initial_popsize is not None else 10 * self.dim\n        self.popsize = self.initial_popsize\n        self.F = F\n        self.CR = CR\n        self.popsize_factor = popsize_factor  # Factor to increase popsize\n        self.stagnation_threshold = stagnation_threshold\n        self.entropy_threshold = entropy_threshold\n        self.eval_count = 0\n        self.restart_count = 0\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n                if self.eval_count >= self.budget:\n                    return self.f_opt, self.x_opt\n\n            # Check for stagnation and restart or increase popsize\n            if np.std(self.fitness) < self.stagnation_threshold or self.calculate_entropy(self.population) < self.entropy_threshold:\n                self.restart_count += 1\n                if self.popsize < self.initial_popsize * 4: # Limit popsize increase to a factor of 4\n                    self.popsize = int(self.popsize * self.popsize_factor)\n                    self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n                    self.fitness = np.array([func(x) for x in self.population])\n                    self.eval_count += self.popsize\n                    best_idx = np.argmin(self.fitness)\n                    self.f_opt = self.fitness[best_idx]\n                    self.x_opt = self.population[best_idx]\n\n                else:  # Full Restart\n                    self.population = np.random.uniform(lb, ub, size=(self.initial_popsize, self.dim))\n                    self.fitness = np.array([func(x) for x in self.population])\n                    self.popsize = self.initial_popsize\n                    self.eval_count += self.initial_popsize\n                    best_idx = np.argmin(self.fitness)\n                    self.f_opt = self.fitness[best_idx]\n                    self.x_opt = self.population[best_idx]\n        return self.f_opt, self.x_opt\n\n    def calculate_entropy(self, data, bins=10):\n        \"\"\"Calculates entropy of the population distribution in each dimension.\"\"\"\n        entropy = 0.0\n        for i in range(self.dim):\n            hist, _ = np.histogram(data[:, i], bins=bins, density=True)\n            hist = hist + 1e-10  # Avoid log(0)\n            pk = hist / np.sum(hist)\n            entropy += -np.sum(pk * np.log2(pk))\n        return entropy / self.dim", "configspace": "", "generation": 2, "feedback": "The algorithm DynamicDESrestart scored 0.577 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["48a1b0cd-3634-4253-ad7c-6a0d37274741"], "operator": null, "metadata": {"aucs": [0.2122995498876722, 0.35546190709425085, 0.5787050884204535, 0.8569926852259717, 0.6244068885807467, 0.6565983773433084, 0.5575756956130014, 0.5676372920607907, 0.612547552695222, 0.5655981299149694, 0.7748824805022828, 0.9985575451333203, 0.349061845178971, 0.6178202520267594, 0.8066376461237404, 0.6763293055300078, 0]}}
{"id": "36c3e18d-0814-4a36-85d6-7085ee6aafb3", "fitness": 0.26337670882329933, "name": "DynamicDE", "description": "Differential Evolution with a dynamically adjusted population size and covariance matrix adaptation for mutation.", "code": "import numpy as np\n\nclass DynamicDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=20, min_pop_size=5, max_pop_size=100, adapt_freq=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.adapt_freq = adapt_freq\n        self.F = 0.5\n        self.CR = 0.7\n        self.CMA_mu = int(self.pop_size / 4)\n        self.CMA_sigma = 0.1\n        self.CMA_C = np.eye(self.dim)\n        self.CMA_d = np.ones(self.dim)\n        self.CMA_eigenspace = np.eye(self.dim)\n        self.t = 0\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_fitness_history = []\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation using CMA\n                z = np.random.normal(0, 1, self.dim)\n                mutant = self.population[i] + self.CMA_sigma * self.CMA_eigenspace.dot(self.CMA_d * z)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                if f < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = trial\n            \n            self.best_fitness_history.append(self.f_opt)\n\n            # Population size adaptation\n            if self.t % self.adapt_freq == 0:\n                if len(self.best_fitness_history) > self.adapt_freq:\n                    improvement = self.best_fitness_history[-self.adapt_freq-1] - self.best_fitness_history[-1]\n                    if improvement > 0:\n                        self.pop_size = min(self.pop_size + 1, self.max_pop_size)\n                    else:\n                        self.pop_size = max(self.pop_size - 1, self.min_pop_size)\n\n                    if self.pop_size != self.population.shape[0]:\n                        # Resize population (keep best individuals)\n                        best_indices = np.argsort(self.fitness)[:self.pop_size]\n                        self.population = self.population[best_indices]\n                        self.fitness = self.fitness[best_indices]\n                        while self.population.shape[0] < self.pop_size:\n                            x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(1, self.dim))\n                            f = func(x[0])\n                            self.budget -= 1\n                            self.population = np.vstack((self.population, x))\n                            self.fitness = np.append(self.fitness, f)\n\n\n            # CMA Update\n            if self.t % self.adapt_freq == 0:\n              \n                # Sort population based on fitness\n                sorted_indices = np.argsort(self.fitness)\n                mu_individuals = self.population[sorted_indices[:self.CMA_mu]]\n                \n                # Calculate the weighted mean of the selected individuals\n                weights = np.log(self.CMA_mu + 0.5) - np.log(np.arange(1, self.CMA_mu + 1))\n                weights /= np.sum(weights)\n                mean = np.sum(mu_individuals * weights[:, np.newaxis], axis=0)\n                \n                # Update covariance matrix\n                C = np.zeros_like(self.CMA_C)\n                for k in range(self.CMA_mu):\n                    diff = mu_individuals[k] - mean\n                    C += weights[k] * np.outer(diff, diff)\n                self.CMA_C = C\n\n                # Eigendecomposition\n                self.CMA_d, self.CMA_eigenspace = np.linalg.eigh(self.CMA_C)\n                self.CMA_d = np.sqrt(np.maximum(self.CMA_d, 0)) # Ensure positive values\n                \n\n            self.t += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm DynamicDE scored 0.263 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["90627713-fbf7-40fc-a4a5-99a11978eaf3"], "operator": null, "metadata": {"aucs": [0.10852964674068677, 0.24552281372860674, 0.2872277161313148, 0.25054601824628564, 0.15825494992569367, 0.2511047402589006, 0.23162560485692751, 0.22324614603053694, 0.19711763559659712, 0.15231345394783147, 0.2136617927603658, 0.6432868867212791, 0.35181803394684397, 0.17377381786346724, 0.8254668492479952, 0.2855459691714983, 0.23197505228587467, 0.2566626119860511, 0.17985443701922998, 0]}}
{"id": "e1f2bf71-49f5-49c9-9fab-27d194e62335", "fitness": 0.401019546271831, "name": "AdaptiveDERestart", "description": "An adaptive DE with a restart mechanism and a learning rate annealing strategy for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDERestart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.restart_prob = restart_prob\n        self.learning_rate = 1.0  # Initial learning rate for parameter adaptation\n        self.learning_rate_decay = 0.995  # Decay factor for learning rate\n\n    def _mutation_rand1(self, population, best_idx):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        return population[idxs[0]] + self.F * (population[idxs[1]] - population[idxs[2]])\n\n    def _crossover(self, mutant, target):\n         return np.where(np.random.rand(self.dim) < self.CR, mutant, target)\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        used_budget = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        \n        generation = 0\n        while used_budget < self.budget:\n            generation += 1\n            \n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            \n            for i in range(self.pop_size):\n                # Mutation\n                mutant = self._mutation_rand1(population, best_idx)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                trial_vector = self._crossover(mutant, population[i])\n                \n                # Evaluation\n                f = func(trial_vector)\n                used_budget += 1\n                \n                # Selection\n                if f < fitness[i]:\n                    new_fitness[i] = f\n                    new_population[i] = trial_vector\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n\n            population = new_population\n            fitness = new_fitness\n            best_idx = np.argmin(fitness)\n            \n            # Parameter Adaptation with learning rate annealing\n            self.F = np.clip(self.F + self.learning_rate * np.random.normal(0, 0.01), 0.1, 0.9)\n            self.CR = np.clip(self.CR + self.learning_rate * np.random.normal(0, 0.01), 0.1, 0.9)\n            \n            # Restart mechanism\n            if np.random.rand() < self.restart_prob:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                used_budget += self.pop_size\n                \n                best_idx = np.argmin(fitness)\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n\n            # Anneal the learning rate\n            self.learning_rate *= self.learning_rate_decay\n\n\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDERestart scored 0.401 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ce708f84-36b8-44d0-a9e7-858e653fc1cc"], "operator": null, "metadata": {"aucs": [0.20143481343767466, 0.268826950375712, 0.37196788419838156, 0.3470456343355719, 0.4177146513830057, 0.4577741034056677, 0.2968626531965347, 0.36263233347856416, 0.3067174594318297, 0.22051578703740682, 0.42342668246378745, 0.9858194638717183, 0.32264764854735206, 0.3333049908266996, 0.7164459743201208, 0.4537522400839301, 0.3547101738257813, 0.4868783917287246, 0.18280541580447296, 0.5091076736836847]}}
{"id": "7d1ac466-6146-47bc-9677-77516426b583", "fitness": 0.5252868701531569, "name": "CauchyAdaptiveDE", "description": "Differential Evolution with a Cauchy mutation operator and adaptive parameter control based on success rate.", "code": "import numpy as np\n\nclass CauchyAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, F_adaptive=True, CR_adaptive=True, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.F_adaptive = F_adaptive\n        self.CR_adaptive = CR_adaptive\n        self.cauchy_scale = cauchy_scale\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        memory_F = np.ones(self.popsize) * self.F\n        memory_CR = np.ones(self.popsize) * self.CR\n        success_F = []\n        success_CR = []\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation using Cauchy distribution\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n\n                if self.F_adaptive:\n                     F = memory_F[i]\n                else:\n                     F = self.F\n                \n                mutant = x1 + F * np.random.standard_cauchy(size=self.dim) * self.cauchy_scale * (x2 - x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                if self.CR_adaptive:\n                    CR = memory_CR[i]\n                else:\n                    CR = self.CR\n                \n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    success_F.append(F)\n                    success_CR.append(CR)\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n                    if self.F_adaptive:\n                        memory_F[i] = np.random.normal(self.F, 0.1)\n                        memory_F[i] = np.clip(memory_F[i], 0.1, 1.0)\n                    if self.CR_adaptive:\n                        memory_CR[i] = np.random.normal(self.CR, 0.1)\n                        memory_CR[i] = np.clip(memory_CR[i], 0.1, 1.0)\n            \n            # Adaptive F and CR based on success history\n            if self.F_adaptive and len(success_F) > 0:\n                self.F = np.mean(success_F)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                success_F = []\n            if self.CR_adaptive and len(success_CR) > 0:\n                self.CR = np.mean(success_CR)\n                self.CR = np.clip(self.CR, 0.1, 1.0)\n                success_CR = []\n                \n\n            # Population diversity maintenance (optional)\n            if np.std(self.fitness) < 1e-8:  # Stagnation\n                self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.eval_count += self.popsize\n                best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.population[best_idx]\n                memory_F = np.ones(self.popsize) * self.F\n                memory_CR = np.ones(self.popsize) * self.CR\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm CauchyAdaptiveDE scored 0.525 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["48a1b0cd-3634-4253-ad7c-6a0d37274741"], "operator": null, "metadata": {"aucs": [0.23746213089101997, 0.21040390772688278, 0.36990031642146337, 0.3144766519126696, 0.7488656203091258, 0.6553679424741784, 0.3322681024428331, 0.4292160380491161, 0.713011921551078, 0.5959575928794888, 0.4875398210684653, 0.9929777231198338, 0.27017278776143416, 0.3945141065253349, 0.730563210537339, 0.7639328583804917, 0.4287477411062107, 0.7598769288110593, 0.5658101193174181, 0.5046718817776952]}}
{"id": "7a86dc02-d5a6-4e45-9f38-1366ac69ed87", "fitness": 0.7570715556935182, "name": "AdaptiveDELocalSearch", "description": "An adaptive Differential Evolution variant using a pool of mutation strategies, adaptive parameter control based on fitness improvement, and a local search operator triggered probabilistically.", "code": "import numpy as np\n\nclass AdaptiveDELocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_prob = local_search_prob\n        self.mutation_strategies = [self._mutation_rand1, self._mutation_current_to_best_1, self._mutation_best1]\n        self.success_counts = [1] * len(self.mutation_strategies)\n        self.total_counts = [1] * len(self.mutation_strategies)\n        self.epsilon = 1e-6\n        self.archive = []\n        self.archive_fitness = []\n\n    def _mutation_rand1(self, population, best_idx):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        return population[idxs[0]] + self.F * (population[idxs[1]] - population[idxs[2]])\n\n    def _mutation_current_to_best_1(self, population, best_idx, i):\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        return population[i] + self.F * (population[best_idx] - population[i]) + self.F * (population[idxs[0]] - population[idxs[1]])\n\n    def _mutation_best1(self, population, best_idx):\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        return population[best_idx] + self.F * (population[idxs[0]] - population[idxs[1]])\n\n    def _local_search(self, x, func):\n        # Simple random walk local search\n        step_size = 0.1 * (func.bounds.ub - func.bounds.lb)\n        new_x = x + np.random.uniform(-step_size, step_size, size=self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        used_budget = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        \n        while used_budget < self.budget:\n            for i in range(self.pop_size):\n                # Adaptive mutation strategy selection\n                probabilities = np.array(self.success_counts) / np.array(self.total_counts)\n                probabilities /= np.sum(probabilities)\n                mutation_idx = np.random.choice(len(self.mutation_strategies), p=probabilities)\n                \n                if mutation_idx == 0:\n                    mutant = self._mutation_rand1(population, best_idx)\n                elif mutation_idx == 1:\n                    mutant = self._mutation_current_to_best_1(population, best_idx, i)\n                else:\n                    mutant = self._mutation_best1(population, best_idx)\n                    \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial_vector = self._local_search(trial_vector, func)\n                \n                # Evaluation\n                f = func(trial_vector)\n                used_budget += 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    self.success_counts[mutation_idx] += 1\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                \n                self.total_counts[mutation_idx] += 1\n            \n            best_idx = np.argmin(fitness)\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDELocalSearch scored 0.757 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ce708f84-36b8-44d0-a9e7-858e653fc1cc"], "operator": null, "metadata": {"aucs": [0.34249109055027727, 0.36612510721836466, 0.8754213060280129, 0.9322181169257143, 0.8813036344709548, 0.9036976414186576, 0.8393634919034909, 0.8535400068777539, 0.8828150980647677, 0.8497393007987746, 0.9492288226784592, 0.9996515833658283, 0.6522556034514085, 0.8723411374478569, 0.9626823923523626, 0.8889278205834193, 0.4447850581106262, 0.9265108014078611, 0.1995946723498967, 0.5187384278658753]}}
{"id": "ded6f06d-602a-4dcf-b350-3b186c02eeaf", "fitness": -Infinity, "name": "DE_NM", "description": "A hybrid algorithm combining the exploration of Differential Evolution with the exploitation of a Nelder-Mead simplex search, adaptively switching between them based on stagnation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=30, F=0.5, Cr=0.7, nm_iterations=5, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.nm_iterations = nm_iterations\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.de_active = True # Start with DE\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        best_value = fitness[best_index]\n\n        while self.budget > 0:\n            if self.de_active:\n                # Differential Evolution\n                for i in range(self.pop_size):\n                    # Mutation\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = a + self.F * (b - c)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    crossover = np.random.rand(self.dim) < self.Cr\n                    trial = np.where(crossover, mutant, population[i])\n\n                    # Selection\n                    trial_fitness = func(trial)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if trial_fitness < fitness[i]:\n                        fitness[i] = trial_fitness\n                        population[i] = trial.copy()\n\n                        if trial_fitness < best_value:\n                            best_value = trial_fitness\n                            best_position = trial.copy()\n\n                if self.budget <= 0:\n                    break\n\n                # Check for stagnation\n                if np.min(fitness) >= best_value:\n                    self.stagnation_counter += 1\n                else:\n                     self.stagnation_counter = 0\n                \n                if self.stagnation_counter >= self.stagnation_threshold:\n                    self.de_active = False # Switch to Nelder-Mead\n                    self.stagnation_counter = 0 #reset counter\n                    #print(\"Switching to Nelder-Mead\")\n\n            else:\n                # Nelder-Mead Local Search around the best solution\n                result = minimize(func, best_position, method='Nelder-Mead', options={'maxiter': self.nm_iterations, 'maxfev':self.budget})\n                if result.success:\n                    best_position = result.x\n                    best_value = result.fun\n                self.budget -= result.nfev\n                if self.budget <= 0:\n                    break\n                self.de_active = True # Switch back to DE after local search\n                #print(\"Switching back to DE\")\n                # Re-evaluate population to update values based on the NM improvement\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size - 1 #subtract 1, as best_value is known from above\n                if self.budget <= 0:\n                    break\n\n\n\n        self.f_opt = best_value\n        self.x_opt = best_position\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 70, in __call__\nNameError: name 'minimize' is not defined\n.", "error": "", "parent_ids": ["648fb854-d4b7-4e5f-8923-eadd4b221ef9"], "operator": null, "metadata": {}}
{"id": "e3f173c3-5cf1-40fe-904c-edfce38db62d", "fitness": -Infinity, "name": "OrthogonalLearningDE", "description": "A Differential Evolution strategy that incorporates a self-adaptive learning rate and a diversity maintenance mechanism using orthogonal learning.", "code": "import numpy as np\n\nclass OrthogonalLearningDE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, F=0.5, Cr=0.9, lr_init=0.1, lr_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lr_init = lr_init\n        self.lr_decay = lr_decay\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        best_fitness = fitness[best_index]\n        best_solution = population[best_index].copy()\n\n        learning_rate = self.lr_init\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.Cr\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Evaluate\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial_vector\n\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial_vector.copy()\n                        learning_rate = self.lr_init  # Reset learning rate upon improvement\n                \n                # Orthogonal Learning-based Population Update\n                else:\n                    # Create orthogonal array (simplified - 2-level factorial design)\n                    oa_matrix = np.array([[1, 1], [1, -1], [-1, 1], [-1, -1]]) # 2 factors, 2 levels\n                    \n                    # Select two random dimensions\n                    dims_to_explore = np.random.choice(self.dim, 2, replace=False)\n                    \n                    # Iterate through orthogonal array points\n                    for oa_point in oa_matrix:\n                        new_individual = population[i].copy()\n\n                        # Map OA levels to function bounds for selected dimensions\n                        for j, dim_idx in enumerate(dims_to_explore):\n                            if oa_point[j] == 1:\n                                new_individual[dim_idx] = np.random.uniform(population[i][dim_idx], func.bounds.ub)\n                            else:\n                                new_individual[dim_idx] = np.random.uniform(func.bounds.lb, population[i][dim_idx])\n                        \n                            new_individual[dim_idx] = np.clip(new_individual[dim_idx], func.bounds.lb, func.bounds.ub)\n                        \n                        new_fitness = func(new_individual)\n                        self.budget -= 1\n                        if self.budget <= 0:\n                           break\n                        \n                        if new_fitness < fitness[i]:\n                            fitness[i] = new_fitness\n                            population[i] = new_individual.copy()\n                            if new_fitness < best_fitness:\n                                best_fitness = new_fitness\n                                best_solution = new_individual.copy()\n                        \n                    if self.budget <= 0:\n                        break\n\n\n            learning_rate *= self.lr_decay #Decay learning rate each generation\n\n        self.f_opt = best_fitness\n        self.x_opt = best_solution\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occured: TypeError: only size-1 arrays can be converted to Python scalars\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 68, in __call__\nValueError: setting an array element with a sequence.\n.", "error": "", "parent_ids": ["648fb854-d4b7-4e5f-8923-eadd4b221ef9"], "operator": null, "metadata": {}}
{"id": "390d48d2-6af7-477f-91d6-48c9d7b2ab03", "fitness": -Infinity, "name": "SelfAdjustingDE", "description": "A self-adjusting Differential Evolution algorithm that dynamically adapts its parameters (F, CR) and mutation strategy based on the recent success rate of generating better solutions.", "code": "import numpy as np\n\nclass SelfAdjustingDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, initial_F=0.5, initial_CR=0.7, learning_rate=0.1, mutation_strategies=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = initial_F\n        self.CR = initial_CR\n        self.learning_rate = learning_rate\n        self.eval_count = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        if mutation_strategies is None:\n             self.mutation_strategies = [\n                lambda x, F, x1, x2, x3: x1 + F * (x2 - x3),  # DE/rand/1\n                lambda x, F, x1, x2, x3: x + F * (x1 - x2),    # DE/current-to-rand/1\n                lambda x, F, x1, x2, x3: x1 + F * (x2 - x3) + F*(x4 - x5) #DE/rand/2, implemented by using x4 and x5 as the next two random vectors\n            ]\n        else:\n            self.mutation_strategies = mutation_strategies\n        self.num_mutation_strategies = len(self.mutation_strategies)\n        self.success_counts = np.zeros(self.num_mutation_strategies)\n        self.strategy_weights = np.ones(self.num_mutation_strategies) / self.num_mutation_strategies\n\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n\n                # Strategy Selection\n                strategy_index = np.random.choice(self.num_mutation_strategies, p=self.strategy_weights)\n                mutation_strategy = self.mutation_strategies[strategy_index]\n\n\n                # Mutation\n                idxs = np.random.choice(self.popsize, 5, replace=False) #pick 5 random indices for DE/rand/2\n                x1, x2, x3, x4, x5 = self.population[idxs]\n                mutant = mutation_strategy(self.population[i], self.F, x1, x2, x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.success_counts[strategy_index] += 1\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n                    # Adjust F and CR\n                    self.F = np.clip(self.F + self.learning_rate * np.random.normal(0, 0.1), 0.1, 0.9)\n                    self.CR = np.clip(self.CR + self.learning_rate * np.random.normal(0, 0.1), 0.1, 0.9)\n\n                if self.eval_count >= self.budget:\n                    return self.f_opt, self.x_opt\n            # Update strategy weights based on success counts\n            self.strategy_weights = (1 - self.learning_rate) * self.strategy_weights + self.learning_rate * (self.success_counts / np.sum(self.success_counts))\n            self.strategy_weights /= np.sum(self.strategy_weights)  # Normalize\n            self.success_counts[:] = 0  # Reset success counts after updating weights\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 49, in __call__\n  File \"<string>\", line 19, in <lambda>\nNameError: name 'x4' is not defined\n.", "error": "", "parent_ids": ["2d22ab48-e76a-459b-a9f8-0a09d4a9e9f3"], "operator": null, "metadata": {}}
{"id": "9544669e-cee1-4e77-9424-0ddb6b8dad8a", "fitness": -Infinity, "name": "SelfAdaptiveDE_NM", "description": "Differential Evolution with self-adaptive population size and a weighted difference mutation, combined with a local search based on Nelder-Mead simplex.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SelfAdaptiveDE_NM:\n    def __init__(self, budget=10000, dim=10, popsize_init=None, F=0.5, CR=0.7, local_search_freq=10):\n        self.budget = budget\n        self.dim = dim\n        self.popsize_init = popsize_init if popsize_init is not None else 10 * self.dim\n        self.popsize = self.popsize_init\n        self.F = F\n        self.CR = CR\n        self.local_search_freq = local_search_freq\n        self.eval_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        generation = 0\n\n        while self.eval_count < self.budget:\n            generation += 1\n            for i in range(self.popsize):\n                # Weighted Difference Mutation\n                idxs = np.random.choice(self.popsize, 4, replace=False)\n                x1, x2, x3, x4 = self.population[idxs]\n                weights = np.random.rand(2)\n                weights /= np.sum(weights)  # Normalize weights\n                mutant = x1 + self.F * (weights[0] * (x2 - x3) + weights[1] * (x4 - x1))  # Weighted difference\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n            # Local Search (Nelder-Mead)\n            if generation % self.local_search_freq == 0:\n                idx = np.argmin(self.fitness)\n                x_local = self.population[idx].copy()\n                \n                def obj_for_nm(x):\n                    return func(x)\n\n                res = minimize(obj_for_nm, x_local, method='Nelder-Mead', bounds=func.bounds)\n                nfev = res.nfev\n                if self.eval_count + nfev <= self.budget:\n                    self.eval_count += nfev\n                    f_local = res.fun\n                    x_local = res.x\n                    if f_local < self.f_opt:\n                        self.f_opt = f_local\n                        self.x_opt = x_local\n                else:\n                   break  # Stop if local search exceeds budget\n            \n            # Self-Adaptive Population Size (simplified - can be made more sophisticated)\n            if generation % 20 == 0:  # Adjust every 20 generations\n                if np.std(self.fitness) < 1e-6:  # Stagnation\n                    self.popsize = int(self.popsize * 0.8)\n                    if self.popsize < 4 * self.dim:\n                        self.popsize = self.popsize_init  # Reset\n                    \n                    # Resample population (only if budget allows)\n                    if self.eval_count + self.popsize * self.dim <= self.budget:\n                        new_population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n                        new_fitness = np.array([func(x) for x in new_population])\n                        self.eval_count += self.popsize\n                        \n                        # Combine old and new populations and select best\n                        combined_population = np.concatenate((self.population, new_population))\n                        combined_fitness = np.concatenate((self.fitness, new_fitness))\n                        \n                        indices = np.argsort(combined_fitness)[:self.popsize]\n                        self.population = combined_population[indices]\n                        self.fitness = combined_fitness[indices]\n                        \n                        best_idx = np.argmin(self.fitness)\n                        self.f_opt = self.fitness[best_idx]\n                        self.x_opt = self.population[best_idx]\n                    else:\n                        break\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 59, in __call__\nNameError: name 'minimize' is not defined\n.", "error": "", "parent_ids": ["7d1ac466-6146-47bc-9677-77516426b583"], "operator": null, "metadata": {}}
{"id": "6a191389-7c05-4aa3-bf5d-1d4156c41ee6", "fitness": -Infinity, "name": "AdaptiveDECrossoverRepair", "description": "Differential Evolution with self-adaptive parameters, a combination of Gaussian and Cauchy mutation, and a repair mechanism to enhance boundary exploration.", "code": "import numpy as np\n\nclass AdaptiveDECrossoverRepair:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        memory_F = np.ones(self.popsize) * self.F\n        memory_CR = np.ones(self.popsize) * self.CR\n        success_F = []\n        success_CR = []\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation using a combination of Gaussian and Cauchy\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n\n                # Adaptive F\n                F = memory_F[i]\n                mutant = x1 + F * (np.random.normal(size=self.dim) * (x2 - x3) + 0.1 * np.random.standard_cauchy(size=self.dim) * (x1 - x3))\n                \n\n                # Crossover\n                CR = memory_CR[i]\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Repair mechanism: Reflect back if out of bounds\n                for j in range(self.dim):\n                    if trial[j] < lb:\n                        trial[j] = lb + (lb - trial[j])  # Reflect\n                        if trial[j] > ub: #If after reflection is still out of bounds, clip it.\n                           trial[j] = lb #Clip to the boundary if reflection is not sufficient\n                    elif trial[j] > ub:\n                        trial[j] = ub - (trial[j] - ub)  # Reflect\n                        if trial[j] < lb: #If after reflection is still out of bounds, clip it.\n                           trial[j] = ub #Clip to the boundary if reflection is not sufficient\n                \n                trial = np.clip(trial, lb, ub) # Another clipping for safety\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    success_F.append(F)\n                    success_CR.append(CR)\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n                    # Update memory for F and CR\n                    memory_F[i] = np.random.normal(self.F, 0.1)\n                    memory_F[i] = np.clip(memory_F[i], 0.1, 1.0)\n                    memory_CR[i] = np.random.normal(self.CR, 0.1)\n                    memory_CR[i] = np.clip(memory_CR[i], 0.1, 1.0)\n            \n            # Adaptive F and CR based on success history\n            if len(success_F) > 0:\n                self.F = np.mean(success_F)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                success_F = []\n            if len(success_CR) > 0:\n                self.CR = np.mean(success_CR)\n                self.CR = np.clip(self.CR, 0.1, 1.0)\n                success_CR = []\n            \n            # Population diversity maintenance (optional)\n            if np.std(self.fitness) < 1e-8:  # Stagnation\n                self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.eval_count += self.popsize\n                best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.population[best_idx]\n                memory_F = np.ones(self.popsize) * self.F\n                memory_CR = np.ones(self.popsize) * self.CR\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 43, in __call__\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n.", "error": "", "parent_ids": ["7d1ac466-6146-47bc-9677-77516426b583"], "operator": null, "metadata": {}}
{"id": "3c63f647-24c1-4806-933c-d9fc7d1e75f5", "fitness": -Infinity, "name": "SOMA_DE", "description": "A self-organizing migrating algorithm with a differential evolution mutation strategy and adaptive population management.", "code": "import numpy as np\n\nclass SOMA_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, path_length=0.1, step_size=0.1, perturbation_chance=0.1, migration_interval=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.path_length = path_length\n        self.step_size = step_size\n        self.perturbation_chance = perturbation_chance\n        self.migration_interval = migration_interval\n        self.population = None\n        self.fitness = None\n        self.leader_index = None\n        self.generation = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.leader_index = np.argmin(self.fitness)\n\n    def migrate(self, func):\n        for i in range(self.pop_size):\n            if i == self.leader_index:\n                continue\n\n            for step in np.arange(self.step_size, self.path_length + self.step_size, self.step_size):\n                new_position = self.population[i] + step * (self.population[self.leader_index] - self.population[i])\n\n                # Perturbation\n                for d in range(self.dim):\n                    if np.random.rand() < self.perturbation_chance:\n                        new_position[d] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n                if self.budget <= 0:\n                    return\n\n                if new_fitness < self.fitness[i]:\n                    self.population[i] = new_position\n                    self.fitness[i] = new_fitness\n\n                    if new_fitness < self.fitness[self.leader_index]:\n                        self.leader_index = i\n\n    def differential_evolution_mutation(self, func):\n        # Apply DE mutation to each individual (except the leader)\n        for i in range(self.pop_size):\n            if i == self.leader_index:\n                continue\n\n            # Select three random individuals (a, b, c)\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            a, b, c = self.population[indices]\n\n            # Mutation: v = a + F * (b - c)\n            mutation_factor = 0.8  # Fixed mutation factor\n            mutated_vector = a + mutation_factor * (b - c)\n            mutated_vector = np.clip(mutated_vector, func.bounds.lb, func.bounds.ub)\n\n            # Crossover (Binomial/Uniform)\n            crossover_rate = 0.7\n            trial_vector = np.copy(self.population[i])  # Start with the current individual\n            for d in range(self.dim):\n                if np.random.rand() < crossover_rate:\n                    trial_vector[d] = mutated_vector[d]\n\n            # Evaluate the trial vector\n            trial_fitness = func(trial_vector)\n            self.budget -= 1\n            if self.budget <= 0:\n                return\n            \n\n            # Selection: Replace if the trial vector is better\n            if trial_fitness < self.fitness[i]:\n                self.population[i] = trial_vector\n                self.fitness[i] = trial_fitness\n\n                if trial_fitness < self.fitness[self.leader_index]:\n                    self.leader_index = i\n    \n    def adapt_population(self, func):\n        # Check for stagnation (e.g., little improvement in leader's fitness)\n        stagnation_threshold = 1e-6\n        if self.generation > 50 and np.abs(self.fitness[self.leader_index] - self.previous_leader_fitness) < stagnation_threshold:\n            # Introduce new random individuals to increase diversity\n            num_new_individuals = int(self.pop_size * 0.2)  # Replace 20% of population\n            new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new_individuals, self.dim))\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= num_new_individuals\n            if self.budget <= 0:\n                return\n            \n\n            # Replace the worst individuals with the new ones\n            worst_indices = np.argsort(self.fitness)[-num_new_individuals:]\n            self.population[worst_indices] = new_population\n            self.fitness[worst_indices] = new_fitness\n\n            # Update the leader\n            self.leader_index = np.argmin(self.fitness)\n\n        self.previous_leader_fitness = self.fitness[self.leader_index]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        self.previous_leader_fitness = self.fitness[self.leader_index]\n\n        while self.budget > 0:\n            self.migrate(func)\n            if self.budget <= 0:\n                break\n            \n            self.differential_evolution_mutation(func)\n            if self.budget <= 0:\n                break\n            \n            self.adapt_population(func)\n            if self.budget <= 0:\n                break\n\n            self.generation += 1\n\n        self.f_opt = self.fitness[self.leader_index]\n        self.x_opt = self.population[self.leader_index]\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occured: TypeError: only size-1 arrays can be converted to Python scalars\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 115, in __call__\n  File \"<string>\", line 34, in migrate\nValueError: setting an array element with a sequence.\n.", "error": "", "parent_ids": ["648fb854-d4b7-4e5f-8923-eadd4b221ef9"], "operator": null, "metadata": {}}
{"id": "20431147-1cc6-4c6e-91bf-0ddc8f90643f", "fitness": 0.0, "name": "AdaptiveDE", "description": "Differential Evolution with self-adaptive population size and a combined Cauchy-Gaussian mutation, dynamically adjusting mutation strength based on stagnation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_popsize=None, F=0.5, CR=0.7, stagnation_threshold=1e-6, popsize_reduction_factor=0.9, popsize_increase_factor=1.1, min_popsize=10, cauchy_scale=0.1, gaussian_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_popsize = initial_popsize if initial_popsize is not None else 10 * self.dim\n        self.popsize = self.initial_popsize\n        self.F = F\n        self.CR = CR\n        self.stagnation_threshold = stagnation_threshold\n        self.popsize_reduction_factor = popsize_reduction_factor\n        self.popsize_increase_factor = popsize_increase_factor\n        self.min_popsize = min_popsize\n        self.cauchy_scale = cauchy_scale\n        self.gaussian_scale = gaussian_scale\n\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        stagnation_counter = 0\n        mutation_strength = 1.0  # Initial mutation strength\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation: Combined Cauchy and Gaussian\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n\n                cauchy_component = np.random.standard_cauchy(size=self.dim) * self.cauchy_scale\n                gaussian_component = np.random.normal(0, 1, size=self.dim) * self.gaussian_scale\n\n                mutant = x1 + self.F * mutation_strength * (cauchy_component + gaussian_component) * (x2 - x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n            # Adaptive Population Size\n            if len(self.best_fitness_history) > 1:\n                if abs(self.best_fitness_history[-1] - self.best_fitness_history[-2]) < self.stagnation_threshold:\n                    stagnation_counter += 1\n                else:\n                    stagnation_counter = 0\n\n            if stagnation_counter > 5:  # Stagnation detected\n                # Reduce population size\n                new_popsize = int(self.popsize * self.popsize_reduction_factor)\n                new_popsize = max(new_popsize, self.min_popsize)\n\n                if new_popsize < self.popsize:\n                    self.popsize = new_popsize\n                    self.population = self.population[np.argsort(self.fitness)[:self.popsize]]\n                    self.fitness = self.fitness[np.argsort(self.fitness)[:self.popsize]]\n                    stagnation_counter = 0\n                    mutation_strength *= 0.8 # Decrease mutation strength upon stagnation\n                else:\n                     mutation_strength *= 1.2 # Increase mutation strength when not reducing popsize to escape local optima.\n\n            elif self.eval_count/self.budget > 0.75 and self.popsize < self.initial_popsize * 2: #Late increase to improve the optimum\n                new_popsize = int(self.popsize * self.popsize_increase_factor)\n                if new_popsize > self.popsize and self.eval_count + new_popsize - self.popsize < self.budget:\n                     new_individuals = np.random.uniform(lb, ub, size=(new_popsize - self.popsize, self.dim))\n                     new_fitness = np.array([func(x) for x in new_individuals])\n                     self.eval_count += new_popsize - self.popsize\n                     self.population = np.vstack((self.population, new_individuals))\n                     self.fitness = np.concatenate((self.fitness, new_fitness))\n                     self.popsize = new_popsize\n\n\n            self.best_fitness_history.append(self.f_opt)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7d1ac466-6146-47bc-9677-77516426b583"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "bdddf431-fae9-4d1a-a217-0b58e4b89411", "fitness": 0.18892458448935684, "name": "SelfOrganizingScoutBee", "description": "A self-organizing scout bee algorithm with dynamic step size adaptation and random opposition-based learning for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass SelfOrganizingScoutBee:\n    def __init__(self, budget=10000, dim=10, num_bees=50, scout_rate=0.1, step_size_init=0.5, step_size_decay=0.99, opposition_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.num_bees = num_bees\n        self.scout_rate = scout_rate\n        self.step_size_init = step_size_init\n        self.step_size_decay = step_size_decay\n        self.opposition_rate = opposition_rate\n\n    def __call__(self, func):\n        # Initialize bee positions randomly\n        bees = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_bees, self.dim))\n        fitness = np.array([func(bee) for bee in bees])\n        self.budget -= self.num_bees\n\n        # Find the best bee\n        best_index = np.argmin(fitness)\n        best_bee = bees[best_index].copy()\n        best_fitness = fitness[best_index]\n\n        step_size = self.step_size_init\n\n        while self.budget > 0:\n            for i in range(self.num_bees):\n                # Scout bees: random exploration\n                if np.random.rand() < self.scout_rate:\n                    new_bee = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    new_fitness = func(new_bee)\n                    self.budget -= 1\n\n                    if new_fitness < fitness[i]:\n                        bees[i] = new_bee\n                        fitness[i] = new_fitness\n\n                        if new_fitness < best_fitness:\n                            best_fitness = new_fitness\n                            best_bee = new_bee.copy()\n\n                # Employed bees: exploitation around the best bee\n                else:\n                    # Select a random dimension to modify\n                    dim_index = np.random.randint(self.dim)\n\n                    # Generate a random step in that dimension\n                    step = np.random.uniform(-step_size, step_size)\n\n                    # Create a new bee based on the current bee and the random step\n                    new_bee = bees[i].copy()\n                    new_bee[dim_index] += step\n                    new_bee = np.clip(new_bee, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate the new bee\n                    new_fitness = func(new_bee)\n                    self.budget -= 1\n                    \n                    if self.budget <= 0:\n                        break\n\n                    # Update if the new bee is better\n                    if new_fitness < fitness[i]:\n                        bees[i] = new_bee\n                        fitness[i] = new_fitness\n                        \n                        if new_fitness < best_fitness:\n                            best_fitness = new_fitness\n                            best_bee = new_bee.copy()\n                    \n                    # Opposition based learning:\n                    elif np.random.rand() < self.opposition_rate:\n                        opposite_bee = func.bounds.ub + func.bounds.lb - new_bee\n                        opposite_bee = np.clip(opposite_bee, func.bounds.lb, func.bounds.ub)\n                        opposite_fitness = func(opposite_bee)\n                        self.budget -=1\n                        if self.budget <=0:\n                            break\n                        \n                        if opposite_fitness < fitness[i]:\n                            bees[i] = opposite_bee\n                            fitness[i] = opposite_fitness\n\n                            if opposite_fitness < best_fitness:\n                                best_fitness = opposite_fitness\n                                best_bee = opposite_bee.copy()\n            \n            if self.budget <= 0:\n                break\n            # Decay step size\n            step_size *= self.step_size_decay\n\n        self.f_opt = best_fitness\n        self.x_opt = best_bee\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm SelfOrganizingScoutBee scored 0.189 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["648fb854-d4b7-4e5f-8923-eadd4b221ef9"], "operator": null, "metadata": {"aucs": [0.12227512998472811, 0.20187017797865425, 0.3295502790782605, 0.20899895039005933, 0.18898679740139546, 0.20377157866611895, 0.255943762415638, 0]}}
{"id": "eaa8598a-47ab-44fa-9aa5-9d695df3b44b", "fitness": 0.34791338238190567, "name": "SelfAdaptiveDE", "description": "Differential Evolution with a self-adaptive population size and a simplified mutation strategy based on best-so-far, focusing on exploitation and faster convergence.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_popsize=None, F=0.5, CR=0.7, popsize_reduction_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.initial_popsize = initial_popsize if initial_popsize is not None else 10 * self.dim\n        self.popsize = self.initial_popsize\n        self.F = F\n        self.CR = CR\n        self.popsize_reduction_factor = popsize_reduction_factor\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        \n        generation = 0\n        while self.eval_count < self.budget:\n            generation += 1\n            for i in range(self.popsize):\n                # Simplified Mutation: Focus on exploitation using the best solution so far\n                mutant = self.x_opt + self.F * (np.random.uniform(lb, ub, size=self.dim) - self.population[i]) #Simplified mutation with random vector\n\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n            #Adapt population size\n            if generation % 10 == 0 and self.popsize > 5: \n                #Reduce population size gradually\n                new_popsize = int(self.popsize * self.popsize_reduction_factor)\n                \n                if new_popsize < 5:\n                    new_popsize = 5\n                \n                if new_popsize < self.popsize:\n                    \n                    sorted_indices = np.argsort(self.fitness)\n                    \n                    self.population = self.population[sorted_indices[:new_popsize]]\n                    self.fitness = self.fitness[sorted_indices[:new_popsize]]\n                    \n                    self.popsize = new_popsize\n                \n            if self.eval_count > self.budget:\n                break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm SelfAdaptiveDE scored 0.348 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7d1ac466-6146-47bc-9677-77516426b583"], "operator": null, "metadata": {"aucs": [0.13365867807815135, 0.24524843272583152, 0.34072506852100304, 0.32159372084816573, 0.2578306282706626, 0.30480840682262866, 0.2794601092249416, 0.2729760594975532, 0.26739211049485434, 0.19124053691934628, 0.3652315257195301, 0.9978911228035872, 0.29641875750745383, 0.2575054787289157, 0.7249010177673639, 0.34980664662399086, 0.2907700242254223, 0.3659249322861805, 0.20767554412879985, 0.48720884644373075]}}
{"id": "a86371f7-a47a-484f-9ce2-c43a46834cad", "fitness": 0.6039698152653884, "name": "AdaptiveDECMA", "description": "Adaptive Differential Evolution with a self-adaptive covariance matrix adaptation for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDECMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.learning_rate = learning_rate\n        self.C = np.eye(dim)  # Covariance matrix\n        self.mean = None\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize population\n        if self.mean is None:\n            self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        \n        population = np.random.multivariate_normal(self.mean, self.C, size=self.pop_size)\n        population = np.clip(population, func.bounds.lb, func.bounds.ub)\n        \n        fitness = np.array([func(x) for x in population])\n        used_budget = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        \n        while used_budget < self.budget:\n            # Generate mutants using DE/rand/1\n            mutants = []\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                mutant = population[idxs[0]] + self.F * (population[idxs[1]] - population[idxs[2]])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                mutants.append(mutant)\n            mutants = np.array(mutants)\n            \n            # Crossover\n            crossover_mask = np.random.rand(self.pop_size, self.dim) < self.CR\n            trial_vectors = np.where(crossover_mask, mutants, population)\n            \n            # Evaluate trial vectors\n            trial_fitness = np.array([func(x) for x in trial_vectors])\n            used_budget += self.pop_size\n            \n            # Selection\n            improved = trial_fitness < fitness\n            \n            # Update population and fitness\n            fitness[improved] = trial_fitness[improved]\n            population[improved] = trial_vectors[improved]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n            \n            # Update mean and covariance matrix adaptively\n            delta = population - self.mean\n            weighted_delta = np.mean(delta[improved], axis=0) if np.any(improved) else np.zeros(self.dim)\n            \n            self.mean = (1 - self.learning_rate) * self.mean + self.learning_rate * np.mean(population, axis=0)\n            \n            # Update covariance matrix using rank-one update (simplified)\n            if np.any(improved):\n                d = population[improved] - self.mean\n                self.C = (1 - self.learning_rate) * self.C + self.learning_rate * np.cov(d.T)\n            else:\n                 self.C = (1- self.learning_rate) * self.C + self.learning_rate * np.eye(self.dim)\n            \n\n            # Ensure covariance matrix is positive semi-definite\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)  # Reset if not positive semi-definite\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDECMA scored 0.604 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a86dc02-d5a6-4e45-9f38-1366ac69ed87"], "operator": null, "metadata": {"aucs": [0.21852909664679554, 0.47170335895146986, 0.6430861393946988, 0.8305582486152527, 0.6051676777086852, 0.6912487130992924, 0.5170296428837586, 0.5108615339848916, 0.712584923708024, 0.5703934229376095, 0.7459059462666484, 0.9134881071236669, 0.33446793102054073, 0.6229013103331548, 0.8647617728228211, 0.7222840456351995, 0.5713274794400702, 0.7927069607532382, 0.22590079118524098, 0.5144892027967076]}}
{"id": "cc204f72-c903-4864-96a0-b3db90b891ed", "fitness": 0.7938416120219675, "name": "AdaptiveDEArchiveLocalSearch", "description": "An improved adaptive Differential Evolution algorithm featuring a diversity maintenance mechanism using an archive of past solutions and a self-adaptive local search intensity.", "code": "import numpy as np\n\nclass AdaptiveDEArchiveLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, archive_size=10, local_search_prob=0.1, local_search_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.archive_size = archive_size\n        self.local_search_prob = local_search_prob\n        self.local_search_decay = local_search_decay # Decay rate for local search probability\n        self.mutation_strategies = [self._mutation_rand1, self._mutation_current_to_best_1, self._mutation_best1, self._mutation_rand_archive]\n        self.success_counts = [1] * len(self.mutation_strategies)\n        self.total_counts = [1] * len(self.mutation_strategies)\n        self.epsilon = 1e-6\n        self.archive = []\n        self.archive_fitness = []\n        self.archive_full = False\n\n\n    def _mutation_rand1(self, population, best_idx):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        return population[idxs[0]] + self.F * (population[idxs[1]] - population[idxs[2]])\n\n    def _mutation_current_to_best_1(self, population, best_idx, i):\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        return population[i] + self.F * (population[best_idx] - population[i]) + self.F * (population[idxs[0]] - population[idxs[1]])\n\n    def _mutation_best1(self, population, best_idx):\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        return population[best_idx] + self.F * (population[idxs[0]] - population[idxs[1]])\n\n    def _mutation_rand_archive(self, population):\n        if not self.archive:  # Ensure archive is not empty\n            return self._mutation_rand1(population, np.random.randint(self.pop_size))\n        \n        idx1 = np.random.choice(self.pop_size, 1, replace=False)[0]\n        idx_archive = np.random.choice(len(self.archive), 1, replace=False)[0]\n        idxs = np.random.choice(self.pop_size, 1, replace=False)[0]  # choosing only one index\n        return population[idx1] + self.F * (self.archive[idx_archive] - population[idxs])\n\n\n    def _local_search(self, x, func):\n        # Simple random walk local search\n        step_size = 0.1 * (func.bounds.ub - func.bounds.lb)\n        new_x = x + np.random.uniform(-step_size, step_size, size=self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        used_budget = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        \n        while used_budget < self.budget:\n            for i in range(self.pop_size):\n                # Adaptive mutation strategy selection\n                probabilities = np.array(self.success_counts) / np.array(self.total_counts)\n                probabilities /= np.sum(probabilities)\n                mutation_idx = np.random.choice(len(self.mutation_strategies), p=probabilities)\n                \n                if mutation_idx == 0:\n                    mutant = self._mutation_rand1(population, best_idx)\n                elif mutation_idx == 1:\n                    mutant = self._mutation_current_to_best_1(population, best_idx, i)\n                elif mutation_idx == 2:\n                    mutant = self._mutation_best1(population, best_idx)\n                else:\n                    mutant = self._mutation_rand_archive(population)\n                    \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial_vector = self._local_search(trial_vector, func)\n                    self.local_search_prob *= self.local_search_decay # Reduce local search intensity\n                \n                # Evaluation\n                f = func(trial_vector)\n                used_budget += 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    self.success_counts[mutation_idx] += 1\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n\n                    # Update archive\n                    if self.archive_full:\n                        if f < np.max(self.archive_fitness):\n                            worst_idx = np.argmax(self.archive_fitness)\n                            self.archive[worst_idx] = trial_vector\n                            self.archive_fitness[worst_idx] = f\n                    else:\n                        self.archive.append(trial_vector)\n                        self.archive_fitness.append(f)\n                        if len(self.archive) == self.archive_size:\n                            self.archive_full = True\n                \n                self.total_counts[mutation_idx] += 1\n            \n            best_idx = np.argmin(fitness)\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDEArchiveLocalSearch scored 0.794 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a86dc02-d5a6-4e45-9f38-1366ac69ed87"], "operator": null, "metadata": {"aucs": [0.6166584993218962, 0.869640622798669, 0.8550287914701845, 0.9238926460484338, 0.8793026372479534, 0.8835149185226009, 0.8074845052376618, 0.8356082219690585, 0.873779482189317, 0.849222237960959, 0.9260206041381563, 0.9989001238868584, 0.3756814081415172, 0.8694479161961688, 0.9552173147731207, 0.8801135049557453, 0.8270556753744704, 0.9176548763390975, 0.2262147834792061, 0.5063934703882735]}}
{"id": "c1c0f903-0059-4016-bf16-49231dd93155", "fitness": 0.4116225889254255, "name": "AdaptiveNichingDE", "description": "An adaptive Differential Evolution using a combination of Cauchy and Gaussian mutation, with adaptive F and CR parameters, and a niching strategy to promote diversity.", "code": "import numpy as np\n\nclass AdaptiveNichingDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, F_adaptive=True, CR_adaptive=True, cauchy_scale=0.1, gaussian_scale=0.1, niching_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.F_adaptive = F_adaptive\n        self.CR_adaptive = CR_adaptive\n        self.cauchy_scale = cauchy_scale\n        self.gaussian_scale = gaussian_scale\n        self.niching_radius = niching_radius\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        memory_F = np.ones(self.popsize) * self.F\n        memory_CR = np.ones(self.popsize) * self.CR\n        success_F = []\n        success_CR = []\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation using a combination of Cauchy and Gaussian distributions\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n\n                if self.F_adaptive:\n                     F = memory_F[i]\n                else:\n                     F = self.F\n                \n                # Apply Cauchy mutation with a certain probability, otherwise Gaussian\n                if np.random.rand() < 0.5:\n                    mutant = x1 + F * np.random.standard_cauchy(size=self.dim) * self.cauchy_scale * (x2 - x3)\n                else:\n                    mutant = x1 + F * np.random.normal(size=self.dim) * self.gaussian_scale * (x2 - x3)\n                \n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                if self.CR_adaptive:\n                    CR = memory_CR[i]\n                else:\n                    CR = self.CR\n                \n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection and Niching\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Niching: if trial is too close to another individual, penalize its fitness\n                for j in range(self.popsize):\n                    if i != j and np.linalg.norm(trial - self.population[j]) < self.niching_radius:\n                        f_trial += 0.01 * np.abs(self.fitness[j] - f_trial)  # Small penalty\n\n                if f_trial < self.fitness[i]:\n                    success_F.append(F)\n                    success_CR.append(CR)\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n                    if self.F_adaptive:\n                        memory_F[i] = np.random.normal(self.F, 0.1)\n                        memory_F[i] = np.clip(memory_F[i], 0.1, 1.0)\n                    if self.CR_adaptive:\n                        memory_CR[i] = np.random.normal(self.CR, 0.1)\n                        memory_CR[i] = np.clip(memory_CR[i], 0.1, 1.0)\n            \n            # Adaptive F and CR based on success history\n            if self.F_adaptive and len(success_F) > 0:\n                self.F = np.mean(success_F)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                success_F = []\n            if self.CR_adaptive and len(success_CR) > 0:\n                self.CR = np.mean(success_CR)\n                self.CR = np.clip(self.CR, 0.1, 1.0)\n                success_CR = []\n                \n\n            # Population diversity maintenance (optional)\n            if np.std(self.fitness) < 1e-8:  # Stagnation\n                self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.eval_count += self.popsize\n                best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.population[best_idx]\n                memory_F = np.ones(self.popsize) * self.F\n                memory_CR = np.ones(self.popsize) * self.CR\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveNichingDE scored 0.412 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7d1ac466-6146-47bc-9677-77516426b583"], "operator": null, "metadata": {"aucs": [0.20812911989973304, 0.30890687877709355, 0.3480298634772012, 0.22588749286733678, 0.27167731185953514, 0.3954354323293654, 0.33555983375674714, 0.4321213211333702, 0.37450279475577375, 0.21268833557804034, 0.8416904497445581, 0.9989937637544931, 0.2871787959774471, 0.31447778022631323, 0.734440755324706, 0.3507100708726122, 0.46955625554456737, 0.3961798702442705, 0.22821563133639344, 0.4980700210489519]}}
{"id": "83a098a5-bff6-42b6-9ba9-5fd090ed5567", "fitness": 0.0, "name": "AdaptiveVelocityDE", "description": "An adaptive Differential Evolution algorithm that uses a combination of best-so-far and random mutation with velocity updates and a restart mechanism.", "code": "import numpy as np\n\nclass AdaptiveVelocityDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, restart_prob=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.restart_prob = restart_prob\n        self.velocity = np.zeros((self.popsize, self.dim))\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation with velocity update and best-so-far component\n                random_index = np.random.randint(0, self.popsize)\n                mutant = self.population[i] + self.velocity[i] + self.F * (self.x_opt - self.population[i]) + self.F * (self.population[random_index] - self.population[i])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    # Update velocity\n                    self.velocity[i] = trial - self.population[i]\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n                # Restart mechanism: Randomly re-initialize individuals to avoid stagnation\n                if np.random.rand() < self.restart_prob:\n                    self.population[i] = np.random.uniform(lb, ub, size=self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    self.eval_count += 1\n                    self.velocity[i] = np.zeros(self.dim)  # Reset velocity\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveVelocityDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["eaa8598a-47ab-44fa-9aa5-9d695df3b44b"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "359bb483-9b04-40ef-a287-f249d66040b1", "fitness": 0.0, "name": "RingTopologyDE", "description": "An adaptive DE algorithm with a ring topology-based neighborhood and a restart mechanism based on stagnation detection, combined with local search.", "code": "import numpy as np\n\nclass RingTopologyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, neighborhood_size=5, stagnation_threshold=100, local_search_prob=0.1, local_search_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.neighborhood_size = neighborhood_size\n        self.stagnation_threshold = stagnation_threshold\n        self.local_search_prob = local_search_prob\n        self.local_search_decay = local_search_decay\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def _mutation(self, population, i):\n        # Ring topology selection of parents\n        neighbors = [(i + j) % self.pop_size for j in range(-self.neighborhood_size // 2, self.neighborhood_size // 2 + 1)]\n        idxs = np.random.choice(neighbors, 3, replace=False)\n        \n        return population[idxs[0]] + self.F * (population[idxs[1]] - population[idxs[2]])\n    \n    def _local_search(self, x, func):\n        # Simple random walk local search\n        step_size = 0.1 * (func.bounds.ub - func.bounds.lb)\n        new_x = x + np.random.uniform(-step_size, step_size, size=self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        used_budget = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        self.best_fitness_history.append(self.f_opt)\n        \n        while used_budget < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                mutant = self._mutation(population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial_vector = self._local_search(trial_vector, func)\n                    self.local_search_prob *= self.local_search_decay # Reduce local search intensity\n\n                # Evaluation\n                f = func(trial_vector)\n                used_budget += 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n            \n            # Stagnation check\n            best_idx = np.argmin(fitness)\n            self.best_fitness_history.append(fitness[best_idx])\n            \n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                if self.best_fitness_history[-1] >= np.min(self.best_fitness_history[-self.stagnation_threshold:]):\n                    self.stagnation_counter += 1\n                else:\n                    self.stagnation_counter = 0\n                    \n                if self.stagnation_counter >= self.stagnation_threshold:\n                    # Restart: Re-initialize population (excluding the best)\n                    for i in range(self.pop_size):\n                        if i != best_idx:\n                            population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                            fitness[i] = func(population[i])\n                            used_budget += 1\n                    \n                    self.stagnation_counter = 0\n                    best_idx = np.argmin(fitness)\n                    self.f_opt = fitness[best_idx]\n                    self.x_opt = population[best_idx]\n                    self.best_fitness_history = [self.f_opt] #reset the history\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm RingTopologyDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cc204f72-c903-4864-96a0-b3db90b891ed"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "517287f7-b19f-4cc2-99eb-254a660d662b", "fitness": 0.0, "name": "MirroredDECMA", "description": "A differential evolution strategy that uses a mirrored sampling technique combined with covariance matrix adaptation to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass MirroredDECMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.learning_rate = learning_rate\n        self.C = np.eye(dim)  # Covariance matrix\n        self.mean = None\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize population\n        if self.mean is None:\n            self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        \n        population = np.random.multivariate_normal(self.mean, self.C, size=self.pop_size)\n        population = np.clip(population, func.bounds.lb, func.bounds.ub)\n        \n        fitness = np.array([func(x) for x in population])\n        used_budget = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        \n        while used_budget < self.budget:\n            # Generate mutants using DE/rand/1 and mirrored sampling\n            mutants = []\n            mirrored_mutants = []\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                mutant = population[idxs[0]] + self.F * (population[idxs[1]] - population[idxs[2]])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                mutants.append(mutant)\n\n                # Mirrored sampling: Reflect the mutant around the mean\n                mirrored_mutant = 2 * self.mean - mutant\n                mirrored_mutant = np.clip(mirrored_mutant, func.bounds.lb, func.bounds.ub)\n                mirrored_mutants.append(mirrored_mutant)\n\n            mutants = np.array(mutants)\n            mirrored_mutants = np.array(mirrored_mutants)\n            \n            # Crossover\n            crossover_mask = np.random.rand(self.pop_size, self.dim) < self.CR\n            trial_vectors = np.where(crossover_mask, mutants, population)\n            mirrored_trial_vectors = np.where(crossover_mask, mirrored_mutants, population) # Use mirrored mutants also\n            \n            # Evaluate trial vectors\n            trial_fitness = np.array([func(x) for x in trial_vectors])\n            mirrored_trial_fitness = np.array([func(x) for x in mirrored_trial_vectors])\n            used_budget += 2*self.pop_size\n            \n            # Selection\n            improved = trial_fitness < fitness\n            mirrored_improved = mirrored_trial_fitness < fitness\n            \n            # Update population and fitness\n            fitness[improved] = trial_fitness[improved]\n            population[improved] = trial_vectors[improved]\n\n            fitness[mirrored_improved] = mirrored_trial_fitness[mirrored_improved]\n            population[mirrored_improved] = mirrored_trial_vectors[mirrored_improved]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n            \n            # Update mean and covariance matrix adaptively\n            delta = population - self.mean\n            weighted_delta = np.mean(delta[improved], axis=0) if np.any(improved) else np.zeros(self.dim)\n            \n            self.mean = (1 - self.learning_rate) * self.mean + self.learning_rate * np.mean(population, axis=0)\n            \n            # Update covariance matrix using rank-one update (simplified)\n            if np.any(improved) or np.any(mirrored_improved):\n                improved_indices = np.concatenate([np.where(improved)[0], np.where(mirrored_improved)[0]])\n                d = population[improved_indices] - self.mean\n                if d.size > 0:\n                    self.C = (1 - self.learning_rate) * self.C + self.learning_rate * np.cov(d.T)\n                else:\n                    self.C = (1 - self.learning_rate) * self.C + self.learning_rate * np.eye(self.dim)\n            else:\n                 self.C = (1- self.learning_rate) * self.C + self.learning_rate * np.eye(self.dim)\n            \n\n            # Ensure covariance matrix is positive semi-definite\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)  # Reset if not positive semi-definite\n\n            used_budget = min(used_budget, self.budget)  # Ensure not exceeding budget\n            if used_budget >= self.budget:\n                break\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm MirroredDECMA scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a86371f7-a47a-484f-9ce2-c43a46834cad"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "e8405dba-8ea5-4f83-a53d-cc52c4b68725", "fitness": 0.0, "name": "CooperativeAdaptiveDE_OL", "description": "Cooperative Adaptive Differential Evolution with orthogonal learning and a dynamic external archive for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass CooperativeAdaptiveDE_OL(object):\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.archive_size = archive_size\n        self.archive = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        used_budget = self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        # Main loop\n        while used_budget < self.budget:\n            # Cooperative DE: Each individual interacts with the best and a random individual\n            mutants = []\n            for i in range(self.pop_size):\n                best_individual = population[np.argmin(fitness)]\n                random_individual = population[np.random.randint(self.pop_size)]\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n\n                # DE/current-to-best/1\n                mutant = population[i] + self.F * (best_individual - population[i]) + self.F * (population[idxs[0]] - population[idxs[1]])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                mutants.append(mutant)\n            mutants = np.array(mutants)\n\n            # Crossover\n            crossover_mask = np.random.rand(self.pop_size, self.dim) < self.CR\n            trial_vectors = np.where(crossover_mask, mutants, population)\n\n            # Orthogonal Learning: Select two dimensions and optimize\n            for i in range(self.pop_size):\n                d1, d2 = np.random.choice(self.dim, 2, replace=False)\n                \n                # Simple line search along the selected dimensions\n                alpha = np.linspace(-1, 1, 5)  # Evaluate 5 points\n                fitness_values = []\n                for a in alpha:\n                    x_ol = trial_vectors[i].copy()\n                    x_ol[d1] = trial_vectors[i][d1] + a * (func.bounds.ub[d1] - func.bounds.lb[d1]) * 0.01 # scale small amount\n                    x_ol[d2] = trial_vectors[i][d2] + a * (func.bounds.ub[d2] - func.bounds.lb[d2]) * 0.01 # scale small amount\n                    x_ol = np.clip(x_ol, func.bounds.lb, func.bounds.ub)\n                    fitness_values.append(func(x_ol))\n                \n                best_alpha_idx = np.argmin(fitness_values)\n                x_ol = trial_vectors[i].copy()\n                x_ol[d1] = trial_vectors[i][d1] + alpha[best_alpha_idx] * (func.bounds.ub[d1] - func.bounds.lb[d1])* 0.01\n                x_ol[d2] = trial_vectors[i][d2] + alpha[best_alpha_idx] * (func.bounds.ub[d2] - func.bounds.lb[d2])* 0.01\n                x_ol = np.clip(x_ol, func.bounds.lb, func.bounds.ub)\n                \n                fitness_ol = func(x_ol)\n                used_budget += 5  # Each individual uses 5 evaluations on orthogonal learning\n                if fitness_ol < fitness[i]:\n                   trial_vectors[i] = x_ol\n                   fitness[i] = fitness_ol\n\n\n            # Evaluate trial vectors\n            trial_fitness = np.array([func(x) for x in trial_vectors])\n            used_budget += self.pop_size\n\n            # Selection\n            improved = trial_fitness < fitness\n            population[improved] = trial_vectors[improved]\n            fitness[improved] = trial_fitness[improved]\n\n            # Update archive\n            for x in population[improved]:\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(x)\n                else:\n                    # Replace the worst individual in the archive\n                    archive_fitness = [func(a) for a in self.archive]\n                    worst_idx = np.argmax(archive_fitness)\n                    if func(x) < archive_fitness[worst_idx]:\n                        self.archive[worst_idx] = x\n\n            # Update best solution\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm CooperativeAdaptiveDE_OL scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a86371f7-a47a-484f-9ce2-c43a46834cad"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "1e2bd3ee-4a1a-4c79-81cd-1748f3a8b5a2", "fitness": 0.0, "name": "AdaptiveDEOrthogonalRestart", "description": "Adaptive DE with orthogonal learning to create promising offspring and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonalRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, orthogonal_trials=5, restart_trigger=50, restart_factor=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.orthogonal_trials = orthogonal_trials\n        self.restart_trigger = restart_trigger\n        self.restart_factor = restart_factor\n        self.best_fitness_history = []\n\n    def _mutation(self, population, best_idx, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        return population[idxs[0]] + self.F * (population[idxs[1]] - population[idxs[2]])\n\n    def _crossover(self, mutant, individual):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial_vector = np.where(crossover_mask, mutant, individual)\n        return trial_vector\n\n    def _orthogonal_learning(self, population, func, bounds):\n        # Orthogonal experimental design for creating trial vectors\n        levels = 3  # Number of levels for each dimension\n        L = np.zeros((levels, self.dim))\n\n        # Sample points using Latin hypercube sampling for diversification\n        for j in range(self.dim):\n            L[:, j] = np.linspace(bounds.lb[j], bounds.ub[j], levels)\n\n        trial_vectors = []\n        fitness_values = []\n\n        for _ in range(self.orthogonal_trials):\n            # Create a random orthogonal array\n            oa = np.random.randint(0, levels, size=self.dim)\n            trial_vector = np.array([L[oa[i], i] for i in range(self.dim)])\n            trial_vectors.append(trial_vector)\n            fitness_values.append(func(trial_vector))\n        \n        best_idx = np.argmin(fitness_values)\n        return trial_vectors[best_idx], fitness_values[best_idx]\n\n    def _restart(self, population, best_x, func):\n        # Restart the population around the current best solution with reduced bounds.\n        new_population = np.zeros_like(population)\n        for i in range(self.pop_size):\n            new_x = best_x + np.random.uniform(-self.restart_factor, self.restart_factor, size=self.dim) * (func.bounds.ub - func.bounds.lb)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_population[i] = new_x\n        return new_population\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        used_budget = self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        self.best_fitness_history.append(self.f_opt)\n        \n        iteration = 0\n\n        while used_budget < self.budget:\n            iteration += 1\n            for i in range(self.pop_size):\n                # Mutation\n                mutant = self._mutation(population, best_idx, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial_vector = self._crossover(mutant, population[i])\n\n                # Orthogonal learning to improve the trial vector\n                orthogonal_trial, orthogonal_fitness = self._orthogonal_learning(population, func, func.bounds)\n                used_budget += self.orthogonal_trials\n                if orthogonal_fitness < func(trial_vector): # Only check, func is already called in orth_learning\n                   trial_vector = orthogonal_trial\n                   f = orthogonal_fitness\n                else: \n                  f = func(trial_vector)\n                  used_budget += 1\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n            \n            best_idx = np.argmin(fitness)\n            \n            self.best_fitness_history.append(self.f_opt)\n\n            # Restart mechanism\n            if iteration > self.restart_trigger and np.std(self.best_fitness_history[-self.restart_trigger:]) < 1e-6:\n                population = self._restart(population, self.x_opt, func)\n                fitness = np.array([func(x) for x in population])\n                used_budget += self.pop_size\n                best_idx = np.argmin(fitness)\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n                self.best_fitness_history.append(self.f_opt)\n                iteration = 0  # Reset iteration counter\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDEOrthogonalRestart scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cc204f72-c903-4864-96a0-b3db90b891ed"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "1317e44f-38b4-4dc5-ad73-6024c1146a82", "fitness": 0.0621592418039878, "name": "DynDE", "description": "Differential Evolution with a dynamically adjusted mutation strategy based on the success rate of previous mutations and a restart mechanism.", "code": "import numpy as np\n\nclass DynDE:\n    def __init__(self, budget=10000, dim=10, initial_popsize=None, F_initial=0.5, CR=0.7, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_popsize = initial_popsize if initial_popsize is not None else 10 * self.dim\n        self.popsize = self.initial_popsize\n        self.F = F_initial\n        self.CR = CR\n        self.restart_trigger = restart_trigger\n        self.success_rate = 0.5 # Initial success rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.success_history = []\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation:\n                indices = np.random.choice(self.popsize, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n\n                mutant = self.population[i] + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.success_history.append(1)\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                else:\n                    self.success_history.append(0)\n                \n                # Dynamic F adaptation based on success rate\n                if len(self.success_history) > 50:\n                    recent_success_rate = np.mean(self.success_history[-50:])\n                    if recent_success_rate > 0.6:\n                        self.F = min(self.F * 1.1, 1.0)  # Increase F if doing well\n                    elif recent_success_rate < 0.2:\n                        self.F = max(self.F * 0.9, 0.1)  # Decrease F if not doing well\n\n            # Restart mechanism: If no improvement for a while, restart a portion of the population\n            if len(self.success_history) > 100 and np.mean(self.success_history[-100:]) < self.restart_trigger:\n                 # Sort the population according to the fitness\n                sorted_indices = np.argsort(self.fitness)\n                \n                # Keep the best individuals\n                num_elites = int(self.popsize * 0.2)\n                elites_indices = sorted_indices[:num_elites]\n                elites = self.population[elites_indices]\n                elites_fitness = self.fitness[elites_indices]\n                \n                # Generate new random individuals for the rest of the population\n                remaining_popsize = self.popsize - num_elites\n                new_population = np.random.uniform(lb, ub, size=(remaining_popsize, self.dim))\n                new_fitness = np.array([func(x) for x in new_population])\n                self.eval_count += remaining_popsize\n\n                # Combine the elites with the new population\n                self.population = np.concatenate((elites, new_population), axis=0)\n                self.fitness = np.concatenate((elites_fitness, new_fitness), axis=0)\n                \n                # Update the best solution if needed\n                min_fitness_index = np.argmin(self.fitness)\n                self.f_opt = self.fitness[min_fitness_index]\n                self.x_opt = self.population[min_fitness_index]\n\n                self.success_history = []\n\n            if self.eval_count > self.budget:\n                break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm DynDE scored 0.062 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["eaa8598a-47ab-44fa-9aa5-9d695df3b44b"], "operator": null, "metadata": {"aucs": [0.1243184836079756, 0]}}
{"id": "1178030a-0654-4c74-809d-df2a44f06f82", "fitness": -Infinity, "name": "CooperativeOrthogonalDE", "description": "Cooperative Differential Evolution with Orthogonal Learning and Dynamic Population Size, where multiple DE subpopulations cooperate, use orthogonal learning to improve promising solutions, and adjust population sizes dynamically.", "code": "import numpy as np\n\nclass CooperativeOrthogonalDE:\n    def __init__(self, budget=10000, dim=10, num_subpopulations=5, initial_popsize=None, F=0.5, CR=0.7, orthogonal_dimension=3, dynamic_popsize=True):\n        self.budget = budget\n        self.dim = dim\n        self.num_subpopulations = num_subpopulations\n        self.initial_popsize = initial_popsize if initial_popsize is not None else 5 * self.dim\n        self.F = F\n        self.CR = CR\n        self.orthogonal_dimension = orthogonal_dimension\n        self.dynamic_popsize = dynamic_popsize\n        self.subpopulations = []\n        self.fitness = []\n        self.popsize = []\n        self.eval_counts = []\n        self.lb = None\n        self.ub = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def initialize_subpopulations(self, func):\n        lb = self.lb\n        ub = self.ub\n        for i in range(self.num_subpopulations):\n            self.popsize.append(self.initial_popsize)\n            self.subpopulations.append(np.random.uniform(lb, ub, size=(self.popsize[i], self.dim)))\n            self.fitness.append(np.array([func(x) for x in self.subpopulations[i]]))\n            self.eval_counts.append(self.popsize[i])  # Track evaluations per subpopulation\n            \n            best_idx = np.argmin(self.fitness[i])\n            if self.fitness[i][best_idx] < self.f_opt:\n                self.f_opt = self.fitness[i][best_idx]\n                self.x_opt = self.subpopulations[i][best_idx]\n\n    def orthogonal_design(self, x_center, orthogonal_dimension):\n        \"\"\"Generate an orthogonal design around x_center.\"\"\"\n        design = np.zeros((orthogonal_dimension + 1, orthogonal_dimension))\n        for i in range(1, orthogonal_dimension + 1):\n            for j in range(orthogonal_dimension):\n                if ((i - 1) >> j) & 1:\n                    design[i, j] = 1\n                else:\n                    design[i, j] = -1\n\n        return design\n\n    def orthogonal_learning(self, func, x_best):\n        \"\"\"Perform orthogonal learning around the best solution.\"\"\"\n        orthogonal_dimension = min(self.orthogonal_dimension, self.dim)\n        design = self.orthogonal_design(x_best, orthogonal_dimension)\n        \n        lb = self.lb\n        ub = self.ub\n        \n        levels = np.linspace(-0.1, 0.1, orthogonal_dimension + 1)  # Adjust levels as needed\n        \n        trials = np.zeros((orthogonal_dimension + 1, self.dim))\n        for i in range(orthogonal_dimension + 1):\n            trials[i, :] = x_best.copy()\n            for j in range(orthogonal_dimension):\n                trials[i, j] = x_best[j] + levels[i] * (ub - lb)/2 # scale the levels\n                trials[i, j] = np.clip(trials[i, j], lb, ub)\n\n        fitness_values = np.array([func(trial) for trial in trials])\n        \n        self.eval_counts[0] += orthogonal_dimension + 1\n        \n        best_idx = np.argmin(fitness_values)\n        \n        if fitness_values[best_idx] < self.f_opt:\n            self.f_opt = fitness_values[best_idx]\n            self.x_opt = trials[best_idx]\n            \n        return self.f_opt, self.x_opt\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.initialize_subpopulations(func)\n\n        while sum(self.eval_counts) < self.budget:\n            for i in range(self.num_subpopulations):\n                for j in range(self.popsize[i]):\n                    # Mutation\n                    idxs = np.random.choice(self.popsize[i], 3, replace=False)\n                    x1, x2, x3 = self.subpopulations[i][idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    # Crossover\n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial = np.where(crossover_mask, mutant, self.subpopulations[i][j])\n\n                    # Evaluation\n                    f_trial = func(trial)\n                    self.eval_counts[i] += 1\n\n                    # Selection\n                    if f_trial < self.fitness[i][j]:\n                        self.subpopulations[i][j] = trial\n                        self.fitness[i][j] = f_trial\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n\n                # Cooperation: Share best solution\n                best_idx = np.argmin(self.fitness[i])\n                best_solution = self.subpopulations[i][best_idx]\n                for k in range(self.num_subpopulations):\n                    if k != i:\n                        worst_idx = np.argmax(self.fitness[k])\n                        if self.fitness[i][best_idx] < self.fitness[k][worst_idx]:\n                            self.subpopulations[k][worst_idx] = best_solution\n                            self.fitness[k][worst_idx] = self.fitness[i][best_idx]\n                            if self.fitness[i][best_idx] < self.f_opt:\n                                self.f_opt = self.fitness[i][best_idx]\n                                self.x_opt = best_solution\n                \n                # Orthogonal Learning (applied to best solution of each subpopulation)\n                best_idx = np.argmin(self.fitness[i])\n                self.orthogonal_learning(func, self.subpopulations[i][best_idx])\n\n                # Dynamic Population Size\n                if self.dynamic_popsize:\n                    if np.std(self.fitness[i]) < 1e-6:  # Stagnation detection\n                        self.popsize[i] = int(self.popsize[i] * 0.9)\n                        if self.popsize[i] < 5:\n                             self.popsize[i] = 5\n                    else:\n                        self.popsize[i] = int(self.popsize[i] * 1.1)\n                        if self.popsize[i] > 20 * self.dim:\n                             self.popsize[i] = 20 * self.dim\n\n                    # Resize population\n                    old_pop = self.subpopulations[i]\n                    old_fitness = self.fitness[i]\n                    self.subpopulations[i] = np.random.uniform(self.lb, self.ub, size=(self.popsize[i], self.dim))\n                    self.fitness[i] = np.array([func(x) for x in self.subpopulations[i]])\n                    self.eval_counts[i] += self.popsize[i]\n\n                    # Keep the best individuals from previous population\n                    num_keep = min(self.popsize[i], len(old_pop))\n                    best_indices = np.argsort(old_fitness)[:num_keep]\n                    self.subpopulations[i][:num_keep] = old_pop[best_indices]\n                    self.fitness[i][:num_keep] = old_fitness[best_indices]\n                    \n                    best_idx = np.argmin(self.fitness[i])\n                    if self.fitness[i][best_idx] < self.f_opt:\n                        self.f_opt = self.fitness[i][best_idx]\n                        self.x_opt = self.subpopulations[i][best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occured: TypeError: only size-1 arrays can be converted to Python scalars\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 122, in __call__\n  File \"<string>\", line 62, in orthogonal_learning\nValueError: setting an array element with a sequence.\n.", "error": "", "parent_ids": ["c1c0f903-0059-4016-bf16-49231dd93155"], "operator": null, "metadata": {}}
{"id": "1eea07d5-afe8-49bf-a2b7-77d7cce7872c", "fitness": -Infinity, "name": "AdaptiveDEMutationLocalSearch", "description": "A Differential Evolution variant with a dynamically adjusted mutation strategy based on the success rate of recent mutations, combined with a local search refinement step.", "code": "import numpy as np\n\nclass AdaptiveDEMutationLocalSearch:\n    def __init__(self, budget=10000, dim=10, popsize=None, F_initial=0.5, CR=0.7, local_search_prob=0.1, local_search_stepsize=0.1, success_history_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F_initial = F_initial\n        self.CR = CR\n        self.local_search_prob = local_search_prob\n        self.local_search_stepsize = local_search_stepsize\n        self.success_history_size = success_history_size\n        self.success_history = []  # Store the success/failure of recent mutations\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.F = self.F_initial  # Start with the initial F value\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation: Adjust mutation strength (F) based on success history\n                if self.success_history:\n                    success_rate = np.mean(self.success_history)\n                    self.F = self.F_initial * (1 + success_rate)  # Increase F if mutations are frequently successful\n                    self.F = np.clip(self.F, 0.1, 1.0) # Keep F within reasonable bounds\n                else:\n                     self.F = self.F_initial\n\n                indices = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = self.population[i] + self.F * (x2 - x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.success_history.append(1)\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                else:\n                    self.success_history.append(0)\n                \n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    x_local = self.population[i].copy()\n                    for d in range(self.dim):\n                        x_local[d] += np.random.uniform(-self.local_search_stepsize, self.local_search_stepsize)\n                        x_local[d] = np.clip(x_local[d], lb, ub)\n                    \n                    f_local = func(x_local)\n                    self.eval_count += 1\n                    \n                    if f_local < self.fitness[i]:\n                        self.population[i] = x_local\n                        self.fitness[i] = f_local\n                        if self.fitness[i] < self.f_opt:\n                            self.f_opt = self.fitness[i]\n                            self.x_opt = self.population[i]\n\n            # Maintain success history size\n            if len(self.success_history) > self.success_history_size:\n                self.success_history = self.success_history[-self.success_history_size:]\n            \n            if self.eval_count > self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occured: TypeError: only size-1 arrays can be converted to Python scalars\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 63, in __call__\nValueError: setting an array element with a sequence.\n.", "error": "", "parent_ids": ["eaa8598a-47ab-44fa-9aa5-9d695df3b44b"], "operator": null, "metadata": {}}
{"id": "56a8cc3d-e8ed-4f90-adde-818bb3ba589a", "fitness": 0.6240180646656287, "name": "SelfAdaptiveDERestartOL", "description": "A self-adaptive differential evolution strategy with a restart mechanism triggered by stagnation detection and orthogonal learning to enhance diversity.", "code": "import numpy as np\n\nclass SelfAdaptiveDERestartOL:\n    def __init__(self, budget=10000, dim=10, initial_popsize=None, F=0.5, CR=0.7, stagnation_threshold=100, restart_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_popsize = initial_popsize if initial_popsize is not None else 10 * self.dim\n        self.popsize = self.initial_popsize\n        self.F = F\n        self.CR = CR\n        self.stagnation_threshold = stagnation_threshold\n        self.restart_probability = restart_probability\n        self.stagnation_counter = 0\n        self.f_opt_history = []\n\n    def orthogonal_learning(self, population, fitness, lb, ub, num_samples=5):\n        \"\"\"Applies orthogonal learning to generate diverse solutions.\"\"\"\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        \n        new_solutions = []\n        for _ in range(num_samples):\n            basis_vector = np.random.uniform(-1, 1, size=self.dim)\n            basis_vector /= np.linalg.norm(basis_vector)  # Normalize\n\n            # Generate a new solution along the orthogonal direction\n            step_size = np.random.uniform(0.1 * (ub - lb), 0.5 * (ub - lb)) #random step size\n            new_solution = best_solution + step_size * basis_vector\n            new_solution = np.clip(new_solution, lb, ub)\n            new_solutions.append(new_solution)\n        \n        return np.array(new_solutions)\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.f_opt_history.append(self.f_opt)\n        \n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                mutant = self.population[idxs[0]] + self.F * (self.population[idxs[1]] - self.population[idxs[2]])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            self.f_opt_history.append(self.f_opt)\n            \n            # Stagnation detection\n            if len(self.f_opt_history) > self.stagnation_threshold:\n                if np.abs(self.f_opt_history[-1] - self.f_opt_history[-self.stagnation_threshold]) < 1e-6:\n                    self.stagnation_counter += 1\n                else:\n                    self.stagnation_counter = 0\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                if np.random.rand() < self.restart_probability:\n                    # Apply orthogonal learning\n                    new_solutions = self.orthogonal_learning(self.population, self.fitness, lb, ub)\n\n                    # Replace worst solutions with orthogonal learning solutions\n                    worst_indices = np.argsort(self.fitness)[-len(new_solutions):]\n                    for j, idx in enumerate(worst_indices):\n                        self.population[idx] = new_solutions[j]\n                        self.fitness[idx] = func(new_solutions[j])\n                        self.eval_count += 1\n                        if self.fitness[idx] < self.f_opt:\n                            self.f_opt = self.fitness[idx]\n                            self.x_opt = self.population[idx]\n\n                    # Reset stagnation counter\n                    self.stagnation_counter = 0\n                    self.f_opt_history = [self.f_opt] \n                    \n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm SelfAdaptiveDERestartOL scored 0.624 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["eaa8598a-47ab-44fa-9aa5-9d695df3b44b"], "operator": null, "metadata": {"aucs": [0.22924428284230547, 0.4189167048075906, 0.6299389782617166, 0.8396799767489861, 0.691294702870932, 0.7594750959459092, 0.5547922871611143, 0.5553913394493584, 0.7087036033768691, 0.6177767112311563, 0.7895433514292738, 0.9994769778834356, 0.37758239558549545, 0.6291261781395958, 0.8919470845934652, 0.7554798256562836, 0.5148650470182414, 0.7935658554291452, 0.21418805662238538, 0.509372838259313]}}
{"id": "eddf2fdd-b8e3-4279-b156-c46827927caf", "fitness": 0.5894112059472693, "name": "CooperativeAdaptiveDE", "description": "Cooperative Adaptive Differential Evolution with a restart strategy based on population entropy and fitness improvement stagnation.", "code": "import numpy as np\n\nclass CooperativeAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7,\n                 F_adaptive=True, CR_adaptive=True, restart_patience=500):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.F_adaptive = F_adaptive\n        self.CR_adaptive = CR_adaptive\n        self.restart_patience = restart_patience\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        memory_F = np.ones(self.popsize) * self.F\n        memory_CR = np.ones(self.popsize) * self.CR\n        success_F = []\n        success_CR = []\n\n        self.best_fitness_history.append(self.f_opt)\n        stagnation_counter = 0\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Cooperative strategy: choose a different random base vector for each dimension\n                base_idx = np.random.randint(0, self.popsize)\n                idxs = np.random.choice(self.popsize, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                base_vector = self.population[base_idx]\n\n                if self.F_adaptive:\n                    F = memory_F[i]\n                else:\n                    F = self.F\n\n                mutant = base_vector + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                if self.CR_adaptive:\n                    CR = memory_CR[i]\n                else:\n                    CR = self.CR\n\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    success_F.append(F)\n                    success_CR.append(CR)\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                        stagnation_counter = 0 # Reset stagnation counter\n\n                    if self.F_adaptive:\n                        memory_F[i] = np.random.normal(self.F, 0.1)\n                        memory_F[i] = np.clip(memory_F[i], 0.1, 1.0)\n                    if self.CR_adaptive:\n                        memory_CR[i] = np.random.normal(self.CR, 0.1)\n                        memory_CR[i] = np.clip(memory_CR[i], 0.1, 1.0)\n                else:\n                    stagnation_counter += 1 # Increment stagnation counter\n\n            # Adaptive F and CR based on success history\n            if self.F_adaptive and len(success_F) > 0:\n                self.F = np.mean(success_F)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                success_F = []\n            if self.CR_adaptive and len(success_CR) > 0:\n                self.CR = np.mean(success_CR)\n                self.CR = np.clip(self.CR, 0.1, 1.0)\n                success_CR = []\n\n            self.best_fitness_history.append(self.f_opt)\n\n            # Restart strategy based on stagnation\n            if stagnation_counter > self.restart_patience:\n                self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.eval_count += self.popsize\n                best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.population[best_idx]\n                memory_F = np.ones(self.popsize) * self.F\n                memory_CR = np.ones(self.popsize) * self.CR\n                stagnation_counter = 0\n                self.best_fitness_history.append(self.f_opt)\n                print(\"Restarting population due to stagnation.\")\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm CooperativeAdaptiveDE scored 0.589 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c1c0f903-0059-4016-bf16-49231dd93155"], "operator": null, "metadata": {"aucs": [0.1848061946354529, 0.255166874628318, 0.5909965743930008, 0.8408464598876885, 0.7154783326593483, 0.7494495758461346, 0.359416006930825, 0.5213922814933742, 0.5998932831135122, 0.6576240424025666, 0.8280156321581709, 0.9889614890946942, 0.33317140949201807, 0.48977797919731436, 0.8569208637147243, 0.7795005641540922, 0.538369179644739, 0.8233089635146583, 0.17837855270621006, 0.49674985927854176]}}
{"id": "40cffe77-1b22-401f-9005-5fe5a6c2884a", "fitness": 0.7059565422293482, "name": "AdaptiveDEwithLocalSearch", "description": "Differential Evolution with a combined mutation strategy (current-to-best and rand/1), adaptive parameters, and a local search fine-tuning step after a stagnation detection mechanism triggers a restart.", "code": "import numpy as np\n\nclass AdaptiveDEwithLocalSearch:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, local_search_iterations=5, local_search_stepsize=0.1, stagnation_threshold=1e-6, stagnation_iterations=500):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.local_search_iterations = local_search_iterations\n        self.local_search_stepsize = local_search_stepsize\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_iterations = stagnation_iterations\n        self.best_fitness_history = []\n\n    def local_search(self, func, x):\n        x_current = x.copy()\n        f_current = func(x_current)\n        eval_count = 1\n        for _ in range(self.local_search_iterations):\n            step = np.random.uniform(-self.local_search_stepsize, self.local_search_stepsize, size=self.dim)\n            x_new = np.clip(x_current + step, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            eval_count += 1\n            if f_new < f_current:\n                f_current = f_new\n                x_current = x_new\n        return f_current, x_current, eval_count\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.best_fitness_history.append(self.f_opt)\n        stagnation_counter = 0\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation: Combination of current-to-best and rand/1\n                best_idx = np.argmin(self.fitness)\n                x_best = self.population[best_idx]\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                \n                mutant = self.population[i] + self.F * (x_best - self.population[i]) + self.F * (x2 - x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n            # Stagnation detection\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.stagnation_iterations:\n                self.best_fitness_history.pop(0)\n                if np.std(self.best_fitness_history) < self.stagnation_threshold:\n                    stagnation_counter += 1\n                    if stagnation_counter >= 2:\n                        # Apply Local Search to the best individual\n                        f_local, x_local, ls_eval_count = self.local_search(func, self.x_opt)\n                        self.eval_count += ls_eval_count\n                        if f_local < self.f_opt:\n                            self.f_opt = f_local\n                            self.x_opt = x_local\n                        \n                        # Restart the population around the best individual\n                        self.population = np.random.normal(self.x_opt, (ub - lb) * 0.05, size=(self.popsize, self.dim))\n                        self.population = np.clip(self.population, lb, ub)\n                        self.fitness = np.array([func(x) for x in self.population])\n                        self.eval_count += self.popsize\n                        best_idx = np.argmin(self.fitness)\n                        self.f_opt = self.fitness[best_idx]\n                        self.x_opt = self.population[best_idx]\n                        self.best_fitness_history = [self.f_opt] # Reset fitness history\n                        stagnation_counter = 0  # Reset stagnation counter\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDEwithLocalSearch scored 0.706 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c1c0f903-0059-4016-bf16-49231dd93155"], "operator": null, "metadata": {"aucs": [0.2646839754836825, 0.6723753051488698, 0.810233047900401, 0.9060176790502703, 0.8197349931319518, 0.860429129943675, 0.5500296481613351, 0.7882896058140464, 0.8403887353582115, 0.22071794775481635, 0.9114530848585104, 0.9996643693335372, 0.48796909476912775, 0.8164747336946789, 0.9500700139654906, 0.8455983041926696, 0.7255739810172417, 0.8994233950416904, 0.24860936798767774, 0.5013944319790791]}}
{"id": "7da151bb-e266-41d6-b29e-ec43d8d87e36", "fitness": 0.3896425316778436, "name": "AdaptiveDiversityDE", "description": "An adaptive Differential Evolution algorithm with a dynamically adjusted mutation strategy that combines global and local search based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveDiversityDE:\n    def __init__(self, budget=10000, dim=10, initial_popsize=None, F_initial=0.5, CR_initial=0.7, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_popsize = initial_popsize if initial_popsize is not None else 10 * self.dim\n        self.popsize = self.initial_popsize\n        self.F = F_initial\n        self.CR = CR_initial\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        \n        while self.eval_count < self.budget:\n            # Calculate population diversity\n            diversity = self.calculate_diversity()\n\n            for i in range(self.popsize):\n                # Adaptive Mutation Strategy\n                if diversity > self.diversity_threshold:\n                    # Global Exploration: Use more diverse mutation\n                    donor_indices = np.random.choice(self.popsize, 3, replace=False)\n                    mutant = self.population[donor_indices[0]] + self.F * (self.population[donor_indices[1]] - self.population[donor_indices[2]])\n                else:\n                    # Local Exploitation: Perturb the current best solution\n                    mutant = self.x_opt + self.F * (np.random.uniform(lb, ub, size=self.dim) - self.population[i])\n                    \n\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n            if self.eval_count > self.budget:\n                break\n        return self.f_opt, self.x_opt\n\n    def calculate_diversity(self):\n        # Calculate the average distance between individuals in the population\n        distances = []\n        for i in range(self.popsize):\n            for j in range(i + 1, self.popsize):\n                distances.append(np.linalg.norm(self.population[i] - self.population[j]))\n        \n        if distances:\n            return np.mean(distances) / (np.max(self.population) - np.min(self.population)) # Normalize by range\n        else:\n            return 0.0", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDiversityDE scored 0.390 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["eaa8598a-47ab-44fa-9aa5-9d695df3b44b"], "operator": null, "metadata": {"aucs": [0.17984192131101084, 0.3241058423653118, 0.3653014630682432, 0.37536468838324455, 0.2768750403518191, 0.40299427132625776, 0.3468866908774644, 0.3115836916240817, 0.3107285922227788, 0.22882380239228073, 0.4330051355679324, 0.9953831008447923, 0.3304803196446652, 0.2828456216097003, 0.7921804499276587, 0.38052907296540883, 0.33163220589374354, 0.41425217704099515, 0.20294027259524772, 0.5070962735442341]}}
{"id": "d5c48783-1f68-4b08-8cc0-89fedacd96e4", "fitness": -Infinity, "name": "NeighborhoodDE", "description": "A Differential Evolution strategy that employs a neighborhood-based mutation, parameter adaptation using a rank-based mechanism, and a local search refinement step based on the Nelder-Mead simplex algorithm.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass NeighborhoodDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, neighborhood_size=5,\n                 F_adaptive=True, CR_adaptive=True, local_search_freq=500):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.neighborhood_size = neighborhood_size\n        self.F_adaptive = F_adaptive\n        self.CR_adaptive = CR_adaptive\n        self.local_search_freq = local_search_freq\n        self.eval_count = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = None\n        self.fitness = None\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, i):\n        # Select neighborhood\n        idxs = np.random.choice(self.popsize, self.neighborhood_size, replace=False)\n        \n        # Ensure the current individual is not in the neighborhood\n        while i in idxs:\n            idxs = np.random.choice(self.popsize, self.neighborhood_size, replace=False)\n\n        # Choose three distinct individuals from neighborhood\n        a, b, c = idxs[:3]\n        \n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, mutant, i):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, self.population[i])\n        return trial\n\n    def selection(self, trial, i, func):\n        f_trial = func(trial)\n        self.eval_count += 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial\n            self.fitness[i] = f_trial\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n                return True\n        return False\n\n    def adapt_parameters(self):\n        # Rank-based adaptation: Adjust F and CR based on fitness rank\n        ranked_indices = np.argsort(self.fitness)\n        best_indices = ranked_indices[:self.popsize // 4]  # Top 25%\n\n        if self.F_adaptive:\n            self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)  # Example: Adjust F randomly\n        if self.CR_adaptive:\n            self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0) # Example: Adjust CR randomly\n\n    def local_search(self, func):\n        # Apply local search (Nelder-Mead) to the best individual\n        res = minimize(func, self.x_opt, method='Nelder-Mead',\n                       bounds=func.bounds, options={'maxfev': self.local_search_freq // 2})\n        if res.fun < self.f_opt:\n            self.f_opt = res.fun\n            self.x_opt = res.x\n        self.eval_count += res.nfev\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Mutation\n                mutant = self.mutate(i)\n                lb = func.bounds.lb\n                ub = func.bounds.ub\n                mutant = np.clip(mutant, lb, ub)\n                # Crossover\n                trial = self.crossover(mutant, i)\n                trial = np.clip(trial, lb, ub)\n\n                # Selection\n                self.selection(trial, i, func)\n\n                if self.eval_count >= self.budget:\n                    break\n\n            # Adapt parameters periodically\n            self.adapt_parameters()\n\n            # Local search\n            if self.eval_count % self.local_search_freq == 0 and self.eval_count < self.budget:\n                self.local_search(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 110, in __call__\n  File \"<string>\", line 75, in local_search\nNameError: name 'minimize' is not defined\n.", "error": "", "parent_ids": ["eddf2fdd-b8e3-4279-b156-c46827927caf"], "operator": null, "metadata": {}}
{"id": "6c17f719-c243-4df7-9d7b-cfe6530c306f", "fitness": 0.0, "name": "EnsembleAdaptiveDE", "description": "Differential Evolution with ensemble of mutation strategies, adaptive crossover rate, and a gradient-based local search.", "code": "import numpy as np\n\nclass EnsembleAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, local_search_iterations=5, local_search_stepsize=0.01, mutation_strategy_probs=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.local_search_iterations = local_search_iterations\n        self.local_search_stepsize = local_search_stepsize\n        self.mutation_strategy_probs = mutation_strategy_probs if mutation_strategy_probs is not None else [0.4, 0.3, 0.3]  # Probabilities for rand/1, current-to-best, and rand/2\n\n    def gradient_descent(self, func, x, iterations, step_size):\n        x_current = x.copy()\n        f_current = func(x_current)\n        eval_count = 1\n        for _ in range(iterations):\n            # Estimate gradient (simplified finite difference)\n            gradient = np.zeros_like(x_current)\n            for i in range(self.dim):\n                x_plus = x_current.copy()\n                x_minus = x_current.copy()\n                delta = step_size\n                x_plus[i] += delta\n                x_minus[i] -= delta\n                x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n                x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n                f_plus = func(x_plus)\n                f_minus = func(x_minus)\n                eval_count += 2\n                gradient[i] = (f_plus - f_minus) / (2 * delta)\n\n            x_new = x_current - step_size * gradient\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            eval_count += 1\n            if f_new < f_current:\n                f_current = f_new\n                x_current = x_new\n            else:\n                break # Stop if no improvement\n        return f_current, x_current, eval_count\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation Strategy Ensemble\n                rand_val = np.random.rand()\n                if rand_val < self.mutation_strategy_probs[0]:  # rand/1\n                    idxs = np.random.choice(self.popsize, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                elif rand_val < self.mutation_strategy_probs[0] + self.mutation_strategy_probs[1]:  # current-to-best\n                    best_idx = np.argmin(self.fitness)\n                    x_best = self.population[best_idx]\n                    idxs = np.random.choice(self.popsize, 1, replace=False)\n                    x1 = self.population[idxs[0]]\n                    mutant = self.population[i] + self.F * (x_best - self.population[i]) + self.F * (self.population[i] - x1)\n\n                else:  # rand/2\n                    idxs = np.random.choice(self.popsize, 5, replace=False)\n                    x1, x2, x3, x4, x5 = self.population[idxs]\n                    mutant = x1 + self.F * (x2 - x3) + self.F * (x4 - x5)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                # Adaptive Crossover\n                CR_individual = np.random.normal(self.CR, 0.1)\n                CR_individual = np.clip(CR_individual, 0, 1)\n                crossover_mask = np.random.rand(self.dim) < CR_individual\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n            # Gradient-based Local Search (applied to best individual)\n            f_local, x_local, ls_eval_count = self.gradient_descent(func, self.x_opt, self.local_search_iterations, self.local_search_stepsize)\n            self.eval_count += ls_eval_count\n            if f_local < self.f_opt:\n                self.f_opt = f_local\n                self.x_opt = x_local\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm EnsembleAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["40cffe77-1b22-401f-9005-5fe5a6c2884a"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "388b3cd1-89c1-4402-91e1-9264e82a30be", "fitness": 0.0, "name": "DynamicPopulationDE", "description": "A differential evolution strategy with dynamically adjusted population size based on fitness improvement and a local search phase around the best solution.", "code": "import numpy as np\n\nclass DynamicPopulationDE:\n    def __init__(self, budget=10000, dim=10, initial_popsize=None, F=0.5, CR=0.7, popsize_increase_factor=1.2, popsize_decrease_factor=0.8, stagnation_threshold=1000):\n        self.budget = budget\n        self.dim = dim\n        self.initial_popsize = initial_popsize if initial_popsize is not None else 10 * self.dim\n        self.popsize = self.initial_popsize\n        self.F = F\n        self.CR = CR\n        self.popsize_increase_factor = popsize_increase_factor\n        self.popsize_decrease_factor = popsize_decrease_factor\n        self.stagnation_threshold = stagnation_threshold\n        self.last_improvement_eval = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.last_improvement_eval = self.eval_count\n        \n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation\n                donor_indices = np.random.choice(self.popsize, 3, replace=False)\n                mutant = self.population[donor_indices[0]] + self.F * (self.population[donor_indices[1]] - self.population[donor_indices[2]])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                        self.last_improvement_eval = self.eval_count\n\n            # Population size adjustment\n            if self.eval_count - self.last_improvement_eval > self.stagnation_threshold:\n                if self.popsize > 5:\n                    self.popsize = int(self.popsize * self.popsize_decrease_factor)\n                    self.popsize = max(self.popsize, 5)  # Ensure popsize doesn't go too low\n                    self.population = self.population[np.argsort(self.fitness)[:self.popsize]]\n                    self.fitness = self.fitness[np.argsort(self.fitness)[:self.popsize]]\n                    # Local search around best\n                    self.local_search(func, lb, ub)\n                    self.last_improvement_eval = self.eval_count # Reset stagnation timer after popsize change\n\n            elif self.eval_count < self.budget and self.popsize < 2 * self.initial_popsize:\n                if np.random.rand() < 0.1: # Increase probabilistically\n                   self.popsize = int(self.popsize * self.popsize_increase_factor)\n                   self.popsize = min(self.popsize, 2*self.initial_popsize)\n                   new_population = np.random.uniform(lb, ub, size=(self.popsize - len(self.population), self.dim))\n                   new_fitness = np.array([func(x) for x in new_population])\n                   self.eval_count += len(new_population)\n                   self.population = np.vstack((self.population, new_population))\n                   self.fitness = np.concatenate((self.fitness, new_fitness))\n\n            if self.eval_count > self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, lb, ub, num_steps=50):\n        # Perform a local search around the current best solution\n        step_size = 0.01 * (ub - lb)\n        for _ in range(num_steps):\n            neighbor = self.x_opt + np.random.uniform(-step_size, step_size, size=self.dim)\n            neighbor = np.clip(neighbor, lb, ub)\n            f_neighbor = func(neighbor)\n            self.eval_count += 1\n            if f_neighbor < self.f_opt:\n                self.f_opt = f_neighbor\n                self.x_opt = neighbor\n                self.last_improvement_eval = self.eval_count\n            if self.eval_count >= self.budget:\n                break", "configspace": "", "generation": 5, "feedback": "The algorithm DynamicPopulationDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7da151bb-e266-41d6-b29e-ec43d8d87e36"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "67e7f92d-fbb4-4cf2-bff4-989d36b52f29", "fitness": 0.7132615953163517, "name": "DynamicPopulationDE", "description": "A Differential Evolution strategy employing a dynamic population size adjustment based on stagnation detection and a combined mutation strategy.", "code": "import numpy as np\n\nclass DynamicPopulationDE:\n    def __init__(self, budget=10000, dim=10, initial_popsize=None, F=0.5, CR=0.7, stagnation_threshold=1000, popsize_increase_factor=1.1, popsize_decrease_factor=0.9, min_popsize=10, max_popsize=200):\n        self.budget = budget\n        self.dim = dim\n        self.initial_popsize = initial_popsize if initial_popsize is not None else 10 * self.dim\n        self.popsize = self.initial_popsize\n        self.F = F\n        self.CR = CR\n        self.stagnation_threshold = stagnation_threshold\n        self.popsize_increase_factor = popsize_increase_factor\n        self.popsize_decrease_factor = popsize_decrease_factor\n        self.min_popsize = min_popsize\n        self.max_popsize = max_popsize\n        self.best_fitness_history = []\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation: Combine current-to-best and rand/1\n                if np.random.rand() < 0.5:\n                    # current-to-best\n                    donor_indices = np.random.choice(self.popsize, 2, replace=False)\n                    mutant = self.population[i] + self.F * (self.x_opt - self.population[i]) + self.F * (self.population[donor_indices[0]] - self.population[donor_indices[1]])\n                else:\n                    # rand/1\n                    donor_indices = np.random.choice(self.popsize, 3, replace=False)\n                    mutant = self.population[donor_indices[0]] + self.F * (self.population[donor_indices[1]] - self.population[donor_indices[2]])\n\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n            \n            # Stagnation Check and Population Size Adjustment\n            if self.f_opt == self.best_fitness_history[-1]:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            self.best_fitness_history.append(self.f_opt)\n            \n            if self.stagnation_counter > self.stagnation_threshold:\n                # Adjust Population Size\n                if np.random.rand() < 0.5:\n                    new_popsize = int(self.popsize * self.popsize_increase_factor)\n                    new_popsize = min(new_popsize, self.max_popsize)\n                else:\n                    new_popsize = int(self.popsize * self.popsize_decrease_factor)\n                    new_popsize = max(new_popsize, self.min_popsize)\n                \n                if new_popsize != self.popsize:\n                    self.popsize = new_popsize\n                    new_population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n                    new_fitness = np.array([func(x) for x in new_population])\n                    self.eval_count += self.popsize - len(self.population)\n                    \n                    # Keep the best individual\n                    idx = np.argmin(new_fitness)\n                    new_population[0] = self.x_opt\n                    new_fitness[0] = self.f_opt\n                    \n                    self.population = new_population\n                    self.fitness = new_fitness\n\n                self.stagnation_counter = 0 # Reset stagnation counter\n\n            if self.eval_count > self.budget:\n                break\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm DynamicPopulationDE scored 0.713 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7da151bb-e266-41d6-b29e-ec43d8d87e36"], "operator": null, "metadata": {"aucs": [0.28930450642231986, 0.6781798290126095, 0.7531523528739147, 0.8912708471214876, 0.7960436920155098, 0.8324281288075962, 0.6419916320453585, 0.7186027889625369, 0.800536252348635, 0.7454212855240856, 0.8543888444742203, 0.9961319829925357, 0.4739748899381395, 0.743416135838032, 0.9289227021565405, 0.8290563261999431, 0.6644604021325133, 0.8825389118119833, 0.23354810084110533, 0.5118622948079679]}}
{"id": "ba559db4-e7d7-408b-a7d3-c185c4737201", "fitness": 0.7197964612123097, "name": "NeighborhoodAdaptiveDE", "description": "An enhanced Differential Evolution strategy employing a neighborhood-based mutation, adaptive parameter control using the Lehmer mean, and an aging mechanism to promote exploration.", "code": "import numpy as np\n\nclass NeighborhoodAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7,\n                 F_adaptive=True, CR_adaptive=True, neighborhood_size=5, age_limit=500):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.F_adaptive = F_adaptive\n        self.CR_adaptive = CR_adaptive\n        self.neighborhood_size = neighborhood_size\n        self.age_limit = age_limit\n        self.ages = np.zeros(self.popsize)  # Initialize ages for each individual\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        memory_F = np.ones(self.popsize) * self.F\n        memory_CR = np.ones(self.popsize) * self.CR\n        success_F = []\n        success_CR = []\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Neighborhood-based mutation\n                neighbors = np.random.choice(self.popsize, self.neighborhood_size, replace=False)\n                best_neighbor_idx = neighbors[np.argmin(self.fitness[neighbors])]\n                idxs = np.random.choice(self.popsize, 2, replace=False)\n                x1, x2 = self.population[idxs]\n\n                if self.F_adaptive:\n                    F = memory_F[i]\n                else:\n                    F = self.F\n\n                mutant = self.population[best_neighbor_idx] + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                if self.CR_adaptive:\n                    CR = memory_CR[i]\n                else:\n                    CR = self.CR\n\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    success_F.append(F)\n                    success_CR.append(CR)\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    self.ages[i] = 0  # Reset age if improved\n\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n                    if self.F_adaptive:\n                        memory_F[i] = np.random.normal(self.F, 0.1)\n                        memory_F[i] = np.clip(memory_F[i], 0.1, 1.0)\n                    if self.CR_adaptive:\n                        memory_CR[i] = np.random.normal(self.CR, 0.1)\n                        memory_CR[i] = np.clip(memory_CR[i], 0.1, 1.0)\n                else:\n                    self.ages[i] += 1  # Increment age if not improved\n            #Adaptive F and CR using Lehmer mean\n            if self.F_adaptive and len(success_F) > 0:\n                self.F = np.sum(np.array(success_F)**2) / np.sum(success_F)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                success_F = []\n            if self.CR_adaptive and len(success_CR) > 0:\n                self.CR = np.sum(np.array(success_CR)**2) / np.sum(success_CR)\n                self.CR = np.clip(self.CR, 0.1, 1.0)\n                success_CR = []\n\n\n            # Aging mechanism: replace old individuals\n            for i in range(self.popsize):\n                if self.ages[i] > self.age_limit:\n                    self.population[i] = np.random.uniform(lb, ub, size=self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    self.eval_count += 1\n                    self.ages[i] = 0\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm NeighborhoodAdaptiveDE scored 0.720 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["eddf2fdd-b8e3-4279-b156-c46827927caf"], "operator": null, "metadata": {"aucs": [0.2945522201805816, 0.5950587743057002, 0.7594761449061129, 0.9125229999037553, 0.8179500489418062, 0.8348163486100464, 0.6713349197036483, 0.6123530618083276, 0.7841367511154533, 0.7547110260236126, 0.8854956856616326, 0.9974871816548474, 0.5247432397927045, 0.74130906567449, 0.9428999218502104, 0.8348894650259449, 0.6558854494823201, 0.8687942898905485, 0.24673052061738476, 0.6607821090970674]}}
{"id": "2831f3fa-7649-45a2-89cb-d21827722a9b", "fitness": 0.49517521093110056, "name": "AdaptiveDELearningAutomataCauchy", "description": "An adaptive Differential Evolution strategy with a learning automata-based mutation selection and a Cauchy mutation operator for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveDELearningAutomataCauchy:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, learning_rate=0.1, initial_exploration_probability=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.learning_rate = learning_rate\n        self.initial_exploration_probability = initial_exploration_probability\n        self.mutation_probabilities = np.array([self.initial_exploration_probability, 1 - self.initial_exploration_probability]) # Probabilities for Cauchy and rand/1 mutation\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Learning Automata to select mutation strategy\n                mutation_choice = np.random.choice([0, 1], p=self.mutation_probabilities) # 0: Cauchy, 1: rand/1\n\n                if mutation_choice == 0:\n                    # Cauchy Mutation\n                    mutant = self.cauchy_mutation(self.population[i], scale=self.F * (ub - lb))\n                    mutant = np.clip(mutant, lb, ub)\n                else:\n                    # rand/1 Mutation\n                    idxs = np.random.choice(self.popsize, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    # Reward the selected mutation operator\n                    if mutation_choice == 0:\n                        self.mutation_probabilities[0] += self.learning_rate * (1 - self.mutation_probabilities[0])\n                        self.mutation_probabilities[1] -= self.learning_rate * self.mutation_probabilities[1]\n                    else:\n                        self.mutation_probabilities[1] += self.learning_rate * (1 - self.mutation_probabilities[1])\n                        self.mutation_probabilities[0] -= self.learning_rate * self.mutation_probabilities[0]\n                    \n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                else:\n                    # Punish the selected mutation operator\n                    if mutation_choice == 0:\n                        self.mutation_probabilities[0] -= self.learning_rate * self.mutation_probabilities[0]\n                        self.mutation_probabilities[1] += self.learning_rate * (1 - self.mutation_probabilities[1])\n                    else:\n                        self.mutation_probabilities[1] -= self.learning_rate * self.mutation_probabilities[1]\n                        self.mutation_probabilities[0] += self.learning_rate * (1 - self.mutation_probabilities[0])\n\n                # Normalize probabilities\n                self.mutation_probabilities /= np.sum(self.mutation_probabilities)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDELearningAutomataCauchy scored 0.495 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["40cffe77-1b22-401f-9005-5fe5a6c2884a"], "operator": null, "metadata": {"aucs": [0.17574086096928554, 0.26441790143118893, 0.4593461455638437, 0.676793982224692, 0.48019921988672687, 0.5917213629451862, 0.38078835081564955, 0.43162795967810286, 0.500241910137728, 0.4224906439977333, 0.6595474984124365, 0.9902265012424434, 0.29255248789256316, 0.4663554330710554, 0.7775858361937865, 0.595521605639743, 0.36458470855949676, 0.6905024169551345, 0.18695902447428647, 0.49630036853092774]}}
{"id": "2831f3fa-7649-45a2-89cb-d21827722a9b", "fitness": 0.49517521093110056, "name": "AdaptiveDELearningAutomataCauchy", "description": "An adaptive Differential Evolution strategy with a learning automata-based mutation selection and a Cauchy mutation operator for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveDELearningAutomataCauchy:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, learning_rate=0.1, initial_exploration_probability=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.learning_rate = learning_rate\n        self.initial_exploration_probability = initial_exploration_probability\n        self.mutation_probabilities = np.array([self.initial_exploration_probability, 1 - self.initial_exploration_probability]) # Probabilities for Cauchy and rand/1 mutation\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Learning Automata to select mutation strategy\n                mutation_choice = np.random.choice([0, 1], p=self.mutation_probabilities) # 0: Cauchy, 1: rand/1\n\n                if mutation_choice == 0:\n                    # Cauchy Mutation\n                    mutant = self.cauchy_mutation(self.population[i], scale=self.F * (ub - lb))\n                    mutant = np.clip(mutant, lb, ub)\n                else:\n                    # rand/1 Mutation\n                    idxs = np.random.choice(self.popsize, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    # Reward the selected mutation operator\n                    if mutation_choice == 0:\n                        self.mutation_probabilities[0] += self.learning_rate * (1 - self.mutation_probabilities[0])\n                        self.mutation_probabilities[1] -= self.learning_rate * self.mutation_probabilities[1]\n                    else:\n                        self.mutation_probabilities[1] += self.learning_rate * (1 - self.mutation_probabilities[1])\n                        self.mutation_probabilities[0] -= self.learning_rate * self.mutation_probabilities[0]\n                    \n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                else:\n                    # Punish the selected mutation operator\n                    if mutation_choice == 0:\n                        self.mutation_probabilities[0] -= self.learning_rate * self.mutation_probabilities[0]\n                        self.mutation_probabilities[1] += self.learning_rate * (1 - self.mutation_probabilities[1])\n                    else:\n                        self.mutation_probabilities[1] -= self.learning_rate * self.mutation_probabilities[1]\n                        self.mutation_probabilities[0] += self.learning_rate * (1 - self.mutation_probabilities[0])\n\n                # Normalize probabilities\n                self.mutation_probabilities /= np.sum(self.mutation_probabilities)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDELearningAutomataCauchy scored 0.495 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["40cffe77-1b22-401f-9005-5fe5a6c2884a"], "operator": null, "metadata": {"aucs": [0.17574086096928554, 0.26441790143118893, 0.4593461455638437, 0.676793982224692, 0.48019921988672687, 0.5917213629451862, 0.38078835081564955, 0.43162795967810286, 0.500241910137728, 0.4224906439977333, 0.6595474984124365, 0.9902265012424434, 0.29255248789256316, 0.4663554330710554, 0.7775858361937865, 0.595521605639743, 0.36458470855949676, 0.6905024169551345, 0.18695902447428647, 0.49630036853092774]}}
{"id": "2831f3fa-7649-45a2-89cb-d21827722a9b", "fitness": 0.49517521093110056, "name": "AdaptiveDELearningAutomataCauchy", "description": "An adaptive Differential Evolution strategy with a learning automata-based mutation selection and a Cauchy mutation operator for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveDELearningAutomataCauchy:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, learning_rate=0.1, initial_exploration_probability=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.learning_rate = learning_rate\n        self.initial_exploration_probability = initial_exploration_probability\n        self.mutation_probabilities = np.array([self.initial_exploration_probability, 1 - self.initial_exploration_probability]) # Probabilities for Cauchy and rand/1 mutation\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Learning Automata to select mutation strategy\n                mutation_choice = np.random.choice([0, 1], p=self.mutation_probabilities) # 0: Cauchy, 1: rand/1\n\n                if mutation_choice == 0:\n                    # Cauchy Mutation\n                    mutant = self.cauchy_mutation(self.population[i], scale=self.F * (ub - lb))\n                    mutant = np.clip(mutant, lb, ub)\n                else:\n                    # rand/1 Mutation\n                    idxs = np.random.choice(self.popsize, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    # Reward the selected mutation operator\n                    if mutation_choice == 0:\n                        self.mutation_probabilities[0] += self.learning_rate * (1 - self.mutation_probabilities[0])\n                        self.mutation_probabilities[1] -= self.learning_rate * self.mutation_probabilities[1]\n                    else:\n                        self.mutation_probabilities[1] += self.learning_rate * (1 - self.mutation_probabilities[1])\n                        self.mutation_probabilities[0] -= self.learning_rate * self.mutation_probabilities[0]\n                    \n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                else:\n                    # Punish the selected mutation operator\n                    if mutation_choice == 0:\n                        self.mutation_probabilities[0] -= self.learning_rate * self.mutation_probabilities[0]\n                        self.mutation_probabilities[1] += self.learning_rate * (1 - self.mutation_probabilities[1])\n                    else:\n                        self.mutation_probabilities[1] -= self.learning_rate * self.mutation_probabilities[1]\n                        self.mutation_probabilities[0] += self.learning_rate * (1 - self.mutation_probabilities[0])\n\n                # Normalize probabilities\n                self.mutation_probabilities /= np.sum(self.mutation_probabilities)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDELearningAutomataCauchy scored 0.495 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["40cffe77-1b22-401f-9005-5fe5a6c2884a"], "operator": null, "metadata": {"aucs": [0.17574086096928554, 0.26441790143118893, 0.4593461455638437, 0.676793982224692, 0.48019921988672687, 0.5917213629451862, 0.38078835081564955, 0.43162795967810286, 0.500241910137728, 0.4224906439977333, 0.6595474984124365, 0.9902265012424434, 0.29255248789256316, 0.4663554330710554, 0.7775858361937865, 0.595521605639743, 0.36458470855949676, 0.6905024169551345, 0.18695902447428647, 0.49630036853092774]}}
{"id": "2831f3fa-7649-45a2-89cb-d21827722a9b", "fitness": 0.49517521093110056, "name": "AdaptiveDELearningAutomataCauchy", "description": "An adaptive Differential Evolution strategy with a learning automata-based mutation selection and a Cauchy mutation operator for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveDELearningAutomataCauchy:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, learning_rate=0.1, initial_exploration_probability=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.learning_rate = learning_rate\n        self.initial_exploration_probability = initial_exploration_probability\n        self.mutation_probabilities = np.array([self.initial_exploration_probability, 1 - self.initial_exploration_probability]) # Probabilities for Cauchy and rand/1 mutation\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Learning Automata to select mutation strategy\n                mutation_choice = np.random.choice([0, 1], p=self.mutation_probabilities) # 0: Cauchy, 1: rand/1\n\n                if mutation_choice == 0:\n                    # Cauchy Mutation\n                    mutant = self.cauchy_mutation(self.population[i], scale=self.F * (ub - lb))\n                    mutant = np.clip(mutant, lb, ub)\n                else:\n                    # rand/1 Mutation\n                    idxs = np.random.choice(self.popsize, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    # Reward the selected mutation operator\n                    if mutation_choice == 0:\n                        self.mutation_probabilities[0] += self.learning_rate * (1 - self.mutation_probabilities[0])\n                        self.mutation_probabilities[1] -= self.learning_rate * self.mutation_probabilities[1]\n                    else:\n                        self.mutation_probabilities[1] += self.learning_rate * (1 - self.mutation_probabilities[1])\n                        self.mutation_probabilities[0] -= self.learning_rate * self.mutation_probabilities[0]\n                    \n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                else:\n                    # Punish the selected mutation operator\n                    if mutation_choice == 0:\n                        self.mutation_probabilities[0] -= self.learning_rate * self.mutation_probabilities[0]\n                        self.mutation_probabilities[1] += self.learning_rate * (1 - self.mutation_probabilities[1])\n                    else:\n                        self.mutation_probabilities[1] -= self.learning_rate * self.mutation_probabilities[1]\n                        self.mutation_probabilities[0] += self.learning_rate * (1 - self.mutation_probabilities[0])\n\n                # Normalize probabilities\n                self.mutation_probabilities /= np.sum(self.mutation_probabilities)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDELearningAutomataCauchy scored 0.495 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["40cffe77-1b22-401f-9005-5fe5a6c2884a"], "operator": null, "metadata": {"aucs": [0.17574086096928554, 0.26441790143118893, 0.4593461455638437, 0.676793982224692, 0.48019921988672687, 0.5917213629451862, 0.38078835081564955, 0.43162795967810286, 0.500241910137728, 0.4224906439977333, 0.6595474984124365, 0.9902265012424434, 0.29255248789256316, 0.4663554330710554, 0.7775858361937865, 0.595521605639743, 0.36458470855949676, 0.6905024169551345, 0.18695902447428647, 0.49630036853092774]}}
{"id": "2831f3fa-7649-45a2-89cb-d21827722a9b", "fitness": 0.49517521093110056, "name": "AdaptiveDELearningAutomataCauchy", "description": "An adaptive Differential Evolution strategy with a learning automata-based mutation selection and a Cauchy mutation operator for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveDELearningAutomataCauchy:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, learning_rate=0.1, initial_exploration_probability=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.learning_rate = learning_rate\n        self.initial_exploration_probability = initial_exploration_probability\n        self.mutation_probabilities = np.array([self.initial_exploration_probability, 1 - self.initial_exploration_probability]) # Probabilities for Cauchy and rand/1 mutation\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Learning Automata to select mutation strategy\n                mutation_choice = np.random.choice([0, 1], p=self.mutation_probabilities) # 0: Cauchy, 1: rand/1\n\n                if mutation_choice == 0:\n                    # Cauchy Mutation\n                    mutant = self.cauchy_mutation(self.population[i], scale=self.F * (ub - lb))\n                    mutant = np.clip(mutant, lb, ub)\n                else:\n                    # rand/1 Mutation\n                    idxs = np.random.choice(self.popsize, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    # Reward the selected mutation operator\n                    if mutation_choice == 0:\n                        self.mutation_probabilities[0] += self.learning_rate * (1 - self.mutation_probabilities[0])\n                        self.mutation_probabilities[1] -= self.learning_rate * self.mutation_probabilities[1]\n                    else:\n                        self.mutation_probabilities[1] += self.learning_rate * (1 - self.mutation_probabilities[1])\n                        self.mutation_probabilities[0] -= self.learning_rate * self.mutation_probabilities[0]\n                    \n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                else:\n                    # Punish the selected mutation operator\n                    if mutation_choice == 0:\n                        self.mutation_probabilities[0] -= self.learning_rate * self.mutation_probabilities[0]\n                        self.mutation_probabilities[1] += self.learning_rate * (1 - self.mutation_probabilities[1])\n                    else:\n                        self.mutation_probabilities[1] -= self.learning_rate * self.mutation_probabilities[1]\n                        self.mutation_probabilities[0] += self.learning_rate * (1 - self.mutation_probabilities[0])\n\n                # Normalize probabilities\n                self.mutation_probabilities /= np.sum(self.mutation_probabilities)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDELearningAutomataCauchy scored 0.495 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["40cffe77-1b22-401f-9005-5fe5a6c2884a"], "operator": null, "metadata": {"aucs": [0.17574086096928554, 0.26441790143118893, 0.4593461455638437, 0.676793982224692, 0.48019921988672687, 0.5917213629451862, 0.38078835081564955, 0.43162795967810286, 0.500241910137728, 0.4224906439977333, 0.6595474984124365, 0.9902265012424434, 0.29255248789256316, 0.4663554330710554, 0.7775858361937865, 0.595521605639743, 0.36458470855949676, 0.6905024169551345, 0.18695902447428647, 0.49630036853092774]}}
{"id": "2831f3fa-7649-45a2-89cb-d21827722a9b", "fitness": 0.49517521093110056, "name": "AdaptiveDELearningAutomataCauchy", "description": "An adaptive Differential Evolution strategy with a learning automata-based mutation selection and a Cauchy mutation operator for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveDELearningAutomataCauchy:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, learning_rate=0.1, initial_exploration_probability=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.learning_rate = learning_rate\n        self.initial_exploration_probability = initial_exploration_probability\n        self.mutation_probabilities = np.array([self.initial_exploration_probability, 1 - self.initial_exploration_probability]) # Probabilities for Cauchy and rand/1 mutation\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Learning Automata to select mutation strategy\n                mutation_choice = np.random.choice([0, 1], p=self.mutation_probabilities) # 0: Cauchy, 1: rand/1\n\n                if mutation_choice == 0:\n                    # Cauchy Mutation\n                    mutant = self.cauchy_mutation(self.population[i], scale=self.F * (ub - lb))\n                    mutant = np.clip(mutant, lb, ub)\n                else:\n                    # rand/1 Mutation\n                    idxs = np.random.choice(self.popsize, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    # Reward the selected mutation operator\n                    if mutation_choice == 0:\n                        self.mutation_probabilities[0] += self.learning_rate * (1 - self.mutation_probabilities[0])\n                        self.mutation_probabilities[1] -= self.learning_rate * self.mutation_probabilities[1]\n                    else:\n                        self.mutation_probabilities[1] += self.learning_rate * (1 - self.mutation_probabilities[1])\n                        self.mutation_probabilities[0] -= self.learning_rate * self.mutation_probabilities[0]\n                    \n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                else:\n                    # Punish the selected mutation operator\n                    if mutation_choice == 0:\n                        self.mutation_probabilities[0] -= self.learning_rate * self.mutation_probabilities[0]\n                        self.mutation_probabilities[1] += self.learning_rate * (1 - self.mutation_probabilities[1])\n                    else:\n                        self.mutation_probabilities[1] -= self.learning_rate * self.mutation_probabilities[1]\n                        self.mutation_probabilities[0] += self.learning_rate * (1 - self.mutation_probabilities[0])\n\n                # Normalize probabilities\n                self.mutation_probabilities /= np.sum(self.mutation_probabilities)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDELearningAutomataCauchy scored 0.495 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["40cffe77-1b22-401f-9005-5fe5a6c2884a"], "operator": null, "metadata": {"aucs": [0.17574086096928554, 0.26441790143118893, 0.4593461455638437, 0.676793982224692, 0.48019921988672687, 0.5917213629451862, 0.38078835081564955, 0.43162795967810286, 0.500241910137728, 0.4224906439977333, 0.6595474984124365, 0.9902265012424434, 0.29255248789256316, 0.4663554330710554, 0.7775858361937865, 0.595521605639743, 0.36458470855949676, 0.6905024169551345, 0.18695902447428647, 0.49630036853092774]}}
{"id": "2831f3fa-7649-45a2-89cb-d21827722a9b", "fitness": 0.49517521093110056, "name": "AdaptiveDELearningAutomataCauchy", "description": "An adaptive Differential Evolution strategy with a learning automata-based mutation selection and a Cauchy mutation operator for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveDELearningAutomataCauchy:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, learning_rate=0.1, initial_exploration_probability=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.learning_rate = learning_rate\n        self.initial_exploration_probability = initial_exploration_probability\n        self.mutation_probabilities = np.array([self.initial_exploration_probability, 1 - self.initial_exploration_probability]) # Probabilities for Cauchy and rand/1 mutation\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Learning Automata to select mutation strategy\n                mutation_choice = np.random.choice([0, 1], p=self.mutation_probabilities) # 0: Cauchy, 1: rand/1\n\n                if mutation_choice == 0:\n                    # Cauchy Mutation\n                    mutant = self.cauchy_mutation(self.population[i], scale=self.F * (ub - lb))\n                    mutant = np.clip(mutant, lb, ub)\n                else:\n                    # rand/1 Mutation\n                    idxs = np.random.choice(self.popsize, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    # Reward the selected mutation operator\n                    if mutation_choice == 0:\n                        self.mutation_probabilities[0] += self.learning_rate * (1 - self.mutation_probabilities[0])\n                        self.mutation_probabilities[1] -= self.learning_rate * self.mutation_probabilities[1]\n                    else:\n                        self.mutation_probabilities[1] += self.learning_rate * (1 - self.mutation_probabilities[1])\n                        self.mutation_probabilities[0] -= self.learning_rate * self.mutation_probabilities[0]\n                    \n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                else:\n                    # Punish the selected mutation operator\n                    if mutation_choice == 0:\n                        self.mutation_probabilities[0] -= self.learning_rate * self.mutation_probabilities[0]\n                        self.mutation_probabilities[1] += self.learning_rate * (1 - self.mutation_probabilities[1])\n                    else:\n                        self.mutation_probabilities[1] -= self.learning_rate * self.mutation_probabilities[1]\n                        self.mutation_probabilities[0] += self.learning_rate * (1 - self.mutation_probabilities[0])\n\n                # Normalize probabilities\n                self.mutation_probabilities /= np.sum(self.mutation_probabilities)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDELearningAutomataCauchy scored 0.495 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["40cffe77-1b22-401f-9005-5fe5a6c2884a"], "operator": null, "metadata": {"aucs": [0.17574086096928554, 0.26441790143118893, 0.4593461455638437, 0.676793982224692, 0.48019921988672687, 0.5917213629451862, 0.38078835081564955, 0.43162795967810286, 0.500241910137728, 0.4224906439977333, 0.6595474984124365, 0.9902265012424434, 0.29255248789256316, 0.4663554330710554, 0.7775858361937865, 0.595521605639743, 0.36458470855949676, 0.6905024169551345, 0.18695902447428647, 0.49630036853092774]}}
{"id": "43faccb3-f121-4bb0-94a2-19f745f82e9b", "fitness": -Infinity, "name": "SOMAdaptiveDE", "description": "Differential Evolution with a self-organizing map (SOM) to adapt the population distribution and mutation strategies based on the landscape.", "code": "import numpy as np\nfrom minisom import MiniSom\n\nclass SOMAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, som_grid_size=10,\n                 F=0.5, CR=0.7, mutation_strategy='rand1'):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.som_grid_size = som_grid_size\n        self.F = F\n        self.CR = CR\n        self.mutation_strategy = mutation_strategy\n        self.som = MiniSom(som_grid_size, som_grid_size, dim, sigma=0.3, learning_rate=0.5)\n        self.mutation_strategies = ['rand1', 'best1', 'current_to_rand1', 'current_to_best1']\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        # Initial training of SOM\n        self.som.train(self.population, 1000)\n\n        while self.eval_count < self.budget:\n            # Adapt mutation strategy based on SOM\n            mutation_map = {}\n            for i in range(self.popsize):\n                winner_node = self.som.winner(self.population[i])\n                if winner_node not in mutation_map:\n                    mutation_map[winner_node] = np.random.choice(self.mutation_strategies)\n                current_mutation_strategy = mutation_map[winner_node]\n\n                # Differential Evolution mutation\n                if current_mutation_strategy == 'rand1':\n                    idxs = np.random.choice(self.popsize, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutant = self.population[i] + self.F * (x2 - x3)\n                elif current_mutation_strategy == 'best1':\n                     best_idx = np.argmin(self.fitness)\n                     idxs = np.random.choice(self.popsize, 2, replace=False)\n                     x1, x2 = self.population[idxs]\n                     mutant = self.population[best_idx] + self.F * (x1 - x2)\n                elif current_mutation_strategy == 'current_to_rand1':\n                    idxs = np.random.choice(self.popsize, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutant = self.population[i] + self.F * (x1 - self.population[i]) + self.F * (x2-x3)\n                elif current_mutation_strategy == 'current_to_best1':\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.popsize, 2, replace=False)\n                    x1, x2 = self.population[idxs]\n                    mutant = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1-x2)\n                else:\n                    mutant = self.population[i] #Should not happen\n\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n            # Retrain SOM periodically\n            if self.eval_count % (self.popsize * 5) == 0:\n                self.som.train(self.population, 1000)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 111, in evaluate\n    exec(code, safe_globals, local_env)\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'minisom'\n.", "error": "", "parent_ids": ["ba559db4-e7d7-408b-a7d3-c185c4737201"], "operator": null, "metadata": {}}
{"id": "8061dc66-7e6c-44bf-ad44-64aaacf5fa59", "fitness": 0.0, "name": "SelfAdaptiveDEMemetic", "description": "Differential Evolution with self-adaptive mutation strategies based on the success history of past generations and a local search strategy to refine promising solutions.", "code": "import numpy as np\n\nclass SelfAdaptiveDEMemetic:\n    def __init__(self, budget=10000, dim=10, popsize=None, F_range=(0.1, 0.9), CR_range=(0.1, 0.9), local_search_freq=10, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F_range = F_range\n        self.CR_range = CR_range\n        self.local_search_freq = local_search_freq\n        self.local_search_radius = local_search_radius\n        self.F = np.random.uniform(F_range[0], F_range[1], size=self.popsize)\n        self.CR = np.random.uniform(CR_range[0], CR_range[1], size=self.popsize)\n        self.success_F = []\n        self.success_CR = []\n        self.archive = []\n        self.archive_size = int(self.popsize/2)\n\n    def local_search(self, func, x, radius):\n        # Simple random local search around x\n        best_x = x\n        best_f = func(x)\n        for _ in range(5):\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x\n        return best_f, best_x\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        generation = 0\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = x1 + self.F[i] * (x2 - x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR[i]\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.success_F.append(self.F[i])\n                    self.success_CR.append(self.CR[i])\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n            # Update F and CR based on success history\n            if self.success_F:\n                self.F = np.clip(np.random.normal(np.mean(self.success_F), np.std(self.success_F), size=self.popsize), self.F_range[0], self.F_range[1])\n                self.CR = np.clip(np.random.normal(np.mean(self.success_CR), np.std(self.success_CR), size=self.popsize), self.CR_range[0], self.CR_range[1])\n\n            self.success_F = []\n            self.success_CR = []\n\n            # Memetic Local Search\n            if generation % self.local_search_freq == 0:\n                for i in range(self.popsize):\n                    f_local, x_local = self.local_search(func, self.population[i], self.local_search_radius)\n                    self.eval_count += 5  #Local search makes 5 evaluations\n                    if f_local < self.fitness[i]:\n                        self.population[i] = x_local\n                        self.fitness[i] = f_local\n                        if self.fitness[i] < self.f_opt:\n                            self.f_opt = self.fitness[i]\n                            self.x_opt = self.population[i]\n\n            generation += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm SelfAdaptiveDEMemetic scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2831f3fa-7649-45a2-89cb-d21827722a9b"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "f80f9945-b571-42ab-a7eb-31815ce45e55", "fitness": 0.0, "name": "DiversityAdaptiveDE", "description": "A Differential Evolution variant with self-adaptive parameters and a diversity maintenance strategy based on the minimum inter-particle distance.", "code": "import numpy as np\n\nclass DiversityAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F_base=0.5, CR_base=0.7, F_range=0.2, CR_range=0.2, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F_base = F_base\n        self.CR_base = CR_base\n        self.F_range = F_range\n        self.CR_range = CR_range\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Parameter adaptation\n                F = self.F_base + self.F_range * np.random.normal(0, 1)\n                CR = self.CR_base + self.CR_range * np.random.normal(0, 1)\n                F = np.clip(F, 0.1, 1.0)\n                CR = np.clip(CR, 0.1, 1.0)\n\n                # Mutation: rand/1\n                donor_indices = np.random.choice(self.popsize, 3, replace=False)\n                mutant = self.population[donor_indices[0]] + F * (self.population[donor_indices[1]] - self.population[donor_indices[2]])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n            # Diversity maintenance:\n            distances = self.calculate_distances()\n            min_distance = np.min(distances)\n            if min_distance < self.diversity_threshold:\n                # Introduce new random solutions to increase diversity\n                num_new = int(self.popsize * 0.1)\n                indices_to_replace = np.random.choice(self.popsize, num_new, replace=False)\n                self.population[indices_to_replace] = np.random.uniform(lb, ub, size=(num_new, self.dim))\n                self.fitness[indices_to_replace] = np.array([func(x) for x in self.population[indices_to_replace]])\n                self.eval_count += num_new\n                \n                #Update best solution, as fitness values have changed.\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            if self.eval_count > self.budget:\n                break\n                \n        return self.f_opt, self.x_opt\n\n    def calculate_distances(self):\n        distances = []\n        for i in range(self.popsize):\n            for j in range(i + 1, self.popsize):\n                distance = np.linalg.norm(self.population[i] - self.population[j])\n                distances.append(distance)\n        return np.array(distances)", "configspace": "", "generation": 6, "feedback": "The algorithm DiversityAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["67e7f92d-fbb4-4cf2-bff4-989d36b52f29"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "6c29ffa7-af4e-453a-b270-95b544ac5648", "fitness": -Infinity, "name": "SelfAdaptiveDiversityDE", "description": "A Differential Evolution strategy with self-adaptive parameters, a diversity maintenance mechanism based on crowding distance, and a restart strategy.", "code": "import numpy as np\n\nclass SelfAdaptiveDiversityDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F_mu=0.5, F_sigma=0.1, CR_mu=0.7, CR_sigma=0.1, restart_threshold=5000, crowding_distance_epsilon=1e-6):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F_mu = F_mu\n        self.F_sigma = F_sigma\n        self.CR_mu = CR_mu\n        self.CR_sigma = CR_sigma\n        self.restart_threshold = restart_threshold\n        self.crowding_distance_epsilon = crowding_distance_epsilon\n        self.eval_count = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        self.F = np.random.normal(self.F_mu, self.F_sigma, self.popsize)\n        self.F = np.clip(self.F, 0.0, 1.0)\n        self.CR = np.random.normal(self.CR_mu, self.CR_sigma, self.popsize)\n        self.CR = np.clip(self.CR, 0.0, 1.0)\n        \n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation\n                donor_indices = np.random.choice(self.popsize, 3, replace=False)\n                mutant = self.population[donor_indices[0]] + self.F[i] * (self.population[donor_indices[1]] - self.population[donor_indices[2]])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR[i]\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n                    # Update F and CR\n                    self.F[i] = 0.9 * self.F[i] + 0.1 * np.random.normal(self.F_mu, self.F_sigma)\n                    self.F[i] = np.clip(self.F[i], 0.0, 1.0)\n                    self.CR[i] = 0.9 * self.CR[i] + 0.1 * np.random.normal(self.CR_mu, self.CR_sigma)\n                    self.CR[i] = np.clip(self.CR[i], 0.0, 1.0)\n                else:\n                     #Update F and CR (opposite direction)\n                    self.F[i] = 0.9 * self.F[i] - 0.1 * np.random.normal(self.F_mu, self.F_sigma)\n                    self.F[i] = np.clip(self.F[i], 0.0, 1.0)\n                    self.CR[i] = 0.9 * self.CR[i] - 0.1 * np.random.normal(self.CR_mu, self.CR_sigma)\n                    self.CR[i] = np.clip(self.CR[i], 0.0, 1.0)\n\n\n            # Diversity Maintenance (Crowding Distance)\n            distances = np.zeros(self.popsize)\n            for k in range(self.dim):\n                sorted_indices = np.argsort(self.population[:, k])\n                distances[sorted_indices[0]] = np.inf\n                distances[sorted_indices[-1]] = np.inf\n                for j in range(1, self.popsize - 1):\n                    distances[sorted_indices[j]] += (self.population[sorted_indices[j+1], k] - self.population[sorted_indices[j-1], k]) / (ub - lb + self.crowding_distance_epsilon)\n\n            min_dist = np.min(distances)\n            if min_dist < 1e-6:\n                worst_index = np.argmax(distances)\n                self.population[worst_index] = np.random.uniform(lb, ub, self.dim)\n                self.fitness[worst_index] = func(self.population[worst_index])\n                self.eval_count += 1\n                if self.fitness[worst_index] < self.f_opt:\n                    self.f_opt = self.fitness[worst_index]\n                    self.x_opt = self.population[worst_index]\n\n            self.best_fitness_history.append(self.f_opt)\n\n            # Restart Strategy\n            if self.eval_count > self.restart_threshold and self.f_opt == self.best_fitness_history[-self.restart_threshold//10]:\n                self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.eval_count += self.popsize\n                if np.min(self.fitness) < self.f_opt:\n                  self.f_opt = np.min(self.fitness)\n                  self.x_opt = self.population[np.argmin(self.fitness)]\n                self.F = np.random.normal(self.F_mu, self.F_sigma, self.popsize)\n                self.F = np.clip(self.F, 0.0, 1.0)\n                self.CR = np.random.normal(self.CR_mu, self.CR_sigma, self.popsize)\n                self.CR = np.clip(self.CR, 0.0, 1.0)\n                \n\n            if self.eval_count > self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occured: TypeError: only size-1 arrays can be converted to Python scalars\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 74, in __call__\nValueError: setting an array element with a sequence.\n.", "error": "", "parent_ids": ["67e7f92d-fbb4-4cf2-bff4-989d36b52f29"], "operator": null, "metadata": {}}
{"id": "ca4ab6be-19e7-4a9e-aa1a-2b8427b77add", "fitness": 0.28047387080291913, "name": "AdaptiveDECMA", "description": "An adaptive Differential Evolution strategy with a self-adaptive covariance matrix adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDECMA:\n    def __init__(self, budget=10000, dim=10, initial_popsize=None, F=0.5, CR=0.7, learning_rate_sigma=0.1, learning_rate_C=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_popsize = initial_popsize if initial_popsize is not None else 10 * self.dim\n        self.popsize = self.initial_popsize\n        self.F = F\n        self.CR = CR\n        self.learning_rate_sigma = learning_rate_sigma\n        self.learning_rate_C = learning_rate_C\n        self.mean = None\n        self.C = None\n        self.sigma = 1.0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize mean and covariance matrix\n        self.mean = np.random.uniform(lb, ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        \n        self.population = np.random.multivariate_normal(self.mean, self.sigma**2 * self.C, size=self.popsize)\n        self.population = np.clip(self.population, lb, ub)\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.eval_count < self.budget:\n            # Generate offspring\n            offspring = np.random.multivariate_normal(self.mean, self.sigma**2 * self.C, size=self.popsize)\n            offspring = np.clip(offspring, lb, ub)\n\n            # Evaluate offspring\n            fitness_offspring = np.array([func(x) for x in offspring])\n            self.eval_count += self.popsize\n\n            # Selection\n            for i in range(self.popsize):\n                if fitness_offspring[i] < self.fitness[i]:\n                    self.population[i] = offspring[i]\n                    self.fitness[i] = fitness_offspring[i]\n\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n            # Update mean\n            weights = (self.fitness.mean() - self.fitness) / np.std(self.fitness)\n            weights = np.maximum(0, weights)  # Truncate negative weights\n            weights /= weights.sum()\n            \n            delta_mean = np.sum((self.population - self.mean).T * weights, axis=1)\n            self.mean += self.learning_rate_sigma * delta_mean\n\n            # Update covariance matrix\n            z = (self.population - self.mean) / self.sigma\n            self.C = (1 - self.learning_rate_C) * self.C + self.learning_rate_C * np.cov(z.T)\n            \n            # Ensure C is positive semi-definite\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Update step size\n            self.sigma *= np.exp(self.learning_rate_sigma * (np.mean(weights) - 1/self.popsize))\n\n            self.best_fitness_history.append(self.f_opt)\n            if self.eval_count > self.budget:\n                break\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDECMA scored 0.280 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["67e7f92d-fbb4-4cf2-bff4-989d36b52f29"], "operator": null, "metadata": {"aucs": [0.09458477351794337, 0.13809926572229525, 0.30311862018362434, 0.4798562631345873, 0.15228141686047658, 0.2121175588786126, 0.331238278557503, 0.38420135457792604, 0.18376781066125958, 0.20380280686552388, 0.44048043949991755, 0.8668754843296407, 0.2671487040388201, 0.14131554641415756, 0.37296356561273036, 0.2777465171497272, 0.18953510389105965, 0.2231253628680967, 0.19267244478875512, 0.15454609850572565]}}
{"id": "edb07c6e-0965-45f7-bfd2-675f76325504", "fitness": -Infinity, "name": "CMAES_CauchyDE", "description": "A Differential Evolution strategy that combines a dynamically adjusted Cauchy mutation with a population-based covariance matrix adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass CMAES_CauchyDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, initial_sigma=0.1, cs=0.3, cc=0.1, mu_ratio=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim)) # Recommended CMA-ES popsize\n        self.F = F\n        self.CR = CR\n        self.initial_sigma = initial_sigma\n        self.sigma = self.initial_sigma\n        self.cs = cs\n        self.cc = cc\n        self.mu = int(self.popsize * mu_ratio)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.eval_count = 0\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialization\n        self.m = np.random.uniform(lb, ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        while self.eval_count < self.budget:\n            # Generate population\n            z = np.random.randn(self.dim, self.popsize)\n            x = self.m[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            x = np.clip(x, lb, ub)\n            \n            fitness = np.array([func(xi) for xi in x.T])\n            self.eval_count += self.popsize\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[:, idx]\n            \n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[:, 0]\n\n            # Update CMA-ES parameters\n            m_old = self.m.copy()\n            self.m = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n            \n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * np.linalg.solve(np.linalg.cholesky(self.C), (self.m - m_old)) / self.sigma\n            self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc)) * (self.m - m_old) / self.sigma\n            \n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.eval_count / self.popsize)) < self.chiN * (1.4 + 2 / (self.dim + 1))\n            \n            self.C = (1 - self.cc) * self.C + self.cc * (1 / np.min([1, hsig**2 + 0.3])) * (np.outer(self.pc, self.pc))\n            for i in range(self.mu):\n                y = (x[:, i] - m_old) / self.sigma\n                self.C += self.weights[i] * np.outer(y, y)\n            \n            self.sigma *= np.exp((self.cs / 2) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Cauchy mutation to enhance exploration\n            cauchy_scale = self.F * (ub - lb)\n            for i in range(self.popsize):\n                if np.random.rand() < 0.1: # Apply Cauchy with probability 0.1\n                  z_cauchy = np.random.standard_cauchy(size=self.dim)\n                  x_cauchy = self.m + cauchy_scale * z_cauchy\n                  x_cauchy = np.clip(x_cauchy, lb, ub)\n                  f_cauchy = func(x_cauchy)\n                  self.eval_count += 1\n\n                  if f_cauchy < fitness[i]:\n                      x[:, i] = x_cauchy\n                      fitness[i] = f_cauchy\n                      if fitness[i] < self.f_opt:\n                          self.f_opt = fitness[i]\n                          self.x_opt = x_cauchy\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 43, in __call__\n  File \"<__array_function__ internals>\", line 200, in clip\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 2180, in clip\n    return _wrapfunc(a, 'clip', a_min, a_max, out=out, **kwargs)\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 57, in _wrapfunc\n    return bound(*args, **kwds)\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py\", line 161, in _clip\n    return _clip_dep_invoke_with_casting(\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py\", line 115, in _clip_dep_invoke_with_casting\n    return ufunc(*args, out=out, **kwargs)\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) \n.", "error": "", "parent_ids": ["2831f3fa-7649-45a2-89cb-d21827722a9b"], "operator": null, "metadata": {}}
{"id": "7801bc8b-f37b-40bd-a2fb-73f700f79744", "fitness": 0.42048121501786695, "name": "RingTopologyRestartDE", "description": "Differential Evolution with self-adaptive parameters, a ring topology for neighborhood-based interactions, and a restart mechanism.", "code": "import numpy as np\n\nclass RingTopologyRestartDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F_base=0.5, CR_base=0.7, restart_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F_base = F_base\n        self.CR_base = CR_base\n        self.restart_probability = restart_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Self-adaptive parameters\n                F = np.random.normal(self.F_base, 0.1)\n                F = np.clip(F, 0.1, 1.0)\n                CR = np.random.normal(self.CR_base, 0.1)\n                CR = np.clip(CR, 0.1, 1.0)\n\n                # Ring Topology Selection: Select neighbors\n                left = (i - 1) % self.popsize\n                right = (i + 1) % self.popsize\n\n                # Mutation\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = x1 + F * (x2 - x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n                # Restart mechanism\n                if np.random.rand() < self.restart_probability:\n                    self.population[i] = np.random.uniform(lb, ub, size=self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    self.eval_count += 1\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n                if self.eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm RingTopologyRestartDE scored 0.420 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2831f3fa-7649-45a2-89cb-d21827722a9b"], "operator": null, "metadata": {"aucs": [0.1668429796796127, 0.31052979789103297, 0.44080798878099925, 0.6147647627415274, 0.39641673576006875, 0.5084583253063456, 0.353297441766078, 0.4005978829618936, 0.3921376659313671, 0.34691433754884404, 0.5418189424897104, 0.9936689343747915, 0]}}
{"id": "e225e0f2-c4dc-41f5-a7e4-3d2de824e217", "fitness": 0.3933600334811175, "name": "StochasticRankingDE", "description": "Differential Evolution with a stochastic ranking-based selection and Cauchy mutation, enhancing exploration and handling noisy fitness landscapes.", "code": "import numpy as np\n\nclass StochasticRankingDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, p_rank=0.45):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.p_rank = p_rank  # Probability of ranking based on objective function\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n\n                # Cauchy mutation\n                mutant = self.population[i] + self.F * (x1 - x2) + np.random.standard_cauchy(size=self.dim) * 0.01\n                mutant = np.clip(mutant, lb, ub)\n\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Stochastic ranking\n                if (self.fitness[i] < 0 and f_trial < 0) or (np.random.rand() < self.p_rank):\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = trial\n                        self.fitness[i] = f_trial\n                        if self.fitness[i] < self.f_opt:\n                            self.f_opt = self.fitness[i]\n                            self.x_opt = self.population[i]\n                else:\n                    # If both fitness values are positive and the random number is greater than p_rank\n                    # Rank based on constraint violation (in this case, the objective value itself)\n                    if f_trial < self.fitness[i]:\n                        self.population[i] = trial\n                        self.fitness[i] = f_trial\n                        if self.fitness[i] < self.f_opt:\n                            self.f_opt = self.fitness[i]\n                            self.x_opt = self.population[i]\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm StochasticRankingDE scored 0.393 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ba559db4-e7d7-408b-a7d3-c185c4737201"], "operator": null, "metadata": {"aucs": [0.15586622415430795, 0.2565357167650607, 0.37488192924938857, 0.47604397761960393, 0.3001682088969835, 0.40048491961230837, 0.29127273567084044, 0.33803728941244304, 0.3035139642784904, 0.23807401870777956, 0.48165163201713246, 0.9981365831815983, 0.30629888313687115, 0.30565565548306783, 0.7585381611691295, 0.4121252081223812, 0.3156353761504622, 0.48502301127560554, 0.1822865604281062, 0.4869706142907889]}}
{"id": "9aa10703-a5ba-4e9c-a3f2-532225e3b529", "fitness": 0.44772170308028053, "name": "DynamicAdaptiveDERestart", "description": "A Differential Evolution strategy that dynamically adjusts mutation parameters based on the success rate of recent generations and incorporates a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass DynamicAdaptiveDERestart:\n    def __init__(self, budget=10000, dim=10, popsize=None, F_initial=0.5, CR_initial=0.7, F_adapt_rate=0.1, CR_adapt_rate=0.1, restart_trigger=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F_initial\n        self.CR = CR_initial\n        self.F_adapt_rate = F_adapt_rate\n        self.CR_adapt_rate = CR_adapt_rate\n        self.restart_trigger = restart_trigger  # Threshold for fitness improvement to trigger restart\n        self.last_improvement = 0  # Generation count since last improvement\n        self.restart_interval = 50 # Number of iterations before checking restart condition\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.initial_f_opt = self.f_opt\n\n\n        generation = 0\n        while self.eval_count < self.budget:\n            generation += 1\n            successful_mutations = 0\n\n            for i in range(self.popsize):\n                # Mutation\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    successful_mutations += 1\n\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                        self.last_improvement = generation\n                        \n\n            # Adapt F and CR based on success rate\n            success_rate = successful_mutations / self.popsize\n            self.F = np.clip(self.F + self.F_adapt_rate * (success_rate - 0.5), 0.1, 0.9)\n            self.CR = np.clip(self.CR + self.CR_adapt_rate * (success_rate - 0.5), 0.1, 0.9)\n\n            # Restart mechanism\n            if generation - self.last_improvement > self.restart_interval:\n                if (self.initial_f_opt - self.f_opt) / self.initial_f_opt < self.restart_trigger:\n                    # Trigger restart: re-initialize a portion of the population\n                    num_to_restart = int(0.2 * self.popsize)  # Restart 20% of population\n                    idxs_to_restart = np.random.choice(self.popsize, num_to_restart, replace=False)\n                    self.population[idxs_to_restart] = np.random.uniform(lb, ub, size=(num_to_restart, self.dim))\n                    self.fitness[idxs_to_restart] = np.array([func(x) for x in self.population[idxs_to_restart]])\n                    self.eval_count += num_to_restart\n                    \n                    best_idx = np.argmin(self.fitness)\n                    self.f_opt = self.fitness[best_idx]\n                    self.x_opt = self.population[best_idx]\n                    self.last_improvement = generation\n                    self.initial_f_opt = self.f_opt\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm DynamicAdaptiveDERestart scored 0.448 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2831f3fa-7649-45a2-89cb-d21827722a9b"], "operator": null, "metadata": {"aucs": [0.16692872870756836, 0.23982703155923724, 0.39199018273911945, 0.4128381418717193, 0.42234440633140424, 0.6398915451257936, 0.3287525011493302, 0.4268290078881216, 0.45089819097355355, 0.2228434479756396, 0.3907401758542717, 0.9983001944533234, 0.2361247879966537, 0.4210603553467558, 0.6919166653340934, 0.7692559184617318, 0.35317822335538906, 0.694693302432685, 0.19399360140460786, 0.5020276526446108]}}
{"id": "7d9120c2-e029-441b-9b70-6392bca77eab", "fitness": 0.43225031499542765, "name": "WaveletAdaptiveDE", "description": "A Differential Evolution strategy employing self-adaptive parameters, wavelet mutation for enhanced exploration, and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass WaveletAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F_initial=0.5, CR_initial=0.7, restart_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F_initial\n        self.CR = CR_initial\n        self.restart_threshold = restart_threshold\n        self.best_fitness_history = []\n\n    def wavelet_mutation(self, x, level=3):\n        mutant = x.copy()\n        for i in range(self.dim):\n            # Apply Discrete Wavelet Transform (Haar wavelet)\n            coeff = x[i]\n            for _ in range(level):\n                detail = np.random.normal(0, 0.1)  # Add wavelet detail coefficient\n                coeff += detail\n            mutant[i] = coeff\n        return mutant\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        stagnation_counter = 0\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Self-adaptive parameters\n                self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(self.CR, 0.1), 0.1, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Wavelet mutation\n                mutant = self.wavelet_mutation(mutant)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n            # Stagnation Check and Restart\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.restart_threshold:\n                if abs(self.best_fitness_history[-1] - self.best_fitness_history[-self.restart_threshold]) < 1e-6:\n                    stagnation_counter += 1\n                else:\n                    stagnation_counter = 0\n\n                if stagnation_counter > self.restart_threshold // 2:\n                    # Restart Population\n                    self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n                    self.fitness = np.array([func(x) for x in self.population])\n                    self.eval_count += self.popsize\n                    self.f_opt = np.min(self.fitness)\n                    self.x_opt = self.population[np.argmin(self.fitness)]\n                    self.best_fitness_history = [self.f_opt] # Reset fitness history\n                    stagnation_counter = 0 # Reset stagnation counter\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm WaveletAdaptiveDE scored 0.432 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6c17f719-c243-4df7-9d7b-cfe6530c306f"], "operator": null, "metadata": {"aucs": [0.19904141820747268, 0.3170117717867077, 0.4017318906616808, 0.6698541304262917, 0.3389877120460528, 0.4435765701862301, 0.30782745047803406, 0.36871975657688527, 0.33567896960471666, 0.2626489323520913, 0.4459185324584093, 0.9988231638785422, 0.3211946132102689, 0.3413345067266147, 0.7737763462786069, 0.48599402194022956, 0.3496135708916398, 0.5156134504389452, 0.25933166209833247, 0.5083278296608011]}}
{"id": "3a3cc6fb-865a-4cbe-8713-0240f3a2c0a8", "fitness": 0.6162628943802255, "name": "SelfAdaptiveDEMutation", "description": "Differential Evolution with a self-adaptive mutation factor based on the success history of previous generations and a Cauchy distributed perturbation.", "code": "import numpy as np\n\nclass SelfAdaptiveDEMutation:\n    def __init__(self, budget=10000, dim=10, popsize=None, CR=0.7, F_init=0.5, F_min=0.1, F_max=1.0, cauchy_scale=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.CR = CR\n        self.F_init = F_init\n        self.F_min = F_min\n        self.F_max = F_max\n        self.cauchy_scale = cauchy_scale\n        self.F_history = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.F = np.full(self.popsize, self.F_init)\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n\n                # Self-adaptive F\n                if len(self.F_history) > 0:\n                    successful_F = [f for f, success in self.F_history if success]\n                    if successful_F:\n                        self.F[i] = np.mean(successful_F)\n                    else:\n                        self.F[i] = self.F_init  # Revert to initial value if no success\n                \n                self.F[i] = np.clip(self.F[i] + np.random.normal(0, self.cauchy_scale), self.F_min, self.F_max)\n                \n                mutant = x1 + self.F[i] * (x2 - x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                    self.F_history.append((self.F[i], True))  # Mark F as successful\n                else:\n                    self.F_history.append((self.F[i], False))  # Mark F as unsuccessful\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm SelfAdaptiveDEMutation scored 0.616 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6c17f719-c243-4df7-9d7b-cfe6530c306f"], "operator": null, "metadata": {"aucs": [0.21791413721922814, 0.3842361876944682, 0.5948415731056291, 0.7995064444288564, 0.6763591874239132, 0.774395570531958, 0.5092508588455393, 0.5892516315527847, 0.7110005845766645, 0.5806542744226701, 0.7962404176497737, 0.9900440652899959, 0.3596041051962785, 0.6360052922765507, 0.8731033427623457, 0.7515140699116897, 0.49087731374561827, 0.7905653286637463, 0.2891071879917577, 0.5107863143150387]}}
{"id": "f6b91601-0e99-4036-8b72-c8903016dbf1", "fitness": 0.6542519247525731, "name": "SelfAdaptiveEuclideanDE", "description": "Self-Adaptive Differential Evolution with Elitism and Euclidean Neighborhood-based Parameter Adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass SelfAdaptiveEuclideanDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F_range=(0.1, 0.9), CR_range=(0.1, 0.9), neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F_range = F_range\n        self.CR_range = CR_range\n        self.neighborhood_size = neighborhood_size\n        self.population = None\n        self.fitness = None\n        self.F = None\n        self.CR = None\n        self.x_opt = None\n        self.f_opt = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.popsize\n        self.F = np.random.uniform(self.F_range[0], self.F_range[1], size=self.popsize)\n        self.CR = np.random.uniform(self.CR_range[0], self.CR_range[1], size=self.popsize)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.f_opt = np.min(self.fitness)\n\n    def euclidean_distance(self, x, y):\n        return np.linalg.norm(x - y)\n\n    def adapt_parameters(self):\n        for i in range(self.popsize):\n            # Find the neighborhood based on Euclidean distance in the search space\n            distances = [self.euclidean_distance(self.population[i], self.population[j]) for j in range(self.popsize)]\n            neighborhood_indices = np.argsort(distances)[:self.neighborhood_size]\n\n            # Calculate the mean F and CR values from the neighborhood\n            self.F[i] = np.mean(self.F[neighborhood_indices])\n            self.CR[i] = np.mean(self.CR[neighborhood_indices])\n\n            # Apply bounds to F and CR\n            self.F[i] = np.clip(self.F[i], self.F_range[0], self.F_range[1])\n            self.CR[i] = np.clip(self.CR[i], self.CR_range[0], self.CR_range[1])\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        while self.eval_count < self.budget:\n            # Elitism: Keep the best individual\n            elite_index = np.argmin(self.fitness)\n            elite = self.population[elite_index].copy()\n            elite_fitness = self.fitness[elite_index]\n\n            for i in range(self.popsize):\n                # Mutation\n                donor_indices = np.random.choice(self.popsize, 3, replace=False)\n                mutant = self.population[donor_indices[0]] + self.F[i] * (self.population[donor_indices[1]] - self.population[donor_indices[2]])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR[i]\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Parameter Adaptation\n            self.adapt_parameters()\n\n            # Elitism: Replace a random individual with the elite from the previous generation\n            random_index = np.random.randint(self.popsize)\n            self.population[random_index] = elite\n            self.fitness[random_index] = elite_fitness\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm SelfAdaptiveEuclideanDE scored 0.654 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["67e7f92d-fbb4-4cf2-bff4-989d36b52f29"], "operator": null, "metadata": {"aucs": [0.20287361441431573, 0.48760275702056166, 0.5992146658254875, 0.8578572122087739, 0.7188310017943322, 0.8138524145836837, 0.6657286037954356, 0.6298230958684599, 0.7326345002833128, 0.618986698306647, 0.8341267921370356, 0.9963400078684389, 0.3504736230849087, 0.4837661510918171, 0.8681503273542004, 0.7680091113154079, 0.6081867238917551, 0.8315226875890149, 0.48679679197988657, 0.5302617146379881]}}
{"id": "826765d2-975d-4e24-bdaa-310fb05290dc", "fitness": -Infinity, "name": "AdaptiveNeighborhoodDE", "description": "Neighborhood Search with Adaptive Step Size and Differential Evolution inspired exploration.", "code": "import numpy as np\n\nclass AdaptiveNeighborhoodDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, step_size_init=0.1, step_size_min=0.001, de_mutation_factor=0.5, de_crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 5 * self.dim\n        self.step_size = step_size_init\n        self.step_size_min = step_size_min\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize a single solution (no population)\n        self.x_opt = np.random.uniform(lb, ub, size=self.dim)\n        self.f_opt = func(self.x_opt)\n        self.eval_count = 1\n\n        while self.eval_count < self.budget:\n            # Generate neighbors using adaptive step size\n            neighbors = []\n            for _ in range(self.popsize):\n                neighbor = self.x_opt + np.random.normal(0, self.step_size, size=self.dim)\n                neighbor = np.clip(neighbor, lb, ub)\n                neighbors.append(neighbor)\n            \n            neighbors = np.array(neighbors)\n\n            # Differential Evolution inspired exploration among neighbors\n            if self.popsize >= 3:\n                idxs = np.random.choice(self.popsize, size=(self.popsize, 3), replace=False)\n                v = neighbors[idxs[:, 0]] + self.de_mutation_factor * (neighbors[idxs[:, 1]] - neighbors[idxs[:, 2]])\n                v = np.clip(v, lb, ub)\n                \n                # Crossover\n                cross_mask = np.random.rand(self.popsize, self.dim) < self.de_crossover_rate\n                trial_vectors = np.where(cross_mask, v, neighbors)\n            else:\n                trial_vectors = neighbors #DE cannot be applied\n\n            # Evaluate neighbors and trial vectors\n            fitness_neighbors = np.array([func(x) for x in neighbors])\n            fitness_trials = np.array([func(x) for x in trial_vectors])\n            self.eval_count += 2 * self.popsize\n            \n            # Selection: keep the best among current solution, neighbors, and trial vectors\n            all_candidates = np.concatenate(([self.x_opt], neighbors, trial_vectors))\n            all_fitnesses = np.concatenate(([self.f_opt], fitness_neighbors, fitness_trials))\n            \n            best_index = np.argmin(all_fitnesses)\n            \n            if best_index == 0:\n                pass  # Current solution is still the best\n            elif best_index <= self.popsize:\n                self.x_opt = neighbors[best_index-1]\n                self.f_opt = fitness_neighbors[best_index-1]\n            else:\n                self.x_opt = trial_vectors[best_index-1-self.popsize]\n                self.f_opt = fitness_trials[best_index-1-self.popsize]\n\n\n            # Adaptive step size adjustment\n            if self.f_opt < min(fitness_neighbors.min(), fitness_trials.min()):\n                 self.step_size *= 1.05  # Increase step size if improvement\n            else:\n                self.step_size *= 0.95  # Decrease step size if no improvement\n            self.step_size = max(self.step_size, self.step_size_min)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 34, in __call__\n  File \"mtrand.pyx\", line 984, in numpy.random.mtrand.RandomState.choice\nValueError: Cannot take a larger sample than population when 'replace=False'\n.", "error": "", "parent_ids": ["3a3cc6fb-865a-4cbe-8713-0240f3a2c0a8"], "operator": null, "metadata": {}}
{"id": "4b8e81c0-9b88-44df-b73c-bc274f8fd235", "fitness": -Infinity, "name": "DecayingPopSizeDE", "description": "A Differential Evolution variant that uses a decaying population size and dynamically adjusts mutation parameters with a pool of mutation strategies.", "code": "import numpy as np\n\nclass DecayingPopSizeDE:\n    def __init__(self, budget=10000, dim=10, initial_popsize=None, F_initial=0.5, CR_initial=0.7, popsize_decay_rate=0.0001, mutation_strategies=None):\n        self.budget = budget\n        self.dim = dim\n        self.initial_popsize = initial_popsize if initial_popsize is not None else 10 * self.dim\n        self.popsize = self.initial_popsize\n        self.F = F_initial\n        self.CR = CR_initial\n        self.popsize_decay_rate = popsize_decay_rate\n        self.mutation_strategies = mutation_strategies if mutation_strategies is not None else [\n            lambda x1, x2, x3, F: x1 + F * (x2 - x3),  # DE/rand/1\n            lambda x1, x2, x3, x4, x5, F: x1 + F * (x2 - x3) + F * (x4-x5) #DE/rand/2\n        ]\n        self.strategy_probabilities = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)  # Initially uniform probabilities\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n\n        while self.eval_count < self.budget:\n            # Decay population size\n            self.popsize = max(int(self.initial_popsize * np.exp(-self.popsize_decay_rate * self.eval_count)), 4) # Ensure popsize is at least 4\n            if self.population.shape[0] > self.popsize:\n                # Reduce population size if needed\n                indices_to_keep = np.argsort(self.fitness)[:self.popsize]\n                self.population = self.population[indices_to_keep]\n                self.fitness = self.fitness[indices_to_keep]\n            elif self.population.shape[0] < self.popsize:\n                # Increase population size if needed (e.g., after a restart)\n                num_to_add = self.popsize - self.population.shape[0]\n                new_individuals = np.random.uniform(lb, ub, size=(num_to_add, self.dim))\n                self.population = np.vstack((self.population, new_individuals))\n                new_fitness = np.array([func(x) for x in new_individuals])\n                self.fitness = np.concatenate((self.fitness, new_fitness))\n                self.eval_count += num_to_add\n\n            for i in range(self.popsize):\n                # Strategy selection\n                strategy_index = np.random.choice(len(self.mutation_strategies), p=self.strategy_probabilities)\n                mutation_strategy = self.mutation_strategies[strategy_index]\n\n                # Mutation based on selected strategy\n                if len(mutation_strategy.__code__.co_varnames) == 5:  # DE/rand/1\n                    idxs = np.random.choice(self.popsize, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutant = mutation_strategy(x1, x2, x3, self.F)\n                elif len(mutation_strategy.__code__.co_varnames) == 7: #DE/rand/2\n                    idxs = np.random.choice(self.popsize, 5, replace=False)\n                    x1, x2, x3, x4, x5 = self.population[idxs]\n                    mutant = mutation_strategy(x1, x2, x3, x4, x5, self.F)\n                else:\n                    raise ValueError(\"Unsupported mutation strategy arity.\")\n\n\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.population[i]\n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 63, in __call__\nValueError: Unsupported mutation strategy arity.\n.", "error": "", "parent_ids": ["9aa10703-a5ba-4e9c-a3f2-532225e3b529"], "operator": null, "metadata": {}}
{"id": "8db5cd05-50ef-438b-8853-c18607b462f1", "fitness": 0.0, "name": "GaussianLocalSearchDE", "description": "Differential Evolution with Gaussian Local Search and Archive for Enhanced Exploration and Exploitation.", "code": "import numpy as np\n\nclass GaussianLocalSearchDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.archive_size = archive_size\n        self.population = None\n        self.fitness = None\n        self.x_opt = None\n        self.f_opt = np.inf\n        self.eval_count = 0\n        self.archive = []\n        self.archive_fitness = []\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.popsize\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.f_opt = np.min(self.fitness)\n\n    def gaussian_local_search(self, x, func, sigma=0.1):\n        x_new = x + np.random.normal(0, sigma, size=self.dim)\n        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n        f_new = func(x_new)\n        self.eval_count += 1\n        return x_new, f_new\n\n    def update_archive(self, x, f):\n        if len(self.archive) < self.archive_size:\n            self.archive.append(x)\n            self.archive_fitness.append(f)\n        else:\n            if f < np.max(self.archive_fitness):\n                worst_index = np.argmax(self.archive_fitness)\n                self.archive[worst_index] = x\n                self.archive_fitness[worst_index] = f\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation\n                donor_indices = np.random.choice(self.popsize, 3, replace=False)\n                mutant = self.population[donor_indices[0]] + self.F * (self.population[donor_indices[1]] - self.population[donor_indices[2]])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Gaussian Local Search\n                trial, f_trial = self.gaussian_local_search(trial, func)\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update archive\n                    self.update_archive(trial, f_trial)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    # If trial fails, also try local search on the original individual\n                    x_local, f_local = self.gaussian_local_search(self.population[i], func)\n                    if f_local < self.fitness[i]:\n                        self.population[i] = x_local\n                        self.fitness[i] = f_local\n                        self.update_archive(x_local, f_local)\n                        if f_local < self.f_opt:\n                            self.f_opt = f_local\n                            self.x_opt = x_local\n                    else:\n                        # Learn from archive\n                        if self.archive:\n                            archive_index = np.random.randint(len(self.archive))\n                            archived_solution = self.archive[archive_index]\n                            learning_rate = np.random.uniform(0, 1)\n                            trial = self.population[i] + learning_rate * (archived_solution - self.population[i])\n                            trial = np.clip(trial, lb, ub)\n                            f_trial = func(trial)\n                            self.eval_count += 1\n\n                            if f_trial < self.fitness[i]:\n                                self.population[i] = trial\n                                self.fitness[i] = f_trial\n                                self.update_archive(trial, f_trial)\n                                if f_trial < self.f_opt:\n                                    self.f_opt = f_trial\n                                    self.x_opt = trial\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm GaussianLocalSearchDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f6b91601-0e99-4036-8b72-c8903016dbf1"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "91e9d1b7-f830-40df-853b-7cc1db030cd2", "fitness": 0.0, "name": "LevyHybridDE", "description": "Hybrid Differential Evolution with Lvy Flight Mutation and Archive-based Elitism for enhanced exploration and exploitation of the search space.", "code": "import numpy as np\n\nclass LevyHybridDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.archive_size = archive_size\n        self.archive = []\n        self.archive_fitness = []\n\n    def levy_flight(self, size, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / (np.math.gamma((1 + lam) / 2) * lam * (2 ** ((lam - 1) / 2)))) ** (1 / lam)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        s = u / (np.abs(v) ** (1 / lam))\n        return s\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation with Lvy Flight\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                levy_step = self.levy_flight(self.dim)\n                mutant = x1 + self.F * (x2 - x3) + 0.01 * levy_step * (ub - lb) # Levy flight scaled to the search space\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    # Update population\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(trial)\n                        self.archive_fitness.append(f_trial)\n                    else:\n                        max_archive_fitness_idx = np.argmax(self.archive_fitness)\n                        if f_trial < self.archive_fitness[max_archive_fitness_idx]:\n                            self.archive[max_archive_fitness_idx] = trial\n                            self.archive_fitness[max_archive_fitness_idx] = f_trial\n                            \n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                else:\n                    # If trial is not better than current, consider adding parent to archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i])\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        max_archive_fitness_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[max_archive_fitness_idx]:\n                            self.archive[max_archive_fitness_idx] = self.population[i]\n                            self.archive_fitness[max_archive_fitness_idx] = self.fitness[i]\n\n                # Elitism: Include best archive member in mutation if archive is sufficiently filled\n                if len(self.archive) == self.archive_size and np.random.rand() < 0.1:\n                    best_archive_idx = np.argmin(self.archive_fitness)\n                    best_archive_member = self.archive[best_archive_idx]\n                    idxs = np.random.choice(self.popsize, 2, replace=False)\n                    x2, x3 = self.population[idxs]\n                    mutant = best_archive_member + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, lb, ub)\n                    \n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial = np.where(crossover_mask, mutant, self.population[i])\n\n                    f_trial = func(trial)\n                    self.eval_count += 1\n                    \n                    if f_trial < self.fitness[i]:\n                        self.population[i] = trial\n                        self.fitness[i] = f_trial\n                        if self.fitness[i] < self.f_opt:\n                            self.f_opt = self.fitness[i]\n                            self.x_opt = self.population[i]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm LevyHybridDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9aa10703-a5ba-4e9c-a3f2-532225e3b529"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "5c0d80d4-b79e-4189-a586-fff8c2f1667d", "fitness": 0.0, "name": "CMAES_DE", "description": "A Differential Evolution variant that employs a self-adaptive covariance matrix adaptation strategy for mutation and a local search operator to refine promising solutions.", "code": "import numpy as np\n\nclass CMAES_DE:\n    def __init__(self, budget=10000, dim=10, popsize=None, initial_sigma=0.1, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.initial_sigma = initial_sigma\n        self.local_search_prob = local_search_prob\n        self.mean = None  # Initialize in __call__\n        self.C = None   # Initialize in __call__\n        self.sigma = None # Initialize in __call__\n        self.ps = None  # Initialize in __call__\n        self.pc = None  # Initialize in __call__\n        self.chiN = None # Initialize in __call__\n\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.mean = np.random.uniform(lb, ub, size=self.dim)\n        self.sigma = self.initial_sigma\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        while self.eval_count < self.budget:\n            # Generate population\n            z = np.random.randn(self.popsize, self.dim)\n            x = self.mean + self.sigma * z @ np.linalg.cholesky(self.C).T\n            x = np.clip(x, lb, ub)\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.popsize\n\n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            fitness = fitness[idx_sorted]\n            x = x[idx_sorted]\n            \n            # Local search on best individual\n            if np.random.rand() < self.local_search_prob:\n                x_local = self.local_search(x[0], func, lb, ub)\n                f_local = func(x_local)\n                self.eval_count += 1\n                if f_local < fitness[0]:\n                    fitness[0] = f_local\n                    x[0] = x_local\n\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n            # Update CMA-ES parameters\n            z_sorted = z[idx_sorted]\n            y = x - self.mean\n            y_w = np.sum(self.weights.reshape(-1, 1) * y[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (np.linalg.inv(np.linalg.cholesky(self.C)) @ y_w) / self.sigma\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * y_w / self.sigma\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (np.outer(self.pc, self.pc) + (1 - (np.sum(self.pc**2) / (self.dim))) * self.C) + self.c_mu * np.sum(self.weights.reshape(-1, 1, 1) * np.array([np.outer(y[i], y[i]) for i in range(self.mu)]), axis=0) / (self.sigma**2)\n\n            # Update step size\n            self.sigma = self.sigma * np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.mean = np.sum(self.weights.reshape(-1, 1) * x[:self.mu], axis=0)\n\n\n        return self.f_opt, self.x_opt\n    \n    def local_search(self, x, func, lb, ub, radius=0.1):\n        \"\"\"Performs a simple local search around x.\"\"\"\n        best_x = x\n        best_f = func(x)\n        \n        num_samples = 20  # Number of samples for local search\n        \n        for _ in range(num_samples):\n            x_new = x + np.random.uniform(-radius, radius, size=self.dim)\n            x_new = np.clip(x_new, lb, ub)\n            f_new = func(x_new)\n            \n            if f_new < best_f:\n                best_f = f_new\n                best_x = x_new\n                \n        return best_x", "configspace": "", "generation": 7, "feedback": "The algorithm CMAES_DE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9aa10703-a5ba-4e9c-a3f2-532225e3b529"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "5f1f89f3-ecc9-4502-b54b-f1c2bb1e7c3b", "fitness": 0.0, "name": "CooperativeDEArchiveAging", "description": "Cooperative Differential Evolution with Archive and Aging, employing multiple interacting populations, an archive to store promising solutions, and an aging mechanism to promote diversity and prevent premature convergence.", "code": "import numpy as np\n\nclass CooperativeDEArchiveAging:\n    def __init__(self, budget=10000, dim=10, popsize=None, num_populations=3, CR=0.7, F=0.5, archive_size=50, age_limit=50):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.num_populations = num_populations\n        self.CR = CR\n        self.F = F\n        self.archive_size = archive_size\n        self.age_limit = age_limit\n        self.populations = []\n        self.fitnesses = []\n        self.ages = []\n        self.archive = []  # Store promising solutions\n        self.archive_fitness = []\n        self.archive_ages = []\n        self.eval_count = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize multiple populations\n        for _ in range(self.num_populations):\n            population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n            self.populations.append(population)\n            fitness = np.array([func(x) for x in population])\n            self.fitnesses.append(fitness)\n            self.ages.append(np.zeros(self.popsize, dtype=int))  # Initialize ages\n            self.eval_count += self.popsize\n\n            # Update global best\n            local_best_idx = np.argmin(fitness)\n            if fitness[local_best_idx] < self.f_opt:\n                self.f_opt = fitness[local_best_idx]\n                self.x_opt = population[local_best_idx]\n\n        while self.eval_count < self.budget:\n            for pop_idx in range(self.num_populations):\n                for i in range(self.popsize):\n                    # Mutation: Cooperative strategy - select from other populations and archive\n                    pool = [p for idx, p in enumerate(self.populations) if idx != pop_idx]\n                    if self.archive:\n                         pool.append(np.array(self.archive))  # Add archive to the pool\n\n                    if len(pool) > 0:\n                        chosen_population = np.random.choice(len(pool))\n                        if chosen_population < len(self.populations) -1:\n                            idxs = np.random.choice(self.popsize, 3, replace=False)\n                            x1, x2, x3 = self.populations[pop_idx][idxs]\n                            xp = pool[chosen_population][np.random.randint(0,self.popsize)]\n                            mutant = x1 + self.F * (x2 - x3) #+ self.F * (xp - self.populations[pop_idx][i])\n                            #mutant = x1 + self.F * (x2 - x3) #+ np.random.normal(0,0.1,self.dim)\n                        else:\n                            idxs = np.random.choice(self.popsize, 2, replace=False)\n                            x1, x2 = self.populations[pop_idx][idxs]\n                            archive_idx = np.random.randint(0, len(self.archive))\n                            mutant = x1 + self.F * (x2 - self.archive[archive_idx])\n                    else: #Fallback if no other populations or archive exist\n                        idxs = np.random.choice(self.popsize, 3, replace=False)\n                        x1, x2, x3 = self.populations[pop_idx][idxs]\n                        mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, lb, ub)\n    \n                    # Crossover\n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial = np.where(crossover_mask, mutant, self.populations[pop_idx][i])\n    \n                    # Selection\n                    f_trial = func(trial)\n                    self.eval_count += 1\n    \n                    if f_trial < self.fitnesses[pop_idx][i]:\n                        self.populations[pop_idx][i] = trial\n                        self.fitnesses[pop_idx][i] = f_trial\n                        self.ages[pop_idx][i] = 0  # Reset age\n    \n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n\n                        # Archive update: add if better than worst in archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(trial)\n                            self.archive_fitness.append(f_trial)\n                            self.archive_ages.append(0)\n                        else:\n                            worst_archive_idx = np.argmax(self.archive_fitness)\n                            if f_trial < self.archive_fitness[worst_archive_idx]:\n                                self.archive[worst_archive_idx] = trial\n                                self.archive_fitness[worst_archive_idx] = f_trial\n                                self.archive_ages[worst_archive_idx] = 0\n                    else:\n                        self.ages[pop_idx][i] += 1  # Increase age\n    \n                # Aging: Replace individuals that have reached the age limit\n                for i in range(self.popsize):\n                    if self.ages[pop_idx][i] > self.age_limit:\n                        self.populations[pop_idx][i] = np.random.uniform(lb, ub, size=self.dim)\n                        self.fitnesses[pop_idx][i] = func(self.populations[pop_idx][i])\n                        self.eval_count += 1\n                        self.ages[pop_idx][i] = 0\n                        if self.fitnesses[pop_idx][i] < self.f_opt:\n                            self.f_opt = self.fitnesses[pop_idx][i]\n                            self.x_opt = self.populations[pop_idx][i]\n\n                # Archive aging: Increase age of archive members\n                for j in range(len(self.archive)):\n                    self.archive_ages[j] += 1\n                \n                # Remove old archive members:\n                to_remove = [j for j in range(len(self.archive)) if self.archive_ages[j] > self.age_limit]\n                for j in sorted(to_remove, reverse=True):\n                    del self.archive[j]\n                    del self.archive_fitness[j]\n                    del self.archive_ages[j]\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm CooperativeDEArchiveAging scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3a3cc6fb-865a-4cbe-8713-0240f3a2c0a8"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "e50b6a9b-9546-47aa-9dc0-5cc116e67362", "fitness": 0.0, "name": "DynamicPopulationDE", "description": "Differential Evolution with a dynamically adjusted population size based on stagnation detection and a velocity-based mutation strategy.", "code": "import numpy as np\n\nclass DynamicPopulationDE:\n    def __init__(self, budget=10000, dim=10, initial_popsize=None, F=0.5, CR=0.7, stagnation_threshold=10, popsize_increase_factor=1.5, popsize_decrease_factor=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_popsize = initial_popsize if initial_popsize is not None else 10 * self.dim\n        self.popsize = self.initial_popsize\n        self.F = F\n        self.CR = CR\n        self.stagnation_threshold = stagnation_threshold\n        self.popsize_increase_factor = popsize_increase_factor\n        self.popsize_decrease_factor = popsize_decrease_factor\n        self.population = None\n        self.fitness = None\n        self.x_opt = None\n        self.f_opt = np.inf\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.previous_best_fitness = np.inf\n        self.velocities = None\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.popsize\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.f_opt = np.min(self.fitness)\n        self.velocities = np.zeros_like(self.population)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation: Velocity-based mutation\n                donor_indices = np.random.choice(self.popsize, 3, replace=False)\n                \n                # Update velocity\n                self.velocities[i] = self.F * (self.population[donor_indices[1]] - self.population[donor_indices[2]])\n                \n                mutant = self.population[i] + self.velocities[i]\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Stagnation Check\n            if self.f_opt >= self.previous_best_fitness:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            self.previous_best_fitness = self.f_opt\n\n            # Adjust Population Size\n            if self.stagnation_counter > self.stagnation_threshold:\n                if self.popsize < 2 * self.initial_popsize:  # Avoid excessive population growth\n                    self.popsize = int(self.popsize * self.popsize_increase_factor)\n                    self.population = np.vstack((self.population, np.random.uniform(lb, ub, size=(self.popsize - len(self.population), self.dim))))\n                    self.fitness = np.concatenate((self.fitness, np.array([func(x) for x in self.population[len(self.fitness):]])))\n                    self.eval_count += self.popsize - len(self.fitness) + len(self.population[len(self.fitness):])\n                    self.velocities = np.vstack((self.velocities, np.zeros((self.popsize - len(self.velocities), self.dim))))\n\n                else:\n                    # If popsize is already large, consider decreasing it.\n                     self.popsize = int(self.popsize * self.popsize_decrease_factor)\n                     self.population = self.population[:self.popsize]\n                     self.fitness = self.fitness[:self.popsize]\n                     self.velocities = self.velocities[:self.popsize]\n\n                self.stagnation_counter = 0  # Reset stagnation counter\n            \n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm DynamicPopulationDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f6b91601-0e99-4036-8b72-c8903016dbf1"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "1dea458f-1154-445e-97f3-e2c5f2f7809f", "fitness": 0.0, "name": "LevyCMAES_DE", "description": "An adaptive Differential Evolution strategy employing a Lvy flight mutation operator for enhanced exploration, covariance matrix adaptation for better exploitation, and a periodic population rejuvenation to escape local optima.", "code": "import numpy as np\n\nclass LevyCMAES_DE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F_initial=0.5, CR_initial=0.7, restart_threshold=100, CMA_learning_rate=0.1, rejuvenation_frequency=50):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F_initial\n        self.CR = CR_initial\n        self.restart_threshold = restart_threshold\n        self.CMA_learning_rate = CMA_learning_rate\n        self.rejuvenation_frequency = rejuvenation_frequency\n        self.best_fitness_history = []\n        self.mean = None\n        self.C = None # Covariance matrix\n        self.ps = None # Evolution path for sigma\n        self.pc = None # Evolution path for covariance\n        self.sigma = 0.1 # Overall standard deviation\n        self.eval_count = 0\n\n    def levy_flight(self, beta=1.5):\n        \"\"\"\n        Generates a Lvy flight step.\n        \"\"\"\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.randn(self.dim) * sigma\n        v = np.random.randn(self.dim)\n        step = u / abs(v)**(1/beta)\n        return step\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population and CMA-ES parameters\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        self.mean = self.x_opt.copy()  # Initialize mean with the best solution\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n\n        stagnation_counter = 0\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Self-adaptive parameters\n                self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(self.CR, 0.1), 0.1, 1.0)\n\n                # Mutation using Levy Flight\n                levy_step = self.levy_flight()\n                mutant = self.population[i] + self.F * levy_step * self.sigma\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n                trial = np.clip(trial, lb, ub)\n\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n            # CMA-ES update\n            weights = np.clip(0.5 + np.array([func(x) for x in self.population]) / self.f_opt, 0, 1) # weighting the fitness function\n            weights /= np.sum(weights)\n            old_mean = self.mean.copy()\n            self.mean = np.sum(self.population * weights[:, np.newaxis], axis=0)\n\n            self.ps = (1 - self.CMA_learning_rate) * self.ps + np.sqrt(self.CMA_learning_rate * (2 - self.CMA_learning_rate)) * (self.mean - old_mean) / self.sigma\n            self.pc = (1 - self.CMA_learning_rate) * self.pc + np.sqrt(self.CMA_learning_rate * (2 - self.CMA_learning_rate)) * (self.mean - old_mean) / self.sigma\n\n            self.C = (1 - self.CMA_learning_rate) * self.C + self.CMA_learning_rate * (np.outer(self.pc, self.pc) + 0.001 * np.eye(self.dim)) # Adding the identity matrix to avoid singularity\n\n            # Update sigma (simplified version)\n            self.sigma *= np.exp(0.5 * (np.linalg.norm(self.ps)**2 - self.dim) / (self.dim + 5))\n\n            # Stagnation Check and Restart\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.restart_threshold:\n                if abs(self.best_fitness_history[-1] - self.best_fitness_history[-self.restart_threshold]) < 1e-6:\n                    stagnation_counter += 1\n                else:\n                    stagnation_counter = 0\n\n                if stagnation_counter > self.restart_threshold // 2:\n                    # Restart Population\n                    self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n                    self.fitness = np.array([func(x) for x in self.population])\n                    self.eval_count += self.popsize\n\n                    self.f_opt = np.min(self.fitness)\n                    self.x_opt = self.population[np.argmin(self.fitness)]\n                    self.best_fitness_history = [self.f_opt]  # Reset fitness history\n\n                    # Re-initialize CMA-ES parameters\n                    self.mean = self.x_opt.copy()\n                    self.C = np.eye(self.dim)\n                    self.ps = np.zeros(self.dim)\n                    self.pc = np.zeros(self.dim)\n                    self.sigma = 0.1\n\n                    stagnation_counter = 0\n\n            # Population Rejuvenation\n            if (self.eval_count // self.popsize) % self.rejuvenation_frequency == 0:\n                indices_to_rejuvenate = np.random.choice(self.popsize, self.popsize // 2, replace=False)\n                self.population[indices_to_rejuvenate] = np.random.uniform(lb, ub, size=(len(indices_to_rejuvenate), self.dim))\n                self.fitness[indices_to_rejuvenate] = np.array([func(x) for x in self.population[indices_to_rejuvenate]])\n                self.eval_count += len(indices_to_rejuvenate)\n                best_index = np.argmin(self.fitness)\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm LevyCMAES_DE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7d9120c2-e029-441b-9b70-6392bca77eab"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "0001493e-c56a-42e6-921a-0313dcc56169", "fitness": 0.28696921299849737, "name": "BudgetAwareCMAES", "description": "Covariance matrix adaptation evolution strategy (CMA-ES) with a budget-aware restart strategy and adaptive population sizing.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, restart_factor=3.0):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize  # Initial popsize will be set adaptively\n        self.sigma = sigma0\n        self.mean = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.restart_factor = restart_factor\n        self.restart_count = 0\n        self.min_popsize = 4 + int(3 * np.log(self.dim))\n        self.max_popsize = 4 + int(8 * np.log(self.dim))\n\n    def initialize(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.popsize = self.min_popsize\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def sample_population(self):\n        z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n        A = np.linalg.cholesky(self.C)\n        x = self.mean + self.sigma * z @ A.T\n        return x\n\n    def __call__(self, func):\n        self.initialize(func)\n        \n        mu = self.popsize // 2  # Select only the best mu individuals\n        c_sigma = (mu / self.dim) / ((self.dim + 4) + (mu / self.dim))\n        c_c = (4 + mu / self.dim) / (self.dim + 4)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu)\n        c_mu = min(1 - c_1, 2 * (mu - 1 + 1/mu) / ((self.dim + 2)**2 + 2*mu))\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu - 1) / (self.dim + 1)) - 1) + c_sigma\n        \n        while self.eval_count < self.budget:\n            # Sample population\n            x = self.sample_population()\n            \n            # Clip individuals to respect boundaries\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n\n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n            \n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            xmean = np.mean(x[:mu], axis=0)\n            self.ps = (1 - c_sigma) * self.ps + np.sqrt(c_sigma * (2 - c_sigma)) * (np.linalg.solve(np.linalg.cholesky(self.C), (xmean - self.mean) / self.sigma))\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - c_sigma)**(2 * self.eval_count / self.popsize)) / self.chiN) < (1.4 + 2 / (self.dim + 1))\n            self.pc = (1 - c_c) * self.pc + hsig * np.sqrt(c_c * (2 - c_c)) * (xmean - self.mean) / self.sigma\n            self.mean = xmean\n\n            # Update covariance matrix\n            C_old = self.C.copy()\n            self.C = (1 - c_1 - c_mu) * self.C + c_1 * np.outer(self.pc, self.pc) + c_mu * sum(np.outer((x[i] - self.mean) / self.sigma, (x[i] - self.mean) / self.sigma) for i in range(mu))\n\n            # Adapt step size\n            self.sigma *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Handle potential matrix ill-conditioning\n            if np.any(np.diag(self.C) <= 0):\n                self.C = C_old # Revert to old matrix and increase population size\n                self.popsize = min(self.popsize + 2, self.max_popsize)\n\n            # Restart strategy (Budget-aware)\n            if self.eval_count > self.restart_factor * self.popsize * self.dim: \n               self.initialize(func)\n               self.restart_count += 1\n               self.popsize = max(self.min_popsize, int(self.popsize/2)) # Adapt population Size\n               self.restart_factor *= 1.2\n               \n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm BudgetAwareCMAES scored 0.287 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f6b91601-0e99-4036-8b72-c8903016dbf1"], "operator": null, "metadata": {"aucs": [0.08016330352174539, 0.21455530981190807, 0.25858197166455743, 0.23015502278430744, 0.12369217265121846, 0.1595541215329067, 0.2638543255388187, 0.2286484422438726, 0.17046843961478264, 0.15112965413330293, 0.2891585597831138, 0.9996387732980769, 0.31813535610317367, 0.1731530991955731, 0.5874818315522978, 0.32330997522084803, 0.2841134352157394, 0.3181001733479052, 0.13864229603817435, 0.4268479967176242]}}
{"id": "6bd78e47-260c-43ab-85eb-7565e9a9937d", "fitness": 0.25636953475686086, "name": "DiversityAdaptiveDENeighborhood", "description": "A Differential Evolution variant that adjusts crossover rate based on the population diversity and uses a neighborhood-based mutation with a dynamically adjusted step size.", "code": "import numpy as np\n\nclass DiversityAdaptiveDENeighborhood:\n    def __init__(self, budget=10000, dim=10, popsize=None, CR_init=0.5, F=0.5, neighborhood_size=5, CR_adapt_speed=0.1, step_size_init=0.1, step_size_min=0.001):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.CR_init = CR_init\n        self.F = F\n        self.neighborhood_size = neighborhood_size\n        self.CR_adapt_speed = CR_adapt_speed\n        self.step_size_init = step_size_init\n        self.step_size_min = step_size_min\n        self.step_size = self.step_size_init\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.CR = np.full(self.popsize, self.CR_init)\n\n        while self.eval_count < self.budget:\n            # Calculate population diversity\n            diversity = np.std(self.population)\n\n            # Adjust crossover rate based on diversity\n            self.CR = self.CR_init + self.CR_adapt_speed * diversity\n            self.CR = np.clip(self.CR, 0.1, 0.9) # Ensure CR remains within reasonable bounds\n\n            # Adjust step size\n            self.step_size = max(self.step_size_min, self.step_size_init * (1 - self.eval_count / self.budget))\n\n            for i in range(self.popsize):\n                # Mutation: Neighborhood-based\n                neighbors_indices = np.random.choice(self.popsize, self.neighborhood_size, replace=False)\n                neighbors = self.population[neighbors_indices]\n                center = np.mean(neighbors, axis=0)\n                mutant = self.population[i] + self.step_size * (center - self.population[i]) # dynamically changing step size\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm DiversityAdaptiveDENeighborhood scored 0.256 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3a3cc6fb-865a-4cbe-8713-0240f3a2c0a8"], "operator": null, "metadata": {"aucs": [0.10546556065019008, 0.2162645814517682, 0.28981563512815933, 0.21097217808431679, 0.19481107597671288, 0.1625447179100198, 0.2105762375658624, 0.19101788692048227, 0.18207282684563675, 0.16376453231945176, 0.25956187524341234, 0.9991076118723182, 0.2643128209940775, 0.19934475839318022, 0.17747720573832337, 0.2636279298889662, 0.19942406974343252, 0.21233243696062976, 0.1867809861497466, 0.4381157673005306]}}
{"id": "7021d3a5-2c61-4523-866a-df1937b304c3", "fitness": 0.6623420064985158, "name": "AdaptiveMutationPoolDE", "description": "An adaptive Differential Evolution with a pool of mutation strategies and a learning mechanism to select the best strategy based on its recent performance.", "code": "import numpy as np\n\nclass AdaptiveMutationPoolDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, CR=0.7, mutation_pool=None, selection_pressure=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.CR = CR\n        self.selection_pressure = selection_pressure\n        \n        if mutation_pool is None:\n            self.mutation_pool = [\n                self._mutation_DE_rand1,\n                self._mutation_DE_best1,\n                self._mutation_DE_current_to_rand1,\n                self._mutation_DE_current_to_best1,\n            ]\n        else:\n            self.mutation_pool = mutation_pool\n        \n        self.mutation_success_rates = np.ones(len(self.mutation_pool)) / len(self.mutation_pool)  # Initialize with equal probabilities\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.mutation_history = []\n\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Select mutation strategy based on success rates\n                mutation_index = np.random.choice(len(self.mutation_pool), p=self.mutation_success_rates)\n                mutation_function = self.mutation_pool[mutation_index]\n\n                # Mutation\n                mutant = mutation_function(i)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                    self.mutation_history.append((mutation_index, True))\n                else:\n                    self.mutation_history.append((mutation_index, False))\n\n            self._update_mutation_success_rates()\n\n        return self.f_opt, self.x_opt\n\n    def _mutation_DE_rand1(self, i):\n        idxs = np.random.choice(self.popsize, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        return self.population[i] + 0.5 * (x2 - x3)\n\n    def _mutation_DE_best1(self, i):\n        idxs = np.random.choice(self.popsize, 2, replace=False)\n        x1, x2 = self.population[idxs]\n        return self.population[i] + 0.5 * (self.x_opt - self.population[i]) + 0.5 * (x1 - x2)\n\n    def _mutation_DE_current_to_rand1(self, i):\n         idxs = np.random.choice(self.popsize, 3, replace=False)\n         x1, x2, x3 = self.population[idxs]\n         return self.population[i] + 0.5*(x1 - self.population[i]) + 0.5 * (x2 - x3)\n\n    def _mutation_DE_current_to_best1(self, i):\n        idxs = np.random.choice(self.popsize, 2, replace=False)\n        x1, x2 = self.population[idxs]\n        return self.population[i] + 0.5 * (self.x_opt - self.population[i]) + 0.5 * (x1 - x2)\n\n    def _update_mutation_success_rates(self):\n        for i in range(len(self.mutation_pool)):\n            successes = [success for index, success in self.mutation_history if index == i]\n            if successes:\n                self.mutation_success_rates[i] = self.selection_pressure * np.mean(successes) + (1 - self.selection_pressure) * self.mutation_success_rates[i]\n            else:\n                self.mutation_success_rates[i] *= (1 - self.selection_pressure) #if no updates reduce probability\n        self.mutation_success_rates /= np.sum(self.mutation_success_rates)", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveMutationPoolDE scored 0.662 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3a3cc6fb-865a-4cbe-8713-0240f3a2c0a8"], "operator": null, "metadata": {"aucs": [0.22700519662693774, 0.5844114059902541, 0.7440169934816561, 0.8954919683534767, 0.7839058211907228, 0.831256274472196, 0.43841819875515586, 0.7062219074697862, 0.7915549074752554, 0.23609175051988618, 0.8848452244416882, 0.9993637659282003, 0.4595458611436899, 0.6896270696047806, 0.9135805713058953, 0.8020562953140971, 0.6403533110171886, 0.8643252788650827, 0.25646766969119317, 0.49830065832317316]}}
{"id": "d982cd1b-bdf6-4af7-a3cb-9774ef10ce04", "fitness": 0.36735856037681286, "name": "DistanceAdaptiveDENiche", "description": "Differential Evolution with a distance-based mutation strategy that favors mutations towards individuals further away in the search space, combined with self-adaptive parameters and a niching mechanism.", "code": "import numpy as np\n\nclass DistanceAdaptiveDENiche:\n    def __init__(self, budget=10000, dim=10, popsize=None, F_initial=0.5, CR_initial=0.7, F_adapt_rate=0.1, CR_adapt_rate=0.1, niche_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F_initial\n        self.CR = CR_initial\n        self.F_adapt_rate = F_adapt_rate\n        self.CR_adapt_rate = CR_adapt_rate\n        self.niche_radius = niche_radius  # Radius for niching\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def calculate_distances(self):\n        \"\"\"Calculates pairwise Euclidean distances between all individuals in the population.\"\"\"\n        distances = np.zeros((self.popsize, self.popsize))\n        for i in range(self.popsize):\n            for j in range(i + 1, self.popsize):\n                distances[i, j] = np.linalg.norm(self.population[i] - self.population[j])\n                distances[j, i] = distances[i, j]\n        return distances\n\n    def distance_based_mutation(self, i, distances, lb, ub):\n        \"\"\"Performs mutation favoring individuals further away.\"\"\"\n        farthest_idx = np.argmax(distances[i])  # Find the individual farthest from i\n        idxs = np.random.choice(self.popsize, 2, replace=False)  # Select two random individuals\n        x1, x2 = self.population[idxs]\n\n        mutant = self.population[i] + self.F * (self.population[farthest_idx] - x1) + self.F * (x2 - self.population[i])\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def niching(self):\n        \"\"\"Applies niching to maintain diversity. Penalizes fitness within niches.\"\"\"\n        distances = self.calculate_distances()\n        for i in range(self.popsize):\n            for j in range(i + 1, self.popsize):\n                if distances[i, j] < self.niche_radius:\n                    # Penalize fitness of individuals within the same niche\n                    penalty = 0.1 * (self.niche_radius - distances[i, j])  # Example penalty\n                    self.fitness[i] += penalty\n                    self.fitness[j] += penalty\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n\n        while self.eval_count < self.budget:\n            distances = self.calculate_distances()\n            for i in range(self.popsize):\n                # Mutation\n                mutant = self.distance_based_mutation(i, distances, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n            # Adapt F and CR based on population fitness variance\n            fitness_std = np.std(self.fitness)\n            self.F = np.clip(self.F + self.F_adapt_rate * (fitness_std - 0.1), 0.1, 0.9)\n            self.CR = np.clip(self.CR + self.CR_adapt_rate * (fitness_std - 0.1), 0.1, 0.9)\n\n\n            self.niching() # Apply niching after each generation\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm DistanceAdaptiveDENiche scored 0.367 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9aa10703-a5ba-4e9c-a3f2-532225e3b529"], "operator": null, "metadata": {"aucs": [0.160098147658997, 0.25136780643406287, 0.37172942681425836, 0.35476893043437274, 0.2573831512841922, 0.37076703914395304, 0.3138376437557002, 0.30138413836795364, 0.26652575644656507, 0.19803131270698937, 0.3760756257705091, 0.9900379695085588, 0.33239372706756, 0.2960544870085078, 0.6904053530980065, 0.38904466568948004, 0.28836210999052225, 0.47115689922494475, 0.18002089487869366, 0.48772612225242784]}}
{"id": "b76f0e78-a266-411f-95a4-3b246d4623cf", "fitness": 0.0, "name": "SelfAdaptivePopSizeDE", "description": "Differential Evolution with a self-adaptive population size based on the success rate of the mutation and crossover operations.", "code": "import numpy as np\n\nclass SelfAdaptivePopSizeDE:\n    def __init__(self, budget=10000, dim=10, popsize_init=None, F=0.5, CR=0.7, popsize_min=4, popsize_max=200):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize_init if popsize_init is not None else 10 * self.dim\n        self.popsize = int(self.popsize)\n        self.F = F\n        self.CR = CR\n        self.popsize_min = popsize_min\n        self.popsize_max = popsize_max\n        self.success_rate = 0.5\n        self.success_history = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            successful_mutations = 0\n            for i in range(self.popsize):\n                # Mutation\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                mutant = self.population[i] + self.F * (x_r1 - x_r2)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    successful_mutations += 1\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n            # Adjust population size based on success rate\n            success_rate = successful_mutations / self.popsize\n            self.success_history.append(success_rate)\n            if len(self.success_history) > 10:\n                self.success_history = self.success_history[-10:]\n            self.success_rate = np.mean(self.success_history)\n            \n            if self.success_rate > 0.3:\n                self.popsize = min(self.popsize + 1, self.popsize_max)\n            elif self.success_rate < 0.1:\n                self.popsize = max(self.popsize - 1, self.popsize_min)\n            \n            self.popsize = int(self.popsize)\n\n            # Resize population\n            if self.popsize != self.population.shape[0]:\n                if self.popsize > self.population.shape[0]:\n                    # Add new individuals randomly\n                    new_individuals = np.random.uniform(lb, ub, size=(self.popsize - self.population.shape[0], self.dim))\n                    self.population = np.vstack((self.population, new_individuals))\n                    new_fitness = np.array([func(x) for x in new_individuals])\n                    self.fitness = np.concatenate((self.fitness, new_fitness))\n                    self.eval_count += new_individuals.shape[0]\n                else:\n                    # Remove worst individuals\n                    indices_to_keep = np.argsort(self.fitness)[:self.popsize]\n                    self.population = self.population[indices_to_keep]\n                    self.fitness = self.fitness[indices_to_keep]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm SelfAdaptivePopSizeDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6bd78e47-260c-43ab-85eb-7565e9a9937d"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "a3f892f7-e0b7-4eee-a5b6-186853b2e591", "fitness": -Infinity, "name": "AdaptiveArchiveDE", "description": "A Differential Evolution strategy with a self-adaptive population size and an archive to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveArchiveDE:\n    def __init__(self, budget=10000, dim=10, initial_popsize=50, archive_size=10, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = initial_popsize\n        self.archive_size = archive_size\n        self.F = F\n        self.CR = CR\n        self.population = None\n        self.fitness = None\n        self.archive = None\n        self.archive_fitness = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.archive = np.zeros((self.archive_size, self.dim))\n        self.archive_fitness = np.full(self.archive_size, np.inf)\n\n    def ensure_bounds(self, vec, lb, ub):\n        vec_clipped = np.clip(vec, lb, ub)\n        return vec_clipped\n        \n    def mutate(self, target_index):\n        indices = [i for i in range(self.popsize) if i != target_index]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, mutant, target, CR):\n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def update_archive(self, individual, fitness_value):\n        if fitness_value < np.max(self.archive_fitness):\n            worst_index = np.argmax(self.archive_fitness)\n            self.archive[worst_index] = individual\n            self.archive_fitness[worst_index] = fitness_value\n            \n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                \n                mutant = self.mutate(i)\n                trial = self.crossover(mutant, self.population[i], self.CR)\n                trial = self.ensure_bounds(trial, func.bounds.lb, func.bounds.ub)\n\n                f = func(trial)\n                self.eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.update_archive(self.population[i], self.fitness[i])\n                    self.population[i] = trial\n                    self.fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                else:\n                    # Archive exploitation: replace a random individual in the population \n                    # with a random member from the archive with a small probability\n                    if np.random.rand() < 0.05 and self.eval_count < 0.9 * self.budget: \n                       if np.any(self.archive_fitness < np.inf):\n                           valid_indices = np.where(self.archive_fitness < np.inf)[0]\n                           arch_idx = np.random.choice(valid_indices)\n                           self.population[np.random.randint(self.popsize)] = self.archive[arch_idx]\n                           self.fitness = np.array([func(x) for x in self.population])\n                           self.eval_count += self.popsize -1 # Correction: minus one as only popsize-1 new calls where made. \n                           \n                           if np.min(self.fitness) < self.f_opt: # Find if any new bests. \n                               self.f_opt = np.min(self.fitness)\n                               self.x_opt = self.population[np.argmin(self.fitness)]   \n                \n                # Adjust population size based on progress\n                if self.eval_count % (self.dim * 5) == 0:\n                    if np.std(self.fitness) < 1e-6 and self.popsize < 100:\n                        self.popsize = min(self.popsize + 5, 100)  # Increase popsize if converged\n                        new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(5, self.dim))\n                        new_fitness = np.array([func(x) for x in new_individuals])\n                        self.eval_count += 5\n                        \n                        self.population = np.vstack((self.population, new_individuals))\n                        self.fitness = np.concatenate((self.fitness, new_fitness))\n\n                    elif self.popsize > 20 and self.eval_count < 0.75 * self.budget:\n                        self.popsize = max(20, self.popsize - 2)  # Decrease popsize if not making progress\n                        self.population = self.population[:self.popsize]\n                        self.fitness = self.fitness[:self.popsize]\n                    \n\n                if self.eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 58, in __call__\nIndexError: index 48 is out of bounds for axis 0 with size 48\n.", "error": "", "parent_ids": ["0001493e-c56a-42e6-921a-0313dcc56169"], "operator": null, "metadata": {}}
{"id": "e1067b20-65f8-4dfc-9176-4d9bad6cce67", "fitness": -Infinity, "name": "SelfAdjustingDE", "description": "A Differential Evolution strategy with a self-adjusting population size based on stagnation detection and adaptive parameter control using a mirrored sampling approach.", "code": "import numpy as np\n\nclass SelfAdjustingDE:\n    def __init__(self, budget=10000, dim=10, popsize_init=None, F=0.5, CR=0.7, stagnation_threshold=10):\n        self.budget = budget\n        self.dim = dim\n        self.popsize_init = popsize_init if popsize_init is not None else 10 * dim\n        self.F = F\n        self.CR = CR\n        self.stagnation_threshold = stagnation_threshold\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def initialize(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.popsize_init, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.popsize_init\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n    def mutate(self, pop, F):\n        mutated_pop = np.zeros_like(pop)\n        for i in range(len(pop)):\n            idxs = np.random.choice(len(pop), 3, replace=False)\n            x_r1, x_r2, x_r3 = pop[idxs]\n            mutated_pop[i] = x_r1 + F * (x_r2 - x_r3)\n        return mutated_pop\n\n    def crossover(self, pop, mutated_pop, CR):\n        crossed_pop = np.zeros_like(pop)\n        for i in range(len(pop)):\n            for j in range(self.dim):\n                if np.random.rand() < CR:\n                    crossed_pop[i, j] = mutated_pop[i, j]\n                else:\n                    crossed_pop[i, j] = pop[i, j]\n        return crossed_pop\n\n    def mirrored_sampling(self, func, x):\n        \"\"\"Handles boundary constraints using mirrored sampling.\"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        x_corrected = np.copy(x)\n        for i in range(self.dim):\n            if x[i] < lb:\n                x_corrected[i] = lb + (lb - x[i])\n            elif x[i] > ub:\n                x_corrected[i] = ub - (x[i] - ub)\n                \n            # Double Mirroring to handle corner cases\n            if x_corrected[i] < lb:\n                x_corrected[i] = lb + (lb - x_corrected[i])\n            elif x_corrected[i] > ub:\n                x_corrected[i] = ub - (x_corrected[i] - ub)\n                \n        return x_corrected\n        \n    def __call__(self, func):\n        self.initialize(func)\n        popsize = self.popsize_init\n\n        while self.eval_count < self.budget:\n            # Adaptive F and CR\n            F = np.random.normal(self.F, 0.1, popsize)\n            F = np.clip(F, 0.1, 1.0)\n            CR = np.random.normal(self.CR, 0.1, popsize)\n            CR = np.clip(CR, 0.1, 1.0)\n\n            mutated_population = self.mutate(self.population, F=np.mean(F))\n            crossed_population = self.crossover(self.population, mutated_population, CR=np.mean(CR))\n            \n            # Boundary Handling with Mirrored Sampling\n            for i in range(popsize):\n                crossed_population[i] = self.mirrored_sampling(func, crossed_population[i])\n\n            new_fitness = np.array([func(x) for x in crossed_population])\n            self.eval_count += popsize\n\n            # Selection\n            for i in range(popsize):\n                if new_fitness[i] < self.fitness[i]:\n                    self.fitness[i] = new_fitness[i]\n                    self.population[i] = crossed_population[i]\n\n            # Update optimal solution\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            # Population size adjustment\n            if self.stagnation_counter > self.stagnation_threshold:\n                popsize = int(popsize * 0.9)  # Reduce population size\n                if popsize < 4:\n                    popsize = self.popsize_init # Reset to initial population size\n                \n                # Repopulate the population with better individuals\n                best_indices = np.argsort(self.fitness)[:popsize]\n                self.population = self.population[best_indices]\n                self.fitness = self.fitness[best_indices]\n                \n                remaining_size = self.popsize_init - popsize\n                new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(remaining_size, self.dim))\n                new_fitness_vals = np.array([func(x) for x in new_individuals])\n                self.eval_count += remaining_size\n                \n                self.population = np.concatenate((self.population, new_individuals), axis=0)\n                self.fitness = np.concatenate((self.fitness, new_fitness_vals), axis=0)\n                popsize = self.popsize_init\n\n                self.stagnation_counter = 0\n            else:\n                 if popsize < self.popsize_init:\n                    popsize = self.popsize_init # Reset if population dropped earlier\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 81, in __call__\n  File \"<string>\", line 52, in mirrored_sampling\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n.", "error": "", "parent_ids": ["0001493e-c56a-42e6-921a-0313dcc56169"], "operator": null, "metadata": {}}
{"id": "1a8b6472-cd29-4d71-8279-a524a64ee990", "fitness": 0.0, "name": "GradientAdaptiveCMAES", "description": "A CMA-ES variant that dynamically adjusts its population size and step size based on the function's landscape estimated by local gradient information.", "code": "import numpy as np\n\nclass GradientAdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, gradient_samples=5, stepsize_adapt_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.sigma = sigma0\n        self.mean = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.gradient_samples = gradient_samples\n        self.stepsize_adapt_factor = stepsize_adapt_factor  # Adjust step size adaptation rate\n\n    def initialize(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def sample_population(self):\n        z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n        A = np.linalg.cholesky(self.C)\n        x = self.mean + self.sigma * z @ A.T\n        return x\n\n    def estimate_gradient_norm(self, func, x):\n        \"\"\"Estimates the norm of the gradient around a point.\"\"\"\n        gradient_estimates = []\n        for _ in range(self.gradient_samples):\n            delta = np.random.normal(0, self.sigma, size=self.dim)\n            x_plus = np.clip(x + delta, func.bounds.lb, func.bounds.ub)\n            x_minus = np.clip(x - delta, func.bounds.lb, func.bounds.ub)\n\n            f_plus = func(x_plus)\n            f_minus = func(x_minus)\n            \n            if not isinstance(f_plus, float) or not isinstance(f_minus, float):\n                continue\n\n            gradient_estimates.append((f_plus - f_minus) / (2 * self.sigma))\n\n        if not gradient_estimates:\n          return 0.0\n\n        return np.mean(np.abs(np.array(gradient_estimates)))  # Average absolute gradient estimate\n\n    def adapt_step_size(self, gradient_norm):\n        \"\"\"Adapts the step size based on the estimated gradient norm.\"\"\"\n        if gradient_norm > 1:  # Steep slope\n            self.sigma *= (1 - self.stepsize_adapt_factor) # Reduce step size\n        elif gradient_norm < 0.1:  # Flat region\n            self.sigma *= (1 + self.stepsize_adapt_factor)  # Increase step size\n        # else: keep step size the same\n\n    def __call__(self, func):\n        self.initialize(func)\n        mu = self.popsize // 2\n        c_sigma = (mu / self.dim) / ((self.dim + 4) + (mu / self.dim))\n        c_c = (4 + mu / self.dim) / (self.dim + 4)\n        c_1 = 2 / ((self.dim + 1.3)**2 + mu)\n        c_mu = min(1 - c_1, 2 * (mu - 1 + 1/mu) / ((self.dim + 2)**2 + 2*mu))\n        d_sigma = 1 + 2 * max(0, np.sqrt((mu - 1) / (self.dim + 1)) - 1) + c_sigma\n\n        while self.eval_count < self.budget:\n            # Sample population\n            x = self.sample_population()\n            \n            # Clip individuals to respect boundaries\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n\n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.popsize\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            xmean = np.mean(x[:mu], axis=0)\n            self.ps = (1 - c_sigma) * self.ps + np.sqrt(c_sigma * (2 - c_sigma)) * (np.linalg.solve(np.linalg.cholesky(self.C), (xmean - self.mean) / self.sigma))\n            \n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - c_sigma)**(2 * self.eval_count / self.popsize)) / self.chiN) < (1.4 + 2 / (self.dim + 1))\n            self.pc = (1 - c_c) * self.pc + hsig * np.sqrt(c_c * (2 - c_c)) * (xmean - self.mean) / self.sigma\n            self.mean = xmean\n\n            # Update covariance matrix\n            self.C = (1 - c_1 - c_mu) * self.C + c_1 * np.outer(self.pc, self.pc) + c_mu * sum(np.outer((x[i] - self.mean) / self.sigma, (x[i] - self.mean) / self.sigma) for i in range(mu))\n\n            # Adapt step size\n            gradient_norm = self.estimate_gradient_norm(func, self.mean)\n            self.adapt_step_size(gradient_norm)\n\n            if self.eval_count >= self.budget:\n                break\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm GradientAdaptiveCMAES scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0001493e-c56a-42e6-921a-0313dcc56169"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "1295be8c-7138-4f31-9e87-b834db57feb7", "fitness": 0.0, "name": "GradientAdaptiveDE", "description": "A Differential Evolution variant with a novel mutation strategy that leverages the fitness landscape gradient estimated using a small sample around each individual.", "code": "import numpy as np\n\nclass GradientAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, grad_samples=5, grad_step=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.F = F\n        self.CR = CR\n        self.grad_samples = grad_samples  # Number of samples to estimate gradient\n        self.grad_step = grad_step  # Step size for gradient estimation\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def estimate_gradient(self, func, x):\n        \"\"\"Estimates the gradient of the fitness landscape at a given point x.\"\"\"\n        gradient = np.zeros(self.dim)\n        for _ in range(self.grad_samples):\n            direction = np.random.randn(self.dim)\n            direction /= np.linalg.norm(direction)  # Normalize direction\n\n            x_plus = x + self.grad_step * direction\n            x_minus = x - self.grad_step * direction\n\n            # Clip values to stay within bounds\n            x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n            x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n\n            f_plus = func(x_plus)\n            f_minus = func(x_minus)\n            self.eval_count += 2  # Account for function evaluations\n\n            gradient += (f_plus - f_minus) * direction\n\n        return gradient / (2 * self.grad_samples * self.grad_step)\n\n    def gradient_guided_mutation(self, func, i, lb, ub):\n        \"\"\"Performs mutation guided by the estimated gradient.\"\"\"\n        gradient = self.estimate_gradient(func, self.population[i])\n        idxs = np.random.choice(self.popsize, 2, replace=False)  # Select two random individuals\n        x1, x2 = self.population[idxs]\n\n        # The mutation moves towards the negative gradient direction, scaled by F\n        mutant = self.population[i] + self.F * (self.population[i] - x1) + self.F * (x2 - self.population[i]) - self.F * gradient\n\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation\n                mutant = self.gradient_guided_mutation(func, i, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm GradientAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d982cd1b-bdf6-4af7-a3cb-9774ef10ce04"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "4ad72b37-fe8f-439f-8bb0-0eb774305e08", "fitness": 0.29957882568279376, "name": "CoordinateAdaptiveCMAES", "description": "A simplified CMA-ES variant using rank-mu update and adaptive coordinate-wise learning rates based on successful mutations along each dimension.", "code": "import numpy as np\n\nclass CoordinateAdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize else 4 + int(3 * np.log(self.dim))\n        self.sigma = sigma0\n        self.mean = None\n        self.coordinate_sigmas = None  # Individual learning rates for each dimension\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = None\n\n    def initialize(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.coordinate_sigmas = np.ones(self.dim) * self.sigma\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.success_history = np.zeros(self.dim)\n\n    def sample_population(self):\n        z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n        x = self.mean + self.coordinate_sigmas * z\n        return x\n\n    def __call__(self, func):\n        self.initialize(func)\n        mu = self.popsize // 2\n\n        while self.eval_count < self.budget:\n            # Sample population\n            x = self.sample_population()\n\n            # Clip to boundaries\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n\n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.popsize\n\n            # Sort population\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            xmean = np.mean(x[:mu], axis=0)\n            delta_mean = xmean - self.mean\n            self.mean = xmean\n\n            # Update coordinate-wise learning rates based on success\n            for i in range(self.dim):\n                if np.abs(delta_mean[i]) > 1e-8: # prevent division by zero\n                    success_rate = np.mean((x[:mu, i] - self.mean[i]) * delta_mean[i] > 0) # Measure the success of updates along each coordinate.\n\n                    if success_rate > 0.3:\n                        self.coordinate_sigmas[i] *= 1.05  # Increase learning rate if successful\n                        self.success_history[i] +=1\n                    else:\n                        self.coordinate_sigmas[i] *= 0.95  # Decrease learning rate if not successful\n                        self.success_history[i] = max(0, self.success_history[i] -1) # Reduce the number of past successes\n                self.coordinate_sigmas[i] = np.clip(self.coordinate_sigmas[i], self.sigma/10, self.sigma*10) # Keep the coordinate sigmas in a reasonable range\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm CoordinateAdaptiveCMAES scored 0.300 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0001493e-c56a-42e6-921a-0313dcc56169"], "operator": null, "metadata": {"aucs": [0.10933685440527663, 0.1916987106986836, 0.3154645047349387, 0.21175646342140453, 0.2261200278722808, 0.25898827280735615, 0.23712672334888307, 0.24535652293306243, 0.24748278418176806, 0.1630746480133033, 0.22287467531980032, 0.9807967821499156, 0.248686070796019, 0.23805382252014806, 0.642415739892729, 0.28507055521898006, 0.24004527028077127, 0.31061284530461064, 0.16184553790182932, 0.45476970185411514]}}
{"id": "1ae5907b-7dda-41e4-9456-70a5f3af9360", "fitness": 0.7334066385293108, "name": "RingTopologyDE", "description": "Population-based algorithm with a ring topology for information sharing and an adaptive mutation strategy inspired by differential evolution, promoting exploration and exploitation.", "code": "import numpy as np\n\nclass RingTopologyDE:\n    def __init__(self, budget=10000, dim=10, popsize=40, F=0.5, CR=0.7, topology_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize\n        self.F = F\n        self.CR = CR\n        self.topology_size = topology_size\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def evolve(self, func):\n        for i in range(self.popsize):\n            # Ring topology selection\n            neighbors_idx = [(i - j) % self.popsize for j in range(self.topology_size // 2, 0, -1)] + \\\n                            [i] + \\\n                            [(i + j) % self.popsize for j in range(1, self.topology_size // 2 + 1)]\n\n            # Adaptive DE mutation strategy\n            if np.random.rand() < 0.5: # Use best neighbor\n                best_neighbor_idx = neighbors_idx[np.argmin(self.fitness[neighbors_idx])]\n                \n                candidates = np.random.choice(neighbors_idx, size=2, replace=False)\n                \n                x_r1 = self.population[candidates[0]]\n                x_r2 = self.population[candidates[1]]\n                \n                v = self.population[best_neighbor_idx] + self.F * (x_r1 - x_r2)\n            else:  # Use random neighbor\n                candidates = np.random.choice(neighbors_idx, size=3, replace=False)\n                x_r1 = self.population[candidates[0]]\n                x_r2 = self.population[candidates[1]]\n                x_r3 = self.population[candidates[2]]\n                v = x_r1 + self.F * (x_r2 - x_r3)\n\n            # Crossover\n            u = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(self.dim):\n                    u[j] = v[j]\n                else:\n                    u[j] = self.population[i][j]\n                    \n            # Clip individuals to respect boundaries\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            u = np.clip(u, lb, ub)\n\n            # Evaluation\n            f = func(u)\n            self.eval_count += 1\n\n            # Selection\n            if f < self.fitness[i]:\n                self.population[i] = u\n                self.fitness[i] = f\n\n                # Update optimal solution\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = u\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm RingTopologyDE scored 0.733 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0001493e-c56a-42e6-921a-0313dcc56169"], "operator": null, "metadata": {"aucs": [0.2658875804843116, 0.6534285088466953, 0.7645005748312581, 0.8868732033535629, 0.845572500534085, 0.8646587511677399, 0.6507015219513779, 0.7716114005463441, 0.8473102930001812, 0.7622828606903727, 0.9049290889549131, 0.9994235505264898, 0.41603579696396353, 0.7930153517685903, 0.9194243061376368, 0.846273922120367, 0.7250132233748957, 0.9026176121099483, 0.3146107021645863, 0.5339620210588957]}}
{"id": "8f6ee1f1-6393-43b7-aa28-144c51178a55", "fitness": 0.40020982486715767, "name": "LocalityAwareSelfAdaptiveDE", "description": "A Differential Evolution algorithm that combines a self-adaptive mutation strategy with a locality-based exploration strategy, adjusting its behavior based on the function evaluations.", "code": "import numpy as np\n\nclass LocalityAwareSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, CR=0.7, F=0.5, locality_ratio=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.CR = CR\n        self.F = F\n        self.locality_ratio = locality_ratio\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.F_history = []\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Self-adaptive F\n                F = np.random.normal(self.F, 0.1)\n                F = np.clip(F, 0.1, 1.0)\n\n                # Mutation: Incorporate locality-based exploration\n                if np.random.rand() < self.locality_ratio:\n                    # Local search: Perturb the current individual\n                    mutant = self.population[i] + np.random.normal(0, 0.1, size=self.dim) * (ub - lb)\n                else:\n                    # Standard DE mutation (rand1)\n                    idxs = np.random.choice(self.popsize, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutant = self.population[i] + F * (x2 - x3)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                    self.F_history.append(F)\n                \n            # Adapt F based on recent success\n            if self.F_history:\n              self.F = 0.9 * self.F + 0.1 * np.mean(self.F_history)\n              self.F_history = []\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm LocalityAwareSelfAdaptiveDE scored 0.400 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7021d3a5-2c61-4523-866a-df1937b304c3"], "operator": null, "metadata": {"aucs": [0.14776041617266633, 0.2531466815838612, 0.3847434313721497, 0.4938979068566136, 0.3176779553247273, 0.4262491419266117, 0.29809087730400485, 0.3364262596866612, 0.31256258020571326, 0.1943572278410236, 0.5049013621993059, 0.996917134881393, 0.3285339212869821, 0.2981566466977642, 0.72701192694471, 0.43800438014712406, 0.322217178271881, 0.542308702275005, 0.1896525879938611, 0.49158017837109513]}}
{"id": "a28e796c-4523-4b5e-bbd0-f88ded454d76", "fitness": 0.40286198235071574, "name": "ArchiveDE", "description": "Differential Evolution with an archive to store promising solutions rejected during selection, which can then be used in mutation to increase diversity and exploration.", "code": "import numpy as np\n\nclass ArchiveDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, CR=0.7, F=0.5, archive_size=10, archive_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.CR = CR\n        self.F = F\n        self.archive_size = archive_size\n        self.archive_rate = archive_rate\n        self.archive = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Mutation\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n\n                # With probability archive_rate, use a vector from the archive\n                if self.archive and np.random.rand() < self.archive_rate:\n                    idx_archive = np.random.randint(len(self.archive))\n                    x_archive = self.archive[idx_archive]\n                    mutant = self.population[i] + self.F * (x1 - x2) + self.F * (x_archive - x3) # archive individual mixed with the population\n                else:\n                    mutant = self.population[i] + self.F * (x2 - x3)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    # Replace individual\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update optimal solution\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                else:\n                    # Add the rejected individual to the archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i])\n                    else:\n                        # Replace a random element in the archive\n                        idx_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_replace] = self.population[i]\n                    \n\n            # Potentially prune the archive (optional)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm ArchiveDE scored 0.403 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7021d3a5-2c61-4523-866a-df1937b304c3"], "operator": null, "metadata": {"aucs": [0.1573753942655891, 0.2711905942855005, 0.3773563642552288, 0.446068148851142, 0.30552288145354045, 0.4359179185486939, 0.3039423515436832, 0.35134660627403025, 0.3181358052637656, 0.19234858868577898, 0.6162451412132199, 0.9936633504548494, 0.3316166308042042, 0.3130773159661445, 0.7375280594338047, 0.41391302619292414, 0.318653961406275, 0.49983646401806214, 0.18949685915397652, 0.4840041849439022]}}
{"id": "eff990ba-4bfe-49bd-b55f-db30573aff1d", "fitness": 0.3652824561498742, "name": "CauchyMutationDE", "description": "Differential Evolution with self-adaptive parameters and a Cauchy mutation operator for enhanced exploration, particularly useful for escaping local optima.", "code": "import numpy as np\n\nclass CauchyMutationDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, CR=0.7, F=0.5, F_adapt=True, CR_adapt=True):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.CR = CR\n        self.F = F\n        self.F_adapt = F_adapt\n        self.CR_adapt = CR_adapt\n        self.F_memory = []\n        self.CR_memory = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Parameter adaptation\n                if self.F_adapt:\n                    self.F = self._adapt_parameter(self.F, self.F_memory, 0.1)\n                if self.CR_adapt:\n                    self.CR = self._adapt_parameter(self.CR, self.CR_memory, 0.1)\n\n                # Mutation using Cauchy distribution\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = self.population[i] + self.F * (x2 - x3) + self._cauchy_mutation(self.dim)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                        if self.F_adapt:\n                            self.F_memory.append(self.F)\n                        if self.CR_adapt:\n                            self.CR_memory.append(self.CR)\n\n        return self.f_opt, self.x_opt\n\n    def _cauchy_mutation(self, dim, scale=0.1):\n        return np.random.standard_cauchy(size=dim) * scale\n\n    def _adapt_parameter(self, param, memory, adaptation_rate):\n        if memory:\n            change = adaptation_rate * (np.mean(memory) - param)\n            param += change\n            param = np.clip(param, 0.1, 0.9)  # Ensure F and CR stay within reasonable bounds\n        return param", "configspace": "", "generation": 8, "feedback": "The algorithm CauchyMutationDE scored 0.365 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7021d3a5-2c61-4523-866a-df1937b304c3"], "operator": null, "metadata": {"aucs": [0.1439315077172334, 0.22986015553687045, 0.3572887961352418, 0.41043443400411084, 0.2920086939114621, 0.3787795653817181, 0.28601773014765053, 0.3146913911227347, 0.2915375777585919, 0.1948193475011296, 0.3618830443318245, 0.9952917078062828, 0.2762215490784409, 0.2872116861022871, 0.7159223208474218, 0.37421224227332384, 0.29716869614230634, 0.43060966102613996, 0.1851451088404067, 0.4826139073323057]}}
{"id": "cd279025-8208-4cea-bb68-416db90cae64", "fitness": 0.5299668444215337, "name": "RuggednessAwareAdaptiveDE", "description": "A Differential Evolution variant with a self-adaptive ensemble of mutation strategies weighted by their performance and dynamically adjusted based on landscape ruggedness estimated by fitness variance.", "code": "import numpy as np\n\nclass RuggednessAwareAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, CR=0.7, F=0.5, selection_pressure=0.2, ruggedness_window=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.CR = CR\n        self.F = F\n        self.selection_pressure = selection_pressure\n        self.ruggedness_window = ruggedness_window  # Window size for ruggedness estimation\n\n        self.mutation_strategies = {\n            \"rand1\": self._mutation_DE_rand1,\n            \"best1\": self._mutation_DE_best1,\n            \"current_to_rand1\": self._mutation_DE_current_to_rand1,\n            \"current_to_best1\": self._mutation_DE_current_to_best1\n        }\n        self.strategy_weights = {name: 1.0 / len(self.mutation_strategies) for name in self.mutation_strategies}\n        self.success_rates = {name: 0.0 for name in self.mutation_strategies}\n        self.strategy_usage_count = {name: 0 for name in self.mutation_strategies}\n        self.fitness_history = []\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.popsize):\n                # Select mutation strategy based on weights\n                strategy_name = self._select_strategy()\n                mutation_function = self.mutation_strategies[strategy_name]\n                self.strategy_usage_count[strategy_name] += 1\n\n                # Mutation\n                mutant = mutation_function(i)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness_history.append(f_trial)  # Store for ruggedness calculation\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n                    self.success_rates[strategy_name] += 1\n                else:\n                    self.fitness_history.append(self.fitness[i]) #Store for ruggedness calculation\n\n            self._update_strategy_weights()\n            self._adjust_parameters(func)  # Adjust CR and F based on ruggedness\n        return self.f_opt, self.x_opt\n\n    def _select_strategy(self):\n        names = list(self.strategy_weights.keys())\n        weights = list(self.strategy_weights.values())\n        return np.random.choice(names, p=weights)\n\n    def _mutation_DE_rand1(self, i):\n        idxs = np.random.choice(self.popsize, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        return self.population[i] + self.F * (x2 - x3)\n\n    def _mutation_DE_best1(self, i):\n        idxs = np.random.choice(self.popsize, 2, replace=False)\n        x1, x2 = self.population[idxs]\n        return self.population[i] + self.F * (self.x_opt - self.population[i]) + self.F * (x1 - x2)\n\n    def _mutation_DE_current_to_rand1(self, i):\n         idxs = np.random.choice(self.popsize, 3, replace=False)\n         x1, x2, x3 = self.population[idxs]\n         return self.population[i] + self.F*(x1 - self.population[i]) + self.F * (x2 - x3)\n\n    def _mutation_DE_current_to_best1(self, i):\n        idxs = np.random.choice(self.popsize, 2, replace=False)\n        x1, x2 = self.population[idxs]\n        return self.population[i] + self.F * (self.x_opt - self.population[i]) + self.F * (x1 - x2)\n\n    def _update_strategy_weights(self):\n        total_usage = sum(self.strategy_usage_count.values())\n        if total_usage == 0:\n             return #Avoid division by zero\n        for name in self.strategy_weights:\n            success_rate = self.success_rates[name] / self.strategy_usage_count[name] if self.strategy_usage_count[name] > 0 else 0.0\n            self.strategy_weights[name] = (1 - self.selection_pressure) * self.strategy_weights[name] + self.selection_pressure * success_rate\n            self.strategy_usage_count[name] = 0 #reset\n            self.success_rates[name] = 0 #reset\n        \n        total_weight = sum(self.strategy_weights.values())\n        for name in self.strategy_weights:\n            self.strategy_weights[name] /= total_weight #normalize\n            \n\n    def _adjust_parameters(self, func):\n        # Estimate landscape ruggedness based on recent fitness variance\n        if len(self.fitness_history) > self.ruggedness_window:\n            fitness_window = self.fitness_history[-self.ruggedness_window:]\n            fitness_variance = np.var(fitness_window)\n        else:\n            fitness_variance = 0.0\n\n        # Adjust CR and F based on ruggedness\n        if fitness_variance > 1e-6:  # If landscape is rugged\n            self.CR = min(1.0, self.CR + 0.1)  # Increase exploration\n            self.F = max(0.1, self.F - 0.05)  # Reduce step size\n        else:  # If landscape is smooth\n            self.CR = max(0.2, self.CR - 0.05)  # Increase exploitation\n            self.F = min(0.9, self.F + 0.1)  # Increase step size", "configspace": "", "generation": 8, "feedback": "The algorithm RuggednessAwareAdaptiveDE scored 0.530 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7021d3a5-2c61-4523-866a-df1937b304c3"], "operator": null, "metadata": {"aucs": [0.18250249909984995, 0.6122088533695499, 0.5238162094781342, 0.8435307283992871, 0.49308451527174557, 0.6729652010556166, 0.3048347311791011, 0.4764370361380682, 0.47382198028756617, 0.22324599652800403, 0.869319599243512, 0.9913719154797365, 0.3969202363584291, 0.43761337226169617, 0.7303627766230817, 0.3853484251914028, 0.44045416452800523, 0.8008169156657892, 0.24222671112139138, 0.4984550211507097]}}
{"id": "926b4feb-8e47-4788-957d-7268a19a1537", "fitness": 0.5647879849899782, "name": "SOMAdaptiveDE", "description": "An adaptive Differential Evolution with a self-organizing map (SOM) to cluster individuals and apply different mutation strategies based on cluster membership, promoting diversity and exploitation.", "code": "import numpy as np\n\nclass SOMAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, popsize=None, CR=0.7, som_grid_size=5, learning_rate=0.1, sigma=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 10 * self.dim\n        self.CR = CR\n        self.som_grid_size = som_grid_size\n        self.learning_rate = learning_rate\n        self.sigma = sigma\n        self.som = np.random.rand(som_grid_size, som_grid_size, dim)\n        self.mutation_strategies = [\n            self._mutation_DE_rand1,\n            self._mutation_DE_best1,\n            self._mutation_DE_current_to_rand1,\n            self._mutation_DE_current_to_best1\n        ]\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.popsize\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            # SOM training\n            self._train_som(self.population)\n\n            # Assign individuals to SOM nodes\n            node_assignments = self._assign_to_nodes(self.population)\n\n            for i in range(self.popsize):\n                # Select mutation strategy based on SOM node assignment\n                node_row, node_col = node_assignments[i]\n                mutation_index = (node_row * self.som_grid_size + node_col) % len(self.mutation_strategies)  # Ensure valid index\n                mutation_function = self.mutation_strategies[mutation_index]\n\n                # Mutation\n                mutant = mutation_function(i)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n        return self.f_opt, self.x_opt\n\n    def _train_som(self, data):\n        for x in data:\n            best_node = self._find_best_matching_unit(x)\n            self._update_som_nodes(x, best_node)\n\n    def _find_best_matching_unit(self, x):\n        distances = np.sum((self.som - x)**2, axis=2)\n        return np.unravel_index(np.argmin(distances), distances.shape)\n\n    def _update_som_nodes(self, x, best_node):\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                distance = np.sqrt((i - best_node[0])**2 + (j - best_node[1])**2)\n                influence = np.exp(-distance**2 / (2 * self.sigma**2))\n                self.som[i, j] += self.learning_rate * influence * (x - self.som[i, j])\n\n    def _assign_to_nodes(self, data):\n        assignments = []\n        for x in data:\n            assignments.append(self._find_best_matching_unit(x))\n        return assignments\n\n    def _mutation_DE_rand1(self, i):\n        idxs = np.random.choice(self.popsize, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        return self.population[i] + 0.5 * (x2 - x3)\n\n    def _mutation_DE_best1(self, i):\n        idxs = np.random.choice(self.popsize, 2, replace=False)\n        x1, x2 = self.population[idxs]\n        return self.population[i] + 0.5 * (self.x_opt - self.population[i]) + 0.5 * (x1 - x2)\n\n    def _mutation_DE_current_to_rand1(self, i):\n         idxs = np.random.choice(self.popsize, 3, replace=False)\n         x1, x2, x3 = self.population[idxs]\n         return self.population[i] + 0.5*(x1 - self.population[i]) + 0.5 * (x2 - x3)\n\n    def _mutation_DE_current_to_best1(self, i):\n        idxs = np.random.choice(self.popsize, 2, replace=False)\n        x1, x2 = self.population[idxs]\n        return self.population[i] + 0.5 * (self.x_opt - self.population[i]) + 0.5 * (x1 - x2)", "configspace": "", "generation": 8, "feedback": "The algorithm SOMAdaptiveDE scored 0.565 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7021d3a5-2c61-4523-866a-df1937b304c3"], "operator": null, "metadata": {"aucs": [0.20576480385954843, 0.45099041202880186, 0.542218782185721, 0.8272437277639928, 0.5598899310799408, 0.6967853634993327, 0.36265509314298117, 0.5185095054672135, 0.5957434892850445, 0.31657000264637136, 0.8159662958093226, 0.9957563040356513, 0.3726797454632519, 0.5764339392343112, 0.8756606763022843, 0.6345045964473877, 0.4631379771774484, 0.7751552407441488, 0.2102519458211768, 0.4998418678056312]}}
