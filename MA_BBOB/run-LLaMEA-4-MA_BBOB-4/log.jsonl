{"id": "8c9fd49b-2fc5-473c-a19c-6a06d7f2fc91", "fitness": -Infinity, "name": "ADE_CD", "description": "Adaptive Differential Evolution with Archive and Crowding Distance for Diversity Preservation.", "code": "import numpy as np\n\nclass ADE_CD:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, archive_size=10):\n        \"\"\"\n        Adaptive Differential Evolution with Archive and Crowding Distance.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            F (float): The mutation factor.\n            Cr (float): The crossover rate.\n            archive_size (int): The size of the archive for storing promising solutions.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.archive_size = archive_size\n        self.archive = []\n        self.pop = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n        self.func_evals = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly.\"\"\"\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.func_evals += self.pop_size\n\n    def mutate(self, pop, archive):\n        \"\"\"Perform the mutation operation.\"\"\"\n        mutated_pop = np.zeros_like(pop)\n        for i in range(self.pop_size):\n            indices = np.random.choice(self.pop_size + len(archive), 3, replace=False)\n            if indices[0] < self.pop_size:\n                x_r1 = pop[indices[0]]\n            else:\n                x_r1 = archive[indices[0] - self.pop_size]\n            if indices[1] < self.pop_size:\n                x_r2 = pop[indices[1]]\n            else:\n                x_r2 = archive[indices[1] - self.pop_size]\n            if indices[2] < self.pop_size:\n                x_r3 = pop[indices[2]]\n            else:\n                x_r3 = archive[indices[2] - self.pop_size]\n            mutated_pop[i] = pop[i] + self.F * (x_r2 - x_r3)\n            mutated_pop[i] = np.clip(mutated_pop[i], self.lb, self.ub)\n        return mutated_pop\n\n    def crossover(self, pop, mutated_pop):\n        \"\"\"Perform the crossover operation.\"\"\"\n        crossed_pop = np.zeros_like(pop)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == np.random.randint(self.dim):\n                    crossed_pop[i, j] = mutated_pop[i, j]\n                else:\n                    crossed_pop[i, j] = pop[i, j]\n        return crossed_pop\n\n    def update_archive(self, pop, fitness):\n        \"\"\"Update the archive with promising solutions.\"\"\"\n        for i in range(self.pop_size):\n            if fitness[i] < np.max(self.fitness):\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(pop[i].copy())\n                else:\n                    worst_archive_index = np.argmax([np.linalg.norm(x - np.mean(self.archive, axis=0)) for x in self.archive])\n                    self.archive[worst_archive_index] = pop[i].copy()\n\n    def crowding_distance(self, pop, fitness):\n        \"\"\"Calculate the crowding distance for each solution.\"\"\"\n        distances = np.zeros(self.pop_size)\n        for m in range(self.dim):\n            sorted_indices = np.argsort(pop[:, m])\n            distances[sorted_indices[0]] = np.inf\n            distances[sorted_indices[-1]] = np.inf\n            for i in range(1, self.pop_size - 1):\n                distances[sorted_indices[i]] += (pop[sorted_indices[i+1], m] - pop[sorted_indices[i-1], m]) / (self.ub - self.lb)\n        return distances\n\n    def selection(self, pop, fitness, new_pop, new_fitness):\n        \"\"\"Perform selection based on fitness and crowding distance.\"\"\"\n        combined_pop = np.vstack((pop, new_pop))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        crowding_distances = self.crowding_distance(combined_pop, combined_fitness)\n        \n        selected_indices = []\n        for _ in range(self.pop_size):\n            best_index = -1\n            best_fitness = np.inf\n            best_crowding_distance = -np.inf\n            \n            for i in range(2 * self.pop_size):\n                if i not in selected_indices:\n                    if combined_fitness[i] < best_fitness or (combined_fitness[i] == best_fitness and crowding_distances[i] > best_crowding_distance):\n                        best_index = i\n                        best_fitness = combined_fitness[i]\n                        best_crowding_distance = crowding_distances[i]\n            selected_indices.append(best_index)\n\n        new_pop = combined_pop[selected_indices]\n        new_fitness = combined_fitness[selected_indices]\n        \n        return new_pop, new_fitness\n        \n\n    def __call__(self, func):\n        \"\"\"Optimize the given function.\"\"\"\n        self.initialize_population(func)\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.archive = []\n\n        while self.func_evals < self.budget:\n            mutated_pop = self.mutate(self.pop, self.archive)\n            crossed_pop = self.crossover(self.pop, mutated_pop)\n            new_fitness = np.array([func(x) for x in crossed_pop])\n            self.func_evals += self.pop_size\n\n            self.pop, self.fitness = self.selection(self.pop, self.fitness, crossed_pop, new_fitness)\n            self.update_archive(self.pop, self.fitness)\n\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.pop[np.argmin(self.fitness)]\n                \n            if self.func_evals >= self.budget:\n                break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occurred: index 88 is out of bounds for axis 0 with size 50.", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "ce557976-6c8e-4af2-819b-b483aa22e245", "fitness": 0.309505619018987, "name": "CMAES", "description": "Adaptive Gaussian mutation with covariance matrix adaptation for efficient exploration and exploitation.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.eigeneval = 0\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, ((self.mu-1)/(self.dim+1)) - 1) + 2\n        self.c_c = (4 + self.mu/self.dim)**(-1)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n\n        while self.evals < self.budget:\n            # Generate lambda offsprings\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.popsize)\n            x = self.m + self.sigma0 * z\n            f = np.zeros(self.popsize)\n            \n            # Check boundaries and evaluate\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], func.bounds.lb, func.bounds.ub)\n                f[i] = func(x[i])\n                self.evals += 1\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    \n                if self.evals >= self.budget:\n                    break\n            if self.evals >= self.budget:\n                break\n\n            # Selection and recombination\n            idx = np.argsort(f)\n            x_mu = x[idx[:self.mu]]\n            z_mu = z[idx[:self.mu]]\n            f_mu = f[idx[:self.mu]]\n            \n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n            \n            # Covariance matrix adaptation\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            if np.sum(self.ps**2) / self.dim > self.d_sigma**2:\n                self.sigma0 *= np.exp(0.2 + self.c_sigma / self.d_sigma)\n            else:\n                self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * ((np.sum(self.ps**2) / self.dim) - 1) / 2)\n            \n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n            \n            delta = z_mu - np.zeros(self.dim)\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * (delta[k,:][:, None] @ delta[k,:][None, :])\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CMAES scored 0.310 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.05890809269686781, 0.16073921769853916, 0.39291699674376734, 0.16281729265206546, 0.3443493960230558, 0.13610504047635807, 0.25475643501085465, 0.2811326939403297, 0.17608912137677746, 0.11759279046152538, 0.21436936706668286, 0.9994079085936346, 0.2673080265261799, 0.2163618758263548, 0.6477587368351727, 0.3058111166369958, 0.26524820654658554, 0.4555947558987191, 0.19066458540162767, 0.5421807239676447]}}
{"id": "cdafbf4e-20dd-4c13-8998-094e3f11738f", "fitness": 0.46787865493896874, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with a Population Archive and Scaling Factor Adaptation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=100):\n        \"\"\"\n        Adaptive Differential Evolution with archive and scaling factor adaptation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            archive_size (int): The size of the archive.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n        self.F_memory = [self.F] * 10  # Memory for F values\n        self.CR_memory = [self.CR] * 10 # Memory for CR values\n        self.memory_idx = 0\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.  It should accept a numpy array\n                of length `self.dim` as input and return a scalar value.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the\n                   corresponding solution vector.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = self.population[i].copy()\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size + len(self.archive), 3, replace=False)\n                \n                if indices[0] < self.pop_size:\n                    x_r1 = self.population[indices[0]]\n                else:\n                    x_r1 = self.archive[indices[0] - self.pop_size]\n                \n                if indices[1] < self.pop_size:\n                    x_r2 = self.population[indices[1]]\n                else:\n                    x_r2 = self.archive[indices[1] - self.pop_size]\n                    \n                if indices[2] < self.pop_size:\n                    x_r3 = self.population[indices[2]]\n                else:\n                    x_r3 = self.archive[indices[2] - self.pop_size]\n\n                mutant = self.population[i] + self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    # Replace and update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    self.population[i] = trial_vector\n                    fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector.copy()\n                        \n                    # Adaptive F and CR\n                    self.F = np.random.normal(0.5, 0.3)\n                    self.F = np.clip(self.F, 0.1, 1.0)\n                    self.CR = np.random.normal(0.9, 0.1)\n                    self.CR = np.clip(self.CR, 0.0, 1.0)\n                    \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.468 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.179449323321348, 0.32362445326100553, 0.4170430148714733, 0.6812949613681607, 0.42250109951350157, 0.5177097726459614, 0.334846624903291, 0.3887156071709127, 0.44745085942659335, 0.22441345884426034, 0.7044002853516196, 0.997502898872926, 0.3438086330449429, 0.38038499873800014, 0.8131530148540143, 0.5048072880195794, 0.3610784875559673, 0.644394646188807, 0.18293108019133586, 0.48806259063567237]}}
{"id": "deb1531e-1137-42b1-ba51-3cf012f24ae0", "fitness": 0.630306611186439, "name": "AdaptiveDEAR", "description": "Adaptive Differential Evolution with Archive and Restart, using a dynamically adjusted crossover rate and mutation factor, an archive of past solutions to enhance exploration, and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDEAR:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7 # Initial crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Adaptive parameter control\n                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n                # Mutation\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                if len(self.archive) > 0:\n                    use_archive = np.random.rand() < 0.1  # 10% chance to use archive\n                    if use_archive:\n                        a = np.random.choice(len(self.archive))\n                        x_archive = self.archive[a]\n                        \n                        candidates2 = list(range(self.pop_size))\n                        candidates2.remove(i)\n                        idx = np.random.choice(candidates2)\n                        x_1 = self.population[idx]\n                        \n                        idx = np.random.choice(candidates2)\n                        x_2 = self.population[idx]\n                        \n                        v = self.population[i] + self.F * (x_archive - x_1 + x_2 - self.population[i])\n                    else:\n                        np.random.shuffle(candidates)\n                        x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                        v = self.population[i] + self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n                        \n                else:\n                    np.random.shuffle(candidates)\n                    x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                    v = self.population[i] + self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    pass  # Keep the old solution\n\n                if self.evals >= self.budget:\n                    break\n            # Restart mechanism (optional)\n            if self.evals < self.budget and self.evals > self.budget*0.75 and np.std(self.fitness) < 1e-6:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDEAR scored 0.630 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.17822785485227433, 0.5297217188573426, 0.5625323930435933, 0.8400067652746613, 0.7257251545650145, 0.782838746737027, 0.4899094231206851, 0.6604565129076111, 0.7626841740306916, 0.4645645727192794, 0.8442633933212884, 0.9973221711551162, 0.3970165925947433, 0.6257163666677128, 0.8561518244899502, 0.754446255426209, 0.5728927930311023, 0.8458325230901117, 0.2157198223391511, 0.5001031655052183]}}
{"id": "5d2e691a-ebd2-44f1-b8c5-befcbfc44c31", "fitness": -Infinity, "name": "CMAES", "description": "Improved CMA-ES with eigenvalue decomposition for covariance matrix adaptation, spectral cutoff and a more robust update strategy.", "code": "import numpy as np\nfrom numpy import linalg as LA\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, cs=0.3, damps=0.3, c_mu=0.3, c_1=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.cs = cs\n        self.damps = damps\n        self.c_mu = c_mu\n        self.c_1 = c_1\n        self.evals = 0\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.damps = self.damps * max(0.3, 1 - self.dim/(1e-8 + self.budget))\n        self.c_mu = min(1 - self.c_1, self.c_mu * (self.mu / self.dim));\n        self.c_1 = min(1, self.c_1 * (self.dim / (np.linalg.norm(self.m)**2 + 1e-8))); # adaptive c_1\n\n        while self.evals < self.budget:\n            # Generate lambda offsprings\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.popsize)\n            x = self.m + self.sigma0 * z\n            f = np.zeros(self.popsize)\n            \n            # Check boundaries and evaluate\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], func.bounds.lb, func.bounds.ub)\n                f[i] = func(x[i])\n                self.evals += 1\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    \n                if self.evals >= self.budget:\n                    break\n            if self.evals >= self.budget:\n                break\n\n            # Selection and recombination\n            idx = np.argsort(f)\n            x_mu = x[idx[:self.mu]]\n            z_mu = z[idx[:self.mu]]\n            f_mu = f[idx[:self.mu]]\n            \n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n            \n            # Covariance matrix adaptation\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * zmean\n            \n            norm_ps = np.linalg.norm(self.ps)\n            self.sigma0 *= np.exp((self.cs / self.damps) * (norm_ps / self.chiN - 1))\n            \n            self.pc = (1 - self.c_1) * self.pc + np.sqrt(self.c_1 * (2 - self.c_1)) * (self.m - m_old) / self.sigma0\n\n            delta = z_mu\n            \n            C_temp = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (np.outer(self.pc, self.pc))\n            for k in range(self.mu):\n                C_temp += self.c_mu * self.weights[k] * (np.outer(delta[k], delta[k]))\n\n            # Eigenvalue decomposition and spectral cutoff\n            try:\n                D, B = LA.eigh(C_temp)\n                D = np.maximum(D, 1e-10 * np.max(D))  # Spectral cutoff\n                self.C = B @ np.diag(D) @ B.T\n            except LA.LinAlgError:\n                self.C = np.eye(self.dim)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: name 'LA' is not defined.", "error": "", "parent_ids": ["ce557976-6c8e-4af2-819b-b483aa22e245"], "operator": null, "metadata": {}}
{"id": "98e1be87-4eff-4489-836c-b6ed5ad9a161", "fitness": 0.0, "name": "AdaptiveDE_OD", "description": "Adaptive Differential Evolution with orthogonal design-based parameter control for F and CR and improved archive management.", "code": "import numpy as np\nimport scipy.stats as stats\n\nclass AdaptiveDE_OD:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=100, memory_size=10):\n        \"\"\"\n        Adaptive Differential Evolution with archive, orthogonal design for F and CR adaptation,\n        and improved archive management.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            archive_size (int): The size of the archive.\n            memory_size (int): The size of the memory for F and CR values.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n        self.F_memory = np.ones(memory_size) * self.F  # Memory for F values\n        self.CR_memory = np.ones(memory_size) * self.CR  # Memory for CR values\n        self.memory_idx = 0\n        self.success_F = []\n        self.success_CR = []\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Adaptive Differential Evolution with orthogonal design.\n\n        Args:\n            func (callable): The function to optimize.  It should accept a numpy array\n                of length `self.dim` as input and return a scalar value.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the\n                   corresponding solution vector.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = self.population[i].copy()\n\n        while self.budget > 0:\n            # Orthogonal Design for F and CR\n            OD = self.generate_orthogonal_design(2, 3)  # 2 factors (F, CR), 3 levels\n            for j in range(OD.shape[0]):  # Iterate through OD rows\n                F = self.F_memory[np.random.randint(0, len(self.F_memory))] * (0.8 + 0.4 * OD[j, 0])  # Scale F based on OD level\n                CR = self.CR_memory[np.random.randint(0, len(self.CR_memory))] * (0.8 + 0.4 * OD[j, 1]) # Scale CR based on OD level\n\n                F = np.clip(F, 0.1, 1.0)\n                CR = np.clip(CR, 0.0, 1.0)\n\n                for i in range(self.pop_size):\n                    # Mutation\n                    indices = np.random.choice(self.pop_size + len(self.archive), 3, replace=False)\n\n                    if indices[0] < self.pop_size:\n                        x_r1 = self.population[indices[0]]\n                    else:\n                        x_r1 = self.archive[indices[0] - self.pop_size]\n\n                    if indices[1] < self.pop_size:\n                        x_r2 = self.population[indices[1]]\n                    else:\n                        x_r2 = self.archive[indices[1] - self.pop_size]\n\n                    if indices[2] < self.pop_size:\n                        x_r3 = self.population[indices[2]]\n                    else:\n                        x_r3 = self.archive[indices[2] - self.pop_size]\n\n                    mutant = self.population[i] + F * (x_r1 - x_r2 + x_r3 - self.population[i])\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    crossover_mask = np.random.rand(self.dim) < CR\n                    trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                    # Evaluation\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        # Replace and update archive\n                        self.success_F.append(F)\n                        self.success_CR.append(CR)\n\n                        self.archive.append(self.population[i].copy())\n                        if len(self.archive) > self.archive_size:\n                            # Replace the worst individual in the archive\n                            archive_fitness = [func(x) for x in self.archive]\n                            worst_idx = np.argmax(archive_fitness)\n                            self.archive[worst_idx] = self.population[i].copy()\n\n                        self.population[i] = trial_vector\n                        fitness[i] = f_trial\n\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial_vector.copy()\n\n                    if self.budget <= 0:\n                        break\n                if self.budget <= 0:\n                    break\n\n            # Update memory\n            if self.success_F:\n                self.F_memory[self.memory_idx] = np.mean(self.success_F)\n                self.CR_memory[self.memory_idx] = np.mean(self.success_CR)\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_F = []\n                self.success_CR = []\n            else:\n                # If no improvement, perturb memory values\n                self.F_memory += np.random.normal(0, 0.1, size=self.memory_size)\n                self.CR_memory += np.random.normal(0, 0.1, size=self.memory_size)\n                self.F_memory = np.clip(self.F_memory, 0.1, 1.0)\n                self.CR_memory = np.clip(self.CR_memory, 0.0, 1.0)\n\n        return self.f_opt, self.x_opt\n\n    def generate_orthogonal_design(self, factors, levels):\n        \"\"\"\n        Generates an orthogonal design matrix.  Uses a fixed L9 orthogonal array.\n\n        Args:\n            factors (int): The number of factors.\n            levels (int): The number of levels.\n\n        Returns:\n            numpy.ndarray: The orthogonal design matrix.\n        \"\"\"\n        if factors == 2 and levels == 3:\n            # Fixed L9 orthogonal array\n            OD = np.array([\n                [0, 0],\n                [0, 1],\n                [0, 2],\n                [1, 0],\n                [1, 1],\n                [1, 2],\n                [2, 0],\n                [2, 1],\n                [2, 2]\n            ])\n            return OD\n        else:\n            raise ValueError(\"Only L9 orthogonal array (2 factors, 3 levels) is supported.\")", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE_OD scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cdafbf4e-20dd-4c13-8998-094e3f11738f"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "52dea1b6-1f58-41fb-a497-dcae76555632", "fitness": -Infinity, "name": "ADE_CD", "description": "Adaptive Differential Evolution with Archive and Crowding Distance, fixing index errors in selection and archive update.", "code": "import numpy as np\n\nclass ADE_CD:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, archive_size=10):\n        \"\"\"\n        Adaptive Differential Evolution with Archive and Crowding Distance.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            F (float): The mutation factor.\n            Cr (float): The crossover rate.\n            archive_size (int): The size of the archive for storing promising solutions.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.archive_size = archive_size\n        self.archive = []\n        self.pop = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n        self.func_evals = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly.\"\"\"\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.func_evals += self.pop_size\n\n    def mutate(self, pop, archive):\n        \"\"\"Perform the mutation operation.\"\"\"\n        mutated_pop = np.zeros_like(pop)\n        for i in range(self.pop_size):\n            indices = np.random.choice(self.pop_size + len(archive), 3, replace=False)\n            \n            x_r1 = pop[indices[0]] if indices[0] < self.pop_size else archive[indices[0] - self.pop_size]\n            x_r2 = pop[indices[1]] if indices[1] < self.pop_size else archive[indices[1] - self.pop_size]\n            x_r3 = pop[indices[2]] if indices[2] < self.pop_size else archive[indices[2] - self.pop_size]\n            \n            mutated_pop[i] = pop[i] + self.F * (x_r2 - x_r3)\n            mutated_pop[i] = np.clip(mutated_pop[i], self.lb, self.ub)\n        return mutated_pop\n\n    def crossover(self, pop, mutated_pop):\n        \"\"\"Perform the crossover operation.\"\"\"\n        crossed_pop = np.zeros_like(pop)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == np.random.randint(self.dim):\n                    crossed_pop[i, j] = mutated_pop[i, j]\n                else:\n                    crossed_pop[i, j] = pop[i, j]\n        return crossed_pop\n\n    def update_archive(self, pop, fitness):\n        \"\"\"Update the archive with promising solutions.\"\"\"\n        for i in range(self.pop_size):\n            if fitness[i] < np.max(self.fitness) if self.fitness.size > 0 else True:\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(pop[i].copy())\n                elif len(self.archive) > 0:  # Ensure archive is not empty before trying to replace\n                    worst_archive_index = np.argmax([np.linalg.norm(x - np.mean(self.archive, axis=0)) for x in self.archive])\n                    self.archive[worst_archive_index] = pop[i].copy()\n                else:\n                    self.archive.append(pop[i].copy())  # If archive is empty, just add the solution\n\n    def crowding_distance(self, pop, fitness):\n        \"\"\"Calculate the crowding distance for each solution.\"\"\"\n        distances = np.zeros(pop.shape[0]) # Modified to handle combined population\n        for m in range(self.dim):\n            sorted_indices = np.argsort(pop[:, m])\n            distances[sorted_indices[0]] = np.inf\n            distances[sorted_indices[-1]] = np.inf\n            for i in range(1, pop.shape[0] - 1):\n                distances[sorted_indices[i]] += (pop[sorted_indices[i+1], m] - pop[sorted_indices[i-1], m]) / (self.ub - self.lb)\n        return distances\n\n    def selection(self, pop, fitness, new_pop, new_fitness):\n        \"\"\"Perform selection based on fitness and crowding distance.\"\"\"\n        combined_pop = np.vstack((pop, new_pop))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        crowding_distances = self.crowding_distance(combined_pop, combined_fitness)\n        \n        selected_indices = []\n        for _ in range(self.pop_size):\n            best_index = -1\n            best_fitness = np.inf\n            best_crowding_distance = -np.inf\n            \n            for i in range(len(combined_pop)): # Use len(combined_pop) instead of 2 * self.pop_size\n                if i not in selected_indices:\n                    if combined_fitness[i] < best_fitness or (combined_fitness[i] == best_fitness and crowding_distances[i] > best_crowding_distance):\n                        best_index = i\n                        best_fitness = combined_fitness[i]\n                        best_crowding_distance = crowding_distances[i]\n            if best_index != -1:\n                selected_indices.append(best_index)\n            else:\n                # If no valid index is found, choose a random one\n                remaining_indices = [i for i in range(len(combined_pop)) if i not in selected_indices]\n                if remaining_indices:\n                    selected_indices.append(np.random.choice(remaining_indices))\n                else:\n                    # Handle the case where all indices are already selected (shouldn't happen, but just in case)\n                    selected_indices.append(np.random.randint(len(combined_pop)))\n\n        new_pop = combined_pop[selected_indices]\n        new_fitness = combined_fitness[selected_indices]\n        \n        return new_pop, new_fitness\n        \n\n    def __call__(self, func):\n        \"\"\"Optimize the given function.\"\"\"\n        self.initialize_population(func)\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.archive = []\n\n        while self.func_evals < self.budget:\n            mutated_pop = self.mutate(self.pop, self.archive)\n            crossed_pop = self.crossover(self.pop, mutated_pop)\n            new_fitness = np.array([func(x) for x in crossed_pop])\n            self.func_evals += self.pop_size\n\n            self.pop, self.fitness = self.selection(self.pop, self.fitness, crossed_pop, new_fitness)\n            self.update_archive(self.pop, self.fitness)\n\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.pop[np.argmin(self.fitness)]\n                \n            if self.func_evals >= self.budget:\n                break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["8c9fd49b-2fc5-473c-a19c-6a06d7f2fc91"], "operator": null, "metadata": {}}
{"id": "393917b0-21dd-42ea-9e1f-b58ebddbc121", "fitness": -Infinity, "name": "GuidedCMAES", "description": "Guided CMA-ES with orthogonal sampling and restarts based on stagnation detection.", "code": "import numpy as np\n\nclass GuidedCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, stagnation_threshold=100, restart_factor=2):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.eigeneval = 0\n        self.stagnation_threshold = stagnation_threshold\n        self.restart_factor = restart_factor\n        self.last_improvement = 0\n        self.evals = 0\n        self.restart_count = 0\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, ((self.mu-1)/(self.dim+1)) - 1) + 2\n        self.c_c = (4 + self.mu/self.dim)**(-1)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.last_improvement = 0\n        self.evals = 0\n\n        while self.evals < self.budget:\n            # Generate lambda offsprings using orthogonal sampling\n            z = self.orthogonal_sampling(self.popsize, self.dim, self.C)\n            x = self.m + self.sigma0 * z\n            f = np.zeros(self.popsize)\n\n            # Check boundaries and evaluate\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], func.bounds.lb, func.bounds.ub)\n                f[i] = func(x[i])\n                self.evals += 1\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    self.last_improvement = self.evals\n\n                if self.evals >= self.budget:\n                    break\n            if self.evals >= self.budget:\n                break\n\n            # Selection and recombination\n            idx = np.argsort(f)\n            x_mu = x[idx[:self.mu]]\n            z_mu = z[idx[:self.mu]]\n            f_mu = f[idx[:self.mu]]\n\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n\n            # Covariance matrix adaptation\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            if np.sum(self.ps**2) / self.dim > self.d_sigma**2:\n                self.sigma0 *= np.exp(0.2 + self.c_sigma / self.d_sigma)\n            else:\n                self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * ((np.sum(self.ps**2) / self.dim) - 1) / 2)\n\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n\n            delta = z_mu - np.zeros(self.dim)\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * (delta[k,:][:, None] @ delta[k,:][None, :])\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Stagnation detection and restart\n            if self.evals - self.last_improvement > self.stagnation_threshold:\n                self.restart(func)\n                self.restart_count += 1\n\n        return self.f_opt, self.x_opt\n    \n    def orthogonal_sampling(self, popsize, dim, covariance_matrix):\n        eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n        A = eigenvectors @ np.diag(np.sqrt(eigenvalues))\n        \n        z = np.random.normal(0, 1, size=(popsize, dim))\n        \n        # Apply the inverse transformation to decorrelate the samples\n        orthogonal_samples = z @ A.T\n        return orthogonal_samples\n\n    def restart(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.sigma0 *= self.restart_factor\n        self.last_improvement = self.evals", "configspace": "", "generation": 1, "feedback": "An exception occurred: Eigenvalues did not converge.", "error": "", "parent_ids": ["ce557976-6c8e-4af2-819b-b483aa22e245"], "operator": null, "metadata": {}}
{"id": "7cfd8c2d-c154-4a7b-9712-734b74d1314d", "fitness": 0.34376691200399245, "name": "SADE_NS", "description": "Self-Adaptive Differential Evolution with Neighborhood Search, dynamically adjusting mutation and crossover rates based on individual success and integrating a local neighborhood search to refine solutions.", "code": "import numpy as np\n\nclass SADE_NS:\n    def __init__(self, budget=10000, dim=10, pop_size=40, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.neighborhood_size = neighborhood_size\n        self.mutation_rates = np.full(pop_size, 0.5)  # Individual mutation rates\n        self.crossover_rates = np.full(pop_size, 0.7) # Individual crossover rates\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Get individual mutation and crossover rates\n                F = self.mutation_rates[i]\n                CR = self.crossover_rates[i]\n\n                # Mutation\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                np.random.shuffle(candidates)\n                x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                v = self.population[i] + F * (x_r1 - x_r2 + x_r3 - self.population[i])\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                # Neighborhood Search\n                best_neighbor = f_u\n                best_neighbor_solution = u\n                for _ in range(self.neighborhood_size):\n                    neighbor = u + np.random.normal(0, 0.05, size=self.dim)  # Small perturbation\n                    neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n                    f_neighbor = func(neighbor)\n                    self.evals += 1\n                    if f_neighbor < best_neighbor:\n                        best_neighbor = f_neighbor\n                        best_neighbor_solution = neighbor\n\n                if best_neighbor < self.fitness[i]:\n                    # Update individual parameters based on success\n                    if best_neighbor < f_u:\n                        self.mutation_rates[i] = np.clip(self.mutation_rates[i] * 1.1, 0.1, 1.0) # Increase mutation rate\n                        self.crossover_rates[i] = np.clip(self.crossover_rates[i] * 1.1, 0.1, 1.0) # Increase crossover rate\n                    else:\n                        self.mutation_rates[i] = np.clip(self.mutation_rates[i] * 0.9, 0.1, 1.0) # Decrease mutation rate\n                        self.crossover_rates[i] = np.clip(self.crossover_rates[i] * 0.9, 0.1, 1.0) # Decrease crossover rate\n\n                    self.population[i] = best_neighbor_solution\n                    self.fitness[i] = best_neighbor\n\n                    if best_neighbor < self.f_opt:\n                        self.f_opt = best_neighbor\n                        self.x_opt = best_neighbor_solution\n\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm SADE_NS scored 0.344 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["deb1531e-1137-42b1-ba51-3cf012f24ae0"], "operator": null, "metadata": {"aucs": [0.14919061880213724, 0.23612085697688312, 0.36519039149648846, 0.31401018434390815, 0.26590754897235425, 0.32625125130820665, 0.2813105241969691, 0.2830538714070573, 0.2629400978908748, 0.18376378357531975, 0.35123950407787374, 0.9834213291602436, 0.3176062010302668, 0.24935667004362816, 0.6964295166876775, 0.3288249704891272, 0.2861931520984883, 0.3461949765813921, 0.17369463762965986, 0.4746381533112939]}}
{"id": "3cc4d49e-9bb3-420b-90de-2a94185aaf0a", "fitness": 0.3132809182834044, "name": "SelfOrganizingScout", "description": "A self-organizing scout-based optimization algorithm that dynamically adjusts search behavior based on population diversity and individual success, incorporating local search and adaptive parameter control.", "code": "import numpy as np\n\nclass SelfOrganizingScout:\n    def __init__(self, budget=10000, dim=10, pop_size=40, scout_rate=0.1, local_search_radius=0.1, initial_inertia=0.7):\n        \"\"\"\n        Self-Organizing Scout Optimization Algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            scout_rate (float): The proportion of the population that acts as scouts.\n            local_search_radius (float): The radius for local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.scout_rate = scout_rate\n        self.local_search_radius = local_search_radius\n        self.pop = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n        self.func_evals = 0\n        self.inertia = initial_inertia  # Initial inertia weight\n        self.best_fitness_history = []\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly.\"\"\"\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.func_evals += self.pop_size\n\n    def scout_phase(self):\n        \"\"\"Perform scout-based exploration.\"\"\"\n        num_scouts = int(self.scout_rate * self.pop_size)\n        scout_indices = np.random.choice(self.pop_size, num_scouts, replace=False)\n        for i in scout_indices:\n            new_x = np.random.uniform(self.lb, self.ub, size=self.dim)\n            new_fitness = self.evaluate(new_x)\n            if new_fitness < self.fitness[i]:\n                self.pop[i] = new_x\n                self.fitness[i] = new_fitness\n\n    def local_search(self, index, func):\n        \"\"\"Perform local search around a solution.\"\"\"\n        current_x = self.pop[index].copy()\n        best_x = current_x\n        best_fitness = self.fitness[index]\n\n        for _ in range(5):  # Number of local search iterations\n            new_x = current_x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            new_x = np.clip(new_x, self.lb, self.ub)\n            new_fitness = self.evaluate(new_x)\n\n            if new_fitness < best_fitness:\n                best_fitness = new_fitness\n                best_x = new_x\n\n        return best_x, best_fitness\n\n    def evaluate(self, x, func=None):\n        \"\"\"Evaluate the function and increment the evaluation counter.\"\"\"\n        if self.func_evals < self.budget:\n            if func is None:\n                f = self.func(x)\n            else:\n                f = func(x)\n            self.func_evals += 1\n            return f\n        else:\n            return np.inf\n    \n    def update_inertia(self):\n        \"\"\"Update the inertia weight based on the progress.\"\"\"\n        if len(self.best_fitness_history) > 5:\n            if self.best_fitness_history[-1] == self.best_fitness_history[-5]:\n                self.inertia *= 0.95  # Reduce inertia if no improvement\n            else:\n                self.inertia = min(self.inertia * 1.05, 0.9)  # Increase inertia if improvement\n        self.inertia = np.clip(self.inertia, 0.4, 0.9)\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function.\"\"\"\n        self.func = func\n        self.initialize_population(func)\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n        \n        while self.func_evals < self.budget:\n            self.update_inertia()\n            # Inertia-based movement towards the best solution\n            best_index = np.argmin(self.fitness)\n            for i in range(self.pop_size):\n                if i != best_index:\n                    new_x = self.inertia * self.pop[i] + (1 - self.inertia) * self.pop[best_index] + np.random.uniform(-0.1, 0.1, self.dim) # Adding some randomness\n                    new_x = np.clip(new_x, self.lb, self.ub)\n                    new_fitness = self.evaluate(new_x)\n                    if new_fitness < self.fitness[i]:\n                        self.pop[i] = new_x\n                        self.fitness[i] = new_fitness\n            \n            # Local search\n            for i in range(self.pop_size):\n                new_x, new_fitness = self.local_search(i, func)\n                if new_fitness < self.fitness[i]:\n                    self.pop[i] = new_x\n                    self.fitness[i] = new_fitness\n\n            # Scout phase\n            self.scout_phase()\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.pop[np.argmin(self.fitness)]\n            self.best_fitness_history.append(self.f_opt)\n            \n            if self.func_evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm SelfOrganizingScout scored 0.313 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8c9fd49b-2fc5-473c-a19c-6a06d7f2fc91"], "operator": null, "metadata": {"aucs": [0.10399756661104187, 0.24734211940199424, 0.42793625069585106, 0.22638174528136057, 0.18798307775215373, 0.20727225627785917, 0.2748286559691001, 0.29326919547823627, 0.20431988976217053, 0.19286180782377227, 0.30007474133516854, 0.9976806228812953, 0.307973156511691, 0.18996412170489585, 0.3516267365759067, 0.30934792370504227, 0.33595005843331627, 0.4161740387642455, 0.19587634689145828, 0.4947580538115286]}}
{"id": "18dd39b6-2cc5-4fa9-bb8e-76266cf10846", "fitness": 0.32189107274423345, "name": "EnhancedAdaptiveDE", "description": "Enhanced Adaptive Differential Evolution with per-dimension adaptation of F and CR, combined with a successful rate adaptation and a restart mechanism.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=100, memory_size=10):\n        \"\"\"\n        Enhanced Adaptive Differential Evolution with per-dimension adaptation of F and CR,\n        combined with a successful rate adaptation and a restart mechanism.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            archive_size (int): The size of the archive.\n            memory_size (int): The size of the memory for F and CR values.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.F = np.full(dim, 0.5)  # Initial scaling factor per dimension\n        self.CR = np.full(dim, 0.9)  # Initial crossover rate per dimension\n        self.F_memory = np.zeros((memory_size, dim)) + self.F  # Memory for F values\n        self.CR_memory = np.zeros((memory_size, dim)) + self.CR  # Memory for CR values\n        self.memory_idx = 0\n        self.success_F = []\n        self.success_CR = []\n        self.success_count = 0\n        self.restart_trigger = budget // 10 # Restart every tenth of the budget\n        self.initial_budget = budget\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Enhanced Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.  It should accept a numpy array\n                of length `self.dim` as input and return a scalar value.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the\n                   corresponding solution vector.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = self.population[i].copy()\n        \n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size + len(self.archive), 3, replace=False)\n                \n                if indices[0] < self.pop_size:\n                    x_r1 = self.population[indices[0]]\n                else:\n                    x_r1 = self.archive[indices[0] - self.pop_size]\n                \n                if indices[1] < self.pop_size:\n                    x_r2 = self.population[indices[1]]\n                else:\n                    x_r2 = self.archive[indices[1] - self.pop_size]\n                    \n                if indices[2] < self.pop_size:\n                    x_r3 = self.population[indices[2]]\n                else:\n                    x_r3 = self.archive[indices[2] - self.pop_size]\n\n                mutant = self.population[i] + self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    # Replace and update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    self.success_F.append(self.F.copy())\n                    self.success_CR.append(self.CR.copy())\n                    self.success_count += 1\n\n                    self.population[i] = trial_vector\n                    fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector.copy()\n                        \n                if self.budget <= 0:\n                    break\n\n            # Adapt F and CR\n            if self.success_count > 0:\n                self.F = np.mean(np.array(self.success_F), axis=0)\n                self.CR = np.mean(np.array(self.success_CR), axis=0)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.CR = np.clip(self.CR, 0.0, 1.0)\n\n                self.success_F = []\n                self.success_CR = []\n                self.success_count = 0\n\n            else: # Exploration Phase: If no success -> Reinitialize CR and F\n                 self.F = np.random.uniform(0.1, 1.0, size=self.dim)\n                 self.CR = np.random.uniform(0.0, 1.0, size=self.dim)\n\n            # Restart mechanism\n            if self.initial_budget - self.budget > self.restart_trigger:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.archive = []\n                self.restart_trigger += self.initial_budget // 10\n\n                for i in range(self.pop_size):\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = self.population[i].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedAdaptiveDE scored 0.322 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cdafbf4e-20dd-4c13-8998-094e3f11738f"], "operator": null, "metadata": {"aucs": [0.13950101910761004, 0.21242734757739556, 0.3219899742166723, 0.23759388216879707, 0.23944815077461146, 0.2921956071989653, 0.2675974145959652, 0.2599955037487979, 0.23070905921363505, 0.17394414676130365, 0.2931967441412484, 0.9981100475876341, 0.28305667196938744, 0.25317309517584874, 0.6537442379744383, 0.3248682255614602, 0.2620948043422958, 0.3369017434601802, 0.18012611268433687, 0.47714766662408437]}}
{"id": "d9ecf32d-4eb2-438d-83de-2a7be636132a", "fitness": 0.3500513723371562, "name": "CMAES_Restart", "description": "Improved CMA-ES with dynamic population size and restarts based on stagnation detection.", "code": "import numpy as np\n\nclass CMAES_Restart:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, restart_trigger=1e-12):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize\n        self.mu = None\n        self.weights = None\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.eigeneval = 0\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.restart_trigger = restart_trigger\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n        self.initial_popsize = popsize\n        self.best_archive_f = []\n\n    def initialize(self):\n         # Adapt population size based on dimension, if not specified.\n        self.popsize = self.initial_popsize if self.initial_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, ((self.mu-1)/(self.dim+1)) - 1) + 2\n        self.c_c = (4 + self.mu/self.dim)**(-1)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        self.func = func\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initialize()\n        self.best_archive_f = []\n\n        while self.evals < self.budget:\n            # Generate lambda offsprings\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.popsize)\n            x = self.m + self.sigma0 * z\n            f = np.zeros(self.popsize)\n            \n            # Check boundaries and evaluate\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], self.func.bounds.lb, self.func.bounds.ub)\n                f[i] = func(x[i])\n                self.evals += 1\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    self.best_archive_f.append(self.f_opt)\n                    \n                if self.evals >= self.budget:\n                    break\n            if self.evals >= self.budget:\n                break\n\n            # Selection and recombination\n            idx = np.argsort(f)\n            x_mu = x[idx[:self.mu]]\n            z_mu = z[idx[:self.mu]]\n            f_mu = f[idx[:self.mu]]\n            \n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n            \n            # Covariance matrix adaptation\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            if np.sum(self.ps**2) / self.dim > self.d_sigma**2:\n                self.sigma0 *= np.exp(0.2 + self.c_sigma / self.d_sigma)\n            else:\n                self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * ((np.sum(self.ps**2) / self.dim) - 1) / 2)\n            \n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n            \n            delta = z_mu - np.zeros(self.dim)\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * (delta[k,:][:, None] @ delta[k,:][None, :])\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n            \n            #Stagnation Restart\n            if abs(self.f_opt - self.last_f_opt) < self.restart_trigger:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > 50 + 10*self.dim:  # Tunable parameter for stagnation\n                self.sigma0 *= 2 #Increase stepsize upon restart\n                self.initialize() #Restart\n            else:\n                self.last_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm CMAES_Restart scored 0.350 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ce557976-6c8e-4af2-819b-b483aa22e245"], "operator": null, "metadata": {"aucs": [0.09453421266438744, 0.17989789251133204, 0.2129906015489269, 0.15661382061288842, 0.21173728019779303, 0.9625913043494687, 0.27936730520197894, 0.6568281272485137, 0.2140811405938552, 0.12725490420059027, 0.5377820513479252, 0.9956307809423826, 0.23578815322293933, 0.20285371319711498, 0.6032072679664346, 0.3405108297066579, 0.3349036611124291, 0.16994617744788632, 0.12118012029460001, 0.3633281023750202]}}
{"id": "da3b6baf-3fda-4da9-be73-09d966fd24eb", "fitness": 0.5262523761724853, "name": "AdaptiveDEAR", "description": "Adaptive Differential Evolution with Archive and Restart, using a dynamically adjusted crossover rate and mutation factor, an archive of past solutions to enhance exploration, a restart mechanism to escape local optima, and a scaling factor to improve convergence speed.", "code": "import numpy as np\n\nclass AdaptiveDEAR:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7 # Initial crossover rate\n        self.scaling_factor = 1.0 # Scaling factor for adjusting step size\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Adaptive parameter control\n                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n                # Mutation\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                if len(self.archive) > 0:\n                    use_archive = np.random.rand() < 0.1  # 10% chance to use archive\n                    if use_archive:\n                        a = np.random.choice(len(self.archive))\n                        x_archive = self.archive[a]\n                        \n                        candidates2 = list(range(self.pop_size))\n                        candidates2.remove(i)\n                        idx = np.random.choice(candidates2)\n                        x_1 = self.population[idx]\n                        \n                        idx = np.random.choice(candidates2)\n                        x_2 = self.population[idx]\n                        \n                        v = self.population[i] + self.scaling_factor * self.F * (x_archive - x_1 + x_2 - self.population[i])\n                    else:\n                        np.random.shuffle(candidates)\n                        x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                        v = self.population[i] + self.scaling_factor * self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n                        \n                else:\n                    np.random.shuffle(candidates)\n                    x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                    v = self.population[i] + self.scaling_factor * self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    pass  # Keep the old solution\n\n                if self.evals >= self.budget:\n                    break\n            # Restart mechanism (optional)\n            if self.evals < self.budget and self.evals > self.budget*0.75 and np.std(self.fitness) < 1e-6:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size\n                self.scaling_factor = 1.0 # Reset scaling factor after restart\n            \n            # Adapt scaling factor\n            if np.std(self.fitness) > 1e-3:\n                self.scaling_factor *= 0.99 # Reduce step size when variance is high\n            else:\n                self.scaling_factor *= 1.01 # Increase step size when variance is low\n                self.scaling_factor = min(self.scaling_factor, 2.0)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDEAR scored 0.526 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["deb1531e-1137-42b1-ba51-3cf012f24ae0"], "operator": null, "metadata": {"aucs": [0.1918636213121354, 0.5358190301202009, 0.4103776592509851, 0.858334190503541, 0.5949285463963971, 0.6038310077113187, 0.32109306044510477, 0.6155229396694164, 0.5577424576944154, 0.20008338677935467, 0.6407306088668425, 0.9865502862484793, 0.3098652552722275, 0.40806167067976606, 0.8864092507236507, 0.42394555614045726, 0.4650497405597308, 0.7739248942624837, 0.24408400423826426, 0.4968303565749348]}}
{"id": "bf8a3905-ffc0-4cca-aebb-dadcb4caea1d", "fitness": 0.30031520915775756, "name": "EnhancedAdaptiveDE", "description": "Enhanced Adaptive Differential Evolution with Self-Adaptive Parameters and Velocity Clamping.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=100):\n        \"\"\"\n        Enhanced Adaptive Differential Evolution with self-adaptive parameters and velocity clamping.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            archive_size (int): The size of the archive.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n        self.F_memory = [self.F] * 10  # Memory for F values\n        self.CR_memory = [self.CR] * 10 # Memory for CR values\n        self.memory_idx = 0\n        self.velocity_clamp = 0.5  # Clamp on velocity to prevent excessive jumps\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Enhanced Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.  It should accept a numpy array\n                of length `self.dim` as input and return a scalar value.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the\n                   corresponding solution vector.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = self.population[i].copy()\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size + len(self.archive), 3, replace=False)\n                \n                if indices[0] < self.pop_size:\n                    x_r1 = self.population[indices[0]]\n                else:\n                    x_r1 = self.archive[indices[0] - self.pop_size]\n                \n                if indices[1] < self.pop_size:\n                    x_r2 = self.population[indices[1]]\n                else:\n                    x_r2 = self.archive[indices[1] - self.pop_size]\n                    \n                if indices[2] < self.pop_size:\n                    x_r3 = self.population[indices[2]]\n                else:\n                    x_r3 = self.archive[indices[2] - self.pop_size]\n\n                mutant = self.population[i] + self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n\n                # Velocity clamping\n                velocity = mutant - self.population[i]\n                norm = np.linalg.norm(velocity)\n                if norm > self.velocity_clamp:\n                    velocity = velocity / norm * self.velocity_clamp\n                    mutant = self.population[i] + velocity\n                \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    # Replace and update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    self.population[i] = trial_vector\n                    fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector.copy()\n                        \n                    # Adaptive F and CR (Self-adaptive based on success)\n                    self.F = 0.5 + 0.3 * np.random.randn()\n                    self.F = np.clip(self.F, 0.1, 1.0)\n                    self.CR = 0.9 + 0.1 * np.random.randn()\n                    self.CR = np.clip(self.CR, 0.0, 1.0)\n                    \n                else:\n                    # If trial is worse, slightly reduce F and CR\n                    self.F *= 0.95\n                    self.CR *= 0.95\n                    self.F = np.clip(self.F, 0.1, 1.0)\n                    self.CR = np.clip(self.CR, 0.0, 1.0)\n                    \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedAdaptiveDE scored 0.300 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cdafbf4e-20dd-4c13-8998-094e3f11738f"], "operator": null, "metadata": {"aucs": [0.10887887384130357, 0.2103420629678363, 0.4377130079465634, 0.1817204404128071, 0.1629891989417458, 0.18992760425396193, 0.21327473499544314, 0.19537694985822207, 0.18182459890814118, 0.15138678676749184, 0.2787918703250415, 0.9438418860841302, 0.2848040516955168, 0.2066967271673812, 0.6724301169930267, 0.3306789402925143, 0.2770913092277998, 0.3665623077202569, 0.17267555804967138, 0.43929715670629566]}}
{"id": "132f920b-8a7f-402f-837e-59eb4d4c9eae", "fitness": -Infinity, "name": "ADE_CD", "description": "Adaptive Differential Evolution with Archive, Crowding Distance, and Adaptive Population Size.", "code": "import numpy as np\n\nclass ADE_CD:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, F=0.5, Cr=0.9, archive_size=10, adaptation_rate=0.1):\n        \"\"\"\n        Adaptive Differential Evolution with Archive, Crowding Distance, and Adaptive Population Size.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size_min (int): Minimum population size.\n            pop_size_max (int): Maximum population size.\n            F (float): The mutation factor.\n            Cr (float): The crossover rate.\n            archive_size (int): The size of the archive for storing promising solutions.\n            adaptation_rate (float): Rate at which population size adapts.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with max population size\n        self.F = F\n        self.Cr = Cr\n        self.archive_size = archive_size\n        self.archive = []\n        self.pop = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n        self.func_evals = 0\n        self.adaptation_rate = adaptation_rate\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly.\"\"\"\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.func_evals += self.pop_size\n\n    def mutate(self, pop, archive):\n        \"\"\"Perform the mutation operation.\"\"\"\n        pop_size = pop.shape[0]\n        mutated_pop = np.zeros_like(pop)\n        for i in range(pop_size):\n            indices = np.random.choice(pop_size + len(archive), 3, replace=False)\n            \n            x_r1 = pop[indices[0]] if indices[0] < pop_size else archive[indices[0] - pop_size]\n            x_r2 = pop[indices[1]] if indices[1] < pop_size else archive[indices[1] - pop_size]\n            x_r3 = pop[indices[2]] if indices[2] < pop_size else archive[indices[2] - pop_size]\n            \n            mutated_pop[i] = pop[i] + self.F * (x_r2 - x_r3)\n            mutated_pop[i] = np.clip(mutated_pop[i], self.lb, self.ub)\n        return mutated_pop\n\n    def crossover(self, pop, mutated_pop):\n        \"\"\"Perform the crossover operation.\"\"\"\n        pop_size = pop.shape[0]\n        crossed_pop = np.zeros_like(pop)\n        for i in range(pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == np.random.randint(self.dim):\n                    crossed_pop[i, j] = mutated_pop[i, j]\n                else:\n                    crossed_pop[i, j] = pop[i, j]\n        return crossed_pop\n\n    def update_archive(self, pop, fitness):\n        \"\"\"Update the archive with promising solutions.\"\"\"\n        for i in range(pop.shape[0]):\n            if fitness[i] < np.max(self.fitness):\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(pop[i].copy())\n                else:\n                    if self.archive:  # Check if archive is not empty\n                        worst_archive_index = np.argmax([np.linalg.norm(x - np.mean(self.archive, axis=0)) for x in self.archive])\n                        self.archive[worst_archive_index] = pop[i].copy()\n                    else:\n                        self.archive.append(pop[i].copy())  # If archive empty, add the solution\n\n    def crowding_distance(self, pop, fitness):\n        \"\"\"Calculate the crowding distance for each solution.\"\"\"\n        pop_size = pop.shape[0]\n        distances = np.zeros(pop_size)\n        for m in range(self.dim):\n            sorted_indices = np.argsort(pop[:, m])\n            distances[sorted_indices[0]] = np.inf\n            distances[sorted_indices[-1]] = np.inf\n            for i in range(1, pop_size - 1):\n                distances[sorted_indices[i]] += (pop[sorted_indices[i+1], m] - pop[sorted_indices[i-1], m]) / (self.ub - self.lb)\n        return distances\n\n    def selection(self, pop, fitness, new_pop, new_fitness):\n        \"\"\"Perform selection based on fitness and crowding distance.\"\"\"\n        combined_pop = np.vstack((pop, new_pop))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        crowding_distances = self.crowding_distance(combined_pop, combined_fitness)\n        \n        pop_size = pop.shape[0]\n        selected_indices = []\n        for _ in range(pop_size):\n            best_index = -1\n            best_fitness = np.inf\n            best_crowding_distance = -np.inf\n            \n            for i in range(combined_pop.shape[0]):  # Iterate over the combined population\n                if i not in selected_indices:\n                    if combined_fitness[i] < best_fitness or (combined_fitness[i] == best_fitness and crowding_distances[i] > best_crowding_distance):\n                        best_index = i\n                        best_fitness = combined_fitness[i]\n                        best_crowding_distance = crowding_distances[i]\n            if best_index != -1: # Ensure a best index was found\n                selected_indices.append(best_index)\n            else:\n                # If no best index is found, which should not happen, break to prevent infinite loop\n                break\n\n        new_pop = combined_pop[selected_indices]\n        new_fitness = combined_fitness[selected_indices]\n        \n        return new_pop, new_fitness\n\n    def adapt_population_size(self):\n        \"\"\"Adapt the population size based on the improvement rate.\"\"\"\n        improvement = self.f_opt_prev - self.f_opt if hasattr(self, 'f_opt_prev') else 0\n        if improvement > 0:\n            self.pop_size = min(self.pop_size + int(self.adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        else:\n            self.pop_size = max(self.pop_size - int(self.adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n        \n        self.pop_size = int(self.pop_size)  # Ensure pop_size is an integer\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function.\"\"\"\n        self.pop_size = self.pop_size_max # Reset to initial pop size\n        self.initialize_population(func)\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.archive = []\n\n        while self.func_evals < self.budget:\n            self.f_opt_prev = self.f_opt\n            \n            mutated_pop = self.mutate(self.pop, self.archive)\n            crossed_pop = self.crossover(self.pop, mutated_pop)\n            new_fitness = np.array([func(x) for x in crossed_pop])\n            self.func_evals += crossed_pop.shape[0]\n\n            self.pop, self.fitness = self.selection(self.pop, self.fitness, crossed_pop, new_fitness)\n            self.update_archive(self.pop, self.fitness)\n            \n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.pop[np.argmin(self.fitness)]\n\n            self.adapt_population_size()\n            \n            # Resize population if necessary\n            if self.pop.shape[0] > self.pop_size:\n                 self.pop = self.pop[:self.pop_size]\n                 self.fitness = self.fitness[:self.pop_size]\n            elif self.pop.shape[0] < self.pop_size:\n                # Add random individuals to the population\n                num_to_add = self.pop_size - self.pop.shape[0]\n                new_individuals = np.random.uniform(self.lb, self.ub, size=(num_to_add, self.dim))\n                new_fitness_values = np.array([func(x) for x in new_individuals])\n                self.func_evals += num_to_add\n                self.pop = np.vstack((self.pop, new_individuals))\n                self.fitness = np.concatenate((self.fitness, new_fitness_values))\n                \n            if self.func_evals >= self.budget:\n                break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["8c9fd49b-2fc5-473c-a19c-6a06d7f2fc91"], "operator": null, "metadata": {}}
{"id": "e571713b-4165-4af7-b8b1-5a0669965dd7", "fitness": 0.5986349893678558, "name": "AdaptiveDERestart", "description": "Differential Evolution with self-adaptive parameters and a restart strategy based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveDERestart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=50, restart_patience=500):\n        \"\"\"\n        Adaptive Differential Evolution with self-adaptive parameters and restart.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            archive_size (int): The size of the archive.\n            restart_patience (int): Number of iterations without improvement before restarting.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n        self.restart_patience = restart_patience\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Adaptive Differential Evolution with restart.\n\n        Args:\n            func (callable): The function to optimize.  It should accept a numpy array\n                of length `self.dim` as input and return a scalar value.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the\n                   corresponding solution vector.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = self.population[i].copy()\n        \n        self.best_fitness_history.append(self.f_opt)\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                F = np.random.normal(0.5, 0.3)\n                F = np.clip(F, 0.1, 1.0)\n                CR = np.random.normal(0.9, 0.1)\n                CR = np.clip(CR, 0.0, 1.0)\n                \n                # Mutation\n                indices = np.random.choice(self.pop_size + len(self.archive), 3, replace=False)\n                \n                if indices[0] < self.pop_size:\n                    x_r1 = self.population[indices[0]]\n                else:\n                    x_r1 = self.archive[indices[0] - self.pop_size]\n                \n                if indices[1] < self.pop_size:\n                    x_r2 = self.population[indices[1]]\n                else:\n                    x_r2 = self.archive[indices[1] - self.pop_size]\n                    \n                if indices[2] < self.pop_size:\n                    x_r3 = self.population[indices[2]]\n                else:\n                    x_r3 = self.archive[indices[2] - self.pop_size]\n\n                mutant = self.population[i] + F * (x_r1 - x_r2 + x_r3 - self.population[i])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    # Replace and update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    self.population[i] = trial_vector\n                    fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector.copy()\n                        self.stagnation_counter = 0 # Reset stagnation counter\n                    else:\n                        self.stagnation_counter += 1\n\n            self.best_fitness_history.append(self.f_opt)\n\n            # Restart strategy\n            if self.stagnation_counter > self.restart_patience:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.f_opt = np.min(fitness)\n                self.x_opt = self.population[np.argmin(fitness)].copy()\n                self.stagnation_counter = 0\n                self.archive = []  # Clear the archive after restart\n                print(\"Restarting population\")\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDERestart scored 0.599 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cdafbf4e-20dd-4c13-8998-094e3f11738f"], "operator": null, "metadata": {"aucs": [0.19775464096762785, 0.5053288100561889, 0.48224109666576576, 0.8414918368216393, 0.5936147411139403, 0.7316130022938505, 0.43856665938996553, 0.5934872455063187, 0.6859194973645123, 0.410872565526477, 0.8244822016781903, 0.9860473912184329, 0.5625893953354321, 0.6116093431910383, 0.8754673897617995, 0.6578943872397898, 0.5021215763760982, 0.7802790329080924, 0.19788532562788508, 0.49343364831407033]}}
{"id": "de27b269-284c-44f6-ac76-770ef1cda5bf", "fitness": -Infinity, "name": "AdaptiveDEOrthogonal", "description": "Adaptive Differential Evolution with Elitism, learning rate adaptation and orthogonal crossover to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonal:\n    def __init__(self, budget=10000, dim=10, pop_size=40, elite_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.elite_size = elite_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7 # Initial crossover rate\n        self.learning_rate = 0.1 # Learning rate for parameter adaptation\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        \n        while self.evals < self.budget:\n            # Elitism: Select the top elite_size individuals\n            elite_indices = np.argsort(self.fitness)[:self.elite_size]\n            elite_population = self.population[elite_indices]\n            elite_fitness = self.fitness[elite_indices]\n\n            for i in range(self.pop_size):\n                # Adaptive parameter control with learning rate\n                dF = np.random.normal(0, 0.1)\n                dCR = np.random.normal(0, 0.05)\n                self.F = np.clip(self.F + self.learning_rate * dF, 0.1, 1.0)\n                self.CR = np.clip(self.CR + self.learning_rate * dCR, 0.1, 1.0)\n\n                # Mutation\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                np.random.shuffle(candidates)\n                x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                v = self.population[i] + self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                u = self.orthogonal_crossover(self.population[i], v)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n                if f_u < self.fitness[i]:\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    pass\n\n                if self.evals >= self.budget:\n                    break\n            \n            # Replace worst individuals with elite members\n            worst_indices = np.argsort(self.fitness)[-self.elite_size:]\n            self.population[worst_indices] = elite_population\n            self.fitness[worst_indices] = elite_fitness\n\n            # Adapt learning rate (optional): reduce if no improvement\n            if np.std(self.fitness) < 1e-6:\n                self.learning_rate *= 0.95\n            else:\n                self.learning_rate = min(0.1, self.learning_rate * 1.05)\n        return self.f_opt, self.x_opt\n\n    def orthogonal_crossover(self, x, v, num_points=3):\n        \"\"\"Performs orthogonal crossover between two vectors.\"\"\"\n        dim = len(x)\n        indices = np.random.choice(dim, size=num_points, replace=False)\n        u = x.copy()\n        for i in indices:\n            u[i] = v[i]\n        return u", "configspace": "", "generation": 2, "feedback": "An exception occurred: Cannot take a larger sample than population when 'replace=False'.", "error": "", "parent_ids": ["da3b6baf-3fda-4da9-be73-09d966fd24eb"], "operator": null, "metadata": {}}
{"id": "da1798f3-3435-4732-81a8-f2eb995977b0", "fitness": 0.0, "name": "SADE_EC", "description": "Self-Adaptive Differential Evolution with Elitism, a Cauchy mutation operator, and dynamic population sizing to balance exploration and exploitation.", "code": "import numpy as np\n\nclass SADE_EC:\n    def __init__(self, budget=10000, dim=10, pop_size_min=10, pop_size_max=100, initial_mutation_rate=0.5, initial_crossover_rate=0.7, elite_fraction=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with max pop size and reduce\n        self.mutation_rates = np.full(self.pop_size, initial_mutation_rate)\n        self.crossover_rates = np.full(self.pop_size, initial_crossover_rate)\n        self.elite_fraction = elite_fraction\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Elitism\n            elite_count = int(self.elite_fraction * self.pop_size)\n            elite_indices = np.argsort(self.fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            for i in range(self.pop_size):\n                # Get individual mutation and crossover rates\n                F = self.mutation_rates[i]\n                CR = self.crossover_rates[i]\n\n                # Mutation (Cauchy)\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                np.random.shuffle(candidates)\n                x_r1, x_r2 = self.population[candidates[0]], self.population[candidates[1]]\n                cauchy_noise = F * np.random.standard_cauchy(size=self.dim) # Cauchy mutation\n                v = self.population[i] + cauchy_noise * (x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Update individual parameters based on success\n                    self.mutation_rates[i] = np.clip(self.mutation_rates[i] * 0.9, 0.1, 1.0)\n                    self.crossover_rates[i] = np.clip(self.crossover_rates[i] * 0.9, 0.1, 1.0)\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Adjust parameters if no improvement\n                    self.mutation_rates[i] = np.clip(self.mutation_rates[i] * 1.1, 0.1, 1.0)\n                    self.crossover_rates[i] = np.clip(self.crossover_rates[i] * 1.1, 0.1, 1.0)\n\n                if self.evals >= self.budget:\n                    break\n\n            # Dynamic population size reduction\n            if self.evals > self.budget * 0.5 and self.pop_size > self.pop_size_min:\n                self.pop_size = max(self.pop_size_min, int(self.pop_size * 0.95))\n                # Resize population (keep the best)\n                sorted_indices = np.argsort(self.fitness)\n                self.population = self.population[sorted_indices[:self.pop_size]]\n                self.fitness = self.fitness[sorted_indices[:self.pop_size]]\n                self.mutation_rates = self.mutation_rates[sorted_indices[:self.pop_size]]\n                self.crossover_rates = self.crossover_rates[sorted_indices[:self.pop_size]]\n\n            # Replace worst individuals with elites\n            worst_indices = np.argsort(self.fitness)[-elite_count:]\n            self.population[worst_indices] = elite_population\n            self.fitness[worst_indices] = np.array([func(x) for x in elite_population])\n            self.evals += elite_count\n            if self.evals >= self.budget:\n                break\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm SADE_EC scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7cfd8c2d-c154-4a7b-9712-734b74d1314d"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "8d165c75-2203-4e75-b0ac-36db1a9aaf02", "fitness": 0.0, "name": "SADE_NS", "description": "Self-Adaptive Differential Evolution with adaptive population size, archive, neighborhood search and a more aggressive parameter adaptation.", "code": "import numpy as np\n\nclass SADE_NS:\n    def __init__(self, budget=10000, dim=10, pop_size=40, neighborhood_size=5, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.neighborhood_size = neighborhood_size\n        self.archive_size = archive_size\n        self.mutation_rates = np.full(pop_size, 0.5)\n        self.crossover_rates = np.full(pop_size, 0.7)\n        self.archive = []\n        self.archive_fitness = []\n        self.min_pop_size = 10\n        self.max_pop_size = 100\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Adapt population size\n            if self.evals % 1000 == 0:\n                if len(self.archive) > self.archive_size // 2:  # Successful search\n                    self.pop_size = min(self.pop_size + 5, self.max_pop_size)\n                    self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    self.fitness = np.array([func(x) for x in self.population])\n                    self.evals += self.pop_size\n                else:  # Stagnation\n                    self.pop_size = max(self.pop_size - 5, self.min_pop_size)\n                    if self.pop_size < len(self.population):\n                        indices = np.argsort(self.fitness)[:self.pop_size]\n                        self.population = self.population[indices]\n                        self.fitness = self.fitness[indices]\n                self.mutation_rates = np.full(self.pop_size, 0.5)\n                self.crossover_rates = np.full(self.pop_size, 0.7)\n\n            for i in range(self.pop_size):\n                # Get individual mutation and crossover rates\n                F = self.mutation_rates[i]\n                CR = self.crossover_rates[i]\n\n                # Mutation\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                np.random.shuffle(candidates)\n                x_r1, x_r2 = self.population[candidates[0]], self.population[candidates[1]]\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(len(self.archive))\n                    x_r3 = self.archive[arch_idx]\n                else:\n                     x_r3 = self.population[candidates[2]]\n                v = self.population[i] + F * (x_r1 - x_r2 + x_r3 - self.population[i])\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                # Neighborhood Search\n                best_neighbor = f_u\n                best_neighbor_solution = u\n                for _ in range(self.neighborhood_size):\n                    neighbor = u + np.random.normal(0, 0.05, size=self.dim)\n                    neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n                    f_neighbor = func(neighbor)\n                    self.evals += 1\n                    if f_neighbor < best_neighbor:\n                        best_neighbor = f_neighbor\n                        best_neighbor_solution = neighbor\n\n                if best_neighbor < self.fitness[i]:\n                    # Update individual parameters based on success - More aggressive\n                    if best_neighbor < f_u:\n                        self.mutation_rates[i] = np.clip(self.mutation_rates[i] * 1.2, 0.1, 1.0)\n                        self.crossover_rates[i] = np.clip(self.crossover_rates[i] * 1.2, 0.1, 1.0)\n                    else:\n                        self.mutation_rates[i] = np.clip(self.mutation_rates[i] * 0.8, 0.1, 1.0)\n                        self.crossover_rates[i] = np.clip(self.crossover_rates[i] * 0.8, 0.1, 1.0)\n\n                    self.population[i] = best_neighbor_solution\n                    self.fitness[i] = best_neighbor\n                    \n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(best_neighbor_solution)\n                        self.archive_fitness.append(best_neighbor)\n                    else:\n                        max_archive_fitness_idx = np.argmax(self.archive_fitness)\n                        if best_neighbor < self.archive_fitness[max_archive_fitness_idx]:\n                            self.archive[max_archive_fitness_idx] = best_neighbor_solution\n                            self.archive_fitness[max_archive_fitness_idx] = best_neighbor\n\n                    if best_neighbor < self.f_opt:\n                        self.f_opt = best_neighbor\n                        self.x_opt = best_neighbor_solution\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm SADE_NS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7cfd8c2d-c154-4a7b-9712-734b74d1314d"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "324b7457-0274-4cc9-807d-6c006edf128a", "fitness": 0.0, "name": "DynamicDE", "description": "Differential Evolution with a dynamically adjusted population size based on performance and a local search operator to refine solutions.", "code": "import numpy as np\n\nclass DynamicDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, local_search_probability=0.1):\n        \"\"\"\n        Differential Evolution with dynamic population size and local search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the problem.\n            initial_pop_size (int): The initial population size.\n            min_pop_size (int): The minimum population size.\n            max_pop_size (int): The maximum population size.\n            local_search_probability (float): Probability of applying local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.local_search_probability = local_search_probability\n\n    def __local_search(self, func, x, bounds, step_size=0.1):\n        \"\"\"Performs a simple local search around x.\"\"\"\n        x_new = x + np.random.uniform(-step_size, step_size, size=self.dim)\n        x_new = np.clip(x_new, bounds.lb, bounds.ub)\n        f_new = func(x_new)\n        return f_new, x_new\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with dynamic population size and local search.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the\n                   corresponding solution vector.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = self.population[i].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = self.population[i] + self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                # Local Search\n                if np.random.rand() < self.local_search_probability:\n                    f_local, trial_vector = self.__local_search(func, trial_vector, func.bounds)\n                    if f_local < f_trial:\n                        f_trial = f_local\n\n                if f_trial < fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector.copy()\n\n            self.population = new_population\n            fitness = new_fitness\n\n            # Adjust population size based on performance\n            if generation % 10 == 0:\n                improvement_ratio = np.sum(new_fitness < fitness) / self.pop_size\n                if improvement_ratio > 0.3:\n                    self.pop_size = min(self.pop_size + 5, self.max_pop_size)\n                elif improvement_ratio < 0.1:\n                    self.pop_size = max(self.pop_size - 5, self.min_pop_size)\n                \n                # Resize population\n                if self.pop_size != len(self.population):\n                    new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(abs(self.pop_size-len(self.population)), self.dim))\n                    new_fitness_values = np.array([func(x) for x in new_individuals])\n                    self.budget -= len(new_fitness_values)\n                    \n                    if self.pop_size > len(self.population): # Population increased\n                         self.population = np.vstack((self.population, new_individuals))\n                         fitness = np.concatenate((fitness, new_fitness_values))\n                    else: # Population decreased\n                         indices_to_remove = np.argsort(fitness)[-abs(self.pop_size-len(self.population)):]\n                         self.population = np.delete(self.population, indices_to_remove, axis=0)\n                         fitness = np.delete(fitness, indices_to_remove)\n                \n                for i in range(len(fitness)):\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = self.population[i].copy()\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm DynamicDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e571713b-4165-4af7-b8b1-5a0669965dd7"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "22c7828d-d127-4ead-ac07-20cae03286f2", "fitness": 0.0, "name": "ADE_ELS_DM", "description": "Adaptive Differential Evolution with Elitism, Local Search, and Diversity Maintenance, using dynamically adjusted parameters, elitism to preserve good solutions, local search to refine solutions, and a diversity maintenance strategy to prevent premature convergence.", "code": "import numpy as np\n\nclass ADE_ELS_DM:\n    def __init__(self, budget=10000, dim=10, pop_size=40, elite_count=2, local_search_iterations=3, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.elite_count = elite_count\n        self.local_search_iterations = local_search_iterations\n        self.diversity_threshold = diversity_threshold\n        self.mutation_rates = np.full(pop_size, 0.5)\n        self.crossover_rates = np.full(pop_size, 0.7)\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        # Sort population based on fitness\n        idx = np.argsort(self.fitness)\n        self.population = self.population[idx]\n        self.fitness = self.fitness[idx]\n\n        if self.fitness[0] < self.f_opt:\n            self.f_opt = self.fitness[0]\n            self.x_opt = self.population[0]\n\n        while self.evals < self.budget:\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n\n            for i in range(self.pop_size):\n                # Get individual mutation and crossover rates\n                F = self.mutation_rates[i]\n                CR = self.crossover_rates[i]\n\n                # Mutation\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                np.random.shuffle(candidates)\n                x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                v = self.population[i] + F * (x_r1 - x_r2 + x_r3 - self.population[i])\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Local Search\n                best_local_solution = u\n                best_local_fitness = func(u)\n                self.evals += 1\n\n                for _ in range(self.local_search_iterations):\n                    neighbor = u + np.random.normal(0, 0.05, size=self.dim)\n                    neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n                    f_neighbor = func(neighbor)\n                    self.evals += 1\n\n                    if f_neighbor < best_local_fitness:\n                        best_local_fitness = f_neighbor\n                        best_local_solution = neighbor\n                \n                # Selection\n                if best_local_fitness < self.fitness[i]:\n                    new_population[i] = best_local_solution\n                    new_fitness[i] = best_local_fitness\n\n                    # Update individual parameters based on success\n                    if best_local_fitness < func(u): # Original u before local search\n                        self.mutation_rates[i] = np.clip(self.mutation_rates[i] * 1.1, 0.1, 1.0)\n                        self.crossover_rates[i] = np.clip(self.crossover_rates[i] * 1.1, 0.1, 1.0)\n                    else:\n                        self.mutation_rates[i] = np.clip(self.mutation_rates[i] * 0.9, 0.1, 1.0)\n                        self.crossover_rates[i] = np.clip(self.crossover_rates[i] * 0.9, 0.1, 1.0)\n\n            # Elitism: Replace worst individuals with the best from the previous generation\n            idx = np.argsort(new_fitness)\n            new_population = new_population[idx]\n            new_fitness = new_fitness[idx]\n\n            new_population[self.pop_size-self.elite_count:] = self.population[:self.elite_count]\n            new_fitness[self.pop_size-self.elite_count:] = self.fitness[:self.elite_count]\n            \n            # Diversity Maintenance: If the population is too similar, reinitialize some individuals\n            if self.population_diversity(new_population) < self.diversity_threshold:\n                num_reinitialize = int(self.pop_size * 0.2)\n                new_population[-num_reinitialize:] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reinitialize, self.dim))\n                new_fitness[-num_reinitialize:] = [func(x) for x in new_population[-num_reinitialize:]]\n                self.evals += num_reinitialize\n                \n            idx = np.argsort(new_fitness)\n            self.population = new_population[idx]\n            self.fitness = new_fitness[idx]\n\n            if self.fitness[0] < self.f_opt:\n                self.f_opt = self.fitness[0]\n                self.x_opt = self.population[0]\n\n            if self.evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n    \n    def population_diversity(self, population):\n        \"\"\"Calculates the average Euclidean distance between all pairs of individuals.\"\"\"\n        total_distance = 0\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                total_distance += np.linalg.norm(population[i] - population[j])\n        return total_distance / (self.pop_size * (self.pop_size - 1) / 2)", "configspace": "", "generation": 2, "feedback": "The algorithm ADE_ELS_DM scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7cfd8c2d-c154-4a7b-9712-734b74d1314d"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "92acfe5e-e33c-4bf7-a8d6-303a7dce36a9", "fitness": -Infinity, "name": "CMAES_OrthogonalRestart", "description": "Covariance matrix adaptation evolution strategy with orthogonal sampling and adaptive restart.", "code": "import numpy as np\n\nclass CMAES_OrthogonalRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, restart_patience=500, orthogonal_components=5):\n        \"\"\"\n        Covariance matrix adaptation evolution strategy with orthogonal sampling and adaptive restart.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.  If None, it will be set to 4 + int(3 * np.log(dim)).\n            restart_patience (int): Number of iterations without improvement before restarting.\n            orthogonal_components (int): Number of orthogonal components used for sampling.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 4 + int(3 * np.log(dim)) if pop_size is None else pop_size\n        self.restart_patience = restart_patience\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.orthogonal_components = orthogonal_components\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using CMA-ES with orthogonal sampling and restart.\n\n        Args:\n            func (callable): The function to optimize.  It should accept a numpy array\n                of length `self.dim` as input and return a scalar value.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the\n                   corresponding solution vector.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        # Initialize mean and covariance matrix\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.sigma = 0.3 * (func.bounds.ub - func.bounds.lb)\n        self.C = np.eye(self.dim)  # Covariance matrix\n\n        # Evolution path and step size control\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.c_sigma = (self.pop_size + 2) / (self.dim + 5)\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.c_sigma * (2 - self.c_sigma)) * self.dim) - 1) + self.c_sigma\n        self.c_c = 4 / (self.dim + 4)\n        self.c_mu = 2 / (self.pop_size**2)\n        self.weights = np.log(self.pop_size + 1) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mu_eff = 1 / np.sum(self.weights**2)\n\n        while self.budget > 0:\n            # Sample population\n            Z = np.random.randn(self.dim, self.pop_size)\n            if self.orthogonal_components > 0 and self.dim > 1:\n                Q, _ = np.linalg.qr(np.random.randn(self.dim, self.orthogonal_components))\n                Z[:, :self.orthogonal_components] = Q @ np.random.randn(self.orthogonal_components, self.orthogonal_components)\n\n            x = self.mean[:, np.newaxis] + self.sigma * np.sqrt(self.C) @ Z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            x = x.T\n\n            # Evaluate fitness\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n            if self.budget <= 0:\n                break\n            \n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0].copy()\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n            self.best_fitness_history.append(self.f_opt)\n\n            # Update mean\n            y = x[:self.pop_size] - self.mean\n            self.mean = self.mean + np.sum(self.weights[:, np.newaxis] * y, axis=0)\n\n            # Update evolution paths\n            B = np.sqrt(self.C)\n            y_scaled = np.linalg.solve(B, self.mean - (self.mean - np.sum(self.weights[:, np.newaxis] * x[:self.pop_size], axis=0)))\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mu_eff) * (y_scaled / self.sigma)\n            norm_ps = np.linalg.norm(self.ps)\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c) * self.mu_eff) * y.mean(axis=0) / self.sigma\n           \n\n            # Update covariance matrix\n            rank_mu = self.c_mu * np.sum(self.weights * np.outer(self.pc, self.pc))\n            rank_one = (1 - self.c_mu) * self.c_c * (2-self.c_c) * np.outer(y_scaled, y_scaled)\n            self.C = (1 - self.c_mu) * self.C + rank_mu + rank_one\n            \n            # Step size control\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (norm_ps / self.chiN - 1))\n\n            # Restart strategy\n            if self.stagnation_counter > self.restart_patience:\n                self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.sigma = 0.3 * (func.bounds.ub - func.bounds.lb)\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.stagnation_counter = 0\n                print(\"Restarting CMA-ES population\")\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 5 is different from 2).", "error": "", "parent_ids": ["e571713b-4165-4af7-b8b1-5a0669965dd7"], "operator": null, "metadata": {}}
{"id": "0a17dbcc-ce73-4408-acb2-4682f9e33d18", "fitness": -Infinity, "name": "AdaptiveCMAES_OrthogonalRestart", "description": "Adaptive CMA-ES with orthogonal sampling, a dynamically adjusted population size based on function evaluations, and a restart strategy incorporating a memory of past best solutions.", "code": "import numpy as np\n\nclass AdaptiveCMAES_OrthogonalRestart:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, restart_trigger=1e-12, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize\n        self.mu = None\n        self.weights = None\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.eigeneval = 0\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.restart_trigger = restart_trigger\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n        self.initial_popsize = popsize\n        self.memory_size = memory_size\n        self.best_archive_f = []\n        self.best_archive_x = []\n\n    def initialize(self):\n         # Adapt population size based on dimension, if not specified.\n        self.popsize = self.initial_popsize if self.initial_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, ((self.mu-1)/(self.dim+1)) - 1) + 2\n        self.c_c = (4 + self.mu/self.dim)**(-1)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n\n    def orthogonal_sampling(self, mean, covariance, num_samples):\n        eigenvalues, eigenvectors = np.linalg.eigh(covariance)\n        eigenvalues = np.maximum(eigenvalues, 1e-10) # Ensure positive definite\n        A = eigenvectors @ np.diag(np.sqrt(eigenvalues))\n\n        z = np.random.normal(0, 1, size=(self.dim, num_samples))\n        q, r = np.linalg.qr(z) # Orthogonal basis\n        samples = mean[:, np.newaxis] + self.sigma0 * (A @ q).T\n        return samples\n\n    def __call__(self, func):\n        self.func = func\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initialize()\n        self.best_archive_f = []\n        self.best_archive_x = []\n\n        while self.evals < self.budget:\n            # Dynamically adjust population size\n            remaining_budget = self.budget - self.evals\n            self.popsize = min(self.initial_popsize if self.initial_popsize is not None else 4 + int(3 * np.log(self.dim)), remaining_budget)\n            self.mu = self.popsize // 2\n\n            # Generate lambda offsprings using orthogonal sampling\n            x = self.orthogonal_sampling(self.m, self.C, self.popsize)\n            f = np.zeros(self.popsize)\n            \n            # Check boundaries and evaluate\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], self.func.bounds.lb, self.func.bounds.ub)\n                f[i] = func(x[i])\n                self.evals += 1\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    self.best_archive_f.append(self.f_opt)\n                    self.best_archive_x.append(self.x_opt)\n\n                    if len(self.best_archive_f) > self.memory_size:\n                        self.best_archive_f.pop(0)\n                        self.best_archive_x.pop(0)\n                    \n                if self.evals >= self.budget:\n                    break\n            if self.evals >= self.budget:\n                break\n\n            # Selection and recombination\n            idx = np.argsort(f)\n            x_mu = x[idx[:self.mu]]\n            z = np.linalg.solve(np.linalg.cholesky(self.C), (x_mu - self.m).T / self.sigma0).T #Back-transform\n            z_mu = z\n            f_mu = f[idx[:self.mu]]\n            \n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n            \n            # Covariance matrix adaptation\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            if np.sum(self.ps**2) / self.dim > self.d_sigma**2:\n                self.sigma0 *= np.exp(0.2 + self.c_sigma / self.d_sigma)\n            else:\n                self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * ((np.sum(self.ps**2) / self.dim) - 1) / 2)\n            \n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n            \n            delta = z_mu - np.zeros(self.dim)\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * (delta[k,:][:, None] @ delta[k,:][None, :])\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n            \n            #Stagnation Restart\n            if abs(self.f_opt - self.last_f_opt) < self.restart_trigger:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > 50 + 10*self.dim:  # Tunable parameter for stagnation\n                self.sigma0 *= 2 #Increase stepsize upon restart\n                \n                #Restart using best from archive\n                if self.best_archive_x:\n                    best_idx = np.argmin(self.best_archive_f)\n                    self.m = self.best_archive_x[best_idx]\n                \n                self.initialize() #Restart\n            else:\n                self.last_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: index 2 is out of bounds for axis 0 with size 2.", "error": "", "parent_ids": ["d9ecf32d-4eb2-438d-83de-2a7be636132a"], "operator": null, "metadata": {}}
{"id": "fd59e792-3f87-4df8-b48f-ef9a22809a9c", "fitness": 0.3753259908198928, "name": "AdaptiveCMAES_LocalSearch", "description": "An adaptive CMA-ES variant that dynamically adjusts its parameters based on the function's landscape and employs a population-based local search to refine promising solutions.", "code": "import numpy as np\n\nclass AdaptiveCMAES_LocalSearch:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, restart_trigger=1e-12, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize\n        self.mu = None\n        self.weights = None\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.eigeneval = 0\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.restart_trigger = restart_trigger\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n        self.initial_popsize = popsize\n        self.best_archive_f = []\n        self.local_search_prob = local_search_prob  # Probability of performing local search\n\n    def initialize(self):\n         # Adapt population size based on dimension, if not specified.\n        self.popsize = self.initial_popsize if self.initial_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, ((self.mu-1)/(self.dim+1)) - 1) + 2\n        self.c_c = (4 + self.mu/self.dim)**(-1)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n\n    def local_search(self, x, func, sigma=0.1, num_steps=5):\n        \"\"\"Performs a simple local search around a given solution x.\"\"\"\n        x_current = x.copy()\n        f_current = func(x_current)\n        self.evals += 1\n\n        for _ in range(num_steps):\n            x_new = x_current + np.random.normal(0, sigma, self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.evals += 1\n\n            if f_new < f_current:\n                f_current = f_new\n                x_current = x_new\n\n            if self.evals >= self.budget:\n                break\n\n        return f_current, x_current\n\n    def __call__(self, func):\n        self.func = func\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initialize()\n        self.best_archive_f = []\n\n        while self.evals < self.budget:\n            # Generate lambda offsprings\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.popsize)\n            x = self.m + self.sigma0 * z\n            f = np.zeros(self.popsize)\n            \n            # Check boundaries and evaluate\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], self.func.bounds.lb, self.func.bounds.ub)\n                f[i] = func(x[i])\n                self.evals += 1\n\n                # Perform local search with a certain probability\n                if np.random.rand() < self.local_search_prob:\n                    f_local, x_local = self.local_search(x[i], func)\n                    if f_local < f[i]:\n                        f[i] = f_local\n                        x[i] = x_local\n                        \n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    self.best_archive_f.append(self.f_opt)\n                    \n                if self.evals >= self.budget:\n                    break\n            if self.evals >= self.budget:\n                break\n\n            # Selection and recombination\n            idx = np.argsort(f)\n            x_mu = x[idx[:self.mu]]\n            z_mu = z[idx[:self.mu]]\n            f_mu = f[idx[:self.mu]]\n            \n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n            \n            # Covariance matrix adaptation\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            if np.sum(self.ps**2) / self.dim > self.d_sigma**2:\n                self.sigma0 *= np.exp(0.2 + self.c_sigma / self.d_sigma)\n            else:\n                self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * ((np.sum(self.ps**2) / self.dim) - 1) / 2)\n            \n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n            \n            delta = z_mu - np.zeros(self.dim)\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * (delta[k,:][:, None] @ delta[k,:][None, :])\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n            \n            #Stagnation Restart\n            if abs(self.f_opt - self.last_f_opt) < self.restart_trigger:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > 50 + 10*self.dim:  # Tunable parameter for stagnation\n                self.sigma0 *= 2 #Increase stepsize upon restart\n                self.initialize() #Restart\n            else:\n                self.last_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveCMAES_LocalSearch scored 0.375 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d9ecf32d-4eb2-438d-83de-2a7be636132a"], "operator": null, "metadata": {"aucs": [0.1502907148479813, 0.2277703685635648, 0.7215320283961024, 0.258093312361228, 0.29815653168719713, 0.12016945017871461, 0.39371376624425714, 0.22207697173505847, 0.47301239341668044, 0.20425455020827799, 0.9577258019552013, 0.5152999624768051, 0.3127701209429228, 0.475047486348107, 0.9203031331636053, 0.3759440826436661, 0.2836627116421694, 0.2664728221942342, 0.2030055103222378, 0.127218097069845]}}
{"id": "a2fe65a4-98f8-45dc-9974-b73208a740d5", "fitness": 0.230385872002809, "name": "CMAES_PM_Restart", "description": "Covariance Matrix Adaptation Evolution Strategy with population-based mutation and adaptive restart mechanism using mirrored sampling.", "code": "import numpy as np\n\nclass CMAES_PM_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, cs=0.3, damps=None, restart_patience=500):\n        \"\"\"\n        Covariance Matrix Adaptation Evolution Strategy with population-based mutation and adaptive restart.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size. If None, it's set to 4 + int(3 * np.log(dim)).\n            mu (int): The number of parents. If None, it's set to pop_size // 2.\n            cs (float): Cumulation factor for step-size.\n            damps (float): Damping for step-size. If None, it's set to 1 + dim/2.\n            restart_patience (int): Number of iterations without improvement before restarting.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mu = mu if mu is not None else self.pop_size // 2\n        self.mu = int(self.mu)  # Ensure mu is an integer\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + dim/2\n        self.restart_patience = restart_patience\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        \n        self.mean = np.random.uniform(-5, 5, size=dim)  # Initialize mean\n        self.sigma = 0.5  # Initialize step-size\n        self.C = np.eye(dim)  # Initialize covariance matrix\n        self.ps = np.zeros(dim)  # Evolution path for step-size\n        self.pc = np.zeros(dim)  # Evolution path for covariance matrix\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        \n        weights = np.log(self.pop_size + 1/2) - np.log(np.arange(1, self.pop_size + 1))\n        weights = weights / np.sum(weights)\n        self.weights = weights\n        \n        self.mueff = np.sum(weights)**2 / np.sum(weights**2)\n\n        self.c_cov = (1 / (self.mueff * (dim+1.3)**2 + self.mueff + 1.3))\n        self.c_mu = min(1 - self.c_cov, (2 * (self.mueff - 2 + 1/self.mueff)) / ((dim + 2)**2 + self.mueff))\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using CMA-ES with Population-Based Mutation and Adaptive Restart.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the\n                   corresponding solution vector.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        while self.budget > 0:\n            # Generate and evaluate offspring\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            y = self.sigma * z\n            x = self.mean + y\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            if self.budget <= 0:\n                break\n\n            # Sort offspring by fitness\n            indices = np.argsort(fitness)\n            x = x[indices]\n            fitness = fitness[indices]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0].copy()\n                self.stagnation_counter = 0  # Reset stagnation counter\n            else:\n                self.stagnation_counter += 1\n            \n            self.best_fitness_history.append(self.f_opt)\n\n            # Update distribution parameters\n            xmean = np.sum(self.weights[:self.mu, None] * x[:self.mu], axis=0)\n            \n            self.ps = (1 - self.cs) * self.ps + (self.cs**0.5) * (self.mueff**0.5) * (xmean - self.mean) / self.sigma\n            self.pc = (1 - self.c_cov) * self.pc + (self.c_cov**0.5) * (self.mueff**0.5) * (xmean - self.mean) / self.sigma / np.diag(self.C)**0.5\n            \n            self.mean = xmean\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps)/self.chiN - 1))\n            \n            delta = (x[:self.mu] - self.mean) / self.sigma\n            self.C = (1 - self.c_mu - self.c_cov) * self.C + \\\n                     self.c_mu * np.sum(self.weights[:self.mu, None, None] * delta[:, :, None] * delta[:, None, :], axis=0) + \\\n                     self.c_cov * self.pc[:, None] * self.pc[None, :]\n\n            # Ensure that C remains positive definite\n            try:\n                self.C = np.triu(self.C) + np.triu(self.C, 1).T\n                self.C[np.diag_indices_from(self.C)] = np.maximum(0, self.C[np.diag_indices_from(self.C)])\n                _ = np.linalg.cholesky(self.C)  # Check if C is positive definite\n\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)  # Reset covariance matrix if it's not positive definite\n                self.pc = np.zeros(self.dim)  # Reset evolution path\n\n            # Restart strategy\n            if self.stagnation_counter > self.restart_patience:\n                self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.sigma = 0.5\n                self.C = np.eye(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.stagnation_counter = 0\n                print(\"Restarting population\")\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm CMAES_PM_Restart scored 0.230 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e571713b-4165-4af7-b8b1-5a0669965dd7"], "operator": null, "metadata": {"aucs": [0.10779544834009469, 0.17722859802850266, 0.3098060312069203, 0.18384312534005098, 0.16488641835700069, 0.17569905891185533, 0.21879361022354993, 0.18377483851052734, 0.17062979568147874, 0.17735953465492316, 0.20088069515415097, 0.6752736843913718, 0.25171425282154647, 0.18177515189991778, 0.16669382335791738, 0.2659774024307616, 0.21529864041930302, 0.18409470732805167, 0.1524092445766706, 0.44378337842158466]}}
{"id": "e8ebf76a-b5c4-411a-81da-7e2a0205d397", "fitness": 0.4102224877000338, "name": "AdaptiveDEEAR", "description": "Adaptive Differential Evolution with Elitism, Archive, and Focused Exploration using a learning rate to refine the step size based on success.", "code": "import numpy as np\n\nclass AdaptiveDEEAR:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7  # Initial crossover rate\n        self.learning_rate = learning_rate # Learning rate for scaling factor\n        self.scaling_factor = 1.0  # Initial scaling factor for adjusting step size\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Adaptive parameter control\n                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n                # Mutation\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                if len(self.archive) > 0:\n                    use_archive = np.random.rand() < 0.1  # 10% chance to use archive\n                    if use_archive:\n                        a = np.random.choice(len(self.archive))\n                        x_archive = self.archive[a]\n                        \n                        candidates2 = list(range(self.pop_size))\n                        candidates2.remove(i)\n                        idx = np.random.choice(candidates2)\n                        x_1 = self.population[idx]\n                        \n                        idx = np.random.choice(candidates2)\n                        x_2 = self.population[idx]\n                        \n                        v = self.population[i] + self.scaling_factor * self.F * (x_archive - x_1 + x_2 - self.population[i])\n                    else:\n                        np.random.shuffle(candidates)\n                        x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                        v = self.population[i] + self.scaling_factor * self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                    v = self.population[i] + self.scaling_factor * self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    # Update population\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    # Update scaling factor (success)\n                    self.scaling_factor *= (1 - self.learning_rate + self.learning_rate * (f_u / self.fitness[i]))\n                    self.scaling_factor = min(self.scaling_factor, 2.0)\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Update scaling factor (failure)\n                    self.scaling_factor *= (1 + self.learning_rate * (self.fitness[i] / f_u))\n                    self.scaling_factor = max(self.scaling_factor, 0.5)\n\n\n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Restart mechanism (optional)\n            if self.evals < self.budget and self.evals > self.budget*0.75 and np.std(self.fitness) < 1e-6:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size\n                self.scaling_factor = 1.0  # Reset scaling factor after restart\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDEEAR scored 0.410 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["da3b6baf-3fda-4da9-be73-09d966fd24eb"], "operator": null, "metadata": {"aucs": [0.1280958547908635, 0.19415105352442452, 0.2717283479835765, 0.7480930266638154, 0.26985380397331693, 0.598977740770162, 0.3067265248774743, 0.4153805780772374, 0.25691345798782605, 0.18445880368766332, 0.3215658770270532, 0.9977688014000361, 0.35351061785286875, 0.2884143385255701, 0.7931656302405288, 0.4265176648270663, 0.28091942832233796, 0.7100200790026396, 0.17546298105094793, 0.48272514341526906]}}
{"id": "5299408d-7c42-4be7-b2f1-9c02fad34b2a", "fitness": -Infinity, "name": "CooperativePSO", "description": "Cooperative Enhanced Particle Swarm Optimization with dynamic sub-swarm topologies and adaptive parameter control to improve exploration and exploitation.", "code": "import numpy as np\n\nclass CooperativePSO:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.particles = []\n        self.velocities = []\n        self.personal_best_positions = []\n        self.personal_best_fitnesses = []\n        self.global_best_position = None\n        self.global_best_fitness = np.Inf\n        self.evals = 0\n        self.subswarm_topology = []\n\n    def initialize(self, func):\n        # Initialize swarms\n        for i in range(self.num_swarms):\n            particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n            velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim)) * (func.bounds.ub - func.bounds.lb) * 0.1  # Initialize velocities within a reasonable range\n            personal_best_positions = particles.copy()\n            personal_best_fitnesses = np.array([func(p) for p in particles])\n            self.evals += self.swarm_size\n            \n            self.particles.append(particles)\n            self.velocities.append(velocities)\n            self.personal_best_positions.append(personal_best_positions)\n            self.personal_best_fitnesses.append(personal_best_fitnesses)\n            \n            # Update global best\n            best_index = np.argmin(personal_best_fitnesses)\n            if personal_best_fitnesses[best_index] < self.global_best_fitness:\n                self.global_best_fitness = personal_best_fitnesses[best_index]\n                self.global_best_position = personal_best_positions[best_index].copy()\n        \n        #Initialize subswarm topology, initially fully connected\n        for i in range(self.num_swarms):\n            self.subswarm_topology.append(list(range(self.num_swarms)))\n            self.subswarm_topology[i].remove(i) #remove self from neighborhood\n\n    def update_velocity(self, swarm_index, particle_index, w, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        \n        #Get neighbor best (best from all other swarms)\n        neighbor_best_fitness = np.Inf\n        neighbor_best_position = None\n        \n        for neighbor_index in self.subswarm_topology[swarm_index]:\n            best_index_neighbor = np.argmin(self.personal_best_fitnesses[neighbor_index])\n            if self.personal_best_fitnesses[neighbor_index][best_index_neighbor] < neighbor_best_fitness:\n                neighbor_best_fitness = self.personal_best_fitnesses[neighbor_index][best_index_neighbor]\n                neighbor_best_position = self.personal_best_positions[neighbor_index][best_index_neighbor]\n        \n        self.velocities[swarm_index][particle_index] = (w * self.velocities[swarm_index][particle_index]\n                                           + self.c1 * r1 * (self.personal_best_positions[swarm_index][particle_index] - self.particles[swarm_index][particle_index])\n                                           + self.c2 * r2 * (neighbor_best_position - self.particles[swarm_index][particle_index]))\n\n    def update_position(self, swarm_index, particle_index, func):\n        new_position = self.particles[swarm_index][particle_index] + self.velocities[swarm_index][particle_index]\n        new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        fitness = func(new_position)\n        self.evals += 1\n\n        if fitness < self.personal_best_fitnesses[swarm_index][particle_index]:\n            self.personal_best_fitnesses[swarm_index][particle_index] = fitness\n            self.personal_best_positions[swarm_index][particle_index] = new_position.copy()\n\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best_position = new_position.copy()\n\n        self.particles[swarm_index][particle_index] = new_position\n\n    def adapt_topology(self):\n        # Adapt subswarm topology. For example, randomly change some connections\n        for i in range(self.num_swarms):\n            if np.random.rand() < 0.1: #10% chance to change topology\n                #Randomly add or remove a neighbor\n                if np.random.rand() < 0.5: #Add neighbor\n                    possible_neighbors = list(range(self.num_swarms))\n                    possible_neighbors.remove(i)\n                    for existing_neighbor in self.subswarm_topology[i]:\n                        if existing_neighbor in possible_neighbors:\n                            possible_neighbors.remove(existing_neighbor)\n                    if len(possible_neighbors) > 0:\n                        new_neighbor = np.random.choice(possible_neighbors)\n                        self.subswarm_topology[i].append(new_neighbor)\n                else: #remove neighbor\n                    if len(self.subswarm_topology[i]) > 0:\n                        removed_neighbor = np.random.choice(self.subswarm_topology[i])\n                        self.subswarm_topology[i].remove(removed_neighbor)\n                        \n    def __call__(self, func):\n        self.initialize(func)\n        \n        iteration = 0\n        while self.evals < self.budget:\n            # Inertia weight adaptation\n            w = self.w_start - (self.w_start - self.w_end) * (self.evals / self.budget)\n\n            for i in range(self.num_swarms):\n                for j in range(self.swarm_size):\n                    self.update_velocity(i, j, w, func)\n                    self.update_position(i, j, func)\n            \n            self.adapt_topology() #Adapt swarm topology\n            iteration += 1\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 2, "feedback": "An exception occurred: unsupported operand type(s) for -: 'NoneType' and 'float'.", "error": "", "parent_ids": ["d9ecf32d-4eb2-438d-83de-2a7be636132a"], "operator": null, "metadata": {}}
{"id": "949997ff-df2b-40ad-aa30-7d01fa9a774f", "fitness": 0.42945067340920673, "name": "CMAES_Restart", "description": "Modified CMA-ES with adaptive population sizing, covariance matrix regularization, and a more aggressive restart strategy based on performance stagnation, using a shorter stagnation window to encourage restarts in complex landscapes.", "code": "import numpy as np\n\nclass CMAES_Restart:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, restart_trigger=1e-12):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize\n        self.mu = None\n        self.weights = None\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.eigeneval = 0\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.restart_trigger = restart_trigger\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n        self.initial_popsize = popsize\n        self.best_archive_f = []\n\n    def initialize(self):\n         # Adapt population size based on dimension, if not specified.\n        self.popsize = self.initial_popsize if self.initial_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, ((self.mu-1)/(self.dim+1)) - 1) + 2\n        self.c_c = (4 + self.mu/self.dim)**(-1)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        self.func = func\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initialize()\n        self.best_archive_f = []\n\n        while self.evals < self.budget:\n            # Generate lambda offsprings\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.popsize)\n            x = self.m + self.sigma0 * z\n            f = np.zeros(self.popsize)\n            \n            # Check boundaries and evaluate\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], self.func.bounds.lb, self.func.bounds.ub)\n                f[i] = func(x[i])\n                self.evals += 1\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    self.best_archive_f.append(self.f_opt)\n                    \n                if self.evals >= self.budget:\n                    break\n            if self.evals >= self.budget:\n                break\n\n            # Selection and recombination\n            idx = np.argsort(f)\n            x_mu = x[idx[:self.mu]]\n            z_mu = z[idx[:self.mu]]\n            f_mu = f[idx[:self.mu]]\n            \n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n            \n            # Covariance matrix adaptation\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            if np.sum(self.ps**2) / self.dim > self.d_sigma**2:\n                self.sigma0 *= np.exp(0.2 + self.c_sigma / self.d_sigma)\n            else:\n                self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * ((np.sum(self.ps**2) / self.dim) - 1) / 2)\n            \n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n            \n            delta = z_mu - np.zeros(self.dim)\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * (delta[k,:][:, None] @ delta[k,:][None, :])\n\n            # Regularize covariance matrix\n            min_eig = np.min(np.linalg.eigvalsh(self.C))\n            if min_eig < 0:\n                self.C += (abs(min_eig) + 1e-10) * np.eye(self.dim)\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n            \n            #Stagnation Restart\n            if abs(self.f_opt - self.last_f_opt) < self.restart_trigger:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > 20 + 5*self.dim:  # Tunable parameter for stagnation, reduced for more aggressive restarts\n                self.sigma0 *= 2 #Increase stepsize upon restart\n                self.popsize = min(self.popsize * 2, 20 + int(6 * np.log(self.dim))) # Adapt population size\n                self.initialize() #Restart\n            else:\n                self.last_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm CMAES_Restart scored 0.429 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d9ecf32d-4eb2-438d-83de-2a7be636132a"], "operator": null, "metadata": {"aucs": [0.050695307349244656, 0.16854883569387769, 0.28772467597120166, 0.638731118413056, 0.9612279386407941, 0.9677155238795684, 0.22276760232339565, 0.27389548591688495, 0.18159632525905478, 0.13729462258354141, 0.7464637465713779, 0.980487113964522, 0.3413034505079884, 0.28909584030553304, 0.7161150178002615, 0.31528650326663843, 0.35399535560838347, 0.5237736659144077, 0.14305753486364936, 0.2892378033507539]}}
{"id": "509ddd2c-1ce1-40b5-97d7-fda944907704", "fitness": -Infinity, "name": "AdaptiveCMAES", "description": "Adaptive CMA-ES with orthogonal sampling and a more refined restart strategy, including population shrinking and localized restarts.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, restart_trigger=1e-12):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize\n        self.mu = None\n        self.weights = None\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.eigeneval = 0\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.restart_trigger = restart_trigger\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n        self.initial_popsize = popsize\n        self.archive_f = []\n        self.archive_x = []\n        self.population_shrinkage_factor = 0.75\n\n    def initialize(self):\n        self.popsize = self.initial_popsize if self.initial_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, ((self.mu-1)/(self.dim+1)) - 1) + 2\n        self.c_c = (4 + self.mu/self.dim)**(-1)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n\n    def generate_orthogonal_sample(self, num_samples):\n        H = np.random.randn(self.dim, self.dim)\n        Q, _ = np.linalg.qr(H)\n        z = np.random.normal(0, 1, size=(num_samples, self.dim))\n        return Q @ z[:self.dim, :] if num_samples > self.dim else z[:num_samples]\n\n    def __call__(self, func):\n        self.func = func\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initialize()\n        self.archive_f = []\n        self.archive_x = []\n\n        while self.evals < self.budget:\n            # Generate lambda offsprings using orthogonal sampling\n            z = self.generate_orthogonal_sample(self.popsize).T\n            x = self.m + self.sigma0 * z\n            f = np.zeros(self.popsize)\n\n            # Check boundaries and evaluate\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], self.func.bounds.lb, self.func.bounds.ub)\n                f[i] = func(x[i])\n                self.evals += 1\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    self.archive_f.append(self.f_opt)\n                    self.archive_x.append(self.x_opt)\n\n                if self.evals >= self.budget:\n                    break\n            if self.evals >= self.budget:\n                break\n\n            # Selection and recombination\n            idx = np.argsort(f)\n            x_mu = x[idx[:self.mu]]\n            z_mu = z[idx[:self.mu]]\n            f_mu = f[idx[:self.mu]]\n\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n\n            # Covariance matrix adaptation\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            if np.sum(self.ps**2) / self.dim > self.d_sigma**2:\n                self.sigma0 *= np.exp(0.2 + self.c_sigma / self.d_sigma)\n            else:\n                self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * ((np.sum(self.ps**2) / self.dim) - 1) / 2)\n\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n\n            delta = z_mu - np.zeros(self.dim)\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * (delta[k,:][:, None] @ delta[k,:][None, :])\n\n            # Regularize covariance matrix\n            min_eig = np.min(np.linalg.eigvalsh(self.C))\n            if min_eig < 0:\n                self.C += (abs(min_eig) + 1e-10) * np.eye(self.dim)\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Stagnation Restart with Population Shrinkage and Localized Restart\n            if abs(self.f_opt - self.last_f_opt) < self.restart_trigger:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > 20 + 5*self.dim:\n                # Localized Restart: Restart around the best solution in archive\n                if len(self.archive_x) > 0:\n                    best_idx = np.argmin(self.archive_f)\n                    self.m = self.archive_x[best_idx] + np.random.normal(0, self.sigma0, self.dim) # Restart around best solution\n                    self.m = np.clip(self.m, self.func.bounds.lb, self.func.bounds.ub)\n\n                self.sigma0 *= 1.5  # Adjust step size\n                self.popsize = int(self.popsize * self.population_shrinkage_factor) # Shrink the population\n                self.popsize = max(4 + int(3 * np.log(self.dim)), self.popsize) # Ensure minimum popsize\n                self.initialize()  # Reinitialize with the adapted parameters\n\n            else:\n                self.last_f_opt = self.f_opt\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occurred: index 2 is out of bounds for axis 0 with size 2.", "error": "", "parent_ids": ["949997ff-df2b-40ad-aa30-7d01fa9a774f"], "operator": null, "metadata": {}}
{"id": "23924cfa-16fa-468d-85ff-68dd3162307e", "fitness": -Infinity, "name": "AdaptiveCMAES_Orthogonal", "description": "Adaptive CMA-ES with orthogonal sampling and dynamic parameter adaptation using a success history archive to refine the search strategy.", "code": "import numpy as np\n\nclass AdaptiveCMAES_Orthogonal:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, cs=0.3, damps=None, restart_patience=500, archive_size=100):\n        \"\"\"\n        Adaptive CMA-ES with orthogonal sampling and dynamic parameter adaptation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size. If None, it's set to 4 + int(3 * np.log(dim)).\n            mu (int): The number of parents. If None, it's set to pop_size // 2.\n            cs (float): Cumulation factor for step-size.\n            damps (float): Damping for step-size. If None, it's set to 1 + dim/2.\n            restart_patience (int): Number of iterations without improvement before restarting.\n            archive_size (int): Size of the success history archive.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mu = mu if mu is not None else self.pop_size // 2\n        self.mu = int(self.mu)  # Ensure mu is an integer\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + dim/2\n        self.restart_patience = restart_patience\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.archive_size = archive_size\n        self.archive_x = []\n        self.archive_f = []\n        \n        self.mean = np.random.uniform(-5, 5, size=dim)  # Initialize mean\n        self.sigma = 0.5  # Initialize step-size\n        self.C = np.eye(dim)  # Initialize covariance matrix\n        self.ps = np.zeros(dim)  # Evolution path for step-size\n        self.pc = np.zeros(dim)  # Evolution path for covariance matrix\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        \n        weights = np.log(self.pop_size + 1/2) - np.log(np.arange(1, self.pop_size + 1))\n        weights = weights / np.sum(weights)\n        self.weights = weights\n        \n        self.mueff = np.sum(weights)**2 / np.sum(weights**2)\n\n        self.c_cov = (1 / (self.mueff * (dim+1.3)**2 + self.mueff + 1.3))\n        self.c_mu = min(1 - self.c_cov, (2 * (self.mueff - 2 + 1/self.mueff)) / ((dim + 2)**2 + self.mueff))\n        self.c_sigma_adapt = 0.5  # Learning rate for sigma adaptation\n        self.damps_adapt = 0.1   # Learning rate for damping adaptation\n\n    def orthogonal_sampling(self, num_samples, dim):\n        \"\"\"Generate orthogonal samples using Latin Hypercube Sampling.\"\"\"\n        points = np.zeros((num_samples, dim))\n        for j in range(dim):\n            permutation = np.random.permutation(num_samples)\n            points[:, j] = (permutation + np.random.rand(num_samples)) / num_samples\n        return points\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using CMA-ES with Orthogonal Sampling and Adaptive Parameter Control.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the\n                   corresponding solution vector.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        while self.budget > 0:\n            # Generate and evaluate offspring\n            orthogonal_samples = self.orthogonal_sampling(self.pop_size, self.dim)\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            y = self.sigma * z\n            \n            # Combine orthogonal sampling with CMA-ES sampling\n            x = self.mean + y * orthogonal_samples \n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            if self.budget <= 0:\n                break\n\n            # Sort offspring by fitness\n            indices = np.argsort(fitness)\n            x = x[indices]\n            fitness = fitness[indices]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0].copy()\n                self.stagnation_counter = 0  # Reset stagnation counter\n            else:\n                self.stagnation_counter += 1\n            \n            self.best_fitness_history.append(self.f_opt)\n\n            # Archive the best solution\n            if len(self.archive_x) < self.archive_size:\n                self.archive_x.append(self.x_opt)\n                self.archive_f.append(self.f_opt)\n            else:\n                # Replace worst element in archive\n                max_archive_index = np.argmax(self.archive_f)\n                if self.f_opt < self.archive_f[max_archive_index]:\n                    self.archive_x[max_archive_index] = self.x_opt\n                    self.archive_f[max_archive_index] = self.f_opt\n\n            # Update distribution parameters\n            xmean = np.sum(self.weights[:self.mu, None] * x[:self.mu], axis=0)\n            \n            self.ps = (1 - self.cs) * self.ps + (self.cs**0.5) * (self.mueff**0.5) * (xmean - self.mean) / self.sigma\n            self.pc = (1 - self.c_cov) * self.pc + (self.c_cov**0.5) * (self.mueff**0.5) * (xmean - self.mean) / self.sigma / np.diag(self.C)**0.5\n            \n            self.mean = xmean\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps)/self.chiN - 1))\n\n            # Adaptive sigma learning\n            success_rate = np.mean(fitness[:self.mu] < np.array(self.archive_f)) if self.archive_f else 0.5  # Default to 0.5 if archive is empty\n\n            self.sigma *= np.exp(self.c_sigma_adapt * (success_rate - 0.2))\n            self.damps *= np.exp(self.damps_adapt * (success_rate - 0.2))\n            \n            delta = (x[:self.mu] - self.mean) / self.sigma\n            self.C = (1 - self.c_mu - self.c_cov) * self.C + \\\n                     self.c_mu * np.sum(self.weights[:self.mu, None, None] * delta[:, :, None] * delta[:, None, :], axis=0) + \\\n                     self.c_cov * self.pc[:, None] * self.pc[None, :]\n\n            # Ensure that C remains positive definite\n            try:\n                self.C = np.triu(self.C) + np.triu(self.C, 1).T\n                self.C[np.diag_indices_from(self.C)] = np.maximum(0, self.C[np.diag_indices_from(self.C)])\n                _ = np.linalg.cholesky(self.C)  # Check if C is positive definite\n\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)  # Reset covariance matrix if it's not positive definite\n                self.pc = np.zeros(self.dim)  # Reset evolution path\n\n            # Restart strategy\n            if self.stagnation_counter > self.restart_patience:\n                self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.sigma = 0.5\n                self.C = np.eye(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.stagnation_counter = 0\n                print(\"Restarting population\")\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occurred: operands could not be broadcast together with shapes (3,) (2,) .", "error": "", "parent_ids": ["a2fe65a4-98f8-45dc-9974-b73208a740d5"], "operator": null, "metadata": {}}
{"id": "aab22319-5234-4ba2-bc7f-f73907c56481", "fitness": -Infinity, "name": "AdaptiveCMAES_OrthogonalLocalSearch", "description": "Adaptive CMA-ES with a modified population-based local search, using orthogonal sampling for exploration around elite solutions and adaptive population sizing based on the function's landscape.", "code": "import numpy as np\n\nclass AdaptiveCMAES_OrthogonalLocalSearch:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, restart_trigger=1e-12, local_search_prob=0.1, orthogonal_samples=5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize\n        self.mu = None\n        self.weights = None\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.eigeneval = 0\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.restart_trigger = restart_trigger\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n        self.initial_popsize = popsize\n        self.best_archive_f = []\n        self.local_search_prob = local_search_prob  # Probability of performing local search\n        self.orthogonal_samples = orthogonal_samples #Number of orthogonal samples for local search\n        self.adaptive_popsize = True #Adapt population size\n\n    def initialize(self):\n         # Adapt population size based on dimension, if not specified.\n        self.popsize = self.initial_popsize if self.initial_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, ((self.mu-1)/(self.dim+1)) - 1) + 2\n        self.c_c = (4 + self.mu/self.dim)**(-1)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n\n    def orthogonal_sampling(self, x, sigma, num_samples):\n        \"\"\"Generates orthogonal samples around a point x.\"\"\"\n        H = np.random.randn(self.dim, self.dim)\n        Q, _ = np.linalg.qr(H)\n        samples = x + sigma * Q[:, :num_samples]\n        return samples\n\n    def local_search(self, x, func, sigma=0.1):\n        \"\"\"Performs orthogonal local search around a given solution x.\"\"\"\n        samples = self.orthogonal_sampling(x, sigma, self.orthogonal_samples)\n        \n        f_vals = np.zeros(self.orthogonal_samples)\n        for i in range(self.orthogonal_samples):\n            samples[i] = np.clip(samples[i], func.bounds.lb, func.bounds.ub)\n            f_vals[i] = func(samples[i])\n            self.evals += 1\n        \n        best_idx = np.argmin(f_vals)\n        if f_vals[best_idx] < func(x):\n            return f_vals[best_idx], samples[best_idx].copy()\n        else:\n            fx = func(x)\n            self.evals += 1\n            return fx, x.copy()\n\n    def __call__(self, func):\n        self.func = func\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initialize()\n        self.best_archive_f = []\n\n        while self.evals < self.budget:\n            # Generate lambda offsprings\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.popsize)\n            x = self.m + self.sigma0 * z\n            f = np.zeros(self.popsize)\n            \n            # Check boundaries and evaluate\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], self.func.bounds.lb, self.func.bounds.ub)\n                f[i] = func(x[i])\n                self.evals += 1\n\n                # Perform local search with a certain probability\n                if np.random.rand() < self.local_search_prob:\n                    f_local, x_local = self.local_search(x[i], func)\n                    if f_local < f[i]:\n                        f[i] = f_local\n                        x[i] = x_local\n                        \n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    self.best_archive_f.append(self.f_opt)\n                    \n                if self.evals >= self.budget:\n                    break\n            if self.evals >= self.budget:\n                break\n\n            # Selection and recombination\n            idx = np.argsort(f)\n            x_mu = x[idx[:self.mu]]\n            z_mu = z[idx[:self.mu]]\n            f_mu = f[idx[:self.mu]]\n            \n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n            \n            # Covariance matrix adaptation\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            if np.sum(self.ps**2) / self.dim > self.d_sigma**2:\n                self.sigma0 *= np.exp(0.2 + self.c_sigma / self.d_sigma)\n            else:\n                self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * ((np.sum(self.ps**2) / self.dim) - 1) / 2)\n            \n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n            \n            delta = z_mu - np.zeros(self.dim)\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * (delta[k,:][:, None] @ delta[k,:][None, :])\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n            \n            #Stagnation Restart\n            if abs(self.f_opt - self.last_f_opt) < self.restart_trigger:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > 50 + 10*self.dim:  # Tunable parameter for stagnation\n                self.sigma0 *= 2 #Increase stepsize upon restart\n                if self.adaptive_popsize:\n                    self.popsize = min(self.popsize * 2, 100)\n                    self.mu = self.popsize // 2\n                self.initialize() #Restart\n            else:\n                self.last_f_opt = self.f_opt\n                if self.adaptive_popsize and self.stagnation_counter > 20:\n                    self.popsize = max(4 + int(3 * np.log(self.dim)), self.popsize // 2)\n                    self.mu = self.popsize // 2\n                    self.initialize()\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occurred: index 2 is out of bounds for axis 0 with size 2.", "error": "", "parent_ids": ["fd59e792-3f87-4df8-b48f-ef9a22809a9c"], "operator": null, "metadata": {}}
{"id": "9fd29017-169c-42c3-ac6f-0881f98486a4", "fitness": 0.0, "name": "AdaptiveCMAES_Orthogonal", "description": "Adaptive CMA-ES with orthogonal sampling and dynamic covariance matrix repair, focusing on exploration by adaptively adjusting the step size and covariance matrix based on the success rate of orthogonal samples.", "code": "import numpy as np\n\nclass AdaptiveCMAES_Orthogonal:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, cs=0.3, damps=None, restart_patience=500, orthogonal_trials=5):\n        \"\"\"\n        Adaptive CMA-ES with orthogonal sampling and dynamic covariance matrix repair.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size. If None, it's set to 4 + int(3 * np.log(dim)).\n            mu (int): The number of parents. If None, it's set to pop_size // 2.\n            cs (float): Cumulation factor for step-size.\n            damps (float): Damping for step-size. If None, it's set to 1 + dim/2.\n            restart_patience (int): Number of iterations without improvement before restarting.\n            orthogonal_trials (int): Number of orthogonal samples to generate for each offspring.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mu = mu if mu is not None else self.pop_size // 2\n        self.mu = int(self.mu)  # Ensure mu is an integer\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + dim/2\n        self.restart_patience = restart_patience\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.orthogonal_trials = orthogonal_trials\n        \n        self.mean = np.random.uniform(-5, 5, size=dim)  # Initialize mean\n        self.sigma = 0.5  # Initialize step-size\n        self.C = np.eye(dim)  # Initialize covariance matrix\n        self.ps = np.zeros(dim)  # Evolution path for step-size\n        self.pc = np.zeros(dim)  # Evolution path for covariance matrix\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        \n        weights = np.log(self.pop_size + 1/2) - np.log(np.arange(1, self.pop_size + 1))\n        weights = weights / np.sum(weights)\n        self.weights = weights\n        \n        self.mueff = np.sum(weights)**2 / np.sum(weights**2)\n\n        self.c_cov = (1 / (self.mueff * (dim+1.3)**2 + self.mueff + 1.3))\n        self.c_mu = min(1 - self.c_cov, (2 * (self.mueff - 2 + 1/self.mueff)) / ((dim + 2)**2 + self.mueff))\n\n    def orthogonal_sampling(self, x, func):\n        \"\"\"Generates orthogonal samples around a given point.\"\"\"\n        best_fitness = func(x)\n        best_x = x\n        \n        for _ in range(self.orthogonal_trials):\n            direction = np.random.randn(self.dim)\n            direction /= np.linalg.norm(direction)\n            \n            # Sample along the direction\n            step_size = self.sigma * np.random.uniform(-1, 1)\n            x_new = x + step_size * direction\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            fitness = func(x_new)\n            if fitness < best_fitness:\n                best_fitness = fitness\n                best_x = x_new\n        \n        return best_fitness, best_x\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using CMA-ES with orthogonal sampling and dynamic covariance matrix repair.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the\n                   corresponding solution vector.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        while self.budget > 0:\n            # Generate and evaluate offspring\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            y = self.sigma * z\n            x = self.mean + y\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.zeros(self.pop_size)\n            x_orth = np.zeros((self.pop_size, self.dim))\n            \n            for i in range(self.pop_size):\n                fitness[i], x_orth[i] = self.orthogonal_sampling(x[i], func)\n\n            self.budget -= self.pop_size\n\n            if self.budget <= 0:\n                break\n\n            # Sort offspring by fitness\n            indices = np.argsort(fitness)\n            x = x_orth[indices] # using orthogonally sampled solutions\n            fitness = fitness[indices]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0].copy()\n                self.stagnation_counter = 0  # Reset stagnation counter\n            else:\n                self.stagnation_counter += 1\n            \n            self.best_fitness_history.append(self.f_opt)\n\n            # Update distribution parameters\n            xmean = np.sum(self.weights[:self.mu, None] * x[:self.mu], axis=0)\n            \n            self.ps = (1 - self.cs) * self.ps + (self.cs**0.5) * (self.mueff**0.5) * (xmean - self.mean) / self.sigma\n            self.pc = (1 - self.c_cov) * self.pc + (self.c_cov**0.5) * (self.mueff**0.5) * (xmean - self.mean) / self.sigma / np.diag(self.C)**0.5\n            \n            self.mean = xmean\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps)/self.chiN - 1))\n            \n            delta = (x[:self.mu] - self.mean) / self.sigma\n            self.C = (1 - self.c_mu - self.c_cov) * self.C + \\\n                     self.c_mu * np.sum(self.weights[:self.mu, None, None] * delta[:, :, None] * delta[:, None, :], axis=0) + \\\n                     self.c_cov * self.pc[:, None] * self.pc[None, :]\n\n            # Ensure that C remains positive definite and repair if necessary\n            try:\n                self.C = np.triu(self.C) + np.triu(self.C, 1).T\n                self.C[np.diag_indices_from(self.C)] = np.maximum(0, self.C[np.diag_indices_from(self.C)])\n                _ = np.linalg.cholesky(self.C)  # Check if C is positive definite\n\n            except np.linalg.LinAlgError:\n                # Repair covariance matrix by adding a small multiple of the identity matrix\n                self.C += 1e-6 * np.eye(self.dim)\n                self.C = np.triu(self.C) + np.triu(self.C, 1).T # Ensure symmetry\n                print(\"Covariance matrix repaired\")\n                self.pc = np.zeros(self.dim)  # Reset evolution path\n\n            # Restart strategy\n            if self.stagnation_counter > self.restart_patience:\n                self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.sigma = 0.5\n                self.C = np.eye(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.stagnation_counter = 0\n                print(\"Restarting population\")\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveCMAES_Orthogonal scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a2fe65a4-98f8-45dc-9974-b73208a740d5"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "54c53c8e-68ad-4f13-b624-41002d8d9722", "fitness": 0.079838900831541, "name": "AdaptiveCMAES_DynamicSigmaLocalSearch", "description": "A CMA-ES variant with a dynamic mutation strength adaptation based on the success rate of generating better offspring and a focused local search strategy guided by the covariance matrix.", "code": "import numpy as np\n\nclass AdaptiveCMAES_DynamicSigmaLocalSearch:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, restart_trigger=1e-12, local_search_prob=0.1, success_threshold=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize\n        self.mu = None\n        self.weights = None\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.eigeneval = 0\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.restart_trigger = restart_trigger\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n        self.initial_popsize = popsize\n        self.best_archive_f = []\n        self.local_search_prob = local_search_prob\n        self.success_threshold = success_threshold  # Threshold for success rate\n        self.success_rate = 0.0\n        self.num_successful = 0\n        self.generation_count = 0\n\n    def initialize(self):\n         # Adapt population size based on dimension, if not specified.\n        self.popsize = self.initial_popsize if self.initial_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, ((self.mu-1)/(self.dim+1)) - 1) + 2\n        self.c_c = (4 + self.mu/self.dim)**(-1)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n        self.success_rate = 0.0\n        self.num_successful = 0\n        self.generation_count = 0\n\n    def local_search(self, x, func, sigma_factor=0.1, num_steps=5):\n        \"\"\"Performs a local search guided by the covariance matrix around a given solution x.\"\"\"\n        x_current = x.copy()\n        f_current = func(x_current)\n        self.evals += 1\n\n        #Decompose C\n        try:\n            L = np.linalg.cholesky(self.C)\n        except np.linalg.LinAlgError:\n            L = np.eye(self.dim)\n\n        for _ in range(num_steps):\n            z = np.random.randn(self.dim)\n            step = L @ z\n            x_new = x_current + sigma_factor * self.sigma0 * step  # Scale step size with sigma0\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.evals += 1\n\n            if f_new < f_current:\n                f_current = f_new\n                x_current = x_new\n\n            if self.evals >= self.budget:\n                break\n\n        return f_current, x_current\n\n    def __call__(self, func):\n        self.func = func\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initialize()\n        self.best_archive_f = []\n\n        while self.evals < self.budget:\n            # Generate lambda offsprings\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.popsize)\n            x = self.m + self.sigma0 * z\n            f = np.zeros(self.popsize)\n            successful_offspring = 0\n            \n            # Check boundaries and evaluate\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], self.func.bounds.lb, self.func.bounds.ub)\n                f[i] = func(x[i])\n                self.evals += 1\n\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    self.best_archive_f.append(self.f_opt)\n                    successful_offspring += 1\n\n                # Perform local search with a certain probability\n                if np.random.rand() < self.local_search_prob:\n                    f_local, x_local = self.local_search(x[i], func)\n                    if f_local < f[i]:\n                        f[i] = f_local\n                        x[i] = x_local\n                        successful_offspring += 1\n                        if f[i] < self.f_opt:\n                            self.f_opt = f[i]\n                            self.x_opt = x[i]\n                            self.best_archive_f.append(self.f_opt)\n                            \n                if self.evals >= self.budget:\n                    break\n            if self.evals >= self.budget:\n                break\n\n            # Update success rate\n            self.num_successful += successful_offspring\n            self.generation_count += self.popsize\n            self.success_rate = self.num_successful / self.generation_count if self.generation_count > 0 else 0.0\n\n            # Adjust sigma0 dynamically based on success rate\n            if self.success_rate > self.success_threshold:\n                self.sigma0 *= 1.1  # Increase step size\n            elif self.success_rate < self.success_threshold:\n                self.sigma0 *= 0.9  # Decrease step size\n\n            # Selection and recombination\n            idx = np.argsort(f)\n            x_mu = x[idx[:self.mu]]\n            z_mu = z[idx[:self.mu]]\n            f_mu = f[idx[:self.mu]]\n            \n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n            \n            # Covariance matrix adaptation\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            if np.sum(self.ps**2) / self.dim > self.d_sigma**2:\n                self.sigma0 *= np.exp(0.2 + self.c_sigma / self.d_sigma)\n            else:\n                self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * ((np.sum(self.ps**2) / self.dim) - 1) / 2)\n            \n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n            \n            delta = z_mu - np.zeros(self.dim)\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * (delta[k,:][:, None] @ delta[k,:][None, :])\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n            \n            #Stagnation Restart\n            if abs(self.f_opt - self.last_f_opt) < self.restart_trigger:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > 50 + 10*self.dim:  # Tunable parameter for stagnation\n                self.sigma0 *= 2 #Increase stepsize upon restart\n                self.initialize() #Restart\n            else:\n                self.last_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveCMAES_DynamicSigmaLocalSearch scored 0.080 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["fd59e792-3f87-4df8-b48f-ef9a22809a9c"], "operator": null, "metadata": {"aucs": [0.07571825854501457, 0.1637984439496084, 0]}}
{"id": "d6cfe63c-d172-4208-9fae-c704ff78036f", "fitness": 0.15657486443524438, "name": "AdaptiveDE_SelfAdaptivePop", "description": "Adaptive Differential Evolution with a self-adaptive population size and a probabilistic local search around the best solution.", "code": "import numpy as np\n\nclass AdaptiveDE_SelfAdaptivePop:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, archive_size=10, learning_rate=0.1, local_search_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.initial_pop_size = initial_pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7  # Initial crossover rate\n        self.learning_rate = learning_rate # Learning rate for scaling factor\n        self.scaling_factor = 1.0  # Initial scaling factor for adjusting step size\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Adaptive parameter control\n                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n                # Mutation\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                if len(self.archive) > 0:\n                    use_archive = np.random.rand() < 0.1  # 10% chance to use archive\n                    if use_archive:\n                        a = np.random.choice(len(self.archive))\n                        x_archive = self.archive[a]\n                        \n                        candidates2 = list(range(self.pop_size))\n                        candidates2.remove(i)\n                        idx = np.random.choice(candidates2)\n                        x_1 = self.population[idx]\n                        \n                        idx = np.random.choice(candidates2)\n                        x_2 = self.population[idx]\n                        \n                        v = self.population[i] + self.scaling_factor * self.F * (x_archive - x_1 + x_2 - self.population[i])\n                    else:\n                        np.random.shuffle(candidates)\n                        x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                        v = self.population[i] + self.scaling_factor * self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                    v = self.population[i] + self.scaling_factor * self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    # Update population\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    # Update scaling factor (success)\n                    self.scaling_factor *= (1 - self.learning_rate + self.learning_rate * (f_u / self.fitness[i]))\n                    self.scaling_factor = min(self.scaling_factor, 2.0)\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Update scaling factor (failure)\n                    self.scaling_factor *= (1 + self.learning_rate * (self.fitness[i] / f_u))\n                    self.scaling_factor = max(self.scaling_factor, 0.5)\n\n                if self.evals >= self.budget:\n                    break\n                    \n            #Probabilistic local search\n            if np.random.rand() < self.local_search_probability:\n                best_index = np.argmin(self.fitness)\n                x_best = self.population[best_index]\n                \n                #Generate a new solution by perturbing the best solution\n                noise = np.random.normal(0, 0.01, self.dim) #Small noise\n                x_new = x_best + noise\n                x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                f_new = func(x_new)\n                self.evals += 1\n                \n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n                    \n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Self-Adaptive Population Size Adjustment\n            if self.evals > self.budget * 0.25:\n                if np.std(self.fitness) < 1e-5:\n                    self.pop_size = max(10, int(self.pop_size * 0.8))  # Reduce population if converged\n                elif np.std(self.fitness) > 0.1:\n                    self.pop_size = min(self.initial_pop_size, int(self.pop_size * 1.2))  # Increase if diversity is high\n                \n                # Resize population\n                if self.pop_size != len(self.population):\n                    new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    new_fitness = np.array([func(x) for x in new_population])\n                    self.evals += (self.pop_size - len(self.population))\n                    \n                    if self.pop_size > len(self.population):\n                        self.population = np.concatenate((self.population, new_population[len(self.population):]))\n                        self.fitness = np.concatenate((self.fitness, new_fitness[len(self.fitness):]))\n                    else:\n                        # Keep best individuals\n                        best_indices = np.argsort(self.fitness)[:self.pop_size]\n                        self.population = self.population[best_indices]\n                        self.fitness = self.fitness[best_indices]\n            \n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE_SelfAdaptivePop scored 0.157 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e8ebf76a-b5c4-411a-81da-7e2a0205d397"], "operator": null, "metadata": {"aucs": [0.13321531510048534, 0.19717611013731262, 0.29590803250317954, 0]}}
{"id": "a5c8dbc8-072d-4288-a4cf-53270aab76a9", "fitness": 0.358133222972718, "name": "CMAES_Restart_LocalSearch", "description": "CMA-ES with dynamic population size adjustment based on success, adaptive step size, and covariance matrix regularization, combined with a focused local search strategy triggered by stagnation, enhancing exploration and exploitation.", "code": "import numpy as np\n\nclass CMAES_Restart_LocalSearch:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, restart_trigger=1e-12, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize\n        self.mu = None\n        self.weights = None\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.eigeneval = 0\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.restart_trigger = restart_trigger\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n        self.initial_popsize = popsize\n        self.best_archive_f = []\n        self.local_search_iterations = local_search_iterations\n\n    def initialize(self):\n         # Adapt population size based on dimension, if not specified.\n        self.popsize = self.initial_popsize if self.initial_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, ((self.mu-1)/(self.dim+1)) - 1) + 2\n        self.c_c = (4 + self.mu/self.dim)**(-1)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n\n    def local_search(self, x_start, func):\n        x = x_start.copy()\n        f_best = func(x)\n        self.evals += 1\n        if f_best < self.f_opt:\n            self.f_opt = f_best\n            self.x_opt = x.copy()\n            self.best_archive_f.append(self.f_opt)\n\n        for _ in range(self.local_search_iterations):\n            for i in range(self.dim):\n                #perturb one dimension at a time\n                delta = np.random.normal(0, 0.1) # small step size\n                x_new = x.copy()\n                x_new[i] += delta\n\n                x_new = np.clip(x_new, self.func.bounds.lb, self.func.bounds.ub)\n                f_new = func(x_new)\n                self.evals += 1\n\n                if f_new < f_best:\n                    f_best = f_new\n                    x = x_new.copy()\n                    if f_best < self.f_opt:\n                        self.f_opt = f_best\n                        self.x_opt = x.copy()\n                        self.best_archive_f.append(self.f_opt)\n\n                if self.evals >= self.budget:\n                    return x, f_best\n\n        return x, f_best\n\n    def __call__(self, func):\n        self.func = func\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initialize()\n        self.best_archive_f = []\n\n        while self.evals < self.budget:\n            # Generate lambda offsprings\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.popsize)\n            x = self.m + self.sigma0 * z\n            f = np.zeros(self.popsize)\n            \n            # Check boundaries and evaluate\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], self.func.bounds.lb, self.func.bounds.ub)\n                f[i] = func(x[i])\n                self.evals += 1\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    self.best_archive_f.append(self.f_opt)\n                    \n                if self.evals >= self.budget:\n                    break\n            if self.evals >= self.budget:\n                break\n\n            # Selection and recombination\n            idx = np.argsort(f)\n            x_mu = x[idx[:self.mu]]\n            z_mu = z[idx[:self.mu]]\n            f_mu = f[idx[:self.mu]]\n            \n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n            \n            # Covariance matrix adaptation\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            if np.sum(self.ps**2) / self.dim > self.d_sigma**2:\n                self.sigma0 *= np.exp(0.2 + self.c_sigma / self.d_sigma)\n            else:\n                self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * ((np.sum(self.ps**2) / self.dim) - 1) / 2)\n            \n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n            \n            delta = z_mu - np.zeros(self.dim)\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * (delta[k,:][:, None] @ delta[k,:][None, :])\n\n            # Regularize covariance matrix\n            min_eig = np.min(np.linalg.eigvalsh(self.C))\n            if min_eig < 0:\n                self.C += (abs(min_eig) + 1e-10) * np.eye(self.dim)\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n            \n            #Stagnation Restart\n            if abs(self.f_opt - self.last_f_opt) < self.restart_trigger:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > 20 + 5*self.dim:  # Tunable parameter for stagnation, reduced for more aggressive restarts\n                self.sigma0 *= 2 #Increase stepsize upon restart\n                self.popsize = min(self.popsize * 2, 20 + int(6 * np.log(self.dim))) # Adapt population size\n                \n                # Local search around the best solution before restarting\n                self.x_opt, self.f_opt = self.local_search(self.x_opt, func)\n\n                self.initialize() #Restart\n            else:\n                self.last_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm CMAES_Restart_LocalSearch scored 0.358 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["949997ff-df2b-40ad-aa30-7d01fa9a774f"], "operator": null, "metadata": {"aucs": [0.09811281280882944, 0.1529446995586351, 0.2426827226886331, 0.6365888169013943, 0.32178114372383804, 0.4374005030446567, 0.31000812948159806, 0.4460745303578657, 0.26453325497020364, 0.11315218575288633, 0.3797259738677271, 0.1996946628466315, 0.3009545905649589, 0.2040459838815062, 0.8573276741548644, 0.2914394210916771, 0.28493889462515176, 0.9707966492019946, 0.15868847406539166, 0.49177333586591576]}}
{"id": "60495709-fa2b-4c5b-b3e8-fd4bc4172ae6", "fitness": 0.40033447295407976, "name": "AdaptiveDEEAR", "description": "Adaptive Differential Evolution with Elitism, Archive, and Focused Exploration using a success rate to dynamically adjust both the mutation factor and crossover rate, enhancing exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDEEAR:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7  # Initial crossover rate\n        self.learning_rate = learning_rate # Learning rate for scaling factor\n        self.scaling_factor = 1.0  # Initial scaling factor for adjusting step size\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.success_rate_F = 0.0\n        self.success_rate_CR = 0.0\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        success_count_F = 0\n        success_count_CR = 0\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Adaptive parameter control using success rate\n                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n                # Mutation\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                if len(self.archive) > 0:\n                    use_archive = np.random.rand() < 0.1  # 10% chance to use archive\n                    if use_archive:\n                        a = np.random.choice(len(self.archive))\n                        x_archive = self.archive[a]\n                        \n                        candidates2 = list(range(self.pop_size))\n                        candidates2.remove(i)\n                        idx = np.random.choice(candidates2)\n                        x_1 = self.population[idx]\n                        \n                        idx = np.random.choice(candidates2)\n                        x_2 = self.population[idx]\n                        \n                        v = self.population[i] + self.scaling_factor * self.F * (x_archive - x_1 + x_2 - self.population[i])\n                    else:\n                        np.random.shuffle(candidates)\n                        x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                        v = self.population[i] + self.scaling_factor * self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                    v = self.population[i] + self.scaling_factor * self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    # Update population\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    # Update scaling factor (success)\n                    self.scaling_factor *= (1 - self.learning_rate + self.learning_rate * (f_u / self.fitness[i]))\n                    self.scaling_factor = min(self.scaling_factor, 2.0)\n                    \n                    # Increment success counts\n                    success_count_F += 1\n                    success_count_CR += 1\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Update scaling factor (failure)\n                    self.scaling_factor *= (1 + self.learning_rate * (self.fitness[i] / f_u))\n                    self.scaling_factor = max(self.scaling_factor, 0.5)\n\n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n            \n            # Update success rates\n            self.success_rate_F = success_count_F / self.pop_size\n            self.success_rate_CR = success_count_CR / self.pop_size\n\n            # Dynamic adjustment of F and CR based on success rate\n            self.F = np.clip(self.F * (1 + self.learning_rate * (self.success_rate_F - 0.5)), 0.1, 1.0)\n            self.CR = np.clip(self.CR * (1 + self.learning_rate * (self.success_rate_CR - 0.5)), 0.1, 1.0)\n            \n            success_count_F = 0\n            success_count_CR = 0\n\n            # Restart mechanism (optional)\n            if self.evals < self.budget and self.evals > self.budget*0.75 and np.std(self.fitness) < 1e-6:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size\n                self.scaling_factor = 1.0  # Reset scaling factor after restart\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDEEAR scored 0.400 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e8ebf76a-b5c4-411a-81da-7e2a0205d397"], "operator": null, "metadata": {"aucs": [0.1339825205825924, 0.23605153610032015, 0.304343231265475, 0.3598651359448448, 0.2625782590071398, 0.5968817425474315, 0.27133960253040057, 0.36163418773640443, 0.2627175475069877, 0.19138011617134587, 0.6356162090576394, 0.99677634637371, 0.3254460521728091, 0.2622102488201714, 0.7891119231814541, 0.37019740194288775, 0.24281767206150418, 0.7470713228175181, 0.1737199653139323, 0.48294843794702735]}}
{"id": "8415deaa-462f-4692-8d2c-ef754be30f3c", "fitness": 0.5171031685963859, "name": "AdaptiveDEEAR", "description": "Adaptive Differential Evolution with Elitism, Archive, and Separatly Adjusted Learning Rates for F and CR, plus exploration enhancing mechanisms.", "code": "import numpy as np\n\nclass AdaptiveDEEAR:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, learning_rate_F=0.1, learning_rate_CR=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7  # Initial crossover rate\n        self.learning_rate_F = learning_rate_F  # Learning rate for mutation factor\n        self.learning_rate_CR = learning_rate_CR  # Learning rate for crossover rate\n        self.scaling_factor = 1.0  # Initial scaling factor for adjusting step size\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.exploration_probability = 0.1 # Probability to explore random regions\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Exploration Phase\n                if np.random.rand() < self.exploration_probability:\n                    u = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    f_u = func(u)\n                    self.evals += 1\n\n                    if f_u < self.fitness[i]:\n                        self.population[i] = u\n                        self.fitness[i] = f_u\n\n                        if f_u < self.f_opt:\n                            self.f_opt = f_u\n                            self.x_opt = u\n                    continue # Skip DE step for this individual\n\n                # Adaptive parameter control\n                old_F = self.F\n                old_CR = self.CR\n                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n                # Mutation\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                if len(self.archive) > 0:\n                    use_archive = np.random.rand() < 0.1  # 10% chance to use archive\n                    if use_archive:\n                        a = np.random.choice(len(self.archive))\n                        x_archive = self.archive[a]\n                        \n                        candidates2 = list(range(self.pop_size))\n                        candidates2.remove(i)\n                        idx = np.random.choice(candidates2)\n                        x_1 = self.population[idx]\n                        \n                        idx = np.random.choice(candidates2)\n                        x_2 = self.population[idx]\n                        \n                        v = self.population[i] + self.scaling_factor * self.F * (x_archive - x_1 + x_2 - self.population[i])\n                    else:\n                        np.random.shuffle(candidates)\n                        x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                        v = self.population[i] + self.scaling_factor * self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                    v = self.population[i] + self.scaling_factor * self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    # Update population\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    # Update scaling factor (success)\n                    self.scaling_factor *= (1 - 0.1 * self.learning_rate_F * (1 - (f_u / self.fitness[i])))\n                    self.scaling_factor = min(self.scaling_factor, 2.0)\n\n                    # Update F and CR (success)\n                    self.F = old_F * (1 - self.learning_rate_F) + self.learning_rate_F * self.F\n                    self.CR = old_CR * (1 - self.learning_rate_CR) + self.learning_rate_CR * self.CR\n\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Update scaling factor (failure)\n                    self.scaling_factor *= (1 + 0.1 * self.learning_rate_F * (self.fitness[i] / f_u))\n                    self.scaling_factor = max(self.scaling_factor, 0.5)\n\n                    # Update F and CR (failure)\n                    self.F = old_F * (1 + self.learning_rate_F) - self.learning_rate_F * self.F\n                    self.F = np.clip(self.F, 0.1, 1.0)\n                    \n                    self.CR = old_CR * (1 + self.learning_rate_CR) - self.learning_rate_CR * self.CR\n                    self.CR = np.clip(self.CR, 0.1, 1.0)\n\n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Restart mechanism (optional)\n            if self.evals < self.budget and self.evals > self.budget*0.75 and np.std(self.fitness) < 1e-6:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size\n                self.scaling_factor = 1.0  # Reset scaling factor after restart\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDEEAR scored 0.517 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e8ebf76a-b5c4-411a-81da-7e2a0205d397"], "operator": null, "metadata": {"aucs": [0.16415989992327717, 0.33899095547178926, 0.4583606799478813, 0.7661073688832594, 0.5035050892647499, 0.6558547155130041, 0.3321375990638328, 0.4451304420646002, 0.5458289116661339, 0.36592648590706245, 0.7142488766390458, 0.9973609185077775, 0.3250906707170308, 0.5225261231625797, 0.8062859793218123, 0.5911689749708773, 0.40369031002385614, 0.7382763516520117, 0.18012437275599913, 0.4872886464711377]}}
{"id": "ca9373f6-0e51-4a0a-82da-4360e5ebc6d2", "fitness": 0.47937523363471346, "name": "AdaptiveDEEARSHADEOL", "description": "Adaptive Differential Evolution with Elitism, Archive, Success-History Adaptation of Control Parameters (SHADE), and Orthogonal Learning.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation strategy with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal learning\n                if np.random.rand() < 0.1:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + 0.01 * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = np.abs(f_u - self.fitness[i])\n\n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    # Update memory for SHADE\n                    self.memory_cr[self.memory_idx] = cr_i\n                    self.memory_f[self.memory_idx] = f_i\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Population reduction\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                reduction_rate = 0.1\n                n_reduce = int(self.pop_size * reduction_rate)\n                \n                if n_reduce > 0:\n                    # Remove the worst individuals\n                    worst_indices = np.argsort(self.fitness)[-n_reduce:]\n                    self.population = np.delete(self.population, worst_indices, axis=0)\n                    self.fitness = np.delete(self.fitness, worst_indices)\n                    self.pop_size = len(self.population)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDEEARSHADEOL scored 0.479 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e8ebf76a-b5c4-411a-81da-7e2a0205d397"], "operator": null, "metadata": {"aucs": [0.20436730403538272, 0.3903914287864675, 0.36657064791049365, 0.3907559565590284, 0.7305357268643178, 0.6097787350139364, 0.3785215720492128, 0.4082329232162223, 0.3975135002388812, 0.4029513267753052, 0.3739387807713268, 0.9987060014543936, 0.3148580869411134, 0.581205533136432, 0.7802715465248135, 0.6283299026653572, 0.30307010118650624, 0.6156672649183412, 0.2112786208866918, 0.5005597127600464]}}
{"id": "20d2d17f-c567-4d58-83a1-f55f7f810077", "fitness": -Infinity, "name": "CMAES_SubspaceExploration", "description": "CMA-ES with adaptive step-size control based on the mean change of function values and orthogonal subspace exploration for enhanced diversity.", "code": "import numpy as np\n\nclass CMAES_SubspaceExploration:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, restart_trigger=1e-12, subspace_dimension=3):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize\n        self.mu = None\n        self.weights = None\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.eigeneval = 0\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.restart_trigger = restart_trigger\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n        self.initial_popsize = popsize\n        self.subspace_dimension = subspace_dimension  # Dimension of the orthogonal subspace\n\n    def initialize(self):\n        # Adapt population size based on dimension, if not specified.\n        self.popsize = self.initial_popsize if self.initial_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, ((self.mu-1)/(self.dim+1)) - 1) + 2\n        self.c_c = (4 + self.mu/self.dim)**(-1)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n        self.function_values = [] #Track function values\n\n    def orthogonal_subspace_exploration(self, x_best, func, num_samples=5):\n        \"\"\"Explores a subspace orthogonal to the best solution.\"\"\"\n        # Define a random orthogonal basis\n        Q, _ = np.linalg.qr(np.random.randn(self.dim, self.subspace_dimension))\n\n        best_f = np.Inf\n        best_x = None\n\n        for _ in range(num_samples):\n            # Sample a point in the orthogonal subspace\n            delta = np.random.uniform(-1, 1, size=self.subspace_dimension)\n            x_new = x_best + self.sigma0 * (Q @ delta)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.evals += 1\n\n            if f_new < best_f:\n                best_f = f_new\n                best_x = x_new\n        \n        return best_f, best_x\n\n    def __call__(self, func):\n        self.func = func\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initialize()\n        self.function_values = []\n\n        while self.evals < self.budget:\n            # Generate lambda offsprings\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.popsize)\n            x = self.m + self.sigma0 * z\n            f = np.zeros(self.popsize)\n            \n            # Check boundaries and evaluate\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], self.func.bounds.lb, self.func.bounds.ub)\n                f[i] = func(x[i])\n                self.evals += 1\n                \n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n\n                if self.evals >= self.budget:\n                    break\n            if self.evals >= self.budget:\n                break\n\n            # Selection and recombination\n            idx = np.argsort(f)\n            x_mu = x[idx[:self.mu]]\n            z_mu = z[idx[:self.mu]]\n            f_mu = f[idx[:self.mu]]\n            \n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n            \n            # Covariance matrix adaptation\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            if np.sum(self.ps**2) / self.dim > self.d_sigma**2:\n                self.sigma0 *= np.exp(0.2 + self.c_sigma / self.d_sigma)\n            else:\n                self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * ((np.sum(self.ps**2) / self.dim) - 1) / 2)\n            \n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n            \n            delta = z_mu - np.zeros(self.dim)\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * (delta[k,:][:, None] @ delta[k,:][None, :])\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n            \n            #Stagnation Restart\n            if abs(self.f_opt - self.last_f_opt) < self.restart_trigger:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > 50 + 10*self.dim:  # Tunable parameter for stagnation\n                self.sigma0 *= 2 #Increase stepsize upon restart\n                self.initialize() #Restart\n            else:\n                self.last_f_opt = self.f_opt\n            \n            # Adaptive step size control and orthogonal subspace exploration\n            if len(self.function_values) > 10:\n                delta_f = np.mean(self.function_values[-10:]) - self.function_values[-1]\n                if delta_f > 0:\n                    self.sigma0 *= 1.1  # Increase step size if improving\n                else:\n                    self.sigma0 *= 0.9  # Decrease step size if stagnating\n            \n            #Explore orthogonal subspace\n            f_ortho, x_ortho = self.orthogonal_subspace_exploration(self.x_opt, func)\n            if f_ortho < self.f_opt:\n                self.f_opt = f_ortho\n                self.x_opt = x_ortho\n            \n            self.function_values.append(self.f_opt)\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occurred: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 2).", "error": "", "parent_ids": ["fd59e792-3f87-4df8-b48f-ef9a22809a9c"], "operator": null, "metadata": {}}
{"id": "4057ce99-5c2e-4bc7-a640-269c6d7afe33", "fitness": 0.6034067273394714, "name": "CMAES_Restart", "description": "CMA-ES with adaptive population sizing, covariance matrix regularization, early restart based on performance stagnation, and dynamic step-size adaptation using a mirrored sampling technique to enhance exploration.", "code": "import numpy as np\n\nclass CMAES_Restart:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, restart_trigger=1e-12):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize\n        self.mu = None\n        self.weights = None\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.eigeneval = 0\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.restart_trigger = restart_trigger\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n        self.initial_popsize = popsize\n        self.best_archive_f = []\n\n    def initialize(self):\n         # Adapt population size based on dimension, if not specified.\n        self.popsize = self.initial_popsize if self.initial_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, ((self.mu-1)/(self.dim+1)) - 1) + 2\n        self.c_c = (4 + self.mu/self.dim)**(-1)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        self.func = func\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initialize()\n        self.best_archive_f = []\n\n        while self.evals < self.budget:\n            # Generate lambda offsprings\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.popsize)\n            x = self.m + self.sigma0 * z\n            f = np.zeros(self.popsize)\n            \n            # Mirrored sampling for step-size adaptation\n            x_mirrored = self.m - self.sigma0 * z\n            f_mirrored = np.zeros(self.popsize)\n            \n            # Check boundaries and evaluate\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], self.func.bounds.lb, self.func.bounds.ub)\n                f[i] = func(x[i])\n                self.evals += 1\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    self.best_archive_f.append(self.f_opt)\n                \n                x_mirrored[i] = np.clip(x_mirrored[i], self.func.bounds.lb, self.func.bounds.ub)\n                f_mirrored[i] = func(x_mirrored[i])\n                self.evals += 1\n                if f_mirrored[i] < self.f_opt:\n                    self.f_opt = f_mirrored[i]\n                    self.x_opt = x_mirrored[i]\n                    self.best_archive_f.append(self.f_opt)    \n                    \n                if self.evals >= self.budget:\n                    break\n            if self.evals >= self.budget:\n                break\n\n            # Combine original and mirrored samples\n            x_combined = np.concatenate((x, x_mirrored))\n            f_combined = np.concatenate((f, f_mirrored))\n            \n            # Selection and recombination\n            idx = np.argsort(f_combined)\n            x_mu = x_combined[idx[:self.mu]]\n            z_mu = (x_mu - self.m) / self.sigma0  #Recalculate z_mu based on selected x_mu\n            f_mu = f_combined[idx[:self.mu]]\n            \n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n            \n            # Covariance matrix adaptation\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            if np.sum(self.ps**2) / self.dim > self.d_sigma**2:\n                self.sigma0 *= np.exp(0.2 + self.c_sigma / self.d_sigma)\n            else:\n                self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * ((np.sum(self.ps**2) / self.dim) - 1) / 2)\n            \n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n            \n            delta = z_mu - np.zeros(self.dim)\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * (delta[k,:][:, None] @ delta[k,:][None, :])\n\n            # Regularize covariance matrix\n            min_eig = np.min(np.linalg.eigvalsh(self.C))\n            if min_eig < 0:\n                self.C += (abs(min_eig) + 1e-10) * np.eye(self.dim)\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n            \n            #Stagnation Restart\n            if abs(self.f_opt - self.last_f_opt) < self.restart_trigger:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > 20 + 5*self.dim:  # Tunable parameter for stagnation, reduced for more aggressive restarts\n                self.sigma0 *= 2 #Increase stepsize upon restart\n                self.popsize = min(self.popsize * 2, 20 + int(6 * np.log(self.dim))) # Adapt population size\n                self.initialize() #Restart\n            else:\n                self.last_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm CMAES_Restart scored 0.603 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["949997ff-df2b-40ad-aa30-7d01fa9a774f"], "operator": null, "metadata": {"aucs": [0.14627471871896724, 0.20224136554360916, 0.9330486554895331, 0.9732062339160351, 0.929496973970833, 0.1617052969612207, 0.3254025518444692, 0.9237590353179087, 0.9307346240314122, 0.16890952086721278, 0.9653688840493956, 0.22277861212882744, 0.29099538989464346, 0.93336357709483, 0.9512234046420681, 0.9030806168794165, 0.5424340037409758, 0.9518011426049153, 0.15442337582855692, 0.4578865632645983]}}
{"id": "862d182d-bf8c-44a1-acbb-4b11b6f5efd6", "fitness": 0.0, "name": "NeighborhoodDE", "description": "Differential Evolution with dynamic F and CR inspired by SHADE, combined with a neighborhood-based mutation and a local search.", "code": "import numpy as np\n\nclass NeighborhoodDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, H=10, local_search_freq=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = H\n        self.memory_F = np.full(self.memory_size, 0.5)\n        self.memory_CR = np.full(self.memory_size, 0.7)\n        self.p = 0.1\n        self.archive = []\n        self.local_search_freq = local_search_freq\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.memory_index = 0\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Memory selection\n                rand_mem = np.random.randint(self.memory_size)\n                self.F = self.memory_F[rand_mem]\n                self.CR = self.memory_CR[rand_mem]\n\n                # Neighborhood definition (e.g., k-nearest neighbors)\n                k = min(5, self.pop_size - 1)  # Number of neighbors (excluding itself)\n                distances = np.linalg.norm(self.population - self.population[i], axis=1)\n                neighbor_indices = np.argsort(distances)[1:k+1]  # Exclude itself\n\n                # Mutation using neighborhood individuals\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                if len(self.archive) > 0 and np.random.rand() < self.p:\n                    rand_archive_idx = np.random.randint(len(self.archive))\n                    x_rand = self.archive[rand_archive_idx]\n\n                    idx = np.random.choice(candidates)\n                    x_1 = self.population[idx]\n                    \n                    idx = np.random.choice(candidates)\n                    x_2 = self.population[idx]\n                    v = self.population[i] + self.F * (x_rand - x_1 + x_2 - self.population[i])\n                else:\n\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                    x_r2 = self.population[candidates[1]]\n                    x_r3 = self.population[candidates[2]]\n                    v = self.population[i] + self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n                \n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                        \n                    delta_f = abs(f_u - self.fitness[i])\n                    self.memory_F[self.memory_index] = self.F\n                    self.memory_CR[self.memory_index] = self.CR\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                    self.memory_index = (self.memory_index + 1) % self.memory_size\n                \n                # Local search\n                if self.evals % self.local_search_freq == 0:\n                    x_local = self.population[i].copy()\n                    f_local = self.fitness[i]\n                    \n                    for _ in range(5):\n                        x_new = x_local + np.random.normal(0, 0.1, self.dim)\n                        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                        f_new = func(x_new)\n                        self.evals += 1\n                        \n                        if f_new < f_local:\n                            x_local = x_new\n                            f_local = f_new\n                    \n                    if f_local < self.fitness[i]:\n                        self.population[i] = x_local\n                        self.fitness[i] = f_local\n                        \n                        if f_local < self.f_opt:\n                            self.f_opt = f_local\n                            self.x_opt = x_local\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm NeighborhoodDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["60495709-fa2b-4c5b-b3e8-fd4bc4172ae6"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "39b0c34a-4e81-4c42-a8c4-f44ad49fefcb", "fitness": -Infinity, "name": "AdaptiveDEEARSHADEOLNiching", "description": "Enhanced Adaptive DE with SHADE, Orthogonal Learning, Elitism, Archive, and a novel population diversity maintenance strategy using niching and dynamic subpopulation allocation.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOLNiching:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10, num_niches=4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.num_niches = num_niches\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n\n        # Initialize niches\n        self.niches = [[] for _ in range(self.num_niches)]\n        self.allocate_niches()\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # Determine niche membership\n                niche_idx = self.find_niche(self.population[i])\n\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation strategy with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal learning\n                if np.random.rand() < 0.1:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + 0.01 * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = np.abs(f_u - self.fitness[i])\n\n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    # Update niche membership if necessary\n                    old_niche_idx = self.find_niche(self.population[i])\n                    new_niche_idx = self.find_niche(u)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    # Update memory for SHADE\n                    self.memory_cr[self.memory_idx] = cr_i\n                    self.memory_f[self.memory_idx] = f_i\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Population reduction\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                reduction_rate = 0.1\n                n_reduce = int(self.pop_size * reduction_rate)\n                \n                if n_reduce > 0:\n                    # Remove the worst individuals\n                    worst_indices = np.argsort(self.fitness)[-n_reduce:]\n                    self.population = np.delete(self.population, worst_indices, axis=0)\n                    self.fitness = np.delete(self.fitness, worst_indices)\n                    self.pop_size = len(self.population)\n                    self.allocate_niches()  # Reallocate after reduction\n\n            # Niche Allocation adjustment (Dynamic Subpopulation Allocation)\n            if self.evals % (self.budget // 10) == 0:\n                self.allocate_niches()\n\n        return self.f_opt, self.x_opt\n\n    def allocate_niches(self):\n        \"\"\"Assign individuals to niches based on a simple distance metric (e.g., Euclidean distance to niche center).\"\"\"\n        # Simple K-means-like approach for niche allocation\n        niche_centers = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_niches, self.dim))\n\n        self.niches = [[] for _ in range(self.num_niches)]  # Reset niches\n\n        for i in range(self.pop_size):\n            distances = np.linalg.norm(niche_centers - self.population[i], axis=1)\n            niche_idx = np.argmin(distances)\n            self.niches[niche_idx].append(i)\n            \n    def find_niche(self, individual):\n        \"\"\"Find the niche index for a given individual.\"\"\"\n        niche_centers = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_niches, self.dim)) #Create random niche center, but should not do that here, the centers should be fixed\n        distances = np.linalg.norm(niche_centers - individual, axis=1)\n        return np.argmin(distances)", "configspace": "", "generation": 4, "feedback": "An exception occurred: name 'func' is not defined.", "error": "", "parent_ids": ["ca9373f6-0e51-4a0a-82da-4360e5ebc6d2"], "operator": null, "metadata": {}}
{"id": "4fcc6145-b0e8-44db-a15c-d8c11f382ad3", "fitness": -Infinity, "name": "SOM_SHADE_DE", "description": "A Differential Evolution strategy employing a self-organizing map (SOM) to adaptively adjust mutation strategies based on the search landscape, combined with SHADE for parameter control.", "code": "import numpy as np\nfrom minisom import MiniSom\n\nclass SOM_SHADE_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10, som_grid_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.som_grid_size = som_grid_size # Size of the SOM grid\n        self.som = None  # Initialize SOM to None\n        self.mutation_strategies = [\"current_to_pbest\", \"rand_1\", \"current_to_rand\"]  # Different mutation strategies\n\n    def initialize_som(self, data):\n        \"\"\"Initializes the Self-Organizing Map.\"\"\"\n        self.som = MiniSom(self.som_grid_size, self.som_grid_size, self.dim, sigma=0.3, learning_rate=0.5)\n        self.som.random_weights_init(data)\n        self.som.train_random(data, 100)  # Train SOM for a short period\n\n    def assign_strategy(self):\n        \"\"\"Assigns a mutation strategy to each individual based on SOM mapping.\"\"\"\n        strategy_assignments = {}\n        for i in range(self.pop_size):\n            winner = self.som.winner(self.population[i])  # Find the winning neuron for the individual\n            strategy_index = (winner[0] * self.som_grid_size + winner[1]) % len(self.mutation_strategies)\n            strategy_assignments[i] = self.mutation_strategies[strategy_index]  # Assign strategy based on neuron index\n        return strategy_assignments\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        # Initialize SOM with initial population\n        self.initialize_som(self.population)\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            # Assign mutation strategies based on SOM\n            strategy_assignments = self.assign_strategy()\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n\n                # Select mutation strategy based on SOM assignment\n                mutation_strategy = strategy_assignments[i]\n\n                if mutation_strategy == \"current_to_pbest\":\n                    # Mutation strategy: current-to-pbest\n                    p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                    p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                    x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                    candidates = list(range(self.pop_size))\n                    candidates.remove(i)\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                    x_r2 = self.population[candidates[1]]\n\n                    v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                elif mutation_strategy == \"rand_1\":\n                    # Mutation strategy: rand/1\n                    candidates = list(range(self.pop_size))\n                    candidates.remove(i)\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                    x_r2 = self.population[candidates[1]]\n                    x_r3 = self.population[candidates[2]]\n\n                    v = x_r1 + f_i * (x_r2 - x_r3)\n                elif mutation_strategy == \"current_to_rand\":\n                    # Mutation strategy: current-to-rand\n                    candidates = list(range(self.pop_size))\n                    candidates.remove(i)\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                    x_r2 = self.population[candidates[1]]\n\n                    v = self.population[i] + f_i * (x_r1 - self.population[i] + x_r2 - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = np.abs(f_u - self.fitness[i])\n\n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    # Update memory for SHADE\n                    self.memory_cr[self.memory_idx] = cr_i\n                    self.memory_f[self.memory_idx] = f_i\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n\n            worst_pop_index = np.argmax(self.fitness)\n\n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n\n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Population reduction\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                reduction_rate = 0.1\n                n_reduce = int(self.pop_size * reduction_rate)\n\n                if n_reduce > 0:\n                    # Remove the worst individuals\n                    worst_indices = np.argsort(self.fitness)[-n_reduce:]\n                    self.population = np.delete(self.population, worst_indices, axis=0)\n                    self.fitness = np.delete(self.fitness, worst_indices)\n                    self.pop_size = len(self.population)\n\n            # Retrain the SOM with the updated population every epoch\n            self.initialize_som(self.population)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occurred: No module named 'minisom'.", "error": "", "parent_ids": ["ca9373f6-0e51-4a0a-82da-4360e5ebc6d2"], "operator": null, "metadata": {}}
{"id": "0f064e55-62e3-4ca2-873f-20715f6ab488", "fitness": 0.0, "name": "AdaptiveDEEARGLS", "description": "Adaptive Differential Evolution with Elitism, Archive, and Gaussian Local Search for fine-tuning solutions.", "code": "import numpy as np\n\nclass AdaptiveDEEARGLS:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, learning_rate_F=0.1, learning_rate_CR=0.1, gls_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7  # Initial crossover rate\n        self.learning_rate_F = learning_rate_F  # Learning rate for mutation factor\n        self.learning_rate_CR = learning_rate_CR  # Learning rate for crossover rate\n        self.scaling_factor = 1.0  # Initial scaling factor for adjusting step size\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.exploration_probability = 0.1 # Probability to explore random regions\n        self.gls_probability = gls_probability # Probability to perform Gaussian Local Search\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Exploration Phase\n                if np.random.rand() < self.exploration_probability:\n                    u = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    f_u = func(u)\n                    self.evals += 1\n\n                    if f_u < self.fitness[i]:\n                        self.population[i] = u\n                        self.fitness[i] = f_u\n\n                        if f_u < self.f_opt:\n                            self.f_opt = f_u\n                            self.x_opt = u\n                    continue # Skip DE step for this individual\n\n                # Adaptive parameter control\n                old_F = self.F\n                old_CR = self.CR\n                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n                # Mutation\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                if len(self.archive) > 0:\n                    use_archive = np.random.rand() < 0.1  # 10% chance to use archive\n                    if use_archive:\n                        a = np.random.choice(len(self.archive))\n                        x_archive = self.archive[a]\n                        \n                        candidates2 = list(range(self.pop_size))\n                        candidates2.remove(i)\n                        idx = np.random.choice(candidates2)\n                        x_1 = self.population[idx]\n                        \n                        idx = np.random.choice(candidates2)\n                        x_2 = self.population[idx]\n                        \n                        v = self.population[i] + self.scaling_factor * self.F * (x_archive - x_1 + x_2 - self.population[i])\n                    else:\n                        np.random.shuffle(candidates)\n                        x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                        v = self.population[i] + self.scaling_factor * self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                    v = self.population[i] + self.scaling_factor * self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    # Update population\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    # Update scaling factor (success)\n                    self.scaling_factor *= (1 - 0.1 * self.learning_rate_F * (1 - (f_u / self.fitness[i])))\n                    self.scaling_factor = min(self.scaling_factor, 2.0)\n\n                    # Update F and CR (success)\n                    self.F = old_F * (1 - self.learning_rate_F) + self.learning_rate_F * self.F\n                    self.CR = old_CR * (1 - self.learning_rate_CR) + self.learning_rate_CR * self.CR\n\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                        # Gaussian Local Search\n                        if np.random.rand() < self.gls_probability:\n                            sigma = 0.01 * (func.bounds.ub - func.bounds.lb)\n                            u_gls = np.clip(u + np.random.normal(0, sigma, self.dim), func.bounds.lb, func.bounds.ub)\n                            f_u_gls = func(u_gls)\n                            self.evals += 1\n                            if f_u_gls < self.f_opt:\n                                self.f_opt = f_u_gls\n                                self.x_opt = u_gls\n                                self.population[i] = u_gls\n                                self.fitness[i] = f_u_gls                                \n                            elif f_u_gls < f_u:\n                                self.population[i] = u_gls\n                                self.fitness[i] = f_u_gls\n\n                else:\n                    # Update scaling factor (failure)\n                    self.scaling_factor *= (1 + 0.1 * self.learning_rate_F * (self.fitness[i] / f_u))\n                    self.scaling_factor = max(self.scaling_factor, 0.5)\n\n                    # Update F and CR (failure)\n                    self.F = old_F * (1 + self.learning_rate_F) - self.learning_rate_F * self.F\n                    self.F = np.clip(self.F, 0.1, 1.0)\n                    \n                    self.CR = old_CR * (1 + self.learning_rate_CR) - self.learning_rate_CR * self.CR\n                    self.CR = np.clip(self.CR, 0.1, 1.0)\n\n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Restart mechanism (optional)\n            if self.evals < self.budget and self.evals > self.budget*0.75 and np.std(self.fitness) < 1e-6:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size\n                self.scaling_factor = 1.0  # Reset scaling factor after restart\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDEEARGLS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8415deaa-462f-4692-8d2c-ef754be30f3c"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "1cf4eeee-0fb2-4e9e-8a28-23222c0482ba", "fitness": -Infinity, "name": "AdaptiveDEEARSHADEOL", "description": "Enhanced Adaptive Differential Evolution with Elitism, Archive, SHADE, Orthogonal Learning, and a more aggressive population reduction strategy triggered by stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10, stagnation_threshold=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.stagnation_threshold = stagnation_threshold\n        self.last_improvement = 0\n        self.f_opt_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.last_improvement = 0\n        self.f_opt_history = []\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation strategy with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal learning\n                if np.random.rand() < 0.1:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + 0.01 * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = np.abs(f_u - self.fitness[i])\n\n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    # Update memory for SHADE\n                    self.memory_cr[self.memory_idx] = cr_i\n                    self.memory_f[self.memory_idx] = f_i\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        self.last_improvement = self.evals\n                        \n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n            \n            # Stagnation Check and Population Reduction\n            if self.evals - self.last_improvement > self.stagnation_threshold and self.pop_size > self.min_pop_size:\n                reduction_rate = 0.5  # More aggressive reduction\n                n_reduce = int(self.pop_size * reduction_rate)\n                \n                if n_reduce > 0:\n                    # Remove the worst individuals\n                    worst_indices = np.argsort(self.fitness)[-n_reduce:]\n                    self.population = np.delete(self.population, worst_indices, axis=0)\n                    self.fitness = np.delete(self.fitness, worst_indices)\n                    self.pop_size = len(self.population)\n                    \n                    # Reset last improvement to avoid immediate re-reduction\n                    self.last_improvement = self.evals\n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occurred: index 3 is out of bounds for axis 0 with size 3.", "error": "", "parent_ids": ["ca9373f6-0e51-4a0a-82da-4360e5ebc6d2"], "operator": null, "metadata": {}}
{"id": "b2c2dae3-5143-4026-ab7b-86049d2bf1a2", "fitness": 0.5787906912995913, "name": "CMAES_Restart", "description": "CMA-ES with mirrored sampling, covariance matrix adaptation, step-size control, and a more aggressive restart strategy based on a windowed stagnation detection mechanism and dynamic population size adjustment.", "code": "import numpy as np\n\nclass CMAES_Restart:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, restart_trigger=1e-12, stagnation_window=10):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize\n        self.mu = None\n        self.weights = None\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.eigeneval = 0\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.restart_trigger = restart_trigger\n        self.stagnation_window = stagnation_window\n        self.best_archive_f = []\n        self.past_f_opts = [] # Window to track past best function values\n        self.initial_popsize = popsize\n\n    def initialize(self):\n         # Adapt population size based on dimension, if not specified.\n        self.popsize = self.initial_popsize if self.initial_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, ((self.mu-1)/(self.dim+1)) - 1) + 2\n        self.c_c = (4 + self.mu/self.dim)**(-1)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.past_f_opts = []\n\n    def __call__(self, func):\n        self.func = func\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initialize()\n        self.best_archive_f = []\n        self.past_f_opts = []\n\n        while self.evals < self.budget:\n            # Generate lambda offsprings\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.popsize)\n            x = self.m + self.sigma0 * z\n            f = np.zeros(self.popsize)\n            \n            # Mirrored sampling for step-size adaptation\n            x_mirrored = self.m - self.sigma0 * z\n            f_mirrored = np.zeros(self.popsize)\n            \n            # Check boundaries and evaluate\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], self.func.bounds.lb, self.func.bounds.ub)\n                f[i] = func(x[i])\n                self.evals += 1\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    self.best_archive_f.append(self.f_opt)\n                \n                x_mirrored[i] = np.clip(x_mirrored[i], self.func.bounds.lb, self.func.bounds.ub)\n                f_mirrored[i] = func(x_mirrored[i])\n                self.evals += 1\n                if f_mirrored[i] < self.f_opt:\n                    self.f_opt = f_mirrored[i]\n                    self.x_opt = x_mirrored[i]\n                    self.best_archive_f.append(self.f_opt)    \n                    \n                if self.evals >= self.budget:\n                    break\n            if self.evals >= self.budget:\n                break\n\n            # Combine original and mirrored samples\n            x_combined = np.concatenate((x, x_mirrored))\n            f_combined = np.concatenate((f, f_mirrored))\n            \n            # Selection and recombination\n            idx = np.argsort(f_combined)\n            x_mu = x_combined[idx[:self.mu]]\n            z_mu = (x_mu - self.m) / self.sigma0  #Recalculate z_mu based on selected x_mu\n            f_mu = f_combined[idx[:self.mu]]\n            \n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n            \n            # Covariance matrix adaptation\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            if np.sum(self.ps**2) / self.dim > self.d_sigma**2:\n                self.sigma0 *= np.exp(0.2 + self.c_sigma / self.d_sigma)\n            else:\n                self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * ((np.sum(self.ps**2) / self.dim) - 1) / 2)\n            \n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n            \n            delta = z_mu - np.zeros(self.dim)\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * (delta[k,:][:, None] @ delta[k,:][None, :])\n\n            # Regularize covariance matrix\n            min_eig = np.min(np.linalg.eigvalsh(self.C))\n            if min_eig < 0:\n                self.C += (abs(min_eig) + 1e-10) * np.eye(self.dim)\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Stagnation Detection and Restart\n            self.past_f_opts.append(self.f_opt)\n            if len(self.past_f_opts) > self.stagnation_window:\n                self.past_f_opts.pop(0)  # Maintain window of stagnation_window\n\n            if len(self.past_f_opts) == self.stagnation_window and \\\n               abs(max(self.past_f_opts) - min(self.past_f_opts)) < self.restart_trigger:\n                # Stagnation detected\n                self.sigma0 *= 2 #Increase stepsize upon restart\n                self.popsize = min(self.popsize * 2, 20 + int(6 * np.log(self.dim))) # Adapt population size\n                self.initialize() #Restart\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm CMAES_Restart scored 0.579 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4057ce99-5c2e-4bc7-a640-269c6d7afe33"], "operator": null, "metadata": {"aucs": [0.19433921506546792, 0.4007796623823483, 0.9313699313692957, 0.2820609229088674, 0.3298198086757216, 0.9410555320401994, 0.29300279908962057, 0.9296219012477296, 0.9389236504697203, 0.17666580963475442, 0.9130505176644074, 0.9949037335892968, 0.40892959185042344, 0.41233676705936473, 0.9407557136578815, 0.3365432886733102, 0.3502178960817913, 0.958677057843333, 0.3660151574861117, 0.4767448692021792]}}
{"id": "023f3482-b732-430a-b5fe-d7ef2f700c24", "fitness": 0.6550390516803667, "name": "AdaptiveDEEARSHADEOL", "description": "Adaptive Differential Evolution with Elitism, Archive, Success-History Adaptation of Control Parameters (SHADE), orthogonal learning, and a local search to enhance fine-tuning.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=5, local_search_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_CR = np.full(self.memory_size, 0.5)\n        self.memory_F = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.archive = []\n        self.local_search_probability = local_search_probability\n        self.elite_ratio = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.memory_idx = 0\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n\n        while self.evals < self.budget:\n            \n            ranked_indices = np.argsort(self.fitness)\n            p_best_indices = ranked_indices[:max(1, int(self.p * self.pop_size))]\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                mem_idx = np.random.randint(self.memory_size)\n                CRm = self.memory_CR[mem_idx]\n                Fm = self.memory_F[mem_idx]\n\n                CR = np.random.normal(CRm, 0.1)\n                CR = np.clip(CR, 0.0, 1.0)\n                \n                F = np.random.normal(Fm, 0.1)\n                while F <= 0:\n                    F = np.random.normal(Fm, 0.1)\n                F = np.clip(F, 0.1, 1.0)\n\n\n                # Mutation\n                p_best_idx = np.random.choice(p_best_indices)\n                x_pbest = self.population[p_best_idx]\n                \n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                np.random.shuffle(candidates)\n                x_r1 = self.population[candidates[0]]\n                \n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    x_r2 = self.archive[arc_idx]\n                else:\n                    x_r2 = self.population[candidates[1]]\n\n                v = self.population[i] + F * (x_pbest - self.population[i]) + F * (x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal Learning\n                if np.random.rand() < 0.1:\n                    H = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim, self.dim))\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n                \n                if f_u < self.fitness[i]:\n                    # Local Search\n                    if np.random.rand() < self.local_search_probability:\n                        step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                        u_local = u + np.random.normal(0, step_size, size=self.dim)\n                        u_local = np.clip(u_local, func.bounds.lb, func.bounds.ub)\n                        f_u_local = func(u_local)\n                        self.evals += 1\n                        if f_u_local < f_u:\n                            f_u = f_u_local\n                            u = u_local\n                    \n                    # Update Memory\n                    self.memory_CR[self.memory_idx] = CR\n                    self.memory_F[self.memory_idx] = F\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                    # Update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    # Update population\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n\n            worst_pop_index = np.argmax(self.fitness)\n\n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n\n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDEEARSHADEOL scored 0.655 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8415deaa-462f-4692-8d2c-ef754be30f3c"], "operator": null, "metadata": {"aucs": [0.21503313694973958, 0.753129018855512, 0.7395171417045822, 0.8381675299000892, 0.5588658021446073, 0.8055046647967183, 0.4334872415964556, 0.6801777301686216, 0.7206879352863332, 0.1910074064303593, 0.8986102621617719, 0.9947089458274393, 0.7635697601299706, 0.584800631605174, 0.8866552842590602, 0.7982870499319307, 0.6609858774940855, 0.8525700073229785, 0.21699337017251563, 0.5080222368693881]}}
{"id": "127a4b46-23ed-44ba-9ba2-37fb88d6a671", "fitness": 0.5468325616034343, "name": "AdaptiveDEEARSHADEOL", "description": "Adaptive Differential Evolution with SHADE, orthogonal learning, archive, elitism and improved population reduction using diversity measure.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation strategy with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal learning\n                if np.random.rand() < 0.1:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + 0.01 * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = np.abs(f_u - self.fitness[i])\n\n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    # Update memory for SHADE\n                    self.memory_cr[self.memory_idx] = cr_i\n                    self.memory_f[self.memory_idx] = f_i\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Population reduction based on diversity\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                # Calculate diversity (e.g., average distance to centroid)\n                centroid = np.mean(self.population, axis=0)\n                distances = np.linalg.norm(self.population - centroid, axis=1)\n                avg_distance = np.mean(distances)\n\n                if avg_distance < self.diversity_threshold:\n                    reduction_rate = 0.2  # Increased reduction rate when diversity is low\n                else:\n                    reduction_rate = 0.05 # Reduced reduction rate otherwise\n                    \n                n_reduce = int(self.pop_size * reduction_rate)\n                \n                if n_reduce > 0:\n                    # Remove the worst individuals\n                    worst_indices = np.argsort(self.fitness)[-n_reduce:]\n                    self.population = np.delete(self.population, worst_indices, axis=0)\n                    self.fitness = np.delete(self.fitness, worst_indices)\n                    self.pop_size = len(self.population)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDEEARSHADEOL scored 0.547 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ca9373f6-0e51-4a0a-82da-4360e5ebc6d2"], "operator": null, "metadata": {"aucs": [0.24702700951461687, 0.6822569942045039, 0.4539570965307974, 0.9379625156332778, 0.573855606662734, 0.5500470604860782, 0.5453495346755493, 0.4419547618927824, 0.5118550763382171, 0.20874590142129923, 0.5557492800094452, 0.99943014308011, 0.49960933826225506, 0.7013030053518051, 0.7592228067728072, 0.3776372034359803, 0.4278406204734453, 0.703569541666986, 0.2576725179237821, 0.5016052177322126]}}
{"id": "0069837e-9fa4-400c-b780-7bc37d356e32", "fitness": 0.3321709674094835, "name": "AdaptiveDEEARSHADEOL", "description": "Adaptive Differential Evolution with Elitism, Archive, SHADE, Orthogonal Learning, and improved parameter adaptation with a focus on enhanced exploration and population diversity maintenance via dynamic population size adjustment and a distance-based mutation strategy.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.max_pop_size = 100 # Maximum population size\n        self.population_decay = 0.05 # Rate at which population decays\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n            if self.pop_size > self.max_pop_size:\n                self.pop_size = self.max_pop_size\n\n            # SHADE parameter adaptation with improved memory update\n            successful_cr = []\n            successful_f = []\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation strategy with p-best and archive, distance-based parameter\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n\n                # Distance-based mutation parameter\n                distance = np.linalg.norm(self.population[i] - x_pbest)\n                mutation_factor = f_i * (1 + distance)  # Adapt mutation based on distance\n                v = self.population[i] + mutation_factor * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal learning - Reduced intensity\n                if np.random.rand() < 0.05:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + 0.005 * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = np.abs(f_u - self.fitness[i])\n\n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    successful_cr.append(cr_i)  # Store successful CR values\n                    successful_f.append(f_i)  # Store successful F values\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                if self.evals >= self.budget:\n                    break\n\n            # Update memory for SHADE, using mean of successful values\n            if successful_cr:\n                self.memory_cr[self.memory_idx] = np.mean(successful_cr)\n            if successful_f:\n                self.memory_f[self.memory_idx] = np.mean(successful_f)\n\n            self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n            \n            # Dynamic Population Size Adjustment\n            if self.evals < self.budget:\n                self.pop_size = int(self.pop_size * (1 - self.population_decay))\n                self.pop_size = max(self.min_pop_size, min(self.pop_size, self.max_pop_size)) # Keep within bounds\n\n                if self.pop_size < len(self.population):\n                    # Remove the worst individuals\n                    n_reduce = len(self.population) - self.pop_size\n                    worst_indices = np.argsort(self.fitness)[-n_reduce:]\n                    self.population = np.delete(self.population, worst_indices, axis=0)\n                    self.fitness = np.delete(self.fitness, worst_indices)\n                    \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDEEARSHADEOL scored 0.332 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ca9373f6-0e51-4a0a-82da-4360e5ebc6d2"], "operator": null, "metadata": {"aucs": [0.1672828706768511, 0.17649803372500505, 0.3113925566381045, 0.2530241252948605, 0.25234827445339647, 0.3532280634688377, 0.3029439670032462, 0.2583427228298153, 0.27287717364018094, 0.19236965459187505, 0.26280206274851203, 0.9963630667217986, 0.2773253244012174, 0.2657033596422502, 0.6380773625919395, 0.3328102531051249, 0.24911560104750374, 0.40846617583325884, 0.20360154015255905, 0.46884715962333157]}}
{"id": "0b80578f-1005-4f4d-96a1-b32b9aba79d4", "fitness": -Infinity, "name": "CMAES_OrthogonalLocalSearch", "description": "CMA-ES with orthogonal sampling, adaptive population sizing based on the covariance matrix adaptation, and a local search operator triggered by stagnation.", "code": "import numpy as np\nfrom scipy.linalg import orth\n\nclass CMAES_OrthogonalLocalSearch:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, restart_trigger=1e-12, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize\n        self.mu = None\n        self.weights = None\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.eigeneval = 0\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.restart_trigger = restart_trigger\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n        self.initial_popsize = popsize\n        self.local_search_iterations = local_search_iterations\n\n    def initialize(self):\n         # Adapt population size based on dimension, if not specified.\n        self.popsize = self.initial_popsize if self.initial_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, ((self.mu-1)/(self.dim+1)) - 1) + 2\n        self.c_c = (4 + self.mu/self.dim)**(-1)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        self.func = func\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initialize()\n\n        while self.evals < self.budget:\n            # Generate lambda offsprings using orthogonal sampling\n            Z = np.random.randn(self.popsize, self.dim)\n            Q, _ = np.linalg.qr(Z.T)\n            z = Q.T\n            x = self.m + self.sigma0 * z\n            f = np.zeros(self.popsize)\n\n            # Check boundaries and evaluate\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], self.func.bounds.lb, self.func.bounds.ub)\n                f[i] = func(x[i])\n                self.evals += 1\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    \n                if self.evals >= self.budget:\n                    break\n            if self.evals >= self.budget:\n                break\n\n            # Selection and recombination\n            idx = np.argsort(f)\n            x_mu = x[idx[:self.mu]]\n            z_mu = z[idx[:self.mu]]\n            f_mu = f[idx[:self.mu]]\n            \n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n            \n            # Covariance matrix adaptation\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            if np.sum(self.ps**2) / self.dim > self.d_sigma**2:\n                self.sigma0 *= np.exp(0.2 + self.c_sigma / self.d_sigma)\n            else:\n                self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * ((np.sum(self.ps**2) / self.dim) - 1) / 2)\n            \n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n            \n            delta = z_mu - np.zeros(self.dim)\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * (delta[k,:][:, None] @ delta[k,:][None, :])\n\n            # Regularize covariance matrix\n            min_eig = np.min(np.linalg.eigvalsh(self.C))\n            if min_eig < 0:\n                self.C += (abs(min_eig) + 1e-10) * np.eye(self.dim)\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n            \n            #Stagnation Restart\n            if abs(self.f_opt - self.last_f_opt) < self.restart_trigger:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > 20 + 5*self.dim:  # Tunable parameter for stagnation, reduced for more aggressive restarts\n                self.sigma0 *= 2 #Increase stepsize upon restart\n                self.popsize = min(self.popsize * 2, 20 + int(6 * np.log(self.dim))) # Adapt population size\n\n                #Local Search around current best\n                x_local = self.x_opt.copy()\n                f_local = self.f_opt\n                for _ in range(self.local_search_iterations):\n                    direction = np.random.uniform(-1, 1, size=self.dim)\n                    direction /= np.linalg.norm(direction)\n                    step_size = np.random.uniform(0, self.sigma0)\n                    x_new = x_local + step_size * direction\n                    x_new = np.clip(x_new, self.func.bounds.lb, self.func.bounds.ub)\n                    f_new = func(x_new)\n                    self.evals += 1\n                    if f_new < f_local:\n                        f_local = f_new\n                        x_local = x_new\n                        if f_local < self.f_opt:\n                            self.f_opt = f_local\n                            self.x_opt = x_local\n                    if self.evals >= self.budget:\n                        break\n                if self.evals >= self.budget:\n                    break\n                \n                self.initialize() #Restart\n            else:\n                self.last_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occurred: index 2 is out of bounds for axis 0 with size 2.", "error": "", "parent_ids": ["4057ce99-5c2e-4bc7-a640-269c6d7afe33"], "operator": null, "metadata": {}}
{"id": "30e9650b-9029-4325-a587-dfb1a975603f", "fitness": -Infinity, "name": "OrthogonalAdaptiveDE", "description": "A differential evolution strategy that incorporates orthogonal learning to improve variable-wise search and adaptive scaling factors based on fitness improvements.", "code": "import numpy as np\n\nclass OrthogonalAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7  # Initial crossover rate\n        self.learning_rate = learning_rate  # Learning rate for scaling factor\n        self.scaling_factor = 1.0  # Initial scaling factor for adjusting step size\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.success_rate_F = 0.0\n        self.success_rate_CR = 0.0\n        self.orthogonal_sample_size = 5  # Number of samples for orthogonal design\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        success_count_F = 0\n        success_count_CR = 0\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Adaptive parameter control using success rate\n                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n                # Mutation\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                if len(self.archive) > 0:\n                    use_archive = np.random.rand() < 0.1  # 10% chance to use archive\n                    if use_archive:\n                        a = np.random.choice(len(self.archive))\n                        x_archive = self.archive[a]\n                        \n                        candidates2 = list(range(self.pop_size))\n                        candidates2.remove(i)\n                        idx = np.random.choice(candidates2)\n                        x_1 = self.population[idx]\n                        \n                        idx = np.random.choice(candidates2)\n                        x_2 = self.population[idx]\n                        \n                        v = self.population[i] + self.scaling_factor * self.F * (x_archive - x_1 + x_2 - self.population[i])\n                    else:\n                        np.random.shuffle(candidates)\n                        x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                        v = self.population[i] + self.scaling_factor * self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1, x_r2, x_r3 = self.population[candidates[0]], self.population[candidates[1]], self.population[candidates[2]]\n                    v = self.population[i] + self.scaling_factor * self.F * (x_r1 - x_r2 + x_r3 - self.population[i])\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal Learning for each dimension\n                u_orthogonal = u.copy()\n                for j in range(self.dim):\n                    # Generate orthogonal samples around the current dimension\n                    orthogonal_samples = np.linspace(func.bounds.lb, func.bounds.ub, self.orthogonal_sample_size)  # More diversified orthogonal sampling\n\n                    fitness_orthogonal = []\n                    for sample in orthogonal_samples:\n                        u_temp = u.copy()\n                        u_temp[j] = sample\n                        f_temp = func(u_temp)\n                        fitness_orthogonal.append(f_temp)\n                        self.evals += 1\n                        if self.evals >= self.budget:\n                            break\n                    \n                    if self.evals >= self.budget:\n                        break\n                    \n                    best_sample_index = np.argmin(fitness_orthogonal)\n                    u_orthogonal[j] = orthogonal_samples[best_sample_index]  # Update the dimension with the best orthogonal sample\n\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n                f_u_orthogonal = func(u_orthogonal)\n                self.evals += 1\n                \n                if self.evals >= self.budget:\n                    break\n\n                if f_u_orthogonal < min(f_u, self.fitness[i]):\n                    # Update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    # Update population\n                    self.population[i] = u_orthogonal\n                    self.fitness[i] = f_u_orthogonal\n\n                    # Update scaling factor (success)\n                    self.scaling_factor *= (1 - self.learning_rate + self.learning_rate * (f_u_orthogonal / self.fitness[i]))\n                    self.scaling_factor = min(self.scaling_factor, 2.0)\n                    \n                    # Increment success counts\n                    success_count_F += 1\n                    success_count_CR += 1\n\n                    if f_u_orthogonal < self.f_opt:\n                        self.f_opt = f_u_orthogonal\n                        self.x_opt = u_orthogonal\n                elif f_u < self.fitness[i]:\n                    # Update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    # Update population\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    # Update scaling factor (success)\n                    self.scaling_factor *= (1 - self.learning_rate + self.learning_rate * (f_u / self.fitness[i]))\n                    self.scaling_factor = min(self.scaling_factor, 2.0)\n                    \n                    # Increment success counts\n                    success_count_F += 1\n                    success_count_CR += 1\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Update scaling factor (failure)\n                    self.scaling_factor *= (1 + self.learning_rate * (self.fitness[i] / max(f_u,f_u_orthogonal))) #Added the max function to avoid division by zero\n                    self.scaling_factor = max(self.scaling_factor, 0.5)\n\n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n            \n            # Update success rates\n            self.success_rate_F = success_count_F / self.pop_size\n            self.success_rate_CR = success_count_CR / self.pop_size\n\n            # Dynamic adjustment of F and CR based on success rate\n            self.F = np.clip(self.F * (1 + self.learning_rate * (self.success_rate_F - 0.5)), 0.1, 1.0)\n            self.CR = np.clip(self.CR * (1 + self.learning_rate * (self.success_rate_CR - 0.5)), 0.1, 1.0)\n            \n            success_count_F = 0\n            success_count_CR = 0\n\n            # Restart mechanism (optional)\n            if self.evals < self.budget and self.evals > self.budget*0.75 and np.std(self.fitness) < 1e-6:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size\n                self.scaling_factor = 1.0  # Reset scaling factor after restart\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["60495709-fa2b-4c5b-b3e8-fd4bc4172ae6"], "operator": null, "metadata": {}}
{"id": "42fa9dc4-39e0-4178-b050-765939ee4783", "fitness": 0.27475449040962685, "name": "CMAES_Ensemble", "description": "A CMA-ES variant that uses an ensemble of covariance matrices to enhance exploration and adapts the ensemble based on performance.", "code": "import numpy as np\n\nclass CMAES_Ensemble:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, ensemble_size=3, restart_trigger=1e-12):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize\n        self.ensemble_size = ensemble_size  # Number of covariance matrices in the ensemble\n        self.mu = None\n        self.weights = None\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.eigeneval = 0\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.restart_trigger = restart_trigger\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n        self.initial_popsize = popsize\n        self.ensemble = []  # List to hold the ensemble of covariance matrices\n        self.ensemble_weights = None # Weights for each member of the ensemble\n        self.best_archive_f = []\n\n    def initialize(self):\n        # Adapt population size based on dimension, if not specified.\n        self.popsize = self.initial_popsize if self.initial_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=self.dim)\n        # Initialize the ensemble of covariance matrices\n        self.ensemble = [np.eye(self.dim) for _ in range(self.ensemble_size)]\n        self.pc = [np.zeros(self.dim) for _ in range(self.ensemble_size)]\n        self.ps = [np.zeros(self.dim) for _ in range(self.ensemble_size)]\n        self.ensemble_weights = np.ones(self.ensemble_size) / self.ensemble_size #Initialize ensemble weights uniformly.\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, ((self.mu-1)/(self.dim+1)) - 1) + 2\n        self.c_c = (4 + self.mu/self.dim)**(-1)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        self.func = func\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initialize()\n        self.best_archive_f = []\n\n        while self.evals < self.budget:\n            # Generate lambda offsprings using the ensemble\n            x = np.zeros((self.popsize, self.dim))\n            f = np.zeros(self.popsize)\n            z = np.zeros((self.popsize, self.dim))\n            \n            for i in range(self.popsize):\n                # Select a covariance matrix from the ensemble based on ensemble weights\n                idx = np.random.choice(self.ensemble_size, p=self.ensemble_weights)\n                C = self.ensemble[idx]\n                \n                # Generate a sample using the selected covariance matrix\n                z_i = np.random.multivariate_normal(np.zeros(self.dim), C)\n                z[i,:] = z_i\n                x[i, :] = self.m + self.sigma0 * z_i\n\n            # Check boundaries and evaluate\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], self.func.bounds.lb, self.func.bounds.ub)\n                f[i] = func(x[i])\n                self.evals += 1\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    self.best_archive_f.append(self.f_opt)\n\n                if self.evals >= self.budget:\n                    break\n            if self.evals >= self.budget:\n                break\n                \n            # Selection and recombination\n            idx = np.argsort(f)\n            x_mu = x[idx[:self.mu]]\n            z_mu = z[idx[:self.mu]] #Keep the original z values corresponding to selected individuals.\n            f_mu = f[idx[:self.mu]]\n\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            \n            # Update each member of the ensemble\n            for j in range(self.ensemble_size):\n                #Find individuals generated from covariance matrix j\n                indices = np.where([np.allclose(self.ensemble[j], self.ensemble[k]) for k in range(self.ensemble_size)])[0]\n\n                #zmean = np.sum(self.weights[:, None] * z_mu, axis=0) #Average z over all mu best. No longer possible.\n\n                #Update pc and ps only with the offsprings generated from corresponding C.\n                self.ps[j] = (1 - self.c_sigma) * self.ps[j] + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * np.mean(z_mu, axis = 0) #Corrected update with ALL offspring.\n                if np.sum(self.ps[j]**2) / self.dim > self.d_sigma**2:\n                    self.sigma0 *= np.exp(0.2 + self.c_sigma / self.d_sigma)\n                else:\n                    self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * ((np.sum(self.ps[j]**2) / self.dim) - 1) / 2)\n\n                self.pc[j] = (1 - self.c_c) * self.pc[j] + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n                delta = z_mu - np.zeros(self.dim)\n                self.ensemble[j] = (1 - self.c_1 - self.c_mu) * self.ensemble[j] + self.c_1 * (self.pc[j][:, None] @ self.pc[j][None, :])\n                for k in range(self.mu):\n                    self.ensemble[j] += self.c_mu * self.weights[k] * (delta[k,:][:, None] @ delta[k,:][None, :])\n\n                # Regularize covariance matrix\n                min_eig = np.min(np.linalg.eigvalsh(self.ensemble[j]))\n                if min_eig < 0:\n                    self.ensemble[j] += (abs(min_eig) + 1e-10) * np.eye(self.dim)\n\n                # Keep C positive definite\n                self.ensemble[j] = np.triu(self.ensemble[j]) + np.triu(self.ensemble[j], 1).T\n                try:\n                    np.linalg.cholesky(self.ensemble[j])\n                except np.linalg.LinAlgError:\n                    self.ensemble[j] = np.eye(self.dim)\n            \n            #Adapt ensemble weights based on performance\n            performance = np.zeros(self.ensemble_size)\n            for j in range(self.ensemble_size):\n                  performance[j] = np.mean(f_mu) #Can change this metric\n            \n            #Normalize and update weights, the lower the better\n            performance = np.max(performance) - performance #Invert performance so the lower the value, the higher the performance\n            performance = np.exp(performance) / np.sum(np.exp(performance))\n            self.ensemble_weights = 0.9 * self.ensemble_weights + 0.1 * performance\n            self.ensemble_weights /= np.sum(self.ensemble_weights) # Renormalize\n                \n\n            #Stagnation Restart\n            if abs(self.f_opt - self.last_f_opt) < self.restart_trigger:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > 20 + 5*self.dim:  # Tunable parameter for stagnation, reduced for more aggressive restarts\n                self.sigma0 *= 2 #Increase stepsize upon restart\n                self.popsize = min(self.popsize * 2, 20 + int(6 * np.log(self.dim))) # Adapt population size\n                self.initialize() #Restart\n            else:\n                self.last_f_opt = self.f_opt\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm CMAES_Ensemble scored 0.275 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4057ce99-5c2e-4bc7-a640-269c6d7afe33"], "operator": null, "metadata": {"aucs": [0.16307160835176804, 0.26978251329078773, 0.21885907479819433, 0.30306710024678674, 0.18017335119929012, 0.25558930383891, 0.18975799228657497, 0.12265703826976182, 0.1730012150638509, 0.14937540226925916, 0.3429829387425176, 0.7223373009366814, 0.22397030116593353, 0.1505921893074883, 0.581422927012348, 0.2834765123419324, 0.26836208365941394, 0.6399177525572288, 0.13425849021421377, 0.12243471263959493]}}
{"id": "28d690e0-0303-488c-ba99-1dfe58927487", "fitness": -Infinity, "name": "WaveletMutationDE", "description": "An adaptive DE algorithm that uses a wavelet mutation operator to enhance exploration and exploitation capabilities, coupled with a diversity maintenance strategy using crowding distance.", "code": "import numpy as np\nimport pywt\n\nclass WaveletMutationDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, wavelet='db1', diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.wavelet = wavelet\n        self.diversity_threshold = diversity_threshold #tune this parameter\n        self.archive = []\n        self.elite_ratio = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            # Calculate crowding distance for diversity maintenance\n            crowding_distance = self.calculate_crowding_distance()\n\n            for i in range(self.pop_size):\n                # DE mutation with wavelet perturbation\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                np.random.shuffle(candidates)\n                x_r1 = self.population[candidates[0]]\n                x_r2 = self.population[candidates[1]]\n                x_r3 = self.population[candidates[2]]\n\n                v = self.population[i] + 0.5 * (x_r1 - x_r2) + 0.5 * (x_r3 - self.population[i]) #classic DE\n\n                # Wavelet mutation on a randomly selected dimension\n                j = np.random.randint(self.dim)\n                coeffs = pywt.wavedec(v[j], self.wavelet, level=1)\n                coeffs[1] = coeffs[1] + np.random.normal(0, 0.1, size=len(coeffs[1]))  # Perturb detail coefficients\n                v[j] = pywt.waverec(coeffs, self.wavelet)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Selection: Replace if better or if crowding distance is low (diversity)\n                f_v = func(v)\n                self.evals += 1\n\n                if f_v < self.fitness[i] or crowding_distance[i] < self.diversity_threshold:\n                    # Update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = v\n                    self.fitness[i] = f_v\n\n                    if f_v < self.f_opt:\n                        self.f_opt = f_v\n                        self.x_opt = v\n\n                if self.evals >= self.budget:\n                    break\n            \n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n\n            worst_pop_index = np.argmax(self.fitness)\n\n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n\n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n        return self.f_opt, self.x_opt\n    \n    def calculate_crowding_distance(self):\n        # Crowding distance calculation to maintain diversity\n        distances = np.zeros(self.pop_size)\n        for m in range(self.dim):  # For each dimension\n            # Sort population based on the m-th dimension\n            sorted_indices = np.argsort(self.population[:, m])\n            \n            # Boundary individuals have maximum crowding distance\n            distances[sorted_indices[0]] = np.inf\n            distances[sorted_indices[-1]] = np.inf\n\n            # Calculate distance for intermediate individuals\n            for i in range(1, self.pop_size - 1):\n                distances[sorted_indices[i]] += (self.population[sorted_indices[i+1], m] - self.population[sorted_indices[i-1], m])\n\n        return distances", "configspace": "", "generation": 5, "feedback": "An exception occurred: No module named 'pywt'.", "error": "", "parent_ids": ["023f3482-b732-430a-b5fe-d7ef2f700c24"], "operator": null, "metadata": {}}
{"id": "010ef74e-d325-42ca-bb41-823e2ca7421f", "fitness": -Infinity, "name": "CMAES_Restart", "description": "CMA-ES with mirrored sampling, covariance matrix adaptation, step-size control, aggressive restarts, dynamic population sizing, and a novel adaptive step-size damping strategy based on the condition number of the covariance matrix.", "code": "import numpy as np\n\nclass CMAES_Restart:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, restart_trigger=1e-12, stagnation_window=10, stepsize_damping=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize\n        self.mu = None\n        self.weights = None\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.eigeneval = 0\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.restart_trigger = restart_trigger\n        self.stagnation_window = stagnation_window\n        self.best_archive_f = []\n        self.past_f_opts = [] # Window to track past best function values\n        self.initial_popsize = popsize\n        self.stepsize_damping = stepsize_damping  # Damping factor for step-size adaptation\n\n    def initialize(self):\n         # Adapt population size based on dimension, if not specified.\n        self.popsize = self.initial_popsize if self.initial_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, ((self.mu-1)/(self.dim+1)) - 1) + 2\n        self.c_c = (4 + self.mu/self.dim)**(-1)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.past_f_opts = []\n\n    def __call__(self, func):\n        self.func = func\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initialize()\n        self.best_archive_f = []\n        self.past_f_opts = []\n\n        while self.evals < self.budget:\n            # Generate lambda offsprings\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.popsize)\n            x = self.m + self.sigma0 * z\n            f = np.zeros(self.popsize)\n            \n            # Mirrored sampling for step-size adaptation\n            x_mirrored = self.m - self.sigma0 * z\n            f_mirrored = np.zeros(self.popsize)\n            \n            # Check boundaries and evaluate\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], self.func.bounds.lb, self.func.bounds.ub)\n                f[i] = func(x[i])\n                self.evals += 1\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    self.best_archive_f.append(self.f_opt)\n                \n                x_mirrored[i] = np.clip(x_mirrored[i], self.func.bounds.lb, self.func.bounds.ub)\n                f_mirrored[i] = func(x_mirrored[i])\n                self.evals += 1\n                if f_mirrored[i] < self.f_opt:\n                    self.f_opt = f_mirrored[i]\n                    self.x_opt = x_mirrored[i]\n                    self.best_archive_f.append(self.f_opt)    \n                    \n                if self.evals >= self.budget:\n                    break\n            if self.evals >= self.budget:\n                break\n\n            # Combine original and mirrored samples\n            x_combined = np.concatenate((x, x_mirrored))\n            f_combined = np.concatenate((f, f_mirrored))\n            \n            # Selection and recombination\n            idx = np.argsort(f_combined)\n            x_mu = x_combined[idx[:self.mu]]\n            z_mu = (x_mu - self.m) / self.sigma0  #Recalculate z_mu based on selected x_mu\n            f_mu = f_combined[idx[:self.mu]]\n            \n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n            \n            # Covariance matrix adaptation\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            if np.sum(self.ps**2) / self.dim > self.d_sigma**2:\n                self.sigma0 *= np.exp(0.2 + self.c_sigma / self.d_sigma)\n            else:\n                self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * ((np.sum(self.ps**2) / self.dim) - 1) / 2)\n            \n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n            \n            delta = z_mu - np.zeros(self.dim)\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * (delta[k,:][:, None] @ delta[k,:][None, :])\n\n            # Regularize covariance matrix\n            min_eig = np.min(np.linalg.eigvalsh(self.C))\n            if min_eig < 0:\n                self.C += (abs(min_eig) + 1e-10) * np.eye(self.dim)\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n            \n            # Adaptive step-size damping based on condition number of C\n            try:\n                condition_number = np.linalg.cond(self.C)\n                damping_factor = 1.0 / (1.0 + self.stepsize_damping * np.log10(condition_number))  # Damp more for ill-conditioned C\n                self.sigma0 *= damping_factor\n            except np.linalg.LinAlgError:\n                pass  # Handle potential errors in condition number calculation\n\n            # Stagnation Detection and Restart\n            self.past_f_opts.append(self.f_opt)\n            if len(self.past_f_opts) > self.stagnation_window:\n                self.past_f_opts.pop(0)  # Maintain window of stagnation_window\n\n            if len(self.past_f_opts) == self.stagnation_window and \\\n               abs(max(self.past_f_opts) - min(self.past_f_opts)) < self.restart_trigger:\n                # Stagnation detected\n                self.sigma0 *= 2 #Increase stepsize upon restart\n                self.popsize = min(self.popsize * 2, 20 + int(6 * np.log(self.dim))) # Adapt population size\n                self.initialize() #Restart\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occurred: Eigenvalues did not converge.", "error": "", "parent_ids": ["b2c2dae3-5143-4026-ab7b-86049d2bf1a2"], "operator": null, "metadata": {}}
{"id": "319911a5-6ce8-4107-991e-d4b6953e381a", "fitness": -Infinity, "name": "CMAES_LocalSearch", "description": "A CMA-ES variant that incorporates a self-adaptive local search based on Nelder-Mead simplex during stagnation to refine promising solutions.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CMAES_LocalSearch:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, restart_trigger=1e-12, stagnation_window=10, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize\n        self.mu = None\n        self.weights = None\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.eigeneval = 0\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.restart_trigger = restart_trigger\n        self.stagnation_window = stagnation_window\n        self.best_archive_f = []\n        self.past_f_opts = [] # Window to track past best function values\n        self.initial_popsize = popsize\n        self.local_search_iterations = local_search_iterations\n\n    def initialize(self):\n         # Adapt population size based on dimension, if not specified.\n        self.popsize = self.initial_popsize if self.initial_popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, ((self.mu-1)/(self.dim+1)) - 1) + 2\n        self.c_c = (4 + self.mu/self.dim)**(-1)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.past_f_opts = []\n\n    def local_search(self, x0):\n        \"\"\"\n        Applies a local search (Nelder-Mead) to refine a solution.\n        \"\"\"\n        bounds = [(self.func.bounds.lb, self.func.bounds.ub) for _ in range(self.dim)]\n        res = minimize(self.func, x0, method='Nelder-Mead', bounds=bounds,\n                       options={'maxiter': self.local_search_iterations, 'maxfev': self.local_search_iterations})\n        self.evals += res.nfev  # Increment evaluations by the number of function evaluations in local search\n        return res.fun, res.x\n\n    def __call__(self, func):\n        self.func = func\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initialize()\n        self.best_archive_f = []\n        self.past_f_opts = []\n\n        while self.evals < self.budget:\n            # Generate lambda offsprings\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.popsize)\n            x = self.m + self.sigma0 * z\n            f = np.zeros(self.popsize)\n            \n            # Mirrored sampling for step-size adaptation\n            x_mirrored = self.m - self.sigma0 * z\n            f_mirrored = np.zeros(self.popsize)\n            \n            # Check boundaries and evaluate\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], self.func.bounds.lb, self.func.bounds.ub)\n                f[i] = func(x[i])\n                self.evals += 1\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    self.best_archive_f.append(self.f_opt)\n                \n                x_mirrored[i] = np.clip(x_mirrored[i], self.func.bounds.lb, self.func.bounds.ub)\n                f_mirrored[i] = func(x_mirrored[i])\n                self.evals += 1\n                if f_mirrored[i] < self.f_opt:\n                    self.f_opt = f_mirrored[i]\n                    self.x_opt = x_mirrored[i]\n                    self.best_archive_f.append(self.f_opt)    \n                    \n                if self.evals >= self.budget:\n                    break\n            if self.evals >= self.budget:\n                break\n\n            # Combine original and mirrored samples\n            x_combined = np.concatenate((x, x_mirrored))\n            f_combined = np.concatenate((f, f_mirrored))\n            \n            # Selection and recombination\n            idx = np.argsort(f_combined)\n            x_mu = x_combined[idx[:self.mu]]\n            z_mu = (x_mu - self.m) / self.sigma0  #Recalculate z_mu based on selected x_mu\n            f_mu = f_combined[idx[:self.mu]]\n            \n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n            \n            # Covariance matrix adaptation\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            if np.sum(self.ps**2) / self.dim > self.d_sigma**2:\n                self.sigma0 *= np.exp(0.2 + self.c_sigma / self.d_sigma)\n            else:\n                self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * ((np.sum(self.ps**2) / self.dim) - 1) / 2)\n            \n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n            \n            delta = z_mu - np.zeros(self.dim)\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * (delta[k,:][:, None] @ delta[k,:][None, :])\n\n            # Regularize covariance matrix\n            min_eig = np.min(np.linalg.eigvalsh(self.C))\n            if min_eig < 0:\n                self.C += (abs(min_eig) + 1e-10) * np.eye(self.dim)\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Stagnation Detection and Restart\n            self.past_f_opts.append(self.f_opt)\n            if len(self.past_f_opts) > self.stagnation_window:\n                self.past_f_opts.pop(0)  # Maintain window of stagnation_window\n\n            if len(self.past_f_opts) == self.stagnation_window and \\\n               abs(max(self.past_f_opts) - min(self.past_f_opts)) < self.restart_trigger:\n                # Stagnation detected\n                # Apply local search to the best solution so far\n                f_local, x_local = self.local_search(self.x_opt)\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n                    self.best_archive_f.append(self.f_opt)\n\n                self.sigma0 *= 2 #Increase stepsize upon restart\n                self.popsize = min(self.popsize * 2, 20 + int(6 * np.log(self.dim))) # Adapt population size\n                self.initialize() #Restart\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["b2c2dae3-5143-4026-ab7b-86049d2bf1a2"], "operator": null, "metadata": {}}
{"id": "60c64425-d60b-4530-a04a-ff91a3197366", "fitness": 0.0, "name": "AdaptiveDEEARSHADEOL", "description": "Adaptive Differential Evolution with SHADE, orthogonal learning, archive, elitism, dynamic population size, and a local search operator for enhanced exploitation.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.max_pop_size = 100 # Maximum population size\n        self.population_decay = 0.05 # Rate at which population decays\n        self.local_search_prob = 0.05 # Probability of local search\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n            if self.pop_size > self.max_pop_size:\n                self.pop_size = self.max_pop_size\n\n            # SHADE parameter adaptation with improved memory update\n            successful_cr = []\n            successful_f = []\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation strategy with p-best and archive, distance-based parameter\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n\n                # Distance-based mutation parameter\n                distance = np.linalg.norm(self.population[i] - x_pbest)\n                mutation_factor = f_i * (1 + distance)  # Adapt mutation based on distance\n                v = self.population[i] + mutation_factor * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal learning - Reduced intensity\n                if np.random.rand() < 0.05:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + 0.005 * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                    perturbation = np.random.uniform(-step_size, step_size, size=self.dim)\n                    u_local = u + perturbation\n                    u_local = np.clip(u_local, func.bounds.lb, func.bounds.ub)\n\n                    f_u_local = func(u_local)\n                    self.evals += 1\n\n                    if f_u_local < func(u):\n                        u = u_local\n                    \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = np.abs(f_u - self.fitness[i])\n\n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    successful_cr.append(cr_i)  # Store successful CR values\n                    successful_f.append(f_i)  # Store successful F values\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                if self.evals >= self.budget:\n                    break\n\n            # Update memory for SHADE, using mean of successful values\n            if successful_cr:\n                self.memory_cr[self.memory_idx] = np.mean(successful_cr)\n            if successful_f:\n                self.memory_f[self.memory_idx] = np.mean(successful_f)\n\n            self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n            \n            # Dynamic Population Size Adjustment\n            if self.evals < self.budget:\n                self.pop_size = int(self.pop_size * (1 - self.population_decay))\n                self.pop_size = max(self.min_pop_size, min(self.pop_size, self.max_pop_size)) # Keep within bounds\n\n                if self.pop_size < len(self.population):\n                    # Remove the worst individuals\n                    n_reduce = len(self.population) - self.pop_size\n                    worst_indices = np.argsort(self.fitness)[-n_reduce:]\n                    self.population = np.delete(self.population, worst_indices, axis=0)\n                    self.fitness = np.delete(self.fitness, worst_indices)\n                    \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDEEARSHADEOL scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0069837e-9fa4-400c-b780-7bc37d356e32"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "d889e6e3-f74a-4e9f-838f-b7ce0cec42d2", "fitness": 0.06659853464107962, "name": "AdaptiveDEEARSHADEOL", "description": "Adaptive Differential Evolution with SHADE, orthogonal learning, archive, elitism, dynamic population size, and a local search to fine-tune promising solutions.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.max_pop_size = 100 # Maximum population size\n        self.population_decay = 0.05 # Rate at which population decays\n        self.local_search_prob = 0.05  # Probability of applying local search\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n            if self.pop_size > self.max_pop_size:\n                self.pop_size = self.max_pop_size\n\n            # SHADE parameter adaptation with improved memory update\n            successful_cr = []\n            successful_f = []\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation strategy with p-best and archive, distance-based parameter\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n\n                # Distance-based mutation parameter\n                distance = np.linalg.norm(self.population[i] - x_pbest)\n                mutation_factor = f_i * (1 + distance)  # Adapt mutation based on distance\n                v = self.population[i] + mutation_factor * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal learning - Reduced intensity\n                if np.random.rand() < 0.05:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + 0.005 * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = np.abs(f_u - self.fitness[i])\n\n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    successful_cr.append(cr_i)  # Store successful CR values\n                    successful_f.append(f_i)  # Store successful F values\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                if self.evals >= self.budget:\n                    break\n            \n            # Local Search\n            if np.random.rand() < self.local_search_prob:\n                best_index = np.argmin(self.fitness)\n                x_local = self.population[best_index].copy()\n                \n                # Perform a simple random perturbation for local search\n                for _ in range(5): # Reduce the number of local search steps for budget\n                    perturbation = np.random.uniform(-0.01, 0.01, size=self.dim) # Smaller perturbation\n                    x_perturbed = x_local + perturbation\n                    x_perturbed = np.clip(x_perturbed, func.bounds.lb, func.bounds.ub)\n                    \n                    f_perturbed = func(x_perturbed)\n                    self.evals += 1\n                    \n                    if f_perturbed < self.fitness[best_index]:\n                        self.population[best_index] = x_perturbed\n                        self.fitness[best_index] = f_perturbed\n                        x_local = x_perturbed # Move the local search point\n                        \n                        if f_perturbed < self.f_opt:\n                            self.f_opt = f_perturbed\n                            self.x_opt = x_perturbed\n                        \n                    if self.evals >= self.budget:\n                        break\n            \n\n            # Update memory for SHADE, using mean of successful values\n            if successful_cr:\n                self.memory_cr[self.memory_idx] = np.mean(successful_cr)\n            if successful_f:\n                self.memory_f[self.memory_idx] = np.mean(successful_f)\n\n            self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n            \n            # Dynamic Population Size Adjustment\n            if self.evals < self.budget:\n                self.pop_size = int(self.pop_size * (1 - self.population_decay))\n                self.pop_size = max(self.min_pop_size, min(self.pop_size, self.max_pop_size)) # Keep within bounds\n\n                if self.pop_size < len(self.population):\n                    # Remove the worst individuals\n                    n_reduce = len(self.population) - self.pop_size\n                    worst_indices = np.argsort(self.fitness)[-n_reduce:]\n                    self.population = np.delete(self.population, worst_indices, axis=0)\n                    self.fitness = np.delete(self.fitness, worst_indices)\n                    \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDEEARSHADEOL scored 0.067 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0069837e-9fa4-400c-b780-7bc37d356e32"], "operator": null, "metadata": {"aucs": [0.13319706928215924, 0]}}
{"id": "b63a35a1-941b-4c11-bb71-21099249fb78", "fitness": 0.28759384682458694, "name": "AdaptiveDEEARSHADEOL", "description": "Adaptive Differential Evolution with SHADE, orthogonal learning, archive, elitism, dynamic population size adjustment based on both stagnation and diversity, and a local search phase to enhance fine-tuning.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.diversity_threshold = 0.1\n        self.stagnation_threshold = 1e-6\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.last_improvement_eval = 0\n        self.previous_best_fitness = np.Inf\n\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation strategy with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal learning\n                if np.random.rand() < 0.1:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + 0.01 * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = np.abs(f_u - self.fitness[i])\n\n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    # Update memory for SHADE\n                    self.memory_cr[self.memory_idx] = cr_i\n                    self.memory_f[self.memory_idx] = f_i\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        self.last_improvement_eval = self.evals\n                        \n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n            \n            # Local Search: Apply local search to the best individual\n            if self.evals - self.last_improvement_eval > self.budget // 10:\n                best_index = np.argmin(self.fitness)\n                x_best = self.population[best_index].copy()\n                f_best = self.fitness[best_index]\n                \n                for _ in range(self.local_search_iterations):\n                    # Generate a small random perturbation\n                    perturbation = np.random.normal(0, 0.01, size=self.dim)\n                    x_perturbed = x_best + perturbation\n                    x_perturbed = np.clip(x_perturbed, func.bounds.lb, func.bounds.ub)\n                    \n                    f_perturbed = func(x_perturbed)\n                    self.evals += 1\n                    \n                    if f_perturbed < f_best:\n                        x_best = x_perturbed\n                        f_best = f_perturbed\n                        self.last_improvement_eval = self.evals\n\n                        if f_best < self.f_opt:\n                            self.f_opt = f_best\n                            self.x_opt = x_best\n\n                    if self.evals >= self.budget:\n                        break\n\n                self.population[best_index] = x_best\n                self.fitness[best_index] = f_best\n\n            # Population reduction based on diversity and stagnation\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                # Calculate diversity (e.g., average distance to centroid)\n                centroid = np.mean(self.population, axis=0)\n                distances = np.linalg.norm(self.population - centroid, axis=1)\n                avg_distance = np.mean(distances)\n\n                # Check for stagnation\n                if np.abs(self.f_opt - self.previous_best_fitness) < self.stagnation_threshold:\n                    stagnation = True\n                else:\n                    stagnation = False\n                self.previous_best_fitness = self.f_opt\n\n\n                if avg_distance < self.diversity_threshold or stagnation:\n                    reduction_rate = 0.2  # Increased reduction rate when diversity is low or stagnating\n                else:\n                    reduction_rate = 0.05 # Reduced reduction rate otherwise\n                    \n                n_reduce = int(self.pop_size * reduction_rate)\n                \n                if n_reduce > 0:\n                    # Remove the worst individuals\n                    worst_indices = np.argsort(self.fitness)[-n_reduce:]\n                    self.population = np.delete(self.population, worst_indices, axis=0)\n                    self.fitness = np.delete(self.fitness, worst_indices)\n                    self.pop_size = len(self.population)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDEEARSHADEOL scored 0.288 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["127a4b46-23ed-44ba-9ba2-37fb88d6a671"], "operator": null, "metadata": {"aucs": [0.1513075472636367, 0.2705418733595032, 0.33518312094268243, 0.569546086362223, 0.39898445301947616, 0]}}
{"id": "fb16d1f6-45d5-4773-bda5-42a29213ec34", "fitness": 0.2707133340505571, "name": "NeighborhoodCMAES", "description": "A CMA-ES variant incorporating a neighborhood-based mutation operator alongside the standard covariance matrix adaptation to enhance exploration and exploitation in complex landscapes.", "code": "import numpy as np\n\nclass NeighborhoodCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5, neighborhood_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize\n        self.neighborhood_size = neighborhood_size\n        self.mu = None\n        self.weights = None\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.eigeneval = 0\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive_x = []\n        self.archive_f = []\n        self.archive_limit = 100\n\n    def initialize(self):\n        # Adapt population size based on dimension, if not specified.\n        self.popsize = self.popsize if self.popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, ((self.mu-1)/(self.dim+1)) - 1) + 2\n        self.c_c = (4 + self.mu/self.dim)**(-1)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n\n    def __call__(self, func):\n        self.func = func\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initialize()\n        self.archive_x = []\n        self.archive_f = []\n\n        while self.evals < self.budget:\n            # Generate lambda offsprings using CMA-ES\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.popsize)\n            x = self.m + self.sigma0 * z\n\n            # Generate lambda offsprings using neighborhood mutation\n            x_neighborhood = np.zeros((self.popsize, self.dim))\n            for i in range(self.popsize):\n                if len(self.archive_x) > 0:\n                    # Select a random solution from the archive\n                    idx = np.random.randint(len(self.archive_x))\n                    x_base = self.archive_x[idx]\n\n                    # Mutate within the neighborhood of the selected solution\n                    x_neighborhood[i] = x_base + np.random.uniform(-self.neighborhood_size, self.neighborhood_size, size=self.dim)\n                else:\n                     # If the archive is empty, generate a random solution\n                    x_neighborhood[i] = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=self.dim)\n\n            # Combine CMA-ES and neighborhood offsprings\n            x_combined = np.concatenate((x, x_neighborhood))\n            f_combined = np.zeros(2 * self.popsize)\n\n            # Evaluate the offsprings\n            for i in range(2 * self.popsize):\n                x_combined[i] = np.clip(x_combined[i], self.func.bounds.lb, self.func.bounds.ub)\n                f_combined[i] = func(x_combined[i])\n                self.evals += 1\n                if f_combined[i] < self.f_opt:\n                    self.f_opt = f_combined[i]\n                    self.x_opt = x_combined[i]\n                    \n                if self.evals >= self.budget:\n                    break\n\n            if self.evals >= self.budget:\n                break\n\n            # Selection and recombination\n            idx = np.argsort(f_combined)[:self.mu]\n            x_mu = x_combined[idx]\n            f_mu = f_combined[idx]\n\n            # Update archive\n            for i in range(len(f_mu)):\n                if len(self.archive_x) < self.archive_limit:\n                    self.archive_x.append(x_mu[i])\n                    self.archive_f.append(f_mu[i])\n                else: #Replace the worst\n                    max_archive_index = np.argmax(self.archive_f)\n                    if f_mu[i] < self.archive_f[max_archive_index]:\n                        self.archive_x[max_archive_index] = x_mu[i]\n                        self.archive_f[max_archive_index] = f_mu[i]\n\n            self.m = np.mean(x_mu, axis=0)\n\n            # Covariance matrix adaptation (standard CMA-ES)\n            z_mu = (x_mu - self.m) / self.sigma0\n            zmean = np.mean(z_mu, axis=0)\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            if np.sum(self.ps**2) / self.dim > self.d_sigma**2:\n                self.sigma0 *= np.exp(0.2 + self.c_sigma / self.d_sigma)\n            else:\n                self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * ((np.sum(self.ps**2) / self.dim) - 1) / 2)\n            \n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - np.mean(x_mu, axis=0)) / self.sigma0 #Modified\n            \n            delta = z_mu - np.zeros(self.dim)\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * (delta[k,:][:, None] @ delta[k,:][None, :])\n\n            # Regularize covariance matrix\n            min_eig = np.min(np.linalg.eigvalsh(self.C))\n            if min_eig < 0:\n                self.C += (abs(min_eig) + 1e-10) * np.eye(self.dim)\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm NeighborhoodCMAES scored 0.271 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b2c2dae3-5143-4026-ab7b-86049d2bf1a2"], "operator": null, "metadata": {"aucs": [0.12942201343281412, 0.2274151222107812, 0.27660491627398676, 0.15385858644548556, 0.18777897972842783, 0.5089211193484653, 0.25345643040073973, 0.18545776086964183, 0.18254522396907136, 0.20194089425623207, 0.512341649818254, 0.20993041339299046, 0.2522170836485379, 0.2039609331729647, 0.5048119990067464, 0.3073809844293679, 0.23654657488602793, 0.2523522057205776, 0.1625144138522706, 0.4648093761477571]}}
{"id": "23258f3c-e72a-4566-93b3-5cf12cb0ea78", "fitness": 0.5528920957341918, "name": "AdaptivePSO_SHADE", "description": "An adaptive population-based algorithm that integrates a simplified variant of Particle Swarm Optimization (PSO) for local refinement, along with SHADE for global exploration, and dynamically adjusts the balance between exploration and exploitation based on population diversity.", "code": "import numpy as np\n\nclass AdaptivePSO_SHADE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10, w_init=0.9, w_final=0.4, c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1\n        self.w_init = w_init\n        self.w_final = w_final\n        self.c1 = c1\n        self.c2 = c2\n        self.min_pop_size = 4\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            # Calculate diversity (e.g., average distance to centroid)\n            centroid = np.mean(self.population, axis=0)\n            distances = np.linalg.norm(self.population - centroid, axis=1)\n            avg_distance = np.mean(distances)\n            \n            # Adaptive Exploration/Exploitation Balance\n            if avg_distance < self.diversity_threshold:\n                use_pso = True  # Low diversity: emphasize local search (PSO)\n            else:\n                use_pso = False # High diversity: emphasize global search (SHADE)\n                \n            for i in range(self.pop_size):\n                if use_pso:\n                    # PSO Update\n                    w = self.w_init - (self.w_init - self.w_final) * (self.evals / self.budget)  # Inertia weight decay\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    self.velocities[i] = w * self.velocities[i] + \\\n                                        self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) + \\\n                                        self.c2 * r2 * (self.x_opt - self.population[i])  # x_opt is global best so far\n                    \n                    new_position = self.population[i] + self.velocities[i]\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                else:\n                    # SHADE Update\n                    cr_i = np.random.choice(self.memory_cr)\n                    f_i = np.random.choice(self.memory_f)\n                    f_i = np.clip(f_i, 0.0, 1.0)\n\n                    p_best_count = max(int(self.p * self.pop_size), 1)\n                    p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                    x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                    candidates = list(range(self.pop_size))\n                    candidates.remove(i)\n\n                    use_archive = np.random.rand() < 0.1\n                    if len(self.archive) > 0 and use_archive:\n                        a = np.random.choice(len(self.archive))\n                        x_r1 = self.archive[a]\n                    else:\n                        np.random.shuffle(candidates)\n                        x_r1 = self.population[candidates[0]]\n\n                    x_r2 = self.population[np.random.choice(candidates)]\n                    v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                    new_position = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                    j_rand = np.random.randint(self.dim)\n                    u = np.zeros(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < cr_i or j == j_rand:\n                            u[j] = new_position[j]\n                        else:\n                            u[j] = self.population[i, j]\n                    new_position = u\n\n                # Evaluation\n                f_new = func(new_position)\n                self.evals += 1\n\n                # Selection\n                if f_new < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = new_position\n                    self.fitness[i] = f_new\n\n                    if use_pso == False: # Only update memory if SHADE was used\n                        self.memory_cr[self.memory_idx] = cr_i\n                        self.memory_f[self.memory_idx] = f_i\n                        self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                    \n                    # Update personal best\n                    if f_new < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_new\n                        self.personal_best_positions[i] = new_position.copy()\n\n                    # Update global best\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = new_position\n\n                if self.evals >= self.budget:\n                    break\n\n            # Population reduction based on diversity\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                if avg_distance < self.diversity_threshold:\n                    reduction_rate = 0.2\n                else:\n                    reduction_rate = 0.05\n                n_reduce = int(self.pop_size * reduction_rate)\n\n                if n_reduce > 0:\n                    worst_indices = np.argsort(self.fitness)[-n_reduce:]\n                    self.population = np.delete(self.population, worst_indices, axis=0)\n                    self.fitness = np.delete(self.fitness, worst_indices)\n                    self.personal_best_positions = np.delete(self.personal_best_positions, worst_indices, axis=0)\n                    self.personal_best_fitness = np.delete(self.personal_best_fitness, worst_indices)\n                    self.velocities = np.delete(self.velocities, worst_indices, axis=0)\n                    self.pop_size = len(self.population)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptivePSO_SHADE scored 0.553 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["127a4b46-23ed-44ba-9ba2-37fb88d6a671"], "operator": null, "metadata": {"aucs": [0.2928852848404666, 0.472997400034726, 0.391135186890329, 0.9411002913783212, 0.49519701848523046, 0.459416946642359, 0.4861793046587283, 0.37456442554118086, 0.503970390524525, 0.375894694499991, 0.9354717361985015, 0.9989981140363133, 0.477077999846386, 0.5016546863359813, 0.940222267048939, 0.6408843911355532, 0.38483352937675186, 0.650273328702434, 0.22756141870503932, 0.5075234998020764]}}
{"id": "e2b0f382-8736-46ab-8d98-b508440811f2", "fitness": 0.6636085729680705, "name": "AdaptiveDEEARSHADEOL", "description": "Adaptive Differential Evolution with SHADE, orthogonal learning, archive, elitism, L-SHADE inspired population reduction, and a diversity-based restart mechanism.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=5, local_search_probability=0.05, reduce_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_CR = np.full(self.memory_size, 0.5)\n        self.memory_F = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.archive = []\n        self.local_search_probability = local_search_probability\n        self.elite_ratio = 0.1\n        self.reduce_factor = reduce_factor  # Population reduction factor\n        self.min_pop_size = 10  # Minimum population size\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 5000 # Stagnation Threshold\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.best_fitness_history = []\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n\n        while self.evals < self.budget:\n            \n            ranked_indices = np.argsort(self.fitness)\n            p_best_indices = ranked_indices[:max(1, int(self.p * self.pop_size))]\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                mem_idx = np.random.randint(self.memory_size)\n                CRm = self.memory_CR[mem_idx]\n                Fm = self.memory_F[mem_idx]\n\n                CR = np.random.normal(CRm, 0.1)\n                CR = np.clip(CR, 0.0, 1.0)\n                \n                F = np.random.normal(Fm, 0.1)\n                while F <= 0:\n                    F = np.random.normal(Fm, 0.1)\n                F = np.clip(F, 0.1, 1.0)\n\n\n                # Mutation\n                p_best_idx = np.random.choice(p_best_indices)\n                x_pbest = self.population[p_best_idx]\n                \n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                np.random.shuffle(candidates)\n                x_r1 = self.population[candidates[0]]\n                \n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    x_r2 = self.archive[arc_idx]\n                else:\n                    x_r2 = self.population[candidates[1]]\n\n                v = self.population[i] + F * (x_pbest - self.population[i]) + F * (x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal Learning\n                if np.random.rand() < 0.1:\n                    H = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim, self.dim))\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n                \n                if f_u < self.fitness[i]:\n                    # Local Search\n                    if np.random.rand() < self.local_search_probability:\n                        step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                        u_local = u + np.random.normal(0, step_size, size=self.dim)\n                        u_local = np.clip(u_local, func.bounds.lb, func.bounds.ub)\n                        f_u_local = func(u_local)\n                        self.evals += 1\n                        if f_u_local < f_u:\n                            f_u = f_u_local\n                            u = u_local\n                    \n                    # Update Memory\n                    self.memory_CR[self.memory_idx] = CR\n                    self.memory_F[self.memory_idx] = F\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                    # Update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    # Update population\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n\n            worst_pop_index = np.argmax(self.fitness)\n\n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n\n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n            \n            #Stagnation Check\n            if len(self.best_fitness_history) > 0 and self.f_opt >= self.best_fitness_history[-1]:\n                  self.stagnation_counter += self.pop_size\n            else:\n                  self.stagnation_counter = 0\n            \n            self.best_fitness_history.append(self.f_opt)\n            \n            # Population Reduction (L-SHADE inspired)\n            if self.stagnation_counter > self.stagnation_threshold and self.pop_size > self.min_pop_size:\n                reduction_amount = max(int(self.initial_pop_size * (1 - self.reduce_factor)), self.min_pop_size) #Ensure pop_size doesnt fall below min_pop_size\n\n                if (self.pop_size - reduction_amount) < self.min_pop_size:\n                    reduction_amount = self.pop_size - self.min_pop_size\n                \n                if reduction_amount > 0: # only reduce if there is something to reduce\n                  \n                  indices_to_remove = np.argsort(self.fitness)[-reduction_amount:]\n                  self.population = np.delete(self.population, indices_to_remove, axis=0)\n                  self.fitness = np.delete(self.fitness, indices_to_remove)\n                  self.pop_size = self.population.shape[0]\n                  self.stagnation_counter = 0 # Reset stagnation counter\n\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDEEARSHADEOL scored 0.664 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["023f3482-b732-430a-b5fe-d7ef2f700c24"], "operator": null, "metadata": {"aucs": [0.20776734217395465, 0.72062919112093, 0.7013024731185555, 0.8897144783687434, 0.6687984602512612, 0.8072448404818547, 0.34436567061370593, 0.7082577815139142, 0.7739975761356225, 0.3410654632996183, 0.8883709807731794, 0.9916210686235654, 0.7237122046650135, 0.7126783023795845, 0.9159726186874916, 0.7566482758324744, 0.4907196076544019, 0.8708355612760305, 0.2582351032925101, 0.5002344590989989]}}
{"id": "7f7e8755-4246-47f3-b1e3-b16d2917e0b3", "fitness": 0.5849376005901008, "name": "AdaptiveDEEARSHADEOL", "description": "Adaptive Differential Evolution with SHADE, orthogonal learning, archive, elitism, dynamic population size adjustment based on both diversity and stagnation detection, and improved parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10, stagnation_window=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.diversity_threshold = 0.1\n        self.stagnation_window = stagnation_window\n        self.fitness_history = np.full(self.stagnation_window, np.inf)\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation strategy with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal learning\n                if np.random.rand() < 0.1:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + 0.01 * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = np.abs(f_u - self.fitness[i])\n\n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    # Update memory for SHADE\n                    self.memory_cr[self.memory_idx] = cr_i\n                    self.memory_f[self.memory_idx] = f_i\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Population reduction based on diversity\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                # Calculate diversity (e.g., average distance to centroid)\n                centroid = np.mean(self.population, axis=0)\n                distances = np.linalg.norm(self.population - centroid, axis=1)\n                avg_distance = np.mean(distances)\n\n                # Stagnation Detection\n                self.fitness_history[self.stagnation_counter % self.stagnation_window] = self.f_opt\n                self.stagnation_counter += 1\n                stagnation = np.std(self.fitness_history) < 1e-8 # Check if fitness has stagnated\n\n                if avg_distance < self.diversity_threshold or stagnation:\n                    reduction_rate = 0.2  # Increased reduction rate when diversity is low or stagnation detected\n                    if stagnation:\n                        self.stagnation_counter = 0 # Reset stagnation counter\n                else:\n                    reduction_rate = 0.05 # Reduced reduction rate otherwise\n                    \n                n_reduce = int(self.pop_size * reduction_rate)\n                \n                if n_reduce > 0:\n                    # Remove the worst individuals\n                    worst_indices = np.argsort(self.fitness)[-n_reduce:]\n                    self.population = np.delete(self.population, worst_indices, axis=0)\n                    self.fitness = np.delete(self.fitness, worst_indices)\n                    self.pop_size = len(self.population)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDEEARSHADEOL scored 0.585 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["127a4b46-23ed-44ba-9ba2-37fb88d6a671"], "operator": null, "metadata": {"aucs": [0.22305987753321233, 0.6231135922684303, 0.43386915682794125, 0.9349577884501952, 0.3569985850759394, 0.5157487937395719, 0.6534924917772666, 0.43657683766936695, 0.46217326623360155, 0.7738682793492324, 0.9327080817548952, 0.9960945259198986, 0.3512672190635421, 0.7536734013101738, 0.9234691154580579, 0.4587848612542025, 0.44538202076275857, 0.6856535377408605, 0.23613342712500618, 0.5017271524878634]}}
{"id": "6365b114-4cdc-491a-9cf3-002e4408433d", "fitness": 0.0, "name": "AdaptiveDEEARSHADEOL", "description": "Adaptive Differential Evolution with enhanced exploration, adaptive archive management, and a more robust orthogonal learning strategy with dynamic population size adjustment based on a restart mechanism.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.max_pop_size = 100  # Maximum population size\n        self.population_decay = 0.05  # Rate at which population decays\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 5000 # Number of evaluations without improvement before restart\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.best_fitness_history = []\n        self.best_fitness_history.append(np.min(self.fitness))\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n            if self.pop_size > self.max_pop_size:\n                self.pop_size = self.max_pop_size\n\n            # SHADE parameter adaptation with improved memory update\n            successful_cr = []\n            successful_f = []\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n\n                # Mutation strategy with p-best and archive, distance-based parameter\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.2  # Increased archive usage\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n\n                x_r2 = self.population[np.random.choice(candidates)]\n\n                # Distance-based mutation parameter - Enhanced Exploration\n                distance = np.linalg.norm(self.population[i] - x_pbest)\n                mutation_factor = f_i * (1 + 0.5 * distance)  # Adapt mutation based on distance, reduced factor\n                v = self.population[i] + mutation_factor * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal learning - Adaptive intensity\n                ol_prob = 0.1  # Adjust probability\n                if np.random.rand() < ol_prob:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    ol_intensity = 0.01 * (1 - (self.evals / self.budget))  # Reduce intensity over time\n                    u = self.population[i] + ol_intensity * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = np.abs(f_u - self.fitness[i])\n\n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        # Adaptive archive management: Remove the oldest or the worst\n                        if np.random.rand() < 0.5:\n                            self.archive.pop(0)  # Remove oldest\n                        else:\n                            worst_archive_index = np.argmax([func(x) for x in self.archive])\n                            self.archive.pop(worst_archive_index)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    successful_cr.append(cr_i)  # Store successful CR values\n                    successful_f.append(f_i)  # Store successful F values\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        self.stagnation_counter = 0 # Reset counter when improvement occurs\n                else:\n                    self.stagnation_counter += 1 # Increment counter when no improvement\n\n                if self.evals >= self.budget:\n                    break\n\n            # Update memory for SHADE, using mean of successful values\n            if successful_cr:\n                self.memory_cr[self.memory_idx] = np.mean(successful_cr)\n            if successful_f:\n                self.memory_f[self.memory_idx] = np.mean(successful_f)\n\n            self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n\n            worst_pop_index = np.argmax(self.fitness)\n\n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n\n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Dynamic Population Size Adjustment\n            if self.evals < self.budget:\n                self.pop_size = int(self.pop_size * (1 - self.population_decay))\n                self.pop_size = max(self.min_pop_size, min(self.pop_size, self.max_pop_size))  # Keep within bounds\n\n                if self.pop_size < len(self.population):\n                    # Remove the worst individuals\n                    n_reduce = len(self.population) - self.pop_size\n                    worst_indices = np.argsort(self.fitness)[-n_reduce:]\n                    self.population = np.delete(self.population, worst_indices, axis=0)\n                    self.fitness = np.delete(self.fitness, worst_indices)\n\n            #Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.stagnation_counter = 0\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.memory_cr = np.full(self.memory_size, 0.5)\n                self.memory_f = np.full(self.memory_size, 0.5)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDEEARSHADEOL scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0069837e-9fa4-400c-b780-7bc37d356e32"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "0207d0f1-c134-407f-9bac-8af7d4fd6ec5", "fitness": 0.35805847151186265, "name": "AdaptiveDEEARSHADEOL", "description": "Adaptive Differential Evolution with SHADE, orthogonal learning, archive, elitism and improved population reduction using a combination of fitness and distance-based criteria, and enhanced parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.diversity_threshold = 0.1\n        self.cr_learning_rate = 0.2\n        self.f_learning_rate = 0.2\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.success_cr = []\n        self.success_f = []\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation strategy with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal learning\n                if np.random.rand() < 0.1:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + 0.01 * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = f_u - self.fitness[i]  # Original delta_f calculation\n\n                if f_u < self.fitness[i]:\n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Update memory for SHADE\n            if self.success_cr and self.success_f:\n                mean_cr = np.mean(self.success_cr)\n                mean_f = np.mean(self.success_f)\n\n                self.memory_cr[self.memory_idx] = (1 - self.cr_learning_rate) * self.memory_cr[self.memory_idx] + self.cr_learning_rate * mean_cr\n                self.memory_f[self.memory_idx] = (1 - self.f_learning_rate) * self.memory_f[self.memory_idx] + self.f_learning_rate * mean_f\n\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_cr = []\n                self.success_f = []\n\n\n            # Population reduction based on diversity and fitness\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                # Calculate diversity (e.g., average distance to centroid)\n                centroid = np.mean(self.population, axis=0)\n                distances = np.linalg.norm(self.population - centroid, axis=1)\n                avg_distance = np.mean(distances)\n\n                # Normalize distances and fitness values\n                normalized_distances = distances / np.max(distances) if np.max(distances) > 0 else np.zeros_like(distances)\n                normalized_fitness = (self.fitness - np.min(self.fitness)) / (np.max(self.fitness) - np.min(self.fitness)) if np.max(self.fitness) > np.min(self.fitness) else np.zeros_like(self.fitness)\n\n                # Combine distance and fitness for removal probability\n                removal_probability = normalized_distances + normalized_fitness\n                removal_probability /= np.sum(removal_probability) # Normalize to a probability distribution\n\n                n_reduce = int(self.pop_size * 0.2) # Reduce 20% of the population at most\n\n                # Select individuals for removal based on the combined probability\n                indices_to_remove = np.random.choice(self.pop_size, size=n_reduce, replace=False, p=removal_probability)\n                \n                # Remove selected individuals\n                self.population = np.delete(self.population, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size = len(self.population)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDEEARSHADEOL scored 0.358 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["127a4b46-23ed-44ba-9ba2-37fb88d6a671"], "operator": null, "metadata": {"aucs": [0.14507638054512684, 0.2214805763183867, 0.3031271014497936, 0.2163560765933389, 0.3804739910837108, 0.43704963467641844, 0.27657973480578335, 0.28004697782488264, 0.25412243609887897, 0.5224590317046471, 0.3048446630305638, 1.0, 0.2793016456639441, 0.25836742025264836, 0.6578537237810864, 0.28968416682716447, 0.30631199789486796, 0.3028274136965454, 0.25941253556760524, 0.46579392242185946]}}
{"id": "eb4233fa-dab3-4002-84ee-2348d7265228", "fitness": -Infinity, "name": "AdaptivePSO_CMAES", "description": "Combines the strengths of PSO and CMA-ES by using PSO for initial exploration and CMA-ES for exploitation, adaptively switching between them based on stagnation detection and a diversity measure.", "code": "import numpy as np\nimport cma\n\nclass AdaptivePSO_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=40, w_init=0.9, w_final=0.4, c1=2.0, c2=2.0, stagnation_threshold=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_final = w_final\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.pso_phase = True\n        self.stagnation_counter = 0\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.evals = self.pop_size\n        self.best_fitness_history = []\n\n        while self.evals < self.budget:\n            # Calculate diversity (e.g., average distance to centroid)\n            centroid = np.mean(self.population, axis=0)\n            distances = np.linalg.norm(self.population - centroid, axis=1)\n            avg_distance = np.mean(distances)\n\n            # Stagnation Detection\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                self.best_fitness_history.pop(0)\n                if np.std(self.best_fitness_history) < 1e-6:\n                    self.stagnation_counter += 1\n                else:\n                    self.stagnation_counter = 0\n\n            # Adaptive Strategy Selection\n            if self.stagnation_counter >= self.stagnation_threshold or avg_distance < self.diversity_threshold:\n                self.pso_phase = False  # Switch to CMA-ES if stagnated or low diversity\n            else:\n                self.pso_phase = True   # Otherwise, stay in PSO phase\n\n            if self.pso_phase:\n                # PSO Update\n                for i in range(self.pop_size):\n                    w = self.w_init - (self.w_init - self.w_final) * (self.evals / self.budget)\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    self.velocities[i] = w * self.velocities[i] + \\\n                                        self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) + \\\n                                        self.c2 * r2 * (self.x_opt - self.population[i])\n\n                    new_position = self.population[i] + self.velocities[i]\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                    f_new = func(new_position)\n                    self.evals += 1\n\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_position\n                        self.fitness[i] = f_new\n\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = new_position.copy()\n\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = new_position\n            else:\n                # CMA-ES Update\n                x0 = self.x_opt  # Start CMA-ES from the current best solution\n                sigma = 0.5      # Initial step size\n                es = cma.PureCMAES(x0, sigma, bounds=[func.bounds.lb, func.bounds.ub])\n                \n                while self.evals < self.budget and not es.stop():\n                    solutions = []\n                    for _ in range(es.population_size):\n                        x = es.ask()\n                        f = func(x)\n                        solutions.append((x, f))\n                        self.evals += 1\n                        if f < self.f_opt:\n                            self.f_opt = f\n                            self.x_opt = x\n                            \n                    es.tell([x for x, _ in solutions], [f for _, f in solutions]) # Pass fitness back to ES\n\n            if self.evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occurred: No module named 'cma'.", "error": "", "parent_ids": ["23258f3c-e72a-4566-93b3-5cf12cb0ea78"], "operator": null, "metadata": {}}
{"id": "90a7e9e4-703c-4408-96a2-88b271a127a6", "fitness": -Infinity, "name": "SOM_SHADE_DE", "description": "Differential Evolution with SHADE-inspired adaptation, a self-organizing map (SOM) for population diversity management, and a local search refinement step.", "code": "import numpy as np\nfrom minisom import MiniSom\n\nclass SOM_SHADE_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, memory_size=10, som_grid_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1\n        self.som_grid_size = som_grid_size\n        self.som = MiniSom(som_grid_size, som_grid_size, dim, sigma=0.3, learning_rate=0.5)\n        self.elite_ratio = 0.1\n        self.min_pop_size = 4\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n        \n        self.som.train(self.population, num_iteration=100) # Train SOM initially\n        \n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n            \n            # Adapt population based on SOM\n            new_population = []\n            new_fitness = []\n            \n            # Distribute individuals according to SOM clustering\n            clusters = [[] for _ in range(self.som_grid_size * self.som_grid_size)]\n            for i in range(self.pop_size):\n                winner = self.som.winner(self.population[i])\n                winner_idx = np.ravel_multi_index(winner, (self.som_grid_size, self.som_grid_size))\n                clusters[winner_idx].append(i)\n            \n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n\n                # Mutation\n                p_best_count = max(int(self.p * self.pop_size), 1)\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                np.random.shuffle(candidates)\n                x_r1 = self.population[candidates[0]]\n                \n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r2 = self.archive[a]\n                else:\n                    x_r2 = self.population[candidates[1]]\n                    \n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Local search refinement\n                if np.random.rand() < 0.05:  # Apply local search with a small probability\n                    step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                    u = u + np.random.uniform(-step_size, step_size, size=self.dim)\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = np.abs(f_u - self.fitness[i])\n                \n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    self.memory_cr[self.memory_idx] = cr_i\n                    self.memory_f[self.memory_idx] = f_i\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n            \n            # Elitism\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n\n            worst_pop_index = np.argmax(self.fitness)\n\n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n\n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n            \n            # Retrain SOM every iteration\n            self.som.train(self.population, num_iteration=50, verbose=False)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occurred: No module named 'minisom'.", "error": "", "parent_ids": ["7f7e8755-4246-47f3-b1e3-b16d2917e0b3"], "operator": null, "metadata": {}}
{"id": "8dd2ba65-6a5f-4f2f-9ab7-5b88aaefa26b", "fitness": -Infinity, "name": "ClusteredAdaptiveDE", "description": "Differential Evolution with self-adaptive parameters, a clustering-based population diversity maintenance strategy, and a local search operator.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass ClusteredAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10, num_clusters=5, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.num_clusters = num_clusters\n        self.local_search_iterations = local_search_iterations\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Adaptive DE parameters\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n\n                # Mutation\n                p_best_count = max(int(self.p * self.pop_size), 1)\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                np.random.shuffle(candidates)\n                x_r1 = self.population[candidates[0]]\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r2 = self.archive[a]\n                else:\n                    x_r2 = self.population[candidates[1]]\n\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Local Search\n                if np.random.rand() < 0.1:\n                  u = self.local_search(u, func, func.bounds.lb, func.bounds.ub)\n\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    # Update memory\n                    self.memory_cr[self.memory_idx] = cr_i\n                    self.memory_f[self.memory_idx] = f_i\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n            \n            # Diversity Maintenance using Clustering\n            if self.evals < self.budget:\n                self.maintain_diversity()\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func, lb, ub, step_size=0.01):\n      x_curr = x.copy()\n      f_curr = func(x_curr)\n      self.evals+=1\n\n      for _ in range(self.local_search_iterations):\n          for i in range(self.dim):\n              # Explore positive direction\n              x_new_pos = x_curr.copy()\n              x_new_pos[i] += step_size\n              x_new_pos = np.clip(x_new_pos, lb, ub)\n              f_new_pos = func(x_new_pos)\n              self.evals+=1\n\n              # Explore negative direction\n              x_new_neg = x_curr.copy()\n              x_new_neg[i] -= step_size\n              x_new_neg = np.clip(x_new_neg, lb, ub)\n              f_new_neg = func(x_new_neg)\n              self.evals+=1\n\n              if f_new_pos < f_curr:\n                  f_curr = f_new_pos\n                  x_curr = x_new_pos\n              elif f_new_neg < f_curr:\n                  f_curr = f_new_neg\n                  x_curr = x_new_neg\n\n              if self.evals >= self.budget:\n                break\n          if self.evals >= self.budget:\n            break\n      return x_curr\n\n    def maintain_diversity(self):\n        \"\"\"Maintains population diversity by re-initializing the worst individual in each cluster.\"\"\"\n        kmeans = KMeans(n_clusters=self.num_clusters, random_state=0, n_init=\"auto\").fit(self.population)\n        cluster_labels = kmeans.labels_\n\n        for cluster_id in range(self.num_clusters):\n            cluster_indices = np.where(cluster_labels == cluster_id)[0]\n            if len(cluster_indices) > 0:\n                # Find the worst individual in the cluster\n                fitness_values = self.fitness[cluster_indices]\n                worst_index_in_cluster = np.argmax(fitness_values)\n                worst_individual_index = cluster_indices[worst_index_in_cluster]\n\n                # Re-initialize the worst individual\n                self.population[worst_individual_index] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.fitness[worst_individual_index] = func(self.population[worst_individual_index])\n                self.evals += 1\n                \n                if self.fitness[worst_individual_index] < self.f_opt:\n                    self.f_opt = self.fitness[worst_individual_index]\n                    self.x_opt = self.population[worst_individual_index]", "configspace": "", "generation": 6, "feedback": "An exception occurred: name 'KMeans' is not defined.", "error": "", "parent_ids": ["7f7e8755-4246-47f3-b1e3-b16d2917e0b3"], "operator": null, "metadata": {}}
{"id": "d1d55a71-53ab-45dd-b2cb-b0255fac18a3", "fitness": -Infinity, "name": "AdaptiveDEEARSHADEOL", "description": "Adaptive Differential Evolution with SHADE, orthogonal learning, archive, elitism, dynamic population size adjustment based on both diversity and stagnation, improved parameter adaptation and a more aggressive strategy for population reduction upon stagnation or low diversity.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10, stagnation_window=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.diversity_threshold = 0.1\n        self.stagnation_window = stagnation_window\n        self.fitness_history = np.full(self.stagnation_window, np.inf)\n        self.stagnation_counter = 0\n        self.success_cr = []\n        self.success_f = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation strategy with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal learning\n                if np.random.rand() < 0.1:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + 0.01 * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = np.abs(f_u - self.fitness[i])\n\n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n                    \n                    if len(self.success_cr) > 10:\n                        self.success_cr.pop(0)\n                        self.success_f.pop(0)\n                    \n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                if self.evals >= self.budget:\n                    break\n\n            # Update memory for SHADE\n            if self.success_cr and self.success_f:\n                self.memory_cr[self.memory_idx] = np.mean(self.success_cr)\n                self.memory_f[self.memory_idx] = np.mean(self.success_f)\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n            self.success_cr = []\n            self.success_f = []\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Population reduction based on diversity\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                # Calculate diversity (e.g., average distance to centroid)\n                centroid = np.mean(self.population, axis=0)\n                distances = np.linalg.norm(self.population - centroid, axis=1)\n                avg_distance = np.mean(distances)\n\n                # Stagnation Detection\n                self.fitness_history[self.stagnation_counter % self.stagnation_window] = self.f_opt\n                self.stagnation_counter += 1\n                stagnation = np.std(self.fitness_history) < 1e-8 # Check if fitness has stagnated\n\n                if avg_distance < self.diversity_threshold or stagnation:\n                    reduction_rate = 0.5  # Increased reduction rate when diversity is low or stagnation detected\n                    if stagnation:\n                        self.stagnation_counter = 0 # Reset stagnation counter\n                else:\n                    reduction_rate = 0.05 # Reduced reduction rate otherwise\n                    \n                n_reduce = int(self.pop_size * reduction_rate)\n                \n                if n_reduce > 0:\n                    # Remove the worst individuals\n                    worst_indices = np.argsort(self.fitness)[-n_reduce:]\n                    self.population = np.delete(self.population, worst_indices, axis=0)\n                    self.fitness = np.delete(self.fitness, worst_indices)\n                    self.pop_size = len(self.population)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occurred: index 3 is out of bounds for axis 0 with size 3.", "error": "", "parent_ids": ["7f7e8755-4246-47f3-b1e3-b16d2917e0b3"], "operator": null, "metadata": {}}
{"id": "cf16b339-aa31-4c44-aaa7-4bbcf1ec40f7", "fitness": -Infinity, "name": "AdaptiveDEEARSHADEOL", "description": "Adaptive Differential Evolution with SHADE, orthogonal learning, archive, elitism, L-SHADE inspired population reduction with adaptive scaling factor, diversity-based restart and orthogonal crossover.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=5, local_search_probability=0.05, reduce_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_CR = np.full(self.memory_size, 0.5)\n        self.memory_F = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.archive = []\n        self.local_search_probability = local_search_probability\n        self.elite_ratio = 0.1\n        self.reduce_factor = reduce_factor  # Population reduction factor\n        self.min_pop_size = 10  # Minimum population size\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 5000 # Stagnation Threshold\n        self.population_scaling_factor = 0.1 # Scaling for population size adjustment\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.best_fitness_history = []\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n\n        while self.evals < self.budget:\n            \n            ranked_indices = np.argsort(self.fitness)\n            p_best_indices = ranked_indices[:max(1, int(self.p * self.pop_size))]\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                mem_idx = np.random.randint(self.memory_size)\n                CRm = self.memory_CR[mem_idx]\n                Fm = self.memory_F[mem_idx]\n\n                CR = np.random.normal(CRm, 0.1)\n                CR = np.clip(CR, 0.0, 1.0)\n                \n                F = np.random.normal(Fm, 0.1)\n                while F <= 0:\n                    F = np.random.normal(Fm, 0.1)\n                F = np.clip(F, 0.1, 1.0)\n\n\n                # Mutation\n                p_best_idx = np.random.choice(p_best_indices)\n                x_pbest = self.population[p_best_idx]\n                \n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                np.random.shuffle(candidates)\n                x_r1 = self.population[candidates[0]]\n                \n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    x_r2 = self.archive[arc_idx]\n                else:\n                    x_r2 = self.population[candidates[1]]\n\n                v = self.population[i] + F * (x_pbest - self.population[i]) + F * (x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal Crossover\n                if np.random.rand() < 0.1:\n                  indices = np.random.choice(self.dim, size=min(3, self.dim), replace=False)\n                  H = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(len(indices), len(indices)))\n                  Q, R = np.linalg.qr(H)\n                  diff = u[indices] - self.population[i, indices]\n                  u[indices] = self.population[i, indices] + np.dot(Q, diff)\n                  u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n                \n                if f_u < self.fitness[i]:\n                    # Local Search\n                    if np.random.rand() < self.local_search_probability:\n                        step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                        u_local = u + np.random.normal(0, step_size, size=self.dim)\n                        u_local = np.clip(u_local, func.bounds.lb, func.bounds.ub)\n                        f_u_local = func(u_local)\n                        self.evals += 1\n                        if f_u_local < f_u:\n                            f_u = f_u_local\n                            u = u_local\n                    \n                    # Update Memory\n                    self.memory_CR[self.memory_idx] = CR\n                    self.memory_F[self.memory_idx] = F\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                    # Update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    # Update population\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n\n            worst_pop_index = np.argmax(self.fitness)\n\n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n\n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n            \n            #Stagnation Check\n            if len(self.best_fitness_history) > 0 and self.f_opt >= self.best_fitness_history[-1]:\n                  self.stagnation_counter += self.pop_size\n            else:\n                  self.stagnation_counter = 0\n            \n            self.best_fitness_history.append(self.f_opt)\n            \n            # Population Reduction (L-SHADE inspired)\n            if self.stagnation_counter > self.stagnation_threshold and self.pop_size > self.min_pop_size:\n                reduction_amount = max(int(self.initial_pop_size * (1 - self.reduce_factor)), self.min_pop_size) #Ensure pop_size doesnt fall below min_pop_size\n\n                if (self.pop_size - reduction_amount) < self.min_pop_size:\n                    reduction_amount = self.pop_size - self.min_pop_size\n                \n                if reduction_amount > 0: # only reduce if there is something to reduce\n                  \n                  indices_to_remove = np.argsort(self.fitness)[-reduction_amount:]\n                  self.population = np.delete(self.population, indices_to_remove, axis=0)\n                  self.fitness = np.delete(self.fitness, indices_to_remove)\n                  self.pop_size = self.population.shape[0]\n                  self.stagnation_counter = 0 # Reset stagnation counter\n\n            # Population size adaptation\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.pop_size = min(self.initial_pop_size, int(self.pop_size * (1 + self.population_scaling_factor)))\n                self.population = np.vstack((self.population, np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - self.population.shape[0], self.dim))))\n                self.fitness = np.concatenate((self.fitness, np.array([func(x) for x in self.population[self.fitness.shape[0]:]])))\n                self.evals += (self.pop_size - self.fitness.shape[0])\n\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occurred: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (3, 3) and arg 1 with shape (5,)..", "error": "", "parent_ids": ["e2b0f382-8736-46ab-8d98-b508440811f2"], "operator": null, "metadata": {}}
{"id": "8c172fb6-c5ec-45d9-962a-b5287c4d066d", "fitness": -Infinity, "name": "AdaptiveDEEARSHADEOL", "description": "Adaptive Differential Evolution with SHADE, orthogonal learning, archive, elitism, dynamic population size adjustment based on both diversity and stagnation detection, improved parameter adaptation, and a local search phase using Nelder-Mead simplex algorithm.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.diversity_threshold = 0.1\n        self.cr_learning_rate = 0.2\n        self.f_learning_rate = 0.2\n        self.stagnation_limit = 50  # Number of iterations without improvement before stagnation is detected\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.success_cr = []\n        self.success_f = []\n        self.stagnation_counter = 0\n        self.last_improvement = 0\n\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation strategy with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal learning\n                if np.random.rand() < 0.1:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + 0.01 * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = f_u - self.fitness[i]  # Original delta_f calculation\n\n                if f_u < self.fitness[i]:\n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                        self.last_improvement = self.evals\n                else:\n                    self.stagnation_counter += 1\n                        \n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Update memory for SHADE\n            if self.success_cr and self.success_f:\n                mean_cr = np.mean(self.success_cr)\n                mean_f = np.mean(self.success_f)\n\n                self.memory_cr[self.memory_idx] = (1 - self.cr_learning_rate) * self.memory_cr[self.memory_idx] + self.cr_learning_rate * mean_cr\n                self.memory_f[self.memory_idx] = (1 - self.f_learning_rate) * self.memory_f[self.memory_idx] + self.f_learning_rate * mean_f\n\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_cr = []\n                self.success_f = []\n\n\n            # Population reduction based on diversity and fitness\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                # Calculate diversity (e.g., average distance to centroid)\n                centroid = np.mean(self.population, axis=0)\n                distances = np.linalg.norm(self.population - centroid, axis=1)\n                avg_distance = np.mean(distances)\n\n                # Normalize distances and fitness values\n                normalized_distances = distances / np.max(distances) if np.max(distances) > 0 else np.zeros_like(distances)\n                normalized_fitness = (self.fitness - np.min(self.fitness)) / (np.max(self.fitness) - np.min(self.fitness)) if np.max(self.fitness) > np.min(self.fitness) else np.zeros_like(self.fitness)\n\n                # Combine distance and fitness for removal probability\n                removal_probability = normalized_distances + normalized_fitness\n                removal_probability /= np.sum(removal_probability) # Normalize to a probability distribution\n\n                n_reduce = int(self.pop_size * 0.2) # Reduce 20% of the population at most\n\n                # Select individuals for removal based on the combined probability\n                indices_to_remove = np.random.choice(self.pop_size, size=n_reduce, replace=False, p=removal_probability)\n                \n                # Remove selected individuals\n                self.population = np.delete(self.population, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size = len(self.population)\n            \n            # Local Search using Nelder-Mead if stagnating\n            if self.stagnation_counter > self.stagnation_limit:\n                best_index = np.argmin(self.fitness)\n                best_individual = self.population[best_index].copy()\n                \n                # Define a local adaptation of the function to bind func and pass only x\n                def local_func(x):\n                    return func(x)\n\n                # Perform Nelder-Mead optimization locally\n                res = minimize(local_func, best_individual, method='Nelder-Mead', bounds=func.bounds, options={'maxfev': min(500, self.budget - self.evals)})  # Limit evaluations\n                \n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n                    self.stagnation_counter = 0 #reset\n                    self.last_improvement = self.evals\n                    \n                self.evals += res.nfev\n                \n                if self.evals >= self.budget:\n                    break\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["0207d0f1-c134-407f-9bac-8af7d4fd6ec5"], "operator": null, "metadata": {}}
{"id": "d5cce725-10c9-4111-b330-0981ba822944", "fitness": -Infinity, "name": "AdaptiveDEEARSHADEOL", "description": "Adaptive Differential Evolution with SHADE, orthogonal learning, archive, elitism, dynamic population size adjustment based on fitness improvement and diversity, stagnation detection with a more aggressive restart mechanism, and improved parameter adaptation using a weighted historical memory.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10, stagnation_window=20, restart_pop_multiplier=2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.memory_weights_cr = np.ones(self.memory_size) / self.memory_size\n        self.memory_weights_f = np.ones(self.memory_size) / self.memory_size\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.diversity_threshold = 0.1\n        self.stagnation_window = stagnation_window\n        self.fitness_history = np.full(self.stagnation_window, np.inf)\n        self.stagnation_counter = 0\n        self.restart_pop_multiplier = restart_pop_multiplier # Multiplier for population size after restart\n        self.success_cr = []\n        self.success_f = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.best_fitness_history = [np.min(self.fitness)]\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation: weighted random choice\n                cr_i = np.random.choice(self.memory_cr, p=self.memory_weights_cr)\n                f_i = np.random.choice(self.memory_f, p=self.memory_weights_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation strategy with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal learning\n                if np.random.rand() < 0.1:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + 0.01 * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = f_u - self.fitness[i]\n\n                if f_u < self.fitness[i]:\n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                if self.evals >= self.budget:\n                    break\n\n            # Update memory for SHADE (after each generation)\n            if self.success_cr and self.success_f:\n                self.memory_cr[self.memory_idx] = np.mean(self.success_cr)\n                self.memory_f[self.memory_idx] = np.mean(self.success_f)\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                # Update weights based on success\n                weights_cr = np.array([np.abs(cr - self.memory_cr[self.memory_idx]) for cr in self.success_cr])\n                weights_cr = weights_cr / np.sum(weights_cr) if np.sum(weights_cr) > 0 else np.ones_like(weights_cr) / len(weights_cr)\n                self.memory_weights_cr = (1 - 0.1) * self.memory_weights_cr + 0.1 * weights_cr\n\n                weights_f = np.array([np.abs(f - self.memory_f[self.memory_idx]) for f in self.success_f])\n                weights_f = weights_f / np.sum(weights_f) if np.sum(weights_f) > 0 else np.ones_like(weights_f) / len(weights_f)\n                self.memory_weights_f = (1 - 0.1) * self.memory_weights_f + 0.1 * weights_f\n\n            self.success_cr = []\n            self.success_f = []\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Stagnation Detection\n            self.fitness_history[self.stagnation_counter % self.stagnation_window] = self.f_opt\n            self.stagnation_counter += 1\n            stagnation = np.std(self.fitness_history) < 1e-8 # Check if fitness has stagnated\n\n            # Dynamic Population Size Adjustment and Restart\n            if self.evals < self.budget:\n                # Calculate improvement ratio (fitness change)\n                current_best_fitness = np.min(self.fitness)\n                self.best_fitness_history.append(current_best_fitness)\n                improvement_ratio = (self.best_fitness_history[-2] - current_best_fitness) / np.abs(self.best_fitness_history[-2]) if self.best_fitness_history[-2] !=0 else 0\n\n                if stagnation:\n                    # More aggressive restart with increased population\n                    old_pop_size = self.pop_size\n                    self.pop_size = int(self.pop_size * self.restart_pop_multiplier)\n                    self.pop_size = min(self.pop_size, 2 * self.budget // self.dim) # Prevent excessive population size\n                    self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    self.fitness = np.array([func(x) for x in self.population])\n                    self.evals += self.pop_size - old_pop_size\n                    self.stagnation_counter = 0\n                    self.fitness_history = np.full(self.stagnation_window, np.inf)  # Reset fitness history\n\n                    # Resetting archive and elites\n                    self.archive = []\n                    elite_count = int(self.elite_ratio * self.pop_size)\n                    elite_indices = np.argsort(self.fitness)[:elite_count]\n                    elites = self.population[elite_indices].copy()\n                    elite_fitness = self.fitness[elite_indices].copy()\n                else:\n                    # Population reduction based on diversity and improvement\n                    reduction_rate = 0.1 # Reduced reduction rate\n\n                    # Calculate diversity (e.g., average distance to centroid)\n                    centroid = np.mean(self.population, axis=0)\n                    distances = np.linalg.norm(self.population - centroid, axis=1)\n                    avg_distance = np.mean(distances)\n\n                    if avg_distance < self.diversity_threshold or improvement_ratio < 0.01:\n\n                        n_reduce = int(self.pop_size * reduction_rate)\n\n                        if n_reduce > 0 and self.pop_size > self.min_pop_size:\n                            # Remove the worst individuals\n                            worst_indices = np.argsort(self.fitness)[-n_reduce:]\n                            self.population = np.delete(self.population, worst_indices, axis=0)\n                            self.fitness = np.delete(self.fitness, worst_indices)\n                            self.pop_size = len(self.population)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occurred: operands could not be broadcast together with shapes (10,) (26,) .", "error": "", "parent_ids": ["7f7e8755-4246-47f3-b1e3-b16d2917e0b3"], "operator": null, "metadata": {}}
{"id": "e1177612-f698-402a-8f5f-8f1a98336237", "fitness": 0.2964056159862261, "name": "AdaptiveDEEARSHADEOL", "description": "Adaptive Differential Evolution with SHADE, orthogonal learning, archive, elitism, dynamic population size adjustment based on fitness and distance, improved parameter adaptation with weighted average, and novel diversity-based restart.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.diversity_threshold = 0.1\n        self.cr_learning_rate = 0.2\n        self.f_learning_rate = 0.2\n        self.restart_trigger = 50\n        self.stagnation_counter = 0\n        self.previous_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.success_cr = []\n        self.success_f = []\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation strategy with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal learning\n                if np.random.rand() < 0.1:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + 0.01 * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = f_u - self.fitness[i]  # Original delta_f calculation\n\n                if f_u < self.fitness[i]:\n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Update memory for SHADE - Weighted average\n            if self.success_cr and self.success_f:\n                weights = np.abs(np.array(self.success_f) - 0.5)  # Give less weight to values close to 0.5\n                weights /= np.sum(weights)  # Normalize weights\n\n                weighted_mean_cr = np.average(self.success_cr, weights=weights)\n                weighted_mean_f = np.average(self.success_f, weights=weights)\n\n                self.memory_cr[self.memory_idx] = (1 - self.cr_learning_rate) * self.memory_cr[self.memory_idx] + self.cr_learning_rate * weighted_mean_cr\n                self.memory_f[self.memory_idx] = (1 - self.f_learning_rate) * self.memory_f[self.memory_idx] + self.f_learning_rate * weighted_mean_f\n\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_cr = []\n                self.success_f = []\n\n\n            # Population reduction based on diversity and fitness\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                # Calculate diversity (e.g., average distance to centroid)\n                centroid = np.mean(self.population, axis=0)\n                distances = np.linalg.norm(self.population - centroid, axis=1)\n                avg_distance = np.mean(distances)\n\n                # Normalize distances and fitness values\n                normalized_distances = distances / np.max(distances) if np.max(distances) > 0 else np.zeros_like(distances)\n                normalized_fitness = (self.fitness - np.min(self.fitness)) / (np.max(self.fitness) - np.min(self.fitness)) if np.max(self.fitness) > np.min(self.fitness) else np.zeros_like(self.fitness)\n\n                # Combine distance and fitness for removal probability - Emphasize fitness\n                removal_probability = 0.2 * normalized_distances + 0.8 * normalized_fitness\n                removal_probability /= np.sum(removal_probability) # Normalize to a probability distribution\n\n                n_reduce = int(self.pop_size * 0.2) # Reduce 20% of the population at most\n\n                # Select individuals for removal based on the combined probability\n                indices_to_remove = np.random.choice(self.pop_size, size=n_reduce, replace=False, p=removal_probability)\n                \n                # Remove selected individuals\n                self.population = np.delete(self.population, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size = len(self.population)\n            \n            # Diversity-based restart mechanism\n            if self.f_opt == self.previous_best_fitness:\n                 self.stagnation_counter += 1\n            else:\n                 self.stagnation_counter = 0\n\n            self.previous_best_fitness = self.f_opt  # Update previous best fitness\n\n            if self.stagnation_counter > self.restart_trigger:\n\n                # Option 1: Re-initialize the entire population randomly\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size\n                self.stagnation_counter = 0\n                self.memory_cr = np.full(self.memory_size, 0.5)\n                self.memory_f = np.full(self.memory_size, 0.5)\n            \n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDEEARSHADEOL scored 0.296 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0207d0f1-c134-407f-9bac-8af7d4fd6ec5"], "operator": null, "metadata": {"aucs": [0.12903167174848573, 0.1979636112328439, 0.28371261524945524, 0.21776486530867178, 0.22220589180256745, 0.2236285081715208, 0.24544768884503898, 0.23661559036934354, 0.2303090855972545, 0.17274992727974292, 0.2365819273773785, 0.9996671700463476, 0.25700585410970767, 0.20901146562716366, 0.5871584776417086, 0.2690149727986729, 0.26196321145808565, 0.30428230253755784, 0.18638991809560534, 0.45760756442737116]}}
{"id": "ec2e62bd-618f-4f82-b45e-d97c162bbbd1", "fitness": 0.5590781181218445, "name": "NeighborhoodSHADE", "description": "Combines SHADE with a neighborhood-based mutation and a self-adaptive strategy to balance exploration and exploitation using a success rate based parameter adaptation and population management.", "code": "import numpy as np\n\nclass NeighborhoodSHADE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.neighborhood_size = neighborhood_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.success_cr = []\n        self.success_f = []\n        self.p = 0.1\n        self.min_pop_size = 4\n        self.reduction_factor = 0.9\n        self.evals = 0\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n            \n            for i in range(self.pop_size):\n                # Parameter Adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Neighborhood Selection\n                neighbors = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n                \n                # Mutation with neighborhood and archive\n                p_best_count = max(int(self.p * len(neighbors)), 1)\n                p_best_indices = np.argsort(self.fitness[neighbors])[:p_best_count]\n                x_pbest = self.population[neighbors[np.random.choice(p_best_indices)]]\n                \n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                \n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n                \n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n                \n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n            \n            # Update memory\n            if self.success_cr:\n                self.memory_cr[self.memory_idx] = np.mean(self.success_cr)\n                self.memory_f[self.memory_idx] = np.mean(self.success_f)\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_cr = []\n                self.success_f = []\n\n            # Population reduction\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                n_reduce = int(self.pop_size * (1 - self.reduction_factor))\n                if n_reduce > 0:\n                    worst_indices = np.argsort(self.fitness)[-n_reduce:]\n                    self.population = np.delete(self.population, worst_indices, axis=0)\n                    self.fitness = np.delete(self.fitness, worst_indices)\n                    self.pop_size = len(self.population)\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm NeighborhoodSHADE scored 0.559 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7f7e8755-4246-47f3-b1e3-b16d2917e0b3"], "operator": null, "metadata": {"aucs": [0.25239429577632677, 0.7830632381224283, 0.40200528160620175, 0.6129617441110304, 0.32232848287276217, 0.8697842918100503, 0.334854552854307, 0.8920542219977493, 0.5478723627214539, 0.2782325567828098, 0.2876550290415816, 0.9972079145322833, 0.3652982289586285, 0.4074671683315467, 0.6987055575907657, 0.7484925187106806, 0.7131172816924927, 0.9129387674039416, 0.21494336239060918, 0.5401855051292431]}}
{"id": "730028f6-1054-4afc-9f9f-5d67771a46ba", "fitness": 0.38674491903234953, "name": "AdaptiveDEMultiObjective", "description": "An adaptive DE with a novel mutation strategy using a local search combined with SHADE-inspired parameter adaptation and a multi-objective population reduction technique balancing fitness and diversity.", "code": "import numpy as np\n\nclass AdaptiveDEMultiObjective:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, memory_size=10, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1\n        self.elite_ratio = 0.1\n        self.min_pop_size = 4\n        self.local_search_probability = local_search_probability\n        self.cr_learning_rate = 0.2\n        self.f_learning_rate = 0.2\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.success_cr = []\n        self.success_f = []\n\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n\n                # Mutation with p-best and archive, combined with local search\n                p_best_count = max(int(self.p * self.pop_size), 1)\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n\n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Local search with probability\n                if np.random.rand() < self.local_search_probability:\n                    step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                    v = v + np.random.uniform(-step_size, step_size, size=self.dim)\n                    v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = f_u - self.fitness[i]\n\n                if f_u < self.fitness[i]:\n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Update memory for SHADE\n            if self.success_cr and self.success_f:\n                mean_cr = np.mean(self.success_cr)\n                mean_f = np.mean(self.success_f)\n\n                self.memory_cr[self.memory_idx] = (1 - self.cr_learning_rate) * self.memory_cr[self.memory_idx] + self.cr_learning_rate * mean_cr\n                self.memory_f[self.memory_idx] = (1 - self.f_learning_rate) * self.memory_f[self.memory_idx] + self.f_learning_rate * mean_f\n\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_cr = []\n                self.success_f = []\n\n            # Multi-objective Population Reduction\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                # Calculate crowding distance approximation\n                distances = np.zeros(self.pop_size)\n                sorted_fitness_indices = np.argsort(self.fitness)\n\n                distances[sorted_fitness_indices[0]] = np.inf\n                distances[sorted_fitness_indices[-1]] = np.inf\n\n                for k in range(1, self.pop_size - 1):\n                    distances[sorted_fitness_indices[k]] = distances[sorted_fitness_indices[k]] + (self.fitness[sorted_fitness_indices[k+1]] - self.fitness[sorted_fitness_indices[k-1]])\n\n                # Normalize fitness and crowding distance\n                normalized_fitness = (self.fitness - np.min(self.fitness)) / (np.max(self.fitness) - np.min(self.fitness) + 1e-8)\n                normalized_distances = distances / (np.max(distances) + 1e-8)\n\n                # Calculate combined score: balance fitness and crowding distance\n                combined_score = normalized_fitness - normalized_distances\n\n                # Remove worst individuals based on combined score\n                n_reduce = int(self.pop_size * 0.2)\n                indices_to_remove = np.argsort(combined_score)[:n_reduce]\n\n                self.population = np.delete(self.population, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size = len(self.population)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDEMultiObjective scored 0.387 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0207d0f1-c134-407f-9bac-8af7d4fd6ec5"], "operator": null, "metadata": {"aucs": [0.20730845817213672, 0.20565240523777162, 0.4387946042308718, 0.2241191778146321, 0.2981286118881219, 0.49121630326195886, 0.25846747064369924, 0.21421134717611412, 0.21604986386255975, 0.17235940584219955, 0.8459122106351413, 0.9999151473466051, 0.2480126686222045, 0.26515747723117133, 0.7594698893008729, 0.3296578568067622, 0.30082685871058434, 0.5838527205575212, 0.1886495197407284, 0.4871363835653333]}}
{"id": "ab824553-6d25-4758-ade5-6d21e09c95dc", "fitness": -Infinity, "name": "ClusteredSHADE_NM", "description": "Combines SHADE with a Nelder-Mead local search operator and a diversity-based population control using a clustering approach to identify and replace similar individuals.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.optimize import minimize\n\nclass ClusteredSHADE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=5, local_search_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_CR = np.full(self.memory_size, 0.5)\n        self.memory_F = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.archive = []\n        self.local_search_probability = local_search_probability\n        self.clustering_frequency = 500\n        self.elite_ratio = 0.1 #Elitism\n\n    def nelder_mead(self, func, x0, bounds):\n        \"\"\"Nelder-Mead local search.\"\"\"\n        result = minimize(func, x0, method='Nelder-Mead', bounds=bounds, options={'maxfev': 50})\n        return result.x, result.fun\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.elite_count = int(self.elite_ratio * self.pop_size)\n        self.best_fitness_history = []\n\n        while self.evals < self.budget:\n            ranked_indices = np.argsort(self.fitness)\n            p_best_indices = ranked_indices[:max(1, int(self.p * self.pop_size))]\n            \n            # Elitism: Keep track of the best individuals before mutation\n            elite_indices = np.argsort(self.fitness)[:self.elite_count]\n            elites = self.population[elite_indices].copy()\n            elite_fitness = self.fitness[elite_indices].copy()\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                mem_idx = np.random.randint(self.memory_size)\n                CRm = self.memory_CR[mem_idx]\n                Fm = self.memory_F[mem_idx]\n\n                CR = np.random.normal(CRm, 0.1)\n                CR = np.clip(CR, 0.0, 1.0)\n                \n                F = np.random.normal(Fm, 0.1)\n                while F <= 0:\n                    F = np.random.normal(Fm, 0.1)\n                F = np.clip(F, 0.1, 1.0)\n\n                # Mutation\n                p_best_idx = np.random.choice(p_best_indices)\n                x_pbest = self.population[p_best_idx]\n                \n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                np.random.shuffle(candidates)\n                x_r1 = self.population[candidates[0]]\n                \n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    x_r2 = self.archive[arc_idx]\n                else:\n                    x_r2 = self.population[candidates[1]]\n\n                v = self.population[i] + F * (x_pbest - self.population[i]) + F * (x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n                \n                if f_u < self.fitness[i]:\n                    # Local Search with Nelder-Mead\n                    if np.random.rand() < self.local_search_probability:\n                        u_local, f_u_local = self.nelder_mead(func, u, bounds=[(func.bounds.lb[j], func.bounds.ub[j]) for j in range(self.dim)])\n                        self.evals += 50  # Account for Nelder-Mead evaluations\n                        if f_u_local < f_u:\n                            f_u = f_u_local\n                            u = u_local\n                    \n                    # Update Memory\n                    self.memory_CR[self.memory_idx] = CR\n                    self.memory_F[self.memory_idx] = F\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                    # Update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    # Update population\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n\n            worst_pop_index = np.argmax(self.fitness)\n\n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n\n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n            \n            # Diversity Control using Clustering\n            if self.evals % self.clustering_frequency == 0:\n                kmeans = KMeans(n_clusters=int(self.pop_size/5), random_state=0, n_init = 'auto')  # Reduced number of clusters\n                clusters = kmeans.fit_predict(self.population)\n\n                # For each cluster, find the worst performing individual and replace it with a random individual\n                for cluster_id in range(int(self.pop_size/5)):\n                    cluster_indices = np.where(clusters == cluster_id)[0]\n                    if len(cluster_indices) > 0:\n                        worst_index = cluster_indices[np.argmax(self.fitness[cluster_indices])]\n                        self.population[worst_index] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                        self.fitness[worst_index] = func(self.population[worst_index])\n                        self.evals += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["e2b0f382-8736-46ab-8d98-b508440811f2"], "operator": null, "metadata": {}}
{"id": "0e15437c-f0ef-424f-9ec1-cb27a2825c9e", "fitness": 0.6542586462079882, "name": "AdaptiveDEEARSHADEOL", "description": "Enhanced Adaptive Differential Evolution with SHADE, orthogonal learning, archive, elitism, L-SHADE inspired population reduction, diversity maintenance, and improved parameter adaptation based on fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=5, local_search_probability=0.05, reduce_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_CR = np.full(self.memory_size, 0.5)\n        self.memory_F = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.archive = []\n        self.local_search_probability = local_search_probability\n        self.elite_ratio = 0.1\n        self.reduce_factor = reduce_factor  # Population reduction factor\n        self.min_pop_size = 10  # Minimum population size\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 5000 # Stagnation Threshold\n        self.diversity_threshold = 0.1  # Diversity threshold for restart\n        self.diversity_restart_probability = 0.1\n        self.success_history_CR = []\n        self.success_history_F = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.best_fitness_history = []\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n\n        while self.evals < self.budget:\n            \n            ranked_indices = np.argsort(self.fitness)\n            p_best_indices = ranked_indices[:max(1, int(self.p * self.pop_size))]\n\n            self.success_history_CR = []\n            self.success_history_F = []\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                mem_idx = np.random.randint(self.memory_size)\n                CRm = self.memory_CR[mem_idx]\n                Fm = self.memory_F[mem_idx]\n\n                CR = np.random.normal(CRm, 0.1)\n                CR = np.clip(CR, 0.0, 1.0)\n                \n                F = np.random.normal(Fm, 0.1)\n                while F <= 0:\n                    F = np.random.normal(Fm, 0.1)\n                F = np.clip(F, 0.1, 1.0)\n\n\n                # Mutation\n                p_best_idx = np.random.choice(p_best_indices)\n                x_pbest = self.population[p_best_idx]\n                \n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                np.random.shuffle(candidates)\n                x_r1 = self.population[candidates[0]]\n                \n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    x_r2 = self.archive[arc_idx]\n                else:\n                    x_r2 = self.population[candidates[1]]\n\n                v = self.population[i] + F * (x_pbest - self.population[i]) + F * (x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal Learning\n                if np.random.rand() < 0.1:\n                    H = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim, self.dim))\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n                \n                if f_u < self.fitness[i]:\n                    # Local Search\n                    if np.random.rand() < self.local_search_probability:\n                        step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                        u_local = u + np.random.normal(0, step_size, size=self.dim)\n                        u_local = np.clip(u_local, func.bounds.lb, func.bounds.ub)\n                        f_u_local = func(u_local)\n                        self.evals += 1\n                        if f_u_local < f_u:\n                            f_u = f_u_local\n                            u = u_local\n                    \n                    # Update Memory\n                    self.success_history_CR.append(CR)\n                    self.success_history_F.append(F)\n\n                    # Update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    # Update population\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n            \n            #Update Memory\n            if self.success_history_CR:\n                self.memory_CR[self.memory_idx] = np.mean(self.success_history_CR)\n                self.memory_F[self.memory_idx] = np.mean(self.success_history_F)\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n\n            worst_pop_index = np.argmax(self.fitness)\n\n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n\n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n            \n            #Stagnation Check\n            if len(self.best_fitness_history) > 0 and self.f_opt >= self.best_fitness_history[-1]:\n                  self.stagnation_counter += self.pop_size\n            else:\n                  self.stagnation_counter = 0\n            \n            self.best_fitness_history.append(self.f_opt)\n            \n            # Population Reduction (L-SHADE inspired)\n            if self.stagnation_counter > self.stagnation_threshold and self.pop_size > self.min_pop_size:\n                reduction_amount = max(int(self.initial_pop_size * (1 - self.reduce_factor)), self.min_pop_size) #Ensure pop_size doesnt fall below min_pop_size\n\n                if (self.pop_size - reduction_amount) < self.min_pop_size:\n                    reduction_amount = self.pop_size - self.min_pop_size\n                \n                if reduction_amount > 0: # only reduce if there is something to reduce\n                  \n                  indices_to_remove = np.argsort(self.fitness)[-reduction_amount:]\n                  self.population = np.delete(self.population, indices_to_remove, axis=0)\n                  self.fitness = np.delete(self.fitness, indices_to_remove)\n                  self.pop_size = self.population.shape[0]\n                  self.stagnation_counter = 0 # Reset stagnation counter\n            \n            # Diversity Check and Restart\n            if np.random.rand() < self.diversity_restart_probability:\n                diversity = np.std(self.population)\n                if diversity < self.diversity_threshold:\n                    self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    self.fitness = np.array([func(x) for x in self.population])\n                    self.evals += self.pop_size\n                    self.stagnation_counter = 0\n\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDEEARSHADEOL scored 0.654 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e2b0f382-8736-46ab-8d98-b508440811f2"], "operator": null, "metadata": {"aucs": [0.25893207535945817, 0.764531336419854, 0.7054681617212186, 0.9092865458120074, 0.7438648369858956, 0.8403861902498414, 0.4255233014093218, 0.7137617151077593, 0.7968758005210351, 0.1996879328103922, 0.8741674804597176, 0.9974985863090065, 0.3681204735955287, 0.6113851918711946, 0.769707337643815, 0.819725451142448, 0.6065451641740491, 0.8896195223918115, 0.2617559143053231, 0.5283299058700843]}}
{"id": "08201a8d-6ce2-47ec-8a33-46302f8e00c0", "fitness": -Infinity, "name": "CooperativeCoevolutionDE", "description": "A cooperative coevolutionary DE algorithm that divides the problem into subcomponents optimized by separate DE populations, periodically exchanging information.", "code": "import numpy as np\n\nclass CooperativeCoevolutionDE:\n    def __init__(self, budget=10000, dim=10, num_subcomponents=5, pop_size=20, memory_size=10, exchange_interval=50):\n        self.budget = budget\n        self.dim = dim\n        self.num_subcomponents = num_subcomponents\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.exchange_interval = exchange_interval\n        self.subcomponent_size = dim // num_subcomponents\n        self.memory_cr = np.full((num_subcomponents, memory_size), 0.5)\n        self.memory_f = np.full((num_subcomponents, memory_size), 0.5)\n        self.memory_idx = np.zeros(num_subcomponents, dtype=int)\n        self.cr_learning_rate = 0.2\n        self.f_learning_rate = 0.2\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n\n        # Initialize subcomponent populations\n        self.populations = []\n        self.fitnesses = []\n        self.best_positions = []\n        self.best_fitnesses = []\n        for i in range(self.num_subcomponents):\n            self.populations.append(np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.subcomponent_size)))\n            self.fitnesses.append(np.full(self.pop_size, np.inf))  # Initialize fitnesses to infinity\n            self.best_positions.append(np.zeros(self.subcomponent_size))\n            self.best_fitnesses.append(np.inf)\n        \n        # Initial Evaluation\n        for i in range(self.num_subcomponents):\n            for j in range(self.pop_size):\n                x = self.assemble_solution(i, self.populations[i][j])\n                f = func(x)\n                self.evals += 1\n                self.fitnesses[i][j] = f\n\n                if f < self.best_fitnesses[i]:\n                    self.best_fitnesses[i] = f\n                    self.best_positions[i] = self.populations[i][j].copy()\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n                if self.evals >= self.budget:\n                    return self.f_opt, self.x_opt\n\n        generation = 0\n        while self.evals < self.budget:\n            generation += 1\n            for i in range(self.num_subcomponents):\n                # DE optimization for each subcomponent\n                success_cr = []\n                success_f = []\n                for j in range(self.pop_size):\n                    # SHADE parameter adaptation\n                    cr_i = np.random.choice(self.memory_cr[i])\n                    f_i = np.random.choice(self.memory_f[i])\n                    f_i = np.clip(f_i, 0.0, 1.0)\n\n                    # Mutation\n                    candidates = list(range(self.pop_size))\n                    candidates.remove(j)\n                    np.random.shuffle(candidates)\n                    x_r1 = self.populations[i][candidates[0]]\n                    x_r2 = self.populations[i][candidates[1]]\n\n                    v = self.populations[i][j] + f_i * (x_r1 - x_r2)\n                    v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    u = np.zeros(self.subcomponent_size)\n                    j_rand = np.random.randint(self.subcomponent_size)\n                    for k in range(self.subcomponent_size):\n                        if np.random.rand() < cr_i or k == j_rand:\n                            u[k] = v[k]\n                        else:\n                            u[k] = self.populations[i][j, k]\n\n                    # Evaluation\n                    x = self.assemble_solution(i, u)\n                    f_u = func(x)\n                    self.evals += 1\n                    \n                    if f_u < self.fitnesses[i][j]:\n                        success_cr.append(cr_i)\n                        success_f.append(f_i)\n                        self.populations[i][j] = u\n                        self.fitnesses[i][j] = f_u\n                        \n                        if f_u < self.best_fitnesses[i]:\n                            self.best_fitnesses[i] = f_u\n                            self.best_positions[i] = u.copy()\n                        \n                        if f_u < self.f_opt:\n                            self.f_opt = f_u\n                            self.x_opt = x\n                            \n                    if self.evals >= self.budget:\n                        return self.f_opt, self.x_opt\n                \n                # SHADE memory update\n                if success_cr and success_f:\n                    mean_cr = np.mean(success_cr)\n                    mean_f = np.mean(success_f)\n\n                    self.memory_cr[i][self.memory_idx[i]] = (1 - self.cr_learning_rate) * self.memory_cr[i][self.memory_idx[i]] + self.cr_learning_rate * mean_cr\n                    self.memory_f[i][self.memory_idx[i]] = (1 - self.f_learning_rate) * self.memory_f[i][self.memory_idx[i]] + self.f_learning_rate * mean_f\n\n                    self.memory_idx[i] = (self.memory_idx[i] + 1) % self.memory_size\n\n            # Exchange best information periodically\n            if generation % self.exchange_interval == 0:\n                for i in range(self.num_subcomponents):\n                    for j in range(self.num_subcomponents):\n                        if i != j:\n                            # Replace a random individual with the best from another subcomponent\n                            idx = np.random.randint(self.pop_size)\n                            self.populations[i][idx] = self.best_positions[j].copy()\n\n                            x = self.assemble_solution(i, self.populations[i][idx])\n                            f = func(x)\n                            self.evals += 1\n                            self.fitnesses[i][idx] = f\n                            if f < self.best_fitnesses[i]:\n                                self.best_fitnesses[i] = f\n                                self.best_positions[i] = self.populations[i][idx].copy()\n                            if f < self.f_opt:\n                                self.f_opt = f\n                                self.x_opt = x\n                            if self.evals >= self.budget:\n                                return self.f_opt, self.x_opt\n                            \n        return self.f_opt, self.x_opt\n\n    def assemble_solution(self, subcomponent_index, subcomponent_solution):\n        x = np.zeros(self.dim)\n        start_index = subcomponent_index * self.subcomponent_size\n        end_index = start_index + self.subcomponent_size\n        x[start_index:end_index] = subcomponent_solution\n        \n        # Complete missing dimensions with best known values from each other subcomponents.\n        for i in range(self.num_subcomponents):\n            if i != subcomponent_index:\n                start_index_other = i * self.subcomponent_size\n                end_index_other = start_index_other + self.subcomponent_size\n                x[start_index_other:end_index_other] = self.best_positions[i]\n        return x", "configspace": "", "generation": 7, "feedback": "An exception occurred: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (20, 0) and arg 1 with shape (2,)..", "error": "", "parent_ids": ["730028f6-1054-4afc-9f9f-5d67771a46ba"], "operator": null, "metadata": {}}
{"id": "c237990c-65a2-4426-97e7-50fa53d8cd6e", "fitness": -Infinity, "name": "AdaptiveDEMultiObjective", "description": "Adaptive Differential Evolution with SHADE-inspired parameter adaptation, archive, elitism, multi-objective population reduction considering both fitness and distance, and an enhanced local search using a dynamic step size.", "code": "import numpy as np\n\nclass AdaptiveDEMultiObjective:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, memory_size=10, local_search_probability=0.1, ls_reduction=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1\n        self.elite_ratio = 0.1\n        self.min_pop_size = 4\n        self.local_search_probability = local_search_probability\n        self.cr_learning_rate = 0.2\n        self.f_learning_rate = 0.2\n        self.ls_reduction = ls_reduction\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.success_cr = []\n        self.success_f = []\n\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        step_size = 0.1 * (func.bounds.ub - func.bounds.lb) # Initial step size for local search\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n\n                # Mutation with p-best and archive, combined with local search\n                p_best_count = max(int(self.p * self.pop_size), 1)\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n\n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Local search with probability\n                if np.random.rand() < self.local_search_probability:\n                    v = v + np.random.uniform(-step_size, step_size, size=self.dim)\n                    v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = f_u - self.fitness[i]\n\n                if f_u < self.fitness[i]:\n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        step_size = max(step_size * self.ls_reduction, 1e-6) # Reduce step size upon improvement\n\n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Update memory for SHADE\n            if self.success_cr and self.success_f:\n                mean_cr = np.mean(self.success_cr)\n                mean_f = np.mean(self.success_f)\n\n                self.memory_cr[self.memory_idx] = (1 - self.cr_learning_rate) * self.memory_cr[self.memory_idx] + self.cr_learning_rate * mean_cr\n                self.memory_f[self.memory_idx] = (1 - self.f_learning_rate) * self.memory_f[self.memory_idx] + self.f_learning_rate * mean_f\n\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_cr = []\n                self.success_f = []\n\n            # Multi-objective Population Reduction\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                # Calculate crowding distance approximation\n                distances = np.zeros(self.pop_size)\n                sorted_fitness_indices = np.argsort(self.fitness)\n\n                distances[sorted_fitness_indices[0]] = np.inf\n                distances[sorted_fitness_indices[-1]] = np.inf\n\n                for k in range(1, self.pop_size - 1):\n                    distances[sorted_fitness_indices[k]] = distances[sorted_fitness_indices[k]] + (self.fitness[sorted_fitness_indices[k+1]] - self.fitness[sorted_fitness_indices[k-1]])\n\n                # Normalize fitness and crowding distance\n                normalized_fitness = (self.fitness - np.min(self.fitness)) / (np.max(self.fitness) - np.min(self.fitness) + 1e-8)\n                normalized_distances = distances / (np.max(distances) + 1e-8)\n\n                # Calculate combined score: balance fitness and crowding distance\n                combined_score = normalized_fitness - normalized_distances\n\n                # Remove worst individuals based on combined score\n                n_reduce = int(self.pop_size * 0.2)\n                indices_to_remove = np.argsort(combined_score)[:n_reduce]\n\n                self.population = np.delete(self.population, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size = len(self.population)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["730028f6-1054-4afc-9f9f-5d67771a46ba"], "operator": null, "metadata": {}}
{"id": "d4cd7649-c212-4f1d-aebf-db2b9ff32087", "fitness": -Infinity, "name": "EnsembleReinforcementDENiche", "description": "Differential Evolution with a dynamic ensemble of mutation strategies, adaptive parameter control using reinforcement learning, and a niching-based diversity maintenance mechanism.", "code": "import numpy as np\n\nclass EnsembleReinforcementDENiche:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, memory_size=10, num_mutation_strategies=3, niche_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.num_mutation_strategies = num_mutation_strategies\n        self.niche_radius = niche_radius\n        self.mutation_strategies = [\n            self.mutation_strategy_1,\n            self.mutation_strategy_2,\n            self.mutation_strategy_3\n        ]\n        self.mutation_probabilities = np.full(self.num_mutation_strategies, 1 / self.num_mutation_strategies)\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.archive = []\n        self.evals = 0\n        self.memory_idx = 0\n        self.success_cr = []\n        self.success_f = []\n        self.learning_rate = 0.1\n        self.reward_successful = 0.1\n        self.reward_unsuccessful = -0.05\n        self.min_pop_size = 4\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # Strategy selection using roulette wheel selection\n                strategy_index = np.random.choice(self.num_mutation_strategies, p=self.mutation_probabilities)\n                mutation_strategy = self.mutation_strategies[strategy_index]\n\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n\n                # Mutation\n                v = mutation_strategy(i, cr_i, f_i, func)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n                delta_f = f_u - self.fitness[i]\n\n                if f_u < self.fitness[i]:\n                    # Reward the chosen mutation strategy\n                    self.mutation_probabilities[strategy_index] += self.learning_rate * self.reward_successful * (1 - self.mutation_probabilities[strategy_index])\n                    self.mutation_probabilities /= np.sum(self.mutation_probabilities)\n                    \n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Penalize the chosen mutation strategy\n                    self.mutation_probabilities[strategy_index] += self.learning_rate * self.reward_unsuccessful * (1 - self.mutation_probabilities[strategy_index])\n                    self.mutation_probabilities /= np.sum(self.mutation_probabilities)\n\n                if self.evals >= self.budget:\n                    break\n                    \n            # Niching-based Diversity Maintenance\n            self.niching()\n\n            # Update memory for SHADE\n            if self.success_cr and self.success_f:\n                mean_cr = np.mean(self.success_cr)\n                mean_f = np.mean(self.success_f)\n\n                self.memory_cr[self.memory_idx] = (1 - self.learning_rate) * self.memory_cr[self.memory_idx] + self.learning_rate * mean_cr\n                self.memory_f[self.memory_idx] = (1 - self.learning_rate) * self.memory_f[self.memory_idx] + self.learning_rate * mean_f\n\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_cr = []\n                self.success_f = []\n\n        return self.f_opt, self.x_opt\n\n    def mutation_strategy_1(self, i, cr_i, f_i, func):\n        candidates = list(range(self.pop_size))\n        candidates.remove(i)\n        np.random.shuffle(candidates)\n        x_r1 = self.population[candidates[0]]\n        x_r2 = self.population[candidates[1]]\n        return self.population[i] + f_i * (x_r1 - x_r2)\n\n    def mutation_strategy_2(self, i, cr_i, f_i, func):\n        candidates = list(range(self.pop_size))\n        candidates.remove(i)\n        np.random.shuffle(candidates)\n        x_r1 = self.population[candidates[0]]\n        x_r2 = self.population[candidates[1]]\n        x_r3 = self.population[candidates[2]]\n        return self.population[i] + f_i * (x_r1 - self.population[i]) + f_i * (x_r2 - x_r3)\n    \n    def mutation_strategy_3(self, i, cr_i, f_i, func):\n        best_index = np.argmin(self.fitness)\n        candidates = list(range(self.pop_size))\n        candidates.remove(i)\n        np.random.shuffle(candidates)\n        x_r1 = self.population[candidates[0]]\n        x_r2 = self.population[candidates[1]]\n        return self.population[best_index] + f_i * (x_r1 - x_r2)\n\n    def niching(self):\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distance = np.linalg.norm(self.population[i] - self.population[j])\n                if distance < self.niche_radius:\n                    if self.fitness[i] > self.fitness[j]:\n                        self.population[i] = self.population[j] + np.random.normal(0, 0.01, self.dim)\n                        self.population[i] = np.clip(self.population[i], -5.0, 5.0)\n                        self.fitness[i] = np.inf\n                    else:\n                        self.population[j] = self.population[i] + np.random.normal(0, 0.01, self.dim)\n                        self.population[j] = np.clip(self.population[j], -5.0, 5.0)\n                        self.fitness[j] = np.inf\n\n        # Re-evaluate fitness of modified individuals\n        for i in range(self.pop_size):\n            if self.fitness[i] == np.inf:\n                self.fitness[i] = func(self.population[i])\n                self.evals += 1\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.population[i]\n                \n                if self.evals >= self.budget:\n                    break", "configspace": "", "generation": 7, "feedback": "An exception occurred: name 'func' is not defined.", "error": "", "parent_ids": ["730028f6-1054-4afc-9f9f-5d67771a46ba"], "operator": null, "metadata": {}}
{"id": "10bf2ec4-0335-48c3-ae5c-9a93c37124dc", "fitness": -Infinity, "name": "AdaptiveDEEARSHADEOL", "description": "Enhanced Adaptive Differential Evolution with SHADE, orthogonal learning, archive, elitism, population diversity control using kernel density estimation and a novel multi-parent crossover to improve exploration.", "code": "import numpy as np\nfrom scipy.stats import gaussian_kde\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.diversity_threshold = 0.1\n        self.cr_learning_rate = 0.2\n        self.f_learning_rate = 0.2\n        self.restart_trigger = 50\n        self.stagnation_counter = 0\n        self.previous_best_fitness = np.inf\n        self.kde = None\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.success_cr = []\n        self.success_f = []\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation strategy with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n                        \n                # Multi-Parent Crossover (Enhanced Exploration)\n                num_parents = np.random.randint(2, 5)  # Randomly select 2 to 4 parents\n                parents_indices = np.random.choice(self.pop_size, num_parents, replace=False)\n                parents = self.population[parents_indices]\n                \n                # Calculate the weighted average of the parents\n                weights = np.random.rand(num_parents)\n                weights /= np.sum(weights)\n                \n                weighted_avg = np.sum(parents * weights[:, np.newaxis], axis=0)\n                \n                # Combine with the current individual\n                crossover_rate = 0.3 #Probability to include parent solution\n                for j in range(self.dim):\n                    if np.random.rand() < crossover_rate:\n                         u[j] = weighted_avg[j] #Include information from parent\n                \n\n                # Orthogonal learning\n                if np.random.rand() < 0.1:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + 0.01 * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = f_u - self.fitness[i]  # Original delta_f calculation\n\n                if f_u < self.fitness[i]:\n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Update memory for SHADE - Weighted average\n            if self.success_cr and self.success_f:\n                weights = np.abs(np.array(self.success_f) - 0.5)  # Give less weight to values close to 0.5\n                weights /= np.sum(weights)  # Normalize weights\n\n                weighted_mean_cr = np.average(self.success_cr, weights=weights)\n                weighted_mean_f = np.average(self.success_f, weights=weights)\n\n                self.memory_cr[self.memory_idx] = (1 - self.cr_learning_rate) * self.memory_cr[self.memory_idx] + self.cr_learning_rate * weighted_mean_cr\n                self.memory_f[self.memory_idx] = (1 - self.f_learning_rate) * self.memory_f[self.memory_idx] + self.f_learning_rate * weighted_mean_f\n\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_cr = []\n                self.success_f = []\n\n\n            # Population reduction based on diversity and fitness\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                # Calculate diversity (e.g., using Kernel Density Estimation)\n                try:\n                    self.kde = gaussian_kde(self.population.T)\n                    density_values = self.kde.evaluate(self.population.T)\n                except np.linalg.LinAlgError:\n                    density_values = np.ones(self.pop_size)  # Assign equal density if KDE fails\n\n                # Normalize fitness values\n                normalized_fitness = (self.fitness - np.min(self.fitness)) / (np.max(self.fitness) - np.min(self.fitness)) if np.max(self.fitness) > np.min(self.fitness) else np.zeros_like(self.fitness)\n\n                # Combine density and fitness for removal probability (Lower density is preferred for removal)\n                removal_probability = 0.7 * (1 - (density_values / np.max(density_values))) + 0.3 * normalized_fitness  # Higher weight to density\n                removal_probability /= np.sum(removal_probability)  # Normalize to a probability distribution\n\n                n_reduce = int(self.pop_size * 0.2)  # Reduce 20% of the population at most\n\n                # Select individuals for removal based on the combined probability\n                indices_to_remove = np.random.choice(self.pop_size, size=n_reduce, replace=False, p=removal_probability)\n\n                # Remove selected individuals\n                self.population = np.delete(self.population, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size = len(self.population)\n            \n            # Diversity-based restart mechanism\n            if self.f_opt == self.previous_best_fitness:\n                 self.stagnation_counter += 1\n            else:\n                 self.stagnation_counter = 0\n\n            self.previous_best_fitness = self.f_opt  # Update previous best fitness\n\n            if self.stagnation_counter > self.restart_trigger:\n\n                # Option 1: Re-initialize the entire population randomly\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size\n                self.stagnation_counter = 0\n                self.memory_cr = np.full(self.memory_size, 0.5)\n                self.memory_f = np.full(self.memory_size, 0.5)\n            \n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "An exception occurred: name 'gaussian_kde' is not defined.", "error": "", "parent_ids": ["e1177612-f698-402a-8f5f-8f1a98336237"], "operator": null, "metadata": {}}
{"id": "f8670b29-75c0-4d09-a621-607b3ca4d291", "fitness": 0.443804081139595, "name": "RingTopologyDE", "description": "A self-organizing differential evolution using a ring topology for information sharing and a dynamic subpopulation size for localized exploitation and global exploration.", "code": "import numpy as np\n\nclass RingTopologyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, ring_radius=5, reduction_factor=0.9, min_pop_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.ring_radius = ring_radius\n        self.reduction_factor = reduction_factor\n        self.min_pop_size = min_pop_size\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Ring Topology Neighborhood Selection\n                neighbors = [(i + j) % self.pop_size for j in range(-self.ring_radius, self.ring_radius + 1) if j != 0]\n                neighbor_fitnesses = self.fitness[neighbors]\n                best_neighbor_index = neighbors[np.argmin(neighbor_fitnesses)]\n\n                # DE Mutation\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                r1, r2 = np.random.choice(candidates, 2, replace=False)\n                \n                F = np.random.uniform(0.1, 0.9) # Mutation factor\n                CR = np.random.uniform(0.1, 0.9) # Crossover rate\n                \n                v = self.population[i] + F * (self.population[best_neighbor_index] - self.population[i] + self.population[r1] - self.population[r2])\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n            # Dynamic Population Reduction\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                num_reduce = max(1, int((1 - self.reduction_factor) * self.pop_size))\n                worst_indices = np.argsort(self.fitness)[-num_reduce:] # Remove the worst individuals\n                self.population = np.delete(self.population, worst_indices, axis=0)\n                self.fitness = np.delete(self.fitness, worst_indices)\n                self.pop_size = len(self.population)\n\n                if self.pop_size < self.min_pop_size:\n                    num_to_add = self.min_pop_size - self.pop_size\n                    new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_add, self.dim))\n                    new_fitness = np.array([func(x) for x in new_individuals])\n                    self.population = np.vstack((self.population, new_individuals))\n                    self.fitness = np.concatenate((self.fitness, new_fitness))\n                    self.pop_size = len(self.population)\n                    self.evals += num_to_add\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm RingTopologyDE scored 0.444 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["730028f6-1054-4afc-9f9f-5d67771a46ba"], "operator": null, "metadata": {"aucs": [0.2197842600980805, 0.36558328925457095, 0.4255077974920328, 0.4547874489284185, 0.355368523710893, 0.42834759936190203, 0.3555422869163386, 0.4409353544767036, 0.3760866094966442, 0.2997032002302704, 0.5792058968004867, 0.9974612657550962, 0.30196151539601856, 0.3874466494475397, 0.8508916767006374, 0.38345992761379777, 0.3470314512314657, 0.5978416364328659, 0.21079543298193282, 0.49833980046620663]}}
{"id": "11a15798-7394-405c-a9a2-adf47866836e", "fitness": 0.3815779178911229, "name": "AdaptiveDEEARSHADEOL", "description": "Enhanced Adaptive Differential Evolution with SHADE, orthogonal learning, archive, elitism, L-SHADE inspired population reduction, diversity maintenance, and improved parameter adaptation based on fitness improvement, using a more robust restart and local search.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10, local_search_iterations=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.diversity_threshold = 0.1\n        self.cr_learning_rate = 0.2\n        self.f_learning_rate = 0.2\n        self.restart_trigger = 50\n        self.stagnation_counter = 0\n        self.previous_best_fitness = np.inf\n        self.local_search_iterations = local_search_iterations\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.success_cr = []\n        self.success_f = []\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation strategy with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal learning\n                if np.random.rand() < 0.1:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + 0.01 * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = f_u - self.fitness[i]  # Original delta_f calculation\n\n                if f_u < self.fitness[i]:\n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Update memory for SHADE - Weighted average\n            if self.success_cr and self.success_f:\n                weights = np.abs(np.array(self.success_f) - 0.5)  # Give less weight to values close to 0.5\n                weights /= np.sum(weights)  # Normalize weights\n\n                weighted_mean_cr = np.average(self.success_cr, weights=weights)\n                weighted_mean_f = np.average(self.success_f, weights=weights)\n\n                self.memory_cr[self.memory_idx] = (1 - self.cr_learning_rate) * self.memory_cr[self.memory_idx] + self.cr_learning_rate * weighted_mean_cr\n                self.memory_f[self.memory_idx] = (1 - self.f_learning_rate) * self.memory_f[self.memory_idx] + self.f_learning_rate * weighted_mean_f\n\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_cr = []\n                self.success_f = []\n\n\n            # Population reduction based on diversity and fitness\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                # Calculate diversity (e.g., average distance to centroid)\n                centroid = np.mean(self.population, axis=0)\n                distances = np.linalg.norm(self.population - centroid, axis=1)\n                avg_distance = np.mean(distances)\n\n                # Normalize distances and fitness values\n                normalized_distances = distances / np.max(distances) if np.max(distances) > 0 else np.zeros_like(distances)\n                normalized_fitness = (self.fitness - np.min(self.fitness)) / (np.max(self.fitness) - np.min(self.fitness)) if np.max(self.fitness) > np.min(self.fitness) else np.zeros_like(self.fitness)\n\n                # Combine distance and fitness for removal probability - Emphasize fitness\n                removal_probability = 0.2 * normalized_distances + 0.8 * normalized_fitness\n                removal_probability /= np.sum(removal_probability) # Normalize to a probability distribution\n\n                n_reduce = int(self.pop_size * 0.2) # Reduce 20% of the population at most\n\n                # Select individuals for removal based on the combined probability\n                indices_to_remove = np.random.choice(self.pop_size, size=n_reduce, replace=False, p=removal_probability)\n                \n                # Remove selected individuals\n                self.population = np.delete(self.population, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size = len(self.population)\n            \n            # Diversity-based restart mechanism\n            if self.f_opt == self.previous_best_fitness:\n                 self.stagnation_counter += 1\n            else:\n                 self.stagnation_counter = 0\n\n            self.previous_best_fitness = self.f_opt  # Update previous best fitness\n\n            if self.stagnation_counter > self.restart_trigger:\n\n                # Option 1: Re-initialize the entire population randomly, but keep the best individual.\n                best_individual = self.population[np.argmin(self.fitness)].copy()\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.population[0] = best_individual  # Keep the best individual\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size - 1 # Discount the already calculated best individual.\n                self.stagnation_counter = 0\n                self.memory_cr = np.full(self.memory_size, 0.5)\n                self.memory_f = np.full(self.memory_size, 0.5)\n\n            # Local Search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.evals >= self.budget:\n                    break\n\n                # Generate a small perturbation\n                perturbation = np.random.normal(0, 0.01, size=self.dim)\n                new_x = self.x_opt + perturbation\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new solution\n                new_f = func(new_x)\n                self.evals += 1\n\n                # Update if the new solution is better\n                if new_f < self.f_opt:\n                    self.f_opt = new_f\n                    self.x_opt = new_x\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDEEARSHADEOL scored 0.382 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e1177612-f698-402a-8f5f-8f1a98336237"], "operator": null, "metadata": {"aucs": [0.1928906924727778, 0.19030822228068833, 0.2898601322941622, 0.21949335967249228, 0.2549666009542534, 0.5246207245876561, 0.2848814450878383, 0.27080950600281284, 0.27447007734674966, 0.21034287622446968, 0.8290665658403936, 0.9918896306273499, 0.2465178541852503, 0.3195558016197718, 0.9175812683428757, 0.33093116357598396, 0.2546176181523021, 0.3686867529616604, 0.17712874646646193, 0.482939319126507]}}
{"id": "446e3c6b-d9ef-4e18-8daf-6e7c4caec2ea", "fitness": 0.28922648940203965, "name": "AdaptiveDEEARSHADEOL", "description": "Integrates a local search operator based on Gaussian mutation with adaptive step size to enhance exploitation around promising regions, coupled with SHADE-inspired parameter adaptation and population diversity management for improved performance.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.diversity_threshold = 0.1\n        self.cr_learning_rate = 0.2\n        self.f_learning_rate = 0.2\n        self.restart_trigger = 50\n        self.stagnation_counter = 0\n        self.previous_best_fitness = np.inf\n        self.local_search_prob = 0.1\n        self.local_search_step_size = 0.1\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.success_cr = []\n        self.success_f = []\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation strategy with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal learning\n                if np.random.rand() < 0.1:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + 0.01 * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Local search\n                if np.random.rand() < self.local_search_prob:\n                    # Gaussian mutation with adaptive step size\n                    step_size = self.local_search_step_size * (func.bounds.ub - func.bounds.lb)\n                    v_local = u + np.random.normal(0, step_size, size=self.dim)\n                    v_local = np.clip(v_local, func.bounds.lb, func.bounds.ub)\n                    u = v_local\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = f_u - self.fitness[i]  # Original delta_f calculation\n\n                if f_u < self.fitness[i]:\n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Update memory for SHADE - Weighted average\n            if self.success_cr and self.success_f:\n                weights = np.abs(np.array(self.success_f) - 0.5)  # Give less weight to values close to 0.5\n                weights /= np.sum(weights)  # Normalize weights\n\n                weighted_mean_cr = np.average(self.success_cr, weights=weights)\n                weighted_mean_f = np.average(self.success_f, weights=weights)\n\n                self.memory_cr[self.memory_idx] = (1 - self.cr_learning_rate) * self.memory_cr[self.memory_idx] + self.cr_learning_rate * weighted_mean_cr\n                self.memory_f[self.memory_idx] = (1 - self.f_learning_rate) * self.memory_f[self.memory_idx] + self.f_learning_rate * weighted_mean_f\n\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_cr = []\n                self.success_f = []\n\n\n            # Population reduction based on diversity and fitness\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                # Calculate diversity (e.g., average distance to centroid)\n                centroid = np.mean(self.population, axis=0)\n                distances = np.linalg.norm(self.population - centroid, axis=1)\n                avg_distance = np.mean(distances)\n\n                # Normalize distances and fitness values\n                normalized_distances = distances / np.max(distances) if np.max(distances) > 0 else np.zeros_like(distances)\n                normalized_fitness = (self.fitness - np.min(self.fitness)) / (np.max(self.fitness) - np.min(self.fitness)) if np.max(self.fitness) > np.min(self.fitness) else np.zeros_like(self.fitness)\n\n                # Combine distance and fitness for removal probability - Emphasize fitness\n                removal_probability = 0.2 * normalized_distances + 0.8 * normalized_fitness\n                removal_probability /= np.sum(removal_probability) # Normalize to a probability distribution\n\n                n_reduce = int(self.pop_size * 0.2) # Reduce 20% of the population at most\n\n                # Select individuals for removal based on the combined probability\n                indices_to_remove = np.random.choice(self.pop_size, size=n_reduce, replace=False, p=removal_probability)\n                \n                # Remove selected individuals\n                self.population = np.delete(self.population, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size = len(self.population)\n            \n            # Diversity-based restart mechanism\n            if self.f_opt == self.previous_best_fitness:\n                 self.stagnation_counter += 1\n            else:\n                 self.stagnation_counter = 0\n\n            self.previous_best_fitness = self.f_opt  # Update previous best fitness\n\n            if self.stagnation_counter > self.restart_trigger:\n\n                # Option 1: Re-initialize the entire population randomly\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size\n                self.stagnation_counter = 0\n                self.memory_cr = np.full(self.memory_size, 0.5)\n                self.memory_f = np.full(self.memory_size, 0.5)\n                self.local_search_step_size = 0.1\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDEEARSHADEOL scored 0.289 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e1177612-f698-402a-8f5f-8f1a98336237"], "operator": null, "metadata": {"aucs": [0.12098102848276049, 0.20153659170213012, 0.3507793984471792, 0.17845949563654706, 0.1956490128458589, 0.24092738361838595, 0.2507472668345233, 0.2164692848172476, 0.21158087853578422, 0.1604935810340714, 0.22157069294340703, 0.9979062502314651, 0.2492776815360268, 0.1947679284635926, 0.5695396138130739, 0.28177194793137295, 0.2562549270652851, 0.24874585701806962, 0.1627500815558306, 0.4743208855281821]}}
{"id": "2c222ea9-bea6-42ac-83f9-f617d6f1b861", "fitness": 0.4987626255301637, "name": "AdaptiveDEEARSHADEOL", "description": "Combines adaptive differential evolution with SHADE-inspired parameter control, orthogonal learning, archive, elitism, population reduction, and a Cauchy mutation operator to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=5, local_search_probability=0.05, reduce_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_CR = np.full(self.memory_size, 0.5)\n        self.memory_F = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.archive = []\n        self.local_search_probability = local_search_probability\n        self.elite_ratio = 0.1\n        self.reduce_factor = reduce_factor  # Population reduction factor\n        self.min_pop_size = 10  # Minimum population size\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 5000 # Stagnation Threshold\n        self.diversity_threshold = 0.1  # Diversity threshold for restart\n        self.diversity_restart_probability = 0.1\n        self.success_history_CR = []\n        self.success_history_F = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.best_fitness_history = []\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n\n        while self.evals < self.budget:\n            \n            ranked_indices = np.argsort(self.fitness)\n            p_best_indices = ranked_indices[:max(1, int(self.p * self.pop_size))]\n\n            self.success_history_CR = []\n            self.success_history_F = []\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                mem_idx = np.random.randint(self.memory_size)\n                CRm = self.memory_CR[mem_idx]\n                Fm = self.memory_F[mem_idx]\n\n                CR = np.random.normal(CRm, 0.1)\n                CR = np.clip(CR, 0.0, 1.0)\n                \n                F = np.random.normal(Fm, 0.1)\n                while F <= 0:\n                    F = np.random.normal(Fm, 0.1)\n                F = np.clip(F, 0.1, 1.0)\n\n\n                # Mutation using Cauchy distribution for F\n                p_best_idx = np.random.choice(p_best_indices)\n                x_pbest = self.population[p_best_idx]\n                \n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                np.random.shuffle(candidates)\n                x_r1 = self.population[candidates[0]]\n                \n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    x_r2 = self.archive[arc_idx]\n                else:\n                    x_r2 = self.population[candidates[1]]\n\n                # Cauchy mutation\n                F_cauchy = np.random.standard_cauchy() * 0.1  # Scale factor for Cauchy\n                v = self.population[i] + F_cauchy * (x_pbest - self.population[i]) + F * (x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal Learning\n                if np.random.rand() < 0.1:\n                    H = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim, self.dim))\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n                \n                if f_u < self.fitness[i]:\n                    # Local Search\n                    if np.random.rand() < self.local_search_probability:\n                        step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                        u_local = u + np.random.normal(0, step_size, size=self.dim)\n                        u_local = np.clip(u_local, func.bounds.lb, func.bounds.ub)\n                        f_u_local = func(u_local)\n                        self.evals += 1\n                        if f_u_local < f_u:\n                            f_u = f_u_local\n                            u = u_local\n                    \n                    # Update Memory\n                    self.success_history_CR.append(CR)\n                    self.success_history_F.append(F)\n\n                    # Update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    # Update population\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n            \n            #Update Memory\n            if self.success_history_CR:\n                self.memory_CR[self.memory_idx] = np.mean(self.success_history_CR)\n                self.memory_F[self.memory_idx] = np.mean(self.success_history_F)\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n\n            worst_pop_index = np.argmax(self.fitness)\n\n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n\n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n            \n            #Stagnation Check\n            if len(self.best_fitness_history) > 0 and self.f_opt >= self.best_fitness_history[-1]:\n                  self.stagnation_counter += self.pop_size\n            else:\n                  self.stagnation_counter = 0\n            \n            self.best_fitness_history.append(self.f_opt)\n            \n            # Population Reduction (L-SHADE inspired)\n            if self.stagnation_counter > self.stagnation_threshold and self.pop_size > self.min_pop_size:\n                reduction_amount = max(int(self.initial_pop_size * (1 - self.reduce_factor)), self.min_pop_size) #Ensure pop_size doesnt fall below min_pop_size\n\n                if (self.pop_size - reduction_amount) < self.min_pop_size:\n                    reduction_amount = self.pop_size - self.min_pop_size\n                \n                if reduction_amount > 0: # only reduce if there is something to reduce\n                  \n                  indices_to_remove = np.argsort(self.fitness)[-reduction_amount:]\n                  self.population = np.delete(self.population, indices_to_remove, axis=0)\n                  self.fitness = np.delete(self.fitness, indices_to_remove, axis=0)\n                  self.pop_size = self.population.shape[0]\n                  self.stagnation_counter = 0 # Reset stagnation counter\n            \n            # Diversity Check and Restart\n            if np.random.rand() < self.diversity_restart_probability:\n                diversity = np.std(self.population)\n                if diversity < self.diversity_threshold:\n                    self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    self.fitness = np.array([func(x) for x in self.population])\n                    self.evals += self.pop_size\n                    self.stagnation_counter = 0\n\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDEEARSHADEOL scored 0.499 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0e15437c-f0ef-424f-9ec1-cb27a2825c9e"], "operator": null, "metadata": {"aucs": [0.17021467794691636, 0.40711960737178854, 0.46273633892543975, 0.7164433076901908, 0.41793339677461594, 0.564610390027565, 0.3184565836513088, 0.39357213537968405, 0.4085539086928526, 0.2535935096168108, 0.78234724235212, 0.9985360424689419, 0.5356722537493217, 0.4149607223478361, 0.8300364458496207, 0.5412434606482027, 0.3867139013193308, 0.675384356957069, 0.19186331546422897, 0.5052609133694304]}}
{"id": "2c97f0ac-eb73-4a3c-b287-ae96cbc591e0", "fitness": 0.3705397991146393, "name": "AdaptiveDEEARSHADEOL", "description": "Enhanced Adaptive Differential Evolution with SHADE, orthogonal learning, archive, elitism, L-SHADE inspired population reduction and restart mechanism using a success rate based on function value improvement.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.elite_ratio = 0.1  # Ratio of elite individuals to keep\n        self.min_pop_size = 4\n        self.cr_learning_rate = 0.2\n        self.f_learning_rate = 0.2\n        self.restart_trigger = 50\n        self.stagnation_counter = 0\n        self.previous_best_fitness = np.inf\n        self.success_fitness_improvement = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.success_cr = []\n        self.success_f = []\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation strategy with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)  # Ensure at least one p-best\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n                \n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Orthogonal learning\n                if np.random.rand() < 0.1:\n                    H = np.random.randn(self.dim, self.dim)\n                    Q, R = np.linalg.qr(H)\n                    u = self.population[i] + 0.01 * np.dot(Q, (u - self.population[i]))\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = self.fitness[i] - f_u  # Modified delta_f calculation\n                if delta_f > 0:\n\n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n                    self.success_fitness_improvement.append(delta_f)\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Update memory for SHADE - Weighted average\n            if self.success_cr and self.success_f and self.success_fitness_improvement:\n                weights = np.array(self.success_fitness_improvement)\n                weights /= np.sum(weights)  # Normalize weights\n\n                weighted_mean_cr = np.average(self.success_cr, weights=weights)\n                weighted_mean_f = np.average(self.success_f, weights=weights)\n\n                self.memory_cr[self.memory_idx] = (1 - self.cr_learning_rate) * self.memory_cr[self.memory_idx] + self.cr_learning_rate * weighted_mean_cr\n                self.memory_f[self.memory_idx] = (1 - self.f_learning_rate) * self.memory_f[self.memory_idx] + self.f_learning_rate * weighted_mean_f\n\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_cr = []\n                self.success_f = []\n                self.success_fitness_improvement = []\n\n\n            # Population reduction based on fitness\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                sorted_indices = np.argsort(self.fitness)[::-1] # Sort from worst to best\n                n_reduce = int(self.pop_size * 0.2) # Reduce 20% of the population at most\n                indices_to_remove = sorted_indices[:n_reduce]\n                \n                # Remove selected individuals\n                self.population = np.delete(self.population, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size = len(self.population)\n            \n            # Diversity-based restart mechanism\n            if self.f_opt == self.previous_best_fitness:\n                 self.stagnation_counter += 1\n            else:\n                 self.stagnation_counter = 0\n\n            self.previous_best_fitness = self.f_opt  # Update previous best fitness\n\n            if self.stagnation_counter > self.restart_trigger:\n\n                # Option 1: Re-initialize the entire population randomly\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size\n                self.stagnation_counter = 0\n                self.memory_cr = np.full(self.memory_size, 0.5)\n                self.memory_f = np.full(self.memory_size, 0.5)\n            \n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDEEARSHADEOL scored 0.371 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e1177612-f698-402a-8f5f-8f1a98336237"], "operator": null, "metadata": {"aucs": [0.17237196188237902, 0.34274776740385204, 0.4086860750822311, 0.3052393745026931, 0.2687510431393423, 0.2955698016161382, 0.32066702182315954, 0.3234608086050059, 0.35970960543407526, 0.20925189910749853, 0.4089831408096558, 0.9995359884056835, 0.28338542438462067, 0.27687453669600104, 0.7294367056037678, 0.326022369788718, 0.29702340426604346, 0.37957293308738316, 0.23780686773080983, 0.46569925292372805]}}
{"id": "3fbadccc-c5e1-4db0-839c-7f0c307aa043", "fitness": 0.0, "name": "HybridDEGradientRL", "description": "Hybrid algorithm combining differential evolution with a gradient-based local search, adaptive parameter control via reinforcement learning, and a Cauchy mutation operator for enhanced exploration.", "code": "import numpy as np\n\nclass HybridDEGradientRL:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, memory_size=10, local_search_probability=0.1, learning_rate=0.1, exploration_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1\n        self.elite_ratio = 0.1\n        self.min_pop_size = 4\n        self.local_search_probability = local_search_probability\n        self.learning_rate = learning_rate\n        self.exploration_rate = exploration_rate\n        self.archive = []\n        self.cr_learning_rate = 0.2\n        self.f_learning_rate = 0.2\n        self.rewards = np.zeros(self.memory_size)\n\n    def gradient_descent(self, func, x, learning_rate=0.01, max_iter=10):\n        x_current = x.copy()\n        f_current = func(x_current)\n        \n        for _ in range(max_iter):\n            gradient = self.approximate_gradient(func, x_current)\n            x_new = x_current - learning_rate * gradient\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n\n            if f_new < f_current:\n                x_current = x_new\n                f_current = f_new\n            else:\n                break\n        return x_current, f_current\n\n    def approximate_gradient(self, func, x, epsilon=1e-5):\n        grad = np.zeros_like(x)\n        for i in range(len(x)):\n            x_plus = x.copy()\n            x_minus = x.copy()\n            x_plus[i] += epsilon\n            x_minus[i] -= epsilon\n            grad[i] = (func(x_plus) - func(x_minus)) / (2 * epsilon)\n        return grad\n        \n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.success_cr = []\n        self.success_f = []\n        self.iteration = 0\n\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # Reinforcement learning for parameter selection\n                if np.random.rand() < self.exploration_rate:\n                    cr_i = np.random.rand()\n                    f_i = np.random.rand()\n                else:\n                    cr_i = self.memory_cr[self.memory_idx]\n                    f_i = self.memory_f[self.memory_idx]\n\n                f_i = np.clip(f_i, 0.0, 1.0)\n                \n                # Mutation using Cauchy distribution for diversity\n                cauchy_scale = 0.1\n                mutation = cauchy_scale * np.random.standard_cauchy(size=self.dim)\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                np.random.shuffle(candidates)\n                x_r1 = self.population[candidates[0]]\n                x_r2 = self.population[candidates[1]]\n\n                v = self.population[i] + f_i * (x_r1 - x_r2) + mutation\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Local search with gradient descent\n                if np.random.rand() < self.local_search_probability:\n                    u, f_u_local = self.gradient_descent(func, u)\n                    f_u = f_u_local\n                else:\n                    f_u = func(u)\n                \n                self.evals += 1\n                delta_f = f_u - self.fitness[i]\n\n                if f_u < self.fitness[i]:\n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                    reward = 1\n                else:\n                    reward = -1\n\n                self.rewards[self.memory_idx] = reward\n\n                if self.evals >= self.budget:\n                    break\n\n            # Elitism\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Update memory for parameter adaptation\n            if self.success_cr and self.success_f:\n                mean_cr = np.mean(self.success_cr)\n                mean_f = np.mean(self.success_f)\n\n                self.memory_cr[self.memory_idx] = (1 - self.cr_learning_rate) * self.memory_cr[self.memory_idx] + self.cr_learning_rate * mean_cr\n                self.memory_f[self.memory_idx] = (1 - self.f_learning_rate) * self.memory_f[self.memory_idx] + self.f_learning_rate * mean_f\n\n                # Update memory index\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_cr = []\n                self.success_f = []\n\n            self.iteration += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm HybridDEGradientRL scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["730028f6-1054-4afc-9f9f-5d67771a46ba"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "5daa2838-e96d-41d5-be4d-bf926efdcb32", "fitness": 0.7011298273698469, "name": "CovarianceMatrixDE", "description": "An adaptive DE that leverages a covariance matrix adaptation strategy for mutation and parameter control inspired by CMA-ES, alongside a local search mechanism and population diversity maintenance.", "code": "import numpy as np\n\nclass CovarianceMatrixDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, memory_size=10, local_search_probability=0.1, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1\n        self.elite_ratio = 0.1\n        self.min_pop_size = 4\n        self.local_search_probability = local_search_probability\n        self.cr_learning_rate = 0.2\n        self.f_learning_rate = 0.2\n        self.initial_step_size = initial_step_size\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for step size\n        self.damps = 1 + (3 * np.log(self.dim)) / np.sqrt(self.dim) # Damping for step size\n        self.cs = 0.3  # Learning rate for step size\n        self.cc = 2 / (self.dim + np.sqrt(2)) # Learning rate for rank-one update of C\n        self.mu_eff = self.pop_size / 4\n        self.weights = np.log(self.pop_size + 1/2) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mu_eff)\n        self.cmu = min(1-self.c1, 2 * (self.mueff-2 + 1/self.mueff) / ((self.dim+2)**2 + self.mueff))\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.success_cr = []\n        self.success_f = []\n        self.step_size = self.initial_step_size\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            sorted_indices = np.argsort(self.fitness)\n            elite_indices = sorted_indices[:self.pop_size]\n            xmean = np.sum(self.weights.reshape(-1, 1) * self.population[elite_indices], axis=0)\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n\n                # Mutation using CMA-ES-inspired strategy\n                z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                v = xmean + self.step_size * z\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Local search with probability\n                if np.random.rand() < self.local_search_probability:\n                    step_size_local = 0.01 * (func.bounds.ub - func.bounds.lb)\n                    v = v + np.random.uniform(-step_size_local, step_size_local, size=self.dim)\n                    v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = f_u - self.fitness[i]\n\n                if f_u < self.fitness[i]:\n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n            # Update memory for SHADE\n            if self.success_cr and self.success_f:\n                mean_cr = np.mean(self.success_cr)\n                mean_f = np.mean(self.success_f)\n\n                self.memory_cr[self.memory_idx] = (1 - self.cr_learning_rate) * self.memory_cr[self.memory_idx] + self.cr_learning_rate * mean_cr\n                self.memory_f[self.memory_idx] = (1 - self.f_learning_rate) * self.memory_f[self.memory_idx] + self.f_learning_rate * mean_f\n\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_cr = []\n                self.success_f = []\n\n            # CMA-ES Adaptation\n            z = (self.population[sorted_indices[0]] - xmean) / self.step_size\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * z\n            self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc)) * z\n\n            self.C = (1-self.c1-self.cmu) * self.C + self.c1 * np.outer(self.pc, self.pc)\n            \n            for k in range(self.pop_size):\n                z = (self.population[sorted_indices[k]] - xmean) / self.step_size\n                self.C += self.cmu * self.weights[k] * np.outer(z, z)\n            \n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            self.step_size *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n            \n            # Ensure the covariance matrix is positive definite\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-6 * np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm CovarianceMatrixDE scored 0.701 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["730028f6-1054-4afc-9f9f-5d67771a46ba"], "operator": null, "metadata": {"aucs": [0.2848171237886762, 0.6478553889822936, 0.749093970944678, 0.8890741813808556, 0.8272734075461039, 0.8354517829909887, 0.3652514181137393, 0.7621257124405465, 0.8323621984613849, 0.7657537273667746, 0.8703505836740061, 0.9951735560314477, 0.37197244578901134, 0.8168835166165251, 0.8789279159686434, 0.835625352477571, 0.7074562037157959, 0.8615033792139254, 0.21647231273008816, 0.5091723691638822]}}
{"id": "4faea787-e8e8-4d79-bde2-ac55201cefcb", "fitness": 0.41226624232320175, "name": "AdaptiveDECauchy", "description": "Adaptive DE with a novel mutation strategy using p-best and archive, SHADE-inspired parameter adaptation, multi-objective population reduction based on crowding distance, elitism, and a Cauchy mutation for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveDECauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, memory_size=10, local_search_probability=0.1, cauchy_mutation_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1\n        self.elite_ratio = 0.1\n        self.min_pop_size = 4\n        self.local_search_probability = local_search_probability\n        self.cr_learning_rate = 0.2\n        self.f_learning_rate = 0.2\n        self.cauchy_mutation_probability = cauchy_mutation_probability\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.success_cr = []\n        self.success_f = []\n\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n\n                # Mutation with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n\n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n                \n                # Cauchy Mutation\n                if np.random.rand() < self.cauchy_mutation_probability:\n                    cauchy_values = np.random.standard_cauchy(size=self.dim) * 0.01 * (func.bounds.ub - func.bounds.lb)\n                    v = v + cauchy_values\n                    v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Local search with probability\n                if np.random.rand() < self.local_search_probability:\n                    step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                    v = v + np.random.uniform(-step_size, step_size, size=self.dim)\n                    v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = f_u - self.fitness[i]\n\n                if f_u < self.fitness[i]:\n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Update memory for SHADE\n            if self.success_cr and self.success_f:\n                mean_cr = np.mean(self.success_cr)\n                mean_f = np.mean(self.success_f)\n\n                self.memory_cr[self.memory_idx] = (1 - self.cr_learning_rate) * self.memory_cr[self.memory_idx] + self.cr_learning_rate * mean_cr\n                self.memory_f[self.memory_idx] = (1 - self.f_learning_rate) * self.memory_f[self.memory_idx] + self.f_learning_rate * mean_f\n\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_cr = []\n                self.success_f = []\n\n            # Multi-objective Population Reduction\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                # Calculate crowding distance approximation\n                distances = np.zeros(self.pop_size)\n                sorted_fitness_indices = np.argsort(self.fitness)\n\n                distances[sorted_fitness_indices[0]] = np.inf\n                distances[sorted_fitness_indices[-1]] = np.inf\n\n                for k in range(1, self.pop_size - 1):\n                    distances[sorted_fitness_indices[k]] = distances[sorted_fitness_indices[k]] + (self.fitness[sorted_fitness_indices[k+1]] - self.fitness[sorted_fitness_indices[k-1]])\n\n                # Normalize fitness and crowding distance\n                normalized_fitness = (self.fitness - np.min(self.fitness)) / (np.max(self.fitness) - np.min(self.fitness) + 1e-8)\n                normalized_distances = distances / (np.max(distances) + 1e-8)\n\n                # Calculate combined score: balance fitness and crowding distance\n                combined_score = normalized_fitness - normalized_distances\n\n                # Remove worst individuals based on combined score\n                n_reduce = int(self.pop_size * 0.2)\n                indices_to_remove = np.argsort(combined_score)[:n_reduce]\n\n                self.population = np.delete(self.population, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size = len(self.population)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDECauchy scored 0.412 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["730028f6-1054-4afc-9f9f-5d67771a46ba"], "operator": null, "metadata": {"aucs": [0.1664143284086922, 0.20190642375584256, 0.4345832247385214, 0.8501381378997876, 0.23617262180947263, 0.5257544574339501, 0.33860683703330274, 0.3733474348257093, 0.2884471079669494, 0.19217393336750843, 0.4113874580392126, 0.9945538135238907, 0.26647706780013336, 0.28241853103861525, 0.7989068706028888, 0.33374219774719416, 0.30200384958941784, 0.5509338413847246, 0.2114064848275098, 0.4859502246707127]}}
{"id": "88f2ffa9-5147-4283-829e-d80a875a1426", "fitness": -Infinity, "name": "LandscapeAwareDE", "description": "Differential Evolution with a self-adjusting strategy based on the current function landscape, using a combination of different mutation operators and a learning mechanism for the parameters.", "code": "import numpy as np\n\nclass LandscapeAwareDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_strategies=['DE/rand/1', 'DE/current-to-best/1', 'DE/rand/2'], cr=0.7, f=0.5, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_strategies = mutation_strategies\n        self.cr = cr\n        self.f = f\n        self.learning_rate = learning_rate\n        self.fitness_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.best_fitness = self.fitness[self.best_index]\n        self.best_solution = self.population[self.best_index].copy()\n        self.fitness_history.append(self.best_fitness)\n        self.strategy_weights = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n\n        while self.evals < self.budget:\n            strategy_index = np.random.choice(len(self.mutation_strategies), p=self.strategy_weights)\n            strategy = self.mutation_strategies[strategy_index]\n\n            for i in range(self.pop_size):\n                # Mutation\n                if strategy == 'DE/rand/1':\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[indices]\n                    v = self.population[i] + self.f * (x_r2 - x_r3)\n                elif strategy == 'DE/current-to-best/1':\n                    x_best = self.population[self.best_index]\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.population[indices]\n                    v = self.population[i] + self.f * (x_best - self.population[i]) + self.f * (x_r1 - x_r2)\n                elif strategy == 'DE/rand/2':\n                    indices = np.random.choice(self.pop_size, 5, replace=False)\n                    x_r1, x_r2, x_r3, x_r4, x_r5 = self.population[indices]\n                    v = self.population[i] + self.f * (x_r2 - x_r3) + self.f * (x_r4 - x_r5)\n                else:\n                    raise ValueError(f\"Unknown mutation strategy: {strategy}\")\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.best_fitness:\n                        self.best_fitness = f_u\n                        self.best_solution = u.copy()\n                        self.best_index = i\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n            # Adjust strategy weights based on recent performance\n            if len(self.fitness_history) > 10:\n                improvements = [self.fitness_history[i] - self.fitness_history[i-1] for i in range(1,len(self.fitness_history))]\n                avg_improvement = np.mean(improvements[-10:])\n                \n                #Simple attempt to update probabilities\n                for i in range(len(self.strategy_weights)):\n                    self.strategy_weights[i] = max(0, self.strategy_weights[i] + np.random.normal(0, self.learning_rate * avg_improvement) )\n                    \n                self.strategy_weights /= np.sum(self.strategy_weights) # Normalize probabilities\n\n            self.fitness_history.append(self.best_fitness)\n            if len(self.fitness_history) > 100:\n                self.fitness_history.pop(0)\n            if self.evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occurred: scale < 0.", "error": "", "parent_ids": ["4faea787-e8e8-4d79-bde2-ac55201cefcb"], "operator": null, "metadata": {}}
{"id": "720f42d9-4c09-4fa0-a3a3-6d54052c72a4", "fitness": -Infinity, "name": "KrigingGuidedDE", "description": "Population-based DE algorithm with a multi-strategy mutation, periodic fitness landscape analysis for parameter control, and a local search guided by Kriging surrogate model.", "code": "import numpy as np\nfrom scipy.optimize import minimize\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass KrigingGuidedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, kriging_interval=500, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.kriging_interval = kriging_interval\n        self.local_search_iterations = local_search_iterations\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive_size = 50\n        self.archive = []\n        self.mutation_strategies = ['rand1', 'current_to_best', 'best2']\n        self.p_mutation_strategy = [0.4, 0.3, 0.3]\n        self.F = 0.5\n        self.CR = 0.7\n\n\n    def initialize_population(self, func):\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        return population, fitness\n\n    def mutation(self, population, fitness, strategy, best_idx, i):\n        if strategy == 'rand1':\n            idxs = np.random.choice(len(population), 3, replace=False)\n            x_r1, x_r2, x_r3 = population[idxs]\n            v = population[i] + self.F * (x_r2 - x_r3)\n        elif strategy == 'current_to_best':\n            x_best = population[best_idx]\n            idxs = np.random.choice(len(population), 2, replace=False)\n            x_r1, x_r2 = population[idxs]\n            v = population[i] + self.F * (x_best - population[i]) + self.F * (x_r1 - x_r2)\n        elif strategy == 'best2':\n            x_best = population[best_idx]\n            idxs = np.random.choice(len(population), 3, replace=False)\n            x_r1, x_r2, x_r3 = population[idxs]\n            v = x_best + self.F * (x_r1 - x_r2) + self.F * (x_r3 - population[i])\n        \n        v = np.clip(v, self.lb, self.ub)\n        return v\n\n    def crossover(self, x, v):\n        u = np.zeros_like(x)\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                u[j] = v[j]\n            else:\n                u[j] = x[j]\n        return u\n\n    def local_search(self, func, x, bounds):\n        best_x = x\n        best_f = func(x)\n        for _ in range(self.local_search_iterations):\n            res = minimize(func, x, bounds=bounds, method='L-BFGS-B')\n            if res.fun < best_f:\n                best_f = res.fun\n                best_x = res.x\n        return best_x, best_f\n\n    def build_kriging_model(self, population, fitness):\n        kernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n        gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5, random_state=42)\n        gp.fit(population, fitness)\n        return gp\n    \n    def kriging_guided_search(self, func, gp, bounds):\n        def expected_improvement(x):\n            x = x.reshape(1, -1)\n            mu, sigma = gp.predict(x, return_std=True)\n            mu_sample_opt = np.min(gp.y_train_) #Best sampled value\n            \n            imp = mu_sample_opt - mu\n            Z = imp / sigma\n            ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z) #Calculates the Expected Improvement\n\n            return -ei  #We want to maximize EI, but minimize() only minimizes, so we return the negative of EI.\n        \n        from scipy.stats import norm\n        x0 = np.random.uniform(bounds[0][0], bounds[0][1], size=self.dim)\n        res = minimize(expected_improvement, x0, bounds=bounds, method='L-BFGS-B') #Minimize the negative EI\n        return res.x, func(res.x)\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        bounds = [(self.lb, self.ub)] * self.dim\n\n        population, fitness = self.initialize_population(func)\n        self.evals += self.pop_size\n\n        while self.evals < self.budget:\n            best_idx = np.argmin(fitness)\n            \n            # Mutation and Crossover\n            new_population = []\n            new_fitness = []\n            for i in range(self.pop_size):\n                strategy = np.random.choice(self.mutation_strategies, p=self.p_mutation_strategy)\n                v = self.mutation(population, fitness, strategy, best_idx, i)\n                u = self.crossover(population[i], v)\n\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < fitness[i]:\n                    new_population.append(u)\n                    new_fitness.append(f_u)\n                    population[i] = u\n                    fitness[i] = f_u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n            # Kriging-guided search\n            if self.evals % self.kriging_interval == 0:\n                gp = self.build_kriging_model(population, fitness)\n                x_ei, f_ei = self.kriging_guided_search(func, gp, bounds)\n                self.evals += 1\n\n                if f_ei < self.f_opt:\n                    self.f_opt = f_ei\n                    self.x_opt = x_ei\n\n                worst_idx = np.argmax(fitness)\n                if f_ei < fitness[worst_idx]:\n                    population[worst_idx] = x_ei\n                    fitness[worst_idx] = f_ei\n\n            #Periodic local search\n            for i in range(self.pop_size):\n                x_local, f_local = self.local_search(func, population[i].copy(), bounds)\n                self.evals += self.local_search_iterations\n                if f_local < fitness[i]:\n                    population[i] = x_local\n                    fitness[i] = f_local\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["2c222ea9-bea6-42ac-83f9-f617d6f1b861"], "operator": null, "metadata": {}}
{"id": "b6776feb-bcf9-4a98-8aac-8e4ece2ea4f0", "fitness": 0.0, "name": "AdaptiveDECauchyEnhanced", "description": "Integrates a weighted mutation strategy, an improved local search inspired by CMA-ES, and dynamic parameter adjustments based on fitness improvement to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDECauchyEnhanced:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, memory_size=10, local_search_probability=0.1, cauchy_mutation_probability=0.1, ls_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1\n        self.elite_ratio = 0.1\n        self.min_pop_size = 4\n        self.local_search_probability = local_search_probability\n        self.cr_learning_rate = 0.2\n        self.f_learning_rate = 0.2\n        self.cauchy_mutation_probability = cauchy_mutation_probability\n        self.ls_scale = ls_scale  # Scale for local search step size\n        self.improvement_threshold = 1e-6  # Threshold for considering fitness improvement\n        self.success_count = 0 # Counter for consecutive successful local searches\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.success_cr = []\n        self.success_f = []\n\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n\n                # Mutation with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n\n                x_r2 = self.population[np.random.choice(candidates)]\n\n                # Weighted Mutation\n                w1, w2, w3, w4 = np.random.rand(4)\n                w_sum = w1 + w2 + w3 + w4\n                w1 /= w_sum\n                w2 /= w_sum\n                w3 /= w_sum\n                w4 /= w_sum\n\n                v = w1 * self.population[i] + w2 * f_i * (x_pbest - self.population[i]) + w3 * f_i * (x_r1 - x_r2) + w4 * np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n                \n                # Cauchy Mutation\n                if np.random.rand() < self.cauchy_mutation_probability:\n                    cauchy_values = np.random.standard_cauchy(size=self.dim) * 0.01 * (func.bounds.ub - func.bounds.lb)\n                    v = v + cauchy_values\n                    v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Local search with probability - CMA-ES inspired adaptation\n                if np.random.rand() < self.local_search_probability:\n                    step_size = self.ls_scale * (func.bounds.ub - func.bounds.lb) * np.exp(-0.1 * self.success_count)\n                    v_ls = v + np.random.normal(0, step_size, size=self.dim)\n                    v_ls = np.clip(v_ls, func.bounds.lb, func.bounds.ub)\n                    f_ls = func(v_ls)\n                    self.evals += 1\n                    if f_ls < func(v):\n                        v = v_ls\n                        self.success_count += 1\n                    else:\n                        self.success_count = max(0, self.success_count - 1)  # Reduce if not improving\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = f_u - self.fitness[i]\n\n                if f_u < self.fitness[i]:\n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Update memory for SHADE\n            if self.success_cr and self.success_f:\n                mean_cr = np.mean(self.success_cr)\n                mean_f = np.mean(self.success_f)\n\n                self.memory_cr[self.memory_idx] = (1 - self.cr_learning_rate) * self.memory_cr[self.memory_idx] + self.cr_learning_rate * mean_cr\n                self.memory_f[self.memory_idx] = (1 - self.f_learning_rate) * self.memory_f[self.memory_idx] + self.f_learning_rate * mean_f\n\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_cr = []\n                self.success_f = []\n\n            # Multi-objective Population Reduction\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                # Calculate crowding distance approximation\n                distances = np.zeros(self.pop_size)\n                sorted_fitness_indices = np.argsort(self.fitness)\n\n                distances[sorted_fitness_indices[0]] = np.inf\n                distances[sorted_fitness_indices[-1]] = np.inf\n\n                for k in range(1, self.pop_size - 1):\n                    distances[sorted_fitness_indices[k]] = distances[sorted_fitness_indices[k]] + (self.fitness[sorted_fitness_indices[k+1]] - self.fitness[sorted_fitness_indices[k-1]])\n\n                # Normalize fitness and crowding distance\n                normalized_fitness = (self.fitness - np.min(self.fitness)) / (np.max(self.fitness) - np.min(self.fitness) + 1e-8)\n                normalized_distances = distances / (np.max(distances) + 1e-8)\n\n                # Calculate combined score: balance fitness and crowding distance\n                combined_score = normalized_fitness - normalized_distances\n\n                # Remove worst individuals based on combined score\n                n_reduce = int(self.pop_size * 0.2)\n                indices_to_remove = np.argsort(combined_score)[:n_reduce]\n\n                self.population = np.delete(self.population, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size = len(self.population)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDECauchyEnhanced scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4faea787-e8e8-4d79-bde2-ac55201cefcb"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "dbc7937e-eccb-411f-95d4-7f1f812d0c0b", "fitness": 0.0, "name": "AdaptiveDEOLRestart", "description": "Enhanced Adaptive DE with Orthogonal Learning, a restart mechanism, and adaptive Cauchy mutation scaling for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDEOLRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, memory_size=10, local_search_probability=0.1, cauchy_mutation_probability=0.1, restart_trigger=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1\n        self.elite_ratio = 0.1\n        self.min_pop_size = 4\n        self.local_search_probability = local_search_probability\n        self.cr_learning_rate = 0.2\n        self.f_learning_rate = 0.2\n        self.cauchy_mutation_probability = cauchy_mutation_probability\n        self.restart_trigger = restart_trigger # Trigger restarts based on fitness stagnation\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.orthogonal_learning_probability = 0.2\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.success_cr = []\n        self.success_f = []\n\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            # Restart mechanism\n            if len(self.best_fitness_history) > 10:\n                if np.std(self.best_fitness_history[-10:]) < self.restart_trigger:\n                    self.stagnation_counter += 1\n                else:\n                    self.stagnation_counter = 0\n\n                if self.stagnation_counter > 5:\n                    # Reset population and parameters\n                    self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    self.fitness = np.array([func(x) for x in self.population])\n                    self.memory_cr = np.full(self.memory_size, 0.5)\n                    self.memory_f = np.full(self.memory_size, 0.5)\n                    self.stagnation_counter = 0\n                    self.archive = []\n                    self.memory_idx = 0\n                    self.success_cr = []\n                    self.success_f = []\n                    elite_indices = np.argsort(self.fitness)[:elite_count]\n                    elites = self.population[elite_indices].copy()\n                    elite_fitness = self.fitness[elite_indices].copy()\n                    print(\"Restarting population due to stagnation\")\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n\n                # Mutation with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n\n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Learning\n                if np.random.rand() < self.orthogonal_learning_probability:\n                   basis = np.random.randn(self.dim, self.dim)\n                   Q, R = np.linalg.qr(basis)  # Orthogonalize the basis\n                   step_size = 0.05 * (func.bounds.ub - func.bounds.lb)\n                   v = self.population[i] + step_size * np.dot(Q, np.random.randn(self.dim))\n                   v = np.clip(v, func.bounds.lb, func.bounds.ub)\n                \n                # Cauchy Mutation with adaptive scaling\n                if np.random.rand() < self.cauchy_mutation_probability:\n                    cauchy_scale = 0.01 * (func.bounds.ub - func.bounds.lb) * np.exp(-self.evals / self.budget * 5) # adaptively decrease scale\n                    cauchy_values = np.random.standard_cauchy(size=self.dim) * cauchy_scale\n                    v = v + cauchy_values\n                    v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n\n                # Local search with probability\n                if np.random.rand() < self.local_search_probability:\n                    step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                    v = v + np.random.uniform(-step_size, step_size, size=self.dim)\n                    v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = f_u - self.fitness[i]\n\n                if f_u < self.fitness[i]:\n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Update memory for SHADE\n            if self.success_cr and self.success_f:\n                mean_cr = np.mean(self.success_cr)\n                mean_f = np.mean(self.success_f)\n\n                self.memory_cr[self.memory_idx] = (1 - self.cr_learning_rate) * self.memory_cr[self.memory_idx] + self.cr_learning_rate * mean_cr\n                self.memory_f[self.memory_idx] = (1 - self.f_learning_rate) * self.memory_f[self.memory_idx] + self.f_learning_rate * mean_f\n\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_cr = []\n                self.success_f = []\n\n            # Multi-objective Population Reduction\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                # Calculate crowding distance approximation\n                distances = np.zeros(self.pop_size)\n                sorted_fitness_indices = np.argsort(self.fitness)\n\n                distances[sorted_fitness_indices[0]] = np.inf\n                distances[sorted_fitness_indices[-1]] = np.inf\n\n                for k in range(1, self.pop_size - 1):\n                    distances[sorted_fitness_indices[k]] = distances[sorted_fitness_indices[k]] + (self.fitness[sorted_fitness_indices[k+1]] - self.fitness[sorted_fitness_indices[k-1]])\n\n                # Normalize fitness and crowding distance\n                normalized_fitness = (self.fitness - np.min(self.fitness)) / (np.max(self.fitness) - np.min(self.fitness) + 1e-8)\n                normalized_distances = distances / (np.max(distances) + 1e-8)\n\n                # Calculate combined score: balance fitness and crowding distance\n                combined_score = normalized_fitness - normalized_distances\n\n                # Remove worst individuals based on combined score\n                n_reduce = int(self.pop_size * 0.2)\n                indices_to_remove = np.argsort(combined_score)[:n_reduce]\n\n                self.population = np.delete(self.population, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size = len(self.population)\n            \n            self.best_fitness_history.append(self.f_opt)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDEOLRestart scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4faea787-e8e8-4d79-bde2-ac55201cefcb"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "f467723a-2ba4-4c0e-a784-a4652c145f8a", "fitness": 0.20926827226387598, "name": "StochasticGradientCMAES", "description": "Combines a simplified CMA-ES with a population-based stochastic gradient search, adapting step sizes based on gradient estimates and covariance matrix adaptation.", "code": "import numpy as np\n\nclass StochasticGradientCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, learning_rate=0.01, initial_step_size=0.1, beta=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.learning_rate = learning_rate\n        self.step_size = initial_step_size\n        self.beta = beta\n        self.mean = None\n        self.C = None\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.momentum = np.zeros(self.dim)\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        if self.mean is None:\n            self.mean = np.random.uniform(lb, ub, size=self.dim)\n        if self.C is None:\n            self.C = np.eye(self.dim)\n\n        while self.evals < self.budget:\n            # Generate population around the mean using CMA-ES-like sampling\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            population = self.mean + self.step_size * z\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            fitness = np.array([func(x) for x in population])\n            self.evals += self.pop_size\n\n            # Update the best solution found so far\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n\n            # Stochastic gradient estimation\n            gradient_estimate = np.zeros(self.dim)\n            for i in range(self.pop_size):\n                gradient_estimate += (fitness[i] - self.f_opt) * (population[i] - self.mean)\n\n            gradient_estimate /= self.pop_size\n            \n            # Momentum-based update\n            self.momentum = self.beta * self.momentum + (1 - self.beta) * gradient_estimate\n\n            # Update the mean using the estimated gradient\n            self.mean = self.mean - self.learning_rate * self.momentum\n            self.mean = np.clip(self.mean, lb, ub)\n\n            # Simplified CMA-ES-like covariance matrix adaptation\n            diff = population - self.mean\n            self.C = (1 - self.learning_rate) * self.C + self.learning_rate * np.cov(diff.T)\n            \n            # Ensure C is positive semi-definite\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-6 * np.eye(self.dim)\n            \n            self.step_size *= np.exp(0.5 * (np.mean(fitness) - self.f_opt) / self.f_opt)\n\n            if self.evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm StochasticGradientCMAES scored 0.209 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5daa2838-e96d-41d5-be4d-bf926efdcb32"], "operator": null, "metadata": {"aucs": [0.030651281954998222, 0.1106406556951024, 0.19939500954379374, 0.13029601331859308, 0.12124616467757865, 0.16308807792698043, 0.165901624450702, 0.1350115381527145, 0.1486976769654309, 0.12561730367029755, 0.13001056992616156, 0.977796843600966, 0.1035028833639402, 0.18414048267865712, 0.48999398726819665, 0.20102460568995562, 0.17404917331872272, 0.15074334338976403, 0.09682259240474922, 0.3467356172802152]}}
{"id": "45a39718-7a24-4472-9ff9-fb2f03e60b8b", "fitness": 0.2066646317566926, "name": "AdaptiveDEEARSHADEOL", "description": "Combines SHADE with a modified mutation strategy using a weighted difference vector, adaptive CR/F updates, and a diversity-guided restart mechanism.", "code": "import numpy as np\n\nclass AdaptiveDEEARSHADEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10, memory_size=5, local_search_probability=0.05, reduce_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_CR = np.full(self.memory_size, 0.5)\n        self.memory_F = np.full(self.memory_size, 0.5)\n        self.p = 0.1  # Probability for selecting p-best solutions\n        self.archive = []\n        self.local_search_probability = local_search_probability\n        self.elite_ratio = 0.1\n        self.reduce_factor = reduce_factor  # Population reduction factor\n        self.min_pop_size = 10  # Minimum population size\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 5000 # Stagnation Threshold\n        self.diversity_threshold = 0.1  # Diversity threshold for restart\n        self.diversity_restart_probability = 0.1\n        self.success_history_CR = []\n        self.success_history_F = []\n        self.epsilon = 1e-6 # Small constant to prevent division by zero\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.best_fitness_history = []\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n\n        while self.evals < self.budget:\n            \n            ranked_indices = np.argsort(self.fitness)\n            p_best_indices = ranked_indices[:max(1, int(self.p * self.pop_size))]\n\n            self.success_history_CR = []\n            self.success_history_F = []\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                mem_idx = np.random.randint(self.memory_size)\n                CRm = self.memory_CR[mem_idx]\n                Fm = self.memory_F[mem_idx]\n\n                CR = np.random.normal(CRm, 0.1)\n                CR = np.clip(CR, 0.0, 1.0)\n                \n                F = np.random.normal(Fm, 0.1)\n                while F <= 0:\n                    F = np.random.normal(Fm, 0.1)\n                F = np.clip(F, 0.1, 1.0)\n\n\n                # Mutation using pbest and archive, with weighted difference vector\n                p_best_idx = np.random.choice(p_best_indices)\n                x_pbest = self.population[p_best_idx]\n                \n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                np.random.shuffle(candidates)\n                x_r1 = self.population[candidates[0]]\n                \n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    x_r2 = self.archive[arc_idx]\n                else:\n                    x_r2 = self.population[candidates[1]]\n                \n                # Calculate weights based on fitness\n                weight_pbest = np.abs(self.f_opt - self.fitness[i]) / (np.abs(self.f_opt - self.fitness[i]) + np.abs(self.f_opt - self.fitness[p_best_idx]) + self.epsilon)\n                weight_r1 = np.abs(self.f_opt - self.fitness[i]) / (np.abs(self.f_opt - self.fitness[i]) + np.abs(self.f_opt - self.fitness[candidates[0]]) + self.epsilon)\n                weight_r2 = np.abs(self.f_opt - self.fitness[i]) / (np.abs(self.f_opt - self.fitness[i]) + np.abs(self.f_opt - self.fitness[candidates[1]]) + self.epsilon)\n\n                # Create weighted difference vector\n                diff_vector = weight_pbest * (x_pbest - self.population[i]) + weight_r1 * (x_r1 - x_r2)\n                v = self.population[i] + F * diff_vector\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n                \n                if f_u < self.fitness[i]:\n                    # Local Search\n                    if np.random.rand() < self.local_search_probability:\n                        step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                        u_local = u + np.random.normal(0, step_size, size=self.dim)\n                        u_local = np.clip(u_local, func.bounds.lb, func.bounds.ub)\n                        f_u_local = func(u_local)\n                        self.evals += 1\n                        if f_u_local < f_u:\n                            f_u = f_u_local\n                            u = u_local\n                    \n                    # Update Memory\n                    self.success_history_CR.append(CR)\n                    self.success_history_F.append(F)\n\n                    # Update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    # Update population\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n            \n            #Update Memory\n            if self.success_history_CR:\n                weights = np.abs(np.array(self.success_history_CR) - self.memory_CR[self.memory_idx])\n                weights /= np.sum(weights) + self.epsilon\n                self.memory_CR[self.memory_idx] = np.sum(np.array(self.success_history_CR) * weights)\n                self.memory_F[self.memory_idx] = np.mean(self.success_history_F)\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n\n            worst_pop_index = np.argmax(self.fitness)\n\n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n\n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n            \n            #Stagnation Check\n            if len(self.best_fitness_history) > 0 and self.f_opt >= self.best_fitness_history[-1]:\n                  self.stagnation_counter += self.pop_size\n            else:\n                  self.stagnation_counter = 0\n            \n            self.best_fitness_history.append(self.f_opt)\n            \n            # Population Reduction (L-SHADE inspired)\n            if self.stagnation_counter > self.stagnation_threshold and self.pop_size > self.min_pop_size:\n                reduction_amount = max(int(self.initial_pop_size * (1 - self.reduce_factor)), self.min_pop_size) #Ensure pop_size doesnt fall below min_pop_size\n\n                if (self.pop_size - reduction_amount) < self.min_pop_size:\n                    reduction_amount = self.pop_size - self.min_pop_size\n                \n                if reduction_amount > 0: # only reduce if there is something to reduce\n                  \n                  indices_to_remove = np.argsort(self.fitness)[-reduction_amount:]\n                  self.population = np.delete(self.population, indices_to_remove, axis=0)\n                  self.fitness = np.delete(self.fitness, indices_to_remove, axis=0)\n                  self.pop_size = self.population.shape[0]\n                  self.stagnation_counter = 0 # Reset stagnation counter\n            \n            # Diversity Check and Restart\n            if np.random.rand() < self.diversity_restart_probability:\n                diversity = np.std(self.population)\n                if diversity < self.diversity_threshold:\n                    self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    self.fitness = np.array([func(x) for x in self.population])\n                    self.evals += self.pop_size\n                    self.stagnation_counter = 0\n\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDEEARSHADEOL scored 0.207 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2c222ea9-bea6-42ac-83f9-f617d6f1b861"], "operator": null, "metadata": {"aucs": [0.04836381239620824, 0.13587828121583678, 0.22200942245364463, 0.1318148286864742, 0.13089249957368954, 0.17540413558952128, 0.2094331071817903, 0.11713104828221677, 0.1940890098782625, 0.14890813741779474, 0.16618732457958663, 0.9998355800641564, 0.1295032067765567, 0.13320199945085187, 0.1451967880160293, 0.2046220333378832, 0.1727753982797633, 0.16102367096628023, 0.09173201727281355, 0.41529033371449087]}}
{"id": "a3d56485-2a54-4cc0-bb66-7e53f3ead873", "fitness": 0.4183249871799729, "name": "DynamicRingVelocityDE", "description": "A self-organizing differential evolution algorithm using a dynamic ring topology that adapts based on the fitness landscape and incorporates a velocity-based mutation strategy to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicRingVelocityDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, initial_ring_radius=5, reduction_factor=0.9, min_pop_size=5, velocity_weight=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_ring_radius = initial_ring_radius\n        self.ring_radius = initial_ring_radius\n        self.reduction_factor = reduction_factor\n        self.min_pop_size = min_pop_size\n        self.velocity_weight = velocity_weight\n        self.velocities = None\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.velocities = np.zeros((self.pop_size, self.dim))  # Initialize velocities\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Dynamic Ring Topology Neighborhood Selection based on Fitness Landscape\n                distances = np.linalg.norm(self.population - self.population[i], axis=1)\n                sorted_indices = np.argsort(distances)\n                neighbors = sorted_indices[1:min(self.ring_radius + 1, self.pop_size)] # Exclude self and limit to ring_radius\n\n                neighbor_fitnesses = self.fitness[neighbors]\n                best_neighbor_index = neighbors[np.argmin(neighbor_fitnesses)] if len(neighbors) > 0 else i\n\n                # DE Mutation with Velocity\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                r1, r2 = np.random.choice(candidates, 2, replace=False) if len(candidates) > 1 else (i, i) # Handle cases with small population\n                \n                F = np.random.uniform(0.1, 0.9) # Mutation factor\n                CR = np.random.uniform(0.1, 0.9) # Crossover rate\n\n                # Velocity update based on best neighbor and random individuals\n                self.velocities[i] = self.velocity_weight * self.velocities[i] + \\\n                                     F * (self.population[best_neighbor_index] - self.population[i] + self.population[r1] - self.population[r2])\n                \n                v = self.population[i] + self.velocities[i]\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n            # Dynamic Ring Radius Adjustment\n            self.ring_radius = max(1, int(self.initial_ring_radius * (1 - self.evals / self.budget)))\n                \n            # Dynamic Population Reduction\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                num_reduce = max(1, int((1 - self.reduction_factor) * self.pop_size))\n                worst_indices = np.argsort(self.fitness)[-num_reduce:] # Remove the worst individuals\n                self.population = np.delete(self.population, worst_indices, axis=0)\n                self.fitness = np.delete(self.fitness, worst_indices)\n                self.velocities = np.delete(self.velocities, worst_indices, axis=0) # Delete velocities as well\n                self.pop_size = len(self.population)\n\n                if self.pop_size < self.min_pop_size:\n                    num_to_add = self.min_pop_size - self.pop_size\n                    new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_add, self.dim))\n                    new_fitness = np.array([func(x) for x in new_individuals])\n                    new_velocities = np.zeros((num_to_add, self.dim)) # Initialize new velocities\n                    self.population = np.vstack((self.population, new_individuals))\n                    self.fitness = np.concatenate((self.fitness, new_fitness))\n                    self.velocities = np.vstack((self.velocities, new_velocities))\n                    self.pop_size = len(self.population)\n                    self.evals += num_to_add\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm DynamicRingVelocityDE scored 0.418 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f8670b29-75c0-4d09-a621-607b3ca4d291"], "operator": null, "metadata": {"aucs": [0.1605170782919677, 0.24521224923983853, 0.4065039400768483, 0.4741124615490715, 0.37030065131394885, 0.3782593892996948, 0.31578025731161075, 0.3947453164950493, 0.3887295637321635, 0.36590745075222575, 0.2944758064332985, 0.9961074060523936, 0.2980453289497961, 0.47772965140066437, 0.7778127433005455, 0.4534656054256013, 0.3169477169352445, 0.5361830287344955, 0.21223623127031788, 0.5034278670346832]}}
{"id": "6ce5ba8b-cf65-4e12-a9b2-aec3cf246e7c", "fitness": 0.5657809622190249, "name": "AdaptiveRingDE", "description": "A DE variant that dynamically adjusts its mutation strategy based on the success rate of different mutation operators within subpopulations arranged in a ring topology.", "code": "import numpy as np\n\nclass AdaptiveRingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, ring_radius=5, mutation_strategies=[\"DE/rand/1\", \"DE/local/1\", \"DE/current-to-best/1\"]):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.ring_radius = ring_radius\n        self.mutation_strategies = mutation_strategies\n        self.strategy_successes = {strategy: np.zeros(pop_size) for strategy in self.mutation_strategies}  # Track success of each strategy for each individual\n        self.F = np.random.uniform(0.1, 0.9, size=pop_size)\n        self.CR = np.random.uniform(0.1, 0.9, size=pop_size)\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Ring Topology Neighborhood Selection\n                neighbors = [(i + j) % self.pop_size for j in range(-self.ring_radius, self.ring_radius + 1) if j != 0]\n                neighbor_fitnesses = self.fitness[neighbors]\n                best_neighbor_index = neighbors[np.argmin(neighbor_fitnesses)]\n\n                # Strategy Selection based on recent success\n                strategy_success_rates = {strategy: np.mean(self.strategy_successes[strategy][i]) for strategy in self.mutation_strategies}\n                best_strategy = max(strategy_success_rates, key=strategy_success_rates.get) # Chooses strategy with highest average recent success\n                # Mutation\n                if best_strategy == \"DE/rand/1\":\n                    candidates = list(range(self.pop_size))\n                    candidates.remove(i)\n                    r1, r2, r3 = np.random.choice(candidates, 3, replace=False)\n                    v = self.population[r1] + self.F[i] * (self.population[r2] - self.population[r3])\n                elif best_strategy == \"DE/local/1\":\n                     candidates = list(range(self.pop_size))\n                     candidates.remove(i)\n                     r1, r2 = np.random.choice(candidates, 2, replace=False)\n                     v = self.population[i] + self.F[i] * (self.population[best_neighbor_index] - self.population[i] + self.population[r1] - self.population[r2])\n                elif best_strategy == \"DE/current-to-best/1\":\n                    candidates = list(range(self.pop_size))\n                    candidates.remove(i)\n                    r1, r2 = np.random.choice(candidates, 2, replace=False)\n                    v = self.population[i] + self.F[i] * (self.population[best_neighbor_index] - self.population[i]) + self.F[i] * (self.population[r1] - self.population[r2])\n                else:\n                    raise ValueError(\"Invalid mutation strategy\")\n\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR[i] or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.strategy_successes[best_strategy][i] = 1 # Mark Strategy as a success for individual i\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    self.strategy_successes[best_strategy][i] = 0 # Mark Strategy as a failure for individual i\n\n\n                if self.evals >= self.budget:\n                    break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveRingDE scored 0.566 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f8670b29-75c0-4d09-a621-607b3ca4d291"], "operator": null, "metadata": {"aucs": [0.2030877904332361, 0.2944609940370395, 0.5046247423261836, 0.8041856061851714, 0.6050115529574674, 0.7165596541300845, 0.5455587883869601, 0.5419923746175843, 0.6364272084635241, 0.437468272930991, 0.7324999234542857, 0.9928546269049489, 0.2970626285730409, 0.5282312898398278, 0.8361116030153014, 0.7619692731054475, 0.38303100485228014, 0.7524501205508736, 0.21834496909630696, 0.5236868205199416]}}
{"id": "cc536802-4611-4c78-86ff-19257cca47d9", "fitness": 0.6115120565888787, "name": "FuzzyAdaptiveDE", "description": "A DE variant incorporating a multi-strategy mutation that adaptively selects between different mutation strategies, a fuzzy adaptive parameter control and a simplified population reduction strategy.", "code": "import numpy as np\n\nclass FuzzyAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, memory_size=5, reduce_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_CR = np.full(self.memory_size, 0.5)\n        self.memory_F = np.full(self.memory_size, 0.5)\n        self.archive = []\n        self.elite_ratio = 0.1\n        self.reduce_factor = reduce_factor  # Population reduction factor\n        self.min_pop_size = 10  # Minimum population size\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 5000\n        self.success_history_CR = []\n        self.success_history_F = []\n        self.mutation_strategy_probabilities = np.array([0.33, 0.33, 0.34]) # Probabilities for selecting mutation strategies\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.best_fitness_history = []\n\n        # Elitism: Keep track of the best individuals\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n\n            # Fuzzy Adaptive Parameter Control\n            fuzzy_rules = {\n                'CR_low': {'F_low': (0.9, 0.1), 'F_high': (0.7, 0.3)},\n                'CR_high': {'F_low': (0.3, 0.7), 'F_high': (0.1, 0.9)}\n            }\n            \n            ranked_indices = np.argsort(self.fitness)\n            best_index = ranked_indices[0]\n            worst_index = ranked_indices[-1]\n\n            CR_range = np.std(self.population) #Diversity measure for CR\n            F_range = np.abs(self.fitness[best_index] - self.fitness[worst_index]) #Fitness difference for F\n\n            # Normalize ranges to [0, 1]\n            CR_norm = np.clip((CR_range - 0) / (5 - 0), 0, 1) # Assume max range is 5\n            F_norm = np.clip((F_range - 0) / (10 - 0), 0, 1) # Assume max fitness difference is 10\n\n            #Fuzzification\n            CR_membership_low = 1 - CR_norm\n            CR_membership_high = CR_norm\n            F_membership_low = 1 - F_norm\n            F_membership_high = F_norm\n            \n            #Rule Evaluation and Aggregation\n            rule1 = min(CR_membership_low, F_membership_low) #if CR is low AND F is low\n            rule2 = min(CR_membership_low, F_membership_high) #if CR is low AND F is high\n            rule3 = min(CR_membership_high, F_membership_low) #if CR is high AND F is low\n            rule4 = min(CR_membership_high, F_membership_high) #if CR is high AND F is high\n\n            #Consequent determination and aggregation\n            CR_val1 = fuzzy_rules['CR_low']['F_low'][0] #High\n            F_val1 = fuzzy_rules['CR_low']['F_low'][1] #Low\n            CR_val2 = fuzzy_rules['CR_low']['F_high'][0] #High\n            F_val2 = fuzzy_rules['CR_low']['F_high'][1] #High\n            CR_val3 = fuzzy_rules['CR_high']['F_low'][0] #Low\n            F_val3 = fuzzy_rules['CR_high']['F_low'][1] #Low\n            CR_val4 = fuzzy_rules['CR_high']['F_high'][0] #Low\n            F_val4 = fuzzy_rules['CR_high']['F_high'][1] #High\n\n            CR = (rule1*CR_val1 + rule2*CR_val2 + rule3*CR_val3 + rule4*CR_val4) / (rule1+rule2+rule3+rule4 + 1e-6)\n            F = (rule1*F_val1 + rule2*F_val2 + rule3*F_val3 + rule4*F_val4) / (rule1+rule2+rule3+rule4 + 1e-6)\n\n            CR = np.clip(CR, 0.0, 1.0)\n            F = np.clip(F, 0.1, 1.0)\n\n            for i in range(self.pop_size):\n\n                # Adaptive Mutation Strategy Selection\n                mutation_strategy = np.random.choice([0, 1, 2], p=self.mutation_strategy_probabilities)\n                \n                if mutation_strategy == 0:  # DE/rand/1\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[indices]\n                    v = self.population[i] + F * (x_r1 - x_r2) + F * (x_r3 - self.population[i])\n                elif mutation_strategy == 1:  # DE/current-to-best/1\n                    best_index = np.argmin(self.fitness)\n                    x_best = self.population[best_index]\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.population[indices]\n                    v = self.population[i] + F * (x_best - self.population[i]) + F * (x_r1 - x_r2)\n                else:  #DE/rand/2\n                    indices = np.random.choice(self.pop_size, 5, replace=False)\n                    x_r1, x_r2, x_r3, x_r4, x_r5 = self.population[indices]\n                    v = self.population[i] + F * (x_r1 - x_r2) + F * (x_r3 - x_r4) + F * (x_r5 - self.population[i]) # Add current vector\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n                if f_u < self.fitness[i]:\n                    # Update Memory (simplified, no SHADE)\n                    self.success_history_CR.append(CR)\n                    self.success_history_F.append(F)\n\n                    # Update archive\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    # Update population\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n            #Update Memory\n            if self.success_history_CR:\n                self.memory_CR[self.memory_idx] = np.mean(self.success_history_CR)\n                self.memory_F[self.memory_idx] = np.mean(self.success_history_F)\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n\n            worst_pop_index = np.argmax(self.fitness)\n\n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n\n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n                \n            #Stagnation Check\n            if len(self.best_fitness_history) > 0 and self.f_opt >= self.best_fitness_history[-1]:\n                  self.stagnation_counter += self.pop_size\n            else:\n                  self.stagnation_counter = 0\n            \n            self.best_fitness_history.append(self.f_opt)\n\n            # Population Reduction (simplified L-SHADE inspired)\n            if self.stagnation_counter > self.stagnation_threshold and self.pop_size > self.min_pop_size:\n                reduction_amount = int(self.pop_size * (1 - self.reduce_factor))\n                if (self.pop_size - reduction_amount) < self.min_pop_size:\n                    reduction_amount = self.pop_size - self.min_pop_size\n\n                if reduction_amount > 0:\n                  indices_to_remove = np.argsort(self.fitness)[-reduction_amount:]\n                  self.population = np.delete(self.population, indices_to_remove, axis=0)\n                  self.fitness = np.delete(self.fitness, indices_to_remove, axis=0)\n                  self.pop_size = self.population.shape[0]\n                  self.stagnation_counter = 0 # Reset stagnation counter\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm FuzzyAdaptiveDE scored 0.612 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2c222ea9-bea6-42ac-83f9-f617d6f1b861"], "operator": null, "metadata": {"aucs": [0.20555126683929603, 0.5174067056833654, 0.4465583363620951, 0.8464439704161784, 0.6585179688127496, 0.7962748763678397, 0.45818359418256993, 0.6393997496170791, 0.7674042110311374, 0.36455182633273053, 0.8163214022121793, 0.9972059214903438, 0.296097809365487, 0.5644283506423631, 0.8839130935333811, 0.7949406820978004, 0.6094378682975331, 0.834449534501293, 0.23578812133536986, 0.4973658426567835]}}
{"id": "78762991-230b-4453-9f6c-0832c8aed89a", "fitness": -Infinity, "name": "KNNDESocial", "description": "An adaptive DE using a k-nearest neighbors-based social learning strategy with dynamic parameter adjustment based on success history and population diversity.", "code": "import numpy as np\nfrom scipy.spatial import KDTree\n\nclass KNNDESocial:\n    def __init__(self, budget=10000, dim=10, pop_size=50, k_neighbors=5, archive_size=10, initial_F=0.5, initial_CR=0.7, F_decay=0.99, CR_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.k_neighbors = k_neighbors\n        self.archive_size = archive_size\n        self.initial_F = initial_F\n        self.initial_CR = initial_CR\n        self.F_decay = F_decay\n        self.CR_decay = CR_decay\n        self.archive = []\n        self.archive_fitness = []\n        self.F_history = []\n        self.CR_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.F = self.initial_F\n        self.CR = self.initial_CR\n\n        while self.evals < self.budget:\n            tree = KDTree(self.population)  # Build KDTree for neighbor search\n\n            for i in range(self.pop_size):\n                # Social Learning: Find k-nearest neighbors (excluding self)\n                distances, indices = tree.query(self.population[i], k=self.k_neighbors + 1)\n                neighbors = indices[1:]  # Exclude the individual itself\n\n                # Select a random neighbor as the social influence\n                neighbor_index = np.random.choice(neighbors)\n                \n                # DE Mutation with Social Learning\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                r1, r2 = np.random.choice(candidates, 2, replace=False)\n                \n                v = self.population[i] + self.F * (self.population[neighbor_index] - self.population[i] + self.population[r1] - self.population[r2])\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Success: Update population and archive\n                    delta_f = self.fitness[i] - f_u\n                    self.F_history.append(self.F)\n                    self.CR_history.append(self.CR)\n                    \n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                    \n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(u)\n                        self.archive_fitness.append(f_u)\n                    else:\n                        # Replace the worst in archive\n                        max_archive_index = np.argmax(self.archive_fitness)\n                        if f_u < self.archive_fitness[max_archive_index]:\n                            self.archive[max_archive_index] = u\n                            self.archive_fitness[max_archive_index] = f_u\n                \n                #Parameter adaptation\n                self.F *= self.F_decay\n                self.CR *= self.CR_decay\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occurred: name 'KDTree' is not defined.", "error": "", "parent_ids": ["f8670b29-75c0-4d09-a621-607b3ca4d291"], "operator": null, "metadata": {}}
{"id": "75733154-5e71-411a-ac87-79e49eb1ec37", "fitness": 0.45037815263364933, "name": "AdaptiveDEOCauchy", "description": "Improved adaptive DE with orthogonal crossover, adaptive local search, and enhanced Cauchy mutation based on successful individuals to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass AdaptiveDEOCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, memory_size=10, local_search_probability=0.1, cauchy_mutation_probability=0.1, orthogonal_crossover_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1\n        self.elite_ratio = 0.1\n        self.min_pop_size = 4\n        self.local_search_probability = local_search_probability\n        self.cr_learning_rate = 0.2\n        self.f_learning_rate = 0.2\n        self.cauchy_mutation_probability = cauchy_mutation_probability\n        self.orthogonal_crossover_probability = orthogonal_crossover_probability\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.success_cr = []\n        self.success_f = []\n        self.success_vectors = []\n\n        elite_count = int(self.elite_ratio * self.pop_size)\n        elite_indices = np.argsort(self.fitness)[:elite_count]\n        elites = self.population[elite_indices].copy()\n        elite_fitness = self.fitness[elite_indices].copy()\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n\n                # Mutation with p-best and archive\n                p_best_count = max(int(self.p * self.pop_size), 1)\n                p_best_indices = np.argsort(self.fitness)[:p_best_count]\n                x_pbest = self.population[np.random.choice(p_best_indices)]\n\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n\n                use_archive = np.random.rand() < 0.1\n                if len(self.archive) > 0 and use_archive:\n                    a = np.random.choice(len(self.archive))\n                    x_r1 = self.archive[a]\n                else:\n                    np.random.shuffle(candidates)\n                    x_r1 = self.population[candidates[0]]\n\n                x_r2 = self.population[np.random.choice(candidates)]\n                v = self.population[i] + f_i * (x_pbest - self.population[i] + x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n                \n                # Cauchy Mutation based on successful individuals\n                if np.random.rand() < self.cauchy_mutation_probability:\n                    if len(self.success_vectors) > 0:\n                        # Calculate mean displacement vector from successful mutations\n                        mean_displacement = np.mean(self.success_vectors, axis=0)\n                        cauchy_values = np.random.standard_cauchy(size=self.dim) * 0.01 * mean_displacement  # Scale by mean displacement\n                        v = v + cauchy_values\n                        v = np.clip(v, func.bounds.lb, func.bounds.ub)\n                    else:\n                        cauchy_values = np.random.standard_cauchy(size=self.dim) * 0.01 * (func.bounds.ub - func.bounds.lb)\n                        v = v + cauchy_values\n                        v = np.clip(v, func.bounds.lb, func.bounds.ub)\n                        \n\n                # Local search with adaptive step size\n                if np.random.rand() < self.local_search_probability:\n                    adaptive_step_size = 0.01 * (func.bounds.ub - func.bounds.lb) * np.random.rand() # Smaller steps more often\n                    v = v + np.random.uniform(-adaptive_step_size, adaptive_step_size, size=self.dim)\n                    v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                if np.random.rand() < self.orthogonal_crossover_probability:\n                    u = self.orthogonal_crossover(self.population[i], v, func.bounds.lb, func.bounds.ub)\n                else:\n                    # Crossover\n                    u = np.zeros(self.dim)\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < cr_i or j == j_rand:\n                            u[j] = v[j]\n                        else:\n                            u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = f_u - self.fitness[i]\n\n                if f_u < self.fitness[i]:\n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n                    self.success_vectors.append(u - self.population[i])  # Store the displacement vector\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n            # Elitism Replacement\n            worst_elite_index = np.argmax(elite_fitness)\n            worst_elite_fitness = elite_fitness[worst_elite_index]\n            \n            worst_pop_index = np.argmax(self.fitness)\n            \n            if worst_elite_fitness > self.fitness[worst_pop_index]:\n                elite_fitness[worst_elite_index] = self.fitness[worst_pop_index]\n                elites[worst_elite_index] = self.population[worst_pop_index].copy()\n                \n                self.population[worst_pop_index] = elites[worst_elite_index].copy()\n                self.fitness[worst_pop_index] = elite_fitness[worst_elite_index]\n\n            # Update memory for SHADE\n            if self.success_cr and self.success_f:\n                mean_cr = np.mean(self.success_cr)\n                mean_f = np.mean(self.success_f)\n\n                self.memory_cr[self.memory_idx] = (1 - self.cr_learning_rate) * self.memory_cr[self.memory_idx] + self.cr_learning_rate * mean_cr\n                self.memory_f[self.memory_idx] = (1 - self.f_learning_rate) * self.memory_f[self.memory_idx] + self.f_learning_rate * mean_f\n\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_cr = []\n                self.success_f = []\n                self.success_vectors = []\n\n            # Multi-objective Population Reduction\n            if self.evals < self.budget and self.pop_size > self.min_pop_size:\n                # Calculate crowding distance approximation\n                distances = np.zeros(self.pop_size)\n                sorted_fitness_indices = np.argsort(self.fitness)\n\n                distances[sorted_fitness_indices[0]] = np.inf\n                distances[sorted_fitness_indices[-1]] = np.inf\n\n                for k in range(1, self.pop_size - 1):\n                    distances[sorted_fitness_indices[k]] = distances[sorted_fitness_indices[k]] + (self.fitness[sorted_fitness_indices[k+1]] - self.fitness[sorted_fitness_indices[k-1]])\n\n                # Normalize fitness and crowding distance\n                normalized_fitness = (self.fitness - np.min(self.fitness)) / (np.max(self.fitness) - np.min(self.fitness) + 1e-8)\n                normalized_distances = distances / (np.max(distances) + 1e-8)\n\n                # Calculate combined score: balance fitness and crowding distance\n                combined_score = normalized_fitness - normalized_distances\n\n                # Remove worst individuals based on combined score\n                n_reduce = int(self.pop_size * 0.2)\n                indices_to_remove = np.argsort(combined_score)[:n_reduce]\n\n                self.population = np.delete(self.population, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size = len(self.population)\n\n        return self.f_opt, self.x_opt\n\n    def orthogonal_crossover(self, x1, x2, lb, ub):\n        \"\"\"Performs orthogonal crossover between two individuals.\"\"\"\n        basis = np.random.randn(self.dim, self.dim)  # Generate a random basis\n        basis, _ = np.linalg.qr(basis)  # Orthonormalize the basis\n\n        # Project the individuals onto the basis vectors\n        proj_x1 = np.dot(x1, basis)\n        proj_x2 = np.dot(x2, basis)\n\n        # Create a new individual by swapping some projections\n        mask = np.random.choice([0, 1], size=self.dim)  # Randomly select which projections to swap\n        proj_new = np.where(mask == 1, proj_x1, proj_x2)\n\n        # Reconstruct the individual\n        new_x = np.dot(proj_new, basis.T)\n\n        # Clip to bounds\n        new_x = np.clip(new_x, lb, ub)\n        return new_x", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDEOCauchy scored 0.450 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4faea787-e8e8-4d79-bde2-ac55201cefcb"], "operator": null, "metadata": {"aucs": [0.13714947969988012, 0.1714945519717156, 0.5304335590618265, 0.8973559300989187, 0.2645779319391046, 0.35395208213492135, 0.29858725933510843, 0.4593295316943631, 0.275771725620339, 0.17375747794876284, 0.853186450830724, 0.9938821669447242, 0.23362641226673164, 0.2634317512801643, 0.7106742403621176, 0.5904953120529366, 0.29815532882734064, 0.7839879909731848, 0.22184707531528647, 0.49586679431483593]}}
{"id": "64eaf2b1-f4a3-401c-b3fe-c17096f74965", "fitness": 0.6318466884293451, "name": "DynamicDE", "description": "A differential evolution strategy employing a dynamic population size adjustment based on fitness landscape ruggedness and a weighted mutation scheme to balance exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, F=0.5, CR=0.9, ruggedness_threshold=0.01, reduction_factor=0.9, exploration_weight=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.F = F\n        self.CR = CR\n        self.ruggedness_threshold = ruggedness_threshold\n        self.reduction_factor = reduction_factor\n        self.exploration_weight = exploration_weight\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 5000\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Calculate fitness landscape ruggedness\n            fitness_diffs = np.abs(self.fitness[:, np.newaxis] - self.fitness)\n            ruggedness = np.mean(fitness_diffs)\n\n            # Adjust population size based on ruggedness\n            if ruggedness > self.ruggedness_threshold and self.pop_size < self.initial_pop_size * 2:\n                self.pop_size = min(self.pop_size + 1, self.initial_pop_size * 2)\n                new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - len(self.population), self.dim))\n                self.population = np.vstack((self.population, new_individuals))\n                new_fitness = np.array([func(x) for x in new_individuals])\n                self.fitness = np.concatenate((self.fitness, new_fitness))\n                self.evals += len(new_individuals)\n\n            for i in range(self.pop_size):\n                # Weighted Mutation (mixes current-to-pbest and standard DE mutation)\n                indices = np.random.choice(self.pop_size, 4, replace=False)\n                x_r1, x_r2, x_r3, x_r4 = self.population[indices]\n\n                # p-best selection for current-to-pbest mutation\n                p_best_idx = np.argsort(self.fitness)[:max(1, int(0.1 * self.pop_size))][np.random.randint(max(1, int(0.1 * self.pop_size)))]\n                x_pbest = self.population[p_best_idx]\n\n                v1 = self.population[i] + self.F * (x_pbest - self.population[i]) + self.F * (x_r1 - x_r2)\n                v2 = x_r3 + self.F * (x_r1 - x_r2)\n                \n                v = self.exploration_weight * v1 + (1 - self.exploration_weight) * v2\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n            #Stagnation Check\n            if len(self.best_fitness_history) > 0 and self.f_opt >= self.best_fitness_history[-1]:\n                self.stagnation_counter += self.pop_size\n            else:\n                self.stagnation_counter = 0\n            \n            self.best_fitness_history.append(self.f_opt)\n\n            # Dynamic Population Reduction based on stagnation\n            if self.stagnation_counter > self.stagnation_threshold and self.pop_size > self.min_pop_size:\n                reduction_amount = max(int(self.initial_pop_size * (1 - self.reduction_factor)), self.min_pop_size)\n\n                if (self.pop_size - reduction_amount) < self.min_pop_size:\n                    reduction_amount = self.pop_size - self.min_pop_size\n                \n                if reduction_amount > 0:\n                    indices_to_remove = np.argsort(self.fitness)[-reduction_amount:]\n                    self.population = np.delete(self.population, indices_to_remove, axis=0)\n                    self.fitness = np.delete(self.fitness, indices_to_remove, axis=0)\n                    self.pop_size = self.population.shape[0]\n                    self.stagnation_counter = 0 # Reset stagnation counter\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm DynamicDE scored 0.632 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2c222ea9-bea6-42ac-83f9-f617d6f1b861"], "operator": null, "metadata": {"aucs": [0.3215914048779799, 0.8089745555970878, 0.49118048106651446, 0.2633415085165146, 0.813166937888196, 0.8439982932175127, 0.6192020656347734, 0.7321112223277351, 0.8047166260665829, 0.3838779575376686, 0.9252502877216455, 0.9956929722513231, 0.4766960287859222, 0.8103389726751918, 0.6742930185256026, 0.3702409658696064, 0.6888311120561041, 0.8947825011451762, 0.2190133258272291, 0.499633530998537]}}
