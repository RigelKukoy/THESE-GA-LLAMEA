{"id": "26de202a-8ab3-4fdd-92ee-aeb6aaf3a61b", "fitness": -Infinity, "name": "CMAES", "description": "Covariance matrix adaptation evolution strategy with mirrored sampling and a budget-aware adaptation of the step size.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, mu_factor = 0.25, cs = 0.3, c_cov = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(mu_factor * dim)\n        self.lambda_ = 4 * self.mu  # Population size\n        self.weights = np.log(self.lambda_ + 1/2) - np.log(np.arange(1, self.lambda_ + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = None # Mean\n        self.sigma = 0.5 # Step size\n        self.C = None # Covariance matrix\n        self.pc = None # Evolution path for C\n        self.ps = None # Evolution path for sigma\n        self.chiN = np.sqrt(self.dim) * (1 - (1/(4*self.dim)) + 1/(21 * self.dim**2))\n        self.cs = cs\n        self.c_cov = c_cov\n\n    def __call__(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        used_budget = 0\n\n        while used_budget < self.budget:\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.lambda_)\n            x = self.m + self.sigma * z\n            \n            # Mirror sampling\n            x_mirrored = self.m - self.sigma * z\n            x = np.vstack((x, x_mirrored))\n            \n            # Clip to bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += 2 * self.lambda_  # Account for mirrored points\n\n            if used_budget > self.budget:\n                # Truncate if we exceeded budget\n                num_to_keep = 2*self.lambda_ - (used_budget - self.budget)\n                idx = np.argsort(f)[:int(num_to_keep)]  # Get indices of best solutions within budget\n                x = x[idx]\n                f = f[idx]\n                used_budget = self.budget\n\n            idx = np.argsort(f)[:self.mu]\n            x_best = x[idx]\n            z_best = (x_best - self.m) / self.sigma\n\n            self.m = np.sum(self.weights[:, None] * x_best, axis=0)\n\n            # Adapt step size\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * np.sum(self.weights[:, None] * z_best, axis=0)\n            sigma_adapt = np.linalg.norm(self.ps) / self.chiN\n            self.sigma *= np.exp(self.cs/0.6 * (sigma_adapt - 1))\n            self.sigma = max(self.sigma, 1e-10)\n\n            # Adapt covariance matrix\n            self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * np.sum(self.weights[:, None] * (x_best - self.m), axis=0) / self.sigma\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :])\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occurred: zero-size array to reduction operation minimum which has no identity.", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "24239a80-1b7e-47e6-b5fa-76c3d142511a", "fitness": -Infinity, "name": "CMAES", "description": "Covariance matrix adaptation evolution strategy with resampling and adaptive step size control.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov_rank_one=None, c_cov_mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.mu-1)/(self.dim+1))-1) + self.cs\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 1 / (10*self.dim**2) * (self.budget/self.popsize)\n        self.c_cov_mu = c_cov_mu if c_cov_mu is not None else 2 / (self.dim**2) * (self.budget/self.popsize)\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def sample_population(self):\n        z = np.random.randn(self.dim, self.popsize)\n        C_sqrt = np.linalg.cholesky(self.C)\n        x = self.m[:, np.newaxis] + self.sigma * C_sqrt @ z\n        x = np.clip(x, -5, 5)\n        return x.T, z\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            x, z = self.sample_population()\n            f = np.array([func(xi) for xi in x])\n            self.eval_count += self.popsize\n            \n            idx = np.argsort(f)\n            x = x[idx]\n            z = z[:, idx]\n            f = f[idx]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n            \n            z_mu = np.sum(self.weights * z[:, :self.mu], axis=1)\n            self.m = self.m + self.cs * self.sigma * z_mu\n\n            self.ps = (1 - self.cs) * self.ps + (self.cs**0.5) * z_mu\n            norm_ps = np.linalg.norm(self.ps)\n            \n            c_mu = min(1, self.c_cov_mu * self.popsize / (np.linalg.norm(self.ps)**2 + 1e-8) )\n\n            self.pc = (1 - c_mu) * self.pc + np.sqrt(c_mu * (2 - c_mu)) * z_mu\n            \n\n            self.C = (1 - self.c_cov_rank_one - self.c_cov_mu) * self.C \\\n                     + self.c_cov_rank_one * np.outer(self.pc, self.pc) \\\n                     + self.c_cov_mu * np.sum(self.weights[i] * np.outer(z[:,i], z[:,i]) for i in range(self.mu))\n\n            self.sigma = self.sigma * np.exp((self.cs / self.damps) * (norm_ps / self.chiN - 1))\n\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            \n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-6 * np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occurred: Matrix is not positive definite.", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "64343faf-abe7-4909-9743-1f91bab87a2d", "fitness": -Infinity, "name": "CMAES_with_Restart", "description": "Covariance matrix adaptation evolution strategy with resampling and archive.", "code": "import numpy as np\n\nclass CMAES_with_Restart:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, c_cov=0.1, sigma0=0.2, mu_ratio=0.25, archive_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.cs = cs\n        self.c_cov = c_cov\n        self.sigma = sigma0\n        self.mu = int(self.popsize * mu_ratio)\n        self.weights = np.log(self.popsize + 1) - np.log(np.arange(1, self.popsize + 1))\n        self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.eigen_updated = 0\n        self.D = None\n        self.B = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive_x = []\n        self.archive_f = []\n        self.archive_size = archive_size\n\n\n    def sample(self, func):\n        z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n        y = self.sigma * (self.B @ (self.D * z))\n        x = self.m + y\n        \n        #Check Bounds and Resample\n        for i in range(self.popsize):\n             while not func.bounds.contains(x[:,i]):\n                z[:,i] = np.random.normal(0, 1, size=(self.dim))\n                y[:,i] = self.sigma * (self.B @ (self.D * z[:,i]))\n                x[:,i] = self.m + y[:,i]\n\n        f = np.array([func(x[:, i]) for i in range(self.popsize)])\n        return x, f, y\n\n    def update(self, x, f, y):\n        idx = np.argsort(f)\n        x_sorted = x[:, idx]\n        y_sorted = y[:, idx]\n\n        m_old = self.m.copy()\n        self.m = np.sum(self.weights * x_sorted[:, :self.mu], axis=1)\n        y_w = np.sum(self.weights * y_sorted[:, :self.mu], axis=1)\n\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * np.sum(self.weights**2)) * (self.B @ self.D @ (y_w / self.sigma))\n        self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov) * np.sum(self.weights**2)) * (self.m - m_old) / self.sigma\n\n        self.sigma *= np.exp((self.cs / 0.817) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n\n        dC = self.weights * y_sorted[:, :self.mu] @ y_sorted[:, :self.mu].T\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * (dC / self.sigma**2 + self.c_cov * (1 - self.c_cov)**-1 * self.pc[:, None] @ self.pc[None, :])\n\n    def update_eigen(self):\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        self.D, self.B = np.linalg.eigh(self.C)\n        self.D = np.sqrt(np.maximum(self.D, 1e-16))\n        self.eigen_updated = 0\n    \n    def archive(self, x, f):\n        for i in range(x.shape[1]):\n            xi = x[:,i]\n            fi = f[i]\n\n            # Check for duplicates within the archive\n            duplicate = False\n            for archived_x in self.archive_x:\n                if np.allclose(xi, archived_x):\n                    duplicate = True\n                    break\n\n            if not duplicate:\n                self.archive_x.append(xi)\n                self.archive_f.append(fi)\n                \n                if len(self.archive_x) > self.archive_size:\n                    worst_idx = np.argmax(self.archive_f)\n                    del self.archive_x[worst_idx]\n                    del self.archive_f[worst_idx]\n    \n    def restart(self, func):\n         # Sample from the archive if available\n        if self.archive_x:\n            idx = np.argmin(self.archive_f)\n            self.m = self.archive_x[idx].copy()\n            self.sigma = 0.2  # Reset sigma to a default value upon restart\n\n        else:\n            self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.update_eigen()\n        self.eigen_updated = 0\n\n    def __call__(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.update_eigen()\n\n        fevals = 0\n        restarts = 0\n        max_restarts = 5\n\n        while fevals < self.budget and restarts < max_restarts:\n            x, f, y = self.sample(func)\n            fevals += self.popsize\n\n            # Update archive\n            self.archive(x, f)\n\n            # Update best solution\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[:, np.argmin(f)]\n\n            self.update(x, f, y)\n            self.eigen_updated += 1\n\n            if self.eigen_updated > self.popsize / 2:\n                self.update_eigen()\n\n            # Restart mechanism\n            if self.sigma < 1e-10:  # Check if the step size is too small.\n                self.restart(func)\n                restarts += 1\n        \n        # Final check with archive for best solution\n        if self.archive_f:\n            best_archive_idx = np.argmin(self.archive_f)\n            if self.archive_f[best_archive_idx] < self.f_opt:\n                self.f_opt = self.archive_f[best_archive_idx]\n                self.x_opt = self.archive_x[best_archive_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,) (2,6) .", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "8b639242-117f-44c5-8db5-0d336d1d85c1", "fitness": 0.35414685534124435, "name": "AdaptiveVelocityParticleSwarm", "description": "Population-based algorithm with velocity updates biased towards the best-performing individual and adaptive exploration based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveVelocityParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = 0.5  # Clamp velocities to prevent divergence\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb), size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Adaptive exploration based on population diversity\n                diversity = np.mean(np.std(population, axis=0))\n                exploration_rate = np.clip(1.0 - diversity, 0.1, 0.9)  # Scale exploration based on diversity\n                \n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * r2 * (global_best_position - population[i]) +\n                                 exploration_rate * np.random.uniform(-self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb), size=self.dim))  # Exploration term\n                \n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveVelocityParticleSwarm scored 0.354 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.17643335040042585, 0.1767501483057906, 0.34229995570395244, 0.38016378804641104, 0.258361943912111, 0.3274871333745133, 0.2891585824317894, 0.28747334328343277, 0.3463689482167731, 0.20591779867175697, 0.37781317138074566, 0.9999151195839261, 0.2679351243919649, 0.261090909421405, 0.7189682099372352, 0.3274597346132273, 0.28784493378019904, 0.3762225173914163, 0.18454015758897413, 0.4907322363888378]}}
{"id": "0e8e39aa-40bc-405a-a4fd-81533a9edc2d", "fitness": -Infinity, "name": "CMAES", "description": "CMA-ES with mirrored sampling, budget handling, and simplified covariance adaptation, avoiding singular matrix errors.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, mu_factor = 0.25, cs = 0.3, c_cov = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(mu_factor * dim)\n        self.lambda_ = 4 * self.mu  # Population size\n        self.weights = np.log(self.lambda_ + 1/2) - np.log(np.arange(1, self.lambda_ + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = None # Mean\n        self.sigma = 0.5 # Step size\n        self.C = None # Covariance matrix\n        self.pc = None # Evolution path for C\n        self.ps = None # Evolution path for sigma\n        self.chiN = np.sqrt(self.dim) * (1 - (1/(4*self.dim)) + 1/(21 * self.dim**2))\n        self.cs = cs\n        self.c_cov = c_cov\n        self.min_sigma = 1e-10 # Added to prevent sigma from becoming zero\n\n    def __call__(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        used_budget = 0\n\n        while used_budget < self.budget:\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.lambda_)\n            x = self.m + self.sigma * z\n            \n            # Mirror sampling\n            x_mirrored = self.m - self.sigma * z\n            x = np.vstack((x, x_mirrored))\n            \n            # Clip to bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += 2 * self.lambda_\n\n            if used_budget > self.budget:\n                num_to_keep = 2 * self.lambda_ - (used_budget - self.budget)\n                idx = np.argsort(f)[:int(num_to_keep)]\n                x = x[idx]\n                f = f[idx]\n                used_budget = self.budget\n\n            idx = np.argsort(f)[:self.mu]\n            x_best = x[idx]\n            z_best = (x_best - self.m) / self.sigma\n\n            self.m = np.sum(self.weights[:, None] * x_best, axis=0)\n\n            # Adapt step size\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * np.sum(self.weights[:, None] * z_best, axis=0)\n            sigma_adapt = np.linalg.norm(self.ps) / self.chiN\n            self.sigma *= np.exp(self.cs/0.6 * (sigma_adapt - 1))\n            self.sigma = max(self.sigma, self.min_sigma) # prevent sigma from becoming zero\n\n            # Adapt covariance matrix - simplified update\n            self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * np.sum(self.weights[:, None] * z_best, axis=0)\n            \n            # Rank-one update to avoid singularity\n            delta = self.pc[:, None] @ self.pc[None, :]\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * delta + 1e-8 * np.eye(self.dim)  # Add a small diagonal to ensure positive definiteness\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: zero-size array to reduction operation minimum which has no identity.", "error": "", "parent_ids": ["26de202a-8ab3-4fdd-92ee-aeb6aaf3a61b"], "operator": null, "metadata": {}}
{"id": "31f84c15-90cf-4e4d-a84b-1c76cb96895e", "fitness": 0.0, "name": "AdaptiveCMAES", "description": "An adaptive CMA-ES variant that reduces the population size and increases exploration as the budget runs out.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, mu_factor=0.25, cs=0.3, c_cov=0.1, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(mu_factor * dim)\n        self.lambda_ = 4 * self.mu  # Population size\n        self.weights = np.log(self.lambda_ + 1/2) - np.log(np.arange(1, self.lambda_ + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = None  # Mean\n        self.sigma = initial_sigma  # Step size\n        self.C = None  # Covariance matrix\n        self.pc = None  # Evolution path for C\n        self.ps = None  # Evolution path for sigma\n        self.chiN = np.sqrt(self.dim) * (1 - (1/(4*self.dim)) + 1/(21 * self.dim**2))\n        self.cs = cs\n        self.c_cov = c_cov\n        self.initial_lambda = self.lambda_\n\n    def __call__(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        used_budget = 0\n        generation = 0\n\n        while used_budget < self.budget:\n            # Adaptive population size reduction\n            remaining_budget = self.budget - used_budget\n            self.lambda_ = max(int(self.initial_lambda * (remaining_budget / self.budget)), self.mu + 1) #Ensure lambda > mu.\n\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.lambda_)\n            x = self.m + self.sigma * z\n\n            # Clip to bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.lambda_\n\n            if used_budget > self.budget:\n                # Truncate if we exceeded budget\n                num_to_keep = self.lambda_ - (used_budget - self.budget)\n                idx = np.argsort(f)[:int(num_to_keep)]  # Get indices of best solutions within budget\n                x = x[idx]\n                f = f[idx]\n                used_budget = self.budget\n            else:\n                idx = np.argsort(f)[:self.mu]\n                x_best = x[idx]\n                z_best = (x_best - self.m) / self.sigma\n\n                self.m = np.sum(self.weights[:self.mu, None] * x_best, axis=0) #Use sliced weights\n\n                # Adapt step size\n                self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * np.sum(self.weights[:self.mu, None] * z_best, axis=0)\n                sigma_adapt = np.linalg.norm(self.ps) / self.chiN\n                self.sigma *= np.exp(self.cs/0.6 * (sigma_adapt - 1))\n                self.sigma = max(self.sigma, 1e-10) #Avoid sigma = 0\n\n                # Adapt covariance matrix\n                self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * np.sum(self.weights[:self.mu, None] * (x_best - self.m), axis=0) / self.sigma\n                self.C = (1 - self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :])\n                # Ensure C remains positive definite\n                try:\n                    np.linalg.cholesky(self.C)\n                except np.linalg.LinAlgError:\n                    self.C = np.eye(self.dim)  # Reset covariance matrix\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n            generation += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveCMAES scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["26de202a-8ab3-4fdd-92ee-aeb6aaf3a61b"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "746587f4-4a60-4f52-b0bf-094df5bb9eca", "fitness": -Infinity, "name": "CMAES_with_Restart", "description": "Covariance matrix adaptation evolution strategy with archive, resampling, and a simplified rank-one update of the covariance matrix for better exploration.", "code": "import numpy as np\n\nclass CMAES_with_Restart:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, c_cov=0.1, sigma0=0.2, mu_ratio=0.25, archive_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.cs = cs\n        self.c_cov = c_cov\n        self.sigma = sigma0\n        self.mu = int(self.popsize * mu_ratio)\n        self.weights = np.log(self.popsize + 1) - np.log(np.arange(1, self.popsize + 1))\n        self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.eigen_updated = 0\n        self.D = None\n        self.B = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive_x = []\n        self.archive_f = []\n        self.archive_size = archive_size\n\n\n    def sample(self, func):\n        z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n        y = self.sigma * (self.B @ (self.D * z))\n        x = self.m[:, None] + y\n        \n        #Check Bounds and Resample\n        for i in range(self.popsize):\n             while not func.bounds.contains(x[:,i]):\n                z[:,i] = np.random.normal(0, 1, size=(self.dim))\n                y[:,i] = self.sigma * (self.B @ (self.D * z[:,i]))\n                x[:,i] = self.m + y[:,i]\n\n        f = np.array([func(x[:, i]) for i in range(self.popsize)])\n        return x, f, y\n\n    def update(self, x, f, y):\n        idx = np.argsort(f)\n        x_sorted = x[:, idx]\n        y_sorted = y[:, idx]\n\n        m_old = self.m.copy()\n        self.m = np.sum(self.weights * x_sorted[:, :self.mu], axis=1)\n        y_w = np.sum(self.weights * y_sorted[:, :self.mu], axis=1)\n\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * np.sum(self.weights**2)) * (self.B @ self.D @ (y_w / self.sigma))\n        self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov) * np.sum(self.weights**2)) * (self.m - m_old) / self.sigma\n\n        self.sigma *= np.exp((self.cs / 0.817) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n\n        # Rank-one update\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * self.pc[:, None] @ self.pc[None, :]\n\n    def update_eigen(self):\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        self.D, self.B = np.linalg.eigh(self.C)\n        self.D = np.sqrt(np.maximum(self.D, 1e-16))\n        self.eigen_updated = 0\n    \n    def archive(self, x, f):\n        for i in range(x.shape[1]):\n            xi = x[:,i]\n            fi = f[i]\n\n            # Check for duplicates within the archive\n            duplicate = False\n            for archived_x in self.archive_x:\n                if np.allclose(xi, archived_x):\n                    duplicate = True\n                    break\n\n            if not duplicate:\n                self.archive_x.append(xi)\n                self.archive_f.append(fi)\n                \n                if len(self.archive_x) > self.archive_size:\n                    worst_idx = np.argmax(self.archive_f)\n                    del self.archive_x[worst_idx]\n                    del self.archive_f[worst_idx]\n    \n    def restart(self, func):\n         # Sample from the archive if available\n        if self.archive_x:\n            idx = np.argmin(self.archive_f)\n            self.m = self.archive_x[idx].copy()\n            self.sigma = 0.2  # Reset sigma to a default value upon restart\n\n        else:\n            self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.update_eigen()\n        self.eigen_updated = 0\n\n    def __call__(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.update_eigen()\n\n        fevals = 0\n        restarts = 0\n        max_restarts = 5\n\n        while fevals < self.budget and restarts < max_restarts:\n            x, f, y = self.sample(func)\n            fevals += self.popsize\n\n            # Update archive\n            self.archive(x, f)\n\n            # Update best solution\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[:, np.argmin(f)]\n\n            self.update(x, f, y)\n            self.eigen_updated += 1\n\n            if self.eigen_updated > self.popsize / 2:\n                self.update_eigen()\n\n            # Restart mechanism\n            if self.sigma < 1e-10:  # Check if the step size is too small.\n                self.restart(func)\n                restarts += 1\n        \n        # Final check with archive for best solution\n        if self.archive_f:\n            best_archive_idx = np.argmin(self.archive_f)\n            if self.archive_f[best_archive_idx] < self.f_opt:\n                self.f_opt = self.archive_f[best_archive_idx]\n                self.x_opt = self.archive_x[best_archive_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,) (2,6) .", "error": "", "parent_ids": ["64343faf-abe7-4909-9743-1f91bab87a2d"], "operator": null, "metadata": {}}
{"id": "cb6b89b0-85e4-4384-9838-45a7590d0468", "fitness": -Infinity, "name": "CMAES_with_Restart", "description": "Fixes broadcasting errors, adds bounds handling to CMA-ES with archive and restarts, improving robustness and exploration.", "code": "import numpy as np\n\nclass CMAES_with_Restart:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, c_cov=0.1, sigma0=0.2, mu_ratio=0.25, archive_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.cs = cs\n        self.c_cov = c_cov\n        self.sigma = sigma0\n        self.mu = int(self.popsize * mu_ratio)\n        self.weights = np.log(self.popsize + 1) - np.log(np.arange(1, self.popsize + 1))\n        self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.eigen_updated = 0\n        self.D = None\n        self.B = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive_x = []\n        self.archive_f = []\n        self.archive_size = archive_size\n\n\n    def sample(self, func):\n        z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n        y = self.sigma * (self.B @ (self.D * z))\n        x = self.m[:, None] + y  # Added broadcasting\n\n        #Check Bounds and Resample\n        for i in range(self.popsize):\n             while not func.bounds.contains(x[:,i]):\n                x[:,i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                y[:,i] = x[:,i] - self.m # Recalculate y after resampling\n        \n        f = np.array([func(x[:, i]) for i in range(self.popsize)])\n        return x, f, y\n\n    def update(self, x, f, y):\n        idx = np.argsort(f)\n        x_sorted = x[:, idx]\n        y_sorted = y[:, idx]\n\n        m_old = self.m.copy()\n        self.m = np.sum(self.weights * x_sorted[:, :self.mu], axis=1)\n        y_w = np.sum(self.weights * y_sorted[:, :self.mu], axis=1)\n\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * np.sum(self.weights**2)) * (self.B @ self.D @ (y_w / self.sigma))\n        self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov) * np.sum(self.weights**2)) * (self.m - m_old) / self.sigma\n\n        self.sigma *= np.exp((self.cs / 0.817) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n\n        dC = self.weights * y_sorted[:, :self.mu] @ y_sorted[:, :self.mu].T\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * (dC / self.sigma**2 - self.c_cov * (1 - self.c_cov) * self.pc[:, None] @ self.pc[None, :]) #Fixed dC formula\n\n    def update_eigen(self):\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        self.D, self.B = np.linalg.eigh(self.C)\n        self.D = np.sqrt(np.maximum(self.D, 1e-16))\n        self.eigen_updated = 0\n    \n    def archive(self, x, f):\n        for i in range(x.shape[1]):\n            xi = x[:,i]\n            fi = f[i]\n\n            # Check for duplicates within the archive\n            duplicate = False\n            for archived_x in self.archive_x:\n                if np.allclose(xi, archived_x):\n                    duplicate = True\n                    break\n\n            if not duplicate:\n                self.archive_x.append(xi)\n                self.archive_f.append(fi)\n                \n                if len(self.archive_x) > self.archive_size:\n                    worst_idx = np.argmax(self.archive_f)\n                    del self.archive_x[worst_idx]\n                    del self.archive_f[worst_idx]\n    \n    def restart(self, func):\n         # Sample from the archive if available\n        if self.archive_x:\n            idx = np.argmin(self.archive_f)\n            self.m = self.archive_x[idx].copy()\n            self.sigma = 0.2  # Reset sigma to a default value upon restart\n\n        else:\n            self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.update_eigen()\n        self.eigen_updated = 0\n\n    def __call__(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.update_eigen()\n\n        fevals = 0\n        restarts = 0\n        max_restarts = 5\n\n        while fevals < self.budget and restarts < max_restarts:\n            x, f, y = self.sample(func)\n            fevals += self.popsize\n\n            # Update archive\n            self.archive(x, f)\n\n            # Update best solution\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[:, np.argmin(f)]\n\n            self.update(x, f, y)\n            self.eigen_updated += 1\n\n            if self.eigen_updated > self.popsize / 2:\n                self.update_eigen()\n\n            # Restart mechanism\n            if self.sigma < 1e-10:  # Check if the step size is too small.\n                self.restart(func)\n                restarts += 1\n        \n        # Final check with archive for best solution\n        if self.archive_f:\n            best_archive_idx = np.argmin(self.archive_f)\n            if self.archive_f[best_archive_idx] < self.f_opt:\n                self.f_opt = self.archive_f[best_archive_idx]\n                self.x_opt = self.archive_x[best_archive_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,) (2,6) .", "error": "", "parent_ids": ["64343faf-abe7-4909-9743-1f91bab87a2d"], "operator": null, "metadata": {}}
{"id": "ecb3f617-5cb0-4110-95c1-453675605af7", "fitness": -Infinity, "name": "CMAES_with_Restart", "description": "Fixes broadcasting errors in CMA-ES update steps and enhances restart strategy by incorporating a check for stagnation in the mean.", "code": "import numpy as np\n\nclass CMAES_with_Restart:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, c_cov=0.1, sigma0=0.2, mu_ratio=0.25, archive_size=100, stagnation_threshold=1e-6):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.cs = cs\n        self.c_cov = c_cov\n        self.sigma = sigma0\n        self.mu = int(self.popsize * mu_ratio)\n        self.weights = np.log(self.popsize + 1) - np.log(np.arange(1, self.popsize + 1))\n        self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.eigen_updated = 0\n        self.D = None\n        self.B = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive_x = []\n        self.archive_f = []\n        self.archive_size = archive_size\n        self.stagnation_threshold = stagnation_threshold\n        self.m_old = None\n\n\n    def sample(self, func):\n        z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n        y = self.sigma * (self.B @ (self.D * z))\n        x = self.m + y\n        \n        #Check Bounds and Resample\n        for i in range(self.popsize):\n             while not func.bounds.contains(x[:,i]):\n                z[:,i] = np.random.normal(0, 1, size=(self.dim))\n                y[:,i] = self.sigma * (self.B @ (self.D * z[:,i]))\n                x[:,i] = self.m + y[:,i]\n\n        f = np.array([func(x[:, i]) for i in range(self.popsize)])\n        return x, f, y\n\n    def update(self, x, f, y):\n        idx = np.argsort(f)\n        x_sorted = x[:, idx]\n        y_sorted = y[:, idx]\n\n        m_old = self.m.copy()\n        self.m = np.sum(self.weights * x_sorted[:, :self.mu], axis=1)\n        y_w = np.sum(self.weights * y_sorted[:, :self.mu], axis=1)\n\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * np.sum(self.weights**2)) * (self.B @ self.D @ (y_w / self.sigma))\n        self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov) * np.sum(self.weights**2)) * (self.m - m_old) / self.sigma\n\n        self.sigma *= np.exp((self.cs / 0.817) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n\n        dC = np.zeros_like(self.C)\n        for i in range(self.mu):\n            dC += self.weights[i] * np.outer(y_sorted[:, i], y_sorted[:, i])\n\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * (dC / self.sigma**2 + self.c_cov * (1 - self.c_cov)**-1 * np.outer(self.pc, self.pc))\n\n\n    def update_eigen(self):\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        try:\n            self.D, self.B = np.linalg.eigh(self.C)\n            self.D = np.sqrt(np.maximum(self.D, 1e-16))\n            self.eigen_updated = 0\n        except np.linalg.LinAlgError:\n            # If eigen decomposition fails, restart\n            print(\"Eigen decomposition failed, restarting...\")\n            self.restart(func) # Pass func to restart\n    \n    def archive(self, x, f):\n        for i in range(x.shape[1]):\n            xi = x[:,i]\n            fi = f[i]\n\n            # Check for duplicates within the archive\n            duplicate = False\n            for archived_x in self.archive_x:\n                if np.allclose(xi, archived_x):\n                    duplicate = True\n                    break\n\n            if not duplicate:\n                self.archive_x.append(xi)\n                self.archive_f.append(fi)\n                \n                if len(self.archive_x) > self.archive_size:\n                    worst_idx = np.argmax(self.archive_f)\n                    del self.archive_x[worst_idx]\n                    del self.archive_f[worst_idx]\n    \n    def restart(self, func):\n         # Sample from the archive if available\n        if self.archive_x:\n            idx = np.argmin(self.archive_f)\n            self.m = self.archive_x[idx].copy()\n            self.sigma = 0.2  # Reset sigma to a default value upon restart\n\n        else:\n            self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.update_eigen()\n        self.eigen_updated = 0\n        self.m_old = None # Reset m_old after restart\n\n    def __call__(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.update_eigen()\n        self.m_old = self.m.copy()\n\n        fevals = 0\n        restarts = 0\n        max_restarts = 5\n\n        while fevals < self.budget and restarts < max_restarts:\n            x, f, y = self.sample(func)\n            fevals += self.popsize\n\n            # Update archive\n            self.archive(x, f)\n\n            # Update best solution\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[:, np.argmin(f)]\n\n            self.update(x, f, y)\n            self.eigen_updated += 1\n\n            if self.eigen_updated > self.popsize / 2:\n                self.update_eigen()\n\n            # Restart mechanism: Check for small sigma OR stagnation.\n            if self.sigma < 1e-10 or np.linalg.norm(self.m - self.m_old) < self.stagnation_threshold:  # Check if the step size is too small OR stagnation\n                self.restart(func)\n                restarts += 1\n\n            self.m_old = self.m.copy() # Update m_old for the next iteration\n        \n        # Final check with archive for best solution\n        if self.archive_f:\n            best_archive_idx = np.argmin(self.archive_f)\n            if self.archive_f[best_archive_idx] < self.f_opt:\n                self.f_opt = self.archive_f[best_archive_idx]\n                self.x_opt = self.archive_x[best_archive_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,) (2,6) .", "error": "", "parent_ids": ["64343faf-abe7-4909-9743-1f91bab87a2d"], "operator": null, "metadata": {}}
{"id": "bb964852-a27b-41d7-853b-97c862e8d50b", "fitness": 0.1914176186609428, "name": "GradientEstimationOptimizer", "description": "Gradient Estimation with Noisy Perturbations: Estimate the gradient using random perturbations and adapt the step size based on the gradient norm and budget.", "code": "import numpy as np\n\nclass GradientEstimationOptimizer:\n    def __init__(self, budget=10000, dim=10, step_size=0.1, num_perturbations=10):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = step_size\n        self.num_perturbations = num_perturbations\n\n    def __call__(self, func):\n        self.x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = func(self.x)\n        self.x_opt = self.x.copy()\n        used_budget = 1\n\n        while used_budget < self.budget:\n            # Estimate gradient using random perturbations\n            gradient = np.zeros(self.dim)\n            for _ in range(self.num_perturbations):\n                perturbation = np.random.normal(0, 0.1, size=self.dim)\n                x_perturbed = self.x + perturbation\n                x_perturbed = np.clip(x_perturbed, func.bounds.lb, func.bounds.ub)\n                f_perturbed = func(x_perturbed)\n                gradient += (f_perturbed - self.f_opt) * perturbation\n                used_budget += 1\n                if used_budget >= self.budget:\n                    break\n            \n            if used_budget >= self.budget:\n                break\n\n            gradient /= self.num_perturbations * np.linalg.norm(perturbation)**2 # Normalize the gradient estimate\n\n\n            # Update position\n            self.x = self.x - self.step_size * gradient\n            self.x = np.clip(self.x, func.bounds.lb, func.bounds.ub)\n            \n            f = func(self.x)\n            used_budget += 1\n            \n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = self.x.copy()\n\n            # Adapt step size (optional - can be removed if unstable)\n            self.step_size *= 0.99  # Gradually reduce step size\n            self.step_size = max(self.step_size, 1e-6)\n            if used_budget >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm GradientEstimationOptimizer scored 0.191 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["26de202a-8ab3-4fdd-92ee-aeb6aaf3a61b"], "operator": null, "metadata": {"aucs": [0.11526285130707914, 0.41375539487365864, 0.16555481830779972, 0.142192278804677, 0.2235870977754012, 0.12273825303545505, 0.19617333608760223, 0.2099501320056173, 0.1439135808758596, 0.11770686370216588, 0.15355286358158682, 0.18557290834391893, 0.2907877025466915, 0.17991115932447244, 0.11492821581625867, 0.1719853694794241, 0.16155123556083506, 0.1314341618432725, 0.1528725453230434, 0.4349216046240366]}}
{"id": "b08fcaa4-5a64-4e14-9e58-ef9e8818e81b", "fitness": 0.22616964598935207, "name": "CMAES", "description": "Adaptive Covariance Matrix Adaptation Evolution Strategy with simplified rank-one update and robust covariance matrix handling.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov_rank_one=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.mu-1)/(self.dim+1))-1) + self.cs\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 1 / (10*self.dim**2) # Simplified c_cov\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def sample_population(self):\n        z = np.random.randn(self.dim, self.popsize)\n        try:\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m[:, np.newaxis] + self.sigma * C_sqrt @ z\n        except np.linalg.LinAlgError:\n            self.C = self.C + 1e-6 * np.eye(self.dim) # Add jitter if not positive definite\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m[:, np.newaxis] + self.sigma * C_sqrt @ z\n\n        x = np.clip(x, -5, 5)\n        return x.T, z\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            x, z = self.sample_population()\n            f = np.array([func(xi) for xi in x])\n            self.eval_count += self.popsize\n            \n            idx = np.argsort(f)\n            x = x[idx]\n            z = z[:, idx]\n            f = f[idx]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n            \n            z_mu = np.sum(self.weights * z[:, :self.mu], axis=1)\n            self.m = self.m + self.cs * self.sigma * z_mu\n\n            self.ps = (1 - self.cs) * self.ps + (self.cs**0.5) * z_mu\n            norm_ps = np.linalg.norm(self.ps)\n\n            self.C = (1 - self.c_cov_rank_one) * self.C + self.c_cov_rank_one * np.outer(self.ps, self.ps) #Simplified update\n            \n            self.sigma = self.sigma * np.exp((self.cs / self.damps) * (norm_ps / self.chiN - 1))\n\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            \n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-6 * np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm CMAES scored 0.226 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["24239a80-1b7e-47e6-b5fa-76c3d142511a"], "operator": null, "metadata": {"aucs": [0.10403389496295623, 0.1801420417006948, 0.3301734506127275, 0.18816406512828576, 0.13079564476047456, 0.15043065497764707, 0.2285348266589422, 0.3483944941660576, 0.2507666361540124, 0.15529745898638647, 0.1567701329993737, 0.2187666218285722, 0.24964066373109028, 0.16542684237332528, 0.6277215299297307, 0.25639021687799846, 0.24678288428271422, 0.16804643367242644, 0.17163033485591128, 0.19548409112771437]}}
{"id": "067787bb-cdf3-4afa-a634-97814da87bc8", "fitness": 0.1978746526133072, "name": "CMAES", "description": "CMA-ES with simplified covariance update, rank-one adaptation, and a check for positive definiteness using eigenvalue decomposition.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov_rank_one=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.mu-1)/(self.dim+1))-1) + self.cs\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 1 / (10*self.dim**2) #Simplified\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def sample_population(self):\n        z = np.random.randn(self.dim, self.popsize)\n        C_sqrt = np.linalg.cholesky(self.C)\n        x = self.m[:, np.newaxis] + self.sigma * C_sqrt @ z\n        x = np.clip(x, -5, 5)\n        return x.T, z\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            x, z = self.sample_population()\n            f = np.array([func(xi) for xi in x])\n            self.eval_count += self.popsize\n            \n            idx = np.argsort(f)\n            x = x[idx]\n            z = z[:, idx]\n            f = f[idx]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n            \n            z_mu = np.sum(self.weights * z[:, :self.mu], axis=1)\n            self.m = self.m + self.cs * self.sigma * z_mu\n\n            self.ps = (1 - self.cs) * self.ps + (self.cs**0.5) * z_mu\n            norm_ps = np.linalg.norm(self.ps)\n\n            self.C = (1 - self.c_cov_rank_one) * self.C + self.c_cov_rank_one * np.outer(self.ps, self.ps)  #Rank-one update\n\n            self.sigma = self.sigma * np.exp((self.cs / self.damps) * (norm_ps / self.chiN - 1))\n\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            \n            # Check for positive definiteness using eigenvalue decomposition and fix if needed\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                w, v = np.linalg.eig(self.C)\n                w[w < 0] = 1e-6  # Set negative eigenvalues to a small positive value\n                self.C = v @ np.diag(w) @ v.T # Reconstruct covariance matrix\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm CMAES scored 0.198 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["24239a80-1b7e-47e6-b5fa-76c3d142511a"], "operator": null, "metadata": {"aucs": [0.06975600484608935, 0.17391508095512054, 0.3568913106256234, 0.17930866371387932, 0.17427859343947838, 0.15019267799325664, 0.20562372919381766, 0.1923198920719449, 0.14566179271656143, 0.15675462133079177, 0.16726930470693546, 0.1915210061762147, 0.2525266108378307, 0.19370510967315335, 0.3799005433143773, 0.2572219829448411, 0.2362876848768547, 0.16821480309325687, 0.1414345455830065, 0.16470909417310964]}}
{"id": "8355bb72-5936-4b23-b178-3d667db8e4c1", "fitness": 0.33599463868460944, "name": "AdaptivePSO", "description": "Simplified PSO with adaptive exploration based on global best fitness change and dynamic inertia.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=1.5, social_coeff=1.5, initial_inertia=0.9, inertia_decay=0.995):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.initial_inertia = initial_inertia\n        self.inertia_decay = inertia_decay\n        self.velocity_clamp = 0.5\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb), size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n\n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        inertia = self.initial_inertia\n        \n        # Optimization loop\n        while self.budget > 0:\n            old_global_best_fitness = global_best_fitness # Store for adaptive inertia\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * r2 * (global_best_position - population[i]))\n\n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n\n                # Update position\n                new_position = population[i] + velocities[i]\n\n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n                population[i] = new_position\n                \n            # Adaptive inertia: Reduce inertia if global best improves, increase otherwise\n            if global_best_fitness < old_global_best_fitness:\n                inertia *= self.inertia_decay  # Reduce inertia (exploitation)\n            else:\n                inertia = min(self.initial_inertia, inertia / self.inertia_decay)  # Increase inertia (exploration)\n                \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptivePSO scored 0.336 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8b639242-117f-44c5-8db5-0d336d1d85c1"], "operator": null, "metadata": {"aucs": [0.17225917203191643, 0.266708934153697, 0.35920178298712313, 0.23898714635794427, 0.255131072575686, 0.2786469789323983, 0.27985307546697435, 0.32344391811474127, 0.32392267464535385, 0.21512661427839974, 0.28250260470564004, 0.9994112437535904, 0.2280475236777817, 0.24695084160403524, 0.6486961929977444, 0.34307860882318575, 0.31270859556833797, 0.2898389538747912, 0.1983097872672036, 0.4570670518756429]}}
{"id": "2592c5ec-5777-4452-8547-064ca9179980", "fitness": 0.32842866388169967, "name": "PSO_DE", "description": "Combines Particle Swarm Optimization with a mutation operator inspired by Differential Evolution to enhance exploration and escape local optima.", "code": "import numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, de_coeff=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.de_coeff = de_coeff\n        self.velocity_clamp = 0.5\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb), size=(self.pop_size, self.dim))\n        \n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Standard PSO Velocity Update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * r2 * (global_best_position - population[i]))\n                \n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n                \n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                \n                # Mutation Vector\n                v_mutation = x_r1 + self.de_coeff * (x_r2 - x_r3)\n                v_mutation = np.clip(v_mutation, lb, ub)\n                \n                # Crossover (Binomial)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > 0.9 or j == j_rand:\n                        population[i, j] = v_mutation[j]\n                    else:\n                        population[i, j] = population[i, j] + velocities[i, j]\n\n                new_position = np.clip(population[i], lb, ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm PSO_DE scored 0.328 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8b639242-117f-44c5-8db5-0d336d1d85c1"], "operator": null, "metadata": {"aucs": [0.15158239349299218, 0.20830644364606465, 0.2983825175164633, 0.35444498848678463, 0.23427593919159884, 0.29371521228639363, 0.2781455265167758, 0.2708130473102287, 0.24219315741174108, 0.1960415989666764, 0.29649178350304806, 0.9990022287639884, 0.25778861815835974, 0.26118286023586634, 0.6410775617965923, 0.3197722038755213, 0.25927364260607266, 0.3609617377642368, 0.1733283987762516, 0.471793417328336]}}
{"id": "9481928e-a566-45e1-98c9-11106ea1e9af", "fitness": -Infinity, "name": "CMAES_with_Restart", "description": "CMA-ES with archive and adaptive step size, simplified and corrected for broadcasting issues.", "code": "import numpy as np\n\nclass CMAES_with_Restart:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, c_cov=0.1, sigma0=0.2, mu_ratio=0.25, archive_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.cs = cs\n        self.c_cov = c_cov\n        self.sigma = sigma0\n        self.mu = int(self.popsize * mu_ratio)\n        self.weights = np.log(self.popsize + 1) - np.log(np.arange(1, self.popsize + 1))\n        self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.eigen_updated = 0\n        self.D = None\n        self.B = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive_x = []\n        self.archive_f = []\n        self.archive_size = archive_size\n\n\n    def sample(self, func):\n        z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n        y = self.sigma * (self.B @ (self.D * z))\n        x = self.m[:, None] + y\n        \n        #Check Bounds and Resample\n        for i in range(self.popsize):\n             while not func.bounds.contains(x[:,i]):\n                z[:,i] = np.random.normal(0, 1, size=(self.dim))\n                y[:,i] = self.sigma * (self.B @ (self.D * z[:,i]))\n                x[:,i] = self.m + y[:,i]\n\n        f = np.array([func(x[:, i]) for i in range(self.popsize)])\n        return x, f, y\n\n    def update(self, x, f, y):\n        idx = np.argsort(f)\n        x_sorted = x[:, idx]\n        y_sorted = y[:, idx]\n\n        m_old = self.m.copy()\n        self.m = np.sum(self.weights * x_sorted[:, :self.mu], axis=1)\n        y_w = np.sum(self.weights * y_sorted[:, :self.mu], axis=1)\n\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * np.sum(self.weights**2)) * (self.B @ self.D @ (y_w / self.sigma))\n        self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov) * np.sum(self.weights**2)) * (self.m - m_old) / self.sigma\n\n        self.sigma *= np.exp((self.cs / 0.817) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n\n        dC = self.weights * y_sorted[:, :self.mu] @ y_sorted[:, :self.mu].T\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * (dC / self.sigma**2 + self.c_cov * (1 - self.c_cov)**-1 * self.pc[:, None] @ self.pc[None, :])\n\n    def update_eigen(self):\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        self.D, self.B = np.linalg.eigh(self.C)\n        self.D = np.sqrt(np.maximum(self.D, 1e-16))\n        self.eigen_updated = 0\n    \n    def archive(self, x, f):\n        for i in range(x.shape[1]):\n            xi = x[:,i]\n            fi = f[i]\n\n            # Check for duplicates within the archive\n            duplicate = False\n            for archived_x in self.archive_x:\n                if np.allclose(xi, archived_x):\n                    duplicate = True\n                    break\n\n            if not duplicate:\n                self.archive_x.append(xi)\n                self.archive_f.append(fi)\n                \n                if len(self.archive_x) > self.archive_size:\n                    worst_idx = np.argmax(self.archive_f)\n                    del self.archive_x[worst_idx]\n                    del self.archive_f[worst_idx]\n    \n    def restart(self, func):\n         # Sample from the archive if available\n        if self.archive_x:\n            idx = np.argmin(self.archive_f)\n            self.m = self.archive_x[idx].copy()\n            self.sigma = 0.2  # Reset sigma to a default value upon restart\n\n        else:\n            self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.update_eigen()\n        self.eigen_updated = 0\n\n    def __call__(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.update_eigen()\n\n        fevals = 0\n        restarts = 0\n        max_restarts = 5\n\n        while fevals < self.budget and restarts < max_restarts:\n            x, f, y = self.sample(func)\n            fevals += self.popsize\n\n            # Update archive\n            self.archive(x, f)\n\n            # Update best solution\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[:, np.argmin(f)]\n\n            self.update(x, f, y)\n            self.eigen_updated += 1\n\n            if self.eigen_updated > self.popsize / 2:\n                self.update_eigen()\n\n            # Restart mechanism\n            if self.sigma < 1e-10:  # Check if the step size is too small.\n                self.restart(func)\n                restarts += 1\n        \n        # Final check with archive for best solution\n        if self.archive_f:\n            best_archive_idx = np.argmin(self.archive_f)\n            if self.archive_f[best_archive_idx] < self.f_opt:\n                self.f_opt = self.archive_f[best_archive_idx]\n                self.x_opt = self.archive_x[best_archive_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,) (2,6) .", "error": "", "parent_ids": ["64343faf-abe7-4909-9743-1f91bab87a2d"], "operator": null, "metadata": {}}
{"id": "6c5fa33d-6ad6-4ac0-a139-868565461e64", "fitness": 0.44206409517208795, "name": "AdaptiveVelocityParticleSwarm", "description": "Adaptive PSO with dynamic inertia weight, constriction factor, and velocity clamping based on swarm diversity.", "code": "import numpy as np\n\nclass AdaptiveVelocityParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_coeff=2.0, social_coeff=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb), (ub - lb), size=(self.pop_size, self.dim)) # Initial velocities span the entire range\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Calculate swarm diversity (average distance to the mean position)\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1)) / (ub - lb) # Normalized diversity\n            \n            # Adaptive inertia weight (linearly decreasing with diversity)\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * diversity\n            \n            # Constriction factor to prevent divergence\n            phi = self.cognitive_coeff + self.social_coeff\n            constriction_factor = 2 / np.abs(2 - phi - np.sqrt(phi**2 - 4 * phi)) if phi > 4 else 1.0\n\n            # Adaptive velocity clamping\n            velocity_clamp = diversity * (ub - lb) # Smaller clamp when swarm is diverse, larger otherwise\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * r2 * (global_best_position - population[i])) * constriction_factor\n                \n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (wrap around)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveVelocityParticleSwarm scored 0.442 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8b639242-117f-44c5-8db5-0d336d1d85c1"], "operator": null, "metadata": {"aucs": [0.15656362575885596, 0.30946597762543493, 0.5544541301838322, 0.8968509300905654, 0.29790592294415363, 0.28251991339259386, 0.3181790961003915, 0.5092926902198722, 0.6238265837533312, 0.19067232753558705, 0.23273891672936475, 0.9981797910853621, 0.2622238692070138, 0.27768941909988254, 0.7369515189513001, 0.6227445094111341, 0.4826488103862979, 0.2907289981316611, 0.1854809145324955, 0.6121639583026295]}}
{"id": "c6b6a515-4e7d-423c-bc2e-683c6b195eef", "fitness": -Infinity, "name": "CMAES", "description": "Enhanced CMA-ES with adaptive covariance matrix learning rate and step size adaptation based on success rate.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov_rank_one=None, c_cov_mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.mu-1)/(self.dim+1))-1) + self.cs\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 2 / (self.dim**2 + 6)\n        self.c_cov_mu = c_cov_mu if c_cov_mu is not None else 2 / ( (self.dim+2)**2 ) + self.c_cov_rank_one/self.mu\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_rate = 0.2  # Initialize success rate\n        self.learning_rate = 0.2\n\n    def sample_population(self):\n        z = np.random.randn(self.dim, self.popsize)\n        try:\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m[:, np.newaxis] + self.sigma * C_sqrt @ z\n        except np.linalg.LinAlgError:\n            self.C = self.C + 1e-6 * np.eye(self.dim) # Add jitter if not positive definite\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m[:, np.newaxis] + self.sigma * C_sqrt @ z\n\n        x = np.clip(x, -5, 5)\n        return x.T, z\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            x, z = self.sample_population()\n            f = np.array([func(xi) for xi in x])\n            self.eval_count += self.popsize\n            \n            idx = np.argsort(f)\n            x = x[idx]\n            z = z[:, idx]\n            f = f[idx]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                self.success_rate = 1.0 # successful iteration\n\n            else:\n                self.success_rate = 0.0\n            \n            z_mu = np.sum(self.weights * z[:, :self.mu], axis=1)\n            y_mu = np.sum(self.weights * x[:self.mu], axis=0) - self.m\n            self.m = self.m + self.cs * self.sigma * z_mu\n\n            self.ps = (1 - self.cs) * self.ps + (self.cs**0.5) * z_mu\n            self.pc = (1 - self.cs) * self.pc + (self.cs**0.5) * y_mu / self.sigma\n\n            norm_ps = np.linalg.norm(self.ps)\n            \n            C_temp = self.c_cov_rank_one * np.outer(self.pc, self.pc) + self.c_cov_mu * np.sum(self.weights[:, None, None] * np.array([np.outer(x_i - self.m, x_i - self.m) for x_i in x[:self.mu]]), axis=0)\n            self.C = (1 - self.c_cov_rank_one - self.c_cov_mu) * self.C + C_temp\n            \n            # Adaptive sigma update based on success rate\n            self.sigma *= np.exp(self.learning_rate * (self.success_rate - 0.2))\n            self.sigma = min(max(self.sigma, 1e-10), 10)  # Clamp sigma\n\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            \n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-6 * np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: operands could not be broadcast together with shapes (3,) (3,2) .", "error": "", "parent_ids": ["b08fcaa4-5a64-4e14-9e58-ef9e8818e81b"], "operator": null, "metadata": {}}
{"id": "7758aea9-d350-4cc0-b6ac-95035dcab08c", "fitness": 0.07952545702162062, "name": "AdaptiveMirroredCMAES", "description": "Adaptive CMA-ES with mirrored sampling and population aging to improve exploration and avoid premature convergence.", "code": "import numpy as np\n\nclass AdaptiveMirroredCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov_rank_one=None, c_cov_rank_mu=None, age_limit=10):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.mu-1)/(self.dim+1))-1) + self.cs\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 1 / (10*self.dim**2)\n        self.c_cov_rank_mu = c_cov_rank_mu if c_cov_rank_mu is not None else 0.25 / (self.dim**2)  #rank-mu update\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.age_limit = age_limit\n        self.population_age = np.zeros(self.popsize)\n        self.min_sigma = 1e-12\n\n    def sample_population(self):\n        z = np.random.randn(self.dim, self.popsize // 2)\n        z = np.concatenate((z, -z), axis=1)  # Mirrored sampling\n\n        try:\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m[:, np.newaxis] + self.sigma * C_sqrt @ z\n        except np.linalg.LinAlgError:\n            self.C = self.C + 1e-6 * np.eye(self.dim) # Add jitter if not positive definite\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m[:, np.newaxis] + self.sigma * C_sqrt @ z\n\n        x = np.clip(x, -5, 5)\n        return x.T, z\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            x, z = self.sample_population()\n            f = np.array([func(xi) for xi in x])\n            self.eval_count += self.popsize\n            self.population_age += 1\n            \n            idx = np.argsort(f)\n            x = x[idx]\n            z = z[:, idx]\n            f = f[idx]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                self.population_age[:] = 0 # Reset age upon finding better solution\n            \n            # Apply aging: replace old individuals with random ones\n            aged_out = self.population_age >= self.age_limit\n            num_aged_out = np.sum(aged_out)\n            if num_aged_out > 0:\n                z_rand = np.random.randn(self.dim, num_aged_out)\n                try:\n                    C_sqrt = np.linalg.cholesky(self.C)\n                    x_rand = self.m[:, np.newaxis] + self.sigma * C_sqrt @ z_rand\n                except np.linalg.LinAlgError:\n                    self.C = self.C + 1e-6 * np.eye(self.dim)\n                    C_sqrt = np.linalg.cholesky(self.C)\n                    x_rand = self.m[:, np.newaxis] + self.sigma * C_sqrt @ z_rand\n                x_rand = np.clip(x_rand, -5, 5)\n                f_rand = np.array([func(xi) for xi in x_rand.T])\n                self.eval_count += num_aged_out\n                \n                x[aged_out] = x_rand.T\n                f[aged_out] = f_rand\n                z[:,aged_out] = z_rand #correct z values\n                self.population_age[aged_out] = 0\n                \n                idx = np.argsort(f)\n                x = x[idx]\n                z = z[:, idx]\n                f = f[idx]\n                \n\n            z_mu = np.sum(self.weights * z[:, :self.mu], axis=1)\n            \n            # Update mean\n            self.m = self.m + self.cs * self.sigma * z_mu\n\n            # Update evolution path\n            self.ps = (1 - self.cs) * self.ps + (self.cs**0.5) * z_mu\n            norm_ps = np.linalg.norm(self.ps)\n\n            #Simplified update using rank-one and rank-mu updates\n            self.pc = (1 - self.cs) * self.pc + (self.cs**0.5) * np.sqrt(self.mu/(self.popsize)) * z_mu\n            \n            delta = (1 - self.c_cov_rank_one - self.c_cov_rank_mu)\n            self.C = delta * self.C + self.c_cov_rank_one * np.outer(self.ps, self.ps)\n            for i in range(self.mu):\n                self.C += self.c_cov_rank_mu * self.weights[i] * np.outer(z[:,i], z[:,i])\n                \n            self.sigma = self.sigma * np.exp((self.cs / self.damps) * (norm_ps / self.chiN - 1))\n            self.sigma = max(self.sigma, self.min_sigma)  # prevent sigma from going to zero\n\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            \n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-6 * np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveMirroredCMAES scored 0.080 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b08fcaa4-5a64-4e14-9e58-ef9e8818e81b"], "operator": null, "metadata": {"aucs": [0.060683418717980775, 0.17789295234688107, 0]}}
{"id": "57dde946-45fe-4d53-9c1e-6e8d1d18edf5", "fitness": -Infinity, "name": "EnhancedAdaptiveVelocityParticleSwarm", "description": "Enhanced Adaptive Velocity Particle Swarm with aging, dynamic population size, and a mutation operator to improve exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveVelocityParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_coeff=2.0, social_coeff=2.0, aging_rate=0.01, mutation_rate=0.05, pop_size_adapt_freq=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.aging_rate = aging_rate\n        self.mutation_rate = mutation_rate\n        self.pop_size_adapt_freq = pop_size_adapt_freq\n        self.ages = np.zeros(self.pop_size)\n        self.min_pop_size = 5\n        self.max_pop_size = 50\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb), (ub - lb), size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Track stagnation\n        stagnation_counter = 0\n        last_global_best = global_best_fitness\n        \n        # Optimization loop\n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n            # Calculate swarm diversity (average distance to the mean position)\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1)) / (ub - lb)\n\n            # Adaptive inertia weight (linearly decreasing with diversity)\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * diversity\n            \n            # Constriction factor to prevent divergence\n            phi = self.cognitive_coeff + self.social_coeff\n            constriction_factor = 2 / np.abs(2 - phi - np.sqrt(phi**2 - 4 * phi)) if phi > 4 else 1.0\n\n            # Adaptive velocity clamping\n            velocity_clamp = diversity * (ub - lb)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * r2 * (global_best_position - population[i])) * constriction_factor\n                \n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n\n                # Mutation operator\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.uniform(-0.1 * (ub - lb), 0.1 * (ub - lb), size=self.dim)\n                    new_position = np.clip(new_position + mutation, lb, ub)\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    self.ages[i] = 0 # Reset age\n\n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                        stagnation_counter = 0 # Reset stagnation counter\n                else:\n                    self.ages[i] += self.aging_rate # Increase age if not improving\n\n                population[i] = new_position\n\n            # Stagnation check\n            if abs(global_best_fitness - last_global_best) < 1e-6:\n                stagnation_counter += 1\n            else:\n                stagnation_counter = 0\n            last_global_best = global_best_fitness\n\n            # Re-initialize particles if stagnation is detected\n            if stagnation_counter > 50:\n                # Re-initialize a portion of the population\n                num_reinit = int(0.2 * self.pop_size)\n                indices_to_reinit = np.argsort(personal_best_fitnesses)[-num_reinit:]  # Reinit worst particles\n                for i in indices_to_reinit:\n                     population[i] = np.random.uniform(lb, ub, size=self.dim)\n                     velocities[i] = np.random.uniform(-(ub - lb), (ub - lb), size=self.dim)\n                     personal_best_positions[i] = population[i].copy()\n                     personal_best_fitnesses[i] = func(population[i])\n                     self.budget -= 1\n                     if personal_best_fitnesses[i] < global_best_fitness:\n                         global_best_fitness = personal_best_fitnesses[i]\n                         global_best_position = population[i].copy()\n                stagnation_counter = 0 # Reset stagnation after re-initialization\n\n            # Dynamic population size adjustment\n            if iteration % self.pop_size_adapt_freq == 0:\n                # Reduce population size based on average age\n                avg_age = np.mean(self.ages)\n                if avg_age > 0.5 and self.pop_size > self.min_pop_size:\n                    self.pop_size = max(self.min_pop_size, int(self.pop_size * 0.9))\n                    self.ages = self.ages[:self.pop_size]\n                    population = population[:self.pop_size]\n                    velocities = velocities[:self.pop_size]\n                    personal_best_positions = personal_best_positions[:self.pop_size]\n                    personal_best_fitnesses = personal_best_fitnesses[:self.pop_size]\n                    print(f\"Reduced pop size to {self.pop_size}\")\n\n                # Increase population size if diversity is low\n                elif diversity < 0.1 and self.pop_size < self.max_pop_size:\n                    num_new = min(self.max_pop_size - self.pop_size, 2)\n                    new_population = np.random.uniform(lb, ub, size=(num_new, self.dim))\n                    new_velocities = np.random.uniform(-(ub - lb), (ub - lb), size=(num_new, self.dim))\n                    new_fitness = np.array([func(x) for x in new_population])\n                    self.budget -= num_new\n\n                    new_personal_best_positions = new_population.copy()\n                    new_personal_best_fitnesses = new_fitness.copy()\n\n                    population = np.concatenate((population, new_population))\n                    velocities = np.concatenate((velocities, new_velocities))\n                    personal_best_positions = np.concatenate((personal_best_positions, new_personal_best_positions))\n                    personal_best_fitnesses = np.concatenate((personal_best_fitnesses, new_personal_best_fitnesses))\n                    self.ages = np.concatenate((self.ages, np.zeros(num_new)))\n                    self.pop_size += num_new\n                    print(f\"Increased pop size to {self.pop_size}\")\n\n                    # Update global best if any new particle is better\n                    for j in range(num_new):\n                        if new_personal_best_fitnesses[j] < global_best_fitness:\n                            global_best_fitness = new_personal_best_fitnesses[j]\n                            global_best_position = new_personal_best_positions[j].copy()\n\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 2, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["6c5fa33d-6ad6-4ac0-a139-868565461e64"], "operator": null, "metadata": {}}
{"id": "74be386b-31dd-4152-9d44-047564e0b55c", "fitness": -Infinity, "name": "CooperativeSwarm", "description": "Cooperative Swarm Optimization with inter-swarm communication and dynamic sub-swarm allocation based on performance.", "code": "import numpy as np\n\nclass CooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, pop_size=20, cognitive_coeff=1.5, social_coeff=1.5, inter_swarm_coeff=0.5, initial_inertia=0.9, inertia_decay=0.995):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.inter_swarm_coeff = inter_swarm_coeff\n        self.initial_inertia = initial_inertia\n        self.inertia_decay = inertia_decay\n        self.velocity_clamp = 0.5\n        self.swarm_sizes = np.full(self.num_swarms, self.pop_size // self.num_swarms, dtype=int)\n        self.swarm_sizes[:self.pop_size % self.num_swarms] += 1\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarms\n        swarms = []\n        for i in range(self.num_swarms):\n            swarm_size = self.swarm_sizes[i]\n            population = np.random.uniform(lb, ub, size=(swarm_size, self.dim))\n            velocities = np.random.uniform(-self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb), size=(swarm_size, self.dim))\n            fitness = np.array([func(x) for x in population])\n            self.budget -= swarm_size\n\n            personal_best_positions = population.copy()\n            personal_best_fitnesses = fitness.copy()\n            global_best_index = np.argmin(fitness)\n            global_best_position = population[global_best_index].copy()\n            global_best_fitness = fitness[global_best_index]\n\n            swarms.append({\n                'population': population,\n                'velocities': velocities,\n                'fitness': fitness,\n                'personal_best_positions': personal_best_positions,\n                'personal_best_fitnesses': personal_best_fitnesses,\n                'global_best_position': global_best_position,\n                'global_best_fitness': global_best_fitness,\n                'inertia': self.initial_inertia\n            })\n\n        # Optimization loop\n        while self.budget > 0:\n            #Inter-swarm communication: Find the overall global best\n            overall_global_best_fitness = np.inf\n            overall_global_best_position = None\n            best_swarm_index = -1\n            for i in range(self.num_swarms):\n                if swarms[i]['global_best_fitness'] < overall_global_best_fitness:\n                    overall_global_best_fitness = swarms[i]['global_best_fitness']\n                    overall_global_best_position = swarms[i]['global_best_position'].copy()\n                    best_swarm_index = i\n\n            # Update each swarm\n            for i in range(self.num_swarms):\n                old_global_best_fitness = swarms[i]['global_best_fitness']\n                swarm = swarms[i]\n                swarm_size = self.swarm_sizes[i]\n\n                for j in range(swarm_size):\n                    # Update velocity\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    r3 = np.random.rand(self.dim)\n\n                    swarm['velocities'][j] = (swarm['inertia'] * swarm['velocities'][j] +\n                                     self.cognitive_coeff * r1 * (swarm['personal_best_positions'][j] - swarm['population'][j]) +\n                                     self.social_coeff * r2 * (swarm['global_best_position'] - swarm['population'][j]) +\n                                     self.inter_swarm_coeff * r3 * (overall_global_best_position - swarm['population'][j]))\n\n                    # Clamp velocities\n                    swarm['velocities'][j] = np.clip(swarm['velocities'][j], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n\n                    # Update position\n                    new_position = swarm['population'][j] + swarm['velocities'][j]\n\n                    # Handle boundary constraints (clip)\n                    new_position = np.clip(new_position, lb, ub)\n\n                    # Evaluate new position\n                    new_fitness = func(new_position)\n                    self.budget -= 1\n\n                    # Update personal best\n                    if new_fitness < swarm['personal_best_fitnesses'][j]:\n                        swarm['personal_best_fitnesses'][j] = new_fitness\n                        swarm['personal_best_positions'][j] = new_position.copy()\n\n                        # Update global best\n                        if new_fitness < swarm['global_best_fitness']:\n                            swarm['global_best_fitness'] = new_fitness\n                            swarm['global_best_position'] = new_position.copy()\n\n                    swarm['population'][j] = new_position\n\n                # Adaptive inertia\n                if swarm['global_best_fitness'] < old_global_best_fitness:\n                    swarm['inertia'] *= self.inertia_decay\n                else:\n                    swarm['inertia'] = min(self.initial_inertia, swarm['inertia'] / self.inertia_decay)\n                \n                swarms[i] = swarm # Update swarm in the list\n            \n            # Dynamic sub-swarm allocation (adjust swarm sizes)\n            if self.num_swarms > 1:\n                performance = np.array([swarm['global_best_fitness'] for swarm in swarms])\n                normalized_performance = np.max(performance) / (performance + 1e-8)  # Avoid division by zero and invert to prioritize better swarms\n\n                allocation_probabilities = normalized_performance / np.sum(normalized_performance)\n                new_swarm_sizes = np.round(allocation_probabilities * self.pop_size).astype(int)\n\n                # Ensure the total population size remains the same\n                diff = np.sum(new_swarm_sizes) - self.pop_size\n                if diff > 0:\n                    indices = np.argsort(allocation_probabilities)[::-1] #Sort by performance\n                    for k in range(diff):\n                        new_swarm_sizes[indices[k]] -= 1\n                elif diff < 0:\n                    indices = np.argsort(allocation_probabilities)\n                    for k in range(-diff):\n                        new_swarm_sizes[indices[k]] += 1\n                \n                # Apply new swarm sizes\n                for i in range(self.num_swarms):\n                    old_size = self.swarm_sizes[i]\n                    new_size = new_swarm_sizes[i]\n                    self.swarm_sizes[i] = new_size\n                    \n                    if new_size > old_size:\n                        # Add new particles to the swarm\n                        num_new_particles = new_size - old_size\n                        new_population = np.random.uniform(lb, ub, size=(num_new_particles, self.dim))\n                        new_velocities = np.random.uniform(-self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb), size=(num_new_particles, self.dim))\n                        new_fitness = np.array([func(x) for x in new_population])\n                        self.budget -= num_new_particles\n\n                        new_personal_best_positions = new_population.copy()\n                        new_personal_best_fitnesses = new_fitness.copy()\n\n                        swarm = swarms[i]\n                        swarm['population'] = np.vstack((swarm['population'], new_population))\n                        swarm['velocities'] = np.vstack((swarm['velocities'], new_velocities))\n                        swarm['fitness'] = np.concatenate((swarm['fitness'], new_fitness))\n                        swarm['personal_best_positions'] = np.vstack((swarm['personal_best_positions'], new_personal_best_positions))\n                        swarm['personal_best_fitnesses'] = np.concatenate((swarm['personal_best_fitnesses'], new_personal_best_fitnesses))\n\n                        # Update global best within the swarm\n                        local_best_index = np.argmin(swarm['fitness'])\n                        swarm['global_best_position'] = swarm['population'][local_best_index].copy()\n                        swarm['global_best_fitness'] = swarm['fitness'][local_best_index]\n                        swarms[i] = swarm\n\n                    elif new_size < old_size:\n                        # Remove particles from the swarm (remove the worst performing)\n                        num_remove_particles = old_size - new_size\n                        swarm = swarms[i]\n\n                        #Remove the worst performing particles\n                        worst_indices = np.argsort(swarm['fitness'])[-num_remove_particles:]\n\n                        keep_indices = np.setdiff1d(np.arange(old_size), worst_indices)\n\n                        swarm['population'] = swarm['population'][keep_indices]\n                        swarm['velocities'] = swarm['velocities'][keep_indices]\n                        swarm['fitness'] = swarm['fitness'][keep_indices]\n                        swarm['personal_best_positions'] = swarm['personal_best_positions'][keep_indices]\n                        swarm['personal_best_fitnesses'] = swarm['personal_best_fitnesses'][keep_indices]\n\n                        # Update global best within the swarm\n                        local_best_index = np.argmin(swarm['fitness'])\n                        swarm['global_best_position'] = swarm['population'][local_best_index].copy()\n                        swarm['global_best_fitness'] = swarm['fitness'][local_best_index]\n                        swarms[i] = swarm\n            \n\n        # Return the overall global best\n        overall_global_best_fitness = np.inf\n        overall_global_best_position = None\n        for swarm in swarms:\n            if swarm['global_best_fitness'] < overall_global_best_fitness:\n                overall_global_best_fitness = swarm['global_best_fitness']\n                overall_global_best_position = swarm['global_best_position'].copy()\n\n        return overall_global_best_fitness, overall_global_best_position", "configspace": "", "generation": 2, "feedback": "An exception occurred: attempt to get argmin of an empty sequence.", "error": "", "parent_ids": ["8355bb72-5936-4b23-b178-3d667db8e4c1"], "operator": null, "metadata": {}}
{"id": "ba4e2cc6-de50-443a-b40c-afc78b681b06", "fitness": 0.23510073489833028, "name": "AdaptiveCMAES", "description": "Adaptive CMA-ES with rank-one covariance update, dynamic population size based on budget and dimension, and a simplified yet effective strategy parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = min(budget // 10, 4 + int(3 * np.log(self.dim)))  # Dynamic pop size\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.cs = 0.3 # Simplified, fixed cs\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mu-1)/(self.dim+1))-1) + self.cs # Simplified damps\n        self.c_cov_rank_one = 1 / (10*self.dim**2) # Simplified c_cov\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def sample_population(self):\n        z = np.random.randn(self.dim, self.popsize)\n        try:\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m[:, np.newaxis] + self.sigma * C_sqrt @ z\n        except np.linalg.LinAlgError:\n            self.C = self.C + 1e-6 * np.eye(self.dim)\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m[:, np.newaxis] + self.sigma * C_sqrt @ z\n\n        x = np.clip(x, self.lb, self.ub)\n        return x.T, z\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            x, z = self.sample_population()\n            f = np.array([func(xi) for xi in x])\n            self.eval_count += self.popsize\n            \n            idx = np.argsort(f)\n            x = x[idx]\n            z = z[:, idx]\n            f = f[idx]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n            \n            z_mu = np.sum(self.weights * z[:, :self.mu], axis=1)\n            self.m = self.m + self.cs * self.sigma * z_mu\n\n            self.ps = (1 - self.cs) * self.ps + (self.cs**0.5) * z_mu\n            norm_ps = np.linalg.norm(self.ps)\n\n            self.C = (1 - self.c_cov_rank_one) * self.C + self.c_cov_rank_one * np.outer(self.ps, self.ps)\n            \n            self.sigma = self.sigma * np.exp((self.cs / self.damps) * (norm_ps / self.chiN - 1))\n\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            \n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-6 * np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveCMAES scored 0.235 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b08fcaa4-5a64-4e14-9e58-ef9e8818e81b"], "operator": null, "metadata": {"aucs": [0.04854361342492375, 0.17707180269471534, 0.36527225263650187, 0.1346811697126803, 0.1313209646815725, 0.15003016415330928, 0.2185821447388635, 0.4163600920505973, 0.15351793769674515, 0.15636440008843933, 0.20494489115481695, 0.21312153609814943, 0.252746941136731, 0.21444664237721656, 0.6637442093041265, 0.2608168992143294, 0.24795653153606012, 0.3687978292759626, 0.15965697123997868, 0.16403770475088553]}}
{"id": "5a87dd04-4409-46b5-bbe9-cc4e01fe771c", "fitness": 0.4668930794736463, "name": "AdaptiveVelocityParticleSwarm", "description": "Simplified Adaptive PSO with diversity-controlled velocity clamping and inertia, removing constriction factor for robustness and speed.", "code": "import numpy as np\n\nclass AdaptiveVelocityParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_coeff=2.0, social_coeff=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim)) # Initial velocities are smaller\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Calculate swarm diversity (average distance to the global best)\n            diversity = np.mean(np.linalg.norm(population - global_best_position, axis=1)) / (ub - lb) # Normalized diversity\n\n            # Adaptive inertia weight (linearly decreasing with diversity)\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * diversity\n            inertia = np.clip(inertia, self.inertia_min, self.inertia_max) # Ensure inertia is within bounds\n            \n            # Adaptive velocity clamping\n            velocity_clamp = diversity * (ub - lb) # Smaller clamp when swarm is diverse, larger otherwise\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * r2 * (global_best_position - population[i]))\n                \n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveVelocityParticleSwarm scored 0.467 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6c5fa33d-6ad6-4ac0-a139-868565461e64"], "operator": null, "metadata": {"aucs": [0.22778044546609255, 0.5377423138840529, 0.507647124717403, 0.9060952138709992, 0.25446094406134523, 0.2839485467507791, 0.31581720720015405, 0.47042171467293614, 0.5653478779900775, 0.15604325789147877, 0.8430511487347744, 0.9982274726640249, 0.2703661464518945, 0.2794215252830211, 0.5888383971305771, 0.618331031614161, 0.40097519962485406, 0.3795501348354505, 0.1967424428860749, 0.5370534437427752]}}
{"id": "4051d13e-2cb8-4680-a9a9-4db23522fc9e", "fitness": 0.4985912415489627, "name": "AdaptiveVelocityParticleSwarm", "description": "Simplified Adaptive PSO with constriction factor and velocity clamping based on swarm diversity, focusing on efficiency and parameter reduction.", "code": "import numpy as np\n\nclass AdaptiveVelocityParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=2.0, social_coeff=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia  # Single inertia value\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) / 2, (ub - lb) / 2, size=(self.pop_size, self.dim))  # Reduced velocity range\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Constriction factor (pre-calculated)\n        phi = self.cognitive_coeff + self.social_coeff\n        constriction_factor = 2 / np.abs(2 - phi - np.sqrt(phi**2 - 4 * phi)) if phi > 4 else 1.0\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Calculate swarm diversity (average distance to the global best)\n            diversity = np.mean(np.linalg.norm(population - global_best_position, axis=1)) / (ub - lb) # Normalized diversity relative to global best\n            \n            # Adaptive velocity clamping (simpler version)\n            velocity_clamp = diversity * (ub - lb)\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = constriction_factor * (self.inertia * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * r2 * (global_best_position - population[i]))\n                \n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveVelocityParticleSwarm scored 0.499 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6c5fa33d-6ad6-4ac0-a139-868565461e64"], "operator": null, "metadata": {"aucs": [0.21058836984418772, 0.1996150196950245, 0.8653978810799692, 0.16519534779808487, 0.9017208058309507, 0.2855525089270293, 0.3327845795676192, 0.8313044113862736, 0.21800613058080875, 0.8893157368967701, 0.944581725342933, 0.9988862459627129, 0.31430426772339826, 0.338045026240388, 0.7407816112978336, 0.33322918074275953, 0.40085769029945906, 0.38083794645544444, 0.17357086265949817, 0.4472494826481116]}}
{"id": "4b65da68-fe30-47af-a48f-fa0901d3f43f", "fitness": 0.20760008461159898, "name": "CMAES", "description": "Improved CMA-ES with learning rate adaptation based on conjugate evolution paths and dynamic covariance matrix adaptation.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov_rank_one=None, c_cov_rank_mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.mu-1)/(self.dim+1))-1) + self.cs\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 1 / (10*self.dim**2)\n        self.c_cov_rank_mu = c_cov_rank_mu if c_cov_rank_mu is not None else 0.1 #/ (self.dim**2) # Simplified c_cov\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.eigen_updated = 0\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n\n    def sample_population(self):\n        z = np.random.randn(self.dim, self.popsize)\n        x = self.m[:, np.newaxis] + self.sigma * (self.B * self.D) @ z\n        x = np.clip(x, -5, 5)\n        return x.T, z\n\n    def update_decomposition(self):\n         if self.eval_count - self.eigen_updated > self.popsize:\n                self.eigen_updated = self.eval_count\n                self.C = np.triu(self.C) + np.triu(self.C, 1).T\n                try:\n                    self.D, self.B = np.linalg.eigh(self.C)\n                    self.D = np.sqrt(np.abs(self.D))\n                except np.linalg.LinAlgError:\n                    self.C = self.C + 1e-6 * np.eye(self.dim)\n                    self.D, self.B = np.linalg.eigh(self.C)\n                    self.D = np.sqrt(np.abs(self.D))\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            x, z = self.sample_population()\n            f = np.array([func(xi) for xi in x])\n            self.eval_count += self.popsize\n            \n            idx = np.argsort(f)\n            x = x[idx]\n            z = z[:, idx]\n            f = f[idx]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n            \n            z_mu = np.sum(self.weights * z[:, :self.mu], axis=1)\n            y = self.B @ (self.D * z_mu)\n            self.m = self.m + self.cs * self.sigma * y\n\n            self.ps = (1 - self.cs) * self.ps + (self.cs**0.5) * z_mu\n            norm_ps = np.linalg.norm(self.ps)\n            \n            c_temp = (self.cs * (2 - self.cs))\n            self.pc = (1 - c_temp) * self.pc + (c_temp**0.5) * y\n\n            \n            rank_one = np.outer(self.pc, self.pc)\n            rank_mu = np.sum(np.array([w * np.outer(self.B @ (self.D * z[:, i]), self.B @ (self.D * z[:, i])) for i, w in enumerate(self.weights)]), axis=0)\n            self.C = (1 - self.c_cov_rank_one - self.c_cov_rank_mu) * self.C + self.c_cov_rank_one * rank_one + self.c_cov_rank_mu * rank_mu\n\n            self.sigma = self.sigma * np.exp((self.cs / self.damps) * (norm_ps / self.chiN - 1))\n            self.update_decomposition()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm CMAES scored 0.208 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b08fcaa4-5a64-4e14-9e58-ef9e8818e81b"], "operator": null, "metadata": {"aucs": [0.059448163343525096, 0.17946645048341803, 0.3168004347135347, 0.17277038976314163, 0.13670850355442288, 0.15008973186049424, 0.1769120626828644, 0.2959264729774934, 0.1554350911864314, 0.14925055550062027, 0.19693876813259525, 0.22130617261628927, 0.3107165257774014, 0.18770630146102418, 0.24308580475563102, 0.26312259170857255, 0.24649073259919996, 0.3739253793952747, 0.14417683475036536, 0.17172472496967983]}}
{"id": "dcbc34e9-0ebe-46a2-afb7-0a0bcabb69ee", "fitness": 0.3267751112208511, "name": "AdaptivePSO", "description": "Adaptive PSO with dynamic parameter adjustments based on stagnation detection and a simplified velocity update.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=1.5, social_coeff=1.5, initial_inertia=0.9, inertia_decay=0.995, stagnation_threshold=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.initial_inertia = initial_inertia\n        self.inertia_decay = inertia_decay\n        self.velocity_clamp = 0.5\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.exploration_rate = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb), size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n\n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        inertia = self.initial_inertia\n        \n        # Optimization loop\n        while self.budget > 0:\n            old_global_best_fitness = global_best_fitness # Store for adaptive inertia\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Simplified Velocity Update\n                velocities[i] = (inertia * velocities[i] +\n                                 self.cognitive_coeff * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * (global_best_position - population[i]))\n\n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n\n                # Update position\n                new_position = population[i] + velocities[i]\n\n                # Exploration: Randomly move a particle if exploration rate is met\n                if np.random.rand() < self.exploration_rate:\n                    new_position = np.random.uniform(lb, ub)\n\n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                        self.stagnation_counter = 0  # Reset stagnation counter\n\n                population[i] = new_position\n                \n            # Adaptive inertia: Reduce inertia if global best improves, increase otherwise\n            if global_best_fitness < old_global_best_fitness:\n                inertia *= self.inertia_decay  # Reduce inertia (exploitation)\n                self.stagnation_counter = 0 # Reset stagnation\n            else:\n                self.stagnation_counter += 1\n                inertia = min(self.initial_inertia, inertia / self.inertia_decay)  # Increase inertia (exploration)\n                \n                # Stagnation Detection and Mitigation\n                if self.stagnation_counter > self.stagnation_threshold:\n                    # Option 1: Increase Exploration Rate\n                    self.exploration_rate = min(0.5, self.exploration_rate * 1.2) # Increase exploration\n                    \n                    # Option 2: Randomly re-initialize a portion of the population\n                    num_reinitialize = int(self.pop_size * 0.2)\n                    indices_to_reinitialize = np.random.choice(self.pop_size, num_reinitialize, replace=False)\n                    population[indices_to_reinitialize] = np.random.uniform(lb, ub, size=(num_reinitialize, self.dim))\n                    velocities[indices_to_reinitialize] = np.random.uniform(-self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb), size=(num_reinitialize, self.dim))\n\n                    self.stagnation_counter = 0  # Reset stagnation counter\n                    \n            # Decrease exploration rate\n            self.exploration_rate = max(0.01, self.exploration_rate * 0.99)\n                \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptivePSO scored 0.327 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8355bb72-5936-4b23-b178-3d667db8e4c1"], "operator": null, "metadata": {"aucs": [0.14970661399591734, 0.2788376966170022, 0.29270760112811467, 0.23759967699782758, 0.2431278013288345, 0.32617481138688165, 0.2621621710772719, 0.21894990192926733, 0.25417954869846526, 0.20489431421641702, 0.24207419179539424, 0.9996642351384825, 0.26575362193139107, 0.26491937083963146, 0.6675930953908922, 0.32264545474948203, 0.2673431545142372, 0.3487200403996227, 0.21369847066491254, 0.47475045161697904]}}
{"id": "3874f2f2-ec07-4991-b725-42f20349a849", "fitness": 0.30996291071975124, "name": "PSO_DE", "description": "Simplified PSO-DE by removing binomial crossover and integrating DE mutation directly into the velocity update for a more streamlined exploration-exploitation balance.", "code": "import numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, de_coeff=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.de_coeff = de_coeff\n        self.velocity_clamp = 0.5\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb), size=(self.pop_size, self.dim))\n        \n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Standard PSO Velocity Update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * r2 * (global_best_position - population[i]))\n                \n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                \n                # Mutation Vector - Directly influence the velocity\n                mutation_vector = self.de_coeff * (x_r2 - x_r3)\n                velocities[i] += mutation_vector\n\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm PSO_DE scored 0.310 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2592c5ec-5777-4452-8547-064ca9179980"], "operator": null, "metadata": {"aucs": [0.14410638433794976, 0.1848529021161831, 0.3130387121748608, 0.25172009400800266, 0.22675863754392078, 0.26635267976594945, 0.275944091423282, 0.21972443514099227, 0.2134300188238002, 0.18408186184810604, 0.24443133230082936, 0.9991015710518054, 0.2654536016511425, 0.24386710836048453, 0.6444318987377828, 0.3041118130126921, 0.2377667886951924, 0.3485492242173396, 0.16431069176994284, 0.4672243674147668]}}
{"id": "ccb14618-9937-4809-a029-286da5f5d50d", "fitness": 0.44211836633048857, "name": "HybridDEPSO", "description": "Hybrid algorithm combining the exploration of Differential Evolution (DE) with the exploitation of Particle Swarm Optimization (PSO), further enhanced with a self-adaptive mutation strategy.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, w_max=0.9, w_min=0.4, c1=2, c2=2, adapt_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.Cr = Cr  # Crossover rate\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1 = c1\n        self.c2 = c2\n        self.adapt_prob = adapt_prob # Probability to adapt mutation strategy\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize velocities\n        velocities = np.zeros_like(population)\n\n        # Find best particle\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_max - (self.w_max - self.w_min) * (1 - self.budget / 10000) # Linear decay\n\n            for i in range(self.pop_size):\n                # Adaptive mutation strategy\n                if np.random.rand() < self.adapt_prob:\n                    # DE mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n                    v_trial = x_r1 + self.F * (x_r2 - x_r3)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    trial_vector = np.copy(population[i])\n                    for j in range(self.dim):\n                        if np.random.rand() < self.Cr or j == j_rand:\n                            trial_vector[j] = v_trial[j]\n                else:\n                    # PSO update\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    velocities[i] = w * velocities[i] + \\\n                                  self.c1 * r1 * (population[i] - population[i]) + \\\n                                  self.c2 * r2 * (best_position - population[i])\n                    trial_vector = population[i] + velocities[i]\n\n                # Boundary handling\n                trial_vector = np.clip(trial_vector, lb, ub)\n                \n                # Evaluate trial vector\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n\n                # Selection: replace if better\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial_vector.copy()\n\n                    # Update best particle\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_position = population[i].copy()\n            \n\n        return fitness[best_index], best_position", "configspace": "", "generation": 2, "feedback": "The algorithm HybridDEPSO scored 0.442 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6c5fa33d-6ad6-4ac0-a139-868565461e64"], "operator": null, "metadata": {"aucs": [0.13906406915636782, 0.2877424270912421, 0.4294752720768449, 0.7265776855664814, 0.2499531783152471, 0.537308461307574, 0.30467200894413005, 0.3491179026945421, 0.4459576597979763, 0.3613670381581251, 0.5695618856446618, 0.997893493078973, 0.2580273780214789, 0.24403960837831618, 0.7802178981841142, 0.5216452189620471, 0.3467029529387965, 0.6282544594674814, 0.19155907781970827, 0.4732296510056626]}}
{"id": "f2084b87-37a4-4c30-ab25-5b57f0abb331", "fitness": 0.1983376953283889, "name": "CMAES", "description": "Simplified CMA-ES with rank-one update and adaptive step size, focusing on computational efficiency and robustness.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov_rank_one=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.mu-1)/(self.dim+1))-1) + self.cs\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 1 / (10*self.dim**2)\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def sample_population(self):\n        z = np.random.randn(self.dim, self.popsize)\n        try:\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * (C_sqrt @ z).T\n        except np.linalg.LinAlgError:\n            self.C += 1e-6 * np.eye(self.dim)\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * (C_sqrt @ z).T\n\n        x = np.clip(x, -5, 5)\n        return x, z\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            x, z = self.sample_population()\n            f = np.array([func(xi) for xi in x])\n            self.eval_count += self.popsize\n            \n            idx = np.argsort(f)\n            x = x[idx]\n            z = z[:, idx]\n            f = f[idx]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n            \n            z_mu = np.sum(self.weights * z[:, :self.mu], axis=1)\n            self.m += self.cs * self.sigma * z_mu\n\n            self.ps = (1 - self.cs) * self.ps + (self.cs**0.5) * z_mu\n            self.C = (1 - self.c_cov_rank_one) * self.C + self.c_cov_rank_one * np.outer(self.ps, self.ps)\n            \n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            \n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C += 1e-6 * np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm CMAES scored 0.198 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b08fcaa4-5a64-4e14-9e58-ef9e8818e81b"], "operator": null, "metadata": {"aucs": [0.04398533584467401, 0.18048006921354898, 0.3758500824096138, 0.17841890199831778, 0.20089852560756016, 0.14948760746832956, 0.22075415090999206, 0.18571970340122812, 0.14976933390599645, 0.1457138272205537, 0.201919585223717, 0.23561686761739997, 0.2528726784824227, 0.16397350832242885, 0.17527698506728506, 0.250395409404218, 0.1867996276353695, 0.3690833925295177, 0.13701593000534107, 0.1627223843002632]}}
{"id": "02a33da0-8eb6-4626-ad53-2219ff30d86f", "fitness": -Infinity, "name": "HybridCMAESPSO", "description": "Hybrid algorithm combining CMA-ES sampling with PSO updates, adaptively selecting between global and local search strategies.", "code": "import numpy as np\nimport cma\n\nclass HybridCMAESPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_max=0.9, w_min=0.4, c1=2, c2=2, cma_sigma=0.5, adapt_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1 = c1\n        self.c2 = c2\n        self.cma_sigma = cma_sigma\n        self.adapt_prob = adapt_prob\n        self.es = cma.PureCMAES(self.dim, self.cma_sigma)\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.best_position = None\n        self.best_fitness = np.inf\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.zeros_like(self.population)\n        best_index = np.argmin(self.fitness)\n        self.best_position = self.population[best_index].copy()\n        self.best_fitness = self.fitness[best_index]\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        if self.population is None:\n            self.initialize_population(func)\n\n        while self.budget > 0:\n            w = self.w_max - (self.w_max - self.w_min) * (1 - self.budget / 10000)\n\n            for i in range(self.pop_size):\n                if np.random.rand() < self.adapt_prob:\n                    # CMA-ES sampling for exploration\n                    if self.budget > 0:\n                        x = self.es.ask(1)[0]\n                        x = np.clip(x, lb, ub)\n                        f = func(x)\n                        self.budget -= 1\n                        self.es.tell([(x, f)])\n\n                        if f < self.fitness[i]:\n                            self.fitness[i] = f\n                            self.population[i] = x.copy()\n\n                            if f < self.best_fitness:\n                                self.best_fitness = f\n                                self.best_position = x.copy()\n                else:\n                    # PSO update for exploitation\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    self.velocities[i] = w * self.velocities[i] + \\\n                                          self.c1 * r1 * (self.population[i] - self.population[i]) + \\\n                                          self.c2 * r2 * (self.best_position - self.population[i])\n                    trial_vector = self.population[i] + self.velocities[i]\n                    trial_vector = np.clip(trial_vector, lb, ub)\n\n                    if self.budget > 0:\n                        trial_fitness = func(trial_vector)\n                        self.budget -= 1\n\n                        if trial_fitness < self.fitness[i]:\n                            self.fitness[i] = trial_fitness\n                            self.population[i] = trial_vector.copy()\n\n                            if trial_fitness < self.best_fitness:\n                                self.best_fitness = trial_fitness\n                                self.best_position = self.population[i].copy()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 3, "feedback": "An exception occurred: No module named 'cma'.", "error": "", "parent_ids": ["ccb14618-9937-4809-a029-286da5f5d50d"], "operator": null, "metadata": {}}
{"id": "7180f55a-15af-4ae6-ac5b-bfae094da9dd", "fitness": 0.0, "name": "RingTopologyPSO", "description": "A PSO variant with a ring topology, velocity mutation, and adaptive parameter control using a success history-based adaptation mechanism.", "code": "import numpy as np\n\nclass RingTopologyPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.0, social_coeff=2.0, inertia=0.7, velocity_clamp=0.5, success_history_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.inertia = inertia\n        self.velocity_clamp = velocity_clamp\n        self.success_history_size = success_history_size\n        self.success_history = []\n        self.exploration_probability = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb), size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n\n        # Ring Topology: Determine neighbors for each particle\n        left_neighbors = np.roll(population, 1, axis=0)\n        right_neighbors = np.roll(population, -1, axis=0)\n\n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Ring topology: find best neighbor\n                neighbors = np.stack([left_neighbors[i], right_neighbors[i]], axis=0)\n                neighbor_fitnesses = np.array([func(n) if self.budget > 0 else np.inf for n in neighbors])\n                self.budget -= 2\n                best_neighbor_index = np.argmin(neighbor_fitnesses)\n                best_neighbor = neighbors[best_neighbor_index]\n\n                # Velocity Mutation: Add small random perturbation\n                if np.random.rand() < self.exploration_probability:\n                    mutation = np.random.uniform(-0.1 * (ub - lb), 0.1 * (ub - lb), size=self.dim)\n                    velocities[i] += mutation\n                    velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n\n                # Update velocity\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive_coeff * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * (best_neighbor - population[i])) # Influence from the best neighbor\n\n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n\n                # Update position\n                new_position = population[i] + velocities[i]\n\n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                        self.success_history.append(1) # Success\n                    else:\n                        self.success_history.append(0) # Failure\n\n                    # Keep success history size limited\n                    if len(self.success_history) > self.success_history_size:\n                        self.success_history.pop(0)\n\n                population[i] = new_position\n\n            left_neighbors = np.roll(population, 1, axis=0)\n            right_neighbors = np.roll(population, -1, axis=0)\n\n            # Adaptive Parameter Control (Inertia)\n            if len(self.success_history) > 0:\n                success_rate = np.mean(self.success_history)\n                # Dynamically adjust inertia based on success rate\n                self.inertia = 0.5 + success_rate * 0.4 # Inertia between 0.5 and 0.9\n                self.cognitive_coeff = 1.5 + (1-success_rate) * 1.0\n                self.social_coeff = 1.5 + (1-success_rate) * 1.0\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm RingTopologyPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["dcbc34e9-0ebe-46a2-afb7-0a0bcabb69ee"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "3893645f-080d-4050-babf-647a315d889b", "fitness": -Infinity, "name": "AdaptiveVelocityParticleSwarm", "description": "Adaptive PSO with dynamic diversity-based parameter adjustments and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveVelocityParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_range=(0.4, 0.9), cognitive_coeff=2.0, social_coeff=2.0, stagnation_threshold=0.01, stagnation_steps=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_range = inertia_range\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_steps = stagnation_steps\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) / 2, (ub - lb) / 2, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        self.best_fitness_history.append(global_best_fitness)\n        \n        stagnation_counter = 0\n\n        # Optimization loop\n        while self.budget > 0:\n            # Calculate swarm diversity (average distance to the global best)\n            diversity = np.mean(np.linalg.norm(population - global_best_position, axis=1)) / (ub - lb)\n            \n            # Adaptive inertia weight (linearly decreasing with diversity)\n            inertia = self.inertia_range[0] + (self.inertia_range[1] - self.inertia_range[0]) * (1 - diversity)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = inertia * velocities[i] + \\\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) + \\\n                                 self.social_coeff * r2 * (global_best_position - population[i])\n                \n                # Clamp velocities (using a proportion of the search space)\n                v_max = 0.2 * (ub - lb)  # Clamp velocities to 20% of the search range\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n                population[i] = new_position\n                \n            self.best_fitness_history.append(global_best_fitness)\n            \n            # Stagnation detection\n            if len(self.best_fitness_history) > self.stagnation_steps:\n                if abs(self.best_fitness_history[-1] - self.best_fitness_history[-self.stagnation_steps]) < self.stagnation_threshold:\n                    stagnation_counter += 1\n                else:\n                    stagnation_counter = 0\n            \n            # Restart mechanism\n            if stagnation_counter >= self.stagnation_steps:\n                # Re-initialize a portion of the population around the best solution\n                num_to_restart = int(0.5 * self.pop_size)  # Restart half the population\n                indices_to_restart = np.random.choice(self.pop_size, num_to_restart, replace=False)\n                \n                for i in indices_to_restart:\n                    population[i] = np.random.uniform(max(lb, global_best_position[0]-0.5), min(ub, global_best_position[0]+0.5), size=self.dim)\n\n                    velocities[i] = np.random.uniform(-(ub - lb) / 20, (ub - lb) / 20, size=(self.dim)) # smaller velocity\n                    \n                    new_fitness = func(population[i])\n                    self.budget -= 1\n                    \n                    if new_fitness < personal_best_fitnesses[i]:\n                        personal_best_fitnesses[i] = new_fitness\n                        personal_best_positions[i] = population[i].copy()\n\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = population[i].copy()\n\n                stagnation_counter = 0\n                self.best_fitness_history = self.best_fitness_history[-self.stagnation_steps:]  # Reset history\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 3, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["4051d13e-2cb8-4680-a9a9-4db23522fc9e"], "operator": null, "metadata": {}}
{"id": "141e8e7a-0fb4-4b28-a70b-5d99f9d904ab", "fitness": -Infinity, "name": "OrthogonalLearningPSO", "description": "Population-based algorithm with orthogonal learning, which uses orthogonal design to sample informative points around each particle to improve search efficiency and diversity.", "code": "import numpy as np\n\nclass OrthogonalLearningPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.0, social_coeff=2.0, orthogonal_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.orthogonal_size = orthogonal_size  # Number of samples in orthogonal design\n\n    def generate_orthogonal_array(self, n_factors, n_levels):\n        \"\"\"\n        Generates an orthogonal array using Plackett-Burman design.\n        For simplicity, we assume n_levels = 2.\n        \"\"\"\n        if n_factors > n_levels * 2:\n            raise ValueError(\"Number of factors exceeds the maximum possible for this OA size.\")\n        \n        H = np.array([\n            [+1, +1, +1, -1, +1, -1, -1, +1, -1, -1, -1, ],\n            [+1, +1, -1, +1, -1, -1, +1, -1, -1, -1, +1, ],\n            [+1, -1, +1, -1, -1, +1, -1, -1, -1, +1, +1, ],\n            [+1, +1, +1, +1, +1, +1, +1, +1, +1, +1, +1, ],\n            [+1, -1, -1, +1, +1, -1, -1, +1, -1, +1, -1, ],\n            [+1, -1, -1, -1, +1, +1, -1, -1, +1, -1, +1, ],\n            [+1, -1, +1, +1, -1, -1, +1, -1, +1, -1, -1, ],\n            [+1, +1, -1, -1, -1, +1, +1, -1, -1, +1, -1, ],\n            [+1, +1, -1, -1, +1, -1, -1, +1, +1, -1, -1, ],\n            [+1, -1, +1, -1, -1, -1, +1, +1, -1, +1, -1, ],\n            [+1, -1, -1, +1, -1, +1, -1, -1, -1, -1, +1, ],\n        ])\n        \n        H = (H + 1) // 2 # Convert +1/-1 to 1/0\n        \n        return H[:n_factors+1, :].T\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal and global best\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Generate orthogonal array around the current particle\n                orthogonal_array = self.generate_orthogonal_array(self.dim, 2) # 2 levels for each dimension\n                \n                # Sample points based on the orthogonal array\n                samples = np.zeros((orthogonal_array.shape[0], self.dim))\n                for j in range(orthogonal_array.shape[0]):\n                    for k in range(self.dim):\n                        # Scale and shift the orthogonal array values to the search space\n                        samples[j, k] = population[i, k] + (orthogonal_array[j, k] - 0.5) * (ub - lb) * 0.1 # small perturbation\n                        samples[j, k] = np.clip(samples[j, k], lb, ub)\n                \n                # Evaluate the samples\n                sample_fitnesses = []\n                for j in range(orthogonal_array.shape[0]):\n                    if self.budget > 0:\n                        sample_fitnesses.append(func(samples[j]))\n                        self.budget -= 1\n                    else:\n                        sample_fitnesses.append(np.inf)  # Assign a large fitness value if budget is exhausted\n\n                sample_fitnesses = np.array(sample_fitnesses)\n\n                # Find the best sample\n                best_sample_index = np.argmin(sample_fitnesses)\n\n                # Update personal best with the best sample\n                if sample_fitnesses[best_sample_index] < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = sample_fitnesses[best_sample_index]\n                    personal_best_positions[i] = samples[best_sample_index].copy()\n                    \n                    # Update global best\n                    if sample_fitnesses[best_sample_index] < global_best_fitness:\n                        global_best_fitness = sample_fitnesses[best_sample_index]\n                        global_best_position = samples[best_sample_index].copy()\n                \n                # Update velocity and position (standard PSO update)\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (0.729 * (velocities[i] +  # Constriction factor = 0.729\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * r2 * (global_best_position - population[i])))\n                \n                # Clip velocities\n                velocities[i] = np.clip(velocities[i], -(ub - lb) * 0.1, (ub - lb) * 0.1)\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                population[i] = new_position\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 3, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["5a87dd04-4409-46b5-bbe9-cc4e01fe771c"], "operator": null, "metadata": {}}
{"id": "da2c7dde-c3c0-4ab8-a51e-8d39ee941965", "fitness": 0.4938326299817972, "name": "DynamicAdaptivePSO", "description": "A PSO variant with dynamically adjusted inertia and social coefficient based on the swarm's convergence rate.", "code": "import numpy as np\n\nclass DynamicAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_inertia=0.9, cognitive_coeff=2.0, initial_social_coeff=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = initial_inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = initial_social_coeff\n        self.initial_social_coeff = initial_social_coeff\n\n        self.convergence_history = [] # store the swarm's fbest to track convergence.\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) / 2, (ub - lb) / 2, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        self.convergence_history.append(global_best_fitness)\n\n        # Optimization loop\n        while self.budget > 0:\n            # Convergence rate calculation\n            if len(self.convergence_history) > 10:\n                convergence_rate = abs(self.convergence_history[-1] - self.convergence_history[-10]) / 10\n            else:\n                convergence_rate = 0\n\n            # Dynamic parameter adjustment\n            if convergence_rate < 1e-6:  # Swarm is converging slowly\n                self.inertia *= 0.95       # Reduce inertia to allow finer search\n                self.social_coeff += 0.1    # Increase social influence\n            else:\n                self.inertia = min(self.inertia * 1.05, 0.9)   # Increase inertia to promote exploration\n                self.social_coeff = max(self.social_coeff - 0.05, self.initial_social_coeff) # Decrease social influence\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.inertia * velocities[i] + \\\n                                self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) + \\\n                                self.social_coeff * r2 * (global_best_position - population[i])\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n                population[i] = new_position\n            self.convergence_history.append(global_best_fitness)\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm DynamicAdaptivePSO scored 0.494 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4051d13e-2cb8-4680-a9a9-4db23522fc9e"], "operator": null, "metadata": {"aucs": [0.12491698499800385, 0.2522535676430454, 0.56635338181082, 0.8615382048192084, 0.26357795522736405, 0.6209289458461754, 0.3290425979856708, 0.4366364878370066, 0.6578875702260376, 0.6537414513232767, 0.7831241235820998, 0.9958641370566559, 0.2356051258878088, 0.2865961578199877, 0.7035621792452665, 0.633790378530227, 0.40298041221821645, 0.3810954667311024, 0.19234086856065336, 0.4948166022873166]}}
{"id": "bee90618-ad55-48a7-809f-d86e2e5f036e", "fitness": 0.36995669350274135, "name": "AdaptiveVelocityParticleSwarm", "description": "Enhanced Adaptive PSO with simplified velocity update and dynamic inertia based on swarm's best fitness variance for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveVelocityParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_coeff=2.0, social_coeff=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Calculate inertia weight based on fitness variance\n            fitness_var = np.var(fitness)\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (fitness_var / (1e-8 + np.var(personal_best_fitnesses)))\n            inertia = np.clip(inertia, self.inertia_min, self.inertia_max)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Simplified velocity update\n                velocities[i] = (inertia * velocities[i] +\n                                 self.cognitive_coeff * np.random.rand() * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * np.random.rand() * (global_best_position - population[i]))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (bounce back)\n                oob = (new_position < lb) | (new_position > ub)\n                velocities[i][oob] *= -0.5  # Reduce velocity and reverse direction\n                new_position = np.clip(new_position, lb, ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveVelocityParticleSwarm scored 0.370 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5a87dd04-4409-46b5-bbe9-cc4e01fe771c"], "operator": null, "metadata": {"aucs": [0.06749908200994048, 0.18387240954934803, 0.3937291497233617, 0.32363731285416586, 0.18833202640192193, 0.5240999417295273, 0.26226654289048035, 0.2668196650668846, 0.23898427512590192, 0.15267739797432844, 0.3731588355440213, 0.9979273661124106, 0.39590880032276776, 0.2802284072713831, 0.5479556823903646, 0.36195895133179634, 0.3368193073704415, 0.8630333969832822, 0.18035429998235886, 0.4598710194201401]}}
{"id": "9ec96e76-e98b-4541-9472-d5c56d1a2a53", "fitness": 0.31168072149485077, "name": "AdaptiveVelocityParticleSwarm", "description": "Simplified Adaptive PSO with shrinking velocity clamping and inertia based on the remaining budget.", "code": "import numpy as np\n\nclass AdaptiveVelocityParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_coeff=2.0, social_coeff=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Calculate remaining budget ratio for adaptive parameters\n            remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n\n            # Adaptive inertia weight (linearly decreasing with remaining budget)\n            inertia = self.inertia_min + (self.inertia_max - self.inertia_min) * remaining_ratio\n            \n            # Adaptive velocity clamping (shrinking with remaining budget)\n            velocity_clamp = (ub - lb) * remaining_ratio # Smaller clamp as budget decreases\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * r2 * (global_best_position - population[i]))\n                \n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveVelocityParticleSwarm scored 0.312 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5a87dd04-4409-46b5-bbe9-cc4e01fe771c"], "operator": null, "metadata": {"aucs": [0.145935954600946, 0.18173908988409904, 0.2893481100044959, 0.35964982148593627, 0.25496605306475373, 0.2628615942972887, 0.22477796089427515, 0.20332349290634755, 0.24027897831305378, 0.20691272077920253, 0.18791417505273744, 0.9994839508884662, 0.25426718959955663, 0.24277912810392532, 0.5858655687360916, 0.3116024778367157, 0.2624798217082931, 0.36302546496886967, 0.167058842134846, 0.48934403463711384]}}
{"id": "2c0d47bc-71a2-42e1-99ee-b5f39ed60090", "fitness": 0.4211270824499966, "name": "HybridDEPSO", "description": "Enhanced Hybrid DE/PSO with simplified velocity clamping and adaptive parameter control based on success rate.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, w=0.7, c1=1.5, c2=1.5, adapt_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.Cr = Cr  # Crossover rate\n        self.w = w  # Inertia weight\n        self.c1 = c1\n        self.c2 = c2\n        self.adapt_rate = adapt_rate\n        self.success_history = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize velocities\n        velocities = np.zeros_like(population)\n\n        # Find best particle\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        best_fitness = fitness[best_index]\n\n        while self.budget > 0:\n            successful_moves = 0\n            for i in range(self.pop_size):\n                # With a probability adapt_rate, perform DE, otherwise PSO\n                if np.random.rand() < self.adapt_rate:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n                    \n                    # Mutation and Crossover\n                    v_trial = x_r1 + self.F * (x_r2 - x_r3)\n                    j_rand = np.random.randint(self.dim)\n                    trial_vector = np.copy(population[i])\n                    for j in range(self.dim):\n                        if np.random.rand() < self.Cr or j == j_rand:\n                            trial_vector[j] = v_trial[j]\n                else:\n                    # Particle Swarm Optimization\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    velocities[i] = self.w * velocities[i] + \\\n                                  self.c1 * r1 * (best_position - population[i]) + \\\n                                  self.c2 * r2 * (population[best_index] - population[i])\n                    \n                    # Velocity clamping - simplified\n                    v_max = 0.1 * (ub - lb)  # Clamp velocity to 10% of the range\n                    velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                    \n                    trial_vector = population[i] + velocities[i]\n\n                # Boundary handling\n                trial_vector = np.clip(trial_vector, lb, ub)\n                \n                # Evaluate trial vector\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n\n                # Selection: replace if better\n                if trial_fitness < fitness[i]:\n                    successful_moves +=1\n                    fitness[i] = trial_fitness\n                    population[i] = trial_vector.copy()\n\n                    # Update best particle\n                    if trial_fitness < best_fitness:\n                        best_index = i\n                        best_position = population[i].copy()\n                        best_fitness = trial_fitness\n            \n            # Adaptive parameter control based on recent success\n            self.success_history.append(successful_moves / self.pop_size)\n            if len(self.success_history) > 10:\n                self.success_history.pop(0)\n            \n            avg_success = np.mean(self.success_history)\n\n            if avg_success > 0.4:  # More exploration needed\n                self.Cr *= 0.95\n                self.F *= 1.05\n            elif avg_success < 0.1: # More exploitation needed\n                self.Cr *= 1.05\n                self.F *= 0.95\n            \n            self.Cr = np.clip(self.Cr, 0.1, 0.99)\n            self.F = np.clip(self.F, 0.1, 2.0)\n\n        return best_fitness, best_position", "configspace": "", "generation": 3, "feedback": "The algorithm HybridDEPSO scored 0.421 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ccb14618-9937-4809-a029-286da5f5d50d"], "operator": null, "metadata": {"aucs": [0.1360656931549702, 0.3196836849514285, 0.4476404777513229, 0.24592415465699802, 0.23824492303579814, 0.5467478143081796, 0.32471763400627185, 0.35290132415833175, 0.5727347377330508, 0.20288251953600112, 0.5166791900771042, 0.9980890586219235, 0.297157313566205, 0.3003441404196652, 0.7140443597782573, 0.44315625536578573, 0.3266996892075965, 0.7649251542927682, 0.1694430754512195, 0.5044604489270541]}}
{"id": "e029f71e-5bf7-4432-9c73-6c5ccbb447b2", "fitness": 0.43531256567441856, "name": "HybridDEPSO", "description": "Enhanced Hybrid DE/PSO with dynamic parameter adaptation based on fitness improvement and stagnation detection to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, w_max=0.9, w_min=0.4, c1=2, c2=2, adapt_prob=0.1, stagnation_limit=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.Cr = Cr  # Crossover rate\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1 = c1\n        self.c2 = c2\n        self.adapt_prob = adapt_prob # Probability to adapt mutation strategy\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize velocities\n        velocities = np.zeros_like(population)\n\n        # Find best particle\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        self.best_fitness_history.append(fitness[best_index])\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_max - (self.w_max - self.w_min) * (1 - self.budget / 10000) # Linear decay\n\n            # Stagnation detection and parameter adaptation\n            if len(self.best_fitness_history) > self.stagnation_limit:\n                if np.std(self.best_fitness_history[-self.stagnation_limit:]) < 1e-8:  #Stagnation threshold\n                    self.stagnation_counter += 1\n                    # Increase exploration if stagnating\n                    self.F = min(self.F * 1.1, 0.9)\n                    self.Cr = min(self.Cr * 1.1, 0.99)\n                    # Increase PSO exploration as well\n                    self.c1 = min(self.c1 * 1.1, 3) \n                else:\n                    self.stagnation_counter = 0\n                    # Reset parameters if improving\n                    self.F = 0.5\n                    self.Cr = 0.9\n                    self.c1 = 2\n            \n\n            for i in range(self.pop_size):\n                # Adaptive mutation strategy\n                if np.random.rand() < self.adapt_prob:\n                    # DE mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n                    v_trial = x_r1 + self.F * (x_r2 - x_r3)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    trial_vector = np.copy(population[i])\n                    for j in range(self.dim):\n                        if np.random.rand() < self.Cr or j == j_rand:\n                            trial_vector[j] = v_trial[j]\n                else:\n                    # PSO update\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    velocities[i] = w * velocities[i] + \\\n                                  self.c1 * r1 * (best_position - population[i]) + \\\n                                  self.c2 * r2 * (population[i] - population[i]) # Corrected PSO part\n                    trial_vector = population[i] + velocities[i]\n\n                # Boundary handling\n                trial_vector = np.clip(trial_vector, lb, ub)\n                \n                # Evaluate trial vector\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n\n                # Selection: replace if better\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial_vector.copy()\n\n                    # Update best particle\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_position = population[i].copy()\n                        \n            self.best_fitness_history.append(fitness[best_index])        \n\n        return fitness[best_index], best_position", "configspace": "", "generation": 3, "feedback": "The algorithm HybridDEPSO scored 0.435 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ccb14618-9937-4809-a029-286da5f5d50d"], "operator": null, "metadata": {"aucs": [0.14894491822747036, 0.28421986333614446, 0.4652525174322837, 0.6446064114354051, 0.42024460142917064, 0.27547469411728787, 0.2996507727997434, 0.4273424986220393, 0.47854457380472426, 0.3525147379726724, 0.27171066801327814, 0.998214337536751, 0.3135028935840928, 0.403729464474195, 0.8131956821423478, 0.5024766163443, 0.3251522070284458, 0.6243360794949657, 0.18060792020358352, 0.4765298554894708]}}
{"id": "241a015c-c432-4f34-94c4-85590e152fa0", "fitness": 0.3027017429655004, "name": "AdaptivePSO", "description": "Adaptive PSO with covariance-based velocity sampling and dynamic exploration-exploitation balance using success history.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=1.5, social_coeff=1.5, initial_inertia=0.9, stagnation_threshold=10, success_rate_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.initial_inertia = initial_inertia\n        self.stagnation_threshold = stagnation_threshold\n        self.velocity_clamp = 0.5\n        self.stagnation_counter = 0\n        self.exploration_rate = 0.1\n        self.success_rate_threshold = success_rate_threshold\n        self.success_history = []  # Store recent success/failure (1/0)\n        self.success_history_length = 20\n        self.inertia = self.initial_inertia\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb), size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n\n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Exploration utility function\n        def explore(x):\n            return np.random.uniform(lb, ub)\n\n        # Exploitation utility function: Sample velocity using covariance information\n        def exploit(i, current_position, pbest, gbest, inertia, covariance_matrix):\n            mean = (inertia * velocities[i] +\n                    self.cognitive_coeff * (pbest - current_position) +\n                    self.social_coeff * (gbest - current_position))\n\n            try:\n                velocities[i] = np.random.multivariate_normal(mean, covariance_matrix)\n            except:\n                # Fallback to uniform sampling if covariance is not positive definite\n                velocities[i] = np.random.uniform(-self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb), size=self.dim)\n            \n            velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n            return velocities[i]\n\n        # Initialize covariance matrix (identity matrix)\n        covariance_matrix = np.eye(self.dim) * 0.1 * (ub-lb)**2 # scale covariance matrix with the range of the search space\n\n        # Optimization loop\n        while self.budget > 0:\n            old_global_best_fitness = global_best_fitness  # Store for adaptive inertia\n            \n            # Calculate success rate (fraction of improvement in last N iterations)\n            if self.success_history:\n                success_rate = np.mean(self.success_history)\n            else:\n                success_rate = 0.5  # Start with a neutral rate\n\n            # Dynamically adjust exploration rate based on success history\n            if success_rate > self.success_rate_threshold:\n                self.exploration_rate = max(0.01, self.exploration_rate * 0.95)  # Reduce exploration\n            else:\n                self.exploration_rate = min(0.5, self.exploration_rate * 1.05)  # Increase exploration\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Choose between exploration and exploitation\n                if np.random.rand() < self.exploration_rate:\n                    new_position = explore(population[i])\n                else:\n                    velocities[i] = exploit(i, population[i], personal_best_positions[i], global_best_position, self.inertia, covariance_matrix)\n                    new_position = population[i] + velocities[i]\n\n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                        self.success_history.append(1) # Mark as success\n                    else:\n                        self.success_history.append(0) # Mark as failure\n                else:\n                    self.success_history.append(0) # Mark as failure\n\n                population[i] = new_position\n\n            # Update covariance matrix\n            if len(self.success_history) >= self.success_history_length:\n                self.success_history = self.success_history[-self.success_history_length:]\n                # Calculate the mean position of the population\n                mean_position = np.mean(population, axis=0)\n\n                # Calculate the covariance matrix\n                covariance_matrix = np.cov(population.T)\n                # Add a small value to the diagonal to ensure positive definiteness\n                covariance_matrix += np.eye(self.dim) * 1e-6\n            \n\n            # Adaptive inertia: Reduce inertia if global best improves, increase otherwise\n            if global_best_fitness < old_global_best_fitness:\n                self.inertia = max(0.1, self.inertia * 0.99)  # Reduce inertia (exploitation)\n                self.stagnation_counter = 0  # Reset stagnation\n            else:\n                self.stagnation_counter += 1\n                self.inertia = min(self.initial_inertia, self.inertia / 0.99)  # Increase inertia (exploration)\n\n                # Stagnation Detection and Mitigation\n                if self.stagnation_counter > self.stagnation_threshold:\n                    # Option 2: Randomly re-initialize a portion of the population\n                    num_reinitialize = int(self.pop_size * 0.2)\n                    indices_to_reinitialize = np.random.choice(self.pop_size, num_reinitialize, replace=False)\n                    population[indices_to_reinitialize] = np.random.uniform(lb, ub, size=(num_reinitialize, self.dim))\n                    velocities[indices_to_reinitialize] = np.random.uniform(-self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb), size=(num_reinitialize, self.dim))\n\n                    self.stagnation_counter = 0  # Reset stagnation counter\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptivePSO scored 0.303 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["dcbc34e9-0ebe-46a2-afb7-0a0bcabb69ee"], "operator": null, "metadata": {"aucs": [0.13070834199810633, 0.18785818892948214, 0.2926953072331414, 0.22717466859485524, 0.23462200781109555, 0.24654675154303474, 0.25312274391605183, 0.24017944081230513, 0.20973936520279646, 0.18023095693874924, 0.2511679204160059, 0.9973312480413985, 0.24607619749097343, 0.23014694844235017, 0.6553074249595192, 0.29749788766626273, 0.228150280563425, 0.3070288032903271, 0.17867209343459112, 0.4597782820255356]}}
{"id": "88c081d6-f7f1-40da-be98-f5fb696c9a87", "fitness": 0.43361467525485564, "name": "AdaptiveVelocityParticleSwarm", "description": "Simplified Adaptive PSO with diversity-controlled inertia and learning coefficients, eliminating velocity clamping for efficiency and focusing on parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveVelocityParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_max=2.5, social_max=2.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Calculate swarm diversity (average distance to the global best)\n            diversity = np.mean(np.linalg.norm(population - global_best_position, axis=1)) / (ub - lb)\n\n            # Adaptive inertia weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * diversity\n            inertia = np.clip(inertia, self.inertia_min, self.inertia_max)\n            \n            # Adaptive cognitive and social coefficients\n            cognitive_coeff = self.cognitive_max - (self.cognitive_max - 1.0) * diversity # Reduce cognitive influence as diversity decreases\n            social_coeff = 1.0 + (self.social_max - 1.0) * diversity # Increase social influence as diversity decreases\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeff * r2 * (global_best_position - population[i]))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveVelocityParticleSwarm scored 0.434 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5a87dd04-4409-46b5-bbe9-cc4e01fe771c"], "operator": null, "metadata": {"aucs": [0.2143671561003323, 0.20711183700128388, 0.48591686560115877, 0.8186037742414989, 0.4308431329057909, 0.49248316082364774, 0.2569884186234359, 0.3909815028689624, 0.2114883756832222, 0.18763964102896347, 0.5925161552975655, 0.9984614609585608, 0.31017048490773647, 0.26579659308701753, 0.7217574191767955, 0.600380384299406, 0.39356084693160076, 0.3807440313756786, 0.2235455665288063, 0.48893669765564796]}}
{"id": "a9414f26-1a82-4856-a6b1-105bce85b5a1", "fitness": 0.3463422933922097, "name": "HybridDEPSO", "description": "Enhanced Hybrid DEPSO with adaptive parameter control, population diversity maintenance, and a restart mechanism for improved exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, w_max=0.9, w_min=0.4, c1=2, c2=2, adapt_prob=0.1, diversity_threshold=0.1, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.Cr = Cr  # Crossover rate\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1 = c1\n        self.c2 = c2\n        self.adapt_prob = adapt_prob  # Probability to adapt mutation strategy\n        self.diversity_threshold = diversity_threshold\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize velocities\n        velocities = np.zeros_like(population)\n\n        # Find best particle\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        best_fitness = fitness[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Adaptive F and Cr\n            self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 0.9)\n            self.Cr = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)\n\n            # Update inertia weight (linearly decreasing)\n            w = self.w_max - (self.w_max - self.w_min) * (generation / (self.budget + generation)) # Linear decay\n\n            for i in range(self.pop_size):\n                # Adaptive mutation strategy\n                if np.random.rand() < self.adapt_prob:\n                    # DE mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n                    v_trial = x_r1 + self.F * (x_r2 - x_r3)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    trial_vector = np.copy(population[i])\n                    for j in range(self.dim):\n                        if np.random.rand() < self.Cr or j == j_rand:\n                            trial_vector[j] = v_trial[j]\n                else:\n                    # PSO update\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    velocities[i] = w * velocities[i] + \\\n                                  self.c1 * r1 * (best_position - population[i]) + \\\n                                  self.c2 * r2 * (population[best_index] - population[i]) #correct version\n                    trial_vector = population[i] + velocities[i]\n\n                # Boundary handling\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                # Evaluate trial vector\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n\n                # Selection: replace if better\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial_vector.copy()\n\n                    # Update best particle\n                    if trial_fitness < best_fitness:\n                        best_index = i\n                        best_position = population[i].copy()\n                        best_fitness = trial_fitness\n            \n            # Diversity check and restart mechanism\n            if self.check_diversity(population) < self.diversity_threshold and np.random.rand() < self.restart_prob:\n                population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                best_index = np.argmin(fitness)\n                best_position = population[best_index].copy()\n                best_fitness = fitness[best_index]\n                velocities = np.zeros_like(population) # Reset velocities as well.\n\n        return best_fitness, best_position\n\n    def check_diversity(self, population):\n        \"\"\"Calculates the average pairwise distance between particles.\"\"\"\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(population[i] - population[j]))\n        return np.mean(distances) if distances else 1.0", "configspace": "", "generation": 3, "feedback": "The algorithm HybridDEPSO scored 0.346 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ccb14618-9937-4809-a029-286da5f5d50d"], "operator": null, "metadata": {"aucs": [0.14983785443597186, 0.2513840446950312, 0.3558870515686765, 0.3807133869310726, 0.23661516348591405, 0.378794616502635, 0.2935371937738508, 0.26348113255193784, 0.301614489646968, 0.216917664791907, 0.46586842690384844, 0.9967186806111274, 0.2430006214418703, 0.24453558950814946, 0.6465567171673263, 0.34374366892230024, 0.27313691124005557, 0.2530894608357309, 0.18058577818772448, 0.4508274146420964]}}
{"id": "aca7b2dc-2350-441f-a8d2-77c2c0292897", "fitness": -Infinity, "name": "CMAES_NM", "description": "Combines CMA-ES exploration with a local search using Nelder-Mead simplex to refine promising solutions.", "code": "import numpy as np\nimport cma\nfrom scipy.optimize import minimize\n\nclass CMAES_NM:\n    def __init__(self, budget=10000, dim=10, sigma0=0.5, n_restarts=2):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.n_restarts = n_restarts  # Number of restarts\n        self.es = None\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        bounds = [(lb, ub)] * self.dim\n        \n        f_opt = np.inf\n        x_opt = None\n        \n        for _ in range(self.n_restarts):\n            # Initialize CMA-ES\n            x0 = np.random.uniform(lb, ub, size=self.dim)\n            self.es = cma.purecma.PureCMAES(x0, self.sigma0, bounds=bounds)\n\n            while self.es.result.evals_fevals < self.budget // self.n_restarts:\n                solutions = self.es.ask()\n                fitness_list = []\n                for s in solutions:\n                    fitness = func(s)\n                    fitness_list.append(fitness)\n                    \n                self.es.tell(solutions, fitness_list)\n                \n                if self.es.result.fbest < f_opt:\n                    f_opt = self.es.result.fbest\n                    x_opt = self.es.result.xbest\n            \n            # Local Search with Nelder-Mead around the CMA-ES best\n            if x_opt is not None:\n              res = minimize(func, x_opt, method='Nelder-Mead', bounds=bounds, options={'maxiter': self.budget // (10 * self.n_restarts)}) #Limit max iterations\n              if res.fun < f_opt:\n                f_opt = res.fun\n                x_opt = res.x\n                \n        return f_opt, x_opt", "configspace": "", "generation": 4, "feedback": "An exception occurred: No module named 'cma'.", "error": "", "parent_ids": ["e029f71e-5bf7-4432-9c73-6c5ccbb447b2"], "operator": null, "metadata": {}}
{"id": "df5a0092-9d7c-459e-9e2a-605baa6d4d40", "fitness": -Infinity, "name": "DiversityEnhancedAdaptivePSO", "description": "An adaptive PSO that adjusts inertia and social coefficient based on both convergence rate and population diversity, using a niching strategy to maintain diversity.", "code": "import numpy as np\n\nclass DiversityEnhancedAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_inertia=0.9, cognitive_coeff=2.0, initial_social_coeff=0.5, niche_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = initial_inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = initial_social_coeff\n        self.initial_social_coeff = initial_social_coeff\n        self.niche_radius = niche_radius\n\n        self.convergence_history = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) / 2, (ub - lb) / 2, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        self.convergence_history.append(global_best_fitness)\n\n        # Optimization loop\n        while self.budget > 0:\n            # Convergence rate calculation\n            if len(self.convergence_history) > 10:\n                convergence_rate = abs(self.convergence_history[-1] - self.convergence_history[-10]) / 10\n            else:\n                convergence_rate = 0\n\n            # Population diversity calculation\n            distances = np.linalg.norm(population - np.mean(population, axis=0), axis=1)\n            diversity = np.mean(distances)\n\n            # Dynamic parameter adjustment based on convergence and diversity\n            if convergence_rate < 1e-6:  # Swarm is converging slowly\n                self.inertia *= 0.95       # Reduce inertia to allow finer search\n                self.social_coeff += 0.1    # Increase social influence\n            else:\n                self.inertia = min(self.inertia * 1.05, 0.9)   # Increase inertia to promote exploration\n                self.social_coeff = max(self.social_coeff - 0.05, self.initial_social_coeff) # Decrease social influence\n\n            if diversity < 0.1 * (ub - lb):  # Low diversity: promote exploration\n                self.inertia = 0.9\n                self.social_coeff = self.initial_social_coeff\n                self.cognitive_coeff = 2.0\n            else:\n                 self.cognitive_coeff = 1.5 # reduce cognitive component if enough diversity\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Niche formation: Attract particles to niches around current best\n                attraction_vector = np.zeros(self.dim)\n                for j in range(self.pop_size):\n                    if i != j and np.linalg.norm(population[i] - population[j]) < self.niche_radius:\n                        attraction_vector += (population[j] - population[i])\n\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.inertia * velocities[i] + \\\n                                self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) + \\\n                                self.social_coeff * r2 * (global_best_position - population[i]) + \\\n                                0.1 * attraction_vector # Niche attraction\n\n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n                population[i] = new_position\n            self.convergence_history.append(global_best_fitness)\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 4, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["da2c7dde-c3c0-4ab8-a51e-8d39ee941965"], "operator": null, "metadata": {}}
{"id": "1f0c1b24-39e1-494b-b46e-f116f7957b49", "fitness": 0.0, "name": "AdaptiveVelocityParticleSwarmEnhanced", "description": "Adaptive PSO with dynamic parameter adjustments based on swarm stagnation and success rate, incorporating a mutation operator for enhanced exploration and an archive to prevent premature convergence.", "code": "import numpy as np\n\nclass AdaptiveVelocityParticleSwarmEnhanced:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_max=2.5, social_max=2.5, stagnation_threshold=50, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.stagnation_threshold = stagnation_threshold\n        self.archive_size = archive_size\n        self.archive = []\n        self.archive_fitness = []\n        self.success_rate = 0.0\n        self.success_history = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        stagnation_counter = 0\n\n        # Optimization loop\n        while self.budget > 0:\n            # Calculate swarm diversity (average distance to the global best)\n            diversity = np.mean(np.linalg.norm(population - global_best_position, axis=1)) / (ub - lb)\n\n            # Adaptive inertia weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * diversity\n            inertia = np.clip(inertia, self.inertia_min, self.inertia_max)\n            \n            # Adaptive cognitive and social coefficients\n            cognitive_coeff = self.cognitive_max - (self.cognitive_max - 1.0) * diversity # Reduce cognitive influence as diversity decreases\n            social_coeff = 1.0 + (self.social_max - 1.0) * diversity # Increase social influence as diversity decreases\n            \n            # Update velocities and positions\n            improved = False\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeff * r2 * (global_best_position - population[i]))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Mutation (exploration)\n                if np.random.rand() < 0.1:\n                    new_position = np.random.uniform(lb, ub, size=self.dim)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                        improved = True\n                        stagnation_counter = 0  # Reset stagnation counter when improvement occurs\n                    self.success_history.append(1)\n                else:\n                    self.success_history.append(0)\n\n                population[i] = new_position\n            \n            # Stagnation Check\n            if not improved:\n                stagnation_counter += 1\n\n            if stagnation_counter > self.stagnation_threshold:\n                # Trigger diversification: Reset a portion of the population\n                num_to_reset = int(self.pop_size * 0.3)\n                indices_to_reset = np.random.choice(self.pop_size, num_to_reset, replace=False)\n                for i in indices_to_reset:\n                    population[i] = np.random.uniform(lb, ub, size=self.dim)\n                    velocities[i] = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=self.dim)\n                    fitness[i] = func(population[i])\n                    self.budget -=1\n                    personal_best_positions[i] = population[i].copy()\n                    personal_best_fitnesses[i] = fitness[i]\n                    if fitness[i] < global_best_fitness:\n                        global_best_fitness = fitness[i]\n                        global_best_position = population[i].copy()\n                stagnation_counter = 0\n\n            # Archive the global best\n            if len(self.archive) < self.archive_size:\n                self.archive.append(global_best_position.copy())\n                self.archive_fitness.append(global_best_fitness)\n            else:\n                if global_best_fitness < np.max(self.archive_fitness):\n                    worst_index = np.argmax(self.archive_fitness)\n                    self.archive[worst_index] = global_best_position.copy()\n                    self.archive_fitness[worst_index] = global_best_fitness\n\n            # Success Rate calculation\n            if len(self.success_history) > 20:\n                self.success_rate = np.mean(self.success_history[-20:])\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveVelocityParticleSwarmEnhanced scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["88c081d6-f7f1-40da-be98-f5fb696c9a87"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "b9736e05-d3bd-4232-bf67-a2573fd4696c", "fitness": 0.0, "name": "HybridDEPSO", "description": "Dynamically adjusts DE/PSO parameters, including population size, based on stagnation and improvement, incorporating a restart mechanism for enhanced exploration.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, w_max=0.9, w_min=0.4, c1=2, c2=2, adapt_prob=0.1, stagnation_limit=50, restart_trigger=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.Cr = Cr  # Crossover rate\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1 = c1\n        self.c2 = c2\n        self.adapt_prob = adapt_prob # Probability to adapt mutation strategy\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.restart_trigger = restart_trigger  # Trigger for population restart\n        self.initial_pop_size = pop_size  # Store initial population size\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize velocities\n        velocities = np.zeros_like(population)\n\n        # Find best particle\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        self.best_fitness_history.append(fitness[best_index])\n        \n        generation = 0  # Keep track of generations\n\n        while self.budget > 0:\n            generation += 1\n            # Update inertia weight (linearly decreasing)\n            w = self.w_max - (self.w_max - self.w_min) * (1 - self.budget / 10000) # Linear decay\n\n            # Stagnation detection and parameter adaptation\n            if len(self.best_fitness_history) > self.stagnation_limit:\n                if np.std(self.best_fitness_history[-self.stagnation_limit:]) < 1e-8:  #Stagnation threshold\n                    self.stagnation_counter += 1\n                    # Increase exploration if stagnating\n                    self.F = min(self.F * 1.1, 0.9)\n                    self.Cr = min(self.Cr * 1.1, 0.99)\n                    # Increase PSO exploration as well\n                    self.c1 = min(self.c1 * 1.1, 3)\n                    # Increase population size if stagnating\n                    self.pop_size = min(self.pop_size + 2, self.initial_pop_size * 2) #Increase, but cap it.\n                    new_individuals = np.random.uniform(lb, ub, size=(2, self.dim)) #create only 2 new indivuals\n                    new_fitness = np.array([func(x) for x in new_individuals])\n                    self.budget -= 2\n                    population = np.vstack((population, new_individuals))\n                    fitness = np.concatenate((fitness, new_fitness))\n                    velocities = np.vstack((velocities, np.zeros_like(new_individuals))) #also append velocity\n\n                    #Find the new best index\n                    best_index = np.argmin(fitness)\n                    best_position = population[best_index].copy()\n                    \n                else:\n                    self.stagnation_counter = 0\n                    # Reset parameters if improving\n                    self.F = 0.5\n                    self.Cr = 0.9\n                    self.c1 = 2\n                    self.pop_size = self.initial_pop_size #Also reset pop size\n\n            # Restart mechanism\n            if self.stagnation_counter > self.restart_trigger:\n                # Reinitialize population with the best individual preserved\n                best_individual = population[best_index].copy()\n                population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                population[0] = best_individual  # Keep the best\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size -1 #Correct Budget\n                velocities = np.zeros_like(population)\n                best_index = np.argmin(fitness)\n                best_position = population[best_index].copy()\n                self.stagnation_counter = 0  # Reset stagnation counter\n                print(\"Restarting population\")\n\n\n            for i in range(self.pop_size):\n                # Adaptive mutation strategy\n                if np.random.rand() < self.adapt_prob:\n                    # DE mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n                    v_trial = x_r1 + self.F * (x_r2 - x_r3)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    trial_vector = np.copy(population[i])\n                    for j in range(self.dim):\n                        if np.random.rand() < self.Cr or j == j_rand:\n                            trial_vector[j] = v_trial[j]\n                else:\n                    # PSO update\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    velocities[i] = w * velocities[i] + \\\n                                  self.c1 * r1 * (best_position - population[i]) + \\\n                                  self.c2 * r2 * (best_position - population[i]) # Corrected PSO part, second term should be best_position\n                    trial_vector = population[i] + velocities[i]\n\n                # Boundary handling\n                trial_vector = np.clip(trial_vector, lb, ub)\n                \n                # Evaluate trial vector\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n\n                # Selection: replace if better\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial_vector.copy()\n\n                    # Update best particle\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_position = population[i].copy()\n                        \n            self.best_fitness_history.append(fitness[best_index])        \n\n        return fitness[best_index], best_position", "configspace": "", "generation": 4, "feedback": "The algorithm HybridDEPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e029f71e-5bf7-4432-9c73-6c5ccbb447b2"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "7d005f9f-a374-4aa7-8f4d-dd53d458c690", "fitness": 0.5250957138618146, "name": "SimplifiedAdaptivePSO", "description": "Simplified PSO with adaptive coefficients based on the difference between personal and global best to balance exploration and exploitation.", "code": "import numpy as np\n\nclass SimplifiedAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_max=2.0, social_max=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Adaptive coefficients based on fitness difference\n            fitness_diff = np.abs(personal_best_fitnesses - global_best_fitness)\n            \n            # Normalize the fitness difference\n            if np.max(fitness_diff) > 0:\n                normalized_diff = fitness_diff / np.max(fitness_diff)\n            else:\n                normalized_diff = np.zeros(self.pop_size) #if all fitnesses are equal\n            \n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * (1 - normalized_diff)\n            social_coeffs = 1.0 + (self.social_max - 1.0) * normalized_diff\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * normalized_diff\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia[i] * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm SimplifiedAdaptivePSO scored 0.525 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["88c081d6-f7f1-40da-be98-f5fb696c9a87"], "operator": null, "metadata": {"aucs": [0.14753730322334946, 0.17671165338720274, 0.8648537727944947, 0.9564112050804909, 0.31061912743634856, 0.2546746830489368, 0.31568039495065303, 0.7385173438587236, 0.21200447217490215, 0.1928346778976341, 0.8755013837269863, 0.9961330860080636, 0.3254671189483318, 0.2912432468858769, 0.7169991225706372, 0.9136233707435845, 0.6063353669532023, 0.9318375263153671, 0.1613530737796216, 0.5135763474518865]}}
{"id": "7b0697b0-4a3f-4267-8f71-7a1113d596d7", "fitness": 0.4881793521036051, "name": "AdaptivePSO", "description": "Simplified Adaptive PSO with inertia and acceleration coefficients tuned based on the success rate of particles in improving their personal best positions.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_max=2.0, social_max=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        success_rate = 0.5 # Initial success rate\n        \n        # Optimization loop\n        while self.budget > 0:\n            num_success = 0\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * success_rate  # Inertia decreases with success rate\n                cognitive_coeff = 1.0 + (self.cognitive_max - 1.0) * (1 - success_rate) # Cognitive increases when success rate decreases\n                social_coeff = 1.0 + (self.social_max - 1.0) * success_rate # Social increases when success rate increases\n\n                velocities[i] = (inertia * velocities[i] +\n                                 cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeff * r2 * (global_best_position - population[i]))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    num_success += 1\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n            \n            # Update success rate (using a moving average)\n            success_rate = 0.8 * success_rate + 0.2 * (num_success / self.pop_size) \n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptivePSO scored 0.488 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["88c081d6-f7f1-40da-be98-f5fb696c9a87"], "operator": null, "metadata": {"aucs": [0.15452237364778154, 0.17733985676519115, 0.5097862464046695, 0.9520543714930482, 0.2593694972591275, 0.9563026959673951, 0.3235027801175303, 0.3967335880061178, 0.8318588685591519, 0.1891104910898922, 0.28344591628545834, 0.9952594643491549, 0.2507254178480133, 0.26608075360318995, 0.7943935536136272, 0.9348254458115735, 0.5096765388295836, 0.29113951749233824, 0.1900157667004585, 0.497443898228798]}}
{"id": "54a7aa1e-907d-4a1a-afea-216c83bc12a0", "fitness": 0.4397404529646779, "name": "SelfAdaptivePSO", "description": "Implements a self-adaptive PSO with dynamic inertia, acceleration coefficients, and a mutation operator to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass SelfAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_max=2.5, social_max=2.5, mutation_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.mutation_rate = mutation_rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Calculate swarm diversity (average distance to the global best)\n            diversity = np.mean(np.linalg.norm(population - global_best_position, axis=1)) / (ub - lb)\n\n            # Adaptive inertia weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * diversity\n            inertia = np.clip(inertia, self.inertia_min, self.inertia_max)\n            \n            # Adaptive cognitive and social coefficients\n            cognitive_coeff = self.cognitive_max - (self.cognitive_max - 1.0) * diversity # Reduce cognitive influence as diversity decreases\n            social_coeff = 1.0 + (self.social_max - 1.0) * diversity # Increase social influence as diversity decreases\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Self-Adaptive Acceleration Coefficients\n                cognitive_i = cognitive_coeff * np.random.uniform(0, 1.5)  # Individual adaptation\n                social_i = social_coeff * np.random.uniform(0, 1.5)         # Social adaptation\n                \n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 cognitive_i * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_i * r2 * (global_best_position - population[i]))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Mutation operator: randomly perturb positions to avoid premature convergence\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.uniform(-0.1 * (ub - lb), 0.1 * (ub - lb), self.dim)\n                    new_position = np.clip(new_position + mutation, lb, ub) # Ensure boundaries are respected\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm SelfAdaptivePSO scored 0.440 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["88c081d6-f7f1-40da-be98-f5fb696c9a87"], "operator": null, "metadata": {"aucs": [0.1897426252292983, 0.2311657500138985, 0.4485023530757277, 0.8442179448245539, 0.2691478255151025, 0.43712768647926425, 0.3059478715852363, 0.3585991378010909, 0.3818087133090271, 0.38750996746386157, 0.6240583905234751, 0.9974836237493206, 0.32413944512350656, 0.28785514157152625, 0.6656741125593616, 0.5105474792329878, 0.33030137157389594, 0.45725636146851034, 0.2258590971550689, 0.5178641610388426]}}
{"id": "853f0c0b-af5a-49fd-910d-dd66c5823707", "fitness": 0.3950568537777922, "name": "HybridDEPSO", "description": "Combines DE and PSO with adaptive parameter control based on success rate and distance to the global best to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, w_max=0.9, w_min=0.4, c1=2, c2=2, adapt_prob=0.1, stagnation_limit=50, success_rate_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.Cr = Cr  # Crossover rate\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1 = c1\n        self.c2 = c2\n        self.adapt_prob = adapt_prob  # Probability to adapt mutation strategy\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.success_rate_memory = success_rate_memory\n        self.success_history_F = np.zeros(self.success_rate_memory)\n        self.success_history_Cr = np.zeros(self.success_rate_memory)\n        self.success_history_ptr = 0\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize velocities\n        velocities = np.zeros_like(population)\n\n        # Find best particle\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        self.best_fitness_history.append(fitness[best_index])\n\n        archive = []  # Archive for DE\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_max - (self.w_max - self.w_min) * (1 - self.budget / 10000)  # Linear decay\n\n            # Parameter adaptation based on success rate\n            mean_F = np.mean(self.success_history_F)\n            mean_Cr = np.mean(self.success_history_Cr)\n\n            for i in range(self.pop_size):\n                # Adaptive mutation strategy\n                if np.random.rand() < self.adapt_prob:\n                    # DE mutation with archive\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = population[idxs]\n                    if len(archive) > 0 and np.random.rand() < 0.5:\n                        x_r3 = archive[np.random.randint(len(archive))]\n                    else:\n                        x_r3 = population[np.random.randint(self.pop_size)]\n\n                    F = np.random.normal(mean_F, 0.1) if mean_F > 0 else self.F\n                    F = np.clip(F, 0.1, 1.0)\n                    v_trial = population[i] + F * (x_r1 - x_r2) # Using current particle as base\n\n                    # Crossover\n                    Cr = np.random.normal(mean_Cr, 0.1) if mean_Cr > 0 else self.Cr\n                    Cr = np.clip(Cr, 0.1, 1.0)\n                    j_rand = np.random.randint(self.dim)\n                    trial_vector = np.copy(population[i])\n                    for j in range(self.dim):\n                        if np.random.rand() < Cr or j == j_rand:\n                            trial_vector[j] = v_trial[j]\n                else:\n                    # PSO update\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n\n                    # Adaptive c1 and c2 based on distance to best\n                    distance_factor = np.linalg.norm(population[i] - best_position) / np.linalg.norm(ub - lb) # Normalized distance\n\n                    c1_adapted = self.c1 * (1 - distance_factor) # Closer -> more exploitation\n                    c2_adapted = self.c2 * distance_factor  # Farther -> more exploration\n\n                    velocities[i] = w * velocities[i] + \\\n                                  c1_adapted * r1 * (best_position - population[i]) + \\\n                                  c2_adapted * r2 * (best_position - population[i]) # Attract towards best\n                    trial_vector = population[i] + velocities[i]\n\n                # Boundary handling\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                # Evaluate trial vector\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n\n                # Selection: replace if better\n                if trial_fitness < fitness[i]:\n                    # Update success history\n                    self.success_history_F[self.success_history_ptr] = F if 'F' in locals() else 0.5 # Store last used F and Cr\n                    self.success_history_Cr[self.success_history_ptr] = Cr if 'Cr' in locals() else 0.9\n                    self.success_history_ptr = (self.success_history_ptr + 1) % self.success_rate_memory\n                    \n                    fitness[i] = trial_fitness\n                    archive.append(population[i].copy()) # Add old to archive\n                    if len(archive) > self.pop_size:\n                        archive.pop(0)\n\n                    population[i] = trial_vector.copy()\n\n                    # Update best particle\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_position = population[i].copy()\n\n            self.best_fitness_history.append(fitness[best_index])\n\n        return fitness[best_index], best_position", "configspace": "", "generation": 4, "feedback": "The algorithm HybridDEPSO scored 0.395 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e029f71e-5bf7-4432-9c73-6c5ccbb447b2"], "operator": null, "metadata": {"aucs": [0.15570982683789536, 0.2253199065315925, 0.32501182193506817, 0.5409029960274363, 0.28070926871560764, 0.4836324621590695, 0.2797771616919579, 0.27292198624674036, 0.42883392358971273, 0.21085345937368938, 0.48677961506730116, 0.9987521330206229, 0.2866337106809135, 0.3054037692202315, 0.6865831213537676, 0.4687512977828483, 0.26557952443919175, 0.5533035854656649, 0.16234317002942467, 0.48333433538710857]}}
{"id": "156435c4-72d5-4917-ab56-02a1c171a733", "fitness": 0.4051874068202393, "name": "HybridDEPSO", "description": "Improved Hybrid DE/PSO with adaptive velocity clamping, dynamic parameter adjustment based on fitness landscape features, and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, w_max=0.9, w_min=0.4, c1=2, c2=2, adapt_prob=0.1, stagnation_limit=50, clamp_coeff=0.5, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.Cr = Cr  # Crossover rate\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1 = c1\n        self.c2 = c2\n        self.adapt_prob = adapt_prob # Probability to adapt mutation strategy\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.clamp_coeff = clamp_coeff  # Coefficient for velocity clamping\n        self.restart_prob = restart_prob # Probability of restarting population\n        self.lb = -5.0 # setting the bounds here prevents calling func.bounds\n        self.ub = 5.0\n\n    def __call__(self, func):\n        #lb = func.bounds.lb # avoid calling func\n        #ub = func.bounds.ub\n        lb = self.lb\n        ub = self.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize velocities\n        velocities = np.zeros_like(population)\n\n        # Find best particle\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        self.best_fitness_history.append(fitness[best_index])\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_max - (self.w_max - self.w_min) * (1 - self.budget / 10000) # Linear decay\n\n            # Stagnation detection and parameter adaptation\n            if len(self.best_fitness_history) > self.stagnation_limit:\n                if np.std(self.best_fitness_history[-self.stagnation_limit:]) < 1e-8:  #Stagnation threshold\n                    self.stagnation_counter += 1\n                    # Increase exploration if stagnating\n                    self.F = min(self.F * 1.1, 0.9)\n                    self.Cr = min(self.Cr * 1.1, 0.99)\n                    # Increase PSO exploration as well\n                    self.c1 = min(self.c1 * 1.1, 3)\n                    # Restart population if stagnation persists\n                    if self.stagnation_counter > self.stagnation_limit * 2 and np.random.rand() < self.restart_prob:\n                        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                        fitness = np.array([func(x) for x in population])\n                        self.budget -= self.pop_size\n                        velocities = np.zeros_like(population)\n                        best_index = np.argmin(fitness)\n                        best_position = population[best_index].copy()\n                        self.best_fitness_history.append(fitness[best_index])\n                        self.stagnation_counter = 0\n                        \n                else:\n                    self.stagnation_counter = 0\n                    # Reset parameters if improving\n                    self.F = 0.5\n                    self.Cr = 0.9\n                    self.c1 = 2\n            \n\n            for i in range(self.pop_size):\n                # Adaptive mutation strategy\n                if np.random.rand() < self.adapt_prob:\n                    # DE mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n                    v_trial = x_r1 + self.F * (x_r2 - x_r3)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    trial_vector = np.copy(population[i])\n                    for j in range(self.dim):\n                        if np.random.rand() < self.Cr or j == j_rand:\n                            trial_vector[j] = v_trial[j]\n                else:\n                    # PSO update\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    velocities[i] = w * velocities[i] + \\\n                                  self.c1 * r1 * (best_position - population[i]) + \\\n                                  self.c2 * r2 * (population[i] - population[i]) # Corrected PSO part\n\n                    # Velocity clamping\n                    v_max = self.clamp_coeff * (ub - lb)\n                    velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                    \n                    trial_vector = population[i] + velocities[i]\n\n                # Boundary handling\n                trial_vector = np.clip(trial_vector, lb, ub)\n                \n                # Evaluate trial vector\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n\n                # Selection: replace if better\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial_vector.copy()\n\n                    # Update best particle\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_position = population[i].copy()\n                        \n            self.best_fitness_history.append(fitness[best_index])        \n\n        return fitness[best_index], best_position", "configspace": "", "generation": 4, "feedback": "The algorithm HybridDEPSO scored 0.405 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e029f71e-5bf7-4432-9c73-6c5ccbb447b2"], "operator": null, "metadata": {"aucs": [0.17235608416007286, 0.26652233748557497, 0.44180948677138554, 0.3155551641127725, 0.43895659440876855, 0.4510097373160248, 0.28960014257449596, 0.3507315095850585, 0.4721090591805597, 0.3018138776714856, 0.23347512939743664, 0.9996548220890317, 0.23181354434878676, 0.28511510192577494, 0.5963280081687257, 0.550000251135808, 0.4139895603968201, 0.6352392122902961, 0.1760075611109838, 0.48166095227492356]}}
{"id": "ff3d98e6-9001-4a6d-a4a9-57dbe2504f32", "fitness": 0.36246396683227766, "name": "HybridDEPSOCauchy", "description": "Combines DE and PSO with a Cauchy mutation operator in DE and a self-adaptive learning strategy for PSO parameters, enhancing exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSOCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, w_init=0.9, c1_init=2.0, c2_init=2.0, adapt_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.Cr = Cr  # Crossover rate\n        self.w = w_init  # Inertia weight\n        self.c1 = c1_init\n        self.c2 = c2_init\n        self.adapt_rate = adapt_rate\n        self.success_history = []\n        self.w_current = w_init\n        self.c1_current = c1_init\n        self.c2_current = c2_init\n        self.w_history = [w_init]\n        self.c1_history = [c1_init]\n        self.c2_history = [c2_init]\n\n    def cauchy_mutation(self, x, scale=0.1):\n        \"\"\"Applies Cauchy mutation to a vector x.\"\"\"\n        mutation = scale * np.random.standard_cauchy(size=x.shape)\n        return x + mutation\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize velocities\n        velocities = np.zeros_like(population)\n\n        # Find best particle\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        best_fitness = fitness[best_index]\n\n        while self.budget > 0:\n            successful_moves = 0\n            for i in range(self.pop_size):\n                # With a probability adapt_rate, perform DE, otherwise PSO\n                if np.random.rand() < self.adapt_rate:\n                    # Differential Evolution with Cauchy Mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n                    \n                    # Mutation and Crossover\n                    v_trial = x_r1 + self.F * (x_r2 - x_r3)\n                    v_trial = self.cauchy_mutation(v_trial)  # Apply Cauchy mutation\n                    j_rand = np.random.randint(self.dim)\n                    trial_vector = np.copy(population[i])\n                    for j in range(self.dim):\n                        if np.random.rand() < self.Cr or j == j_rand:\n                            trial_vector[j] = v_trial[j]\n                else:\n                    # Particle Swarm Optimization with self-adaptive parameters\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    \n                    # Self-adaptive learning for PSO parameters\n                    self.w_current = self.w + 0.1 * np.random.randn()\n                    self.c1_current = self.c1 + 0.2 * np.random.randn()\n                    self.c2_current = self.c2 + 0.2 * np.random.randn()\n\n                    self.w_current = np.clip(self.w_current, 0.1, 0.99)\n                    self.c1_current = np.clip(self.c1_current, 0.1, 3.0)\n                    self.c2_current = np.clip(self.c2_current, 0.1, 3.0)\n                    \n                    velocities[i] = self.w_current * velocities[i] + \\\n                                  self.c1_current * r1 * (best_position - population[i]) + \\\n                                  self.c2_current * r2 * (population[best_index] - population[i])\n                    \n                    # Velocity clamping - simplified\n                    v_max = 0.1 * (ub - lb)  # Clamp velocity to 10% of the range\n                    velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                    \n                    trial_vector = population[i] + velocities[i]\n\n                # Boundary handling\n                trial_vector = np.clip(trial_vector, lb, ub)\n                \n                # Evaluate trial vector\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n\n                # Selection: replace if better\n                if trial_fitness < fitness[i]:\n                    successful_moves +=1\n                    fitness[i] = trial_fitness\n                    population[i] = trial_vector.copy()\n\n                    # Update best particle\n                    if trial_fitness < best_fitness:\n                        best_index = i\n                        best_position = population[i].copy()\n                        best_fitness = trial_fitness\n            \n            # Adaptive parameter control based on recent success (DE parameters)\n            self.success_history.append(successful_moves / self.pop_size)\n            if len(self.success_history) > 10:\n                self.success_history.pop(0)\n            \n            avg_success = np.mean(self.success_history)\n\n            if avg_success > 0.4:  # More exploration needed\n                self.Cr *= 0.95\n                self.F *= 1.05\n            elif avg_success < 0.1: # More exploitation needed\n                self.Cr *= 1.05\n                self.F *= 0.95\n            \n            self.Cr = np.clip(self.Cr, 0.1, 0.99)\n            self.F = np.clip(self.F, 0.1, 2.0)\n            \n            self.w_history.append(self.w_current)\n            self.c1_history.append(self.c1_current)\n            self.c2_history.append(self.c2_current)\n\n        return best_fitness, best_position", "configspace": "", "generation": 4, "feedback": "The algorithm HybridDEPSOCauchy scored 0.362 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2c0d47bc-71a2-42e1-99ee-b5f39ed60090"], "operator": null, "metadata": {"aucs": [0.1184193064377298, 0.1821753690810446, 0.36435521381609337, 0.4222983917640113, 0.28757264759799295, 0.3546927873533675, 0.2822605060278498, 0.31448998702692377, 0.2943762538782636, 0.16666195231275027, 0.39197363927773476, 0.9897570430481388, 0.25060682222739583, 0.2960453640318247, 0.7272252581094214, 0.3741321611757811, 0.31012642757553444, 0.43173711616291877, 0.1851370325036974, 0.505236057237078]}}
{"id": "bca3ea9e-8e3d-4975-8e7d-d6f3b8456e02", "fitness": -Infinity, "name": "AdaptiveNeighborhoodPSO", "description": "Adaptive PSO with dynamic parameter adjustment based on swarm stagnation and fitness landscape analysis using a neighborhood-based approach for exploitation.", "code": "import numpy as np\n\nclass AdaptiveNeighborhoodPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_max=2.5, social_max=2.5, neighborhood_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        stagnation_counter = 0\n        previous_global_fitness = global_best_fitness\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Calculate swarm diversity (average distance to the global best)\n            diversity = np.mean(np.linalg.norm(population - global_best_position, axis=1)) / (ub - lb)\n\n            # Adaptive inertia weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * diversity\n            inertia = np.clip(inertia, self.inertia_min, self.inertia_max)\n            \n            # Adaptive cognitive and social coefficients\n            cognitive_coeff = self.cognitive_max - (self.cognitive_max - 1.0) * diversity # Reduce cognitive influence as diversity decreases\n            social_coeff = 1.0 + (self.social_max - 1.0) * diversity # Increase social influence as diversity decreases\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Neighborhood selection (ring topology)\n                neighbors = np.arange(i - self.neighborhood_size // 2, i + self.neighborhood_size // 2 + 1) % self.pop_size\n                \n                # Find the best neighbor\n                best_neighbor_index = neighbors[np.argmin(fitness[neighbors])]\n                \n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeff * r2 * (population[best_neighbor_index] - population[i]))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness\n            \n            # Stagnation detection\n            if abs(global_best_fitness - previous_global_fitness) < 1e-6:\n                stagnation_counter += 1\n            else:\n                stagnation_counter = 0\n            \n            # Adjust parameters if stagnated\n            if stagnation_counter > 20:\n                # Increase exploration by increasing inertia and cognitive coefficient\n                inertia = min(self.inertia_max, inertia + 0.1)\n                cognitive_coeff = min(self.cognitive_max, cognitive_coeff + 0.1)\n                \n                # Reset stagnation counter\n                stagnation_counter = 0\n                \n                # Perturb particles to escape local optima\n                for i in range(self.pop_size):\n                    population[i] = np.random.uniform(lb, ub, size=self.dim)\n                    velocities[i] = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=self.dim)\n                    new_fitness = func(population[i])\n                    self.budget -= 1\n                    fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitnesses[i]:\n                        personal_best_fitnesses[i] = new_fitness\n                        personal_best_positions[i] = population[i].copy()\n\n                        if new_fitness < global_best_fitness:\n                            global_best_fitness = new_fitness\n                            global_best_position = population[i].copy()\n                \n            previous_global_fitness = global_best_fitness\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 4, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["88c081d6-f7f1-40da-be98-f5fb696c9a87"], "operator": null, "metadata": {}}
{"id": "17f94d89-45ae-4e94-8c64-6af060be46dc", "fitness": 0.37570619619812595, "name": "HybridDEPSO", "description": "Improved Hybrid DE/PSO with adaptive parameter control based on success rate and enhanced stagnation handling with random restarts and a more robust PSO update.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, w_max=0.9, w_min=0.4, c1=2, c2=2, adapt_prob=0.1, stagnation_limit=50, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.Cr = Cr  # Crossover rate\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1 = c1\n        self.c2 = c2\n        self.adapt_prob = adapt_prob # Probability to adapt mutation strategy\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.restart_prob = restart_prob  # Probability of restarting the population\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize velocities\n        velocities = np.zeros_like(population)\n\n        # Find best particle\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        self.best_fitness_history.append(fitness[best_index])\n        success_rate = 0.5\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_max - (self.w_max - self.w_min) * (1 - self.budget / 10000) # Linear decay\n\n            # Stagnation detection and parameter adaptation\n            if len(self.best_fitness_history) > self.stagnation_limit:\n                if np.std(self.best_fitness_history[-self.stagnation_limit:]) < 1e-8:  #Stagnation threshold\n                    self.stagnation_counter += 1\n                    # Increase exploration if stagnating\n                    self.F = min(self.F * 1.1, 0.9)\n                    self.Cr = min(self.Cr * 1.1, 0.99)\n                    # Increase PSO exploration as well\n                    self.c1 = min(self.c1 * 1.1, 3)\n\n                    # Restart the population with a small probability if stagnation persists\n                    if np.random.rand() < self.restart_prob:\n                        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                        fitness = np.array([func(x) for x in population])\n                        self.budget -= self.pop_size\n                        velocities = np.zeros_like(population)  # Reset velocities too\n                        best_index = np.argmin(fitness)\n                        best_position = population[best_index].copy()\n                        self.best_fitness_history.append(fitness[best_index])\n                        self.stagnation_counter = 0 # Reset counter after restart\n\n\n                else:\n                    self.stagnation_counter = 0\n                    # Reset parameters if improving\n                    self.F = 0.5\n                    self.Cr = 0.9\n                    self.c1 = 2\n            \n\n            successful_mutations = 0\n            for i in range(self.pop_size):\n                # Adaptive mutation strategy\n                if np.random.rand() < self.adapt_prob:\n                    # DE mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n                    v_trial = x_r1 + self.F * (x_r2 - x_r3)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    trial_vector = np.copy(population[i])\n                    for j in range(self.dim):\n                        if np.random.rand() < self.Cr or j == j_rand:\n                            trial_vector[j] = v_trial[j]\n                else:\n                    # PSO update\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    velocities[i] = w * velocities[i] + \\\n                                  self.c1 * r1 * (best_position - population[i]) + \\\n                                  self.c2 * r2 * (population[i] - population[i])\n                    trial_vector = population[i] + velocities[i]\n\n                # Boundary handling\n                trial_vector = np.clip(trial_vector, lb, ub)\n                \n                # Evaluate trial vector\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n\n                # Selection: replace if better\n                if trial_fitness < fitness[i]:\n                    successful_mutations += 1\n                    fitness[i] = trial_fitness\n                    population[i] = trial_vector.copy()\n\n                    # Update best particle\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_position = population[i].copy()\n                        \n            self.best_fitness_history.append(fitness[best_index])\n\n            #Adjust F and Cr based on success rate\n            if successful_mutations > 0:\n                success_rate = 0.9 * success_rate + 0.1 * (successful_mutations / self.pop_size)\n            else:\n                success_rate = 0.9 * success_rate\n\n            if success_rate > 0.6:\n                self.F = max(self.F * 0.9, 0.1)\n                self.Cr = max(self.Cr * 0.9, 0.1)\n            elif success_rate < 0.2:\n                self.F = min(self.F * 1.1, 0.9)\n                self.Cr = min(self.Cr * 1.1, 0.9)\n                \n\n        return fitness[best_index], best_position", "configspace": "", "generation": 4, "feedback": "The algorithm HybridDEPSO scored 0.376 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e029f71e-5bf7-4432-9c73-6c5ccbb447b2"], "operator": null, "metadata": {"aucs": [0.15206147425071104, 0.24258688044029408, 0.45430401190687986, 0.3011843344469368, 0.22131101353012828, 0.5444458113580215, 0.2814506835205327, 0.36048291311554026, 0.2553559708301143, 0.19669390517287877, 0.369059809460655, 0.9967858785258635, 0.25071940396083525, 0.266358468092759, 0.7108027376212911, 0.3509371232352899, 0.29451330592084357, 0.6104760956796613, 0.1825733775080043, 0.47202072538527895]}}
{"id": "7e7d15a3-6a00-43f8-bfb5-6ebb4e608bfb", "fitness": -Infinity, "name": "RankCauchyPSO", "description": "Implements a PSO with a Cauchy mutation operator applied probabilistically based on particle fitness rank, promoting diversity and escaping local optima.", "code": "import numpy as np\nfrom scipy.stats import cauchy\n\nclass RankCauchyPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive=2.0, social=2.0, mutation_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive = cognitive\n        self.social = social\n        self.mutation_prob = mutation_prob\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Inertia weight (linearly decreasing)\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (1 - self.budget / 10000) #linear decay\n\n            # Get fitness ranks\n            fitness_ranks = np.argsort(np.argsort(fitness)) # Higher rank => worse fitness\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 self.cognitive * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social * r2 * (global_best_position - population[i]))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Cauchy mutation based on fitness rank\n                if np.random.rand() < self.mutation_prob * (fitness_ranks[i] / self.pop_size): #mutation probability scaled by the rank\n                    mutation = cauchy.rvs(loc=0, scale=0.1, size=self.dim) * (ub - lb)\n                    new_position = np.clip(new_position + mutation, lb, ub)\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 5, "feedback": "An exception occurred: name 'cauchy' is not defined.", "error": "", "parent_ids": ["54a7aa1e-907d-4a1a-afea-216c83bc12a0"], "operator": null, "metadata": {}}
{"id": "137c3bac-f2be-482f-8e2e-e092132cb967", "fitness": -Infinity, "name": "SimplifiedSelfAdaptivePSO", "description": "Simplified self-adaptive PSO with dynamic inertia and focused exploration around the global best.", "code": "import numpy as np\n\nclass SimplifiedSelfAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_coeff=2.0, social_coeff=2.0, exploration_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Adaptive inertia weight based on global best fitness\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (1 - (global_best_fitness - func.bounds.f_min) / (func.bounds.f_max - func.bounds.f_min))\n            inertia = np.clip(inertia, self.inertia_min, self.inertia_max)\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * r2 * (global_best_position - population[i]))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n\n                # Exploration around global best\n                if np.random.rand() < self.exploration_rate:\n                    new_position = global_best_position + np.random.uniform(-0.1 * (ub - lb), 0.1 * (ub - lb), self.dim)\n\n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 5, "feedback": "An exception occurred: 'ioh.iohcpp.RealBounds' object has no attribute 'f_min'.", "error": "", "parent_ids": ["54a7aa1e-907d-4a1a-afea-216c83bc12a0"], "operator": null, "metadata": {}}
{"id": "755fbc2e-2b82-4101-9921-38dc061c70e6", "fitness": 0.0985111868994572, "name": "CauchyMutatedPSO", "description": "Implements a PSO variant with a Cauchy mutation operator applied to the global best position, enhancing exploration around promising regions.", "code": "import numpy as np\n\nclass CauchyMutatedPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, mutation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.mutation_rate = mutation_rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * r2 * (global_best_position - population[i]))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n            \n            #Mutate global best with cauchy distribution\n            if np.random.rand() < self.mutation_rate:\n                cauchy_mutation = np.random.standard_cauchy(size=self.dim)\n                mutated_global_best = global_best_position + 0.1 * cauchy_mutation #Scale the mutation\n                mutated_global_best = np.clip(mutated_global_best, lb, ub)\n\n                mutated_fitness = func(mutated_global_best)\n                self.budget -= 1\n\n                if mutated_fitness < global_best_fitness:\n                    global_best_fitness = mutated_fitness\n                    global_best_position = mutated_global_best.copy()\n                    \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm CauchyMutatedPSO scored 0.099 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7d005f9f-a374-4aa7-8f4d-dd53d458c690"], "operator": null, "metadata": {"aucs": [0.1970223737989144, 0]}}
{"id": "42f3f102-0549-4d48-a835-5c9216c31921", "fitness": 0.56497106160546, "name": "SimplifiedAdaptivePSO", "description": "Simplified PSO with adaptive coefficients based on a single normalized difference to balance exploration and exploitation, and simplified coefficient updates.", "code": "import numpy as np\n\nclass SimplifiedAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_max=2.0, social_max=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Calculate average fitness difference\n            avg_fitness_diff = np.mean(np.abs(personal_best_fitnesses - global_best_fitness))\n\n            # Normalize the average fitness difference\n            if avg_fitness_diff > 0:\n                normalized_diff = min(1.0, avg_fitness_diff / np.abs(global_best_fitness)) # Ensure the ratio is within [0, 1]\n            else:\n                normalized_diff = 0.0\n            \n            # Adaptive coefficients\n            cognitive_coeff = 1.0 + (self.cognitive_max - 1.0) * (1 - normalized_diff)\n            social_coeff = 1.0 + (self.social_max - 1.0) * normalized_diff\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * normalized_diff\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeff * r2 * (global_best_position - population[i]))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm SimplifiedAdaptivePSO scored 0.565 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7d005f9f-a374-4aa7-8f4d-dd53d458c690"], "operator": null, "metadata": {"aucs": [0.1398502848192742, 0.17534195523876228, 0.9510624950603427, 0.8641045506688753, 0.2807472067503364, 0.9402349918432887, 0.627044132498935, 0.5757361462676778, 0.2835509463946976, 0.8923773221061286, 0.2251933354449247, 0.9968769859859727, 0.23921418512652504, 0.2915220388034442, 0.744689082181756, 0.9320139498395716, 0.4184126099428601, 0.9712073206886314, 0.2775512235169233, 0.4726904689302731]}}
{"id": "f1fd5314-ef25-4799-8f0a-847ec192407d", "fitness": 0.5616326783850918, "name": "SimplifiedAdaptivePSO", "description": "Simplified PSO with adaptive inertia and acceleration coefficients based on normalized particle fitness rank, focusing on code brevity and efficiency.", "code": "import numpy as np\n\nclass SimplifiedAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_max=2.0, social_max=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        while self.budget > 0:\n            ranked_indices = np.argsort(fitness)\n            normalized_rank = (np.arange(self.pop_size) / (self.pop_size - 1)) if self.pop_size > 1 else np.zeros(self.pop_size)\n            \n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * normalized_rank\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * (1 - normalized_rank)\n            social_coeffs = 1.0 + (self.social_max - 1.0) * normalized_rank\n            \n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia[i] * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n                \n                new_position = np.clip(population[i] + velocities[i], lb, ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm SimplifiedAdaptivePSO scored 0.562 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7d005f9f-a374-4aa7-8f4d-dd53d458c690"], "operator": null, "metadata": {"aucs": [0.16562217924198663, 0.28039445014073106, 0.8962566259642344, 0.6035071727348698, 0.2544686368257294, 0.9315107102191029, 0.3362696237978329, 0.6604893646514041, 0.9238737055392594, 0.306008669476023, 0.8949238522955815, 0.9992021626802333, 0.2725053941525716, 0.7309111644218418, 0.7311151752654668, 0.8047865880273395, 0.3310115465956933, 0.38246243723299767, 0.2304896282703759, 0.4968444801685582]}}
{"id": "5ecc284d-dd96-4fe4-be68-d97bc92892b9", "fitness": 0.4741530027543545, "name": "SimplifiedAdaptivePSO", "description": "Simplified PSO with adaptive cognitive and social coefficients based on distance to global best, favoring exploration far from the global best and exploitation nearby.", "code": "import numpy as np\n\nclass SimplifiedAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal bests\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Calculate distance to global best\n            distances = np.linalg.norm(population - global_best_position, axis=1)\n            \n            # Normalize distances\n            if np.max(distances) > 0:\n                normalized_distances = distances / np.max(distances)\n            else:\n                normalized_distances = np.zeros(self.pop_size)\n\n            # Adaptive coefficients (exploration far, exploitation near)\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * normalized_distances\n            social_coeffs = 1.0 + (self.social_max - 1.0) * (1 - normalized_distances)\n            inertia = 0.5 + 0.4 * (1 - normalized_distances) # Inertia between 0.5 and 0.9\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (inertia[i] * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n                \n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm SimplifiedAdaptivePSO scored 0.474 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7d005f9f-a374-4aa7-8f4d-dd53d458c690"], "operator": null, "metadata": {"aucs": [0.21055640863179115, 0.22352985250001012, 0.724518257041781, 0.20561397982796104, 0.30375238492078793, 0.8016122125312047, 0.46437036212650706, 0.7086283716611721, 0.7838374107091768, 0.20296321622627056, 0.2393292168714788, 0.9972784959777509, 0.27455070968109263, 0.2840495521054943, 0.7313357394528199, 0.797850001227862, 0.40451505464264215, 0.3818717849351745, 0.20429297380406897, 0.5386040702120435]}}
{"id": "5b305ae8-f409-45fe-a7e1-7af1d87671ef", "fitness": 0.44966481541102465, "name": "CauchyMutationPSO", "description": "A PSO variant that dynamically adjusts its exploration-exploitation balance using a combination of Cauchy mutation and velocity clamping based on population diversity.", "code": "import numpy as np\n\nclass CauchyMutationPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive=2.0, social=2.0, clamp_factor=0.5, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive = cognitive\n        self.social = social\n        self.clamp_factor = clamp_factor\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Calculate population diversity (standard deviation)\n            diversity = np.std(population)\n            \n            # Adjust inertia weight based on diversity\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (diversity / (ub - lb))\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (inertia * velocities[i] +\n                                 self.cognitive * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social * r2 * (global_best_position - population[i]))\n                \n                # Velocity clamping based on clamp_factor\n                v_max = self.clamp_factor * (ub - lb)\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Apply Cauchy mutation if diversity is low\n                if diversity < self.diversity_threshold:\n                    mutation = np.random.standard_cauchy(size=self.dim) * (ub - lb) * 0.01 # Scale Cauchy distribution\n                    new_position += mutation\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm CauchyMutationPSO scored 0.450 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7b0697b0-4a3f-4267-8f71-7a1113d596d7"], "operator": null, "metadata": {"aucs": [0.18888593910829388, 0.3865502121463946, 0.422218201519554, 0.8960645296306733, 0.3015032318515629, 0.7058415379165319, 0.3249428834640894, 0.3839687326953457, 0.21796432199228255, 0.23533087352748572, 0.8618264852863529, 0.9988446031462347, 0.2998940597121491, 0.2864885119972198, 0.6509322178808448, 0.3866028613158743, 0.46471692013082466, 0.29071343346775047, 0.1740465249345987, 0.5159602264964278]}}
{"id": "d4e08cfc-17a6-44af-978f-d84f70700e83", "fitness": 0.3867860661064792, "name": "HybridDEPSO", "description": "Enhanced Hybrid DE/PSO with adaptive parameter control using sigmoid functions and a simplified velocity update rule to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, w_max=0.9, w_min=0.4, c1=2, c2=2, adapt_prob=0.1, stagnation_limit=50, clamp_coeff=0.5, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.Cr = Cr  # Crossover rate\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1 = c1\n        self.c2 = c2\n        self.adapt_prob = adapt_prob # Probability to adapt mutation strategy\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.clamp_coeff = clamp_coeff  # Coefficient for velocity clamping\n        self.restart_prob = restart_prob # Probability of restarting population\n        self.lb = -5.0 # setting the bounds here prevents calling func.bounds\n        self.ub = 5.0\n\n    def sigmoid(self, x):\n        return 1 / (1 + np.exp(-x))\n\n    def __call__(self, func):\n        lb = self.lb\n        ub = self.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize velocities\n        velocities = np.zeros_like(population)\n\n        # Find best particle\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        self.best_fitness_history.append(fitness[best_index])\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_max - (self.w_max - self.w_min) * (1 - self.budget / 10000) # Linear decay\n\n            # Stagnation detection and parameter adaptation\n            if len(self.best_fitness_history) > self.stagnation_limit:\n                if np.std(self.best_fitness_history[-self.stagnation_limit:]) < 1e-8:  #Stagnation threshold\n                    self.stagnation_counter += 1\n                    # Increase exploration if stagnating\n                    self.F = min(self.F * 1.1, 0.9)\n                    self.Cr = min(self.Cr * 1.1, 0.99)\n                    # Increase PSO exploration as well\n                    self.c1 = min(self.c1 * 1.1, 3)\n                    # Restart population if stagnation persists\n                    if self.stagnation_counter > self.stagnation_limit * 2 and np.random.rand() < self.restart_prob:\n                        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                        fitness = np.array([func(x) for x in population])\n                        self.budget -= self.pop_size\n                        velocities = np.zeros_like(population)\n                        best_index = np.argmin(fitness)\n                        best_position = population[best_index].copy()\n                        self.best_fitness_history.append(fitness[best_index])\n                        self.stagnation_counter = 0\n                        \n                else:\n                    self.stagnation_counter = 0\n                    # Reset parameters if improving\n                    self.F = 0.5\n                    self.Cr = 0.9\n                    self.c1 = 2\n            \n\n            for i in range(self.pop_size):\n                # Adaptive mutation strategy\n                if np.random.rand() < self.adapt_prob:\n                    # DE mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n                    v_trial = x_r1 + self.F * (x_r2 - x_r3)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    trial_vector = np.copy(population[i])\n                    for j in range(self.dim):\n                        if np.random.rand() < self.Cr or j == j_rand:\n                            trial_vector[j] = v_trial[j]\n                else:\n                    # PSO update\n                    r1 = np.random.rand(self.dim)\n                    # Simplified velocity update, removing the cognitive component\n                    velocities[i] = w * velocities[i] + self.c1 * r1 * (best_position - population[i])\n\n                    # Velocity clamping\n                    v_max = self.clamp_coeff * (ub - lb)\n                    velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                    \n                    trial_vector = population[i] + velocities[i]\n\n                # Boundary handling\n                trial_vector = np.clip(trial_vector, lb, ub)\n                \n                # Evaluate trial vector\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n\n                # Selection: replace if better\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial_vector.copy()\n\n                    # Update best particle\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_position = population[i].copy()\n                        \n                        # Adaptive parameter adjustments based on improvement\n                        improvement_ratio = (self.best_fitness_history[-1] - trial_fitness) / self.best_fitness_history[-1] if self.best_fitness_history else 0\n                        \n                        # Sigmoid function to smoothly adjust parameters\n                        sigmoid_output = self.sigmoid(improvement_ratio * 10)  # Scale improvement for better sigmoid response\n\n                        # Adapt F and Cr\n                        self.F = 0.5 + 0.3 * sigmoid_output  # F between 0.5 and 0.8\n                        self.Cr = 0.7 + 0.29 * sigmoid_output # Cr between 0.7 and 0.99\n                        # Adapt c1\n                        self.c1 = 1.5 + 1.49 * sigmoid_output # c1 between 1.5 and 2.99\n\n            self.best_fitness_history.append(fitness[best_index])        \n\n        return fitness[best_index], best_position", "configspace": "", "generation": 5, "feedback": "The algorithm HybridDEPSO scored 0.387 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["156435c4-72d5-4917-ab56-02a1c171a733"], "operator": null, "metadata": {"aucs": [0.1636897781334148, 0.24500908729982007, 0.36923274397730443, 0.6188845207594691, 0.24695669485584038, 0.27646144209645807, 0.2965296739905129, 0.34086647554497695, 0.38401854779125977, 0.1788793762989711, 0.2330588146497946, 0.9983273198321231, 0.28313929606580046, 0.34722978047788866, 0.6482859676764307, 0.5400035680958156, 0.324640066473734, 0.5829801436110296, 0.1685673514184728, 0.48896067308046853]}}
{"id": "e6940e1c-fe66-4f08-9e67-82d43b660fad", "fitness": 0.27396149454421553, "name": "HybridDEPSO", "description": "Simplified Hybrid DE/PSO with reduced parameter adaptation and stagnation handling for improved efficiency.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_limit=50, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.restart_prob = restart_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        lb = self.lb\n        ub = self.ub\n\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        velocities = np.zeros_like(population)\n\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        self.best_fitness_history.append(fitness[best_index])\n\n        while self.budget > 0:\n            # Stagnation detection and restart\n            if len(self.best_fitness_history) > self.stagnation_limit:\n                if np.std(self.best_fitness_history[-self.stagnation_limit:]) < 1e-8 and np.random.rand() < self.restart_prob:\n                    population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    self.budget -= self.pop_size\n                    velocities = np.zeros_like(population)\n                    best_index = np.argmin(fitness)\n                    best_position = population[best_index].copy()\n                    self.best_fitness_history.append(fitness[best_index])\n\n            for i in range(self.pop_size):\n                # DE mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                v_trial = x_r1 + self.F * (x_r2 - x_r3)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        trial_vector[j] = v_trial[j]\n\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                              self.c1 * r1 * (best_position - population[i]) + \\\n                              self.c2 * r2 * (population[best_index] - population[i])\n\n                trial_vector = trial_vector + velocities[i]\n\n                # Boundary handling\n                trial_vector = np.clip(trial_vector, lb, ub)\n                \n                # Evaluate trial vector\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n\n                # Selection: replace if better\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial_vector.copy()\n\n                    # Update best particle\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_position = population[i].copy()\n                        \n            self.best_fitness_history.append(fitness[best_index])\n\n        return fitness[best_index], best_position", "configspace": "", "generation": 5, "feedback": "The algorithm HybridDEPSO scored 0.274 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["156435c4-72d5-4917-ab56-02a1c171a733"], "operator": null, "metadata": {"aucs": [0.11596309992403764, 0.1336544421288276, 0.2500181623699418, 0.19245678362269203, 0.21047457311556084, 0.23437687426652742, 0.2132276359313129, 0.19992148733345372, 0.18494133473671648, 0.14640643409022158, 0.19769534812325906, 0.9974980409387926, 0.25279585086618084, 0.25031568679952754, 0.5739917043613194, 0.2814107176556998, 0.19240736331561115, 0.24833833681297224, 0.15013210772669938, 0.45320390676495514]}}
{"id": "e2dc7670-4b7a-4fef-827a-87448f7750b2", "fitness": 0.299162562044145, "name": "DE_CMAES", "description": "Blends Differential Evolution with a Covariance Matrix Adaptation Evolution Strategy, using CMA-ES to adapt the mutation distribution of DE.", "code": "import numpy as np\n\nclass DE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, sigma=0.1, cs=0.3, damps=1.0, adapt_interval=10, lb=-5.0, ub=5.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.Cr = Cr  # Crossover rate\n        self.sigma = sigma  # CMA-ES step size\n        self.cs = cs # CMA-ES step size adaptation rate\n        self.damps = damps # CMA-ES damping for step size\n        self.adapt_interval = adapt_interval # Number of iterations between CMA updates\n        self.lb = lb\n        self.ub = ub\n        self.C = np.eye(dim)  # Covariance matrix\n        self.pc = np.zeros(dim) # Evolution path for C\n        self.ps = np.zeros(dim) # Evolution path for sigma\n        self.mean = np.random.uniform(lb, ub, size=dim) # Mean of the CMA-ES distribution\n        self.eigen_decomposition_needed = True # Flag to update eigenvectors\n\n    def __call__(self, func):\n\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        best_index = np.argmin(fitness)\n        best_fitness = fitness[best_index]\n        best_position = population[best_index].copy()\n\n        iteration = 0\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # DE mutation with CMA-ES adaptation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                \n                # Sample mutation vector from CMA-ES distribution\n                if self.eigen_decomposition_needed:\n                    self.D, self.B = np.linalg.eig(self.C)  # Eigen decomposition\n                    self.D = np.sqrt(np.diag(self.D))\n                    self.eigen_decomposition_needed = False\n                \n                z = np.random.randn(self.dim)\n                mutation_vector = self.mean + self.sigma * (self.B @ self.D @ z) # CMA-ES Sampling\n                \n                v_trial = x_r1 + self.F * (x_r2 - x_r3) + 0.1 * (mutation_vector - population[i]) # Combining DE and CMA-ES\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        trial_vector[j] = v_trial[j]\n\n                # Boundary handling\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                # Evaluate trial vector\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial_vector.copy()\n                    \n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_position = trial_vector.copy()\n\n            # CMA-ES Adaptation\n            iteration += 1\n            if iteration % self.adapt_interval == 0:\n                # Selection and Recombination (simplified, using the best particle directly)\n                x_mean_old = self.mean.copy()\n                self.mean = best_position # Simplification\n                \n                # Cumulation for rank-one update of C\n                self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * (self.mean - x_mean_old) / self.sigma\n\n                # Update covariance matrix\n                self.pc = (1 - self.cs) * self.pc + np.sqrt(self.cs * (2 - self.cs)) * (self.mean - x_mean_old) / self.sigma\n                \n                delta_h_sigma = (np.linalg.norm(self.ps)**2 / self.dim) < (2 + 4 / (self.dim + 1))\n                self.C = (1 - self.cs) * self.C + self.cs * (2 - self.cs) * np.outer(self.pc, self.pc) + self.cs * (2 - self.cs) * np.eye(self.dim) # Includes identity matrix\n\n                self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps)/np.sqrt(self.dim) - 1))\n\n                self.eigen_decomposition_needed = True\n            \n        return best_fitness, best_position", "configspace": "", "generation": 5, "feedback": "The algorithm DE_CMAES scored 0.299 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["156435c4-72d5-4917-ab56-02a1c171a733"], "operator": null, "metadata": {"aucs": [0.11279282317956385, 0.19292425267073954, 0.2739609389195452, 0.21835596696518, 0.21060452624376513, 0.23454363622715146, 0.236243833231924, 0.1987220700673411, 0.2319559885423117, 0.1580341451718541, 0.42264692581474217, 0.9895436332766266, 0.25489835265943184, 0.26277371219017454, 0.5853486163055122, 0.2715948658900895, 0.22332372873384554, 0.2917095245822391, 0.14287681747115022, 0.4703968827397118]}}
{"id": "e96fe6e5-112c-44fd-9099-5e5771c9152d", "fitness": 0.0, "name": "EnhancedSelfAdaptivePSO", "description": "Simplified self-adaptive PSO with dynamic inertia and acceleration coefficients, enhanced by orthogonal learning to improve convergence speed and accuracy.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_max=2.0, social_max=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Orthogonal Learning Array (OLA) parameters (simplified for efficiency)\n        ola_size = 3  # Number of particles to consider in orthogonal learning\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Calculate swarm diversity\n            diversity = np.mean(np.linalg.norm(population - global_best_position, axis=1)) / (ub - lb)\n\n            # Adaptive inertia weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * diversity\n            inertia = np.clip(inertia, self.inertia_min, self.inertia_max)\n            \n            # Adaptive cognitive and social coefficients\n            cognitive_coeff = 1.0 + (self.cognitive_max - 1.0) * (1 - diversity)\n            social_coeff = 1.0 + (self.social_max - 1.0) * diversity\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeff * r2 * (global_best_position - population[i]))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n\n            # Orthogonal Learning (applied sparingly to conserve budget)\n            if self.budget > self.dim and np.random.rand() < 0.1: #Reduce OLA execution\n                # Select ola_size random particles\n                selected_indices = np.random.choice(self.pop_size, size=ola_size, replace=False)\n                selected_positions = population[selected_indices]\n\n                # Create an orthogonal array (simplified - only two levels)\n                oa = np.array([[1, 1], [1, 2], [2, 1], [2, 2]])\n\n                # Generate new candidate solutions based on orthogonal array\n                for j in range(len(oa)):\n                    candidate = np.copy(global_best_position)\n                    for k in range(ola_size):\n                        if oa[j, k % 2] == 2:  # Alternate between dimensions\n                            candidate += 0.1 * (selected_positions[k] - global_best_position) / ola_size # small perturbation\n                    candidate = np.clip(candidate, lb, ub)\n\n                    candidate_fitness = func(candidate)\n                    self.budget -= 1\n                    if candidate_fitness < global_best_fitness:\n                        global_best_fitness = candidate_fitness\n                        global_best_position = candidate.copy()\n                        \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedSelfAdaptivePSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["54a7aa1e-907d-4a1a-afea-216c83bc12a0"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "b78e37f1-d343-4ee0-9abf-673e9e04f959", "fitness": 0.5599543739392125, "name": "SimplifiedAdaptivePSO", "description": "Simplified PSO with adaptive cognitive and social coefficients based on normalized fitness rank to balance exploration and exploitation.", "code": "import numpy as np\n\nclass SimplifiedAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Sort fitnesses and get ranks\n            ranked_indices = np.argsort(fitness)\n            ranks = np.empty_like(ranked_indices)\n            ranks[ranked_indices] = np.arange(self.pop_size)\n\n            # Normalize ranks to [0, 1]\n            normalized_ranks = ranks / (self.pop_size - 1)\n            \n            # Adaptive coefficients based on normalized rank\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * (1 - normalized_ranks)\n            social_coeffs = 1.0 + (self.social_max - 1.0) * normalized_ranks\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (0.729 * velocities[i] +  # Constriction factor\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness # Update fitness array\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm SimplifiedAdaptivePSO scored 0.560 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7d005f9f-a374-4aa7-8f4d-dd53d458c690"], "operator": null, "metadata": {"aucs": [0.18290436337768168, 0.20582343710993878, 0.8398574668761403, 0.9044844146326474, 0.29013871455705953, 0.28458493538342977, 0.3078461309733026, 0.8220680103844251, 0.8687379449224093, 0.862636244987464, 0.6918606663516835, 0.997934659353533, 0.21153498502931878, 0.26881998211432045, 0.6517244861301926, 0.8828717459833882, 0.4147259015239013, 0.8410196311029794, 0.20960098892827306, 0.4599127690621627]}}
{"id": "f9474db6-da1f-45f4-a1e4-27021db1b770", "fitness": -Infinity, "name": "SimplifiedAdaptivePSO", "description": "Simplified PSO with adaptive coefficients based on a single normalized fitness rank and reduced parameter count, prioritizing efficiency.", "code": "import numpy as np\n\nclass SimplifiedAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        while self.budget > 0:\n            ranked_indices = np.argsort(fitness)\n            normalized_rank = (np.arange(self.pop_size) / (self.pop_size - 1)) if self.pop_size > 1 else np.zeros(self.pop_size)\n            \n            inertia = 0.5 + 0.4 * (1 - normalized_rank)  # Simplified inertia\n            cognitive_coeff = 1.5 + 0.5 * (1 - normalized_rank) #Simplified cognitive\n            social_coeff = 1.5 + 0.5 * normalized_rank #Simplified social\n            \n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia[i] * velocities[i] +\n                                 cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeff * r2 * (global_best_position - population[i]))\n                \n                new_position = np.clip(population[i] + velocities[i], lb, ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 6, "feedback": "An exception occurred: operands could not be broadcast together with shapes (20,) (2,) .", "error": "", "parent_ids": ["f1fd5314-ef25-4799-8f0a-847ec192407d"], "operator": null, "metadata": {}}
{"id": "f950c878-b233-4a79-99b2-c8d9c55dff9c", "fitness": -Infinity, "name": "AdaptivePSO", "description": "Adaptive PSO with simplified coefficient updates based on fitness rank and velocity clamping for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        while self.budget > 0:\n            ranked_indices = np.argsort(fitness)\n            normalized_rank = (np.arange(self.pop_size) / (self.pop_size - 1)) if self.pop_size > 1 else np.zeros(self.pop_size)\n            \n            inertia = 0.5 + 0.4 * (1 - normalized_rank)  # Simplified inertia\n            cognitive_coeff = 1.5 + 0.5 * (1 - normalized_rank) # Simplified cognitive coeff\n            social_coeff = 1.5 + 0.5 * normalized_rank  # Simplified social coeff\n            \n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia[i] * velocities[i] +\n                                 cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeff * r2 * (global_best_position - population[i]))\n\n                # Velocity clamping\n                v_max = (ub - lb) * 0.2\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                \n                new_position = np.clip(population[i] + velocities[i], lb, ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 6, "feedback": "An exception occurred: operands could not be broadcast together with shapes (20,) (2,) .", "error": "", "parent_ids": ["f1fd5314-ef25-4799-8f0a-847ec192407d"], "operator": null, "metadata": {}}
{"id": "be63aef8-d7f4-4629-9c70-b02fe646cb3b", "fitness": 0.364195992451664, "name": "AdaptivePSO", "description": "Adaptive PSO with dynamic population size reduction based on stagnation and enhanced velocity clamping for boundary handling.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=40, inertia_max=0.9, inertia_min=0.2, cognitive_max=2.0, social_max=2.0, stagnation_threshold=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.min_pop_size = 5  # Minimum population size to prevent excessive reduction\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        best_fitness_history = [global_best_fitness]\n\n\n        # Optimization loop\n        while self.budget > 0 and self.pop_size > self.min_pop_size:\n            # Calculate average fitness difference\n            avg_fitness_diff = np.mean(np.abs(personal_best_fitnesses - global_best_fitness))\n\n            # Normalize the average fitness difference\n            if avg_fitness_diff > 0:\n                normalized_diff = min(1.0, avg_fitness_diff / np.abs(global_best_fitness)) # Ensure the ratio is within [0, 1]\n            else:\n                normalized_diff = 0.0\n            \n            # Adaptive coefficients\n            cognitive_coeff = 1.0 + (self.cognitive_max - 1.0) * (1 - normalized_diff)\n            social_coeff = 1.0 + (self.social_max - 1.0) * normalized_diff\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * normalized_diff\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeff * r2 * (global_best_position - population[i]))\n                \n                # Velocity clamping\n                max_velocity = (ub - lb) * 0.2  # Increased clamping\n                velocities[i] = np.clip(velocities[i], -max_velocity, max_velocity)\n\n\n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n            \n                population[i] = new_position\n\n\n            # Stagnation check and population reduction\n            if global_best_fitness == best_fitness_history[-1]:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter >= self.stagnation_threshold:\n                # Reduce population size\n                self.pop_size = max(int(self.pop_size * 0.75), self.min_pop_size)\n                \n                # Reinitialize population (around the global best)\n                population = np.random.uniform(global_best_position - (ub-lb)*0.1, global_best_position + (ub-lb)*0.1, size=(self.pop_size, self.dim))\n                population = np.clip(population, lb, ub)  # Ensure bounds are respected\n                velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                personal_best_positions = population.copy()\n                personal_best_fitnesses = fitness.copy()\n\n                global_best_index = np.argmin(fitness)\n                if fitness[global_best_index] < global_best_fitness:\n                  global_best_fitness = fitness[global_best_index]\n                  global_best_position = population[global_best_index].copy()\n                \n                self.stagnation_counter = 0  # Reset stagnation counter\n\n            best_fitness_history.append(global_best_fitness)\n            if len(best_fitness_history) > self.stagnation_threshold:\n                best_fitness_history.pop(0)\n\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptivePSO scored 0.364 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["42f3f102-0549-4d48-a835-5c9216c31921"], "operator": null, "metadata": {"aucs": [0.18000935025266718, 0.3509615859501366, 0.9258130336038523, 0]}}
{"id": "8f72b806-4534-462c-9ea0-cdfef1412673", "fitness": 0.30399098733125407, "name": "SimplifiedAdaptivePSO", "description": "Simplified PSO with adaptive inertia and acceleration coefficients based on normalized distance to global best, emphasizing exploration far from the global best by scaling velocity updates.", "code": "import numpy as np\n\nclass SimplifiedAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal and global best\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Calculate normalized distance to global best\n            distances = np.linalg.norm(population - global_best_position, axis=1)\n            normalized_distances = distances / np.max(distances) if np.max(distances) > 0 else np.zeros(self.pop_size)\n\n            # Adaptive coefficients: favoring exploration far from global best\n            inertia = 0.5 + 0.4 * (1 - normalized_distances)\n            cognitive_coeff = 2.0 * normalized_distances  # Higher coeff for further particles\n            social_coeff = 2.0 * (1 - normalized_distances) # Higher coeff for closer particles\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                \n                # Scale velocity update by distance to global best\n                velocity_scale = 1 + normalized_distances[i]  \n                \n                velocities[i] = (inertia[i] * velocities[i] +\n                                 cognitive_coeff[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeff[i] * r2 * (global_best_position - population[i])) * velocity_scale\n                \n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm SimplifiedAdaptivePSO scored 0.304 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5ecc284d-dd96-4fe4-be68-d97bc92892b9"], "operator": null, "metadata": {"aucs": [0.1266746463793348, 0.18788919770882717, 0.27553330448060276, 0.22373231322046527, 0.24849232996910442, 0.237056654076915, 0.2747458202413734, 0.2667092414850689, 0.22251823919467384, 0.18487210288164602, 0.29081651512710704, 0.995283351982942, 0.27223636439965526, 0.266869388313699, 0.5476258545021093, 0.2967847574360363, 0.23134063934944815, 0.28072205666990846, 0.18049526645209246, 0.4694217027540718]}}
{"id": "baf16244-005f-43b5-89aa-863615b9838c", "fitness": 0.5575028790257215, "name": "ShrinkingAdaptivePSO", "description": "PSO with adaptive coefficients based on distance to the global best and a shrinking search space to enhance exploitation.", "code": "import numpy as np\n\nclass ShrinkingAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0, shrinking_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.shrinking_rate = shrinking_rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal bests\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        current_lb = lb\n        current_ub = ub\n\n        # Optimization loop\n        while self.budget > 0:\n            # Calculate distance to global best\n            distances = np.linalg.norm(population - global_best_position, axis=1)\n            \n            # Normalize distances\n            if np.max(distances) > 0:\n                normalized_distances = distances / np.max(distances)\n            else:\n                normalized_distances = np.zeros(self.pop_size)\n\n            # Adaptive coefficients (exploration far, exploitation near)\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * normalized_distances\n            social_coeffs = 1.0 + (self.social_max - 1.0) * (1 - normalized_distances)\n            inertia = 0.5 + 0.4 * (1 - normalized_distances) # Inertia between 0.5 and 0.9\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (inertia[i] * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n                \n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, current_lb, current_ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n            \n            # Shrink the search space\n            current_lb = global_best_position - (ub - lb) / 2 * self.shrinking_rate\n            current_ub = global_best_position + (ub - lb) / 2 * self.shrinking_rate\n            current_lb = np.clip(current_lb, lb, ub)\n            current_ub = np.clip(current_ub, lb, ub)\n        \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm ShrinkingAdaptivePSO scored 0.558 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5ecc284d-dd96-4fe4-be68-d97bc92892b9"], "operator": null, "metadata": {"aucs": [0.1639153444017144, 0.18473584997492865, 0.7727773521246839, 0.9139367926432229, 0.7957761187439725, 0.2848853943152658, 0.6655224340557715, 0.5048559101406009, 0.737520735225671, 0.1914914401051656, 0.8715751697085946, 0.9982339795602359, 0.34418729984285656, 0.278386815132344, 0.7381942472082388, 0.8373416453870789, 0.2933104065306408, 0.8771423351546589, 0.19068378366619387, 0.5055845265925927]}}
{"id": "4bc1b1cb-134b-4235-9c51-11b12fb1921c", "fitness": 0.451700777151318, "name": "EnhancedAdaptivePSO", "description": "Enhanced PSO with dynamic inertia weight and velocity clamping to improve convergence and prevent premature stagnation.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0, velocity_clamp=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.velocity_clamp = velocity_clamp # Add velocity clamping\n    \n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        inertia_weight = 0.9  # Initial inertia weight\n        inertia_decay = 0.995 # Inertia decay rate\n\n        while self.budget > 0:\n            # Sort fitnesses and get ranks\n            ranked_indices = np.argsort(fitness)\n            ranks = np.empty_like(ranked_indices)\n            ranks[ranked_indices] = np.arange(self.pop_size)\n\n            # Normalize ranks to [0, 1]\n            normalized_ranks = ranks / (self.pop_size - 1)\n            \n            # Adaptive coefficients based on normalized rank\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * (1 - normalized_ranks)\n            social_coeffs = 1.0 + (self.social_max - 1.0) * normalized_ranks\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n                \n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness # Update fitness array\n            \n            inertia_weight *= inertia_decay # Decrease inertia weight\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedAdaptivePSO scored 0.452 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b78e37f1-d343-4ee0-9abf-673e9e04f959"], "operator": null, "metadata": {"aucs": [0.25279124783755025, 0.38882714125534845, 0.8631588183596719, 0.24179614140168437, 0.31685502008588096, 0.8966682635275577, 0.32240990005628933, 0.49707851611682163, 0.20390569406022419, 0.20338846552758738, 0.26535515882857486, 0.997668589017014, 0.22639398082372175, 0.25761659083330746, 0.7398191248608884, 0.3864830160098083, 0.407102132939127, 0.8895618040182103, 0.16985704601232865, 0.5072788914547641]}}
{"id": "80f089a2-4984-4fda-865f-5534d85e2f01", "fitness": 0.3221983863511827, "name": "AgingPSO", "description": "A PSO variant with velocity clamping and dynamically adjusted cognitive and social coefficients based on the particle's age.", "code": "import numpy as np\n\nclass AgingPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, velocity_clamp=0.5, cognitive_max=2.0, social_max=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.velocity_clamp = velocity_clamp\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        age = np.zeros(self.pop_size)\n        max_age = self.budget // self.pop_size  # Maximum possible age\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adjust cognitive and social coefficients based on age. Younger particles explore more.\n                normalized_age = age[i] / max_age if max_age > 0 else 0\n                cognitive_coeff = 1.0 + (self.cognitive_max - 1.0) * (1 - normalized_age)\n                social_coeff = 1.0 + (self.social_max - 1.0) * normalized_age\n                \n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (velocities[i] +\n                                 cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeff * r2 * (global_best_position - population[i]))\n                \n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n                \n                new_position = np.clip(population[i] + velocities[i], lb, ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness\n                \n                age[i] += 1  # Increment age\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AgingPSO scored 0.322 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f1fd5314-ef25-4799-8f0a-847ec192407d"], "operator": null, "metadata": {"aucs": [0.15479690967699045, 0.21965010306522803, 0.3027355615538685, 0.2961937626089497, 0.2520721576264182, 0.2719027636841136, 0.27650878640505994, 0.24724609496572525, 0.22072005297351283, 0.19283996808606318, 0.29138166911971297, 0.9986202680134779, 0.2673133181998675, 0.2638647918409097, 0.6384496824544117, 0.2985159160551065, 0.2644272843049099, 0.3376247622743065, 0.16766121603754613, 0.4814426580774753]}}
{"id": "d662049a-99fc-470b-8f1d-05a08cdcbb0d", "fitness": 0.5435588405288956, "name": "AdaptivePSO", "description": "Adaptive PSO with dynamic exploration-exploitation balance using both distance to the global best and fitness rank to adjust coefficients and a diversity maintenance strategy to prevent premature convergence.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0, w_max=0.9, w_min=0.4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.w_max = w_max\n        self.w_min = w_min\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal bests\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Calculate distance to global best\n            distances = np.linalg.norm(population - global_best_position, axis=1)\n            \n            # Normalize distances\n            if np.max(distances) > 0:\n                normalized_distances = distances / np.max(distances)\n            else:\n                normalized_distances = np.zeros(self.pop_size)\n\n            # Rank fitness values\n            ranked_fitness = np.argsort(fitness)\n            normalized_ranks = np.argsort(ranked_fitness) / (self.pop_size - 1)\n            \n            # Adaptive coefficients (exploration far, exploitation near)\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * (normalized_distances + normalized_ranks) / 2\n            social_coeffs = 1.0 + (self.social_max - 1.0) * (1 - (normalized_distances + normalized_ranks) / 2)\n            inertia = self.w_max - (self.w_max - self.w_min) * normalized_ranks # Inertia decreases with better rank\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (inertia[i] * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n                \n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n\n            # Diversity maintenance (random restart of worst particle)\n            if np.std(fitness) < 1e-6:  # If particles are too similar\n                worst_index = np.argmax(fitness)\n                population[worst_index] = np.random.uniform(lb, ub, size=self.dim)\n                velocities[worst_index] = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=self.dim)\n                fitness[worst_index] = func(population[worst_index])\n                self.budget -= 1\n                personal_best_positions[worst_index] = population[worst_index].copy()\n                personal_best_fitnesses[worst_index] = fitness[worst_index]\n                \n                if fitness[worst_index] < global_best_fitness:\n                    global_best_fitness = fitness[worst_index]\n                    global_best_position = population[worst_index].copy()\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptivePSO scored 0.544 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5ecc284d-dd96-4fe4-be68-d97bc92892b9"], "operator": null, "metadata": {"aucs": [0.21448184609893028, 0.1759017605762221, 0.9128330906253245, 0.20577861145469922, 0.30188699304168476, 0.9330017265458117, 0.35704280496762253, 0.48720285749148917, 0.9181052937621754, 0.18666274570698616, 0.9402467600428726, 0.9973846599394448, 0.33622981007659314, 0.3046471490424296, 0.6504323520422796, 0.8408894008562584, 0.4559776630719832, 0.9495718984857483, 0.20578113837083012, 0.4971182483785258]}}
{"id": "7543baeb-52e9-4879-b0b1-e79756d6c1bb", "fitness": 0.34594596489497736, "name": "VelocityClampedAdaptivePSO", "description": "Uses a simplified PSO with velocity clamping based on the population's standard deviation to control exploration, combined with adaptive inertia.", "code": "import numpy as np\n\nclass VelocityClampedAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_coeff=2.0, social_coeff=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n\n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            # Calculate population standard deviation\n            std_dev = np.std(population, axis=0)\n            \n            # Calculate velocity clamp value based on std_dev\n            v_max = 0.1 * (ub - lb) + std_dev\n            \n            #Adaptive Inertia\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (global_best_fitness - np.min(fitness))/(np.max(fitness) - np.min(fitness) + 1e-8) #Adapt inertia to convergence state\n            \n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * r2 * (global_best_position - population[i]))\n\n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n\n                # Update position\n                new_position = population[i] + velocities[i]\n\n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n                population[i] = new_position\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm VelocityClampedAdaptivePSO scored 0.346 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["42f3f102-0549-4d48-a835-5c9216c31921"], "operator": null, "metadata": {"aucs": [0.1754979827068477, 0.3031332038522221, 0.33340083882077853, 0.400943079531039, 0.28028426881470514, 0.2745934171454928, 0.28773699990386625, 0.30277750546530824, 0.26794907224912523, 0.20108272525440885, 0.32793603495215107, 0.9990080300509327, 0.272547572363665, 0.2842041952284792, 0.5840714779042959, 0.3555218524306446, 0.2991176397432922, 0.28790137998504683, 0.18083682822042357, 0.500375193276824]}}
{"id": "cac4697a-3908-400e-9b73-107b2d8c2838", "fitness": 0.5233143194232833, "name": "BudgetAwarePSO", "description": "PSO with linearly decreasing inertia weight and velocity clamping based on the remaining budget to dynamically control exploration and exploitation.", "code": "import numpy as np\n\nclass BudgetAwarePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_coeff=2.0, social_coeff=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        initial_budget = self.budget\n\n        while self.budget > 0:\n            remaining_ratio = self.budget / initial_budget\n            inertia = self.inertia_min + (self.inertia_max - self.inertia_min) * remaining_ratio # Linearly decreasing inertia\n\n            # Velocity clamping based on remaining budget. More exploration at the beginning.\n            v_max = (ub - lb) * 0.1 * remaining_ratio + (ub-lb) * 0.01\n            \n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (inertia * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * r2 * (global_best_position - population[i]))\n\n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -v_max, v_max) \n                \n                new_position = np.clip(population[i] + velocities[i], lb, ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm BudgetAwarePSO scored 0.523 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f1fd5314-ef25-4799-8f0a-847ec192407d"], "operator": null, "metadata": {"aucs": [0.21588730757515573, 0.23022696203117599, 0.6950220410093361, 0.17250058958084646, 0.420531304680007, 0.7491788765917367, 0.33358477638258044, 0.5982317022666781, 0.7157289589813973, 0.23219697011898877, 0.8574976138205083, 0.992501730959965, 0.25057719722057326, 0.6170007095884179, 0.733572802524742, 0.751781426543612, 0.37983267141422916, 0.7944629471818017, 0.19882372605113607, 0.5271460739427766]}}
{"id": "d4742be7-a120-49dd-8200-ce358b39660a", "fitness": 0.1603044652069437, "name": "AdaptivePSO", "description": "Simplified PSO with adaptive coefficients based on fitness improvement rate, dynamically balancing exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = 0.7\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.c1_final = 0.5\n        self.c2_final = 2.5\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        prev_global_best_fitness = np.inf\n\n        while self.budget > 0:\n            improvement_rate = (prev_global_best_fitness - global_best_fitness) / prev_global_best_fitness if prev_global_best_fitness != 0 else 0\n            \n            #Adaptive c1 and c2\n            c1 = self.c1_init + (self.c1_final - self.c1_init) * improvement_rate\n            c2 = self.c2_init + (self.c2_final - self.c2_init) * improvement_rate\n            \n            c1 = np.clip(c1, 0.5, 2.5)\n            c2 = np.clip(c2, 0.5, 2.5)\n            \n\n            prev_global_best_fitness = global_best_fitness\n            \n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (self.inertia * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 c2 * r2 * (global_best_position - population[i]))\n                \n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptivePSO scored 0.160 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b78e37f1-d343-4ee0-9abf-673e9e04f959"], "operator": null, "metadata": {"aucs": [0.10792270994331354, 0.08972649113589581, 0.2267657576659654, 0.13818916158632222, 0.10410272127928089, 0.16012889729885083, 0.16906867953412474, 0.17148048600348154, 0.17497247113251946, 0.11696112791743851, 0.15483494509492324, 0.17005820696585217, 0.06866982038606129, 0.1493226237781251, 0.14240171495207143, 0.19496298099513165, 0.16355146170432067, 0.1716333722613046, 0.10376301953405276, 0.42757265496983754]}}
{"id": "e2d533f2-2389-4f51-831d-b03d2ce13548", "fitness": 0.38006825257576776, "name": "SimplifiedAdaptivePSO", "description": "Simplified PSO with linearly decreasing inertia weight and adaptive acceleration coefficients based on normalized fitness rank, balancing exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass SimplifiedAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        inertia_start = 0.9\n        inertia_end = 0.4\n\n        while self.budget > 0:\n            # Calculate inertia weight (linearly decreasing)\n            inertia = inertia_start - (inertia_start - inertia_end) * (1 - self.budget / (self.budget + self.pop_size))\n\n            # Sort fitnesses and get ranks\n            ranked_indices = np.argsort(fitness)\n            ranks = np.empty_like(ranked_indices)\n            ranks[ranked_indices] = np.arange(self.pop_size)\n\n            # Normalize ranks to [0, 1]\n            normalized_ranks = ranks / (self.pop_size - 1)\n            \n            # Adaptive coefficients based on normalized rank\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * (1 - normalized_ranks)\n            social_coeffs = 1.0 + (self.social_max - 1.0) * normalized_ranks\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness # Update fitness array\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm SimplifiedAdaptivePSO scored 0.380 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b78e37f1-d343-4ee0-9abf-673e9e04f959"], "operator": null, "metadata": {"aucs": [0.2011049445763543, 0.28088564224242707, 0.35453803433678843, 0.521409809839189, 0.2510206075342861, 0.24330621421099485, 0.3078378943262885, 0.3538374563065374, 0.3260004911282105, 0.3062373008732826, 0.2811850968677292, 0.998824985022945, 0.2222859675143627, 0.25523776514991503, 0.7107251201259872, 0.3455425969676892, 0.3155853011777153, 0.4982106170655699, 0.31140150776176134, 0.5161876984873215]}}
{"id": "91f7b8e6-8088-4b95-bc4d-a093c792307c", "fitness": -Infinity, "name": "EnhancedDiversityShrinkingPSO", "description": "Enhanced Adaptive PSO with a diversity-sensitive shrinking mechanism and adaptive parameter control based on both fitness and distance.", "code": "import numpy as np\n\nclass EnhancedDiversityShrinkingPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0, shrinking_rate=0.99, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.shrinking_rate = shrinking_rate\n        self.diversity_threshold = diversity_threshold # Threshold for diversity check\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal bests\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        current_lb = lb\n        current_ub = ub\n\n        # Optimization loop\n        while self.budget > 0:\n            # Calculate distance to global best\n            distances = np.linalg.norm(population - global_best_position, axis=1)\n            \n            # Normalize distances\n            if np.max(distances) > 0:\n                normalized_distances = distances / np.max(distances)\n            else:\n                normalized_distances = np.zeros(self.pop_size)\n\n            # Calculate diversity (average distance between particles)\n            diversity = np.mean([np.linalg.norm(population[i] - population[j]) for i in range(self.pop_size) for j in range(i + 1, self.pop_size)])\n\n            # Adaptive coefficients (exploration far, exploitation near)\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * normalized_distances\n            social_coeffs = 1.0 + (self.social_max - 1.0) * (1 - normalized_distances)\n\n            # Dynamically adjust inertia based on both distance and diversity\n            inertia = 0.4 + 0.5 * (1 - normalized_distances) # Base inertia on distance\n\n            # If diversity is low, increase exploration by increasing inertia\n            if diversity < self.diversity_threshold:\n                inertia = np.clip(inertia + 0.2, 0.4, 0.9) # Increase inertia to enhance exploration\n            \n            # Adaptive shrinking rate\n            adaptive_shrinking_rate = self.shrinking_rate * (1 + 0.2*(1 - diversity/self.diversity_threshold) if diversity < self.diversity_threshold else 1)\n\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (inertia * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n                \n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, current_lb, current_ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n            \n            # Shrink the search space (diversity-sensitive)\n            current_lb = global_best_position - (ub - lb) / 2 * adaptive_shrinking_rate\n            current_ub = global_best_position + (ub - lb) / 2 * adaptive_shrinking_rate\n            current_lb = np.clip(current_lb, lb, ub)\n            current_ub = np.clip(current_ub, lb, ub)\n        \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 7, "feedback": "An exception occurred: operands could not be broadcast together with shapes (20,) (2,) .", "error": "", "parent_ids": ["baf16244-005f-43b5-89aa-863615b9838c"], "operator": null, "metadata": {}}
{"id": "55e9c024-d4c6-44b3-b726-fcb5f5345f3a", "fitness": 0.0, "name": "HybridPSO_SA", "description": "Hybrid PSO with simulated annealing for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0, velocity_clamp=0.5, sa_prob=0.05, initial_temp=1.0, cooling_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.velocity_clamp = velocity_clamp\n        self.sa_prob = sa_prob # Probability of simulated annealing\n        self.initial_temp = initial_temp # Initial temperature for SA\n        self.cooling_rate = cooling_rate # Cooling rate for SA\n        self.temperature = initial_temp\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        inertia_weight = 0.9\n        inertia_decay = 0.995\n\n        while self.budget > 0:\n            # Sort fitnesses and get ranks\n            ranked_indices = np.argsort(fitness)\n            ranks = np.empty_like(ranked_indices)\n            ranks[ranked_indices] = np.arange(self.pop_size)\n\n            # Normalize ranks to [0, 1]\n            normalized_ranks = ranks / (self.pop_size - 1)\n            \n            # Adaptive coefficients based on normalized rank\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * (1 - normalized_ranks)\n            social_coeffs = 1.0 + (self.social_max - 1.0) * normalized_ranks\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n                \n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Simulated Annealing\n                if np.random.rand() < self.sa_prob:\n                    # Generate a random neighbor\n                    neighbor = np.random.uniform(lb, ub, size=self.dim)\n                    new_fitness_sa = func(neighbor)\n                    self.budget -= 1\n                    \n                    # Acceptance probability\n                    delta_e = new_fitness_sa - fitness[i]\n                    acceptance_prob = np.exp(-delta_e / self.temperature) if delta_e > 0 else 1.0\n                    \n                    if np.random.rand() < acceptance_prob:\n                        new_position = neighbor\n                        \n                        \n                # Evaluate new position if not already evaluated with SA\n                if np.all(new_position != population[i]): # Check if SA already evaluated\n                    new_fitness = func(new_position)\n                    self.budget -= 1\n                else:\n                    new_fitness = new_fitness_sa\n\n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness # Update fitness array\n            \n            inertia_weight *= inertia_decay # Decrease inertia weight\n            self.temperature *= self.cooling_rate # Cool down the temperature\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSO_SA scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4bc1b1cb-134b-4235-9c51-11b12fb1921c"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "9642f983-d384-41b7-a406-167129c230c3", "fitness": -Infinity, "name": "HybridPSO", "description": "Hybrid PSO with a local search (Nelder-Mead) applied probabilistically to enhance exploitation around promising solutions.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0, w_max=0.9, w_min=0.4, local_search_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.w_max = w_max\n        self.w_min = w_min\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal bests\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Calculate distance to global best\n            distances = np.linalg.norm(population - global_best_position, axis=1)\n            \n            # Normalize distances\n            if np.max(distances) > 0:\n                normalized_distances = distances / np.max(distances)\n            else:\n                normalized_distances = np.zeros(self.pop_size)\n\n            # Rank fitness values\n            ranked_fitness = np.argsort(fitness)\n            normalized_ranks = np.argsort(ranked_fitness) / (self.pop_size - 1)\n            \n            # Adaptive coefficients (exploration far, exploitation near)\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * (normalized_distances + normalized_ranks) / 2\n            social_coeffs = 1.0 + (self.social_max - 1.0) * (1 - (normalized_distances + normalized_ranks) / 2)\n            inertia = self.w_max - (self.w_max - self.w_min) * normalized_ranks # Inertia decreases with better rank\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (inertia[i] * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n                \n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Local Search (Nelder-Mead)\n                if np.random.rand() < self.local_search_prob:\n                    \n                    def obj_func(x):\n                        if self.budget > 0:\n                            f = func(x)\n                            self.budget -= 1\n                            return f\n                        else:\n                            return np.inf # Return a large value if budget is exceeded\n\n                    result = minimize(obj_func, new_position, method='Nelder-Mead',\n                                        bounds=np.array([lb, ub] * self.dim).reshape(self.dim, 2).tolist(),\n                                        options={'maxfev': min(50, self.budget)})  # Limit function evaluations\n                    \n                    if self.budget > 0 and result.success:\n                        new_position = result.x\n                        new_fitness = result.fun\n                    else:\n                         new_fitness = func(new_position) if self.budget > 0 else np.inf\n                         if self.budget > 0: self.budget -=1\n                         \n                else:\n                    new_fitness = func(new_position) if self.budget > 0 else np.inf\n                    if self.budget > 0: self.budget -= 1\n                        \n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n\n            # Diversity maintenance (random restart of worst particle)\n            if np.std(fitness) < 1e-6:  # If particles are too similar\n                worst_index = np.argmax(fitness)\n                population[worst_index] = np.random.uniform(lb, ub, size=self.dim)\n                velocities[worst_index] = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=self.dim)\n                fitness[worst_index] = func(population[worst_index])\n                if self.budget > 0: self.budget -= 1\n                personal_best_positions[worst_index] = population[worst_index].copy()\n                personal_best_fitnesses[worst_index] = fitness[worst_index]\n                \n                if fitness[worst_index] < global_best_fitness:\n                    global_best_fitness = fitness[worst_index]\n                    global_best_position = population[worst_index].copy()\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 7, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["d662049a-99fc-470b-8f1d-05a08cdcbb0d"], "operator": null, "metadata": {}}
{"id": "68a3fb97-8c46-418e-9881-0bf5761dc991", "fitness": 0.0, "name": "EnhancedAdaptivePSO", "description": "PSO with adaptive coefficients based on normalized rank, constriction factor, and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0, velocity_clamp=0.5, constriction_factor=0.729, stagnation_threshold=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.velocity_clamp = velocity_clamp\n        self.constriction_factor = constriction_factor\n        self.stagnation_threshold = stagnation_threshold\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        inertia_weight = 0.9  # Initial inertia weight\n        inertia_decay = 0.995 # Inertia decay rate\n        stagnation_counter = 0\n\n        while self.budget > 0:\n            # Sort fitnesses and get ranks\n            ranked_indices = np.argsort(fitness)\n            ranks = np.empty_like(ranked_indices)\n            ranks[ranked_indices] = np.arange(self.pop_size)\n\n            # Normalize ranks to [0, 1]\n            normalized_ranks = ranks / (self.pop_size - 1)\n            \n            # Adaptive coefficients based on normalized rank\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * (1 - normalized_ranks)\n            social_coeffs = 1.0 + (self.social_max - 1.0) * normalized_ranks\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.constriction_factor * (inertia_weight * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n                \n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness # Update fitness array\n            \n            inertia_weight *= inertia_decay # Decrease inertia weight\n            \n            # Stagnation check and restart mechanism\n            self.best_fitness_history.append(global_best_fitness)\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-6:\n                    stagnation_counter += 1\n                    if stagnation_counter >= 2:\n                        # Restart: Reinitialize a portion of the population\n                        num_to_restart = self.pop_size // 2\n                        indices_to_restart = np.random.choice(self.pop_size, num_to_restart, replace=False)\n                        population[indices_to_restart] = np.random.uniform(lb, ub, size=(num_to_restart, self.dim))\n                        velocities[indices_to_restart] = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(num_to_restart, self.dim))\n                        \n                        # Evaluate restarted individuals\n                        new_fitnesses = np.array([func(x) for x in population[indices_to_restart]])\n                        self.budget -= num_to_restart\n                        fitness[indices_to_restart] = new_fitnesses\n\n                        # Update personal bests for restarted individuals\n                        for idx, i in enumerate(indices_to_restart):\n                            if new_fitnesses[idx] < personal_best_fitnesses[i]:\n                                personal_best_fitnesses[i] = new_fitnesses[idx]\n                                personal_best_positions[i] = population[i].copy()\n\n                                # Update global best if necessary\n                                if new_fitnesses[idx] < global_best_fitness:\n                                    global_best_fitness = new_fitnesses[idx]\n                                    global_best_position = population[i].copy()\n                        stagnation_counter = 0 # Reset stagnation counter\n                else:\n                    stagnation_counter = 0\n                \n                self.best_fitness_history.pop(0) # Keep history size constant\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedAdaptivePSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4bc1b1cb-134b-4235-9c51-11b12fb1921c"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "8a8b0623-211b-4da5-a648-10c3282f94d4", "fitness": -Infinity, "name": "BudgetAwareCMAES", "description": "Covariance matrix adaptation evolution strategy (CMA-ES) with budget-aware step size adaptation.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_step_size = initial_step_size\n        self.mean = None\n        self.covariance = None\n        self.step_size = None\n        self.pc = None\n        self.ps = None\n        self.C = None\n        self.invC = None\n        self.weights = None\n        self.mu = None\n        self.mueff = None\n        self.cs = None\n        self.damps = None\n        self.cc = None\n        self.chiN = None\n\n    def initialize(self):\n        self.mean = np.random.uniform(-0.5, 0.5, size=self.dim) # Initialize mean within a reasonable range\n        self.covariance = np.eye(self.dim)\n        self.step_size = self.initial_step_size\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.invC = np.eye(self.dim)\n\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n    \n    def sample_population(self):\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        x = self.mean + self.step_size * z @ np.linalg.cholesky(self.C).T\n        return x, z\n\n    def __call__(self, func):\n        self.initialize()\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        best_fitness = np.inf\n        best_x = None\n        \n        while self.budget > self.pop_size:\n            \n            # Generate and evaluate offspring\n            x, z = self.sample_population()\n            \n            # Clip x to respect bounds\n            x = np.clip(x, lb, ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            # Sort by fitness\n            indices = np.argsort(fitness)\n            fitness = fitness[indices]\n            x = x[indices]\n            z = z[indices]\n\n            # Update best solution\n            if fitness[0] < best_fitness:\n                best_fitness = fitness[0]\n                best_x = x[0]\n\n            # Update mean\n            xmean = np.sum(x[:self.mu].T * self.weights, axis=1)\n            zmean = np.sum(z[:self.mu].T * self.weights, axis=1)\n            \n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * zmean\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.budget // self.pop_size))) / self.chiN < 1.4 + 2 / (self.dim + 1))\n            self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (xmean - self.mean) / self.step_size\n            \n            # Update covariance matrix\n            self.C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.ccovmueff * ((1 - hsig**2) * self.cc * (2 - self.cc))) * self.C + self.ccov1 * self.pc[:, None] @ self.pc[None, :] + self.ccovmu * np.sum(self.weights[:, None, None] * (z[:self.mu, :, None] @ z[:self.mu, None, :]), axis=0)\n\n            # Update step size\n            self.step_size *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Update mean\n            self.mean = xmean\n\n            # Ensure covariance matrix is positive definite\n            try:\n                self.C = np.triu(self.C) + np.triu(self.C, 1).T\n                np.linalg.cholesky(self.C)  # Check if positive definite\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim)  # Add a small diagonal offset\n            \n        # Final evaluation within budget\n        while self.budget > 0:\n            x = self.mean + self.step_size * np.random.normal(0, 1, size=self.dim)\n            x = np.clip(x, lb, ub)\n            f = func(x)\n            self.budget -= 1\n            if f < best_fitness:\n                best_fitness = f\n                best_x = x\n            \n        return best_fitness, best_x", "configspace": "", "generation": 7, "feedback": "An exception occurred: 'BudgetAwareCMAES' object has no attribute 'ccov1'.", "error": "", "parent_ids": ["4bc1b1cb-134b-4235-9c51-11b12fb1921c"], "operator": null, "metadata": {}}
{"id": "3aeac10b-532f-417c-bd5f-5f2b7a6ec515", "fitness": 0.0, "name": "SuccessRateAdaptivePSO", "description": "PSO with dynamic parameter adaptation based on success rate and stagnation detection to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass SuccessRateAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0, velocity_clamp=0.5, stagnation_threshold=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.velocity_clamp = velocity_clamp\n        self.stagnation_threshold = stagnation_threshold\n        self.success_rate = 0.0\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.995\n        self.inertia_min = 0.4\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        stagnation_counter = 0\n        last_global_best_fitness = global_best_fitness\n\n        while self.budget > 0:\n            successful_particles = 0\n            \n            # Sort fitnesses and get ranks\n            ranked_indices = np.argsort(fitness)\n            ranks = np.empty_like(ranked_indices)\n            ranks[ranked_indices] = np.arange(self.pop_size)\n\n            # Normalize ranks to [0, 1]\n            normalized_ranks = ranks / (self.pop_size - 1)\n            \n            # Adaptive coefficients based on normalized rank\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * (1 - normalized_ranks)\n            social_coeffs = 1.0 + (self.social_max - 1.0) * normalized_ranks\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n                \n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    successful_particles += 1\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness # Update fitness array\n\n            # Calculate success rate\n            self.success_rate = successful_particles / self.pop_size\n            \n            # Adjust inertia weight based on success rate\n            if self.success_rate > 0.2:\n                self.inertia_weight *= 1.02  # Increase inertia to promote exploration\n            else:\n                self.inertia_weight *= self.inertia_decay # Decrease inertia to promote exploitation\n\n            self.inertia_weight = max(self.inertia_weight, self.inertia_min) # Ensure inertia doesn't get too low\n            self.inertia_weight = min(self.inertia_weight, 0.9) #Limit max inertia\n\n            # Stagnation detection\n            if abs(global_best_fitness - last_global_best_fitness) < 1e-8:\n                stagnation_counter += 1\n            else:\n                stagnation_counter = 0\n            \n            if stagnation_counter > self.stagnation_threshold:\n                # If stagnated, perturb the population to escape local optima\n                for i in range(self.pop_size):\n                    population[i] = np.random.uniform(lb, ub, size=self.dim)\n                    fitness[i] = func(population[i])\n                    self.budget -= 1\n                    if fitness[i] < personal_best_fitnesses[i]:\n                        personal_best_fitnesses[i] = fitness[i]\n                        personal_best_positions[i] = population[i].copy()\n                        if fitness[i] < global_best_fitness:\n                            global_best_fitness = fitness[i]\n                            global_best_position = population[i].copy()\n                stagnation_counter = 0 #Reset counter\n            \n            last_global_best_fitness = global_best_fitness\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm SuccessRateAdaptivePSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4bc1b1cb-134b-4235-9c51-11b12fb1921c"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "53b2425c-fa9f-4b75-ae7f-0c0440d91d14", "fitness": 0.15636456622826891, "name": "EnhancedAdaptivePSO", "description": "Improved PSO with adaptive coefficients based on fitness rank, dynamic velocity clamping, and restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0, velocity_clamp_max=0.5, restart_patience=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.velocity_clamp_max = velocity_clamp_max\n        self.restart_patience = restart_patience\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        inertia_weight = 0.9  # Initial inertia weight\n        inertia_decay = 0.995 # Inertia decay rate\n        velocity_clamp = self.velocity_clamp_max\n\n        stagnation_counter = 0\n\n        while self.budget > 0:\n            # Sort fitnesses and get ranks\n            ranked_indices = np.argsort(fitness)\n            ranks = np.empty_like(ranked_indices)\n            ranks[ranked_indices] = np.arange(self.pop_size)\n\n            # Normalize ranks to [0, 1]\n            normalized_ranks = ranks / (self.pop_size - 1)\n            \n            # Adaptive coefficients based on normalized rank\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * (1 - normalized_ranks)\n            social_coeffs = 1.0 + (self.social_max - 1.0) * normalized_ranks\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n                \n                # Clamp velocities dynamically\n                velocities[i] = np.clip(velocities[i], -velocity_clamp * (ub - lb), velocity_clamp * (ub - lb))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness # Update fitness array\n            \n            inertia_weight *= inertia_decay # Decrease inertia weight\n            velocity_clamp = self.velocity_clamp_max * inertia_weight # Dynamic velocity clamping\n\n            # Stagnation check and restart mechanism\n            self.best_fitness_history.append(global_best_fitness)\n            if len(self.best_fitness_history) > self.restart_patience:\n                if self.best_fitness_history[-1] >= self.best_fitness_history[-self.restart_patience]:\n                    stagnation_counter += 1\n                else:\n                    stagnation_counter = 0\n\n                if stagnation_counter >= self.restart_patience:\n                    # Restart: Re-initialize a portion of the population\n                    num_to_restart = int(0.2 * self.pop_size)  # Restart 20% of the population\n                    indices_to_restart = np.random.choice(self.pop_size, num_to_restart, replace=False)\n                    \n                    population[indices_to_restart] = np.random.uniform(lb, ub, size=(num_to_restart, self.dim))\n                    velocities[indices_to_restart] = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(num_to_restart, self.dim))\n                    fitness[indices_to_restart] = [func(x) for x in population[indices_to_restart]]\n                    self.budget -= num_to_restart\n\n                    personal_best_positions[indices_to_restart] = population[indices_to_restart].copy()\n                    personal_best_fitnesses[indices_to_restart] = fitness[indices_to_restart].copy()\n\n                    global_best_index = np.argmin(fitness)\n                    global_best_position = population[global_best_index].copy()\n                    global_best_fitness = fitness[global_best_index]\n\n                    self.best_fitness_history = []  # Reset history\n                    stagnation_counter = 0\n                    inertia_weight = 0.9\n                    velocity_clamp = self.velocity_clamp_max\n                    \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedAdaptivePSO scored 0.156 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4bc1b1cb-134b-4235-9c51-11b12fb1921c"], "operator": null, "metadata": {"aucs": [0.16756804041241136, 0.3015256582723954, 0]}}
{"id": "93ddbc1d-d3c4-48b0-8c20-593571911126", "fitness": 0.3390442716216981, "name": "AdaptiveSuccessPSO", "description": "PSO with dynamic parameter adaptation based on success rate and stagnation detection for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSuccessPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0, velocity_clamp=0.5, stagnation_limit=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.velocity_clamp = velocity_clamp\n        self.stagnation_limit = stagnation_limit  # Number of iterations without improvement\n        self.success_rate = 0.5 # initial success rate\n        self.success_rate_window = 10 # window size to measure the success rate\n        self.success_history = []\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.995\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        stagnation_counter = 0\n        best_fitness_history = [global_best_fitness]\n\n        while self.budget > 0:\n            \n            # Counters for success rate adaptation\n            success_count = 0\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                old_fitness = fitness[i]\n                \n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_max * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_max * r2 * (global_best_position - population[i]))\n                \n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                        \n                if new_fitness < old_fitness:\n                    success_count += 1 # Counting the successes\n                \n                population[i] = new_position\n                fitness[i] = new_fitness # Update fitness array\n\n            # Success rate adaptation\n            self.success_history.append(success_count / self.pop_size)\n            if len(self.success_history) > self.success_rate_window:\n                self.success_history.pop(0)\n\n            self.success_rate = np.mean(self.success_history)\n            \n            # Adjust cognitive and social coefficients based on success rate\n            if self.success_rate > 0.6:\n                self.cognitive_max *= 0.99  # Decrease cognitive influence\n                self.social_max *= 1.01   # Increase social influence\n            elif self.success_rate < 0.3:\n                self.cognitive_max *= 1.01  # Increase cognitive influence\n                self.social_max *= 0.99   # Decrease social influence\n\n            self.cognitive_max = np.clip(self.cognitive_max, 1.0, 2.0)\n            self.social_max = np.clip(self.social_max, 1.0, 2.0)\n\n            # Stagnation detection\n            if global_best_fitness >= best_fitness_history[-1]:\n                stagnation_counter += 1\n            else:\n                stagnation_counter = 0\n\n            best_fitness_history.append(global_best_fitness)\n\n            if stagnation_counter > self.stagnation_limit:\n                # Trigger re-exploration (e.g., re-initialize a portion of the population)\n                num_reinitialized = int(self.pop_size * 0.2)\n                indices_to_reinitialize = np.random.choice(self.pop_size, num_reinitialized, replace=False)\n                for i in indices_to_reinitialize:\n                    population[i] = np.random.uniform(lb, ub, size=self.dim)\n                    velocities[i] = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=self.dim)\n                    fitness[i] = func(population[i])\n                    self.budget -= 1\n                    personal_best_positions[i] = population[i].copy()\n                    personal_best_fitnesses[i] = fitness[i]\n\n                stagnation_counter = 0 # Reset the counter\n                \n            self.inertia_weight *= self.inertia_decay # Decrease inertia weight\n\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveSuccessPSO scored 0.339 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4bc1b1cb-134b-4235-9c51-11b12fb1921c"], "operator": null, "metadata": {"aucs": [0.2373427036743535, 0.7797901111907408, 0]}}
{"id": "a4a9d96d-2ba5-4e79-a83b-65c29bc9da27", "fitness": 0.5520175160321242, "name": "AdaptiveMutationPSO", "description": "PSO with adaptive learning rates based on the success rate of individual particles and a mutation operator to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveMutationPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=2.0, social_coeff=2.0, mutation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.mutation_rate = mutation_rate\n        self.success_rates = np.zeros(pop_size)\n        self.learning_rates = np.ones(pop_size) * 0.5 # Initialize learning rates\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        success_counts = np.zeros(self.pop_size)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.learning_rates[i] * self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.learning_rates[i] * self.social_coeff * r2 * (global_best_position - population[i]))\n                \n                new_position = np.clip(population[i] + velocities[i], lb, ub)\n                \n                # Mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.uniform(lb, ub, size=self.dim)\n                    new_position = (1 - self.mutation_rate) * new_position + self.mutation_rate * mutation # Blend with mutation\n                    new_position = np.clip(new_position, lb, ub)\n                    \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < personal_best_fitnesses[i]:\n                    success_counts[i] += 1\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness\n\n            # Update learning rates based on success rates\n            self.success_rates = 0.9 * self.success_rates + 0.1 * success_counts\n            self.learning_rates = np.clip(self.success_rates / np.mean(self.success_rates), 0.1, 1.0)\n            success_counts[:] = 0 # Reset for next iteration\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveMutationPSO scored 0.552 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cac4697a-3908-400e-9b73-107b2d8c2838"], "operator": null, "metadata": {"aucs": [0.14943005781080687, 0.2061005321924927, 0.6127414163344962, 0.8356230550798978, 0.6413661227145502, 0.743014486092944, 0.3165477413635671, 0.5331231074986271, 0.6701948039281113, 0.18078394028417188, 0.8993007548794889, 0.9992555978646475, 0.2509179655826067, 0.4627271734035141, 0.9024129422396745, 0.6789370463445191, 0.43240486722864224, 0.839452820606413, 0.17960969920922565, 0.5064061899840897]}}
{"id": "652c14c9-0ba1-4bed-8677-dfd3eaddad00", "fitness": 0.5826638570946353, "name": "AdaptiveSuccessPSO", "description": "PSO with dynamically adjusted cognitive and social coefficients based on particle success rate and adaptive velocity clamping based on population diversity, enhancing both exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSuccessPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0, initial_velocity_clamp=0.5, success_rate_window=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.velocity_clamp = initial_velocity_clamp  # Initial velocity clamping\n        self.success_rate_window = success_rate_window\n        self.success_rates = np.zeros(pop_size)\n        self.success_counts = np.zeros(pop_size)\n        self.iteration_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        inertia_weight = 0.9  # Initial inertia weight\n        inertia_decay = 0.995 # Inertia decay rate\n\n        while self.budget > 0:\n            # Sort fitnesses and get ranks\n            ranked_indices = np.argsort(fitness)\n            ranks = np.empty_like(ranked_indices)\n            ranks[ranked_indices] = np.arange(self.pop_size)\n\n            # Normalize ranks to [0, 1]\n            normalized_ranks = ranks / (self.pop_size - 1)\n            \n            # Adaptive coefficients based on success rate\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * (1 - self.success_rates)\n            social_coeffs = 1.0 + (self.social_max - 1.0) * self.success_rates\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n                \n                # Adaptive velocity clamping based on population diversity\n                diversity = np.mean(np.std(population, axis=0))\n                velocity_clamp = self.velocity_clamp * (1 + diversity)  # Increase clamp if diversity is high\n                \n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -velocity_clamp * (ub - lb), velocity_clamp * (ub - lb))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    self.success_counts[i] += 1\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness # Update fitness array\n\n            inertia_weight *= inertia_decay # Decrease inertia weight\n            \n            # Update success rates every window size iterations\n            if self.iteration_count % self.success_rate_window == 0:\n                self.success_rates = self.success_counts / self.success_rate_window\n                self.success_counts[:] = 0  # Reset success counts\n            \n            self.iteration_count += 1\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveSuccessPSO scored 0.583 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4bc1b1cb-134b-4235-9c51-11b12fb1921c"], "operator": null, "metadata": {"aucs": [0.2418567450427893, 0.33397436813747583, 0.8512564302545156, 0.8846816556558836, 0.26279592625629344, 0.2806627451307996, 0.8326079218179493, 0.7178112186777084, 0.8568809359746468, 0.8641100051202292, 0.9066389478692274, 0.9978523602043814, 0.22520798968566969, 0.2686369754954747, 0.6457009658842329, 0.8894730553253719, 0.5293399835398387, 0.29067734921250465, 0.2778511117829576, 0.49526045082475656]}}
{"id": "ea020d4f-2de5-424e-911f-6b5930ba18cf", "fitness": 0.33161098815489737, "name": "AdaptivePSO", "description": "Adaptive PSO with dynamic coefficients based on distance and fitness, using a ring topology for social learning and a Cauchy mutation for diversity.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0, w_max=0.9, w_min=0.4, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.w_max = w_max\n        self.w_min = w_min\n        self.cauchy_scale = cauchy_scale  # Scale for Cauchy mutation\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal bests\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Calculate distance to global best\n            distances = np.linalg.norm(population - global_best_position, axis=1)\n            \n            # Normalize distances\n            if np.max(distances) > 0:\n                normalized_distances = distances / np.max(distances)\n            else:\n                normalized_distances = np.zeros(self.pop_size)\n\n            # Rank fitness values\n            ranked_fitness = np.argsort(fitness)\n            normalized_ranks = np.argsort(ranked_fitness) / (self.pop_size - 1)\n            \n            # Adaptive coefficients (exploration far, exploitation near)\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * (normalized_distances + normalized_ranks) / 2\n            social_coeffs = 1.0 + (self.social_max - 1.0) * (1 - (normalized_distances + normalized_ranks) / 2)\n            inertia = self.w_max - (self.w_max - self.w_min) * normalized_ranks # Inertia decreases with better rank\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Ring topology for social learning\n                neighbor_left = (i - 1) % self.pop_size\n                neighbor_right = (i + 1) % self.pop_size\n                social_influence = (population[neighbor_left] + population[neighbor_right]) / 2\n\n                velocities[i] = (inertia[i] * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (social_influence - population[i]))\n                \n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Cauchy mutation for diversity\n                if np.random.rand() < 0.1:  # Apply mutation with 10% probability\n                    mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n                    new_position += mutation\n                    new_position = np.clip(new_position, lb, ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n\n            # Diversity maintenance (random restart of worst particle)\n            if np.std(fitness) < 1e-6:  # If particles are too similar\n                worst_index = np.argmax(fitness)\n                population[worst_index] = np.random.uniform(lb, ub, size=self.dim)\n                velocities[worst_index] = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=self.dim)\n                fitness[worst_index] = func(population[worst_index])\n                self.budget -= 1\n                personal_best_positions[worst_index] = population[worst_index].copy()\n                personal_best_fitnesses[worst_index] = fitness[worst_index]\n                \n                if fitness[worst_index] < global_best_fitness:\n                    global_best_fitness = fitness[worst_index]\n                    global_best_position = population[worst_index].copy()\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptivePSO scored 0.332 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d662049a-99fc-470b-8f1d-05a08cdcbb0d"], "operator": null, "metadata": {"aucs": [0.1427575674745114, 0.20912357640605073, 0.3164356600141587, 0.3069096681085509, 0.2770381919246028, 0.3092067738336306, 0.28026714825999266, 0.2559682242504091, 0.24159342618046042, 0.19215747380774062, 0.2731025899245002, 0.9906636721259515, 0.24937983305957256, 0.2880461049646167, 0.6957968134299002, 0.31965484445441006, 0.2672870258665394, 0.35364833903949144, 0.18209865329169772, 0.4810841766811592]}}
{"id": "0028f65d-0379-4183-9acf-fdbe68feea0d", "fitness": 0.6072886834272166, "name": "EnhancedAdaptiveCauchyPSO", "description": "A PSO variant that uses a combination of fitness-based and distance-based adaptation, incorporating a Cauchy mutation operator for enhanced exploration and escape from local optima.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCauchyPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0, w_max=0.9, w_min=0.4, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.w_max = w_max\n        self.w_min = w_min\n        self.cauchy_scale = cauchy_scale\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal bests\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Calculate distance to global best\n            distances = np.linalg.norm(population - global_best_position, axis=1)\n            \n            # Normalize distances\n            if np.max(distances) > 0:\n                normalized_distances = distances / np.max(distances)\n            else:\n                normalized_distances = np.zeros(self.pop_size)\n\n            # Rank fitness values\n            ranked_fitness = np.argsort(fitness)\n            normalized_ranks = np.argsort(ranked_fitness) / (self.pop_size - 1)\n            \n            # Adaptive coefficients (exploration far, exploitation near)\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * (normalized_distances + normalized_ranks) / 2\n            social_coeffs = 1.0 + (self.social_max - 1.0) * (1 - (normalized_distances + normalized_ranks) / 2)\n            inertia = self.w_max - (self.w_max - self.w_min) * normalized_ranks # Inertia decreases with better rank\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (inertia[i] * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n                \n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Cauchy mutation with probability based on normalized distance\n                if np.random.rand() < normalized_distances[i]:\n                    cauchy_mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n                    new_position += cauchy_mutation\n                    new_position = np.clip(new_position, lb, ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n\n            # Diversity maintenance (random restart of worst particle)\n            if np.std(fitness) < 1e-6:  # If particles are too similar\n                worst_index = np.argmax(fitness)\n                population[worst_index] = np.random.uniform(lb, ub, size=self.dim)\n                velocities[worst_index] = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=self.dim)\n                fitness[worst_index] = func(population[worst_index])\n                self.budget -= 1\n                personal_best_positions[worst_index] = population[worst_index].copy()\n                personal_best_fitnesses[worst_index] = fitness[worst_index]\n                \n                if fitness[worst_index] < global_best_fitness:\n                    global_best_fitness = fitness[worst_index]\n                    global_best_position = population[worst_index].copy()\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedAdaptiveCauchyPSO scored 0.607 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d662049a-99fc-470b-8f1d-05a08cdcbb0d"], "operator": null, "metadata": {"aucs": [0.22788723159935975, 0.19559492209802642, 0.8630039638998832, 0.9048333495325939, 0.6752956612351404, 0.910652338395436, 0.33520553307574963, 0.3978850807772416, 0.8376068619705167, 0.5731611444481858, 0.7842087197137969, 0.9984973918001044, 0.29819459718396435, 0.2951440319533426, 0.9353020888860865, 0.8873955516585947, 0.34653690830499895, 0.9463973257062686, 0.21828255078028014, 0.5146884155247611]}}
{"id": "cf79d3bc-6b5f-4bcd-85a8-e7134b65a4d1", "fitness": -Infinity, "name": "RepulsivePSO", "description": "A PSO variant that employs a repulsive force from the global best to encourage exploration when particles are too close, combined with adaptive inertia and Cauchy mutation.", "code": "import numpy as np\n\nclass RepulsivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive=2.0, social=2.0, w_max=0.9, w_min=0.4, cauchy_scale=0.1, repulsion_strength=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive = cognitive\n        self.social = social\n        self.w_max = w_max\n        self.w_min = w_min\n        self.cauchy_scale = cauchy_scale\n        self.repulsion_strength = repulsion_strength\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal bests\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            # Adaptive inertia weight\n            inertia = self.w_max - (self.w_max - self.w_min) * (1 - (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-8))\n\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                # Repulsive force: if a particle is too close to the global best, push it away\n                distance_to_global_best = np.linalg.norm(population[i] - global_best_position)\n                if distance_to_global_best < 0.1 * (ub - lb):  # Threshold for closeness\n                    repulsion_force = self.repulsion_strength * (population[i] - global_best_position) / (distance_to_global_best + 1e-8)\n                else:\n                    repulsion_force = 0.0\n\n                velocities[i] = (inertia[i] * velocities[i] +\n                                 self.cognitive * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social * r2 * (global_best_position - population[i]) +\n                                 repulsion_force) # Added repulsion force\n\n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n\n                # Cauchy mutation\n                if np.random.rand() < 0.1:\n                    cauchy_mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n                    new_position += cauchy_mutation\n                    new_position = np.clip(new_position, lb, ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n                population[i] = new_position\n\n            # Diversity maintenance (random restart of worst particle)\n            if np.std(fitness) < 1e-6:  # If particles are too similar\n                worst_index = np.argmax(fitness)\n                population[worst_index] = np.random.uniform(lb, ub, size=self.dim)\n                velocities[worst_index] = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=self.dim)\n                fitness[worst_index] = func(population[worst_index])\n                self.budget -= 1\n                personal_best_positions[worst_index] = population[worst_index].copy()\n                personal_best_fitnesses[worst_index] = fitness[worst_index]\n\n                if fitness[worst_index] < global_best_fitness:\n                    global_best_fitness = fitness[worst_index]\n                    global_best_position = population[worst_index].copy()\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 8, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["0028f65d-0379-4183-9acf-fdbe68feea0d"], "operator": null, "metadata": {}}
{"id": "636893f8-dacc-4b06-b291-1f2015dedeeb", "fitness": -Infinity, "name": "TopologicalCauchyPSO", "description": "Hybrid PSO with velocity clamping based on topological neighborhood diversity and a Cauchy mutation operator whose scale is adapted by the fitness improvement rate.", "code": "import numpy as np\n\nclass TopologicalCauchyPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, neighborhood_size=3, cauchy_scale_init=0.1, fitness_improvement_rate_weight=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n        self.cauchy_scale = cauchy_scale_init\n        self.fitness_improvement_rate_weight = fitness_improvement_rate_weight\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitnesses = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.fitness_history = np.zeros(pop_size)\n\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitnesses = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.global_best_fitness = self.fitness[global_best_index]\n        self.fitness_history = self.fitness.copy()\n\n\n    def update_velocity(self, i):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        \n        # Topological neighborhood best\n        neighborhood_indices = [(i + j) % self.pop_size for j in range(-self.neighborhood_size // 2, self.neighborhood_size // 2 + 1)]\n        neighborhood_fitnesses = self.personal_best_fitnesses[neighborhood_indices]\n        neighborhood_best_index = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n        neighborhood_best_position = self.personal_best_positions[neighborhood_best_index]\n        \n        self.velocities[i] = (self.inertia * self.velocities[i] +\n                             self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                             self.social_coeff * r2 * (neighborhood_best_position - self.population[i]))\n\n        # Velocity clamping based on topological diversity\n        distances = np.linalg.norm(self.population[neighborhood_indices] - self.population[i], axis=1)\n        diversity = np.std(distances)\n        max_velocity = (func.bounds.ub - func.bounds.lb) * (0.1 + diversity * 0.2)  # Scale max velocity by diversity\n        self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n\n    def mutate(self, i):\n        mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n        new_position = self.population[i] + mutation\n        return np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.budget > 0:\n            fitness_before = self.fitness.copy()\n\n            for i in range(self.pop_size):\n                self.update_velocity(i)\n                new_position = self.population[i] + self.velocities[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Cauchy Mutation\n                mutated_position = self.mutate(i)\n\n                new_fitness = func(new_position)\n                mutated_fitness = func(mutated_position)\n                self.budget -= 2\n\n                if new_fitness < mutated_fitness:\n                    candidate_position = new_position\n                    candidate_fitness = new_fitness\n                else:\n                    candidate_position = mutated_position\n                    candidate_fitness = mutated_fitness\n\n\n                if candidate_fitness < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = candidate_fitness\n                    self.personal_best_positions[i] = candidate_position.copy()\n                    \n                    if candidate_fitness < self.global_best_fitness:\n                        self.global_best_fitness = candidate_fitness\n                        self.global_best_position = candidate_position.copy()\n                \n                self.population[i] = candidate_position\n                self.fitness[i] = candidate_fitness\n\n            # Adapt Cauchy scale based on fitness improvement rate\n            fitness_improvement_rate = np.mean((fitness_before - self.fitness) / fitness_before)\n            self.cauchy_scale = max(0.001, self.cauchy_scale * np.exp(self.fitness_improvement_rate_weight * fitness_improvement_rate))  # Ensure cauchy_scale remains positive\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "An exception occurred: name 'func' is not defined.", "error": "", "parent_ids": ["a4a9d96d-2ba5-4e79-a83b-65c29bc9da27"], "operator": null, "metadata": {}}
{"id": "af3ef34e-8dc5-4bc5-9636-a151cf9ef115", "fitness": 0.0, "name": "AdaptiveSuccessPSO", "description": "Adaptive PSO with dynamic parameter adaptation, orthogonal learning, and velocity rescaling for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSuccessPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0, velocity_clamp=0.5, stagnation_limit=50, orthogonal_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.velocity_clamp = velocity_clamp\n        self.stagnation_limit = stagnation_limit  # Number of iterations without improvement\n        self.success_rate = 0.5 # initial success rate\n        self.success_rate_window = 10 # window size to measure the success rate\n        self.success_history = []\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.995\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        stagnation_counter = 0\n        best_fitness_history = [global_best_fitness]\n\n        while self.budget > 0:\n            \n            # Counters for success rate adaptation\n            success_count = 0\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                old_fitness = fitness[i]\n                \n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_max * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_max * r2 * (global_best_position - population[i]))\n                \n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                        \n                if new_fitness < old_fitness:\n                    success_count += 1 # Counting the successes\n                \n                population[i] = new_position\n                fitness[i] = new_fitness # Update fitness array\n\n            # Success rate adaptation\n            self.success_history.append(success_count / self.pop_size)\n            if len(self.success_history) > self.success_rate_window:\n                self.success_history.pop(0)\n\n            self.success_rate = np.mean(self.success_history)\n            \n            # Adjust cognitive and social coefficients based on success rate\n            if self.success_rate > 0.6:\n                self.cognitive_max *= 0.99  # Decrease cognitive influence\n                self.social_max *= 1.01   # Increase social influence\n            elif self.success_rate < 0.3:\n                self.cognitive_max *= 1.01  # Increase cognitive influence\n                self.social_max *= 0.99   # Decrease social influence\n\n            self.cognitive_max = np.clip(self.cognitive_max, 1.0, 2.0)\n            self.social_max = np.clip(self.social_max, 1.0, 2.0)\n\n            # Stagnation detection\n            if global_best_fitness >= best_fitness_history[-1]:\n                stagnation_counter += 1\n            else:\n                stagnation_counter = 0\n\n            best_fitness_history.append(global_best_fitness)\n\n            if stagnation_counter > self.stagnation_limit:\n                # Trigger re-exploration (e.g., re-initialize a portion of the population)\n                num_reinitialized = int(self.pop_size * 0.2)\n                indices_to_reinitialize = np.random.choice(self.pop_size, num_reinitialized, replace=False)\n                for i in indices_to_reinitialize:\n                    population[i] = np.random.uniform(lb, ub, size=self.dim)\n                    velocities[i] = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=self.dim)\n                    fitness[i] = func(population[i])\n                    self.budget -= 1\n                    personal_best_positions[i] = population[i].copy()\n                    personal_best_fitnesses[i] = fitness[i]\n\n                stagnation_counter = 0 # Reset the counter\n            \n            # Orthogonal Learning Strategy\n            for i in range(self.pop_size):\n                # Select two random particles (excluding the current particle)\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                particle1 = population[indices[0]]\n                particle2 = population[indices[1]]\n\n                # Generate an orthogonal direction\n                orthogonal_direction = particle1 - particle2\n\n                # Create a new candidate solution\n                new_candidate = population[i] + self.orthogonal_learning_rate * orthogonal_direction\n\n                # Clip the new candidate within the bounds\n                new_candidate = np.clip(new_candidate, lb, ub)\n\n                # Evaluate the new candidate\n                new_fitness_orthogonal = func(new_candidate)\n                self.budget -= 1\n\n                # Replace the current particle if the new candidate is better\n                if new_fitness_orthogonal < fitness[i]:\n                    population[i] = new_candidate\n                    fitness[i] = new_fitness_orthogonal\n                    personal_best_positions[i] = new_candidate.copy()\n                    personal_best_fitnesses[i] = new_fitness_orthogonal\n                    if new_fitness_orthogonal < global_best_fitness:\n                        global_best_fitness = new_fitness_orthogonal\n                        global_best_position = new_candidate.copy()\n\n            # Velocity Rescaling\n            velocities = velocities * (1 - self.success_rate) # Reduce velocities when success rate is low\n\n            self.inertia_weight *= self.inertia_decay # Decrease inertia weight\n\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveSuccessPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["93ddbc1d-d3c4-48b0-8c20-593571911126"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "c977c320-aa20-40ca-bd9d-f00a027c9c8c", "fitness": 0.30876942798655665, "name": "AdaptivePSO", "description": "Simplified PSO with adaptive exploration/exploitation balance based on population diversity and a restart mechanism upon stagnation.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive=2.0, social=2.0, inertia=0.9, stagnation_limit=50, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive = cognitive\n        self.social = social\n        self.inertia = inertia\n        self.stagnation_limit = stagnation_limit\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        stagnation_counter = 0\n\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (self.inertia * velocities +\n                          self.cognitive * r1 * (personal_best_positions - population) +\n                          self.social * r2 * (global_best_position - population))\n            \n            population = population + velocities\n            population = np.clip(population, lb, ub)\n            \n            new_fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n\n            # Update personal and global bests\n            improved = new_fitness < personal_best_fitnesses\n            personal_best_fitnesses[improved] = new_fitness[improved]\n            personal_best_positions[improved] = population[improved].copy()\n\n            if np.min(new_fitness) < global_best_fitness:\n                global_best_fitness = np.min(new_fitness)\n                global_best_position = population[np.argmin(new_fitness)].copy()\n                stagnation_counter = 0  # Reset stagnation counter\n            else:\n                stagnation_counter += 1\n\n            fitness = new_fitness\n\n            # Stagnation check and re-initialization\n            if stagnation_counter > self.stagnation_limit:\n                # Check population diversity\n                diversity = np.std(population)\n                if diversity < self.diversity_threshold:\n                    # Re-initialize a portion of the population\n                    num_reinitialized = int(self.pop_size * 0.3)\n                    indices_to_reinitialize = np.random.choice(self.pop_size, num_reinitialized, replace=False)\n                    population[indices_to_reinitialize] = np.random.uniform(lb, ub, size=(num_reinitialized, self.dim))\n                    velocities[indices_to_reinitialize] = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(num_reinitialized, self.dim))\n                    fitness[indices_to_reinitialize] = np.array([func(x) for x in population[indices_to_reinitialize]])\n                    self.budget -= num_reinitialized\n                    personal_best_positions[indices_to_reinitialize] = population[indices_to_reinitialize].copy()\n                    personal_best_fitnesses[indices_to_reinitialize] = fitness[indices_to_reinitialize].copy()\n                stagnation_counter = 0  # Reset stagnation counter\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptivePSO scored 0.309 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["93ddbc1d-d3c4-48b0-8c20-593571911126"], "operator": null, "metadata": {"aucs": [0.13862785993197924, 0.19543439202569768, 0.29541060537368324, 0.307200565955296, 0.23912744945113484, 0.24762560232640307, 0.26020255534560743, 0.2598835954092502, 0.22378806883086455, 0.16840702017610287, 0.2317174305923526, 0.9980951953954906, 0.21581366688273718, 0.24190137512393806, 0.5477006103115776, 0.3184374436877221, 0.27930044648973584, 0.33582598661828233, 0.2013171883026098, 0.4695715015006686]}}
{"id": "d1c94e9e-7e19-4ccc-967a-314af1bc0e42", "fitness": 0.47712082631710884, "name": "RepulsivePSO", "description": "An adaptive PSO variant that incorporates a repulsive force from the worst performing particles to improve exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass RepulsivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0, repulsive_factor=0.1, inertia_weight=0.7, damping_factor=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.repulsive_factor = repulsive_factor\n        self.inertia_weight = inertia_weight\n        self.damping_factor = damping_factor\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Find worst particle\n            worst_index = np.argmax(fitness)\n            worst_position = population[worst_index].copy()\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Repulsive force\n                repulsion = self.repulsive_factor * np.random.rand(self.dim) * (population[i] - worst_position)\n\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_max * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_max * r2 * (global_best_position - population[i]) +\n                                 repulsion)\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness\n            \n            # Dampen inertia weight\n            self.inertia_weight *= self.damping_factor\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm RepulsivePSO scored 0.477 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["652c14c9-0ba1-4bed-8677-dfd3eaddad00"], "operator": null, "metadata": {"aucs": [0.17649170299796169, 0.2235696058648694, 0.5176239989557119, 0.24069976980248964, 0.5254673350010513, 0.7275595069611067, 0.3402832828542872, 0.5169189975525534, 0.6088920104561499, 0.1877140890361927, 0.908589602196239, 0.9976591824712732, 0.2724011523592611, 0.2913732518020312, 0.6494962916120228, 0.6384814907846625, 0.42910652238589664, 0.3799086203894785, 0.4541577361562529, 0.4560223767026842]}}
{"id": "bb272894-be71-4547-aea6-028ebef809e4", "fitness": 0.4739156235976698, "name": "AdaptiveMutationPSO", "description": "Simplified Adaptive Mutation PSO with dynamic inertia and learning rate, focusing on efficiency and balancing exploration/exploitation.", "code": "import numpy as np\n\nclass AdaptiveMutationPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_start=0.9, inertia_end=0.4, cognitive_coeff=2.0, social_coeff=2.0, mutation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_start = inertia_start\n        self.inertia_end = inertia_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.mutation_rate = mutation_rate\n        self.learning_rate = 0.5\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        while self.budget > 0:\n            inertia = self.inertia_start - (self.inertia_start - self.inertia_end) * (1 - self.budget / 10000) #Dynamic Inertia\n\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (inertia * velocities[i] +\n                                 self.learning_rate * self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.learning_rate * self.social_coeff * r2 * (global_best_position - population[i]))\n                \n                new_position = np.clip(population[i] + velocities[i], lb, ub)\n                \n                # Mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.uniform(lb, ub, size=self.dim)\n                    new_position = (1 - self.mutation_rate) * new_position + self.mutation_rate * mutation # Blend with mutation\n                    new_position = np.clip(new_position, lb, ub)\n                    \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n\n            #Adaptive learning rate (simple)\n            if global_best_fitness == np.min(personal_best_fitnesses):\n                self.learning_rate *= 1.05 #increase learning rate when there is exploitation\n                self.learning_rate = min(self.learning_rate, 1.0)\n            else:\n                self.learning_rate *= 0.95 # decrease learning rate when exploration is needed\n                self.learning_rate = max(self.learning_rate, 0.1)\n                \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveMutationPSO scored 0.474 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a4a9d96d-2ba5-4e79-a83b-65c29bc9da27"], "operator": null, "metadata": {"aucs": [0.1658950724060867, 0.383733318135253, 0.4693584357472974, 0.7081844412555609, 0.46696628085737313, 0.5204199409032213, 0.32675908516843977, 0.41799366930062165, 0.4754085239614131, 0.3520867001250565, 0.641833296710294, 0.996498987823173, 0.2475868655594684, 0.4200959103014268, 0.7612670589502366, 0.3731134782464641, 0.3613057681589529, 0.6223929428202695, 0.27439178508987805, 0.4930209104329084]}}
{"id": "7734ae5a-9612-438a-acaa-516439cefab7", "fitness": 0.5774003464731189, "name": "AdaptiveMutationPSO", "description": "Simplified PSO with adaptive learning rates based on particle success and a decaying mutation rate for exploration.", "code": "import numpy as np\n\nclass AdaptiveMutationPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=2.0, social_coeff=2.0, initial_mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.mutation_rate = initial_mutation_rate\n        self.initial_mutation_rate = initial_mutation_rate\n        self.success_rates = np.zeros(pop_size)\n        self.learning_rates = np.ones(pop_size) * 0.5\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        success_counts = np.zeros(self.pop_size)\n\n        while self.budget > 0:\n            #Decay the mutation rate\n            self.mutation_rate = self.initial_mutation_rate * (self.budget / 10000)\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.learning_rates[i] * self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.learning_rates[i] * self.social_coeff * r2 * (global_best_position - population[i]))\n                \n                new_position = np.clip(population[i] + velocities[i], lb, ub)\n                \n                # Mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.uniform(lb, ub, size=self.dim)\n                    new_position = (1 - self.mutation_rate) * new_position + self.mutation_rate * mutation # Blend with mutation\n                    new_position = np.clip(new_position, lb, ub)\n                    \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < personal_best_fitnesses[i]:\n                    success_counts[i] += 1\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                population[i] = new_position\n                fitness[i] = new_fitness\n\n            # Update learning rates based on success rates, simplified averaging\n            self.success_rates = 0.8 * self.success_rates + 0.2 * success_counts\n            self.learning_rates = np.clip(self.success_rates / np.mean(self.success_rates), 0.1, 1.0)\n            success_counts[:] = 0\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveMutationPSO scored 0.577 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a4a9d96d-2ba5-4e79-a83b-65c29bc9da27"], "operator": null, "metadata": {"aucs": [0.25646392070155266, 0.18712106937485895, 0.6500257822699584, 0.9353499997546713, 0.5472757111138136, 0.7309148431256214, 0.32443215419412386, 0.594675935777448, 0.6244596655430912, 0.2191633057397161, 0.8904180002382416, 0.9967104005064675, 0.2259227114020308, 0.6611372470951867, 0.8987411020697653, 0.7381150205239041, 0.511541850950767, 0.8253943954446104, 0.24106629558141957, 0.48907751805513155]}}
{"id": "97dff9bc-71de-4dc9-8818-619276cc5b7b", "fitness": 0.5310105679269631, "name": "RingTopologyAdaptiveCauchyPSO", "description": "A PSO variant with a ring topology, adaptive inertia weight, and a Cauchy mutation operator applied probabilistically based on particle stagnation.", "code": "import numpy as np\n\nclass RingTopologyAdaptiveCauchyPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=2.0, social_coeff=2.0, stagnation_threshold=10, cauchy_mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.stagnation_threshold = stagnation_threshold\n        self.cauchy_mutation_rate = cauchy_mutation_rate\n        self.stagnation_counters = np.zeros(pop_size)\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        while self.budget > 0:\n            # Adaptive Inertia Weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (self.budget / 10000)\n\n            for i in range(self.pop_size):\n                # Ring Topology: Neighbors are i-1 and i+1 (with wrap-around)\n                neighbor_left = (i - 1) % self.pop_size\n                neighbor_right = (i + 1) % self.pop_size\n\n                # Determine the best neighbor\n                if personal_best_fitnesses[neighbor_left] < personal_best_fitnesses[neighbor_right]:\n                    best_neighbor_position = personal_best_positions[neighbor_left]\n                else:\n                    best_neighbor_position = personal_best_positions[neighbor_right]\n                \n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (inertia * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * r2 * (best_neighbor_position - population[i]))\n                \n                new_position = np.clip(population[i] + velocities[i], lb, ub)\n                \n                # Cauchy Mutation based on stagnation\n                if self.stagnation_counters[i] > self.stagnation_threshold and np.random.rand() < self.cauchy_mutation_rate:\n                    cauchy_mutation = np.random.standard_cauchy(size=self.dim) * (ub - lb) * 0.01 # Scale cauchy\n                    new_position = np.clip(new_position + cauchy_mutation, lb, ub)\n                    \n\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    self.stagnation_counters[i] = 0  # Reset stagnation counter\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                else:\n                    self.stagnation_counters[i] += 1\n                \n                population[i] = new_position\n                fitness[i] = new_fitness\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm RingTopologyAdaptiveCauchyPSO scored 0.531 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a4a9d96d-2ba5-4e79-a83b-65c29bc9da27"], "operator": null, "metadata": {"aucs": [0.20172221110335864, 0.1894388414489877, 0.5290111371909219, 0.9242102973459857, 0.5463786887150424, 0.728127710481155, 0.335355107875716, 0.4194543562098564, 0.6213901904898924, 0.21968907652747238, 0.8048393358903885, 0.9964997205510463, 0.3163129773360859, 0.39515460374849665, 0.7359391543325868, 0.6744062468015113, 0.42018769792269717, 0.7947697882073068, 0.2680867435766787, 0.4992374727840777]}}
{"id": "7cc40d72-4e57-4c52-94b2-0adfe6d64256", "fitness": 0.5757479829471032, "name": "AdaptiveSuccessPSO", "description": "PSO with success-rate-based adaptation of cognitive/social coefficients, velocity clamping based on diversity, and a restart mechanism when stagnation is detected, and a decay of exploration to enhance exploitation.", "code": "import numpy as np\n\nclass AdaptiveSuccessPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0, initial_velocity_clamp=0.5, success_rate_window=10, stagnation_threshold=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.velocity_clamp = initial_velocity_clamp  # Initial velocity clamping\n        self.success_rate_window = success_rate_window\n        self.success_rates = np.zeros(pop_size)\n        self.success_counts = np.zeros(pop_size)\n        self.iteration_count = 0\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.exploration_decay = 0.99  # Decay exploration rate\n        self.exploration_rate = 1.0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        inertia_weight = 0.9  # Initial inertia weight\n        inertia_decay = 0.995 # Inertia decay rate\n\n        while self.budget > 0:\n            # Sort fitnesses and get ranks\n            ranked_indices = np.argsort(fitness)\n            ranks = np.empty_like(ranked_indices)\n            ranks[ranked_indices] = np.arange(self.pop_size)\n\n            # Normalize ranks to [0, 1]\n            normalized_ranks = ranks / (self.pop_size - 1)\n            \n            # Adaptive coefficients based on success rate\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * (1 - self.success_rates)\n            social_coeffs = 1.0 + (self.social_max - 1.0) * self.success_rates\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n                \n                # Adaptive velocity clamping based on population diversity and exploration rate\n                diversity = np.mean(np.std(population, axis=0))\n                velocity_clamp = self.velocity_clamp * (1 + diversity) * self.exploration_rate # Increase clamp if diversity is high\n                \n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -velocity_clamp * (ub - lb), velocity_clamp * (ub - lb))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    self.success_counts[i] += 1\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                else:\n                     self.stagnation_counter += 1\n                \n                population[i] = new_position\n                fitness[i] = new_fitness # Update fitness array\n\n            inertia_weight *= inertia_decay # Decrease inertia weight\n            self.exploration_rate *= self.exploration_decay  # Decay exploration rate\n            \n            # Update success rates every window size iterations\n            if self.iteration_count % self.success_rate_window == 0:\n                self.success_rates = self.success_counts / self.success_rate_window\n                self.success_counts[:] = 0  # Reset success counts\n            \n            # Stagnation detection and restart\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Restart the population around the current best\n                population = np.random.normal(global_best_position, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n                population = np.clip(population, lb, ub)\n\n                # Re-evaluate population\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                personal_best_positions = population.copy()\n                personal_best_fitnesses = fitness.copy()\n\n                global_best_index = np.argmin(fitness)\n                global_best_position = population[global_best_index].copy()\n                global_best_fitness = fitness[global_best_index]\n\n                velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n                self.stagnation_counter = 0\n                self.exploration_rate = 1.0  # Reset exploration rate\n\n            \n            self.iteration_count += 1\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveSuccessPSO scored 0.576 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["652c14c9-0ba1-4bed-8677-dfd3eaddad00"], "operator": null, "metadata": {"aucs": [0.22921636791459765, 0.2186385291324826, 0.8246756896698242, 0.8722393740754936, 0.8154202329224329, 0.8323567722520826, 0.3342022161785939, 0.5983801423034898, 0.844221402272972, 0.7638770856961654, 0]}}
{"id": "2624e7c3-75a3-42e2-9270-a9475be16690", "fitness": 0.6457775266787098, "name": "AdaptiveSuccessPSO_Enhanced", "description": "PSO with adaptive coefficients based on a combination of success rate and distance to the global best, employing a dynamic local search intensification based on particle fitness ranking.", "code": "import numpy as np\n\nclass AdaptiveSuccessPSO_Enhanced:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0,\n                 initial_velocity_clamp=0.5, success_rate_window=10, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.velocity_clamp = initial_velocity_clamp\n        self.success_rate_window = success_rate_window\n        self.success_rates = np.zeros(pop_size)\n        self.success_counts = np.zeros(pop_size)\n        self.iteration_count = 0\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n\n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Optimization loop\n        inertia_weight = 0.9\n        inertia_decay = 0.995\n\n        while self.budget > 0:\n            # Sort fitnesses and get ranks\n            ranked_indices = np.argsort(fitness)\n            ranks = np.empty_like(ranked_indices)\n            ranks[ranked_indices] = np.arange(self.pop_size)\n\n            # Normalize ranks to [0, 1]\n            normalized_ranks = ranks / (self.pop_size - 1)\n\n            # Adaptive coefficients based on success rate and distance to global best\n            distance_to_global_best = np.linalg.norm(population - global_best_position, axis=1)\n            normalized_distances = distance_to_global_best / np.max(distance_to_global_best)  # Normalize distances\n\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * (1 - self.success_rates) * normalized_distances\n            social_coeffs = 1.0 + (self.social_max - 1.0) * self.success_rates * (1 - normalized_distances)\n\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n\n                # Adaptive velocity clamping based on population diversity\n                diversity = np.mean(np.std(population, axis=0))\n                velocity_clamp = self.velocity_clamp * (1 + diversity)\n\n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -velocity_clamp * (ub - lb), velocity_clamp * (ub - lb))\n\n                # Update position\n                new_position = population[i] + velocities[i]\n\n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n\n                # Local search intensification based on rank\n                if np.random.rand() < self.local_search_probability * (1 - normalized_ranks[i]):  # Higher ranked particles have higher probability\n                    # Perform a small random perturbation around the current position\n                    perturbation = np.random.uniform(-0.05 * (ub - lb), 0.05 * (ub - lb), size=self.dim)  # Smaller perturbation\n                    new_position = np.clip(new_position + perturbation, lb, ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    self.success_counts[i] += 1\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n                population[i] = new_position\n                fitness[i] = new_fitness  # Update fitness array\n\n            inertia_weight *= inertia_decay  # Decrease inertia weight\n\n            # Update success rates every window size iterations\n            if self.iteration_count % self.success_rate_window == 0:\n                self.success_rates = self.success_counts / self.success_rate_window\n                self.success_counts[:] = 0  # Reset success counts\n\n            self.iteration_count += 1\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveSuccessPSO_Enhanced scored 0.646 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["652c14c9-0ba1-4bed-8677-dfd3eaddad00"], "operator": null, "metadata": {"aucs": [0.17364312378051983, 0.2511960473069952, 0.7387339456281705, 0.9226278905304475, 0.8302678077753375, 0.7985827037243216, 0.32910250157891996, 0.5325767180559845, 0.8375514511274044, 0.8029466202127831, 0.8585920146711326, 0.9957016704676327, 0.2577558938791129, 0.5714136217557485, 0.831600971222395, 0.8441465858904459, 0.6176918004237784, 0.8938750217155754, 0.33764658380943646, 0.4898975600180583]}}
{"id": "e177efeb-4216-44f6-a9f5-acc0a52f0aa9", "fitness": 0.12680234793738832, "name": "AdaptiveSuccessPSO", "description": "PSO with adaptive parameters and a novel restart strategy based on the fitness landscape, promoting exploration in promising regions.", "code": "import numpy as np\n\nclass AdaptiveSuccessPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0, velocity_clamp=0.5, stagnation_limit=50, restart_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.velocity_clamp = velocity_clamp\n        self.stagnation_limit = stagnation_limit\n        self.success_rate = 0.5\n        self.success_rate_window = 10\n        self.success_history = []\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.995\n        self.restart_probability = restart_probability # Probability of restarting a particle near a better particle.\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        # Optimization loop\n        stagnation_counter = 0\n        best_fitness_history = [global_best_fitness]\n\n        while self.budget > 0:\n            \n            # Counters for success rate adaptation\n            success_count = 0\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                old_fitness = fitness[i]\n                \n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_max * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_max * r2 * (global_best_position - population[i]))\n                \n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                        \n                if new_fitness < old_fitness:\n                    success_count += 1\n                \n                population[i] = new_position\n                fitness[i] = new_fitness\n\n            # Success rate adaptation\n            self.success_history.append(success_count / self.pop_size)\n            if len(self.success_history) > self.success_rate_window:\n                self.success_history.pop(0)\n\n            self.success_rate = np.mean(self.success_history)\n            \n            # Adjust cognitive and social coefficients based on success rate\n            if self.success_rate > 0.6:\n                self.cognitive_max *= 0.99\n                self.social_max *= 1.01\n            elif self.success_rate < 0.3:\n                self.cognitive_max *= 1.01\n                self.social_max *= 0.99\n\n            self.cognitive_max = np.clip(self.cognitive_max, 1.0, 2.0)\n            self.social_max = np.clip(self.social_max, 1.0, 2.0)\n\n            # Stagnation detection\n            if global_best_fitness >= best_fitness_history[-1]:\n                stagnation_counter += 1\n            else:\n                stagnation_counter = 0\n\n            best_fitness_history.append(global_best_fitness)\n\n            if stagnation_counter > self.stagnation_limit:\n                # Restart strategy based on fitness landscape\n                for i in range(self.pop_size):\n                    if np.random.rand() < self.restart_probability:\n                        # Find a better particle to restart near\n                        better_indices = np.where(fitness < fitness[i])[0]\n                        if len(better_indices) > 0:\n                            chosen_index = np.random.choice(better_indices)\n                            # Restart near the chosen particle\n                            population[i] = np.random.normal(population[chosen_index], (ub - lb) * 0.05, size=self.dim)\n                            population[i] = np.clip(population[i], lb, ub)\n                        else:\n                            # If no better particle, restart randomly\n                            population[i] = np.random.uniform(lb, ub, size=self.dim)\n\n                        velocities[i] = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=self.dim)\n                        fitness[i] = func(population[i])\n                        self.budget -= 1\n                        personal_best_positions[i] = population[i].copy()\n                        personal_best_fitnesses[i] = fitness[i]\n\n                stagnation_counter = 0 # Reset the counter\n                \n            self.inertia_weight *= self.inertia_decay # Decrease inertia weight\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveSuccessPSO scored 0.127 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["93ddbc1d-d3c4-48b0-8c20-593571911126"], "operator": null, "metadata": {"aucs": [0.25360469587477663, 0]}}
{"id": "7b2150dd-a29d-427d-961f-b43654012174", "fitness": 0.5115200667571529, "name": "RingTopologyAdaptivePSO", "description": "A PSO variant that uses a ring topology with adaptive inertia weight and velocity clamping based on particle fitness and neighborhood best fitness, enhancing both exploration and exploitation.", "code": "import numpy as np\n\nclass RingTopologyAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive=2.0, social=2.0, w_max=0.9, w_min=0.4, velocity_clamp_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive = cognitive\n        self.social = social\n        self.w_max = w_max\n        self.w_min = w_min\n        self.velocity_clamp_factor = velocity_clamp_factor\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * self.velocity_clamp_factor, (ub - lb) * self.velocity_clamp_factor, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal bests\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n        \n        # Ring topology: each particle's neighborhood consists of its two immediate neighbors\n        neighborhood_size = 2\n\n        def get_neighborhood_best(index):\n            # Identify neighbors (wrap around the population)\n            neighbors = [(index - i) % self.pop_size for i in range(neighborhood_size // 2 + 1, 0, -1)]  # Previous neighbors\n            neighbors += [(index + i) % self.pop_size for i in range(1, neighborhood_size // 2 + 1)]  # Next neighbors\n            neighbors.append(index) # Include itself\n\n            # Find the best fitness among the neighbors\n            best_neighbor = min(neighbors, key=lambda n: personal_best_fitnesses[n])\n            return personal_best_positions[best_neighbor].copy(), personal_best_fitnesses[best_neighbor]\n\n        # Find initial global best (used only for initialization purposes)\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Get neighborhood best\n                neighborhood_best_position, neighborhood_best_fitness = get_neighborhood_best(i)\n\n                # Adaptive inertia weight\n                inertia = self.w_max - (self.w_max - self.w_min) * (fitness[i] - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-8) # Adapt inertia based on particle fitness\n\n                # Update velocities and positions\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (inertia * velocities[i] +\n                                 self.cognitive * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social * r2 * (neighborhood_best_position - population[i]))\n                \n                # Velocity clamping\n                v_max = (ub - lb) * self.velocity_clamp_factor\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                \n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    # No global best since it uses neighborhood best\n                    #if new_fitness < global_best_fitness: # Update global best\n                    #    global_best_fitness = new_fitness\n                    #    global_best_position = new_position.copy()\n\n                population[i] = new_position\n            \n        # Determine the overall best after all iterations based on personal bests:\n        best_index = np.argmin(personal_best_fitnesses)\n        return personal_best_fitnesses[best_index], personal_best_positions[best_index]", "configspace": "", "generation": 8, "feedback": "The algorithm RingTopologyAdaptivePSO scored 0.512 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0028f65d-0379-4183-9acf-fdbe68feea0d"], "operator": null, "metadata": {"aucs": [0.18878298877448974, 0.334071565851658, 0.5409524575193132, 0.19574520462078204, 0.5039396852095495, 0.851186168189999, 0.38296640590850506, 0.46078939807365626, 0.6338981805667411, 0.20360083536292428, 0.8921162549448354, 0.9865006866501734, 0.2661300363660465, 0.3379610165848672, 0.8279193773850971, 0.6450396570792809, 0.4111043651850549, 0.8456294640219945, 0.21427732755115403, 0.5077902592969363]}}
