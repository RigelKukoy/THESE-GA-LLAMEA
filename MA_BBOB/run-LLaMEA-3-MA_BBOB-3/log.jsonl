{"id": "18001ba9-f504-4512-bbd7-60578e2970c0", "fitness": 0.0, "name": "AdaptiveStepSize", "description": "Adaptively adjusts the step size for each dimension based on the success rate of previous steps, promoting exploration in promising directions.", "code": "import numpy as np\n\nclass AdaptiveStepSize:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, success_threshold=0.1, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.step_sizes = np.full(dim, initial_step_size)\n        self.successes = np.zeros(dim)\n        self.trials = np.zeros(dim)\n        self.success_threshold = success_threshold\n        self.adaptation_rate = adaptation_rate\n        self.x_opt = None\n        self.f_opt = np.Inf\n\n    def __call__(self, func):\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub)\n        self.f_opt = func(x)\n        self.x_opt = x\n        \n        for i in range(self.budget):\n            # Choose a dimension to perturb\n            dim_index = i % self.dim\n\n            # Generate a perturbation\n            step = np.random.normal(0, self.step_sizes[dim_index], 1)[0]\n            \n            x_new = x.copy()\n            x_new[dim_index] += step\n\n            # Clip to bounds\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(x_new)\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                x = x_new\n                self.x_opt = x\n                self.successes[dim_index] += 1\n            \n            self.trials[dim_index] += 1\n            \n            # Adapt step sizes based on success rate\n            success_rate = self.successes[dim_index] / self.trials[dim_index] if self.trials[dim_index] > 0 else 0\n            \n            if success_rate > self.success_threshold:\n                self.step_sizes[dim_index] *= (1 + self.adaptation_rate)\n            else:\n                self.step_sizes[dim_index] *= (1 - self.adaptation_rate)\n            \n            # Ensure step sizes stay within reasonable bounds\n            self.step_sizes[dim_index] = np.clip(self.step_sizes[dim_index], 1e-6, abs(func.bounds.ub[0] - func.bounds.lb[0]))\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveStepSize scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}}
{"id": "d714da31-472b-4fd1-a69c-8415ef26fb87", "fitness": -Infinity, "name": "CMAES_with_Archive", "description": "Covariance matrix adaptation evolution strategy with adaptive population size and archive for diversity maintenance.", "code": "import numpy as np\n\nclass CMAES_with_Archive:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=None, c_cov=None, archive_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)  # Mean value\n        self.sigma = 0.5 # Overall standard deviation\n        self.C = np.eye(self.dim)    # Covariance matrix\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + 1 / (16 * self.dim**2))\n\n        self.cs = cs\n        self.damps = damp if damp is not None else 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.cs\n        self.cc = (4 + self.mu / self.dim) / (self.dim + 4 + 2 * self.mu / self.dim)\n        self.c_cov = c_cov if c_cov is not None else (1 / (self.dim * np.sqrt(self.dim))) if self.mu == 1 else ((1 / (10 + self.dim / 3)) if (self.mu == self.popsize) else (1 / (2 + self.mu / self.dim)**2 + self.mu / self.dim))\n        self.c_cov_mu = self.c_cov\n        self.archive = []\n        self.archive_size = archive_size\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        used_budget = 0\n\n        while used_budget < self.budget:\n            # 1. Sample population\n            z = np.random.randn(self.dim, self.popsize)\n            x = self.m[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # 2. Evaluate population\n            f = np.array([func(xi) for xi in x.T])\n            used_budget += self.popsize\n\n            # 3. Sort by fitness\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n\n            # 4. Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n\n            # 5. Update distribution parameters\n            xmean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n            \n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), (xmean - self.m) / self.sigma)\n            self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc)) * (xmean - self.m) / self.sigma\n\n            # Update mean\n            self.m = xmean\n\n            # Update covariance matrix\n            dC = (self.c_cov * (1 / self.sigma**2)) * (np.outer(self.pc, self.pc) - (1 - self.cc)**2 * self.C) \n            \n            artmp = (1 / self.sigma) * (x[:, :self.mu] - self.m[:, np.newaxis])\n            dC = dC + self.c_cov_mu * np.sum(self.weights[np.newaxis, np.newaxis, :] * (artmp[:, :, :] @ artmp[:, :, :].transpose(0, 2, 1)), axis=2)\n\n            self.C = self.C + dC\n\n            # Keep covariance matrix positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            \n            e, v = np.linalg.eigh(self.C)\n            e[e < 0] = 1e-8\n            self.C = v @ np.diag(e) @ v.T\n\n            # Update step size\n            self.sigma = self.sigma * np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.sigma = np.clip(self.sigma, 1e-10, 1e10)\n\n            # Archive: Store diverse solutions\n            for xi in x.T:\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(xi)\n                else:\n                    # Replace the most similar solution in the archive\n                    distances = [np.linalg.norm(xi - archived_xi) for archived_xi in self.archive]\n                    max_idx = np.argmax(distances)  # Replace the solution that's most different.\n                    self.archive[max_idx] = xi\n            \n            if used_budget >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "3c40a18c-32a0-4240-90f3-952dcb978967", "fitness": 0.4883214610110449, "name": "HybridPSO_DE", "description": "A population-based algorithm that combines elements of particle swarm optimization and differential evolution, with a focus on exploration and exploitation balance using adaptive parameter control.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, F=0.8, CR=0.9):\n        \"\"\"\n        Initializes the Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.best_pos = self.pop.copy()\n        self.best_fitness = np.array([np.inf] * self.pop_size)\n\n\n    def evaluate_population(self, func):\n         \"\"\"\n         Evaluates the fitness of each particle in the population.\n         \"\"\"\n         for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness[i]:\n                    self.best_fitness[i] = f\n                    self.best_pos[i] = self.pop[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                 break\n\n    def update_velocities(self):\n        \"\"\"\n        Updates the velocities of the particles using PSO equations.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n        cognitive_component = self.c1 * r1 * (self.best_pos - self.pop)\n        social_component = self.c2 * r2 * (self.global_best_pos - self.pop)\n        self.velocities = self.w * self.velocities + cognitive_component + social_component\n\n    def differential_evolution(self, func):\n        \"\"\"\n        Applies differential evolution to the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    trial[j] = mutant[j]\n\n            # Selection\n            f_trial = func(trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial\n                self.fitness[i] = f_trial\n                if f_trial < self.best_fitness[i]:\n                    self.best_fitness[i] = f_trial\n                    self.best_pos[i] = self.pop[i].copy()\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_pos = self.pop[i].copy()\n\n    def constrain(self, func):\n         self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.evaluate_population(func)\n        \n        while self.eval_count < self.budget:\n            self.update_velocities()\n            self.pop += self.velocities\n            self.constrain(func)\n            self.evaluate_population(func)\n            self.differential_evolution(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE scored 0.488 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1610925752542688, 0.45694179042185057, 0.6856251155840595, 0.8671895911295494, 0.25751729385684796, 0.7929763447081362, 0.33140584583914523, 0.6738638851545127, 0.7156022727661756, 0.2002963566500524, 0.2791406553036878, 0.9987517146272233, 0.2805220272393496, 0.2775963715486307, 0.6477244644312325, 0.36079919630480384, 0.5932740092760469, 0.3806758413909457, 0.30612965731676645, 0.49930421141761294]}}
{"id": "a45e875d-6dc9-49e7-851d-a7371a343e34", "fitness": 0.7018766387465949, "name": "CMAES", "description": "Covariance Matrix Adaptation Evolution Strategy with resampling and budget-aware adaptation of parameters.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = cs\n        self.damps = damp if damp is not None else 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.sigma = 0.5\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n        self.invsqrtC = np.eye(self.dim)\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.mean = np.zeros(self.dim)\n        self.evals = 0\n        self.lb = -5\n        self.ub = 5\n        self.tolx = 1e-12 * (self.ub - self.lb)\n        self.tolxup = 1e4\n\n    def sample(self):\n        z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n        x = self.mean[:, np.newaxis] + self.sigma * (self.B @ (self.D[:, np.newaxis] * z))\n        x = np.clip(x, self.lb, self.ub)\n        return x\n\n    def update(self, x, fvals):\n        arindex = np.argsort(fvals)\n        x = x[:, arindex]\n        xmean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n        y = (x[:, :self.mu] - self.mean[:, np.newaxis]) / self.sigma\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * self.invsqrtC @ (xmean - self.mean) / self.sigma\n        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.evals / self.popsize))) < (1.4 + 2 / (self.dim + 1)) * self.chiN\n        self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (xmean - self.mean) / self.sigma\n        \n        C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) + self.cmu * (y @ np.diag(self.weights) @ y.T)\n\n        self.mean = xmean\n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n        self.C = np.triu(C) + np.triu(C, 1).T\n        self.D, self.B = np.linalg.eig(self.C)\n        self.D = np.sqrt(np.real(self.D))\n        self.B = np.real(self.B)\n        self.invsqrtC = self.B @ np.diag(self.D**-1) @ self.B.T\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n\n        while self.evals < self.budget:\n            x = self.sample()\n            fvals = np.array([func(x[:, i]) for i in range(self.popsize)])\n            self.evals += self.popsize\n\n            for i in range(self.popsize):\n                if fvals[i] < self.f_opt:\n                    self.f_opt = fvals[i]\n                    self.x_opt = x[:, i]\n\n            self.update(x, fvals)\n            \n            if np.max(self.D) > self.tolxup * np.min(self.D):\n                self.sigma *= 0.5\n                self.C = np.eye(self.dim)\n                self.B = np.eye(self.dim)\n                self.D = np.ones(self.dim)\n                self.invsqrtC = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n\n            if np.any(self.D < self.tolx):\n                self.D[self.D < self.tolx] = self.tolx\n                self.C = self.B @ np.diag(self.D**2) @ self.B.T\n                self.invsqrtC = self.B @ np.diag(self.D**-1) @ self.B.T\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CMAES scored 0.702 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.24017470277285324, 0.9485567274474873, 0.9410130206903933, 0.17973241258977246, 0.9481481068611346, 0.9545769740886243, 0.3309253192950843, 0.9345256000761084, 0.33210206054694535, 0.12931548754787325, 0.9722332270764235, 0.9526130850624274, 0.8060768342283848, 0.9501819514331962, 0.9748369437708067, 0.913259752234073, 0.9292139537063241, 0.9781116918969792, 0.1397669274655151, 0.482167996141491]}}
{"id": "24c3f0ae-22cc-4077-8905-04766cffa673", "fitness": 0.0, "name": "AdaptiveStepSize", "description": "Adaptively adjusts step sizes for each dimension based on a simplified success rate calculation, aiming for efficient exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveStepSize:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.step_sizes = np.full(dim, initial_step_size)\n        self.adaptation_rate = adaptation_rate\n        self.x_opt = None\n        self.f_opt = np.Inf\n\n    def __call__(self, func):\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub)\n        self.f_opt = func(x)\n        self.x_opt = x\n        success_counts = np.zeros(self.dim)\n\n        for i in range(self.budget):\n            dim_index = i % self.dim\n            step = np.random.normal(0, self.step_sizes[dim_index])\n            x_new = x.copy()\n            x_new[dim_index] += step\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                x = x_new\n                self.x_opt = x\n                success_counts[dim_index] += 1\n                self.step_sizes[dim_index] *= (1 + self.adaptation_rate)\n            else:\n                self.step_sizes[dim_index] *= (1 - self.adaptation_rate)\n\n            self.step_sizes[dim_index] = np.clip(self.step_sizes[dim_index], 1e-6, abs(func.bounds.ub[0] - func.bounds.lb[0]))\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveStepSize scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["18001ba9-f504-4512-bbd7-60578e2970c0"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "16456b4d-5a12-45aa-bc13-6b9dd91c27b8", "fitness": 0.0, "name": "AdaptiveStepSize", "description": "Adaptively adjusts step sizes for each dimension based on a simplified success rate, balancing exploration and exploitation with a momentum-like update.", "code": "import numpy as np\n\nclass AdaptiveStepSize:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, adaptation_rate=0.1, momentum=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.step_sizes = np.full(dim, initial_step_size)\n        self.adaptation_rate = adaptation_rate\n        self.momentum = momentum\n        self.x_opt = None\n        self.f_opt = np.Inf\n        self.velocity = np.zeros(dim)  # Initialize velocity for momentum\n\n    def __call__(self, func):\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub)\n        self.f_opt = func(x)\n        self.x_opt = x\n        \n        for i in range(self.budget):\n            # Choose a dimension to perturb\n            dim_index = i % self.dim\n\n            # Generate a perturbation\n            step = np.random.normal(0, self.step_sizes[dim_index], 1)[0]\n            \n            x_new = x.copy()\n            x_new[dim_index] += step\n\n            # Clip to bounds\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(x_new)\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                x = x_new\n                self.x_opt = x\n                # Positive reinforcement: Increase step size with momentum\n                self.velocity[dim_index] = self.momentum * self.velocity[dim_index] + (1 - self.momentum) * self.adaptation_rate\n                self.step_sizes[dim_index] *= (1 + self.velocity[dim_index])\n            else:\n                # Negative reinforcement: Decrease step size with momentum\n                self.velocity[dim_index] = self.momentum * self.velocity[dim_index] - (1 - self.momentum) * self.adaptation_rate\n                self.step_sizes[dim_index] *= (1 - self.velocity[dim_index])\n            \n            # Ensure step sizes stay within reasonable bounds\n            self.step_sizes[dim_index] = np.clip(self.step_sizes[dim_index], 1e-6, abs(func.bounds.ub[0] - func.bounds.lb[0]))\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveStepSize scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["18001ba9-f504-4512-bbd7-60578e2970c0"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "c8dc2352-0315-4c38-b9b9-59062f59f6f6", "fitness": 0.0, "name": "AdaptiveStepSize", "description": "Adaptively adjusts the step size for each dimension based on the success rate of previous steps, incorporating a momentum term for smoother adaptation and exploration.", "code": "import numpy as np\n\nclass AdaptiveStepSize:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, success_threshold=0.1, adaptation_rate=0.1, momentum=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.step_sizes = np.full(dim, initial_step_size)\n        self.success_rates = np.zeros(dim)\n        self.adaptation_rate = adaptation_rate\n        self.momentum = momentum\n        self.x_opt = None\n        self.f_opt = np.Inf\n\n    def __call__(self, func):\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub)\n        self.f_opt = func(x)\n        self.x_opt = x\n        \n        for i in range(self.budget):\n            # Choose a dimension to perturb\n            dim_index = i % self.dim\n\n            # Generate a perturbation\n            step = np.random.normal(0, self.step_sizes[dim_index], 1)[0]\n            \n            x_new = x.copy()\n            x_new[dim_index] += step\n\n            # Clip to bounds\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(x_new)\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                x = x_new\n                self.x_opt = x\n                self.success_rates[dim_index] = self.momentum * self.success_rates[dim_index] + (1 - self.momentum) * 1\n            else:\n                self.success_rates[dim_index] = self.momentum * self.success_rates[dim_index] + (1 - self.momentum) * 0\n            \n            # Adapt step sizes based on success rate\n            if self.success_rates[dim_index] > 0.5:\n                self.step_sizes[dim_index] *= (1 + self.adaptation_rate)\n            else:\n                self.step_sizes[dim_index] *= (1 - self.adaptation_rate)\n            \n            # Ensure step sizes stay within reasonable bounds\n            self.step_sizes[dim_index] = np.clip(self.step_sizes[dim_index], 1e-6, abs(func.bounds.ub[0] - func.bounds.lb[0]))\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveStepSize scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["18001ba9-f504-4512-bbd7-60578e2970c0"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "6aa76494-7fab-4352-b5fb-13bee953b8b9", "fitness": 0.0, "name": "AdaptiveStepSize", "description": "Adaptively adjusts the step size for each dimension based on a success rate, using a decaying learning rate for smoother updates and a global step size for faster convergence.", "code": "import numpy as np\n\nclass AdaptiveStepSize:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, success_threshold=0.2, adaptation_rate=0.2, global_rate = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.step_sizes = np.full(dim, initial_step_size)\n        self.successes = np.zeros(dim)\n        self.trials = np.zeros(dim)\n        self.success_threshold = success_threshold\n        self.adaptation_rate = adaptation_rate\n        self.global_rate = global_rate\n        self.x_opt = None\n        self.f_opt = np.Inf\n        self.learning_rate = 1.0  # Initialize learning rate\n        self.learning_rate_decay = 0.999 #Decay\n\n    def __call__(self, func):\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub)\n        self.f_opt = func(x)\n        self.x_opt = x\n        \n        for i in range(self.budget):\n            # Choose a dimension to perturb\n            dim_index = i % self.dim\n\n            # Generate a perturbation\n            step = np.random.normal(0, self.step_sizes[dim_index], 1)[0]\n            \n            x_new = x.copy()\n            x_new[dim_index] += step\n\n            # Clip to bounds\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(x_new)\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                x = x_new\n                self.x_opt = x\n                self.successes[dim_index] += 1\n            \n            self.trials[dim_index] += 1\n            \n            # Adapt step sizes based on success rate\n            success_rate = self.successes[dim_index] / (self.trials[dim_index] + 1e-9) \n            \n            if success_rate > self.success_threshold:\n                self.step_sizes[dim_index] *= (1 + self.learning_rate * self.adaptation_rate)\n            else:\n                self.step_sizes[dim_index] *= (1 - self.learning_rate * self.adaptation_rate)\n            \n            # Global step size adaptation\n            if f_new < self.f_opt:\n                 self.step_sizes *= (1 - self.global_rate * self.learning_rate) #Reduce all if we improve\n\n            # Ensure step sizes stay within reasonable bounds\n            self.step_sizes = np.clip(self.step_sizes, 1e-6, abs(func.bounds.ub[0] - func.bounds.lb[0]))\n            \n            #Decay learning rate\n            self.learning_rate *= self.learning_rate_decay\n\n            #Reset counters every dim iterations\n            if (i + 1) % self.dim == 0:\n                 self.successes = np.zeros(self.dim)\n                 self.trials = np.zeros(self.dim)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveStepSize scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["18001ba9-f504-4512-bbd7-60578e2970c0"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "d630bbcc-ad53-495c-9a95-38a27a6f876b", "fitness": -Infinity, "name": "CMAES", "description": "Simplified CMA-ES with adaptive covariance matrix and step size, focusing on core adaptation mechanisms for efficiency.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = cs\n        self.damps = damp if damp is not None else 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.sigma = 0.5\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.mean = np.zeros(self.dim)\n        self.evals = 0\n        self.lb = -5\n        self.ub = 5\n\n    def sample(self):\n        z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n        x = self.mean[:, np.newaxis] + self.sigma * np.linalg.cholesky(self.C) @ z\n        x = np.clip(x, self.lb, self.ub)\n        return x\n\n    def update(self, x, fvals):\n        arindex = np.argsort(fvals)\n        x = x[:, arindex]\n        xmean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n        y = (x[:, :self.mu] - self.mean[:, np.newaxis]) / self.sigma\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (xmean - self.mean) / self.sigma\n        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.evals / self.popsize))) < (1.4 + 2 / (self.dim + 1)) * self.dim**0.5\n        self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (xmean - self.mean) / self.sigma        \n        self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) + self.cmu * (y @ np.diag(self.weights) @ y.T)\n        self.mean = xmean\n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.dim**0.5 - 1))\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n\n        while self.evals < self.budget:\n            x = self.sample()\n            fvals = np.array([func(x[:, i]) for i in range(self.popsize)])\n            self.evals += self.popsize\n\n            for i in range(self.popsize):\n                if fvals[i] < self.f_opt:\n                    self.f_opt = fvals[i]\n                    self.x_opt = x[:, i]\n\n            self.update(x, fvals)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: 'CMAES' object has no attribute 'ps'.", "error": "", "parent_ids": ["a45e875d-6dc9-49e7-851d-a7371a343e34"], "operator": null, "metadata": {}}
{"id": "047bdbf3-f55a-4570-8b5f-b2889dca695a", "fitness": -Infinity, "name": "CMAES_with_Archive", "description": "CMA-ES with archive and simplified covariance update, emphasizing robustness and efficiency.", "code": "import numpy as np\n\nclass CMAES_with_Archive:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=None, c_cov=None, archive_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)  # Mean value\n        self.sigma = 0.5 # Overall standard deviation\n        self.C = np.eye(self.dim)    # Covariance matrix\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + 1 / (16 * self.dim**2))\n\n        self.cs = cs\n        self.damps = damp if damp is not None else 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.cs\n        self.cc = (4 + self.mu / self.dim) / (self.dim + 4 + 2 * self.mu / self.dim)\n        self.c_cov = c_cov if c_cov is not None else (1 / (self.dim * np.sqrt(self.dim))) if self.mu == 1 else ((1 / (10 + self.dim / 3)) if (self.mu == self.popsize) else (1 / (2 + self.mu / self.dim)**2 + self.mu / self.dim))\n        self.archive = []\n        self.archive_size = archive_size\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        used_budget = 0\n\n        while used_budget < self.budget:\n            # 1. Sample population\n            z = np.random.randn(self.dim, self.popsize)\n            x = self.m[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # 2. Evaluate population\n            f = np.array([func(xi) for xi in x.T])\n            used_budget += self.popsize\n\n            # 3. Sort by fitness\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n\n            # 4. Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n\n            # 5. Update distribution parameters\n            xmean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n            \n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), (xmean - self.m) / self.sigma)\n            self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc)) * (xmean - self.m) / self.sigma\n\n            # Update mean\n            self.m = xmean\n\n            # Update covariance matrix\n            dC = self.c_cov * (np.outer(self.pc, self.pc) - self.C)\n            self.C = self.C + dC\n            \n            # Keep covariance matrix positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            \n            try:\n                e, v = np.linalg.eigh(self.C)\n                e[e < 0] = 1e-8\n                self.C = v @ np.diag(e) @ v.T\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim) # Reset C if it becomes singular.\n\n            # Update step size\n            self.sigma = self.sigma * np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.sigma = np.clip(self.sigma, 1e-10, 1e10)\n\n            # Archive: Store diverse solutions\n            for xi in x.T:\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(xi)\n                else:\n                    # Replace the most similar solution in the archive\n                    distances = [np.linalg.norm(xi - archived_xi) for archived_xi in self.archive]\n                    max_idx = np.argmax(distances)  # Replace the solution that's most different.\n                    self.archive[max_idx] = xi\n            \n            if used_budget >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["d714da31-472b-4fd1-a69c-8415ef26fb87"], "operator": null, "metadata": {}}
{"id": "6a5729e8-449f-4d70-8540-667916483795", "fitness": -Infinity, "name": "CMAES_with_Archive", "description": "Covariance Matrix Adaptation Evolution Strategy with simplified covariance update and adaptive population size.", "code": "import numpy as np\n\nclass CMAES_with_Archive:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=None, c_cov=None, archive_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)  # Mean value\n        self.sigma = 0.5 # Overall standard deviation\n        self.C = np.eye(self.dim)    # Covariance matrix\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + 1 / (16 * self.dim**2))\n\n        self.cs = cs\n        self.damps = damp if damp is not None else 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.cs\n        self.cc = (4 + self.mu / self.dim) / (self.dim + 4 + 2 * self.mu / self.dim)\n        self.c_cov = c_cov if c_cov is not None else (1 / (self.dim * np.sqrt(self.dim))) if self.mu == 1 else ((1 / (10 + self.dim / 3)) if (self.mu == self.popsize) else (1 / (2 + self.mu / self.dim)**2 + self.mu / self.dim))\n        self.archive = []\n        self.archive_size = archive_size\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        used_budget = 0\n\n        while used_budget < self.budget:\n            # 1. Sample population\n            z = np.random.randn(self.dim, self.popsize)\n            x = self.m[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # 2. Evaluate population\n            f = np.array([func(xi) for xi in x.T])\n            used_budget += self.popsize\n\n            # 3. Sort by fitness\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n\n            # 4. Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n\n            # 5. Update distribution parameters\n            xmean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n            \n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * np.linalg.solve(np.linalg.cholesky(self.C), (xmean - self.m) / self.sigma)\n            self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc)) * (xmean - self.m) / self.sigma\n\n            # Update mean\n            self.m = xmean\n\n            # Update covariance matrix\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * (np.outer(self.pc, self.pc) + self.c_cov_mu * np.eye(self.dim))\n\n\n            # Keep covariance matrix positive definite\n            try:\n                e, v = np.linalg.eigh(self.C)\n                e[e < 0] = 1e-8\n                self.C = v @ np.diag(e) @ v.T\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Update step size\n            self.sigma = self.sigma * np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.sigma = np.clip(self.sigma, 1e-10, 1e10)\n\n            # Archive: Store diverse solutions\n            for xi in x.T:\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(xi)\n                else:\n                    # Replace the most similar solution in the archive\n                    distances = [np.linalg.norm(xi - archived_xi) for archived_xi in self.archive]\n                    max_idx = np.argmax(distances)  # Replace the solution that's most different.\n                    self.archive[max_idx] = xi\n            \n            if used_budget >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["d714da31-472b-4fd1-a69c-8415ef26fb87"], "operator": null, "metadata": {}}
{"id": "b6fab79c-fca9-4f9e-992c-af4020cd5e5a", "fitness": -Infinity, "name": "CMAES_with_Archive", "description": "Simplified CMA-ES with archive and budget-aware adaptation, focusing on core updates and removing potentially problematic archive replacement logic.", "code": "import numpy as np\n\nclass CMAES_with_Archive:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=None, c_cov=None, archive_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)  # Mean value\n        self.sigma = 0.5 # Overall standard deviation\n        self.C = np.eye(self.dim)    # Covariance matrix\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + 1 / (16 * self.dim**2))\n\n        self.cs = cs\n        self.damps = damp if damp is not None else 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.cs\n        self.cc = (4 + self.mu / self.dim) / (self.dim + 4 + 2 * self.mu / self.dim)\n        self.c_cov = c_cov if c_cov is not None else (1 / (self.dim * np.sqrt(self.dim))) if self.mu == 1 else (1 / (2 + self.mu / self.dim)**2 + self.mu / self.dim)\n        self.c_cov_mu = self.c_cov\n        self.archive = []\n        self.archive_size = archive_size\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        used_budget = 0\n\n        while used_budget < self.budget:\n            # 1. Sample population\n            z = np.random.randn(self.dim, self.popsize)\n            x = self.m[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # 2. Evaluate population\n            f = np.array([func(xi) for xi in x.T])\n            used_budget += self.popsize\n\n            # 3. Sort by fitness\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n\n            # 4. Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n\n            # 5. Update distribution parameters\n            xmean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n            \n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * np.linalg.solve(np.linalg.cholesky(self.C), (xmean - self.m) / self.sigma)\n            self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc)) * (xmean - self.m) / self.sigma\n\n            # Update mean\n            self.m = xmean\n\n            # Update covariance matrix\n            artmp = (1 / self.sigma) * (x[:, :self.mu] - self.m[:, np.newaxis])\n            dC = self.c_cov_mu * np.sum(self.weights[np.newaxis, np.newaxis, :] * (artmp[:, :, :] @ artmp[:, :, :].transpose(0, 2, 1)), axis=2)\n            self.C = (1 - self.c_cov) * self.C + dC\n\n            # Keep covariance matrix positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            \n            e, v = np.linalg.eigh(self.C)\n            e[e < 0] = 1e-8\n            self.C = v @ np.diag(e) @ v.T\n\n            # Update step size\n            self.sigma = self.sigma * np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.sigma = np.clip(self.sigma, 1e-10, 1e10)\n\n            # Archive: Store best solutions\n            for xi in x[:, :min(self.mu, x.shape[1])].T:\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(xi)\n                else:\n                    break  # Archive is full\n\n            if used_budget >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["d714da31-472b-4fd1-a69c-8415ef26fb87"], "operator": null, "metadata": {}}
{"id": "c457d95c-7136-422c-96db-bb408fe3b540", "fitness": -Infinity, "name": "CMAES", "description": "Simplified CMA-ES with dynamic population size and restarts for enhanced exploration and faster convergence.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=None, restarts=3):\n        self.budget = budget\n        self.dim = dim\n        self.restarts = restarts\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = cs\n        self.damps = damp if damp is not None else 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.sigma = 0.5\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.mean = np.zeros(self.dim)\n        self.evals = 0\n        self.lb = -5\n        self.ub = 5\n        self.tolx = 1e-12 * (self.ub - self.lb)\n\n    def sample(self):\n        z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n        x = self.mean + self.sigma * np.sqrt(self.C) @ z\n        x = np.clip(x, self.lb, self.ub)\n        return x\n\n    def update(self, x, fvals):\n        arindex = np.argsort(fvals)\n        x = x[:, arindex]\n        xmean = np.sum(x[:, :self.mu] * self.weights, axis=1)\n        y = (x[:, :self.mu] - self.mean) / self.sigma\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (xmean - self.mean) / self.sigma\n        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.evals / self.popsize))) < (1.4 + 2 / (self.dim + 1)) * self.chiN\n        self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (xmean - self.mean) / self.sigma\n        self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (np.outer(self.pc, self.pc)) + self.cmu * (y @ np.diag(self.weights) @ y.T)\n        self.mean = xmean\n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        self.C = np.linalg.cholesky(self.C) ** 2 # Ensure positive definiteness\n        \n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        for restart in range(self.restarts):\n            self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n            self.sigma = 0.5\n            self.pc = np.zeros(self.dim)\n            self.ps = np.zeros(self.dim)\n            self.C = np.eye(self.dim)\n            self.evals_restart = 0\n\n            while self.evals + self.evals_restart < self.budget:\n                x = self.sample()\n                fvals = np.array([func(x[:, i]) for i in range(self.popsize)])\n                self.evals_restart += self.popsize\n\n                for i in range(self.popsize):\n                    if fvals[i] < self.f_opt:\n                        self.f_opt = fvals[i]\n                        self.x_opt = x[:, i]\n\n                self.update(x, fvals)\n                if np.linalg.norm(self.sigma * np.sqrt(np.diag(self.C))) < self.tolx:\n                    break\n            self.evals += self.evals_restart\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,) (2,6) .", "error": "", "parent_ids": ["a45e875d-6dc9-49e7-851d-a7371a343e34"], "operator": null, "metadata": {}}
{"id": "6c29e144-1ade-400d-b37d-9ac969a1a69e", "fitness": 0.27442379423507596, "name": "HybridPSO_DE", "description": "Simplifies Hybrid PSO-DE by adaptively adjusting PSO parameters based on DE's performance, balancing exploration and exploitation with fewer parameters.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, c=1.0, F=0.7, CR=0.8):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c (float): Cognitive and social coefficient for PSO (c1=c2=c).\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c = c\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.de_success_rate = 0.5  # Adaptive DE success rate\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n\n    def evaluate_population(self, func):\n        \"\"\"Evaluates the fitness of each particle in the population.\"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness:\n                    self.best_fitness = f\n                    self.best_pos = self.pop[i].copy()\n                    if f < self.global_best_fitness:\n                        self.global_best_fitness = f\n                        self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def update_velocities(self, w):\n        \"\"\"Updates particle positions using PSO.\"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        self.pop += w * r1 * (self.best_pos - self.pop) + (1 - w) * np.random.rand(self.pop_size, self.dim) * (self.global_best_pos - self.pop)\n\n\n    def differential_evolution(self, func):\n        \"\"\"Applies differential evolution to the population.\"\"\"\n        successful_de = 0\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    trial[j] = mutant[j]\n\n            f_trial = func(trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial\n                self.fitness[i] = f_trial\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_pos = self.pop[i].copy()\n                successful_de += 1\n\n        self.de_success_rate = 0.9 * self.de_success_rate + 0.1 * (successful_de / self.pop_size)\n\n\n    def constrain(self, func):\n        \"\"\"Keeps the particles within the bounds.\"\"\"\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n            self.update_velocities(w)\n            self.constrain(func)\n            self.evaluate_population(func)\n\n            # Apply DE less often if it's not improving results\n            if np.random.rand() < self.de_success_rate:\n                self.differential_evolution(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DE scored 0.274 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3c40a18c-32a0-4240-90f3-952dcb978967"], "operator": null, "metadata": {"aucs": [0.15292173543635545, 0.19898976732328688, 0.25932186418350944, 0.18046325848623423, 0.24521949010518662, 0.20168701197487382, 0.3117572983947944, 0.2669468027086872, 0.24111195312356004, 0.17062658655714624, 0.166354320443743, 0.9988706984808174, 0.2145638471209783, 0.17557090724023705, 0.24165627978358384, 0.3114542574554727, 0.25606597227671446, 0.2381319645120381, 0.18546761770217646, 0.47129425139212267]}}
{"id": "6e029120-2363-4f25-b056-b96fb98ccf91", "fitness": 0.10774674011040833, "name": "SimplifiedCMAES", "description": "Simplified CMA-ES with adaptive covariance matrix and step size control, focusing on efficiency and robustness with fewer parameters.", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=2):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = cs\n        self.damps = damp\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.sigma = 0.5\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.mean = np.zeros(self.dim)\n        self.evals = 0\n        self.lb = -5\n        self.ub = 5\n\n    def sample(self):\n        z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n        x = self.mean[:, np.newaxis] + self.sigma * np.sqrt(self.C) @ z\n        x = np.clip(x, self.lb, self.ub)\n        return x\n\n    def update(self, x, fvals):\n        arindex = np.argsort(fvals)\n        x = x[:, arindex]\n        xmean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n        y = (x[:, :self.mu] - self.mean[:, np.newaxis]) / self.sigma\n        self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (xmean - self.mean) / self.sigma\n        C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) + self.cmu * (y @ np.diag(self.weights) @ y.T)\n        self.mean = xmean\n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.pc) / self.chiN - 1))\n        self.C = np.triu(C) + np.triu(C, 1).T\n        \n        # Ensure positive definiteness\n        try:\n            np.linalg.cholesky(self.C)\n        except np.linalg.LinAlgError:\n            self.C = self.C + 1e-6 * np.eye(self.dim)\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n\n        while self.evals < self.budget:\n            x = self.sample()\n            fvals = np.array([func(x[:, i]) for i in range(self.popsize)])\n            self.evals += self.popsize\n\n            for i in range(self.popsize):\n                if fvals[i] < self.f_opt:\n                    self.f_opt = fvals[i]\n                    self.x_opt = x[:, i]\n\n            self.update(x, fvals)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm SimplifiedCMAES scored 0.108 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a45e875d-6dc9-49e7-851d-a7371a343e34"], "operator": null, "metadata": {"aucs": [0.06393259938458562, 0.0, 0.17914396036662605, 0.06948697940290205, 0.15924498048233504, 0.1274958799720649, 0.14837101944898223, 0.08617272149479427, 0.0673075993702571, 0.12048758456653863, 0.10283904827164791, 0.14071970040293214, 0.0, 0.0983024917450448, 0.11524187514242534, 0.1628789994743418, 0.17435978501665084, 0.10486441244087741, 0.10481521337576649, 0.12926995184939383]}}
{"id": "a4579e28-5bce-4838-b7bf-867285f0c3f0", "fitness": 0.767190834629064, "name": "HybridPSO_DE", "description": "Simplified hybrid PSO-DE with adaptive parameter tuning and a more streamlined structure for better efficiency.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7):\n        \"\"\"\n        Initializes the Hybrid PSO-DE optimizer with simplified parameter adaptation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        self.best_fitness = np.array([np.inf] * self.pop_size)\n\n    def evaluate_population(self, func):\n         \"\"\"\n         Evaluates the fitness of each particle in the population.\n         \"\"\"\n         for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness[i]:\n                    self.best_fitness[i] = f\n                    self.best_pos[i] = self.pop[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                 break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE.\n        \"\"\"\n        w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget) # adaptive w\n\n        for i in range(self.pop_size):\n            # PSO update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = w * (self.pop[i] - self.best_pos[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub) # Constraint handling\n\n\n            # DE update\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            trial = new_pos.copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    trial[j] = mutant[j]\n\n            # Evaluate and update\n            if self.eval_count < self.budget:\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.best_fitness[i]:\n                        self.best_fitness[i] = f_trial\n                        self.best_pos[i] = self.pop[i].copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.evaluate_population(func)\n        \n        while self.eval_count < self.budget:\n            self.update_positions(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DE scored 0.767 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3c40a18c-32a0-4240-90f3-952dcb978967"], "operator": null, "metadata": {"aucs": [0.3901877787000767, 0.8770604084159768, 0.9159936449160387, 0.9559895790906885, 0.933218608458607, 0.9491250653145521, 0.3684807297920646, 0.9003911279307848, 0.91869238911481, 0.22838658585685012, 0.9521803015224871, 0.995095660862374, 0.48625565111647484, 0.9068571191278769, 0.9607800734008547, 0.9398645724660601, 0.8436839026223457, 0.9465263817811771, 0.35367955509453197, 0.5213675569966487]}}
{"id": "cf00fc52-eaa4-439f-9890-3560540c0ba4", "fitness": 0.0, "name": "AdaptiveStepSize", "description": "Adaptively adjusts step sizes for each dimension based on a simplified success rate, using a more robust update rule and global best information.", "code": "import numpy as np\n\nclass AdaptiveStepSize:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, adaptation_rate=0.1, decay_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.step_sizes = np.full(dim, initial_step_size)\n        self.adaptation_rate = adaptation_rate\n        self.decay_rate = decay_rate\n        self.x_opt = None\n        self.f_opt = np.Inf\n\n    def __call__(self, func):\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub)\n        self.f_opt = func(x)\n        self.x_opt = x\n\n        for i in range(self.budget):\n            dim_index = i % self.dim\n            step = np.random.normal(0, self.step_sizes[dim_index])\n            x_new = x.copy()\n            x_new[dim_index] += step\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                x = x_new\n                self.x_opt = x\n                self.step_sizes[dim_index] *= (1 + self.adaptation_rate)\n            else:\n                self.step_sizes[dim_index] *= (1 - self.adaptation_rate)\n\n            self.step_sizes[dim_index] *= self.decay_rate  # Decay step size over time\n            self.step_sizes[dim_index] = np.clip(self.step_sizes[dim_index], 1e-6, abs(func.bounds.ub[0] - func.bounds.lb[0]))\n\n            # Global best informed move\n            x_global_informed = x + 0.1 * (self.x_opt - x) # move towards global best\n            x_global_informed = np.clip(x_global_informed, func.bounds.lb, func.bounds.ub)\n            f_global_informed = func(x_global_informed)\n            if f_global_informed < self.f_opt:\n                 self.f_opt = f_global_informed\n                 self.x_opt = x_global_informed\n                 x = x_global_informed\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveStepSize scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["24c3f0ae-22cc-4077-8905-04766cffa673"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "14bf8f2e-6d15-4369-b66f-1b93973eb7b7", "fitness": -Infinity, "name": "HybridPSO_DE", "description": "Simplifies Hybrid PSO-DE by using a shared global best for velocity updates and reduces DE's impact when it's less effective.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, c=1.0, F=0.7, CR=0.8, de_prob=0.5):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c (float): Cognitive and social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob (float): Probability of applying DE in each iteration.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c = c\n        self.F = F\n        self.CR = CR\n        self.de_prob = de_prob\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.global_best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_velocities(self, w):\n        \"\"\"Updates particle positions using PSO with a shared global best.\"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        self.pop += w * r1 * (self.global_best_pos - self.pop) + (1 - w) * np.random.rand(self.pop_size, self.dim) * (self.global_best_pos - self.pop)\n        self.constrain(func.bounds.lb, func.bounds.ub)\n\n\n    def differential_evolution(self, func):\n        \"\"\"Applies differential evolution to the population.\"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    trial[j] = mutant[j]\n\n            f_trial = func(trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial\n                self.fitness[i] = f_trial\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_pos = self.pop[i].copy()\n\n\n    def constrain(self, lb, ub):\n        \"\"\"Keeps the particles within the bounds.\"\"\"\n        self.pop = np.clip(self.pop, lb, ub)\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n            self.update_velocities(w)\n\n            if np.random.rand() < self.de_prob and self.eval_count < self.budget:\n                self.differential_evolution(func)\n                \n            self.fitness = np.array([func(x) for x in self.pop])\n            self.eval_count += self.pop_size\n            \n            if np.min(self.fitness) < self.global_best_fitness:\n                self.global_best_fitness = np.min(self.fitness)\n                self.global_best_pos = self.pop[np.argmin(self.fitness)].copy()\n            \n            if self.eval_count >= self.budget:\n                self.eval_count = self.budget\n                break\n            \n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 2, "feedback": "An exception occurred: name 'func' is not defined.", "error": "", "parent_ids": ["6c29e144-1ade-400d-b37d-9ac969a1a69e"], "operator": null, "metadata": {}}
{"id": "795ad379-560f-4954-baa5-2f00f8f296c8", "fitness": -Infinity, "name": "AdaptiveHybridPSO_DE", "description": "Integrates a simplified PSO and DE using an adaptive strategy based on their relative performance and reducing parameter count for faster convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, c=1.0, F=0.7):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c (float): Cognitive and social coefficient for PSO (c1=c2=c).\n            F (float): Scaling factor for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c = c\n        self.F = F\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.pso_success_rate = 0.5\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n\n    def evaluate_population(self, func):\n        \"\"\"Evaluates the fitness of each particle in the population.\"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness:\n                    self.best_fitness = f\n                    self.best_pos = self.pop[i].copy()\n                    if f < self.global_best_fitness:\n                        self.global_best_fitness = f\n                        self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def pso_step(self, w, func):\n        \"\"\"Performs a PSO update step.\"\"\"\n        successful_pso = 0\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocity = w * (self.pop[i] - self.best_pos[i]) + self.c * r1 * (self.best_pos[i] - self.pop[i]) + self.c * r2 * (self.global_best_pos - self.pop[i])\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = new_pos.copy()\n                successful_pso +=1\n        return successful_pso / self.pop_size\n\n\n    def de_step(self, func):\n        \"\"\"Performs a DE update step.\"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Simplified binomial crossover\n            trial = np.where(np.random.rand(self.dim) < 0.8, mutant, self.pop[i])\n\n            f_trial = func(trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial\n                self.fitness[i] = f_trial\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_pos = self.pop[i].copy()\n        return 1 # DE always \"succeeds\" in trying\n\n\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive strategy: alternate between PSO and DE\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n            if np.random.rand() < self.pso_success_rate:\n                self.pso_success_rate = 0.8 * self.pso_success_rate + 0.2 * self.pso_step(w, func)\n                \n            else:\n                self.de_step(func)\n                self.pso_success_rate = 0.8 * self.pso_success_rate + 0.2 * 0.0 # Decrement the PSO success\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 2, "feedback": "An exception occurred: index 5 is out of bounds for axis 0 with size 5.", "error": "", "parent_ids": ["6c29e144-1ade-400d-b37d-9ac969a1a69e"], "operator": null, "metadata": {}}
{"id": "cc6a7350-032f-45dc-9d4b-cd84a3909f22", "fitness": 0.11838656704155492, "name": "AdaptiveCMAES", "description": "Adaptive CMA-ES with simplified rank-one update and dynamic population sizing based on performance.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = initial_sigma\n        self.mean = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.lb = -5\n        self.ub = 5\n        self.popsize = 4 + int(3 * np.log(self.dim))\n        self.mueff = self.popsize // 2\n\n        self.cs = 0.3\n        self.damps = 1 + self.dim / 2 # was 2\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        self.pc = np.zeros(self.dim)\n        self.success_rate = 0.5\n\n    def sample(self):\n        z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n        x = self.mean[:, np.newaxis] + self.sigma * np.sqrt(self.C) @ z\n        x = np.clip(x, self.lb, self.ub)\n        return x\n\n    def update(self, x, fvals):\n        arindex = np.argsort(fvals)\n        x = x[:, arindex]\n        xmean = np.mean(x[:, :self.mueff], axis=1)\n        y = xmean - self.mean\n        \n        self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc)) * y / self.sigma\n\n        C = (1 - self.cs) * self.C + self.cs * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :])\n\n        self.mean = xmean\n        self.C = np.triu(C) + np.triu(C, 1).T\n        \n        # Ensure positive definiteness\n        try:\n            np.linalg.cholesky(self.C)\n        except np.linalg.LinAlgError:\n            self.C = self.C + 1e-6 * np.eye(self.dim)\n\n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.pc) / self.chiN - 1))\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n\n        while self.evals < self.budget:\n            x = self.sample()\n            fvals = np.array([func(x[:, i]) for i in range(self.popsize)])\n            self.evals += self.popsize\n\n            for i in range(self.popsize):\n                if fvals[i] < self.f_opt:\n                    self.f_opt = fvals[i]\n                    self.x_opt = x[:, i]\n\n            self.update(x, fvals)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveCMAES scored 0.118 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6e029120-2363-4f25-b056-b96fb98ccf91"], "operator": null, "metadata": {"aucs": [0.04283987507703768, 0.07585951923320444, 0.1722011209912473, 0.10206360823016403, 0.03156056966888987, 0.10436649239662021, 0.17325348073319657, 0.028596718781190966, 0.12695026680381194, 0.09455153218090073, 0.11693033058721158, 0.17581213278136731, 0.22881934416879723, 0.11937113651038866, 0.1523107175688918, 0.19245194359322193, 0.08868321399097945, 0.15084466221550086, 0.08239966806697452, 0.10786500725150194]}}
{"id": "d528053c-84d8-488b-9152-0376ff058f89", "fitness": 0.09171303663683474, "name": "SimplifiedCMAES", "description": "Streamlined CMA-ES with simplified rank-one update and dynamic population size for faster convergence.", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, cs=0.3, damp=2):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = cs\n        self.damps = damp\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.sigma = 0.5\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.mean = np.zeros(self.dim)\n        self.evals = 0\n        self.lb = -5\n        self.ub = 5\n        self.dynamic_popsize = True\n\n    def sample(self):\n        z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n        x = self.mean[:, np.newaxis] + self.sigma * np.sqrt(self.C) @ z\n        x = np.clip(x, self.lb, self.ub)\n        return x\n\n    def update(self, x, fvals):\n        arindex = np.argsort(fvals)\n        x = x[:, arindex]\n        xmean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n        y = (x[:, :self.mu] - self.mean[:, np.newaxis]) / self.sigma\n        self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (xmean - self.mean) / self.sigma\n        \n        # Simplified rank-one update\n        self.C = (1 - self.c1) * self.C + self.c1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :])\n\n        self.mean = xmean\n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.pc) / self.chiN - 1))\n        \n        # Ensure positive definiteness, simplified\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        try:\n            np.linalg.cholesky(self.C)\n        except np.linalg.LinAlgError:\n            self.C = self.C + 1e-6 * np.eye(self.dim)\n            \n        if self.dynamic_popsize:\n            if np.linalg.norm(self.pc) / self.chiN < 0.5:\n                self.popsize = max(4, self.popsize // 2)\n            elif np.linalg.norm(self.pc) / self.chiN > 2:\n                self.popsize = min(int(4 + 3 * np.log(self.dim) * 2), 200) # Max popsize to avoid memory issues\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.evals = 0\n        self.popsize = 4 + int(3 * np.log(self.dim)) # Reset popsize at the beginning\n\n        while self.evals < self.budget:\n            x = self.sample()\n            fvals = np.array([func(x[:, i]) for i in range(self.popsize)])\n            self.evals += self.popsize\n\n            for i in range(self.popsize):\n                if fvals[i] < self.f_opt:\n                    self.f_opt = fvals[i]\n                    self.x_opt = x[:, i]\n\n            self.update(x, fvals)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm SimplifiedCMAES scored 0.092 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6e029120-2363-4f25-b056-b96fb98ccf91"], "operator": null, "metadata": {"aucs": [0.00012406208522874884, 0.041052026175360745, 0.14981522665796287, 0.06333797209111014, 0.06249318717731733, 0.10206961288192051, 0.10465074399435947, 0.11222868065312053, 0.018896584356654977, 0.1081373024337039, 0.05601754335221454, 0.10281880719806291, 0.17990192107142178, 0.09250285655428592, 0.10566153285458857, 0.17885531193707827, 0.051677610033641797, 0.09985266316450692, 0.09394691737386707, 0.11022017069028789]}}
{"id": "843104bf-d29b-426d-ba06-b1b741c61875", "fitness": 0.28010175393740755, "name": "AdaptiveHybridPSODE", "description": "Adaptive Hybrid PSO-DE with simplified parameter control and dynamic allocation of evaluations between PSO and DE based on their observed performance.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, c=1.0, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c = c\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.pso_evals = 0\n        self.de_evals = 0\n        self.pso_success_rate = 0.5\n        self.de_success_rate = 0.5\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.global_best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n\n    def pso_step(self, func, w):\n        r1 = np.random.rand(self.pop_size, self.dim)\n        velocity = w * (self.global_best_pos - self.pop) + self.c * r1 * (self.global_best_pos - self.pop)\n        self.pop += velocity\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n        new_fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        improved = new_fitness < self.fitness\n        self.fitness[improved] = new_fitness[improved]\n        if np.min(self.fitness) < self.global_best_fitness:\n            self.global_best_fitness = np.min(self.fitness)\n            self.global_best_pos = self.pop[np.argmin(self.fitness)].copy()\n        return np.sum(improved) / self.pop_size\n        \n\n    def de_step(self, func):\n        successful_de = 0\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    trial[j] = mutant[j]\n\n            f_trial = func(trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial\n                self.fitness[i] = f_trial\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_pos = self.pop[i].copy()\n                successful_de += 1\n\n        return successful_de / self.pop_size\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        pso_prob = 0.5\n        while self.eval_count < self.budget:\n            if np.random.rand() < pso_prob:\n                w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n                success = self.pso_step(func, w)\n                self.pso_success_rate = 0.9 * self.pso_success_rate + 0.1 * success\n            else:\n                success = self.de_step(func)\n                self.de_success_rate = 0.9 * self.de_success_rate + 0.1 * success\n            \n            pso_prob = self.pso_success_rate / (self.pso_success_rate + self.de_success_rate + 1e-9)\n\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridPSODE scored 0.280 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6c29e144-1ade-400d-b37d-9ac969a1a69e"], "operator": null, "metadata": {"aucs": [0.08627151658995458, 0.17380288503953412, 0.30448809943615684, 0.18279109496875567, 0.17136738205087299, 0.20684148514551282, 0.2595273254838464, 0.19480224730296514, 0.206284553117681, 0.15167308674338287, 0.2008748035362976, 0.9934638474559023, 0.21616981447079164, 0.20272879604046168, 0.619041726272962, 0.32766962123283006, 0.24876690932686651, 0.2292081631254046, 0.17275082896254623, 0.45351089244542575]}}
{"id": "ecd29947-b98e-4243-b33c-a6548b6d9b2b", "fitness": 0.3642677350824992, "name": "HybridPSO_DE", "description": "Streamlined Hybrid PSO-DE with simplified adaptive inertia weight and DE application frequency, enhancing exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, c=1.0, F=0.7, CR=0.8, de_prob=0.5):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c (float): Cognitive and social coefficient for PSO (c1=c2=c).\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob (float): Probability of applying DE in each iteration.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c = c\n        self.F = F\n        self.CR = CR\n        self.de_prob = de_prob\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update\n            r1 = np.random.rand(self.dim)\n            velocity = w * r1 * (self.global_best_pos - self.pop[i])\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n            elif f_new < self.global_best_fitness:\n                 self.global_best_fitness = f_new\n                 self.global_best_pos = new_pos.copy()\n            elif self.fitness[i] < self.global_best_fitness:\n                 self.global_best_fitness = self.fitness[i]\n                 self.global_best_pos = self.pop[i].copy()\n\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n            self.update_population(func, w)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSO_DE scored 0.364 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6c29e144-1ade-400d-b37d-9ac969a1a69e"], "operator": null, "metadata": {"aucs": [0.15576216382153674, 0.5571141942302256, 0.3713086116312907, 0.1984762899970549, 0.23481830184133046, 0.34547758041053545, 0.2942101961147242, 0.3516299653756316, 0.27066729064453343, 0.20012895205075998, 0.27697123575865545, 0.9937961641980461, 0.3851726124026805, 0.29265128301763155, 0.7008744772957641, 0.3514209363328812, 0.27693622915662597, 0.3447726243706304, 0.2184931278147807, 0.464672465184664]}}
{"id": "1f5e4c29-a3c4-4fc1-a6f3-e6d3700f2023", "fitness": 0.5936413699188076, "name": "AdaptiveHybridPSO_DE", "description": "Adaptively blends PSO and DE by probabilistically choosing which update to apply based on their relative success, simplifying parameter tuning.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7, p_pso=0.5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with probabilistic PSO/DE selection.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            p_pso (float): Probability of applying PSO update.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.p_pso = p_pso\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        self.best_fitness = np.array([np.inf] * self.pop_size)\n\n    def evaluate_population(self, func):\n         \"\"\"\n         Evaluates the fitness of each particle in the population.\n         \"\"\"\n         for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness[i]:\n                    self.best_fitness[i] = f\n                    self.best_pos[i] = self.pop[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                 break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with adaptive selection.\n        \"\"\"\n        w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget) # adaptive w\n\n        for i in range(self.pop_size):\n            if np.random.rand() < self.p_pso:\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = w * (self.pop[i] - self.best_pos[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n                new_pos = self.pop[i] + velocity\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub) # Constraint handling\n            else:\n                # DE update\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                new_pos = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        new_pos[j] = mutant[j]\n\n            # Evaluate and update\n            if self.eval_count < self.budget:\n                f_trial = func(new_pos)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.best_fitness[i]:\n                        self.best_fitness[i] = f_trial\n                        self.best_pos[i] = self.pop[i].copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.evaluate_population(func)\n        \n        while self.eval_count < self.budget:\n            self.update_positions(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.594 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a4579e28-5bce-4838-b7bf-867285f0c3f0"], "operator": null, "metadata": {"aucs": [0.24622704688330144, 0.3076442003013782, 0.8632596118487452, 0.9550305889058716, 0.9122795936176019, 0.2560008579882619, 0.38190504551465587, 0.3461980672767482, 0.9644989325142179, 0.947704544337853, 0.9245059543852373, 0.9987215264511533, 0.2725998682443571, 0.343602679066081, 0.7462009912422105, 0.36558420254613355, 0.3906519321048044, 0.9583743536163843, 0.1869743012734134, 0.5048631002577402]}}
{"id": "e90638bc-d735-4124-9e04-b8190c873ac4", "fitness": 0.5917163826546858, "name": "HybridPSO_DE", "description": "Adaptively blends PSO and DE by probabilistically choosing the update strategy based on their recent success.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7, p_adapt=0.1):\n        \"\"\"\n        Initializes the Hybrid PSO-DE optimizer with adaptive strategy selection.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            p_adapt (float): Probability of adapting the strategy.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.p_adapt = p_adapt  # Probability to adapt\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.pso_success = 0.5  # Initial probability of using PSO\n        self.de_success = 0.5   # Initial probability of using DE\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        self.best_fitness = np.array([np.inf] * self.pop_size)\n\n    def evaluate_population(self, func):\n        \"\"\"\n        Evaluates the fitness of each particle in the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness[i]:\n                    self.best_fitness[i] = f\n                    self.best_pos[i] = self.pop[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with adaptive probability.\n        \"\"\"\n        w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget) # adaptive w\n        pso_count = 0\n        de_count = 0\n\n        for i in range(self.pop_size):\n            if np.random.rand() < self.pso_success:\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = w * (self.pop[i] - self.best_pos[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n                new_pos = self.pop[i] + velocity\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub) # Constraint handling\n                trial = new_pos.copy() # trial solution for PSO\n                pso_count += 1\n            else:\n                # DE update\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                de_count += 1\n\n            # Evaluate and update\n            if self.eval_count < self.budget:\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.best_fitness[i]:\n                        self.best_fitness[i] = f_trial\n                        self.best_pos[i] = self.pop[i].copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n        # Strategy adaptation\n        if np.random.rand() < self.p_adapt:\n            total = pso_count + de_count\n            if total > 0:\n                self.pso_success = pso_count / total if total > 0 else 0.5\n                self.de_success = de_count / total if total > 0 else 0.5\n            else:\n                self.pso_success = 0.5\n                self.de_success = 0.5\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.evaluate_population(func)\n        \n        while self.eval_count < self.budget:\n            self.update_positions(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSO_DE scored 0.592 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a4579e28-5bce-4838-b7bf-867285f0c3f0"], "operator": null, "metadata": {"aucs": [0.18863470823241024, 0.3582418457257762, 0.8701778914121483, 0.26613785144655355, 0.9664162080697121, 0.9634121573404367, 0.339041615170406, 0.43035142492587075, 0.9255762564345701, 0.1964627120650254, 0.22964705339175584, 0.9973536073175107, 0.36376731311522703, 0.2963118785564739, 0.9661964468439728, 0.9530553624136997, 0.7902976646220975, 0.9631333309306898, 0.27759951089198787, 0.49251281418739323]}}
{"id": "466b481c-ca88-4f0b-b74c-b18b160e02cf", "fitness": 0.8033986365348935, "name": "AdaptiveHybridPSO_DE", "description": "Adaptively adjusts PSO and DE parameters based on population diversity, focusing on exploration when diversity is high and exploitation when low.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with population diversity-based parameter adaptation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        self.best_fitness = np.array([np.inf] * self.pop_size)\n\n    def evaluate_population(self, func):\n        \"\"\"Evaluates population fitness and updates best positions.\"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness[i]:\n                    self.best_fitness[i] = f\n                    self.best_pos[i] = self.pop[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n    \n    def calculate_diversity(self):\n        \"\"\"Calculates population diversity based on distance from centroid.\"\"\"\n        centroid = np.mean(self.pop, axis=0)\n        distances = np.linalg.norm(self.pop - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n\n    def update_positions(self, func):\n        \"\"\"Updates particle positions using adaptive PSO and DE.\"\"\"\n        diversity = self.calculate_diversity()\n        normalized_diversity = diversity / (func.bounds.ub[0] - func.bounds.lb[0]) # Assuming same bounds for all dims\n\n        # Adapt PSO parameters based on diversity\n        w = self.w_start - (self.w_start - self.w_end) * (1 - normalized_diversity)  # Higher diversity, higher inertia\n        c1 = 1.5 + 0.5 * (1 - normalized_diversity) # Higher diversity, lower cognitive\n        c2 = 1.5 + 0.5 * (1 - normalized_diversity) # Higher diversity, lower social\n\n\n        for i in range(self.pop_size):\n            # PSO update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = w * (self.pop[i] - self.best_pos[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            # DE update\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            trial = new_pos.copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    trial[j] = mutant[j]\n\n            # Evaluate and update\n            if self.eval_count < self.budget:\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.best_fitness[i]:\n                        self.best_fitness[i] = f_trial\n                        self.best_pos[i] = self.pop[i].copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def __call__(self, func):\n        \"\"\"Optimizes the function.\"\"\"\n        self.initialize_population(func)\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.803 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a4579e28-5bce-4838-b7bf-867285f0c3f0"], "operator": null, "metadata": {"aucs": [0.2635082195957982, 0.8425829519286955, 0.9153782452082764, 0.9667359883766905, 0.9302623988253166, 0.9289466078540707, 0.8863389900600951, 0.9068062782068194, 0.9288974244645372, 0.9068809145714488, 0.9558769113183005, 0.9951264375121531, 0.3037822193831916, 0.8648504416315114, 0.952701852897866, 0.9401434643250576, 0.8952163224078789, 0.9565655054969251, 0.23409890346396256, 0.49327265316927305]}}
{"id": "2b178318-b0ab-40a6-a67f-ce35db7fc9c3", "fitness": 0.0, "name": "AdaptiveStepSize", "description": "Adaptively adjusts step sizes for each dimension based on success rate, incorporating momentum for smoother updates and simplified clipping.", "code": "import numpy as np\n\nclass AdaptiveStepSize:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, adaptation_rate=0.1, momentum=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.step_sizes = np.full(dim, initial_step_size)\n        self.adaptation_rate = adaptation_rate\n        self.momentum = momentum\n        self.x_opt = None\n        self.f_opt = np.Inf\n        self.success_rates = np.zeros(dim)\n\n    def __call__(self, func):\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub)\n        self.f_opt = func(x)\n        self.x_opt = x\n\n        for i in range(self.budget):\n            dim_index = i % self.dim\n            step = np.random.normal(0, self.step_sizes[dim_index])\n            x_new = x.copy()\n            x_new[dim_index] += step\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                x = x_new\n                self.x_opt = x\n                self.success_rates[dim_index] = self.momentum * self.success_rates[dim_index] + (1 - self.momentum) * 1\n                self.step_sizes[dim_index] *= (1 + self.adaptation_rate * self.success_rates[dim_index])\n            else:\n                self.success_rates[dim_index] = self.momentum * self.success_rates[dim_index]\n                self.step_sizes[dim_index] *= (1 - self.adaptation_rate * (1 - self.success_rates[dim_index]))\n\n            self.step_sizes[dim_index] = np.clip(self.step_sizes[dim_index], 1e-6, 5.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveStepSize scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["24c3f0ae-22cc-4077-8905-04766cffa673"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "756bc5f6-4659-46db-ace2-82c376da502d", "fitness": -Infinity, "name": "SimplifiedCMAES", "description": "Streamlined CMA-ES with simplified covariance update and adaptive step size, prioritizing computational efficiency and faster convergence.", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=2):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = cs\n        self.damps = damp\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.sigma = 0.5\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.mean = np.zeros(self.dim)\n        self.evals = 0\n        self.lb = -5\n        self.ub = 5\n\n    def sample(self):\n        z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n        x = self.mean[:, np.newaxis] + self.sigma * np.sqrt(self.C) @ z\n        x = np.clip(x, self.lb, self.ub)\n        return x\n\n    def update(self, x, fvals):\n        arindex = np.argsort(fvals)\n        x = x[:, arindex]\n        xmean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n        y = (x[:, :self.mu] - self.mean[:, np.newaxis]) / self.sigma\n        self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (xmean - self.mean) / self.sigma\n        \n        # Simplified rank-one update\n        self.C = (1 - self.c1) * self.C + self.c1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :])\n        \n        self.mean = xmean\n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.pc) / self.chiN - 1))\n        \n        # Ensure positive definiteness, simplified\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        if not np.all(np.linalg.eigvalsh(self.C) > 0):\n            self.C = self.C + 1e-6 * np.eye(self.dim)\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n\n        while self.evals < self.budget:\n            x = self.sample()\n            fvals = np.array([func(x[:, i]) for i in range(self.popsize)])\n            self.evals += self.popsize\n\n            for i in range(self.popsize):\n                if fvals[i] < self.f_opt:\n                    self.f_opt = fvals[i]\n                    self.x_opt = x[:, i]\n\n            self.update(x, fvals)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: Eigenvalues did not converge.", "error": "", "parent_ids": ["6e029120-2363-4f25-b056-b96fb98ccf91"], "operator": null, "metadata": {}}
{"id": "5ae557b8-b542-41f8-ba6c-05aaf8b299ae", "fitness": 0.4762675780121818, "name": "AdaptiveHybridPSO_DE", "description": "Simplified adaptive PSO-DE using a single diversity-based probability to switch between PSO and DE updates, and adaptive inertia weight.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with simplified diversity-based update probability.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        self.best_fitness = np.array([np.inf] * self.pop_size)\n\n    def evaluate_population(self, func):\n        \"\"\"Evaluates population fitness and updates best positions.\"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness[i]:\n                    self.best_fitness[i] = f\n                    self.best_pos[i] = self.pop[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n    \n    def calculate_diversity(self):\n        \"\"\"Calculates population diversity based on distance from centroid.\"\"\"\n        centroid = np.mean(self.pop, axis=0)\n        distances = np.linalg.norm(self.pop - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n\n    def update_positions(self, func):\n        \"\"\"Updates particle positions using adaptive PSO and DE with a single probability.\"\"\"\n        diversity = self.calculate_diversity()\n        normalized_diversity = diversity / (func.bounds.ub[0] - func.bounds.lb[0])\n\n        # Adapt inertia weight based on diversity\n        w = self.w_start - (self.w_start - self.w_end) * (1 - normalized_diversity)\n\n\n        for i in range(self.pop_size):\n            if np.random.rand() < normalized_diversity: # Use diversity as probability for DE\n                # DE update\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                new_pos = trial #DE result becomes the new position\n            else:\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = w * (self.pop[i] - self.best_pos[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n                new_pos = self.pop[i] + velocity\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n\n            # Evaluate and update\n            if self.eval_count < self.budget:\n                f_new = func(new_pos)\n                self.eval_count += 1\n\n                if f_new < self.fitness[i]:\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_new\n\n                    if f_new < self.best_fitness[i]:\n                        self.best_fitness[i] = f_new\n                        self.best_pos[i] = self.pop[i].copy()\n\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def __call__(self, func):\n        \"\"\"Optimizes the function.\"\"\"\n        self.initialize_population(func)\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.476 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["466b481c-ca88-4f0b-b74c-b18b160e02cf"], "operator": null, "metadata": {"aucs": [0.19841926715295932, 0.18646467215961293, 0.913398597984939, 0.24073798425371928, 0.31706531390648984, 0.9704191568068924, 0.3176532629515775, 0.29748695430800287, 0.33743981423213476, 0.2383100833241546, 0.39505160189488875, 0.9980316537596486, 0.254411853202571, 0.3472065935743254, 0.6504493908428071, 0.9519271033286796, 0.24984709695677743, 0.9770085477071278, 0.19385532244638437, 0.49016728944994326]}}
{"id": "a8ecc08f-0269-46a8-ad6e-fb325b2bebc1", "fitness": 0.5248011788212976, "name": "AdaptiveHybridPSO_DE", "description": "Simplifies Adaptive Hybrid PSO-DE by dynamically adjusting PSO/DE probability based on global best stagnation, promoting diversity when improvement stalls.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, F=0.6, CR=0.8, p_pso=0.5, stagnation_threshold=50):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            p_pso (float): Initial probability of applying PSO update.\n            stagnation_threshold (int): Number of iterations without improvement to adjust p_pso.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.p_pso = p_pso\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.stagnation_threshold = stagnation_threshold\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        self.global_best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with adaptive selection.\n        \"\"\"\n        if self.stagnation_counter > self.stagnation_threshold:\n             self.p_pso = 0.1 if self.p_pso > 0.5 else 0.9  # Switch strategy\n             self.stagnation_counter = 0\n\n        for i in range(self.pop_size):\n            if np.random.rand() < self.p_pso:\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = self.w * (self.pop[i] - self.global_best_pos) + self.c1 * r1 * (self.global_best_pos - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n                new_pos = self.pop[i] + velocity\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub) # Constraint handling\n            else:\n                # DE update\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                new_pos = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        new_pos[j] = mutant[j]\n            \n            f_trial = func(new_pos)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_pos = self.pop[i].copy()\n                    self.stagnation_counter = 0 # Reset stagnation counter\n            else:\n                self.stagnation_counter += 1\n            \n            if self.eval_count >= self.budget:\n                 break\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            self.update_positions(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.525 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1f5e4c29-a3c4-4fc1-a6f3-e6d3700f2023"], "operator": null, "metadata": {"aucs": [0.21950189353175642, 0.39356073316834395, 0.8454825241771764, 0.17966960188534142, 0.2662749739088658, 0.3567442131130806, 0.38274603294981957, 0.32436400387364006, 0.2762485377480425, 0.9431526522945499, 0.928614923659575, 0.9955362530286777, 0.36879469967909695, 0.42114048486105427, 0.9187150248982147, 0.7743458148137592, 0.2858924761672532, 0.9500462546720713, 0.17018116125937743, 0.4950113167362561]}}
{"id": "8195a2d2-7055-48e7-9226-c517447c2574", "fitness": 0.375725786652804, "name": "AdaptiveHybridPSO_DE", "description": "Simplified adaptive hybrid PSO-DE that adjusts strategy selection based on recent performance with a smoothed adaptation rate.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, F=0.6, CR=0.8, adapt_rate=0.05):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            adapt_rate (float): Adaptation rate for strategy selection.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.adapt_rate = adapt_rate\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.pso_prob = 0.5  # Probability of using PSO, initialized to 0.5\n        self.success_pso = 0\n        self.success_de = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        self.best_fitness = np.array([np.inf] * self.pop_size)\n\n    def evaluate_population(self, func):\n        \"\"\"\n        Evaluates the fitness of each particle in the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness[i]:\n                    self.best_fitness[i] = f\n                    self.best_pos[i] = self.pop[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO or DE based on pso_prob.\n        \"\"\"\n        self.success_pso = 0\n        self.success_de = 0\n\n        for i in range(self.pop_size):\n            if np.random.rand() < self.pso_prob:\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = self.w * (self.pop[i] - self.best_pos[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n                new_pos = self.pop[i] + velocity\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                trial = new_pos.copy()\n                method = \"PSO\"\n            else:\n                # DE update\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                method = \"DE\"\n\n            # Evaluate and update\n            if self.eval_count < self.budget:\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.best_fitness[i]:\n                        self.best_fitness[i] = f_trial\n                        self.best_pos[i] = self.pop[i].copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = self.pop[i].copy()\n                    \n                    if method == \"PSO\":\n                        self.success_pso += 1\n                    else:\n                        self.success_de += 1\n            else:\n                break\n\n        # Strategy adaptation using a smoother update\n        total_success = self.success_pso + self.success_de\n        if total_success > 0:\n            new_pso_prob = self.success_pso / total_success\n            self.pso_prob = (1 - self.adapt_rate) * self.pso_prob + self.adapt_rate * new_pso_prob\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.376 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e90638bc-d735-4124-9e04-b8190c873ac4"], "operator": null, "metadata": {"aucs": [0.1800337060778524, 0.3063066552236601, 0.35555429285929474, 0.5326056480302072, 0.528182197200453, 0.46988655088799147, 0.2785449793477328, 0.2784477912609853, 0.34831618590480884, 0.17460533777229026, 0.21348347872660978, 0.9994141268281657, 0.25388604227659706, 0.2769779063257277, 0.6397548478243567, 0.3444374683040198, 0.2739963894639983, 0.3781498216835655, 0.18160760833232226, 0.5003246987254416]}}
{"id": "1627d50e-97f9-411f-a340-19819fa38e80", "fitness": 0.6117116840828751, "name": "SimplifiedHybridPSO_DE", "description": "Simplifies Hybrid PSO-DE by using a fixed probability for PSO/DE selection, removing velocity and success tracking for enhanced efficiency.", "code": "import numpy as np\n\nclass SimplifiedHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, F=0.6, CR=0.8, p_pso=0.5):\n        \"\"\"\n        Initializes the Simplified Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            p_pso (float): Probability of using PSO.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.p_pso = p_pso\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n\n    def evaluate_population(self, func):\n        \"\"\"\n        Evaluates the fitness of each particle in the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness:\n                    self.best_fitness = f\n                    self.best_pos = self.pop[i].copy()\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n\n            else:\n                break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO or DE with fixed probability.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            if np.random.rand() < self.p_pso:\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                new_pos = self.pop[i] + self.w * (self.best_pos - self.pop[i]) * r1  + self.c1 * r1 * (self.global_best_pos - self.pop[i]) + self.c2 * r2 * (self.best_pos - self.pop[i])\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n            else:\n                # DE update\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                new_pos = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        new_pos[j] = mutant[j]\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate and update\n            if self.eval_count < self.budget:\n                f_trial = func(new_pos)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = self.pop[i].copy()\n                if f_trial < self.best_fitness:\n                  self.best_fitness = f_trial\n                  self.best_pos = new_pos.copy()\n\n            else:\n                break\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Simplified Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 3, "feedback": "The algorithm SimplifiedHybridPSO_DE scored 0.612 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e90638bc-d735-4124-9e04-b8190c873ac4"], "operator": null, "metadata": {"aucs": [0.4287064056988339, 0.33100948127644425, 0.8503982194634958, 0.9170051035490392, 0.8794063566300147, 0.2442246688319326, 0.321540205000586, 0.8100100630025453, 0.870783957599827, 0.2369017167938937, 0.9361542620033175, 0.9996627669310101, 0.46449157583831757, 0.25545291974502693, 0.9400689020347068, 0.9076588279963513, 0.7125604077310346, 0.3815260047569248, 0.2102872624340183, 0.5363845743401827]}}
{"id": "34991df0-9971-40d8-a6e6-fa136a815abb", "fitness": 0.7748704230141995, "name": "AdaptiveHybridPSO_DE", "description": "Simplified adaptive hybrid PSO-DE with a single probability for choosing between PSO and DE updates, and simplified parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, F=0.6, CR=0.8, p_adapt=0.05, p_pso=0.5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            p_adapt (float): Probability of adapting p_pso.\n            p_pso (float): Initial probability of using PSO.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.p_adapt = p_adapt\n        self.p_pso = p_pso\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.success_pso = 0\n        self.success_de = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        for i in range(self.pop_size):\n            f = func(self.pop[i])\n            self.eval_count += 1\n            self.fitness[i] = f\n            if f < self.best_fitness:\n                self.best_fitness = f\n                self.best_pos[i] = self.pop[i].copy()\n            if f < self.global_best_fitness:\n                self.global_best_fitness = f\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with adaptive probability.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            old_fitness = self.fitness[i]\n            \n            if np.random.rand() < self.p_pso:\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = self.w * (self.pop[i] - self.best_pos[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n                new_pos = self.pop[i] + velocity\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                f_new = func(new_pos)\n                self.eval_count += 1\n                \n                if f_new < self.fitness[i]:\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_new\n                    if f_new < self.best_fitness:\n                        self.best_fitness = f_new\n                        self.best_pos[i] = self.pop[i].copy()\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_pos = self.pop[i].copy()\n                    self.success_pso += 1\n                \n            else:\n                # DE update\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.best_fitness:\n                        self.best_fitness = f_trial\n                        self.best_pos[i] = self.pop[i].copy()\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = self.pop[i].copy()\n                    self.success_de += 1\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n            if np.random.rand() < self.p_adapt and (self.success_pso + self.success_de) > 0:\n                self.p_pso = self.success_pso / (self.success_pso + self.success_de)\n                self.success_pso = 0\n                self.success_de = 0\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.775 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e90638bc-d735-4124-9e04-b8190c873ac4"], "operator": null, "metadata": {"aucs": [0.3259773119516268, 0.7961586187034295, 0.8322123977087289, 0.9360687773455743, 0.8264450444297969, 0.8949045312202757, 0.788524067065933, 0.7969072016224295, 0.8738078175893196, 0.7943882318953931, 0.9154730315219117, 0.9975868932372192, 0.5448457258145714, 0.8643278385133769, 0.9434338923799594, 0.8945644546404582, 0.7605472416095509, 0.9240451325464737, 0.27213487420437155, 0.5150553762835905]}}
{"id": "ceaa2f1e-c619-453c-8876-caec9ccdfd8c", "fitness": 0.6598036976684305, "name": "HybridPSO_DE", "description": "Simplifies adaptive Hybrid PSO-DE by directly adjusting PSO/DE parameters based on the relative improvement they achieve, removing explicit probability update and streamlining parameter adaptation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7, adapt_rate=0.1):\n        \"\"\"\n        Initializes the Hybrid PSO-DE optimizer with simplified adaptive parameter adjustment.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            adapt_rate (float): Rate for adapting PSO/DE parameters.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.adapt_rate = adapt_rate\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.pso_params = {'w': w_start, 'c1': c1, 'c2': c2}\n        self.de_params = {'F': F, 'CR': CR}\n        self.pso_success = 0.0  # track relative improvement\n        self.de_success = 0.0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        self.best_fitness = np.array([np.inf] * self.pop_size)\n\n    def evaluate_population(self, func):\n        \"\"\"\n        Evaluates the fitness of each particle in the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness[i]:\n                    self.best_fitness[i] = f\n                    self.best_pos[i] = self.pop[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE and adapts parameters based on success.\n        \"\"\"\n        pso_improvements = 0.0\n        de_improvements = 0.0\n        w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget)\n        self.pso_params['w'] = w\n\n        for i in range(self.pop_size):\n            # PSO update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = self.pso_params['w'] * (self.pop[i] - self.best_pos[i]) + self.pso_params['c1'] * r1 * (self.best_pos[i] - self.pop[i]) + self.pso_params['c2'] * r2 * (self.global_best_pos - self.pop[i])\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n            f_trial_pso = func(new_pos) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n            \n\n            # DE update\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.pop[a] + self.de_params['F'] * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.de_params['CR'] or j == j_rand:\n                    trial[j] = mutant[j]\n            f_trial_de = func(trial) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n            \n            if f_trial_pso < f_trial_de:\n                if f_trial_pso < self.fitness[i]:\n                    pso_improvements += (self.fitness[i] - f_trial_pso) / max(abs(self.fitness[i]), 1e-9) # relative improvement\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_trial_pso\n                    if f_trial_pso < self.best_fitness[i]:\n                        self.best_fitness[i] = f_trial_pso\n                        self.best_pos[i] = self.pop[i].copy()\n                    if f_trial_pso < self.global_best_fitness:\n                        self.global_best_fitness = f_trial_pso\n                        self.global_best_pos = self.pop[i].copy()\n            else:\n                if f_trial_de < self.fitness[i]:\n                    de_improvements += (self.fitness[i] - f_trial_de) / max(abs(self.fitness[i]), 1e-9)\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial_de\n                    if f_trial_de < self.best_fitness[i]:\n                        self.best_fitness[i] = f_trial_de\n                        self.best_pos[i] = self.pop[i].copy()\n                    if f_trial_de < self.global_best_fitness:\n                        self.global_best_fitness = f_trial_de\n                        self.global_best_pos = self.pop[i].copy()\n\n        # Parameter adaptation\n        total_improvements = pso_improvements + de_improvements\n        if total_improvements > 0:\n            pso_ratio = pso_improvements / total_improvements\n            de_ratio = de_improvements / total_improvements\n\n            # Adjust PSO parameters\n            self.pso_params['c1'] *= (1 + self.adapt_rate * (pso_ratio - 0.5))\n            self.pso_params['c2'] *= (1 + self.adapt_rate * (pso_ratio - 0.5))\n            self.pso_params['c1'] = np.clip(self.pso_params['c1'], 1.0, 4.0)\n            self.pso_params['c2'] = np.clip(self.pso_params['c2'], 1.0, 4.0)\n\n            # Adjust DE parameters\n            self.de_params['F'] *= (1 + self.adapt_rate * (de_ratio - 0.5))\n            self.de_params['CR'] *= (1 + self.adapt_rate * (de_ratio - 0.5))\n            self.de_params['F'] = np.clip(self.de_params['F'], 0.1, 1.0)\n            self.de_params['CR'] = np.clip(self.de_params['CR'], 0.1, 1.0)\n\n        if self.eval_count >= self.budget:\n            return\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.evaluate_population(func)\n        \n        while self.eval_count < self.budget:\n            self.update_positions(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 3, "feedback": "The algorithm HybridPSO_DE scored 0.660 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e90638bc-d735-4124-9e04-b8190c873ac4"], "operator": null, "metadata": {"aucs": [0.28256592553174, 0.8483618134527999, 0.9031064870350073, 0.9722089557844757, 0.31010311991992134, 0.9322055887614931, 0.5120358700453772, 0.8882754517409078, 0.2984424320926684, 0.1792557951423247, 0.9656790172358887, 0.9985302165588454, 0.5113333227075243, 0.8759096181263054, 0.743188542940353, 0.9446301575405635, 0.30912274138845586, 0.9467994435784252, 0.2912923392919581, 0.4830271144935735]}}
{"id": "d4dac1cf-1c0f-45da-9fc0-a94af11cb837", "fitness": 0.6575040251227698, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies Hybrid PSO-DE by adaptively adjusting the probability of applying either PSO or DE based on the improvement rate of each strategy.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, F=0.6, CR=0.8, adapt_rate=0.1):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive strategy selection.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            adapt_rate (float): Rate at which to adjust strategy probabilities.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.adapt_rate = adapt_rate\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.pso_prob = 0.5\n        self.de_prob = 0.5\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_pos = self.pop.copy()\n        self.best_fitness = self.fitness.copy()\n        self.global_best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def pso_update(self, i, func):\n        \"\"\"Applies PSO update to particle i.\"\"\"\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        velocity = self.w * (self.pop[i] - self.best_pos[i]) + \\\n                   self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + \\\n                   self.c2 * r2 * (self.global_best_pos - self.pop[i])\n        new_pos = self.pop[i] + velocity\n        new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n        return new_pos\n\n    def de_update(self, i, func):\n        \"\"\"Applies DE update to particle i.\"\"\"\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        j_rand = np.random.randint(self.dim)\n        trial = self.pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial[j] = mutant[j]\n        return trial\n\n    def __call__(self, func):\n        \"\"\"Optimizes the function.\"\"\"\n        self.initialize_population(func)\n        pso_success = 0\n        de_success = 0\n\n        while self.eval_count < self.budget:\n            pso_count = 0\n            de_count = 0\n            for i in range(self.pop_size):\n                if np.random.rand() < self.pso_prob:\n                    # PSO\n                    new_pos = self.pso_update(i, func)\n                    pso_count += 1\n                else:\n                    # DE\n                    new_pos = self.de_update(i, func)\n                    de_count += 1\n\n                f_trial = func(new_pos)\n                self.eval_count += 1\n                if f_trial < self.fitness[i]:\n                    if np.random.rand() < self.pso_prob:\n                        pso_success +=1\n                    else:\n                        de_success +=1\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_trial\n                    if f_trial < self.best_fitness[i]:\n                        self.best_pos[i] = new_pos.copy()\n                        self.best_fitness[i] = f_trial\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = new_pos.copy()\n                if self.eval_count >= self.budget:\n                    break\n            if pso_count + de_count > 0:\n                pso_rate = pso_success / (pso_count + de_count) if (pso_count + de_count) > 0 else 0.5\n                de_rate = de_success / (pso_count + de_count) if (pso_count + de_count) > 0 else 0.5\n            else:\n                 pso_rate = 0.5\n                 de_rate = 0.5\n\n\n            self.pso_prob += self.adapt_rate * (pso_rate - self.pso_prob)\n            self.de_prob += self.adapt_rate * (de_rate - self.de_prob)\n            self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9)\n            self.de_prob = np.clip(self.de_prob, 0.1, 0.9)\n            pso_success = 0\n            de_success = 0\n\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 3, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.658 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e90638bc-d735-4124-9e04-b8190c873ac4"], "operator": null, "metadata": {"aucs": [0.25162382497076474, 0.8859026412265523, 0.8527761158719452, 0.970562111178036, 0.921053401228151, 0.43558426541984174, 0.8874845815381149, 0.3321598479671576, 0.945819223116438, 0.7357184367289166, 0.36046198036690436, 0.9998261492475988, 0.32175910770232896, 0.4182886027777133, 0.9090915404329709, 0.9119197523792834, 0.25245652552485565, 0.9620440200034575, 0.2959853784821508, 0.499562996292216]}}
{"id": "2eff1fcb-5806-41de-9c09-0feec8a79e68", "fitness": 0.6472650643169761, "name": "AdaptiveHybridPSO_DE", "description": "Simplifies Adaptive Hybrid PSO-DE by removing the local best and adaptively adjusting PSO/DE probability based on global best improvement rate.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7, p_pso=0.5, p_pso_adapt=True):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with probabilistic PSO/DE selection.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            p_pso (float): Initial probability of applying PSO update.\n            p_pso_adapt (bool): Adapt p_pso based on performance.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.p_pso = p_pso\n        self.p_pso_adapt = p_pso_adapt\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.success_history = []\n        self.success_window = 10 # Number of iterations to track success\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n\n    def evaluate_population(self, func):\n         \"\"\"\n         Evaluates the fitness of each particle in the population.\n         \"\"\"\n         for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n                    self.success_history.append(1)  # Mark success\n                else:\n                    self.success_history.append(0)  # Mark failure\n\n            else:\n                 break\n         if len(self.success_history) > self.success_window:\n            self.success_history.pop(0)  # Keep window size constant\n    def update_pso_probability(self):\n        \"\"\"\n        Adjusts the probability of applying PSO based on recent global best improvements.\n        \"\"\"\n        if not self.p_pso_adapt:\n            return\n\n        if len(self.success_history) < self.success_window:\n            return # wait until success window is full\n\n        success_rate = sum(self.success_history) / self.success_window\n        if success_rate > 0.5: # more than half the time, global best improved\n            self.p_pso *= 0.95  # favor DE (reduce PSO prob)\n        else:\n            self.p_pso *= 1.05  # favor PSO (increase PSO prob)\n        self.p_pso = np.clip(self.p_pso, 0.1, 0.9)\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with adaptive selection.\n        \"\"\"\n        w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget) # adaptive w\n\n        for i in range(self.pop_size):\n            if np.random.rand() < self.p_pso:\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = w * (self.pop[i] - self.global_best_pos) + self.c1 * r1 * (self.global_best_pos - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n                new_pos = self.pop[i] + velocity\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub) # Constraint handling\n            else:\n                # DE update\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                new_pos = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        new_pos[j] = mutant[j]\n\n            # Evaluate and update\n            if self.eval_count < self.budget:\n                f_trial = func(new_pos)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_trial\n\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_pos = self.pop[i].copy()\n                    self.success_history.append(1)  # Mark success\n\n                else:\n                    self.success_history.append(0)  # Mark failure\n            else:\n                break\n        if len(self.success_history) > self.success_window:\n            self.success_history.pop(0)  # Keep window size constant\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.evaluate_population(func)\n        \n        while self.eval_count < self.budget:\n            self.update_positions(func)\n            self.update_pso_probability()\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.647 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1f5e4c29-a3c4-4fc1-a6f3-e6d3700f2023"], "operator": null, "metadata": {"aucs": [0.36561679024759264, 0.21327787241891116, 0.8826156756032524, 0.2536605769861072, 0.3047171253083507, 0.9278955269565067, 0.8709209137564479, 0.8759155864339605, 0.9249135181696211, 0.27748829344823345, 0.8971957646434618, 0.9988578527661748, 0.2574994220338338, 0.9159381079860104, 0.9538665419939723, 0.9340270656993883, 0.4082144995528242, 0.9486178409958247, 0.22810863088041344, 0.5059536804586324]}}
{"id": "7ca7393c-f5d8-4a5e-bcf2-7814ef552998", "fitness": 0.7593521058892089, "name": "HybridPSO_DE", "description": "Simplified Hybrid PSO-DE with enhanced exploration by using a larger DE scaling factor and adaptive DE probability based on global best stagnation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, c=1.0, F=0.9, CR=0.7, de_prob_init=0.9, stagnation_threshold=50):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c (float): Cognitive and social coefficient for PSO (c1=c2=c).\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n            stagnation_threshold (int): Number of iterations without improvement to increase DE probability.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c = c\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.stagnation_threshold = stagnation_threshold\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.stagnation_counter = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n                self.stagnation_counter = 0  # Reset stagnation counter\n            else:\n                self.stagnation_counter += 1\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update\n            r1 = np.random.rand(self.dim)\n            velocity = w * r1 * (self.global_best_pos - self.pop[i])\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n                    self.stagnation_counter = 0 # Reset stagnation counter\n            elif f_new < self.global_best_fitness:\n                 self.global_best_fitness = f_new\n                 self.global_best_pos = new_pos.copy()\n                 self.stagnation_counter = 0\n            elif self.fitness[i] < self.global_best_fitness:\n                 self.global_best_fitness = self.fitness[i]\n                 self.global_best_pos = self.pop[i].copy()\n                 self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n            \n            # Adjust DE probability based on stagnation\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.de_prob = min(1.0, self.de_prob * 1.1)  # Increase DE probability\n            else:\n                self.de_prob = self.de_prob_init  # Reset to initial value\n\n            self.update_population(func, w)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 3, "feedback": "The algorithm HybridPSO_DE scored 0.759 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ecd29947-b98e-4243-b33c-a6548b6d9b2b"], "operator": null, "metadata": {"aucs": [0.3378123076999807, 0.7395698569185146, 0.8635900093903093, 0.9537265834539749, 0.8975508228560618, 0.9257458388886419, 0.37241626589129095, 0.8328812421047046, 0.8877239072940827, 0.8775341797984624, 0.9472042770311178, 0.9998249470028386, 0.3289865097966067, 0.8832868527800405, 0.950851507144574, 0.9059093190053592, 0.7870304282736571, 0.9319986530946804, 0.24608881017134832, 0.5173097991879301]}}
{"id": "4e3b4494-728f-4ce2-9d0f-b6d7018bdafc", "fitness": 0.4223794878153685, "name": "AdaptiveHybridPSO_DE", "description": "Simplifies Adaptive Hybrid PSO-DE by directly blending PSO and DE updates with a diversity-adaptive probability, reducing parameter complexity while maintaining exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, F=0.5, CR=0.7, diversity_threshold=0.5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with population diversity-based blending.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.diversity_threshold = diversity_threshold # Tunable parameter for switching between PSO and DE\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n\n    def evaluate_population(self, func):\n        \"\"\"Evaluates population fitness and updates best positions.\"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n    \n    def calculate_diversity(self, func):\n        \"\"\"Calculates population diversity based on average Euclidean distance.\"\"\"\n        distances = np.linalg.norm(self.pop - self.global_best_pos, axis=1)\n        diversity = np.mean(distances) / (func.bounds.ub[0] - func.bounds.lb[0]) # Normalize to [0, 1]\n        return diversity\n\n    def update_positions(self, func):\n        \"\"\"Updates particle positions using adaptive PSO and DE blending.\"\"\"\n        diversity = self.calculate_diversity(func)\n\n        for i in range(self.pop_size):\n            # PSO update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = self.w * (self.pop[i] - self.global_best_pos) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n            pso_new_pos = self.pop[i] + velocity\n            pso_new_pos = np.clip(pso_new_pos, func.bounds.lb, func.bounds.ub)\n\n            # DE update\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n            \n            # Crossover\n            de_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    de_trial[j] = mutant[j]\n\n            # Adaptive Blending\n            if diversity > self.diversity_threshold: # High diversity: Explore with DE\n                new_pos = de_trial\n            else:  # Low diversity: Exploit with PSO\n                new_pos = pso_new_pos\n\n            # Evaluate and Update\n            if self.eval_count < self.budget:\n                f_new = func(new_pos)\n                self.eval_count += 1\n\n                if f_new < self.fitness[i]:\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_new\n                    self.best_pos[i] = self.pop[i].copy() # Update personal best too\n\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def __call__(self, func):\n        \"\"\"Optimizes the function.\"\"\"\n        self.initialize_population(func)\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.422 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["466b481c-ca88-4f0b-b74c-b18b160e02cf"], "operator": null, "metadata": {"aucs": [0.25451357107420414, 0.2788924340980028, 0.33955316879383335, 0.35266175866249516, 0.37504616925193146, 0.46569688813318066, 0.3283217245889767, 0.39625013210597604, 0.7045012995459006, 0.3613330420983554, 0.4377694960274673, 0.9947440801823123, 0.2914575196771324, 0.23573450984214162, 0.6352976038240301, 0.360276812294794, 0.39214875779574754, 0.46624212546718846, 0.26314699965961985, 0.5140016631840798]}}
{"id": "5264e90e-7732-4d1c-b37a-87ba6750fe76", "fitness": 0.526112848017642, "name": "HybridPSO_DE", "description": "Simplified Hybrid PSO-DE with adaptive inertia, simplified velocity update, and probabilistic DE with binomial crossover for enhanced exploration-exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, c=0.1, F=0.5, CR=0.7, de_prob=0.3):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c (float): Cognitive coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob (float): Probability of applying DE in each iteration.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c = c\n        self.F = F\n        self.CR = CR\n        self.de_prob = de_prob\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(self.pop[i]) for i in range(self.pop_size)])\n        self.eval_count += self.pop_size\n        self.global_best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update\n            r1 = np.random.rand(self.dim)\n            velocity = w * (self.pop[i] - self.global_best_pos) + self.c * r1 * (self.global_best_pos - self.pop[i])  # Simplified Velocity Update\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                new_pos = trial\n            \n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = new_pos.copy()\n            elif f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = new_pos.copy()\n            elif self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n            self.update_population(func, w)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 3, "feedback": "The algorithm HybridPSO_DE scored 0.526 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ecd29947-b98e-4243-b33c-a6548b6d9b2b"], "operator": null, "metadata": {"aucs": [0.16632214683710622, 0.3444945881903979, 0.49040641359471915, 0.7801334547547758, 0.5749097518620483, 0.6020161202761967, 0.3650911452095834, 0.49411689832443584, 0.5692929806688034, 0.458519962261141, 0.6832004882055596, 0.9774849616387182, 0.30651349095992264, 0.42037221636525823, 0.778865090378682, 0.655526413401721, 0.3811922979711566, 0.7731338717243452, 0.19835257281156038, 0.5023120949167075]}}
{"id": "5ea4d250-c0bf-4ff7-ba00-f47c111cbb24", "fitness": 0.6525927783692831, "name": "HybridPSO_DE", "description": "Simplifies the adaptive Hybrid PSO-DE by removing individual best positions, focusing on global best influence and dynamically adjusting PSO/DE probability based on recent success.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7, p_adapt=0.1):\n        \"\"\"\n        Initializes the Hybrid PSO-DE optimizer with adaptive strategy selection.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            p_adapt (float): Probability of adapting the strategy.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.p_adapt = p_adapt  # Probability to adapt\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.pso_success = 0.5  # Initial probability of using PSO\n        self.de_success = 0.5   # Initial probability of using DE\n        self.velocities = None\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.velocities = np.zeros((self.pop_size, self.dim))\n\n    def evaluate_population(self, func):\n        \"\"\"\n        Evaluates the fitness of each particle in the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with adaptive probability.\n        \"\"\"\n        w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget) # adaptive w\n        pso_count = 0\n        de_count = 0\n\n        for i in range(self.pop_size):\n            if np.random.rand() < self.pso_success:\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = w * self.velocities[i] + self.c1 * r1 * (self.global_best_pos - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n                new_pos = self.pop[i] + self.velocities[i]\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub) # Constraint handling\n                trial = new_pos.copy() # trial solution for PSO\n                pso_count += 1\n            else:\n                # DE update\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                de_count += 1\n\n            # Evaluate and update\n            if self.eval_count < self.budget:\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n        # Strategy adaptation\n        if np.random.rand() < self.p_adapt:\n            total = pso_count + de_count\n            if total > 0:\n                self.pso_success = pso_count / total\n                self.de_success = de_count / total\n            else:\n                self.pso_success = 0.5\n                self.de_success = 0.5\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.evaluate_population(func)\n        \n        while self.eval_count < self.budget:\n            self.update_positions(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 3, "feedback": "The algorithm HybridPSO_DE scored 0.653 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e90638bc-d735-4124-9e04-b8190c873ac4"], "operator": null, "metadata": {"aucs": [0.4004726948244849, 0.72213082144462, 0.7244037928510187, 0.9240473921200799, 0.8207920330307672, 0.9091005277679741, 0.29382437395570216, 0.5209074794086848, 0.4664263364330202, 0.6648835660008736, 0.8602701176928951, 0.9983852670479976, 0.32668237931224486, 0.4899296771723525, 0.7285907865796505, 0.8605730927790585, 0.7426410638451715, 0.8969541862525915, 0.23489437258435597, 0.4659456062821198]}}
{"id": "1110b4f8-347f-4f87-99f0-61e4a652defb", "fitness": -Infinity, "name": "HybridPSO_DE", "description": "Adaptively adjusts PSO/DE parameters and exploration range based on the success of each strategy, simplifying parameter updates and using a shrinking exploration range.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7, adapt_rate=0.1, exploration_reduction=0.99):\n        \"\"\"\n        Initializes the Hybrid PSO-DE optimizer with simplified adaptive parameter adjustment and shrinking exploration range.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            adapt_rate (float): Rate for adapting PSO/DE parameters.\n            exploration_reduction (float): Reduction factor for exploration range per iteration.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.adapt_rate = adapt_rate\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.pso_params = {'w': w_start, 'c1': c1, 'c2': c2}\n        self.de_params = {'F': F, 'CR': CR}\n        self.pso_success = 0.0  # track relative improvement\n        self.de_success = 0.0\n        self.exploration_reduction = exploration_reduction\n        self.current_bounds = None\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.current_bounds = {'lb': func.bounds.lb, 'ub': func.bounds.ub}\n        self.pop = np.random.uniform(self.current_bounds['lb'], self.current_bounds['ub'], size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        self.best_fitness = np.array([np.inf] * self.pop_size)\n\n    def evaluate_population(self, func):\n        \"\"\"\n        Evaluates the fitness of each particle in the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness[i]:\n                    self.best_fitness[i] = f\n                    self.best_pos[i] = self.pop[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE and adapts parameters based on success.\n        \"\"\"\n        pso_improvements = 0.0\n        de_improvements = 0.0\n        w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget)\n        self.pso_params['w'] = w\n\n        for i in range(self.pop_size):\n            # PSO update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = self.pso_params['w'] * (self.pop[i] - self.best_pos[i]) + self.pso_params['c1'] * r1 * (self.best_pos[i] - self.pop[i]) + self.pso_params['c2'] * r2 * (self.global_best_pos - self.pop[i])\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, self.current_bounds['lb'], self.current_bounds['ub'])\n            f_trial_pso = func(new_pos) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n            \n\n            # DE update\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.pop[a] + self.de_params['F'] * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, self.current_bounds['lb'], self.current_bounds['ub'])\n\n            # Crossover\n            trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.de_params['CR'] or j == j_rand:\n                    trial[j] = mutant[j]\n            f_trial_de = func(trial) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n            \n            if f_trial_pso < f_trial_de:\n                if f_trial_pso < self.fitness[i]:\n                    pso_improvements += (self.fitness[i] - f_trial_pso) / max(abs(self.fitness[i]), 1e-9) # relative improvement\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_trial_pso\n                    if f_trial_pso < self.best_fitness[i]:\n                        self.best_fitness[i] = f_trial_pso\n                        self.best_pos[i] = self.pop[i].copy()\n                    if f_trial_pso < self.global_best_fitness:\n                        self.global_best_fitness = f_trial_pso\n                        self.global_best_pos = self.pop[i].copy()\n            else:\n                if f_trial_de < self.fitness[i]:\n                    de_improvements += (self.fitness[i] - f_trial_de) / max(abs(self.fitness[i]), 1e-9)\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial_de\n                    if f_trial_de < self.best_fitness[i]:\n                        self.best_fitness[i] = f_trial_de\n                        self.best_pos[i] = self.pop[i].copy()\n                    if f_trial_de < self.global_best_fitness:\n                        self.global_best_fitness = f_trial_de\n                        self.global_best_pos = self.pop[i].copy()\n\n        # Parameter adaptation\n        total_improvements = pso_improvements + de_improvements\n\n        # Adjust PSO parameters based on the overall performance of PSO and DE\n        if total_improvements > 0:\n            pso_ratio = pso_improvements / total_improvements\n            de_ratio = de_improvements / total_improvements\n            \n            self.pso_params['c1'] = 2.0 + 1.0 * (pso_ratio - de_ratio)\n            self.pso_params['c2'] = 2.0 + 1.0 * (pso_ratio - de_ratio)\n\n            self.de_params['F'] = 0.5 + 0.3 * (de_ratio - pso_ratio)\n            self.de_params['CR'] = 0.7 + 0.2 * (de_ratio - pso_ratio)\n        \n        # Clip parameters to ensure they remain within reasonable bounds\n        self.pso_params['c1'] = np.clip(self.pso_params['c1'], 1.0, 3.0)\n        self.pso_params['c2'] = np.clip(self.pso_params['c2'], 1.0, 3.0)\n        self.de_params['F'] = np.clip(self.de_params['F'], 0.2, 0.8)\n        self.de_params['CR'] = np.clip(self.de_params['CR'], 0.5, 0.9)\n            \n        # Reduce exploration range\n        range_width = self.current_bounds['ub'] - self.current_bounds['lb']\n        center = (self.current_bounds['ub'] + self.current_bounds['lb']) / 2\n        new_range_width = range_width * self.exploration_reduction\n        self.current_bounds['lb'] = center - new_range_width / 2\n        self.current_bounds['ub'] = center + new_range_width / 2\n        self.current_bounds['lb'] = max(self.current_bounds['lb'], func.bounds.lb)\n        self.current_bounds['ub'] = min(self.current_bounds['ub'], func.bounds.ub)\n        \n        self.pop = np.clip(self.pop, self.current_bounds['lb'], self.current_bounds['ub'])\n            \n\n        if self.eval_count >= self.budget:\n            return\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.evaluate_population(func)\n        \n        while self.eval_count < self.budget:\n            self.update_positions(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 4, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["ceaa2f1e-c619-453c-8876-caec9ccdfd8c"], "operator": null, "metadata": {}}
{"id": "37e5fac9-576c-4ec9-92be-f0e2c4703294", "fitness": 0.366666299658957, "name": "HybridPSO_DE", "description": "Simplified Hybrid PSO-DE using a combined PSO-DE update with adaptive stagnation-based DE probability and reduced parameter set.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c=1.0, F=0.8, CR=0.7, de_prob=0.7, stagnation_threshold=50):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with stagnation-based adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w (float): Inertia weight for PSO.\n            c (float): Cognitive and social coefficient for PSO (c1=c2=c).\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob (float): Initial probability of applying DE.\n            stagnation_threshold (int): Number of iterations without improvement to increase DE probability.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c = c\n        self.F = F\n        self.CR = CR\n        self.de_prob = de_prob\n        self.stagnation_threshold = stagnation_threshold\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.stagnation_counter = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.global_best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_population(self, func):\n        \"\"\"Updates particle positions using a combined PSO-DE approach.\"\"\"\n        for i in range(self.pop_size):\n            # PSO component\n            r1 = np.random.rand(self.dim)\n            velocity = self.w * (self.global_best_pos - self.pop[i]) * r1\n            new_pos = self.pop[i] + velocity\n\n            # DE component\n            if np.random.rand() < self.de_prob:\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[idxs]\n                mutant = a + self.F * (b - c)\n                \n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        new_pos[j] = mutant[j]\n            \n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos.copy()\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = new_pos.copy()\n                    self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n\n        # Update global best after all particles are updated\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_pos = self.pop[best_index].copy()\n            self.stagnation_counter = 0\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_population(func)\n\n            # Adjust DE probability based on stagnation\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.de_prob = min(1.0, self.de_prob * 1.1)  # Increase DE probability\n                self.stagnation_counter = 0 # Reset stagnation after increasing DE prob\n            else:\n                self.de_prob = max(0.1, self.de_prob * 0.95)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSO_DE scored 0.367 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7ca7393c-f5d8-4a5e-bcf2-7814ef552998"], "operator": null, "metadata": {"aucs": [0.19239098870258198, 0.2991018032467144, 0.3044116607838325, 0.3479386416960606, 0.33377649382078, 0.40311534976497343, 0.2978144195397523, 0.393084503832962, 0.32398195140931996, 0.20316436978975638, 0.2171890385153894, 0.9978189738607672, 0.39291951899863686, 0.26932881681088394, 0.7241767622929663, 0.2795631009412296, 0.26222394207278854, 0.35748812417766784, 0.242908687604253, 0.4909288453178231]}}
{"id": "a6c382df-199b-4a88-8991-546a127c841f", "fitness": 0.44012212875261947, "name": "AdaptiveHybridPSO_DE", "description": "Simplified adaptive hybrid PSO-DE with dynamic inertia weight and simplified adaptation of PSO/DE probability based on their relative success.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_max=0.9, w_min=0.4, c1=2, c2=2, F=0.5, CR=0.7, p_pso=0.5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_max (float): Maximum inertia weight for PSO.\n            w_min (float): Minimum inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            p_pso (float): Initial probability of using PSO.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.p_pso = p_pso\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.success_pso = 0\n        self.success_de = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        for i in range(self.pop_size):\n            f = func(self.pop[i])\n            self.eval_count += 1\n            self.fitness[i] = f\n            if f < self.global_best_fitness:\n                self.global_best_fitness = f\n                self.global_best_pos = self.pop[i].copy()\n            self.best_pos[i] = self.pop[i].copy() # Initialize pbest\n\n    def update_positions(self, func, current_eval):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with adaptive probability.\n        \"\"\"\n        # Dynamic inertia weight\n        w = self.w_max - (self.w_max - self.w_min) * (current_eval / self.budget)\n\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            if np.random.rand() < self.p_pso:\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = w * (self.pop[i] - self.best_pos[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n                new_pos = self.pop[i] + velocity\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                f_new = func(new_pos)\n                self.eval_count += 1\n\n                if f_new < self.fitness[i]:\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_new\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_pos = self.pop[i].copy()\n                    self.best_pos[i] = self.pop[i].copy()\n                    self.success_pso += 1\n\n            else:\n                # DE update\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = self.pop[i].copy()\n                    self.best_pos[i] = self.pop[i].copy()\n                    self.success_de += 1\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        current_eval = 0\n        while self.eval_count < self.budget:\n            self.update_positions(func, current_eval)\n            current_eval = self.eval_count\n            \n            #Adapt p_pso based on relative success, but only if both strategies have been used\n            if (self.success_pso + self.success_de) > 0:\n                self.p_pso = self.success_pso / (self.success_pso + self.success_de)\n                self.success_pso = 0\n                self.success_de = 0\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.440 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["34991df0-9971-40d8-a6e6-fa136a815abb"], "operator": null, "metadata": {"aucs": [0.12294142543186115, 0.2106968423973059, 0.681545934490849, 0.1904904397161381, 0.33594343474706656, 0.8896050138620818, 0.29385120192182157, 0.5286512618495346, 0.3474463043210647, 0.20522622349011266, 0.274270646681515, 0.9979540635108055, 0.33959457593684805, 0.29421268605161477, 0.6622186170240403, 0.9673503025118146, 0.2627432056052298, 0.38192846125425706, 0.3268560798942062, 0.48891585435422125]}}
{"id": "640ad929-320d-4a5b-912b-76df9a1f9db2", "fitness": 0.3062185727615262, "name": "AdaptivePSO_DE", "description": "Adaptive PSO-DE using a sigmoidally decaying inertia weight and dynamically adjusting DE probability based on global best fitness improvement.", "code": "import numpy as np\n\nclass AdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_max=0.9, w_min=0.4, c=2.0, F=0.5, CR=0.9, de_prob=0.7, stagnation_threshold=50):\n        \"\"\"\n        Initializes the Adaptive PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_max (float): Initial inertia weight for PSO.\n            w_min (float): Final inertia weight for PSO.\n            c (float): Cognitive and social coefficient for PSO (c1=c2=c).\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob (float): Probability of applying DE.\n            stagnation_threshold (int): Number of iterations without improvement to increase DE probability.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c = c\n        self.F = F\n        self.CR = CR\n        self.de_prob = de_prob\n        self.stagnation_threshold = stagnation_threshold\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.stagnation_counter = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(self.pop[i]) for i in range(self.pop_size)])\n        self.eval_count += self.pop_size\n        self.global_best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update\n            r1, r2 = np.random.rand(2)\n            velocity = w * (self.pop[i] - self.global_best_pos) * r1 + self.c * (self.global_best_pos - self.pop[i]) * r2\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                mutant = self.pop[idxs[0]] + self.F * (self.pop[idxs[1]] - self.pop[idxs[2]])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, new_pos)\n                new_pos = trial\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = new_pos.copy()\n                    self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Adaptive PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n        best_fitness_history = [self.global_best_fitness]\n        \n        while self.eval_count < self.budget:\n            # Sigmoidally decaying inertia weight\n            t = self.eval_count / self.budget\n            w = (self.w_max - self.w_min) / (1 + np.exp(10 * (t - 0.5))) + self.w_min\n\n            # Adjust DE probability based on stagnation\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.de_prob = min(1.0, self.de_prob * 1.2)  # Increase DE probability\n                self.stagnation_counter = 0\n            else:\n                self.de_prob = max(0.1, self.de_prob * 0.9)\n\n            self.update_population(func, w)\n            best_fitness_history.append(self.global_best_fitness)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptivePSO_DE scored 0.306 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7ca7393c-f5d8-4a5e-bcf2-7814ef552998"], "operator": null, "metadata": {"aucs": [0.1277555706290353, 0.23144828286217423, 0.2922967443625043, 0.17439480806929186, 0.27685737712635405, 0.25447029600640503, 0.2348421213860259, 0.2434335640608447, 0.3175068118128982, 0.18675694211486316, 0.2799561622911686, 0.9989408488313009, 0.24471660393352213, 0.2815285414968335, 0.5511035344675528, 0.30475935452322034, 0.2890382976499455, 0.21139300072835698, 0.17478168838259767, 0.44839090449563046]}}
{"id": "010cd7ff-5103-4c22-95b1-d44aec089cd4", "fitness": 0.36891198308570294, "name": "HybridPSO_DE_Adaptive", "description": "Adaptive Hybrid PSO-DE algorithm that simplifies strategy adaptation by directly linking success rates to probability updates, reducing parameter dependence and computational overhead.", "code": "import numpy as np\n\nclass HybridPSO_DE_Adaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, F=0.6, CR=0.8, adapt_rate=0.1):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive strategy selection.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            adapt_rate (float): Rate at which to adjust strategy probabilities.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.adapt_rate = adapt_rate\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.pso_prob = 0.5\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_pos = self.pop.copy()\n        self.best_fitness = self.fitness.copy()\n        self.global_best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def pso_update(self, i, func):\n        \"\"\"Applies PSO update to particle i.\"\"\"\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        velocity = self.w * (self.pop[i] - self.best_pos[i]) + \\\n                   self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + \\\n                   self.c2 * r2 * (self.global_best_pos - self.pop[i])\n        new_pos = self.pop[i] + velocity\n        new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n        return new_pos\n\n    def de_update(self, i, func):\n        \"\"\"Applies DE update to particle i.\"\"\"\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        j_rand = np.random.randint(self.dim)\n        trial = self.pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial[j] = mutant[j]\n        return trial\n\n    def __call__(self, func):\n        \"\"\"Optimizes the function.\"\"\"\n        self.initialize_population(func)\n\n        pso_success_count = 0\n        de_success_count = 0\n        pso_total_count = 0\n        de_total_count = 0\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.pso_prob:\n                    # PSO\n                    new_pos = self.pso_update(i, func)\n                    pso_total_count += 1\n                    strategy = \"PSO\"\n                else:\n                    # DE\n                    new_pos = self.de_update(i, func)\n                    de_total_count += 1\n                    strategy = \"DE\"\n\n                f_trial = func(new_pos)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    if strategy == \"PSO\":\n                        pso_success_count += 1\n                    else:\n                        de_success_count += 1\n\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_trial\n                    if f_trial < self.best_fitness[i]:\n                        self.best_pos[i] = new_pos.copy()\n                        self.best_fitness[i] = f_trial\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = new_pos.copy()\n\n                if self.eval_count >= self.budget:\n                    break\n\n            # Adaptive probability update\n            total_successes = pso_success_count + de_success_count\n            if total_successes > 0:\n                pso_rate = pso_success_count / total_successes\n                de_rate = de_success_count / total_successes\n            else:\n                pso_rate = 0.5\n                de_rate = 0.5\n\n\n            self.pso_prob = (1 - self.adapt_rate) * self.pso_prob + self.adapt_rate * pso_rate\n            self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9)  # Keep probabilities within bounds\n\n\n            # Reset success counts for the next generation\n            pso_success_count = 0\n            de_success_count = 0\n\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSO_DE_Adaptive scored 0.369 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d4dac1cf-1c0f-45da-9fc0-a94af11cb837"], "operator": null, "metadata": {"aucs": [0.09554065421520919, 0.29715377529789455, 0.2977729096318903, 0.19841606068462903, 0.2324424826262218, 0.5737651054686972, 0.30838719660422353, 0.35545351185606455, 0.24908097435513976, 0.15427522773828783, 0.2819387821941558, 0.9982282580997406, 0.3376277636197542, 0.37889179902816095, 0.5886423014888391, 0.3779956259764503, 0.5562253424526376, 0.3456317491429659, 0.24252084091969117, 0.508249300313405]}}
{"id": "b630f803-1065-4dbc-9e8c-6a62eead7b31", "fitness": 0.6900826525961793, "name": "AdaptiveHybridPSO_DE", "description": "Simplified adaptive hybrid PSO-DE with dynamic inertia weight and improved DE mutation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, F=0.7, CR=0.9, p_adapt=0.05, p_pso=0.5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with dynamic inertia and improved DE.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            p_adapt (float): Probability of adapting p_pso.\n            p_pso (float): Initial probability of using PSO.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.p_adapt = p_adapt\n        self.p_pso = p_pso\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.success_pso = 0\n        self.success_de = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        for i in range(self.pop_size):\n            f = func(self.pop[i])\n            self.eval_count += 1\n            self.fitness[i] = f\n            if f < self.global_best_fitness:\n                self.global_best_fitness = f\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with adaptive probability and dynamic inertia.\n        \"\"\"\n        w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget) # Dynamic inertia\n\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            if np.random.rand() < self.p_pso:\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = w * (self.pop[i] - self.global_best_pos) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n                new_pos = self.pop[i] + velocity\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                f_new = func(new_pos)\n                self.eval_count += 1\n                \n                if f_new < self.fitness[i]:\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_new\n                    self.best_pos[i] = self.pop[i].copy()\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_pos = self.pop[i].copy()\n                    self.success_pso += 1\n                \n            else:\n                # DE update (Improved mutation: current-to-best/1)\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n                mutant = self.pop[i] + self.F * (self.global_best_pos - self.pop[i]) + self.F * (self.pop[a] - self.pop[b]) # current-to-best/1\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    self.best_pos[i] = self.pop[i].copy()\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = self.pop[i].copy()\n                    self.success_de += 1\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n            if np.random.rand() < self.p_adapt and (self.success_pso + self.success_de) > 0:\n                self.p_pso = self.success_pso / (self.success_pso + self.success_de)\n                self.success_pso = 0\n                self.success_de = 0\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.690 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["34991df0-9971-40d8-a6e6-fa136a815abb"], "operator": null, "metadata": {"aucs": [0.4404353008214895, 0.38603829038288484, 0.8821949174153131, 0.9449447710400589, 0.3833635098811585, 0.9236415299876166, 0.3694494331397813, 0.9000903783563314, 0.9179943551318428, 0.2058840340728526, 0.9584566627017916, 0.9970599530347077, 0.48762767556039033, 0.8999358935859082, 0.9654275340524876, 0.910250812088671, 0.4120396594778236, 0.9260675884010738, 0.3534972261864393, 0.5372535266049621]}}
{"id": "336d79b6-e955-4a7c-b3ab-ead379ab0020", "fitness": 0.6233112606054216, "name": "HybridPSO_DE", "description": "Dynamically adjusts PSO and DE parameters based on recent performance, simplifying adaptation by focusing on immediate reward and using a decay mechanism for smoother transitions.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7, adapt_rate=0.1, decay_rate=0.95):\n        \"\"\"\n        Initializes the Hybrid PSO-DE optimizer with dynamically adjusted parameters based on recent performance.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            adapt_rate (float): Rate for adapting PSO/DE parameters.\n            decay_rate (float): Decay rate for smoothing parameter adjustments.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.adapt_rate = adapt_rate\n        self.decay_rate = decay_rate\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.pso_success = 0.5  # Initialize with equal weighting\n        self.de_success = 0.5\n        self.w = w_start\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        self.best_fitness = np.array([np.inf] * self.pop_size)\n\n    def evaluate_population(self, func):\n        \"\"\"\n        Evaluates the fitness of each particle in the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness[i]:\n                    self.best_fitness[i] = f\n                    self.best_pos[i] = self.pop[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE and adapts parameters based on success.\n        \"\"\"\n        pso_improvements = 0.0\n        de_improvements = 0.0\n\n        for i in range(self.pop_size):\n            # PSO update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = self.w * (self.pop[i] - self.best_pos[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n            f_trial_pso = func(new_pos) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n\n            # DE update\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    trial[j] = mutant[j]\n            f_trial_de = func(trial) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n\n            # Selection and improvement tracking\n            if f_trial_pso < f_trial_de:\n                if f_trial_pso < self.fitness[i]:\n                    pso_improvements += (self.fitness[i] - f_trial_pso) / max(abs(self.fitness[i]), 1e-9)\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_trial_pso\n                    if f_trial_pso < self.best_fitness[i]:\n                        self.best_fitness[i] = f_trial_pso\n                        self.best_pos[i] = self.pop[i].copy()\n                    if f_trial_pso < self.global_best_fitness:\n                        self.global_best_fitness = f_trial_pso\n                        self.global_best_pos = self.pop[i].copy()\n            else:\n                if f_trial_de < self.fitness[i]:\n                    de_improvements += (self.fitness[i] - f_trial_de) / max(abs(self.fitness[i]), 1e-9)\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial_de\n                    if f_trial_de < self.best_fitness[i]:\n                        self.best_fitness[i] = f_trial_de\n                        self.best_pos[i] = self.pop[i].copy()\n                    if f_trial_de < self.global_best_fitness:\n                        self.global_best_fitness = f_trial_de\n                        self.global_best_pos = self.pop[i].copy()\n\n        # Parameter Adaptation (Simplified)\n        total_improvements = pso_improvements + de_improvements\n        if total_improvements > 0:\n            pso_ratio = pso_improvements / total_improvements\n            self.pso_success = self.decay_rate * self.pso_success + (1 - self.decay_rate) * pso_ratio  # Exponential smoothing\n            self.de_success = 1 - self.pso_success\n        else:\n            self.pso_success *= self.decay_rate\n            self.de_success *= self.decay_rate\n\n        # Adjust parameters based on smoothed success rates\n        self.c1 *= (1 + self.adapt_rate * (self.pso_success - 0.5))\n        self.c2 *= (1 + self.adapt_rate * (self.pso_success - 0.5))\n        self.F *= (1 + self.adapt_rate * (self.de_success - 0.5))\n        self.CR *= (1 + self.adapt_rate * (self.de_success - 0.5))\n        self.c1 = np.clip(self.c1, 1.0, 4.0)\n        self.c2 = np.clip(self.c2, 1.0, 4.0)\n        self.F = np.clip(self.F, 0.1, 1.0)\n        self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        # Linear inertia weight decay\n        self.w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget)\n\n        if self.eval_count >= self.budget:\n            return\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSO_DE scored 0.623 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ceaa2f1e-c619-453c-8876-caec9ccdfd8c"], "operator": null, "metadata": {"aucs": [0.2723596415740077, 0.7596101774582364, 0.9027617457596118, 0.25935280764188606, 0.9191210364952701, 0.9543216166645605, 0.32781143140657076, 0.4321425854300138, 0.9314400486872524, 0.2004519607691848, 0.9304922089348725, 0.997657313944853, 0.38002211135652986, 0.4186316781912296, 0.7444924190716503, 0.9513282469964996, 0.4159914136920235, 0.9550165132666703, 0.216808878287037, 0.49641137648047196]}}
{"id": "b1562a2b-f0a8-4d5c-8ade-5db4c8adabc6", "fitness": 0.537535853554892, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Adaptively adjusts PSO/DE probabilities based on recent success rates, simplifies parameter update, and introduces a small mutation to enhance exploration.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, F=0.6, CR=0.8, adapt_rate=0.1, mutation_rate=0.05):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive strategy selection and mutation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            adapt_rate (float): Rate at which to adjust strategy probabilities.\n            mutation_rate (float): Probability of applying mutation to a particle.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.adapt_rate = adapt_rate\n        self.mutation_rate = mutation_rate\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.pso_prob = 0.5\n        self.de_prob = 0.5\n        self.pso_success = 0\n        self.de_success = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_pos = self.pop.copy()\n        self.best_fitness = self.fitness.copy()\n        self.global_best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def pso_update(self, i, func):\n        \"\"\"Applies PSO update to particle i.\"\"\"\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        velocity = self.w * (self.pop[i] - self.best_pos[i]) + \\\n                   self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + \\\n                   self.c2 * r2 * (self.global_best_pos - self.pop[i])\n        new_pos = self.pop[i] + velocity\n        new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n        return new_pos\n\n    def de_update(self, i, func):\n        \"\"\"Applies DE update to particle i.\"\"\"\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        j_rand = np.random.randint(self.dim)\n        trial = self.pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial[j] = mutant[j]\n        return trial\n\n    def mutate(self, x, func):\n        \"\"\"Applies a small mutation to the particle.\"\"\"\n        if np.random.rand() < self.mutation_rate:\n            mutation = np.random.uniform(-0.1, 0.1, size=self.dim)\n            x = np.clip(x + mutation, func.bounds.lb, func.bounds.ub)\n        return x\n\n    def __call__(self, func):\n        \"\"\"Optimizes the function.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            pso_count = 0\n            de_count = 0\n            for i in range(self.pop_size):\n                if np.random.rand() < self.pso_prob:\n                    # PSO\n                    new_pos = self.pso_update(i, func)\n                    pso_count += 1\n                    strategy = \"pso\"\n                else:\n                    # DE\n                    new_pos = self.de_update(i, func)\n                    de_count += 1\n                    strategy = \"de\"\n\n                new_pos = self.mutate(new_pos, func) # Apply mutation\n\n                f_trial = func(new_pos)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    if strategy == \"pso\":\n                         self.pso_success +=1\n                    else:\n                         self.de_success +=1\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_trial\n                    if f_trial < self.best_fitness[i]:\n                        self.best_pos[i] = new_pos.copy()\n                        self.best_fitness[i] = f_trial\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = new_pos.copy()\n                if self.eval_count >= self.budget:\n                    break\n            total_count = pso_count + de_count\n            if total_count > 0:\n                pso_rate = self.pso_success / total_count\n                de_rate = self.de_success / total_count\n            else:\n                pso_rate = 0.5\n                de_rate = 0.5\n\n            self.pso_prob = (1 - self.adapt_rate) * self.pso_prob + self.adapt_rate * pso_rate\n            self.de_prob = (1 - self.adapt_rate) * self.de_prob + self.adapt_rate * de_rate\n\n            self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9)\n            self.de_prob = np.clip(self.de_prob, 0.1, 0.9)\n            self.pso_success = 0\n            self.de_success = 0\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.538 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d4dac1cf-1c0f-45da-9fc0-a94af11cb837"], "operator": null, "metadata": {"aucs": [0.5588952414828738, 0.19940665948889302, 0.8873098062619912, 0.1991707540675559, 0.3461882798092031, 0.3671836200153694, 0.7885977033856415, 0.3070808141390794, 0.8956235813520586, 0.1959611124103532, 0.4237935851021639, 0.9943814741497928, 0.29647500777048186, 0.8502374937338208, 0.9193707996334172, 0.33590052766140677, 0.40750676834891875, 0.9652672614807097, 0.343225460926465, 0.46914111987764395]}}
{"id": "ebf8fa43-7cf8-4973-83bb-17582ed03cec", "fitness": 0.37381933549557744, "name": "HybridPSO_DE", "description": "Adaptively adjusts PSO and DE parameters based on improvement ratios with a simplified update rule and local search to improve exploration around promising solutions.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7, adapt_rate=0.1, local_search_prob=0.1):\n        \"\"\"\n        Initializes the Hybrid PSO-DE optimizer with simplified adaptive parameter adjustment and local search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            adapt_rate (float): Rate for adapting PSO/DE parameters.\n            local_search_prob (float): Probability of performing local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.adapt_rate = adapt_rate\n        self.local_search_prob = local_search_prob\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.pso_params = {'w': w_start, 'c1': c1, 'c2': c2}\n        self.de_params = {'F': F, 'CR': CR}\n        self.pso_success = 0.0\n        self.de_success = 0.0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        self.best_fitness = np.array([np.inf] * self.pop_size)\n\n    def evaluate_population(self, func):\n        \"\"\"\n        Evaluates the fitness of each particle in the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness[i]:\n                    self.best_fitness[i] = f\n                    self.best_pos[i] = self.pop[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def local_search(self, func, x, step_size=0.1):\n        \"\"\"\n        Performs a local search around the given position.\n        \"\"\"\n        new_x = x + np.random.uniform(-step_size, step_size, size=self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_x) if self.eval_count < self.budget else np.inf\n        self.eval_count += 1\n        return new_x, f_new\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE and adapts parameters based on success.\n        \"\"\"\n        pso_improvements = 0.0\n        de_improvements = 0.0\n        w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget)\n        self.pso_params['w'] = w\n\n        for i in range(self.pop_size):\n            # PSO update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = self.pso_params['w'] * (self.pop[i] - self.best_pos[i]) + self.pso_params['c1'] * r1 * (self.best_pos[i] - self.pop[i]) + self.pso_params['c2'] * r2 * (self.global_best_pos - self.pop[i])\n            new_pos_pso = self.pop[i] + velocity\n            new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n            f_trial_pso = func(new_pos_pso) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n\n            # DE update\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.pop[a] + self.de_params['F'] * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            trial_de = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.de_params['CR'] or j == j_rand:\n                    trial_de[j] = mutant[j]\n            f_trial_de = func(trial_de) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n\n            # Selection: Simplified - Directly compare improvements\n            if f_trial_pso < self.fitness[i]:\n                pso_improvements += (self.fitness[i] - f_trial_pso) / max(abs(self.fitness[i]), 1e-9)\n                self.pop[i] = new_pos_pso\n                self.fitness[i] = f_trial_pso\n                if f_trial_pso < self.best_fitness[i]:\n                    self.best_fitness[i] = f_trial_pso\n                    self.best_pos[i] = self.pop[i].copy()\n                if f_trial_pso < self.global_best_fitness:\n                    self.global_best_fitness = f_trial_pso\n                    self.global_best_pos = self.pop[i].copy()\n            elif f_trial_de < self.fitness[i]:\n                de_improvements += (self.fitness[i] - f_trial_de) / max(abs(self.fitness[i]), 1e-9)\n                self.pop[i] = trial_de\n                self.fitness[i] = f_trial_de\n                if f_trial_de < self.best_fitness[i]:\n                    self.best_fitness[i] = f_trial_de\n                    self.best_pos[i] = self.pop[i].copy()\n                if f_trial_de < self.global_best_fitness:\n                    self.global_best_fitness = f_trial_de\n                    self.global_best_pos = self.pop[i].copy()\n\n            # Local search\n            if np.random.rand() < self.local_search_prob:\n                new_pos, f_new = self.local_search(func, self.pop[i])\n                if f_new < self.fitness[i]:\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_new\n                    if f_new < self.best_fitness[i]:\n                        self.best_fitness[i] = f_new\n                        self.best_pos[i] = self.pop[i].copy()\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_pos = self.pop[i].copy()\n\n        # Parameter adaptation: Simplified update\n        total_improvements = pso_improvements + de_improvements\n        if total_improvements > 0:\n            pso_ratio = pso_improvements / total_improvements\n            self.pso_params['c1'] = 1.0 + 3.0 * pso_ratio  # Simplified update\n            self.pso_params['c2'] = 4.0 - 3.0 * pso_ratio  # Simplified update\n            self.de_params['F'] = 0.1 + 0.9 * (1 - pso_ratio) #Simplified update\n            self.de_params['CR'] = 0.1 + 0.9 * (1-pso_ratio) #Simplified update\n\n        self.pso_params['c1'] = np.clip(self.pso_params['c1'], 1.0, 4.0)\n        self.pso_params['c2'] = np.clip(self.pso_params['c2'], 1.0, 4.0)\n        self.de_params['F'] = np.clip(self.de_params['F'], 0.1, 1.0)\n        self.de_params['CR'] = np.clip(self.de_params['CR'], 0.1, 1.0)\n\n\n        if self.eval_count >= self.budget:\n            return\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSO_DE scored 0.374 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ceaa2f1e-c619-453c-8876-caec9ccdfd8c"], "operator": null, "metadata": {"aucs": [0.19175100608064877, 0.19079413130962297, 0.4607360238708986, 0.17750522855453166, 0.37608498333307616, 0.44542086332470654, 0.26397438439354837, 0.24452299350279494, 0.3261890641041718, 0.17323409442000703, 0.39009462641374526, 0.9977390449578515, 0.4427028065742056, 0.3548537090368291, 0.6520897097424185, 0.2979743014472285, 0.23280371345065676, 0.5726166228978649, 0.21704938963633047, 0.4682500128604118]}}
{"id": "ff71a21c-6f60-4eab-825e-89892a98cd29", "fitness": 0.7467331492193549, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies Hybrid PSO-DE by removing the stagnation counter and directly adjusting the DE probability based on global best improvement, while integrating the cognitive component into the velocity update.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, c=1.0, F=0.9, CR=0.7, de_prob_init=0.9):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c (float): Cognitive and social coefficient for PSO (c1=c2=c).\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c = c\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_global_best = np.inf\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update with cognitive component integrated into velocity\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = w * (r1 * (self.global_best_pos - self.pop[i]) + r2 * (self.pop[i] - self.pop[i]))\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            # Adjust DE probability based on global best improvement\n            if self.global_best_fitness < self.last_global_best:\n                self.de_prob = self.de_prob_init  # Reset to initial value upon improvement\n            else:\n                self.de_prob = min(1.0, self.de_prob * 1.05)  # Gradually increase DE probability without stagnation counter\n\n            self.update_population(func, w)\n            self.last_global_best = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.747 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7ca7393c-f5d8-4a5e-bcf2-7814ef552998"], "operator": null, "metadata": {"aucs": [0.280235946805101, 0.6145091605151749, 0.8160637227153541, 0.9192447577809385, 0.8125102525480871, 0.8869655448602862, 0.770274138759271, 0.8237173291501719, 0.844495021124478, 0.7817866554087161, 0.8927795978993218, 0.9934723527559568, 0.38229704433355627, 0.8387308365626609, 0.9441834933641389, 0.8779122891139294, 0.7582762436606159, 0.9144025814494237, 0.25655215017047206, 0.5262538654094405]}}
{"id": "19497f9b-da57-4a4d-bb74-2829a418a487", "fitness": 0.7353514758370373, "name": "AdaptiveHybridPSO_DE", "description": "Simplified adaptive hybrid PSO-DE with dynamic population size reduction and self-adaptive parameters based on past performance.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, F=0.6, CR=0.8, reduction_factor=0.95):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with dynamic population size.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): Initial population size.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            reduction_factor (float): Factor by which the population size is reduced.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.reduction_factor = reduction_factor\n        self.pso_success_rate = 0.5  # Initial guess\n        self.de_success_rate = 0.5   # Initial guess\n        self.min_pop_size = 5\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        for i in range(self.pop_size):\n            f = func(self.pop[i])\n            self.eval_count += 1\n            self.fitness[i] = f\n            if f < self.best_fitness:\n                self.best_fitness = f\n                self.best_pos[i] = self.pop[i].copy()\n            if f < self.global_best_fitness:\n                self.global_best_fitness = f\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_positions(self, func):\n        \"\"\"Updates particle positions using adaptive PSO and DE.\"\"\"\n        pso_improvements = 0\n        de_improvements = 0\n        \n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            # Adaptive selection of PSO/DE\n            if np.random.rand() < self.pso_success_rate / (self.pso_success_rate + self.de_success_rate + 1e-9):\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = self.w * (self.pop[i] - self.best_pos[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n                new_pos = self.pop[i] + velocity\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                f_new = func(new_pos)\n                self.eval_count += 1\n                if f_new < self.fitness[i]:\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_new\n                    if f_new < self.best_fitness:\n                        self.best_fitness = f_new\n                        self.best_pos[i] = self.pop[i].copy()\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_pos = self.pop[i].copy()\n                    pso_improvements += 1\n            else:\n                # DE update\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                f_trial = func(trial)\n                self.eval_count += 1\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.best_fitness:\n                        self.best_fitness = f_trial\n                        self.best_pos[i] = self.pop[i].copy()\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = self.pop[i].copy()\n                    de_improvements += 1\n\n        # Update success rates\n        total_updates = pso_improvements + de_improvements\n        if total_updates > 0:\n            self.pso_success_rate = 0.9 * self.pso_success_rate + 0.1 * (pso_improvements / total_updates)\n            self.de_success_rate = 0.9 * self.de_success_rate + 0.1 * (de_improvements / total_updates)\n\n    def reduce_population(self):\n          \"\"\"Reduces population size if it is larger than the minimum population size.\"\"\"\n          if self.pop_size > self.min_pop_size:\n              self.pop_size = max(int(self.pop_size * self.reduction_factor), self.min_pop_size)\n              # Keep the best individuals when reducing the population\n              indices = np.argsort(self.fitness)[:self.pop_size]\n              self.pop = self.pop[indices]\n              self.fitness = self.fitness[indices]\n              self.best_pos = self.best_pos[indices]\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using Adaptive Hybrid PSO-DE.\"\"\"\n        self.initialize_population(func)\n        generation = 0\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n            if generation % 10 == 0:\n                self.reduce_population()\n            generation += 1\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.735 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["34991df0-9971-40d8-a6e6-fa136a815abb"], "operator": null, "metadata": {"aucs": [0.3025225764935753, 0.7031198801585078, 0.7382584603432497, 0.8428765742798159, 0.7760057749022679, 0.8118126513235338, 0.6865909665280372, 0.70224227756383, 0.7851592186405756, 0.7499925222245355, 0.8545507262916984, 0.9945080722847152, 0.5690682878556266, 0.7511952715004148, 0.9273549970559126, 0.8011680931815688, 0.6528977082423795, 0.8491817218986305, 0.5603035382857995, 0.6482201976860721]}}
{"id": "ba9da1bf-c0f5-4c50-94a9-04738594debd", "fitness": 0.39139082899306293, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Adaptively adjusts PSO/DE probabilities based on recent success rates, simplifying parameter updates and eliminating explicit success counters for cleaner code.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, F=0.6, CR=0.8, adapt_rate=0.1):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive strategy selection.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            adapt_rate (float): Rate at which to adjust strategy probabilities.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.adapt_rate = adapt_rate\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.pso_prob = 0.5\n        self.de_prob = 0.5\n        self.success_history = []\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_pos = self.pop.copy()\n        self.best_fitness = self.fitness.copy()\n        self.global_best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def pso_update(self, i, func):\n        \"\"\"Applies PSO update to particle i.\"\"\"\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        velocity = self.w * (self.pop[i] - self.best_pos[i]) + \\\n                   self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + \\\n                   self.c2 * r2 * (self.global_best_pos - self.pop[i])\n        new_pos = self.pop[i] + velocity\n        new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n        return new_pos\n\n    def de_update(self, i, func):\n        \"\"\"Applies DE update to particle i.\"\"\"\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        j_rand = np.random.randint(self.dim)\n        trial = self.pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial[j] = mutant[j]\n        return trial\n\n    def __call__(self, func):\n        \"\"\"Optimizes the function.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            success_count = 0\n            strategy_counts = {\"pso\": 0, \"de\": 0}  # Track usage for success rate calculation\n\n            for i in range(self.pop_size):\n                if np.random.rand() < self.pso_prob:\n                    # PSO\n                    new_pos = self.pso_update(i, func)\n                    strategy_counts[\"pso\"] += 1\n                else:\n                    # DE\n                    new_pos = self.de_update(i, func)\n                    strategy_counts[\"de\"] += 1\n\n                f_trial = func(new_pos)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    success_count += 1\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_trial\n                    if f_trial < self.best_fitness[i]:\n                        self.best_pos[i] = new_pos.copy()\n                        self.best_fitness[i] = f_trial\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = new_pos.copy()\n                if self.eval_count >= self.budget:\n                    break\n            # Adaptive probability update based on recent success\n            total_trials = strategy_counts[\"pso\"] + strategy_counts[\"de\"]\n            if total_trials > 0:\n                success_rate = success_count / total_trials\n            else:\n                success_rate = 0.5  # Default to 0.5 if no trials occurred\n\n            # Adjust probabilities based on overall success rate\n            self.pso_prob += self.adapt_rate * (success_rate - 0.5)  # Increase PSO prob if success is above 0.5\n            self.pso_prob = np.clip(self.pso_prob, 0.1, 0.9)\n            self.de_prob = 1 - self.pso_prob #DE prob directly linked to PSO.\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.391 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d4dac1cf-1c0f-45da-9fc0-a94af11cb837"], "operator": null, "metadata": {"aucs": [0.1637896489183136, 0.32401791640674016, 0.43120393159759696, 0.2734698104277077, 0.2210121521915005, 0.42011428604534506, 0.3155846039617384, 0.24306837307680162, 0.62963371276616, 0.21969433595940435, 0.29335067576906126, 1.0, 0.23401106420166884, 0.22829100620729725, 0.8002979572416156, 0.29351841473477847, 0.27359419303479193, 0.6806869945844521, 0.30415173714486454, 0.47832576559142126]}}
{"id": "b0acd896-44da-468a-8267-bcdbf634af79", "fitness": -Infinity, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies Hybrid PSO-DE by directly adjusting the DE probability based on global best improvement and integrating the cognitive component into the PSO velocity update.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, c=1.0, F=0.9, CR=0.7, de_prob_init=0.9):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c (float): Cognitive and social coefficient for PSO (c1=c2=c).\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c = c\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.global_best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update with cognitive component integrated into velocity\n            r1 = np.random.rand(self.dim)\n            velocity = w * velocity + self.c * r1 * (self.global_best_pos - self.pop[i])\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n        velocity = np.zeros((self.pop_size, self.dim))\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            # Adjust DE probability based on global best improvement\n            if self.global_best_fitness < np.min(self.fitness):\n                self.de_prob = self.de_prob_init  # Reset to initial value upon improvement\n            else:\n                self.de_prob = min(1.0, self.de_prob * 1.05)  # Gradually increase DE probability without stagnation counter\n\n            self.update_population(func, w)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 5, "feedback": "An exception occurred: local variable 'velocity' referenced before assignment.", "error": "", "parent_ids": ["ff71a21c-6f60-4eab-825e-89892a98cd29"], "operator": null, "metadata": {}}
{"id": "d1ec22cc-a3c8-42f1-802c-73111f67d22d", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE", "description": "Simplifies adaptive hybrid PSO-DE by directly using fitness improvement for PSO/DE selection and reducing parameter tuning with fixed coefficients.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): Initial population size.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        for i in range(self.pop_size):\n            f = func(self.pop[i])\n            self.eval_count += 1\n            self.fitness[i] = f\n            if f < self.global_best_fitness:\n                self.global_best_fitness = f\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_positions(self, func):\n        \"\"\"Updates particle positions using adaptive PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            # PSO parameters (fixed)\n            w = 0.7\n            c1 = 1.5\n            c2 = 1.5\n            \n            # DE parameters (fixed)\n            F = 0.6\n            CR = 0.8\n\n            # PSO update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = w * (self.pop[i] - self.best_pos[i]) + c1 * r1 * (self.best_pos[i] - self.pop[i]) + c2 * r2 * (self.global_best_pos - self.pop[i])\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                # If PSO is successful\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                self.best_pos[i] = self.pop[i].copy()\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n            else:\n                # DE update if PSO fails\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        trial[j] = mutant[j]\n                f_trial = func(trial)\n                self.eval_count += 1\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using Adaptive Hybrid PSO-DE.\"\"\"\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["19497f9b-da57-4a4d-bb74-2829a418a487"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "5eae8bcc-a56c-498c-a34e-d1aa21ee6892", "fitness": 0.44884707336760943, "name": "AdaptiveHybridPSO_DE", "description": "Simplified adaptive hybrid PSO-DE with performance-based parameter adaptation and dynamic population size, focusing on clarity and efficiency.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, F=0.6, CR=0.8, reduction_factor=0.95):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.reduction_factor = reduction_factor\n        self.min_pop_size = 5\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.pso_prob = 0.5\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_pos = self.pop.copy()\n        self.global_best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_positions(self, func):\n        \"\"\"Updates particle positions using adaptive PSO and DE.\"\"\"\n        pso_success = 0\n        de_success = 0\n\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            if np.random.rand() < self.pso_prob:  # Adaptive PSO/DE selection\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity = self.w * (self.pop[i] - self.best_pos[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n                new_pos = np.clip(self.pop[i] + velocity, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_pos)\n                self.eval_count += 1\n\n                if new_fitness < self.fitness[i]:\n                    self.pop[i] = new_pos\n                    self.fitness[i] = new_fitness\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_pos = new_pos.copy()\n                    pso_success += 1\n            else:\n                # DE Update\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                mutant = self.pop[idxs[0]] + self.F * (self.pop[idxs[1]] - self.pop[idxs[2]])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.pop[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = trial_fitness\n                    if trial_fitness < self.global_best_fitness:\n                        self.global_best_fitness = trial_fitness\n                        self.global_best_pos = trial.copy()\n                    de_success += 1\n        \n        total = pso_success + de_success\n        if total > 0:\n            self.pso_prob = 0.8 * self.pso_prob + 0.2 * (pso_success / total)\n\n\n    def reduce_population(self):\n        \"\"\"Reduces population size.\"\"\"\n        if self.pop_size > self.min_pop_size:\n            new_size = max(int(self.pop_size * self.reduction_factor), self.min_pop_size)\n            indices = np.argsort(self.fitness)[:new_size]\n            self.pop = self.pop[indices]\n            self.fitness = self.fitness[indices]\n            self.pop_size = new_size\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using Adaptive Hybrid PSO-DE.\"\"\"\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n            if self.eval_count < self.budget and self.pop_size > self.min_pop_size:\n                  self.reduce_population()\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.449 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["19497f9b-da57-4a4d-bb74-2829a418a487"], "operator": null, "metadata": {"aucs": [0.21099931224087554, 0.38872097640111913, 0.4180552938949327, 0.4819623474285121, 0.540860765950731, 0.4939879962190219, 0.34617752503458676, 0.42316931012375514, 0.32700554407920635, 0.3208502696595713, 0.3960179720116753, 0.9987033414096863, 0.2951594309687535, 0.31294149090652523, 0.6603894496670387, 0.5976549685837356, 0.34407729668734477, 0.6818780164541163, 0.239636846519645, 0.4986933131113568]}}
{"id": "cbfb46a0-e23e-44a2-8f37-5f9e79dc6277", "fitness": 0.5344501177334944, "name": "AdaptiveHybridPSO_DE", "description": "Integrates a simplified PSO-DE hybrid with dynamic inertia, current-to-best DE mutation, and adaptive strategy selection based on recent performance to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, F=0.7, CR=0.9, p_pso=0.5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with dynamic inertia and improved DE.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            p_pso (float): Initial probability of using PSO.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.p_pso = p_pso\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.success_pso = 0\n        self.success_de = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        for i in range(self.pop_size):\n            f = func(self.pop[i])\n            self.eval_count += 1\n            self.fitness[i] = f\n            if f < self.global_best_fitness:\n                self.global_best_fitness = f\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with adaptive probability and dynamic inertia.\n        \"\"\"\n        w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget) # Dynamic inertia\n\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            if np.random.rand() < self.p_pso:\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = w * (self.global_best_pos - self.pop[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n                new_pos = self.pop[i] + velocity\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                f_new = func(new_pos)\n                self.eval_count += 1\n                \n                if f_new < self.fitness[i]:\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_new\n                    self.best_pos[i] = self.pop[i].copy()\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_pos = self.pop[i].copy()\n                    self.success_pso += 1\n                \n            else:\n                # DE update (Improved mutation: current-to-best/1)\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n                mutant = self.pop[i] + self.F * (self.global_best_pos - self.pop[i]) + self.F * (self.pop[a] - self.pop[b]) # current-to-best/1\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    self.best_pos[i] = self.pop[i].copy()\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = self.pop[i].copy()\n                    self.success_de += 1\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n            if (self.success_pso + self.success_de) > 0:\n                self.p_pso = self.success_pso / (self.success_pso + self.success_de)\n                self.success_pso = 0\n                self.success_de = 0\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.534 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b630f803-1065-4dbc-9e8c-6a62eead7b31"], "operator": null, "metadata": {"aucs": [0.1500324911946691, 0.23733448719639516, 0.8773324288954769, 0.2321761346364225, 0.9256329786250125, 0.9346492091527306, 0.28990310988153256, 0.9253612186403403, 0.9086225313776731, 0.19494130559727274, 0.2325975596946348, 0.9975456051947199, 0.20737350324667891, 0.26836417918141664, 0.589173824746152, 0.35598833221458814, 0.7045284843616668, 0.9603016779117851, 0.18081182427747755, 0.516331468643245]}}
{"id": "96a4a208-0825-4ee1-97d1-03853df87aaf", "fitness": 0.4723980371623955, "name": "AdaptiveHybridPSO_DE", "description": "Simplified adaptive hybrid PSO-DE with dynamic parameter adjustments based on global best improvement and dynamic population size reduction.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, F=0.6, CR=0.8, reduction_factor=0.95):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with dynamic population size.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): Initial population size.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            reduction_factor (float): Factor by which the population size is reduced.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.reduction_factor = reduction_factor\n        self.min_pop_size = 5\n        self.last_improvement = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_pos = self.pop.copy()\n        self.best_fitness = self.fitness.copy()\n        self.global_best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_improvement = 0  # Initialize last improvement counter\n\n    def update_positions(self, func):\n        \"\"\"Updates particle positions using adaptive PSO and DE.\"\"\"\n        \n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            # Adaptive selection of PSO/DE - simplified to fixed probability\n            if np.random.rand() < 0.5:  # 50% chance for PSO\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = self.w * (self.pop[i] - self.best_pos[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n                new_pos = self.pop[i] + velocity\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                f_new = func(new_pos)\n                self.eval_count += 1\n            else:\n                # DE update\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                f_new = func(trial)\n                self.eval_count += 1\n                new_pos = trial # DE uses trial vector\n\n            #Evaluate and update\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.best_fitness[i]:\n                    self.best_fitness[i] = f_new\n                    self.best_pos[i] = self.pop[i].copy()\n                    \n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n                    self.last_improvement = self.eval_count  # Update last improvement\n\n\n        #Adjust parameters based on stagnation\n        if self.eval_count - self.last_improvement > self.budget/10: # If no improvement for 10% of budget\n            self.w = min(self.w * 1.1, 0.9) #Increase exploration\n            self.F = min(self.F * 1.1, 1.0)\n\n        else: #Reward recent improvement\n            self.w = max(self.w * 0.9, 0.4) #Increase exploitation\n            self.F = max(self.F * 0.9, 0.1)\n\n\n    def reduce_population(self):\n          \"\"\"Reduces population size if it is larger than the minimum population size.\"\"\"\n          if self.pop_size > self.min_pop_size:\n              self.pop_size = max(int(self.pop_size * self.reduction_factor), self.min_pop_size)\n              # Keep the best individuals when reducing the population\n              indices = np.argsort(self.fitness)[:self.pop_size]\n              self.pop = self.pop[indices]\n              self.fitness = self.fitness[indices]\n              self.best_pos = self.best_pos[indices]\n              self.best_fitness = self.best_fitness[indices]\n\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using Adaptive Hybrid PSO-DE.\"\"\"\n        self.initialize_population(func)\n        generation = 0\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n            if generation % 10 == 0 and self.pop_size > self.min_pop_size: #Reduce less frequently\n                self.reduce_population()\n            generation += 1\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.472 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["19497f9b-da57-4a4d-bb74-2829a418a487"], "operator": null, "metadata": {"aucs": [0.2124652846658075, 0.191738426729836, 0.4706459991803805, 0.9628421086587711, 0.34182178499564075, 0.38208502542497313, 0.3438472814142015, 0.37120360348897463, 0.5796603803698319, 0.18245456370980484, 0.2182192837298238, 0.9990406740803786, 0.3243813170679465, 0.27706535427914636, 0.8221670356657048, 0.9399766447106747, 0.3121169328522315, 0.8161871576264169, 0.21834695783520408, 0.48169492676216064]}}
{"id": "cd729394-b35f-4ba2-9cff-547a5b2e4c34", "fitness": 0.5868670037951708, "name": "HybridPSO_DE", "description": "Simplified Hybrid PSO-DE with direct comparison and adaptive parameter tuning based on successful updates.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7, adapt_rate=0.1):\n        \"\"\"\n        Initializes the Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            adapt_rate (float): Rate for adapting PSO/DE parameters.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.adapt_rate = adapt_rate\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.w = w_start\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_pos = self.pop.copy()\n        self.best_fitness = self.fitness.copy()\n        self.global_best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE and adapts parameters based on success.\n        \"\"\"\n        for i in range(self.pop_size):\n            # PSO update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = self.w * (self.pop[i] - self.best_pos[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n            new_pos_pso = self.pop[i] + velocity\n            new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n            f_trial_pso = func(new_pos_pso) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n            \n            # DE update\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            trial_de = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    trial_de[j] = mutant[j]\n            f_trial_de = func(trial_de) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n            \n            # Direct Comparison and Update\n            if f_trial_pso < self.fitness[i] and f_trial_pso <= f_trial_de:\n                self.pop[i] = new_pos_pso\n                self.fitness[i] = f_trial_pso\n                if f_trial_pso < self.best_fitness[i]:\n                    self.best_fitness[i] = f_trial_pso\n                    self.best_pos[i] = self.pop[i].copy()\n                if f_trial_pso < self.global_best_fitness:\n                    self.global_best_fitness = f_trial_pso\n                    self.global_best_pos = self.pop[i].copy()\n            elif f_trial_de < self.fitness[i]:\n                self.pop[i] = trial_de\n                self.fitness[i] = f_trial_de\n                if f_trial_de < self.best_fitness[i]:\n                    self.best_fitness[i] = f_trial_de\n                    self.best_pos[i] = self.pop[i].copy()\n                if f_trial_de < self.global_best_fitness:\n                    self.global_best_fitness = f_trial_de\n                    self.global_best_pos = self.pop[i].copy()\n\n        # Linear inertia weight decay\n        self.w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget)\n        \n        # Parameter Adaptation based on global best improvement\n        if self.eval_count < self.budget:\n             self.c1 += self.adapt_rate * np.random.normal(0, 1)\n             self.c2 += self.adapt_rate * np.random.normal(0, 1)\n             self.F += self.adapt_rate * np.random.normal(0, 1)\n             self.CR += self.adapt_rate * np.random.normal(0, 1)\n\n             self.c1 = np.clip(self.c1, 1.0, 4.0)\n             self.c2 = np.clip(self.c2, 1.0, 4.0)\n             self.F = np.clip(self.F, 0.1, 1.0)\n             self.CR = np.clip(self.CR, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSO_DE scored 0.587 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["336d79b6-e955-4a7c-b3ab-ead379ab0020"], "operator": null, "metadata": {"aucs": [0.21804384270270905, 0.18084551715408237, 0.506900193121602, 0.19923177892063726, 0.9479378876926051, 0.9531554355064497, 0.3559411490883031, 0.6412628656559947, 0.8312802958724768, 0.947554785827739, 0.9477140925688646, 0.99809570985933, 0.3671670355194009, 0.3997732664355619, 0.7441400613798077, 0.9332728049487206, 0.45670013072147164, 0.3816025204282384, 0.25167301386197793, 0.47504768863744107]}}
{"id": "b3e4bae8-5e33-4df2-ad5f-88c17f915c83", "fitness": 0.7150662651637457, "name": "AdaptiveHybridPSO_DE", "description": "Simplifies Hybrid PSO-DE by adaptively adjusting PSO parameters based on the global best's improvement rate and reducing function evaluations by comparing PSO and DE moves before evaluation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7, adapt_rate=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with simplified adaptation and reduced evaluations.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            adapt_rate (float): Rate for adapting PSO/DE parameters.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.adapt_rate = adapt_rate\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.w = w_start\n        self.gb_history = []\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        self.best_fitness = np.array([np.inf] * self.pop_size)\n        self.evaluate_population(func)  # Evaluate initial population\n        self.gb_history.append(self.global_best_fitness)\n\n    def evaluate_population(self, func):\n        \"\"\"\n        Evaluates the fitness of each particle in the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness[i]:\n                    self.best_fitness[i] = f\n                    self.best_pos[i] = self.pop[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with reduced evaluations and adaptive parameters.\n        \"\"\"\n        global_best_old = self.global_best_fitness\n        for i in range(self.pop_size):\n            # PSO update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = self.w * (self.pop[i] - self.best_pos[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n            new_pos_pso = self.pop[i] + velocity\n            new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n\n            # DE update\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    trial[j] = mutant[j]\n            new_pos_de = trial\n            \n            # Evaluate only the better move (reduce function evaluations)\n            f_trial_pso = func(new_pos_pso) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n\n            f_trial_de = func(new_pos_de) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n\n            if f_trial_pso < f_trial_de and f_trial_pso < self.fitness[i]:\n                self.pop[i] = new_pos_pso\n                self.fitness[i] = f_trial_pso\n                if f_trial_pso < self.best_fitness[i]:\n                    self.best_fitness[i] = f_trial_pso\n                    self.best_pos[i] = self.pop[i].copy()\n                if f_trial_pso < self.global_best_fitness:\n                    self.global_best_fitness = f_trial_pso\n                    self.global_best_pos = self.pop[i].copy()\n            elif f_trial_de < self.fitness[i]:\n                self.pop[i] = new_pos_de\n                self.fitness[i] = f_trial_de\n                if f_trial_de < self.best_fitness[i]:\n                    self.best_fitness[i] = f_trial_de\n                    self.best_pos[i] = self.pop[i].copy()\n                if f_trial_de < self.global_best_fitness:\n                    self.global_best_fitness = f_trial_de\n                    self.global_best_pos = self.pop[i].copy()\n\n        # Adaptive Parameter Control (based on global best improvement)\n        self.gb_history.append(self.global_best_fitness)\n        if len(self.gb_history) > 2:  # Ensure at least two values to compare\n            improvement = (self.gb_history[-2] - self.gb_history[-1]) / max(abs(self.gb_history[-2]), 1e-9) # avoid div by zero\n            \n            # Adjust PSO parameters based on improvement\n            self.c1 *= (1 + self.adapt_rate * improvement)\n            self.c2 *= (1 + self.adapt_rate * improvement)\n            self.c1 = np.clip(self.c1, 1.0, 4.0)\n            self.c2 = np.clip(self.c2, 1.0, 4.0)\n\n        # Linear inertia weight decay\n        self.w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget)\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n            if self.eval_count >= self.budget:\n                break\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.715 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["336d79b6-e955-4a7c-b3ab-ead379ab0020"], "operator": null, "metadata": {"aucs": [0.3171405698433958, 0.7982274973936925, 0.8515584415201063, 0.962237908996678, 0.3130434082082183, 0.9211579087554055, 0.3860150212739414, 0.8777327889822906, 0.8967145931895257, 0.8773377580958642, 0.9244278553055629, 0.9983855988073167, 0.4474487474993466, 0.8454438911075325, 0.9532880790472958, 0.921576507301187, 0.3297158863225421, 0.9299332024793407, 0.25688979287059477, 0.4930498462750772]}}
{"id": "b437bfbd-32c2-4b4e-b2f2-76757685010e", "fitness": 0.6367010081882551, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplified Hybrid PSO-DE with direct competition, inertia decay, and adaptive parameter adjustment based on successful move counts, promoting exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7, adapt_rate=0.1):\n        \"\"\"\n        Initializes the Hybrid PSO-DE optimizer with simplified adaptive parameters.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            adapt_rate (float): Rate for adapting PSO/DE parameters.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.adapt_rate = adapt_rate\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.pso_success_count = 0\n        self.de_success_count = 0\n        self.w = w_start\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        self.best_fitness = np.array([np.inf] * self.pop_size)\n        self.evaluate_population(func)  # Evaluate initial population\n\n    def evaluate_population(self, func):\n        \"\"\"\n        Evaluates the fitness of each particle in the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness[i]:\n                    self.best_fitness[i] = f\n                    self.best_pos[i] = self.pop[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with direct competition.\n        \"\"\"\n        self.pso_success_count = 0\n        self.de_success_count = 0\n\n        for i in range(self.pop_size):\n            # PSO update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = self.w * (self.pop[i] - self.best_pos[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n            new_pos_pso = self.pop[i] + velocity\n            new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n            f_trial_pso = func(new_pos_pso) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n\n            # DE update\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            trial_de = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    trial_de[j] = mutant[j]\n            trial_de = np.clip(trial_de, func.bounds.lb, func.bounds.ub) # Clip again after crossover\n            f_trial_de = func(trial_de) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n\n            # Direct competition\n            if f_trial_pso < f_trial_de:\n                if f_trial_pso < self.fitness[i]:\n                    self.pop[i] = new_pos_pso\n                    self.fitness[i] = f_trial_pso\n                    if f_trial_pso < self.best_fitness[i]:\n                        self.best_fitness[i] = f_trial_pso\n                        self.best_pos[i] = self.pop[i].copy()\n                    if f_trial_pso < self.global_best_fitness:\n                        self.global_best_fitness = f_trial_pso\n                        self.global_best_pos = self.pop[i].copy()\n                    self.pso_success_count += 1\n            else:\n                if f_trial_de < self.fitness[i]:\n                    self.pop[i] = trial_de\n                    self.fitness[i] = f_trial_de\n                    if f_trial_de < self.best_fitness[i]:\n                        self.best_fitness[i] = f_trial_de\n                        self.best_pos[i] = self.pop[i].copy()\n                    if f_trial_de < self.global_best_fitness:\n                        self.global_best_fitness = f_trial_de\n                        self.global_best_pos = self.pop[i].copy()\n                    self.de_success_count += 1\n                    \n        # Linear inertia weight decay\n        self.w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget)\n        \n        # Parameter adaptation based on success counts\n        total_success = self.pso_success_count + self.de_success_count\n        if total_success > 0:\n            pso_ratio = self.pso_success_count / total_success\n            de_ratio = self.de_success_count / total_success\n\n            self.c1 *= (1 + self.adapt_rate * (pso_ratio - 0.5))\n            self.c2 *= (1 + self.adapt_rate * (pso_ratio - 0.5))\n            self.F *= (1 + self.adapt_rate * (de_ratio - 0.5))\n            self.CR *= (1 + self.adapt_rate * (de_ratio - 0.5))\n\n            self.c1 = np.clip(self.c1, 1.0, 4.0)\n            self.c2 = np.clip(self.c2, 1.0, 4.0)\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        if self.eval_count >= self.budget:\n            return\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.637 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["336d79b6-e955-4a7c-b3ab-ead379ab0020"], "operator": null, "metadata": {"aucs": [0.2133378528522868, 0.7288627238138443, 0.9033407413232263, 0.2653435167501119, 0.33213104746729616, 0.9321311136387054, 0.34986606129529674, 0.8916005477570995, 0.9105162300115434, 0.21935389113221215, 0.8894756332330902, 0.9994099009417838, 0.4519517205066925, 0.3408906331380347, 0.9548217445024059, 0.9198208851058345, 0.8339003295381402, 0.9486048863853423, 0.1935108066618304, 0.4551498977103259]}}
{"id": "44b51846-46fb-4ac2-ae31-dd96e0f838ce", "fitness": 0.6277607359000973, "name": "AdaptiveHybridPSO_DE", "description": "Simplifies Adaptive Hybrid PSO-DE by focusing on a single adaptive probability for switching between PSO and DE, and integrates velocity updates directly into the position update for PSO, dynamically adjusting F and CR.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, F=0.6, CR=0.8):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): Population size.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.adapt_prob = 0.5\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        for i in range(self.pop_size):\n            f = func(self.pop[i])\n            self.eval_count += 1\n            self.fitness[i] = f\n            if f < self.best_fitness:\n                self.best_fitness = f\n                self.best_pos[i] = self.pop[i].copy()\n            if f < self.global_best_fitness:\n                self.global_best_fitness = f\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_positions(self, func):\n        \"\"\"Updates particle positions using adaptive PSO and DE.\"\"\"\n        improvements = 0\n\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Adaptive selection of PSO/DE\n            if np.random.rand() < self.adapt_prob:\n                # Simplified PSO update: direct position update with velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = self.w * (self.pop[i] - self.best_pos[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n                new_pos = self.pop[i] + velocity\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                f_new = func(new_pos)\n                self.eval_count += 1\n\n                if f_new < self.fitness[i]:\n                    improvements +=1\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_new\n                    if f_new < self.best_fitness:\n                        self.best_fitness = f_new\n                        self.best_pos[i] = self.pop[i].copy()\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_pos = self.pop[i].copy()\n            else:\n                # DE update\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                f_trial = func(trial)\n                self.eval_count += 1\n                if f_trial < self.fitness[i]:\n                    improvements += 1\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.best_fitness:\n                        self.best_fitness = f_trial\n                        self.best_pos[i] = self.pop[i].copy()\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = self.pop[i].copy()\n\n        #Adapt F and CR\n        self.F = np.clip(self.F + 0.1 * np.random.normal(0,1), 0.1, 1.0)\n        self.CR = np.clip(self.CR + 0.1 * np.random.normal(0,1), 0.1, 1.0)\n\n        # Adapt probability\n        if improvements > 0:\n            self.adapt_prob = 0.9 * self.adapt_prob + 0.1 * (improvements / self.pop_size)\n        else:\n            self.adapt_prob *= 0.9  # If no improvement, favor the other method\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using Adaptive Hybrid PSO-DE.\"\"\"\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.628 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["19497f9b-da57-4a4d-bb74-2829a418a487"], "operator": null, "metadata": {"aucs": [0.22791118193377036, 0.41306546765067953, 0.6127235361253195, 0.8804984538005355, 0.7423059490556909, 0.6988031503513139, 0.6004031374693977, 0.6160183791459642, 0.703738224640493, 0.6723628442733912, 0.822200099630512, 0.9950252224110974, 0.3584625488890034, 0.6774183345507279, 0.8765769511949318, 0.7247905655382816, 0.4483304007364495, 0.7309442769366254, 0.2450338296932003, 0.5086021639745606]}}
{"id": "9d5757d8-214d-45f3-b140-9bb9a14eef24", "fitness": 0.7524241607728352, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies Hybrid PSO-DE by directly adjusting the DE probability based on global best improvement and further reduces the cognitive component's complexity.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, c=1.0, F=0.9, CR=0.7, de_prob_init=0.9):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c (float): Cognitive and social coefficient for PSO (c1=c2=c).\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c = c\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_global_best = np.inf\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # Simplified PSO update (only global best influence)\n            r = np.random.rand(self.dim)\n            velocity = w * (r * (self.global_best_pos - self.pop[i]))\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                new_pos = trial\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            # Adjust DE probability based on global best improvement\n            if self.global_best_fitness < self.last_global_best:\n                self.de_prob = self.de_prob_init  # Reset to initial value upon improvement\n            else:\n                self.de_prob = min(1.0, self.de_prob * 1.05)  # Gradually increase DE probability without stagnation counter\n\n            self.update_population(func, w)\n            self.last_global_best = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.752 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ff71a21c-6f60-4eab-825e-89892a98cd29"], "operator": null, "metadata": {"aucs": [0.31489802127893574, 0.6601912658833173, 0.811515222029489, 0.9248873019357376, 0.8522377829816994, 0.884924104520254, 0.752310546930933, 0.7830177497304573, 0.8404918297192776, 0.8025680177910365, 0.8816220742622207, 0.9963446285716859, 0.4372937110390053, 0.7335409657570382, 0.7413383234194642, 0.8692793242294432, 0.7381620756377463, 0.9107510005330773, 0.5970022004259332, 0.5161070687799516]}}
{"id": "97b1ae72-ec35-40d0-926e-cce8eebb774c", "fitness": 0.7230128567136827, "name": "AdaptiveHybridPSO_DE", "description": "Simplified adaptive hybrid PSO-DE with dynamic inertia and simplified DE mutation strategy.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, F=0.7, CR=0.9, p_adapt=0.05, p_pso=0.5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with dynamic inertia and simplified DE.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            p_adapt (float): Probability of adapting p_pso.\n            p_pso (float): Initial probability of using PSO.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.p_adapt = p_adapt\n        self.p_pso = p_pso\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.success_pso = 0\n        self.success_de = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        for i in range(self.pop_size):\n            f = func(self.pop[i])\n            self.eval_count += 1\n            self.fitness[i] = f\n            if f < self.global_best_fitness:\n                self.global_best_fitness = f\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with adaptive probability and dynamic inertia.\n        \"\"\"\n        w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget) # Dynamic inertia\n\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            if np.random.rand() < self.p_pso:\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = w * (self.pop[i] - self.global_best_pos) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n                new_pos = self.pop[i] + velocity\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                f_new = func(new_pos)\n                self.eval_count += 1\n                \n                if f_new < self.fitness[i]:\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_new\n                    self.best_pos[i] = self.pop[i].copy()\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_pos = self.pop[i].copy()\n                    self.success_pso += 1\n                \n            else:\n                # DE update (Simplified mutation: rand/1/bin)\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    self.best_pos[i] = self.pop[i].copy()\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = self.pop[i].copy()\n                    self.success_de += 1\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n            if np.random.rand() < self.p_adapt and (self.success_pso + self.success_de) > 0:\n                self.p_pso = self.success_pso / (self.success_pso + self.success_de)\n                self.success_pso = 0\n                self.success_de = 0\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.723 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b630f803-1065-4dbc-9e8c-6a62eead7b31"], "operator": null, "metadata": {"aucs": [0.42704928853894053, 0.780074753118349, 0.5969256637420505, 0.9208453056209093, 0.8150300794219856, 0.8422561397223975, 0.7506619849682958, 0.7920530053586015, 0.813565252268281, 0.24833421959846547, 0.9120818170143639, 0.9959807431768344, 0.7469098916511252, 0.6909137045800529, 0.9425801048695739, 0.8514870102535673, 0.7131576568637865, 0.8962416147725473, 0.22328850031815128, 0.500820398415373]}}
{"id": "a9660d0e-8ec6-4f63-a176-4fd5ac6baa4f", "fitness": 0.7848433668923439, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies Hybrid PSO-DE further by directly using global best difference in velocity update and dynamically adjusting DE probability based on improvement.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, c=1.0, F=0.9, CR=0.7, de_prob_init=0.9):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c (float): Cognitive and social coefficient for PSO (c1=c2=c).\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c = c\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_global_best = np.inf\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update\n            velocity = w * (self.global_best_pos - self.pop[i])\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            # Adjust DE probability based on global best improvement\n            if self.global_best_fitness < self.last_global_best:\n                self.de_prob = self.de_prob_init  # Reset to initial value upon improvement\n                self.de_prob = min(1.0, self.de_prob * 0.95) #slightly decrease de prob after improvement\n            else:\n                self.de_prob = min(1.0, self.de_prob * 1.05)  # Gradually increase DE probability without stagnation counter\n\n            self.update_population(func, w)\n            self.last_global_best = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.785 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ff71a21c-6f60-4eab-825e-89892a98cd29"], "operator": null, "metadata": {"aucs": [0.42016348172878204, 0.8236191855598048, 0.872287815775876, 0.9573684659340839, 0.8964117635583916, 0.9248973076162985, 0.383873972490711, 0.8689347434156616, 0.8877086045734277, 0.9049488075717529, 0.9308404146994711, 0.9994077669305736, 0.39423403254418765, 0.8990051259087835, 0.9534886350545655, 0.9209141867263392, 0.8594289595987132, 0.927102452776223, 0.3652487868830574, 0.5069828285001748]}}
{"id": "d12f0a94-8f72-4ac5-8be5-239b6c2c40d4", "fitness": 0.37619190499098154, "name": "AdaptiveHybridPSO_DE", "description": "Simplified PSO-DE by removing velocity and directly updating position towards global best with adaptive PSO/DE selection based on success.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.7, CR=0.9, p_adapt=0.05, p_pso=0.5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with simplified position update and adaptive PSO/DE.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            p_adapt (float): Probability of adapting p_pso.\n            p_pso (float): Initial probability of using PSO.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.p_adapt = p_adapt\n        self.p_pso = p_pso\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.success_pso = 0\n        self.success_de = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            f = func(self.pop[i])\n            self.eval_count += 1\n            self.fitness[i] = f\n            if f < self.global_best_fitness:\n                self.global_best_fitness = f\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with adaptive probability.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            if np.random.rand() < self.p_pso:\n                # PSO update: move directly towards global best\n                new_pos = self.pop[i] + np.random.rand(self.dim) * (self.global_best_pos - self.pop[i])\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                f_new = func(new_pos)\n                self.eval_count += 1\n                \n                if f_new < self.fitness[i]:\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_new\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_pos = self.pop[i].copy()\n                    self.success_pso += 1\n                \n            else:\n                # DE update (Simplified mutation: rand/1/bin)\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = self.pop[i].copy()\n                    self.success_de += 1\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n            if np.random.rand() < self.p_adapt and (self.success_pso + self.success_de) > 0:\n                self.p_pso = self.success_pso / (self.success_pso + self.success_de)\n                self.success_pso = 0\n                self.success_de = 0\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.376 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["97b1ae72-ec35-40d0-926e-cce8eebb774c"], "operator": null, "metadata": {"aucs": [0.15182826350896994, 0.26405690043529007, 0.37164054234707955, 0.2541352593957905, 0.2384274892791015, 0.4528549416745995, 0.25739100863814435, 0.2574997606788285, 0.2683955790902387, 0.1796148668332762, 0.2945793041004129, 0.9943946753674884, 0.6725235160504759, 0.2662619513630965, 0.6829385985322763, 0.32126125320538557, 0.22281049815339993, 0.6801819493238837, 0.20304126988731808, 0.49000047195457497]}}
{"id": "62dd20aa-3f11-43a1-bbee-08551b74cd7d", "fitness": 0.6162589134969202, "name": "AdaptiveHybridPSO_DE", "description": "Dynamically adjusts PSO inertia weight and DE scaling factor based on global best improvement and simplifies parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, F_start=0.8, CR=0.9, p_pso=0.5, adapt_freq=100):\n        \"\"\"\n        Adaptive Hybrid PSO-DE optimizer with dynamic inertia, dynamic DE scaling factor, and simplified parameter adaptation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F_start (float): Initial scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            p_pso (float): Initial probability of using PSO.\n            adapt_freq (int): Frequency of adapting parameters (every adapt_freq evaluations).\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F_start = F_start\n        self.CR = CR\n        self.p_pso = p_pso\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_improvement = 0\n        self.adapt_freq = adapt_freq\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        for i in range(self.pop_size):\n            f = func(self.pop[i])\n            self.eval_count += 1\n            self.fitness[i] = f\n            if f < self.global_best_fitness:\n                self.global_best_fitness = f\n                self.global_best_pos = self.pop[i].copy()\n                self.last_improvement = self.eval_count\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with adaptive probability and dynamic inertia.\n        \"\"\"\n        w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget) # Dynamic inertia\n        F = self.F_start * np.exp(0.1 * (self.eval_count - self.last_improvement) / self.budget)\n        F = np.clip(F, 0.1, 1.0)\n\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            if np.random.rand() < self.p_pso:\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = w * (self.pop[i] - self.global_best_pos) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n                new_pos = self.pop[i] + velocity\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                f_new = func(new_pos)\n                self.eval_count += 1\n                \n                if f_new < self.fitness[i]:\n                    self.pop[i] = new_pos\n                    self.fitness[i] = f_new\n                    self.best_pos[i] = self.pop[i].copy()\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_pos = self.pop[i].copy()\n                        self.last_improvement = self.eval_count\n                \n            else:\n                # DE update (Simplified mutation: rand/1/bin)\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    self.best_pos[i] = self.pop[i].copy()\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = self.pop[i].copy()\n                        self.last_improvement = self.eval_count\n        \n        if self.eval_count % self.adapt_freq == 0:\n            if self.eval_count - self.last_improvement > self.adapt_freq:\n                self.p_pso = max(0.0, self.p_pso - 0.1)  # Reduce PSO probability if no recent improvement\n            else:\n                self.p_pso = min(1.0, self.p_pso + 0.1)  # Increase PSO probability if recent improvement\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.616 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["97b1ae72-ec35-40d0-926e-cce8eebb774c"], "operator": null, "metadata": {"aucs": [0.24228776911085192, 0.5820172232925106, 0.4760622188044159, 0.8934287222521935, 0.48219871227989386, 0.6340475446384971, 0.5648058157067752, 0.34992687700374503, 0.7241912893090621, 0.6479905945361095, 0.8194646217144586, 0.9853521374769014, 0.6043139777721558, 0.726842822019304, 0.7778946659449693, 0.8055174535987035, 0.458735689155347, 0.8276613650160309, 0.21234964179530658, 0.5100891285111728]}}
{"id": "7b545726-a1d6-40cd-a693-c08cf32bb300", "fitness": 0.6633920381787656, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Further simplifies Hybrid PSO-DE by removing the cognitive component entirely, focusing on global best influence and adaptive DE probability based on improvement stagnation.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, F=0.9, CR=0.7, de_prob_init=0.9, stagnation_threshold=50):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n            stagnation_threshold (int): Number of iterations without improvement before increasing DE probability.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.stagnation_threshold = stagnation_threshold\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # Simplified PSO update (only global best influence)\n            r = np.random.rand(self.dim)\n            velocity = w * r * (self.global_best_pos - self.pop[i])\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                new_pos = trial\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n                    self.stagnation_counter = 0 # Reset stagnation counter\n            else:\n                self.stagnation_counter += 1\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            # Adjust DE probability based on stagnation\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.de_prob = min(1.0, self.de_prob * 1.1) # Increase DE prob if stagnating\n                self.stagnation_counter = 0 # Reset counter after increasing DE prob\n            else:\n                self.de_prob = max(0.0, self.de_prob * 0.99) # Slightly decrease de_prob to allow PSO to converge better\n\n            self.update_population(func, w)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.663 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9d5757d8-214d-45f3-b140-9bb9a14eef24"], "operator": null, "metadata": {"aucs": [0.3311155392013131, 0.8284480235325371, 0.4252774203113714, 0.9609506057271474, 0.4394535369561251, 0.7996994454568167, 0.8626543664897791, 0.7156859811975653, 0.5380982198527491, 0.7032306759980126, 0.9481030148147735, 1.0, 0.4060590786432292, 0.5696599736426982, 0.8253480090284984, 0.790597378371015, 0.3610424919087222, 0.9577597717189933, 0.299897925319241, 0.5047593054047221]}}
{"id": "dbca4c34-2882-40d2-add7-7f477be40f0c", "fitness": 0.625686977115578, "name": "AdaptiveHybridPSO_DE", "description": "Simplifies Adaptive Hybrid PSO-DE by adaptively adjusting the inertia weight based on global best improvement and streamlining the PSO update.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7, adapt_rate=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with simplified adaptation and reduced evaluations.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            adapt_rate (float): Rate for adapting PSO inertia weight.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.adapt_rate = adapt_rate\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.w = w_start\n        self.gb_history = []\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        self.best_fitness = np.array([np.inf] * self.pop_size)\n        self.evaluate_population(func)  # Evaluate initial population\n        self.gb_history.append(self.global_best_fitness)\n\n    def evaluate_population(self, func):\n        \"\"\"\n        Evaluates the fitness of each particle in the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness[i]:\n                    self.best_fitness[i] = f\n                    self.best_pos[i] = self.pop[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with reduced evaluations and adaptive parameters.\n        \"\"\"\n        for i in range(self.pop_size):\n            # PSO update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = self.w * (self.best_pos[i] - self.pop[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n            new_pos_pso = self.pop[i] + velocity\n            new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n\n            # DE update\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    trial[j] = mutant[j]\n            new_pos_de = trial\n            \n            # Evaluate only the better move (reduce function evaluations)\n            f_trial_pso = func(new_pos_pso) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n\n            f_trial_de = func(new_pos_de) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n\n            if f_trial_pso < f_trial_de and f_trial_pso < self.fitness[i]:\n                self.pop[i] = new_pos_pso\n                self.fitness[i] = f_trial_pso\n                if f_trial_pso < self.best_fitness[i]:\n                    self.best_fitness[i] = f_trial_pso\n                    self.best_pos[i] = self.pop[i].copy()\n                if f_trial_pso < self.global_best_fitness:\n                    self.global_best_fitness = f_trial_pso\n                    self.global_best_pos = self.pop[i].copy()\n            elif f_trial_de < self.fitness[i]:\n                self.pop[i] = new_pos_de\n                self.fitness[i] = f_trial_de\n                if f_trial_de < self.best_fitness[i]:\n                    self.best_fitness[i] = f_trial_de\n                    self.best_pos[i] = self.pop[i].copy()\n                if f_trial_de < self.global_best_fitness:\n                    self.global_best_fitness = f_trial_de\n                    self.global_best_pos = self.pop[i].copy()\n\n        # Adaptive Inertia Weight Control (based on global best improvement)\n        self.gb_history.append(self.global_best_fitness)\n        if len(self.gb_history) > 2:  # Ensure at least two values to compare\n            improvement = (self.gb_history[-2] - self.gb_history[-1]) / max(abs(self.gb_history[-2]), 1e-9) # avoid div by zero\n            \n            # Adjust PSO parameters based on improvement\n            self.w *= (1 + self.adapt_rate * improvement)\n            self.w = np.clip(self.w, self.w_end, self.w_start) #clip to the boundaries\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n            if self.eval_count >= self.budget:\n                break\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.626 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b3e4bae8-5e33-4df2-ad5f-88c17f915c83"], "operator": null, "metadata": {"aucs": [0.23662666034359459, 0.26375992500937095, 0.8305740426722253, 0.18228251135973728, 0.8891276137336117, 0.958817961693525, 0.25413835653833605, 0.6692485067750713, 0.9375468650998603, 0.22029829610461915, 0.9262145773895055, 0.9993748581596887, 0.3589250841655429, 0.8018730318294397, 0.9408809517904788, 0.9516692179861522, 0.3999194848956127, 0.9676231797719091, 0.22714576387933882, 0.49769265311394106]}}
{"id": "dee1a5a5-d770-4b4f-92df-bcd0d5270f2c", "fitness": 0.24598911586058142, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Further simplifies Hybrid PSO-DE by removing the inertia weight, directly using the global best difference in velocity, and more aggressively adapting the DE probability based on improvement.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c=1.0, F=0.9, CR=0.7, de_prob_init=0.9):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            c (float): Cognitive and social coefficient for PSO (c1=c2=c).\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c = c\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_global_best = np.inf\n        self.stagnation_counter = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update (no inertia)\n            velocity = self.c * (self.global_best_pos - self.pop[i])\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adjust DE probability based on global best improvement\n            if self.global_best_fitness < self.last_global_best:\n                self.de_prob = self.de_prob_init # Reset to initial value upon improvement\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter +=1\n\n            if self.stagnation_counter > 10:\n                self.de_prob = min(1.0, self.de_prob * 1.1)\n            else:\n                self.de_prob = max(0.1, self.de_prob * 0.9)  # Gradually decrease DE probability without stagnation counter\n\n            self.update_population(func)\n            self.last_global_best = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.246 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a9660d0e-8ec6-4f63-a176-4fd5ac6baa4f"], "operator": null, "metadata": {"aucs": [0.08607206145308721, 0.1565229047130995, 0.2631678994254084, 0.17567284351220147, 0.1907152321742236, 0.21989480234420566, 0.19414389506055862, 0.20327740418089035, 0.18665971173768392, 0.16076810227148852, 0.18455033137042076, 0.9968968422386316, 0.18995666843568526, 0.1778298429889672, 0.20178348829908366, 0.3247754134142, 0.1914372412731724, 0.25796931586911254, 0.1130459738866797, 0.44464234256282775]}}
{"id": "90442093-7482-4ed3-b0bf-b138348cafc4", "fitness": 0.420790454356286, "name": "HybridPSO_DE_SimpleAdaptiveV2", "description": "Simplifies Hybrid PSO-DE by removing the cognitive component and further streamlining DE parameter adaptation based solely on the success rate of DE moves.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptiveV2:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, F=0.9, CR=0.7, de_prob_init=0.9, de_succ_rate_decay=0.95):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability based on the success rate of DE moves.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n            de_succ_rate_decay: Decay factor for DE success rate\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.de_success_rate = 0.0\n        self.de_succ_rate_decay = de_succ_rate_decay\n\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            old_fitness = self.fitness[i]\n            # PSO update: Simplified velocity update (only global best)\n            velocity = w * (self.global_best_pos - self.pop[i])\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            de_applied = False\n            if np.random.rand() < self.de_prob:\n                de_applied = True\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n                if de_applied:\n                    self.de_success_rate = self.de_succ_rate_decay * self.de_success_rate + (1 - self.de_succ_rate_decay) * 1.0  # Update success rate if DE was applied and improved\n\n            else:\n                 if de_applied:\n                    self.de_success_rate = self.de_succ_rate_decay * self.de_success_rate + (1 - self.de_succ_rate_decay) * 0.0 # Update success rate if DE was applied and did not improve\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            # Adjust DE probability based on success rate\n            if self.de_success_rate > 0.2:\n                self.de_prob = max(0.0, self.de_prob * 0.99)  # Reduce DE probability if successful\n            else:\n                self.de_prob = min(1.0, self.de_prob * 1.01)  # Increase DE probability if not successful\n\n            self.update_population(func, w)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptiveV2 scored 0.421 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a9660d0e-8ec6-4f63-a176-4fd5ac6baa4f"], "operator": null, "metadata": {"aucs": [0.2812309438472109, 0.65765161717147, 0.4650609435329567, 0.5811919995681912, 0.3798907058583826, 0.5216536615542718, 0.33922612020723386, 0.32575743616345165, 0.25002799918504803, 0.21310195763202078, 0.41161373007479274, 0.9967848757476117, 0.25069293572068196, 0.2506795978121751, 0.7640362724323958, 0.3297433921837817, 0.3220103882349261, 0.4113136315655854, 0.18980062922671792, 0.4743402494068141]}}
{"id": "276815b0-a239-486f-9a7c-dc905f242936", "fitness": 0.292655278541332, "name": "HybridPSO_DE_SimpleAdaptiveV2", "description": "Further simplifies Hybrid PSO-DE by directly using global best difference in velocity update and dynamically adjusting DE probability based on a simplified success-based adaptation.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptiveV2:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, c=1.0, F=0.9, CR=0.7, de_prob_init=0.9):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c (float): Cognitive and social coefficient for PSO (c1=c2=c).\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c = c\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.success_rate = 0.0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        successful_moves = 0\n        for i in range(self.pop_size):\n            old_fitness = self.fitness[i]\n            # PSO update: Simplified velocity update\n            velocity = w * (self.global_best_pos - self.pop[i])\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                successful_moves += 1\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n        \n        # Simplified success-based adaptation of DE probability\n        self.success_rate = successful_moves / self.pop_size\n        if self.success_rate > 0.2:\n            self.de_prob = max(0.0, self.de_prob - 0.05)  # Decrease DE prob if doing well\n        else:\n            self.de_prob = min(1.0, self.de_prob + 0.05)  # Increase DE prob if not improving\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n            self.update_population(func, w)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptiveV2 scored 0.293 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a9660d0e-8ec6-4f63-a176-4fd5ac6baa4f"], "operator": null, "metadata": {"aucs": [0.1901646122367031, 0.3153813104201538, 0.2276088397999141, 0.19069811051160168, 0.23967029187170164, 0.23174641408814245, 0.259167253183481, 0.22618398726089706, 0.17840460005776126, 0.22636308975955255, 0.23239137385294417, 0.9947452026304031, 0.2340393434663134, 0.3741216764113746, 0.17464469833359508, 0.30648766970290253, 0.2461327110685103, 0.3607230190734855, 0.19159855931290504, 0.45283280778429813]}}
{"id": "9c5a18cc-95eb-4919-86dd-1bf9ff8b50d8", "fitness": 0.7844869020773446, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Dynamically adjusts DE probability based on global best improvement and simplifies PSO by removing the cognitive component and directly using the difference between current and global best positions.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, F=0.9, CR=0.7, de_prob_init=0.9):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability and simplified PSO.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_global_best = np.inf\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # Simplified PSO update (only global best influence, simplified velocity)\n            velocity = w * (self.global_best_pos - self.pop[i]) # Remove random factor\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                new_pos = trial\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            # Adjust DE probability based on global best improvement\n            if self.global_best_fitness < self.last_global_best:\n                self.de_prob = self.de_prob_init  # Reset to initial value upon improvement\n            else:\n                self.de_prob = min(1.0, self.de_prob * 1.05)  # Gradually increase DE probability without stagnation counter\n\n            self.update_population(func, w)\n            self.last_global_best = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.784 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9d5757d8-214d-45f3-b140-9bb9a14eef24"], "operator": null, "metadata": {"aucs": [0.19897172828851895, 0.713084112190356, 0.864972552640518, 0.9353105306044746, 0.9087676258815677, 0.917816142095328, 0.7670081943340541, 0.8550327195242087, 0.9103731576557386, 0.8876106278916606, 0.9302116816008803, 0.9969500444867879, 0.4410715759243514, 0.8218485830689402, 0.9621023794789684, 0.9258193813600197, 0.8508168540716025, 0.9410913291309374, 0.32461396576175927, 0.5362648555562188]}}
{"id": "1daafbd8-b531-49a2-83b4-4d331c92cbab", "fitness": 0.73419313412952, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies Hybrid PSO-DE by removing the cognitive component, further adjusting the DE probability based on the improvement rate, and implementing a simpler DE mutation.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, F=0.9, CR=0.7, de_prob_init=0.9):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_global_best = np.inf\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update (only global best)\n            velocity = w * (self.global_best_pos - self.pop[i])\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[i]) # Simplified DE mutation\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            # Adjust DE probability based on global best improvement\n            improvement = (self.last_global_best - self.global_best_fitness) / abs(self.last_global_best) if self.last_global_best != 0 else 0\n            if improvement > 0:\n              self.de_prob = self.de_prob_init * (1 - improvement) # Decrease DE prob if there is an improvement\n              self.de_prob = max(0.05, self.de_prob)\n            else:\n              self.de_prob = min(1.0, self.de_prob * 1.02)  # Gradually increase DE probability if stuck\n            \n            self.update_population(func, w)\n            self.last_global_best = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.734 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a9660d0e-8ec6-4f63-a176-4fd5ac6baa4f"], "operator": null, "metadata": {"aucs": [0.23134393472823256, 0.5741748157704152, 0.8433150825908514, 0.9160318646828083, 0.86054058004792, 0.8910540759250907, 0.4963362649546058, 0.830074287998129, 0.8330991340714464, 0.8033683728651047, 0.9236041001546206, 0.9977973315317933, 0.3668480883217685, 0.7878340230700195, 0.9410226676366494, 0.8899047379966121, 0.7322243698236656, 0.9243584273952963, 0.30602853820787546, 0.5349019848174941]}}
{"id": "3787d10c-98b4-49b3-9864-c5514356c6d2", "fitness": 0.7571294528362593, "name": "AdaptiveHybridPSO_DE", "description": "Simplifies Hybrid PSO-DE with dynamic parameter adjustment based on global best improvement and reduces evaluations using a probabilistic selection between PSO and DE updates.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7, adapt_rate=0.1, de_prob=0.5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with simplified adaptation,\n        reduced evaluations, and probabilistic PSO/DE selection.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            adapt_rate (float): Rate for adapting PSO/DE parameters.\n            de_prob (float): Probability of applying DE update.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.adapt_rate = adapt_rate\n        self.de_prob = de_prob\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.w = w_start\n        self.gb_history = []\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        self.best_fitness = np.array([np.inf] * self.pop_size)\n        self.evaluate_population(func)  # Evaluate initial population\n        self.gb_history.append(self.global_best_fitness)\n\n    def evaluate_population(self, func):\n        \"\"\"\n        Evaluates the fitness of each particle in the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness[i]:\n                    self.best_fitness[i] = f\n                    self.best_pos[i] = self.pop[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with reduced evaluations and adaptive parameters.\n        \"\"\"\n        for i in range(self.pop_size):\n            # PSO update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = self.w * (self.pop[i] - self.best_pos[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n            new_pos_pso = self.pop[i] + velocity\n            new_pos_pso = np.clip(new_pos_pso, func.bounds.lb, func.bounds.ub)\n\n            # DE update\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    trial[j] = mutant[j]\n            new_pos_de = trial\n            \n            # Probabilistic selection between PSO and DE\n            if np.random.rand() < self.de_prob:\n                new_pos = new_pos_de\n            else:\n                new_pos = new_pos_pso\n\n            # Evaluate the new position\n            f_new = func(new_pos) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.best_fitness[i]:\n                    self.best_fitness[i] = f_new\n                    self.best_pos[i] = self.pop[i].copy()\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n        # Adaptive Parameter Control (based on global best improvement)\n        self.gb_history.append(self.global_best_fitness)\n        if len(self.gb_history) > 2:  # Ensure at least two values to compare\n            improvement = (self.gb_history[-2] - self.gb_history[-1]) / max(abs(self.gb_history[-2]), 1e-9) # avoid div by zero\n            \n            # Adjust PSO parameters based on improvement\n            self.c1 *= (1 + self.adapt_rate * improvement)\n            self.c2 *= (1 + self.adapt_rate * improvement)\n            self.c1 = np.clip(self.c1, 1.0, 4.0)\n            self.c2 = np.clip(self.c2, 1.0, 4.0)\n            self.de_prob = np.clip(self.de_prob + self.adapt_rate * improvement, 0.1, 0.9) # Adjust DE probability\n\n        # Linear inertia weight decay\n        self.w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget)\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n            if self.eval_count >= self.budget:\n                break\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.757 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b3e4bae8-5e33-4df2-ad5f-88c17f915c83"], "operator": null, "metadata": {"aucs": [0.4647690329284887, 0.8127602220955379, 0.8687236105869223, 0.9183425631577542, 0.8354505801849016, 0.925805714034471, 0.8776193660740016, 0.8723017578941732, 0.8192877686561759, 0.20832013523956772, 0.9362227344047735, 0.9965533087738991, 0.2554922759728371, 0.8961103130599004, 0.96051574555581, 0.924616522423432, 0.406378339101505, 0.9397253112079931, 0.7147098328945031, 0.5088839224785384]}}
{"id": "33b3348e-99c7-4b9a-b9e2-677f6a40da86", "fitness": 0.27284246213605395, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Adaptively adjusts DE probability and inertia weight based on global best improvement, simplifying PSO velocity update and capping DE probability.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, c=1.0, F=0.9, CR=0.7, de_prob_init=0.9, de_prob_cap=0.5):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c (float): Cognitive and social coefficient for PSO (c1=c2=c).\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n            de_prob_cap (float): Maximum probability for DE application.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c = c\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.de_prob_cap = de_prob_cap\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_global_best = np.inf\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update\n            velocity = w * (self.global_best_pos - self.pop[i])\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            # Adjust DE probability based on global best improvement\n            if self.global_best_fitness < self.last_global_best:\n                self.de_prob = self.de_prob_init # Reset to initial value upon improvement\n                self.de_prob = min(self.de_prob_cap, self.de_prob * 1.05)\n            else:\n                self.de_prob = max(0.0, self.de_prob * 0.95) # Decrease if no improvement, but not increase\n\n            self.update_population(func, w)\n            self.last_global_best = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.273 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a9660d0e-8ec6-4f63-a176-4fd5ac6baa4f"], "operator": null, "metadata": {"aucs": [0.12736089546770124, 0.18621829805571632, 0.3085588921342993, 0.2009839897650949, 0.2120469383352317, 0.2414095625942979, 0.26885188793383985, 0.22345312072520096, 0.18221768941792993, 0.17590395111503587, 0.3544321471997307, 0.9986342238269854, 0.2381885244811176, 0.1670664328332434, 0.1501115442641836, 0.28743135753441085, 0.22309083324776147, 0.27125393197573444, 0.18576966133239503, 0.4538653604811691]}}
{"id": "be5a503c-d96b-4798-b5d2-2bd08d7f4bc3", "fitness": 0.7744029007737722, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies Hybrid PSO-DE by removing cognitive component, adjusting DE probability based on improvement, and using a direct velocity update.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, F=0.9, CR=0.7, de_prob_init=0.9):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_global_best = np.inf\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update - only global best\n            velocity = w * (self.global_best_pos - self.pop[i])\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            # Adjust DE probability based on global best improvement\n            if self.global_best_fitness < self.last_global_best:\n                self.de_prob = self.de_prob_init # Reset to initial value upon improvement\n            else:\n                self.de_prob = min(1.0, self.de_prob * 1.02)  # Gradually increase DE probability without stagnation counter, reducing factor for more exploration\n\n            self.update_population(func, w)\n            self.last_global_best = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.774 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a9660d0e-8ec6-4f63-a176-4fd5ac6baa4f"], "operator": null, "metadata": {"aucs": [0.3750430512881776, 0.8890635457070564, 0.8826872112398284, 0.9502880319483402, 0.8823048311923385, 0.9289426460000645, 0.3397982175630575, 0.8614098888373314, 0.9073321757768418, 0.8920763212971629, 0.9460280828523795, 0.9944972554681957, 0.23217572921127938, 0.8940705160774101, 0.9598143322481463, 0.9248521793221262, 0.3239250876761941, 0.9196615140332942, 0.8683511777018833, 0.5157362200343365]}}
{"id": "d22c5d6c-b49d-41e2-9da7-bbe81f518bb6", "fitness": 0.2101164050921879, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies the hybrid PSO-DE by reducing DE application and removing velocity clipping while adapting DE probability based on improvement rate for balanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, F=0.9, CR=0.7, de_prob_init=0.9):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_global_best = np.inf\n        self.success_rate = 0.0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        improvements = 0\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update - only global best\n            velocity = w * (self.global_best_pos - self.pop[i])\n            new_pos = self.pop[i] + velocity\n\n            # DE update (applied with a reduced probability)\n            if np.random.rand() < self.de_prob * 0.5: # Reduce DE application\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                improvements += 1\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n        self.success_rate = improvements / self.pop_size if self.pop_size > 0 else 0.0\n\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            # Adjust DE probability based on success rate\n            if self.global_best_fitness < self.last_global_best:\n                 self.de_prob = max(0.0, min(1.0, self.de_prob_init * (1 + (self.success_rate -0.5)/0.5)))\n            else:\n                 self.de_prob = min(1.0, self.de_prob * 1.01) # increase slower when no improvements\n\n            self.update_population(func, w)\n            self.last_global_best = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.210 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["be5a503c-d96b-4798-b5d2-2bd08d7f4bc3"], "operator": null, "metadata": {"aucs": [0.1352239619955884, 0.17917726637361064, 0.2812860981133317, 0.159920803807984, 0.10477028384625342, 0.17255199823613765, 0.2154526953658733, 0.2277211551621674, 0.19583447925359676, 0.12004601584314534, 0.17082633788951118, 0.21779336030208918, 0.22446402555499945, 0.13572461750395814, 0.5556419400903021, 0.24544437992857104, 0.16412547964572533, 0.17441327568370268, 0.10808197965560085, 0.41382794759160946]}}
{"id": "91a54cf6-5c99-4a67-8c28-4902e4ed3461", "fitness": 0.31238025529738633, "name": "HybridPSO_DE_SimpleAdaptiveV2", "description": "Simplifies Hybrid PSO-DE further by removing inertia weight and linearly reducing DE probability, using a direct velocity update towards global best.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptiveV2:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.9, CR=0.7, de_prob_init=0.9):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update - only global best\n            velocity = (self.global_best_pos - self.pop[i])  # Remove inertia weight\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive DE probability - linear reduction\n            self.de_prob = self.de_prob_init * (1 - (self.eval_count / self.budget))\n\n            self.update_population(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptiveV2 scored 0.312 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["be5a503c-d96b-4798-b5d2-2bd08d7f4bc3"], "operator": null, "metadata": {"aucs": [0.10603292394472408, 0.18756801283787727, 0.3481726508774866, 0.30035103604436386, 0.24318286543301038, 0.2347208179472382, 0.26962308704614457, 0.2245564003208812, 0.25860226642399453, 0.20608578139706346, 0.34588611469259567, 0.9953154447070612, 0.12491410878780151, 0.23401467664796605, 0.7168043668486284, 0.34487433717294813, 0.28727278447293325, 0.19033694117513422, 0.15026393286664275, 0.4790265563032319]}}
{"id": "89573604-fcd4-481d-8df0-418a80e859af", "fitness": 0.6734754986161429, "name": "AdaptiveHybridPSO_DE", "description": "Simplifies the adaptive hybrid PSO-DE by directly updating the DE mutation based on the global best, reducing complexity and evaluation counts, and incorporating a simple inertia weight adaptation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, F=0.5, CR=0.7, adapt_rate=0.1, de_prob=0.5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with simplified DE mutation and reduced evaluations.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            adapt_rate (float): Rate for adapting PSO/DE parameters.\n            de_prob (float): Probability of applying DE update.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.adapt_rate = adapt_rate\n        self.de_prob = de_prob\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.w = w_start\n        self.gb_history = []\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.evaluate_population(func)\n        self.gb_history.append(self.global_best_fitness)\n\n    def evaluate_population(self, func):\n        \"\"\"\n        Evaluates the fitness of each particle in the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with simplified DE mutation and adaptive parameters.\n        \"\"\"\n        for i in range(self.pop_size):\n            if np.random.rand() < self.de_prob:\n                # Simplified DE: Directly use global best in mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n                mutant = self.global_best_pos + self.F * (self.pop[a] - self.pop[b])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                new_pos = trial\n            else:\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                velocity = self.w * (self.pop[i] - self.global_best_pos) + r1 * (self.global_best_pos - self.pop[i])\n                new_pos = self.pop[i] + velocity\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate the new position\n            f_new = func(new_pos) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n        # Adaptive Inertia Weight (simple linear decay)\n        self.w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget)\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n            if self.eval_count >= self.budget:\n                break\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.673 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3787d10c-98b4-49b3-9864-c5514356c6d2"], "operator": null, "metadata": {"aucs": [0.12570463037153712, 0.33216557213926723, 0.8750017221596669, 0.9566859679189731, 0.8288726163605461, 0.9333484474184873, 0.3244118046397729, 0.7383175099882633, 0.8887235295662913, 0.23608141268778438, 0.9071260252413925, 0.995537495958777, 0.4826821001947441, 0.7883811945277761, 0.7397468482285334, 0.9218495484870393, 0.8731395527821433, 0.9322542486441667, 0.13982550019426687, 0.4496542448134281]}}
{"id": "d42ec443-3074-440f-a07c-e46bb6c9b2b6", "fitness": 0.1529766684166941, "name": "HybridPSO_DE_SimpleAdaptiveV2", "description": "Further simplifies Hybrid PSO-DE by removing inertia weight, adjusting DE probability inversely proportional to improvement rate for more exploration and removing CR crossover for a more aggressive DE mutation.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptiveV2:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.9, de_prob_init=0.9):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            F (float): Scaling factor for DE.\n            de_prob_init (float): Initial probability of applying DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_global_best = np.inf\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update - only global best\n            velocity = (self.global_best_pos - self.pop[i])\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                new_pos = mutant # Directly replace with mutant\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adjust DE probability based on global best improvement\n            if self.global_best_fitness < self.last_global_best:\n                improvement = (self.last_global_best - self.global_best_fitness) / self.last_global_best\n                self.de_prob = self.de_prob_init * (1 - improvement)  # Reduce DE prob proportionally to improvement\n                self.de_prob = max(0.05, self.de_prob) # Ensure a minimum DE probability for constant exploration\n            else:\n                self.de_prob = min(1.0, self.de_prob * 1.05)  # Gradually increase DE probability\n\n            self.update_population(func)\n            self.last_global_best = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptiveV2 scored 0.153 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["be5a503c-d96b-4798-b5d2-2bd08d7f4bc3"], "operator": null, "metadata": {"aucs": [0.04700900800981567, 0.07820546613238655, 0.21762574873541196, 0.12403307218956161, 0.11842588848298763, 0.16492701995152714, 0.1598899878874549, 0.14414212658404668, 0.17443220568813345, 0.11239562734544228, 0.146683202223318, 0.20076608912216465, 0.08709242571874731, 0.10267035005815872, 0.14186934041359323, 0.19833731151958167, 0.16922528922284819, 0.1668700544181927, 0.1185446113520604, 0.3863885432784485]}}
{"id": "e4689b8e-7517-4ca4-93aa-8d37784a9dfe", "fitness": 0.32300098629753526, "name": "HybridPSO_DE_Simple", "description": "Simplifies Hybrid PSO-DE further by removing the adaptive DE probability and directly controlling exploration via a modified inertia weight and a constant DE probability.", "code": "import numpy as np\n\nclass HybridPSO_DE_Simple:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, F=0.9, CR=0.7, de_prob=0.7):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob (float): Constant probability of applying DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.de_prob = de_prob\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update - only global best\n            velocity = w * (self.global_best_pos - self.pop[i])\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            self.update_population(func, w)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSO_DE_Simple scored 0.323 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["be5a503c-d96b-4798-b5d2-2bd08d7f4bc3"], "operator": null, "metadata": {"aucs": [0.13127112868172408, 0.16688135675287408, 0.26799384656316083, 0.19012434538626866, 0.2252612221505368, 0.28818498829957384, 0.2431086390252527, 0.22795542738808694, 0.6625196246602686, 0.18622739067873995, 0.3052816175842794, 0.9999130824368638, 0.2527338926013043, 0.24508998463520404, 0.758491269670123, 0.2981906599063966, 0.25427215451182983, 0.18017598209409313, 0.1237547078685971, 0.4525884050555281]}}
{"id": "7f2f3c33-19ba-4711-928c-9c6041a00d54", "fitness": 0.7831299133204968, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies and enhances Hybrid PSO-DE by focusing on aggressive exploration through increased DE influence and simplification of parameter adaptation.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.7, w_end=0.3, F=0.8, CR=0.8, de_prob=0.95):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob (float): Probability of applying DE.  Increased default value.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.de_prob = de_prob  # Fixed DE probability - aggressive exploration\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update - only global best\n            velocity = w * (self.global_best_pos - self.pop[i])\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (Simplified)\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            self.update_population(func, w)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.783 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["be5a503c-d96b-4798-b5d2-2bd08d7f4bc3"], "operator": null, "metadata": {"aucs": [0.620097747365699, 0.8212589323060917, 0.8812989235224065, 0.9466046721237128, 0.9201161269423297, 0.9310439403722229, 0.3743029579051821, 0.8769821358434366, 0.9108689932695055, 0.8973025658773339, 0.9591684294932751, 0.9975681678667343, 0.7373653328515675, 0.848410315746544, 0.976272362103303, 0.9267253446789174, 0.3285308757673786, 0.9391481992008877, 0.24842624271839142, 0.5211060004550159]}}
{"id": "f7e70ae2-2b75-499e-bee2-02ae2524079d", "fitness": 0.4310656506984428, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies Hybrid PSO-DE with adaptive DE probability based on improvement rate, direct velocity updates, and a simpler DE mutation strategy with fixed scaling factor.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, F=0.5, CR=0.7, de_prob_init=0.9):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_global_best = np.inf\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update (only global best)\n            velocity = w * (self.global_best_pos - self.pop[i])\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[i]) # Simplified DE mutation\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                trial = np.copy(new_pos)\n                crossover_points = np.random.rand(self.dim) < self.CR\n                trial[crossover_points] = mutant[crossover_points]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            # Adjust DE probability based on global best improvement\n            improvement = (self.last_global_best - self.global_best_fitness) / abs(self.last_global_best) if self.last_global_best != 0 else 0\n            if improvement > 0:\n              self.de_prob = self.de_prob_init * (1 - improvement) # Decrease DE prob if there is an improvement\n              self.de_prob = max(0.05, self.de_prob)\n            else:\n              self.de_prob = min(1.0, self.de_prob * 1.02)  # Gradually increase DE probability if stuck\n            \n            self.update_population(func, w)\n            self.last_global_best = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.431 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1daafbd8-b531-49a2-83b4-4d331c92cbab"], "operator": null, "metadata": {"aucs": [0.1284396760964801, 0.6095048068004948, 0.4714628863255055, 0.2070040784613324, 0.5657550478954761, 0.9649027292950926, 0.38296106563674526, 0.273706521334404, 0.25921451154150765, 0.3543617746031815, 0.3498557827604676, 0.9985803980404853, 0.36138840055934307, 0.4225079326796486, 0.6962104167041083, 0.3216733908500855, 0.2993152973635733, 0.29323464891454043, 0.2116372688443019, 0.44959637926208307]}}
{"id": "3b61735f-3dfe-491e-a3d9-6a1a84b71a03", "fitness": 0.5024165210816106, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies Hybrid PSO-DE by adaptively reducing DE probability based on improvement rate and further simplifies the velocity update by removing inertia weight and using a more aggressive update.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.9, CR=0.7, de_prob_init=0.9, impr_rate=0.05):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability and simplified velocity update.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n            impr_rate (float): Improvement rate threshold for DE probability adjustment.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_global_best = np.inf\n        self.impr_rate = impr_rate\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update - only global best, no inertia\n            velocity = self.global_best_pos - self.pop[i]\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adjust DE probability based on global best improvement rate\n            improvement_rate = (self.last_global_best - self.global_best_fitness) / (abs(self.last_global_best) + 1e-9) # Avoid division by zero\n            if improvement_rate > self.impr_rate:\n                self.de_prob = max(0.0, self.de_prob - 0.05)  # Reduce DE if improvement is good\n            else:\n                self.de_prob = min(1.0, self.de_prob + 0.02)   # Increase DE otherwise for more exploration\n\n            self.update_population(func)\n            self.last_global_best = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.502 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["be5a503c-d96b-4798-b5d2-2bd08d7f4bc3"], "operator": null, "metadata": {"aucs": [0.1257051904363221, 0.39900132287289225, 0.289087996439247, 0.9539371030774579, 0.29627371194152496, 0.847704692086112, 0.36885865710787313, 0.4624395938297966, 0.2733834757266307, 0.2506315062019474, 0.9166831169218537, 0.9971884993988658, 0.38420721853540707, 0.26794947134148184, 0.7424730566007722, 0.29790653559051206, 0.8437086940403474, 0.6859483278572716, 0.14534649222455132, 0.4998957594013448]}}
{"id": "27a8be99-afd1-403e-bbb5-430d6f624c10", "fitness": 0.6046739045907319, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies and enhances Hybrid PSO-DE with adaptive DE probability using exponential decay and stagnation detection for parameter tuning.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, F=0.9, CR=0.7, de_prob_init=0.9, stagnation_threshold=50):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n            stagnation_threshold (int): Number of iterations without improvement to trigger DE probability increase.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_global_best = np.inf\n        self.stagnation_counter = 0\n        self.stagnation_threshold = stagnation_threshold\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update (only global best)\n            velocity = w * (self.global_best_pos - self.pop[i])\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[i]) # Simplified DE mutation\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            # Adjust DE probability based on global best improvement and stagnation\n            if self.global_best_fitness < self.last_global_best:\n                self.stagnation_counter = 0\n                self.de_prob = self.de_prob_init * np.exp(-5 * (self.eval_count / self.budget))\n            else:\n                self.stagnation_counter += 1\n                if self.stagnation_counter > self.stagnation_threshold:\n                    self.de_prob = min(1.0, self.de_prob * 1.1)\n                    self.stagnation_counter = 0  # Reset after increasing\n\n            self.de_prob = np.clip(self.de_prob, 0.05, 1.0)  # Keep within bounds\n\n            self.update_population(func, w)\n            self.last_global_best = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.605 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1daafbd8-b531-49a2-83b4-4d331c92cbab"], "operator": null, "metadata": {"aucs": [0.22283322563484753, 0.42616829515190124, 0.8723308628642792, 0.9495268019128618, 0.80276451686764, 0.9197456745777548, 0.33008373763197696, 0.37079449895113903, 0.9191074010693293, 0.20300265484062796, 0.48611125702600033, 0.9960128795606006, 0.3494997914679, 0.3714949673748663, 0.5851279911058376, 0.9212211967869451, 0.4149072797322215, 0.9573768352875598, 0.5084892810691135, 0.4868789429012351]}}
{"id": "9e1c24a8-322f-4dee-8620-8f147b6001f0", "fitness": 0.7229425382876359, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies Hybrid PSO-DE by removing the cognitive component, adjusting DE probability based on global best improvement with a reduced increment, and using a direct velocity update with an added random exploration component.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, F=0.9, CR=0.7, de_prob_init=0.9, explore_rate=0.05):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n            explore_rate (float): Probability of random exploration.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_global_best = np.inf\n        self.explore_rate = explore_rate\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update - only global best\n            velocity = w * (self.global_best_pos - self.pop[i])\n\n            # Exploration: Randomly move some particles\n            if np.random.rand() < self.explore_rate:\n                velocity += np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.1 # scale the random exploration\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            # Adjust DE probability based on global best improvement\n            if self.global_best_fitness < self.last_global_best:\n                self.de_prob = self.de_prob_init # Reset to initial value upon improvement\n            else:\n                self.de_prob = min(1.0, self.de_prob * 1.01)  # Gradually increase DE probability with a smaller stagnation rate\n\n            self.update_population(func, w)\n            self.last_global_best = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.723 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["be5a503c-d96b-4798-b5d2-2bd08d7f4bc3"], "operator": null, "metadata": {"aucs": [0.36633923827259973, 0.8466009692157452, 0.8734822688930673, 0.9358994325780198, 0.9078415363787495, 0.9099920526448373, 0.3436620241894479, 0.8759231281420892, 0.9050823863646331, 0.225293257556061, 0.9542338278954972, 0.9980598475065291, 0.42865945142920314, 0.8884629467374651, 0.9690612780720285, 0.9214482838142574, 0.40951339194486147, 0.9339852492451716, 0.22813743461672342, 0.537172760255732]}}
{"id": "c28839d5-e220-47e3-8bf4-4389f9231e3d", "fitness": 0.0, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies and enhances the Hybrid PSO-DE by dynamically adjusting DE probability and PSO inertia based on improvement and stagnation, while also incorporating a simple local search step.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, F=0.9, CR=0.7, de_prob_init=0.9, local_search_prob=0.1):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability and inertia, and local search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n            local_search_prob (float): Probability of applying local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.local_search_prob = local_search_prob\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_global_best = np.inf\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 50  # Number of iterations without improvement before increasing DE prob.\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def local_search(self, func, x):\n        \"\"\"Performs a simple local search around a given position.\"\"\"\n        step_size = 0.1 * (func.bounds.ub - func.bounds.lb)\n        new_x = x + np.random.uniform(-step_size, step_size, size=self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_x)\n        self.eval_count += 1\n        return new_x, f_new\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO, DE, and local search.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update (only global best)\n            velocity = w * (self.global_best_pos - self.pop[i])\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[i]) # Simplified DE mutation\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n                \n\n            f_new = func(new_pos)\n            self.eval_count += 1\n            \n            #Local Search\n            if np.random.rand() < self.local_search_prob:\n                new_pos, f_new = self.local_search(func, new_pos)\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight - more aggressive reduction\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)**2\n\n\n            # Adjust DE probability based on global best improvement and stagnation\n            improvement = (self.last_global_best - self.global_best_fitness) / abs(self.last_global_best) if self.last_global_best != 0 else 0\n            if improvement > 0:\n                self.de_prob = self.de_prob_init * (1 - improvement) # Decrease DE prob if there is an improvement\n                self.de_prob = max(0.05, self.de_prob)\n                self.stagnation_counter = 0  # Reset stagnation counter\n            else:\n                self.stagnation_counter += 1\n                if self.stagnation_counter > self.stagnation_threshold:\n                    self.de_prob = min(1.0, self.de_prob * 1.1)  # Increase DE probability if stuck\n                    self.stagnation_counter = 0  # Reset stagnation counter\n\n            self.update_population(func, w)\n            if self.global_best_fitness < self.last_global_best:\n              self.last_global_best = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1daafbd8-b531-49a2-83b4-4d331c92cbab"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "c773c3fa-432e-401c-9909-b1e3ebe89934", "fitness": 0.7266449516805358, "name": "AdaptiveHybridPSO_DE", "description": "Simplifies hybrid PSO-DE by dynamically adjusting DE probability based on recent fitness improvement and applying DE/PSO operators element-wise for finer control.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7, adapt_rate=0.1, de_prob=0.5, history_length=5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            adapt_rate (float): Rate for adapting PSO/DE parameters.\n            de_prob (float): Probability of applying DE update.\n            history_length (int): Length of fitness history for adaptation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.adapt_rate = adapt_rate\n        self.de_prob = de_prob\n        self.history_length = history_length\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.w = w_start\n        self.fitness_history = []\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        self.best_fitness = np.array([np.inf] * self.pop_size)\n        self.evaluate_population(func)  # Evaluate initial population\n        self.fitness_history.append(self.global_best_fitness)\n\n    def evaluate_population(self, func):\n        \"\"\"\n        Evaluates the fitness of each particle in the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness[i]:\n                    self.best_fitness[i] = f\n                    self.best_pos[i] = self.pop[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with element-wise application and adaptive DE probability.\n        \"\"\"\n        for i in range(self.pop_size):\n            new_pos = self.pop[i].copy()  # Start with the current position\n            for j in range(self.dim):\n                if np.random.rand() < self.de_prob:\n                    # DE update for dimension j\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = np.random.choice(idxs, 3, replace=False)\n                    mutant = self.pop[a, j] + self.F * (self.pop[b, j] - self.pop[c, j])\n                    mutant = np.clip(mutant, func.bounds.lb[j], func.bounds.ub[j])\n\n                    if np.random.rand() < self.CR:\n                        new_pos[j] = mutant\n                    else:\n                        new_pos[j] = self.pop[i, j]  # Keep original if crossover fails\n                else:\n                    # PSO update for dimension j\n                    r1 = np.random.rand()\n                    r2 = np.random.rand()\n                    velocity = self.w * (self.pop[i, j] - self.best_pos[i, j]) + self.c1 * r1 * (self.best_pos[i, j] - self.pop[i, j]) + self.c2 * r2 * (self.global_best_pos[j] - self.pop[i, j])\n                    new_pos[j] = self.pop[i, j] + velocity\n                    new_pos[j] = np.clip(new_pos[j], func.bounds.lb[j], func.bounds.ub[j])\n\n            # Evaluate the new position\n            f_new = func(new_pos) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.best_fitness[i]:\n                    self.best_fitness[i] = f_new\n                    self.best_pos[i] = self.pop[i].copy()\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n        # Adaptive DE probability control\n        self.fitness_history.append(self.global_best_fitness)\n        if len(self.fitness_history) > self.history_length:\n            improvement = (np.mean(self.fitness_history[-self.history_length:-1]) - self.fitness_history[-1]) / max(abs(np.mean(self.fitness_history[-self.history_length:-1])), 1e-9)\n            self.de_prob = np.clip(self.de_prob + self.adapt_rate * improvement, 0.1, 0.9)\n\n        # Linear inertia weight decay\n        self.w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget)\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n            if self.eval_count >= self.budget:\n                break\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.727 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3787d10c-98b4-49b3-9864-c5514356c6d2"], "operator": null, "metadata": {"aucs": [0.24919778365700473, 0.6356815520031058, 0.7849884133441506, 0.9520998301191276, 0.9244626861962034, 0.9177973252175107, 0.8605065136868554, 0.8568445926969068, 0.9204911158126189, 0.8854270762473151, 0.3661679324105921, 0.9966907189291822, 0.2482940034881973, 0.8218976416721904, 0.7571000458372079, 0.927965362069453, 0.7168811353871989, 0.9444541446600225, 0.2420351167876894, 0.5239160433881791]}}
{"id": "805bbb08-30a4-4ebc-a1ca-49030a27fd1b", "fitness": 0.0, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies Hybrid PSO-DE by removing inertia weight, focusing solely on DE with adaptive scaling factor based on population diversity, and applying a rank-based selection to enhance exploration.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_init=0.8, F_end=0.2, CR=0.9, de_prob=0.95):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE scaling factor and rank-based selection.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            F_init (float): Initial scaling factor for DE.\n            F_end (float): Final scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob (float): Probability of applying DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_init = F_init\n        self.F_end = F_end\n        self.CR = CR\n        self.de_prob = de_prob\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, F):\n        \"\"\"Updates particle positions using DE with rank-based selection.\"\"\"\n        fitness_ranks = np.argsort(self.fitness)\n\n        for i in range(self.pop_size):\n            # DE update\n            if np.random.rand() < self.de_prob:\n                # Rank-based selection of indices\n                idxs = [fitness_ranks[idx] for idx in np.random.choice(self.pop_size, 3, replace=False)] # Select from ranked individuals\n                if i in idxs:\n                    idxs = [idx for idx in fitness_ranks if idx != i] # Ensure i is not in idxs\n                    idxs = np.random.choice(idxs, 3, replace=False)\n\n                a, b, c = idxs # Selected indices\n\n                mutant = self.pop[a] + F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = self.pop[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                f_new = func(trial)\n                self.eval_count += 1\n\n                if f_new < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_new\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_pos = self.pop[i].copy()\n\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive scaling factor\n            F = self.F_init - (self.F_init - self.F_end) * (self.eval_count / self.budget)\n\n            self.update_population(func, F)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 8, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7f2f3c33-19ba-4711-928c-9c6041a00d54"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "eb05cf36-7fb0-4b15-9b50-42541060330d", "fitness": 0.0, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies Hybrid PSO-DE further by removing inertia weight adaptation, dynamically scaling the DE mutation factor, and reducing DE application to only update global best for focused exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_init=0.9, CR=0.7, de_prob=0.9, explore_rate=0.05):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability and scaling factor.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            F_init (float): Initial scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob (float): Probability of applying DE.\n            explore_rate (float): Probability of random exploration.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_init = F_init\n        self.F = F_init\n        self.CR = CR\n        self.de_prob = de_prob\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_global_best = np.inf\n        self.explore_rate = explore_rate\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func):\n        \"\"\"Updates particle positions using a simplified PSO and DE focusing on the global best.\"\"\"\n        for i in range(self.pop_size):\n            # Simple velocity update based on global best\n            velocity = (self.global_best_pos - self.pop[i])\n\n            # Exploration: Randomly move some particles\n            if np.random.rand() < self.explore_rate:\n                velocity += np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.1\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n\n\n            # Apply DE only to update the global best\n            if np.random.rand() < self.de_prob and f_new < self.global_best_fitness: # DE applied only if new solution is better than global best\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                f_trial = func(trial)\n                self.eval_count += 1 # Count evaluation of the trial point\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_pos = trial.copy()\n                    self.F = self.F_init # reset the scaling factor when a better solution is found\n                else:\n                     self.F *= 0.99 # Damp the scaling factor upon stagnation\n\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # No inertia weight adaptation\n\n            # Adaptive scaling factor\n            self.update_population(func)\n            # Adjust scaling factor F\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 8, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9e1c24a8-322f-4dee-8620-8f147b6001f0"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "880a3b97-146b-4a09-869f-f14514130f46", "fitness": 0.0, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies Hybrid PSO-DE with a reduced population size, direct global best influence in DE, and dynamic DE probability based on global best improvement.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=15, w_init=0.7, w_end=0.3, F=0.8, CR=0.8, de_prob_init=0.9):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population (reduced).\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.de_prob = de_prob_init\n        self.de_prob_init = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_improvement = 0 #track last improvement to adapt de_prob\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n                self.last_improvement = self.eval_count\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update - only global best\n            velocity = w * (self.global_best_pos - self.pop[i])\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update - simplified and uses global best\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n                mutant = self.global_best_pos + self.F * (self.pop[a] - self.pop[b]) # Use global best directly\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n                    self.last_improvement = self.eval_count\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (Simplified)\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n            \n            #Adapt DE probability\n            if (self.eval_count - self.last_improvement) > self.budget/10: # Reduce DE prob if no improvement\n                self.de_prob = max(0.0, self.de_prob - 0.05) \n            else:\n                 self.de_prob = min(self.de_prob_init, self.de_prob + 0.01) # increase slowly\n            \n            self.update_population(func, w)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 8, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7f2f3c33-19ba-4711-928c-9c6041a00d54"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "6ee2fea5-55af-496e-bb7b-693dba1cd34b", "fitness": 0.0, "name": "HybridPSO_DE_SimpleAdaptiveLocal", "description": "Enhances exploration in Hybrid PSO-DE by dynamically adjusting the DE probability based on stagnation detection and incorporating a simplified local search.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptiveLocal:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.7, w_end=0.3, F=0.8, CR=0.8, de_prob_init=0.95, stagnation_threshold=50):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability and local search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n            stagnation_threshold (int): Number of iterations without improvement before increasing DE probability.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.de_prob = de_prob_init\n        self.stagnation_threshold = stagnation_threshold\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.stagnation_counter = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n                self.stagnation_counter = 0\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a simple local search around a given position.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.eval_count += 1\n\n        for _ in range(5):  # Limited local evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.eval_count += 1\n\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n\n        return best_x, best_f\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update - only global best\n            velocity = w * (self.global_best_pos - self.pop[i])\n\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n            \n            # Local search\n            new_pos, f_new = self.local_search(func, new_pos)\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n                    self.stagnation_counter = 0 # Reset stagnation counter\n            else:\n                self.stagnation_counter += 1\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (Simplified)\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            # Adjust DE probability if stagnating\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.de_prob = min(1.0, self.de_prob + 0.1)  # Increase DE prob\n                self.stagnation_counter = 0  # Reset counter\n            else:\n                self.de_prob = max(0.1, self.de_prob - 0.01) # Decrease DE prob\n            self.update_population(func, w)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 8, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptiveLocal scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7f2f3c33-19ba-4711-928c-9c6041a00d54"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "6e63e550-289f-48ac-bab4-b235bd1703d1", "fitness": 0.3250271107585247, "name": "SimplifiedAdaptiveHybridPSO_DE", "description": "Simplifies Adaptive Hybrid PSO-DE by removing inertia weight and the DE crossover, focusing on global best-guided mutation and simple PSO velocity updates for faster convergence.", "code": "import numpy as np\n\nclass SimplifiedAdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, de_prob=0.5):\n        \"\"\"\n        Initializes the Simplified Adaptive Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            F (float): Scaling factor for DE.\n            de_prob (float): Probability of applying DE update.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.de_prob = de_prob\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.evaluate_population(func)\n\n    def evaluate_population(self, func):\n        \"\"\"\n        Evaluates the fitness of each particle in the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using simplified PSO and DE.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            if np.random.rand() < self.de_prob:\n                # Simplified DE: Directly use global best in mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n                mutant = self.global_best_pos + self.F * (self.pop[a] - self.pop[b])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                new_pos = mutant  # Directly use the mutant\n\n            else:\n                # PSO update: simplified velocity update\n                velocity = np.random.rand(self.dim) * (self.global_best_pos - self.pop[i])\n                new_pos = self.pop[i] + velocity\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate the new position\n            f_new = func(new_pos) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Simplified Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n            if self.eval_count >= self.budget:\n                break\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 8, "feedback": "The algorithm SimplifiedAdaptiveHybridPSO_DE scored 0.325 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["89573604-fcd4-481d-8df0-418a80e859af"], "operator": null, "metadata": {"aucs": [0.17871376749304402, 0.22329760859295777, 0.4306952292236931, 0.17146767884687564, 0.23091028583331374, 0.4400808357931728, 0.23061619090081908, 0.2569490553216712, 0.24928757320641826, 0.18773297400004796, 0.37871575556729853, 0.9994197269975472, 0.2592766780564567, 0.17647540322728472, 0.29879514042233823, 0.3997089647960719, 0.19616136587814959, 0.5040253258633618, 0.2142165230085954, 0.47399613214137704]}}
{"id": "d865e325-42ef-4051-b72b-a15cb9acb71e", "fitness": 0.23001722043512066, "name": "SimplifiedAdaptiveHybrid", "description": "Simplifies Adaptive Hybrid PSO-DE by removing PSO velocity and directly updating position using a weighted average of current position, global best, and DE mutation.", "code": "import numpy as np\n\nclass SimplifiedAdaptiveHybrid:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, F=0.5, CR=0.7, de_prob=0.5):\n        \"\"\"\n        Initializes the Simplified Adaptive Hybrid optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight (for global best influence).\n            w_end (float): Final inertia weight.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob (float): Probability of applying DE update.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.de_prob = de_prob\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.w = w_start\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.evaluate_population(func)\n\n    def evaluate_population(self, func):\n        \"\"\"\n        Evaluates the fitness of each particle in the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using a simplified hybrid approach.\n        \"\"\"\n        for i in range(self.pop_size):\n            new_pos = self.pop[i].copy()  # Start with the current position\n\n            if np.random.rand() < self.de_prob:\n                # DE Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n                mutant = self.global_best_pos + self.F * (self.pop[a] - self.pop[b])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        new_pos[j] = mutant[j] # Crossover with mutant\n            \n            # Weighted average update: Blend current position, global best\n            new_pos = self.w * self.global_best_pos + (1 - self.w) * new_pos\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate the new position\n            f_new = func(new_pos) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n        # Adaptive Inertia Weight (simple linear decay)\n        self.w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget)\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Simplified Adaptive Hybrid algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n            if self.eval_count >= self.budget:\n                break\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 8, "feedback": "The algorithm SimplifiedAdaptiveHybrid scored 0.230 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["89573604-fcd4-481d-8df0-418a80e859af"], "operator": null, "metadata": {"aucs": [0.10878527917114111, 0.20049024589923092, 0.2611382890894197, 0.14261217117240121, 0.15531751052513298, 0.18201384764543194, 0.1823795930451958, 0.14936430900840392, 0.23373253663767646, 0.18402616604522026, 0.17139680151449788, 0.9997423845612454, 0.24930555667808807, 0.2049092789248197, 0.1337615777626472, 0.22041142737002362, 0.2630043290302043, 0.22118595660862528, 0.13724385322497124, 0.19952329478803565]}}
{"id": "bc2f6093-f40e-47a9-9d1b-6623d217514c", "fitness": 0.6272975439115529, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies Hybrid PSO-DE with a fixed high DE probability and combines velocity and mutation for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.5, F=0.7, CR=0.7, de_prob=0.9):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with fixed DE probability and combined update.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w (float): Inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob (float): Probability of applying DE.  High value for aggressive exploration.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.F = F\n        self.CR = CR\n        self.de_prob = de_prob\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func):\n        \"\"\"Updates particle positions using a combined PSO and DE update.\"\"\"\n        for i in range(self.pop_size):\n            # PSO velocity update\n            velocity = self.w * (self.global_best_pos - self.pop[i])\n            new_pos = self.pop[i] + velocity\n\n            # DE mutation\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                \n                # Crossover - combine mutant with PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        new_pos[j] = mutant[j] # overwrite with mutant\n            \n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_population(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 8, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.627 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7f2f3c33-19ba-4711-928c-9c6041a00d54"], "operator": null, "metadata": {"aucs": [0.20837196034088312, 0.6631191561803695, 0.5647972596565751, 0.9422756005391867, 0.5254374177167358, 0.5895788637544832, 0.9127317742748187, 0.5674141616226104, 0.879543476022624, 0.2477428297399038, 0.6462871446947962, 0.999428144121809, 0.28510603651369215, 0.5904385389417532, 0.7213121020673885, 0.947718636725113, 0.5756870680906481, 0.9541000851269038, 0.2195950356707278, 0.5052655864300368]}}
{"id": "fced7e0f-98cb-41e3-aebd-359e8c6ff48c", "fitness": 0.6602386813125467, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies Hybrid PSO-DE by focusing on enhanced exploration through a simplified DE update and a higher DE probability, removing the PSO velocity update and simplifying parameter adaptation.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.8, CR=0.8, de_prob=0.9):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with adaptive DE probability.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob (float): Probability of applying DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.de_prob = de_prob\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func):\n        \"\"\"Updates particle positions using DE.\"\"\"\n        for i in range(self.pop_size):\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = self.pop[i].copy() # Copy current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_new = func(trial)\n                self.eval_count += 1\n\n                if f_new < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_new\n                    if f_new < self.global_best_fitness:\n                        self.global_best_fitness = f_new\n                        self.global_best_pos = self.pop[i].copy()\n            else:\n                f_current = func(self.pop[i])\n                self.eval_count += 1\n                if f_current < self.fitness[i]:\n                    self.fitness[i] = f_current\n                if f_current < self.global_best_fitness:\n                    self.global_best_fitness = f_current\n                    self.global_best_pos = self.pop[i].copy()\n\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_population(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 8, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.660 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7f2f3c33-19ba-4711-928c-9c6041a00d54"], "operator": null, "metadata": {"aucs": [0.23331063444527977, 0.5620151401589467, 0.7014294532729959, 0.8820252058470442, 0.7477675357641267, 0.8171158574916525, 0.6568144681279661, 0.6720679522002531, 0.8049821607748757, 0.6552957086078395, 0.2863764557044147, 0.995621154858342, 0.5344696014105419, 0.715087450369462, 0.9252990157076428, 0.8266248076395424, 0.5896397886353502, 0.87320575604662, 0.20823967971499246, 0.5173857994730464]}}
{"id": "2737eee1-d838-4f63-82e3-a896d1688262", "fitness": 0.5230566065323261, "name": "AdaptiveHybridPSO_DE", "description": "Simplified Adaptive Hybrid PSO-DE using a global best-guided DE mutation with reduced evaluations, removing the PSO velocity term and using a more aggressive inertia weight update based on global best stagnation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, F=0.5, CR=0.7, adapt_rate=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with a simplified DE mutation and more aggressive inertia adaptation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for DE part.\n            w_end (float): Final inertia weight for DE part.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            adapt_rate (float): Rate for adapting PSO/DE parameters.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.adapt_rate = adapt_rate\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.w = w_start\n        self.gb_history = []\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.evaluate_population(func)\n        self.gb_history.append(self.global_best_fitness)\n\n    def evaluate_population(self, func):\n        \"\"\"\n        Evaluates the fitness of each particle in the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using a simplified DE mutation guided by the global best and aggressive inertia adaptation.\n        \"\"\"\n        for i in range(self.pop_size):\n            # Simplified DE: Directly use global best in mutation\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b = np.random.choice(idxs, 2, replace=False)\n            mutant = self.global_best_pos + self.F * (self.pop[a] - self.pop[b])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    trial[j] = mutant[j]\n            new_pos = trial\n\n            # Evaluate the new position\n            f_new = func(new_pos) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n                    self.gb_history.append(self.global_best_fitness)  # Update history when global best improves\n                    self.w = self.w_start  # Reset inertia when global best improves\n            \n        # Adaptive Inertia Weight (aggressive decay if no recent improvement)\n        if len(self.gb_history) > 1 and self.gb_history[-1] == self.gb_history[-2]:\n                self.w *= 0.9  # Decay more aggressively if global best stagnates\n        else:\n            self.w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget) # Linear Decay\n        self.w = max(self.w, self.w_end) # Ensure w is not below w_end\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n            if self.eval_count >= self.budget:\n                break\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.523 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["89573604-fcd4-481d-8df0-418a80e859af"], "operator": null, "metadata": {"aucs": [0.15668213817295273, 0.1948225202802467, 0.9438814711781792, 0.17264107168462073, 0.2790655756393028, 0.9609564775088137, 0.32250218080359583, 0.3246458295217628, 0.3103162220004456, 0.19004824044175095, 0.9732123601073286, 0.9963013731660524, 0.316911896214361, 0.29778689406561387, 0.7378929495461737, 0.9531285816532983, 0.41507774625167815, 0.9681077580916079, 0.46962933290918174, 0.47752151140955656]}}
{"id": "f3507566-846a-4927-b92d-52cb02b2f86e", "fitness": 0.6433757509677781, "name": "HybridPSO_DE_SimpleAdaptive", "description": "Simplifies Hybrid PSO-DE by using a single DE variant with a fixed probability, no PSO velocity clipping, and a simplified inertia weight update.", "code": "import numpy as np\n\nclass HybridPSO_DE_SimpleAdaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.7, w_end=0.3, F=0.8, CR=0.8, de_prob=0.9):\n        \"\"\"\n        Initializes the simplified Hybrid PSO-DE optimizer with fixed DE probability and simplified parameter updates.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob (float): Probability of applying DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.de_prob = de_prob\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO and DE.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update - only global best\n            velocity = w * (self.global_best_pos - self.pop[i])\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                new_pos = trial\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (Simplified)\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n            self.update_population(func, w)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 8, "feedback": "The algorithm HybridPSO_DE_SimpleAdaptive scored 0.643 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7f2f3c33-19ba-4711-928c-9c6041a00d54"], "operator": null, "metadata": {"aucs": [0.5633183126393853, 0.35771455318570233, 0.8622031257010577, 0.9585165261645469, 0.46039739977077787, 0.9367329872228043, 0.3739609871294213, 0.576845755763714, 0.9389158684401988, 0.20327231417938296, 0.9430979683815475, 0.9995787625094461, 0.3949007939829565, 0.41724369338404454, 0.9089060045415421, 0.8797023673821166, 0.41615582313728816, 0.9538177619522892, 0.2326880499422902, 0.48954596394505023]}}
{"id": "c70407af-2607-4352-b182-a239c22e7231", "fitness": 0.49365318615575227, "name": "AdaptiveHybridPSO_DE", "description": "Combines PSO and DE with simplified mutation, focusing on velocity clamping and dynamic parameter adjustment based on stagnation detection for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, F=0.5, CR=0.7, stagnation_threshold=50):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with velocity clamping and dynamic parameter adjustment.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_start (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            stagnation_threshold (int): Number of iterations without improvement to trigger parameter adjustment.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.stagnation_threshold = stagnation_threshold\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.w = w_start\n        self.stagnation_counter = 0\n        self.velocity_limit = 1.0  # Clamping value for velocity\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initializes the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.evaluate_population(func)\n\n    def evaluate_population(self, func):\n        \"\"\"\n        Evaluates the fitness of each particle in the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n                    self.stagnation_counter = 0  # Reset stagnation counter\n            else:\n                break\n\n    def update_positions(self, func):\n        \"\"\"\n        Updates the positions of particles using PSO and DE with simplified DE mutation and adaptive parameters.\n        \"\"\"\n        for i in range(self.pop_size):\n            # Apply DE or PSO\n            if np.random.rand() < 0.5:  # Fixed DE probability\n                # Simplified DE: Directly use global best in mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n                mutant = self.global_best_pos + self.F * (self.pop[a] - self.pop[b])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                new_pos = trial\n            else:\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                velocity = self.w * (self.pop[i] - self.global_best_pos) + r1 * (self.global_best_pos - self.pop[i])\n                # Velocity Clamping\n                velocity = np.clip(velocity, -self.velocity_limit, self.velocity_limit)\n                new_pos = self.pop[i] + velocity\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate the new position\n            f_new = func(new_pos) if self.eval_count < self.budget else np.inf\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n                    self.stagnation_counter = 0 # Reset stagnation counter\n            else:\n                 self.stagnation_counter += 1\n\n        # Adaptive Inertia Weight (simple linear decay)\n        self.w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget)\n\n        # Adjust parameters if stagnation is detected\n        if self.stagnation_counter > self.stagnation_threshold:\n            self.F = min(1.0, self.F * 1.2) # Increase F to enhance exploration\n            self.CR = max(0.1, self.CR * 0.8) # Decrease CR to focus on mutation\n            self.stagnation_counter = 0 # Reset\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value found and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n            if self.eval_count >= self.budget:\n                break\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.494 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["89573604-fcd4-481d-8df0-418a80e859af"], "operator": null, "metadata": {"aucs": [0.15611383495135012, 0.2758857452599818, 0.466237402771281, 0.42147493785158063, 0.43386582876721613, 0.6638478970995267, 0.4212594711055817, 0.4783872334792021, 0.5708958238525811, 0.2070451191750925, 0.5575011010225637, 0.9983449259409941, 0.29566643473580667, 0.4580600368235974, 0.7789119479783412, 0.8389663834528429, 0.34731579080744057, 0.7909604575987941, 0.20969614338396692, 0.502627207057303]}}
{"id": "4aa1b575-7bab-41ba-9dca-109410ae9974", "fitness": 0.7295324317480901, "name": "AdaptiveHybridPSO_DE_LocalSearch", "description": "Adaptively balances PSO and DE by adjusting DE probability based on fitness improvement and stagnation, using simplified velocity update and incorporating local search with polynomial mutation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, F=0.7, CR=0.7, de_prob_init=0.7, local_search_rate=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with local search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            de_prob_init (float): Initial probability of applying DE.\n            local_search_rate (float): Probability of applying local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.F = F\n        self.CR = CR\n        self.de_prob_init = de_prob_init\n        self.de_prob = de_prob_init\n        self.pop = None\n        self.fitness = None\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.last_global_best = np.inf\n        self.local_search_rate = local_search_rate\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_pos = self.pop[i].copy()\n\n    def polynomial_mutation(self, x, bounds, eta=20):\n        \"\"\"Polynomial mutation operator.\"\"\"\n        lb, ub = bounds.lb, bounds.ub\n        delta_1 = (x - lb) / (ub - lb)\n        delta_2 = (ub - x) / (ub - lb)\n        rand = np.random.rand(self.dim)\n        mut_pow = 1.0 / (eta + 1.0)\n        mask = rand <= 0.5\n        delta_q = np.zeros(self.dim)\n        delta_q[mask] = (2.0 * rand[mask] + (1.0 - 2.0 * rand[mask]) * (delta_1[mask] ** (eta + 1.0))) ** mut_pow - 1.0\n        delta_q[~mask] = 1.0 - (2.0 * (1.0 - rand[~mask]) + 2.0 * (rand[~mask] - 0.5) * (delta_2[~mask] ** (eta + 1.0))) ** mut_pow\n        y = x + delta_q * (ub - lb)\n        y = np.clip(y, lb, ub)\n        return y\n\n    def update_population(self, func, w):\n        \"\"\"Updates particle positions using PSO, DE and Local Search.\"\"\"\n        for i in range(self.pop_size):\n            # PSO update: Simplified velocity update - only global best\n            velocity = w * (self.global_best_pos - self.pop[i])\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            # DE update\n            if np.random.rand() < self.de_prob:\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial = new_pos.copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                new_pos = trial # Use the trial position\n\n            # Local search\n            if np.random.rand() < self.local_search_rate:\n                new_pos = self.polynomial_mutation(new_pos, func.bounds)\n\n\n            f_new = func(new_pos)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_pos\n                self.fitness[i] = f_new\n                if f_new < self.global_best_fitness:\n                    self.global_best_fitness = f_new\n                    self.global_best_pos = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using the Hybrid PSO-DE algorithm.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            # Adjust DE probability based on global best improvement\n            if self.global_best_fitness < self.last_global_best:\n                self.de_prob = self.de_prob_init # Reset to initial value upon improvement\n            else:\n                self.de_prob = min(1.0, self.de_prob + 0.05)  # Gradually increase DE probability with a smaller stagnation rate\n\n            self.update_population(func, w)\n            self.last_global_best = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveHybridPSO_DE_LocalSearch scored 0.730 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9e1c24a8-322f-4dee-8620-8f147b6001f0"], "operator": null, "metadata": {"aucs": [0.5223995288878249, 0.7558845383379698, 0.9026169398761875, 0.9559830404852927, 0.3607639380065423, 0.9374326640045021, 0.9000050252145637, 0.9144365109047574, 0.935982783371845, 0.3454250853915173, 0.9206238962163193, 0.997529421598949, 0.3333795180363034, 0.3916497382375371, 0.970733843558186, 0.9247368911110797, 0.8854630546624521, 0.9514860737991577, 0.1843522335438419, 0.4997639097169708]}}
