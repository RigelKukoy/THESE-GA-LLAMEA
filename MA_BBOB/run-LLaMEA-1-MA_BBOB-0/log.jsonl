{"id": "6260971a-9c8f-45c9-8110-3a1a347e859e", "fitness": 0.0, "name": "AdaptiveVelocityPSO", "description": "Population-based algorithm with velocity updates and local search refinement, inspired by Particle Swarm Optimization and Differential Evolution, incorporating a restart mechanism when stagnation is detected.", "code": "import numpy as np\n\nclass AdaptiveVelocityPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.49, c2=1.49, w_max=0.9, w_min=0.4, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.w_max = w_max\n        self.w_min = w_min\n        self.local_search_iterations = local_search_iterations\n        self.stagnation_threshold = 1000 # Number of iterations without improvement before restart\n        self.restart_percentage = 0.5 # Percentage of population to restart\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1 * (func.bounds.ub - func.bounds.lb)  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.pbest_positions = self.population.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_index = np.argmin(self.fitness)\n        self.gbest_position = self.population[self.gbest_index].copy()\n        self.gbest_fitness = self.fitness[self.gbest_index]\n\n        eval_count = self.pop_size\n        stagnation_counter = 0\n\n        while eval_count < self.budget:\n            # Adaptive Inertia Weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n            for i in range(self.pop_size):\n                # Update Velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = w * self.velocities[i] + \\\n                                     self.c1 * r1 * (self.pbest_positions[i] - self.population[i]) + \\\n                                     self.c2 * r2 * (self.gbest_position - self.population[i])\n\n                # Limit velocity to avoid explosion\n                v_max = 0.1 * (func.bounds.ub - func.bounds.lb)\n                self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n\n                # Update Position\n                self.population[i] = self.population[i] + self.velocities[i]\n\n                # Boundary Handling (Clipping)\n                self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n           \n\n                # Evaluate Fitness\n                fitness = func(self.population[i])\n                eval_count += 1\n\n                # Update Personal Best\n                if fitness < self.pbest_fitness[i]:\n                    self.pbest_fitness[i] = fitness\n                    self.pbest_positions[i] = self.population[i].copy()\n\n                    #Update Global Best\n                    if fitness < self.gbest_fitness:\n                        self.gbest_fitness = fitness\n                        self.gbest_position = self.population[i].copy()\n                        stagnation_counter = 0  # Reset stagnation counter upon improvement\n\n                else:\n                    stagnation_counter += 1 # Increment stagnation counter\n                \n                #Local Search\n                if eval_count < self.budget:\n                     x_current = self.population[i].copy()\n                     f_current = fitness\n\n                     for _ in range(self.local_search_iterations):\n                         perturbation = np.random.normal(0, 0.01 * (func.bounds.ub - func.bounds.lb), size=self.dim)\n                         x_new = x_current + perturbation\n                         x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                         f_new = func(x_new)\n                         eval_count+=1\n\n                         if f_new < f_current:\n                            x_current = x_new.copy()\n                            f_current = f_new\n\n                         if eval_count >= self.budget:\n                            break\n                     \n                     self.population[i] = x_current\n                     self.fitness[i] = f_current\n                \n                     if f_current < self.pbest_fitness[i]:\n                         self.pbest_fitness[i] = f_current\n                         self.pbest_positions[i] = self.population[i].copy()\n\n                         if f_current < self.gbest_fitness:\n                            self.gbest_fitness = f_current\n                            self.gbest_position = self.population[i].copy()\n                            stagnation_counter = 0\n\n            #Stagnation Restart Mechanism\n            if stagnation_counter > self.stagnation_threshold:\n                num_to_restart = int(self.restart_percentage * self.pop_size)\n                indices_to_restart = np.random.choice(self.pop_size, size=num_to_restart, replace=False)\n\n                for idx in indices_to_restart:\n                    self.population[idx] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    self.velocities[idx] = np.random.uniform(-1, 1, size=self.dim) * 0.1 * (func.bounds.ub - func.bounds.lb) #Reinitialize velocity\n                    self.fitness[idx] = func(self.population[idx])\n                    eval_count += 1\n\n                    self.pbest_positions[idx] = self.population[idx].copy()\n                    self.pbest_fitness[idx] = self.fitness[idx]\n\n                    if self.fitness[idx] < self.gbest_fitness:\n                        self.gbest_fitness = self.fitness[idx]\n                        self.gbest_position = self.population[idx].copy()\n\n                stagnation_counter = 0 # Reset stagnation counter after restart\n            \n            if self.gbest_fitness < self.f_opt:\n                self.f_opt = self.gbest_fitness\n                self.x_opt = self.gbest_position.copy()\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveVelocityPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}}
{"id": "e5fb7f2a-b9cf-40d4-a947-dcb8d3ec58aa", "fitness": 0.13149447497331088, "name": "CMAES", "description": "Covariance matrix adaptation evolution strategy with adaptive step size control and archive for population diversity.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov=None, mu_factor=0.25, sigma0=0.5, memory_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov = c_cov if c_cov is not None else (1 / self.mu) * (2 / ((self.dim + np.sqrt(2))**2))\n        self.c_cov_mu = 0.25 + self.c_cov\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n\n    def __call__(self, func):\n        evals = 0\n        while evals < self.budget:\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ C_sqrt.T\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ np.linalg.inv(C_sqrt).T\n            self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC = (self.c_cov_mu / self.mu) * (self.pc[:, None] @ self.pc[None, :])\n            for i in range(self.mu):\n                dC += (self.c_cov / self.mu) * ((x[i] - m_old)[:, None] @ (x[i] - m_old)[None, :]) / self.sigma**2\n                \n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + dC\n            \n            # Ensure positive definiteness\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Archive for diversity (optional)\n            for xi in x:\n                self.archive.append(xi)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[-self.archive_size:]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CMAES scored 0.131 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.04232274963321725, 0.09200274495074845, 0.2609403333066872, 0.1030883953869679, 0.1056073835443978, 0.14087554070224573, 0.12334458605677823, 0.1272040291436315, 0.139253012256078, 0.11798313927778747, 0.15224076561200295, 0.15820132841346035, 0.148280573510027, 0.08004522875912279, 0.11190291396213548, 0.21648241513049848, 0.11453233528387385, 0.14029142170700037, 0.11709442513232482, 0.13819617769723225]}}
{"id": "9960101e-622a-41bf-82ee-e45d70838973", "fitness": 0.5408404447894856, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with archive and stochastic ranking.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, F=0.7, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutated_population[i] = x1 + self.F * (x2 - x3)\n            \n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n        \n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n            \n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                \n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    idx_to_replace = np.random.randint(0, self.archive_size)\n                    self.archive[idx_to_replace] = self.population[i].copy()\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n        return new_population, new_fitness\n        \n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.541 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.18515179140281202, 0.4012614274329631, 0.4588558271518556, 0.77017463083211, 0.5163473356091806, 0.6279706799552276, 0.3972005950905195, 0.43451269892663613, 0.5136471734281415, 0.4465681902560008, 0.7438795739263694, 0.9984346187086611, 0.46915936706089756, 0.5077274169504062, 0.8805205138385017, 0.6099312027338921, 0.4090966438117001, 0.7363789921209538, 0.21132019570417793, 0.4986700208487017]}}
{"id": "5908a426-e448-4d00-9f48-12f180046988", "fitness": 0.6261833592700048, "name": "CMAES_with_Archive", "description": "Covariance matrix adaptation evolution strategy with adaptive population size and archive for diversity maintenance.", "code": "import numpy as np\n\nclass CMAES_with_Archive:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=None, c_cov=None, archive_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = cs\n        self.damps = damp if damp is not None else 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.ccov1 = c_cov[0] if c_cov is not None else 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.ccovmu = c_cov[1] if c_cov is not None else 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2.3)**2 + self.mueff)\n        self.ccovmu = min(1-self.ccov1, self.ccovmu)\n\n        self.mean = None\n        self.sigma = 0.5\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.archive = []\n        self.archive_size = archive_size\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize(self):\n        self.mean = np.random.uniform(-5, 5, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n    def sample(self):\n        z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n        C_sqrt = np.linalg.cholesky(self.C)\n        x = self.mean[:, np.newaxis] + self.sigma * C_sqrt @ z\n        return x.T\n\n    def update(self, x, f):\n        idx = np.argsort(f)\n        x = x[idx]\n        f = f[idx]\n\n        xmean = np.sum(x[:self.mu] * self.weights[:, np.newaxis], axis=0)\n\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (xmean - self.mean) / self.sigma\n        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.eval_count / self.popsize))) < (1.4 + 2 / (self.dim + 1))\n        self.pc = (1 - 1) * self.pc + hsig * np.sqrt(1 * (2 - 1) * self.mueff) * (xmean - self.mean) / self.sigma\n\n        y = (x[:self.mu] - self.mean) / self.sigma\n        self.C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * (1 - hsig**2)) * self.C \\\n                 + self.ccov1 * np.outer(self.pc, self.pc) \\\n                 + self.ccovmu * np.sum(self.weights[:, np.newaxis, np.newaxis] * y[:, :, np.newaxis] * y[:, np.newaxis, :], axis=0)\n\n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n        self.mean = xmean\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        self.C = self.C + 1e-8 * np.eye(self.dim)\n        \n        for i in range(len(x)):\n            if f[i] < self.f_opt:\n                self.f_opt = f[i]\n                self.x_opt = x[i]\n\n    def archive_management(self, x, f):\n        for i in range(len(x)):\n            if len(self.archive) < self.archive_size:\n                self.archive.append((x[i], f[i]))\n            else:\n                # Replace worst element in archive if current element is better\n                worst_idx = np.argmax([item[1] for item in self.archive])\n                if f[i] < self.archive[worst_idx][1]:\n                    self.archive[worst_idx] = (x[i], f[i])\n\n    def __call__(self, func):\n        self.initialize()\n\n        while self.eval_count < self.budget:\n            x = self.sample()\n            \n            # Ensure bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.eval_count += len(x)\n\n            self.update(x, f)\n            self.archive_management(x, f)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CMAES_with_Archive scored 0.626 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.20705098038763925, 0.886954192747395, 0.5650152068702794, 0.9702481770809139, 0.9548863629204157, 0.9603153980072728, 0.30339303077465296, 0.6765677544072053, 0.8673222663306481, 0.17169826582294423, 0.815878189756413, 0.9869087789846127, 0.33433657039369746, 0.42110220881549376, 0.9622475693022657, 0.33489810572361445, 0.4605326913244304, 0.9724324642243866, 0.16434963050824314, 0.5075293410175721]}}
{"id": "03df9017-f49e-403b-8b48-7c94377b4bf5", "fitness": -Infinity, "name": "CMAES", "description": "CMA-ES with archive, orthogonal sampling, dynamic population size, and active covariance matrix update to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov=None, mu_factor=0.25, sigma0=0.5, memory_size=100, active_update=True):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov = c_cov if c_cov is not None else (1 / self.mu) * (2 / ((self.dim + np.sqrt(2))**2))\n        self.c_cov_mu = 0.25 + self.c_cov\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.active_update = active_update # Add active update flag\n        self.tolXup = 1e9 * np.finfo(float).eps * np.ones(self.dim)\n\n    def orthogonal_sampling(self, popsize):\n        z = np.random.normal(0, 1, size=(popsize // 2, self.dim))\n        z = np.vstack((z, -z))  # Orthogonal sampling\n        return z\n\n    def __call__(self, func):\n        evals = 0\n        while evals < self.budget:\n            # Dynamic population size\n            if evals > self.budget * 0.5:\n                self.popsize = max(4 + int(2 * np.log(self.dim)), 4)  # Reduce popsize later\n\n            # Sample population\n            z = self.orthogonal_sampling(self.popsize) # Orthogonal sampling\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ C_sqrt.T\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ np.linalg.inv(C_sqrt).T\n            self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC = (self.c_cov_mu / self.mu) * (self.pc[:, None] @ self.pc[None, :])\n            \n            if self.active_update: # Active CMA update\n                neg_weights = np.minimum(0, self.weights)\n                w_sum = np.sum(self.weights**2)\n                w_neg_sum = np.sum(neg_weights**2)\n                alpha_mu = 2\n                min_alpha = alpha_mu + self.dim / w_sum\n                \n                for i in range(self.mu):\n                    dC += (self.c_cov / self.mu) * ((x[i] - m_old)[:, None] @ (x[i] - m_old)[None, :]) / self.sigma**2\n                \n                alpha_neg = min(alpha_mu, (self.dim**2) / (w_neg_sum * (alpha_mu - 1)**2 + 2 * self.dim * w_neg_sum))\n                for i in range(self.popsize):\n                    if i >= self.mu:\n                        dC += (alpha_neg * self.c_cov / self.mu) * ((x[i] - m_old)[:, None] @ (x[i] - m_old)[None, :]) / self.sigma**2\n            else: \n                for i in range(self.mu):\n                    dC += (self.c_cov / self.mu) * ((x[i] - m_old)[:, None] @ (x[i] - m_old)[None, :]) / self.sigma**2\n                \n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + dC\n            \n            # Ensure positive definiteness\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Archive for diversity (optional)\n            for xi in x:\n                self.archive.append(xi)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[-self.archive_size:]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 88, in __call__\nIndexError: index 4 is out of bounds for axis 0 with size 4\n.", "error": "", "parent_ids": ["e5fb7f2a-b9cf-40d4-a947-dcb8d3ec58aa"], "operator": null, "metadata": {}}
{"id": "5633150e-0115-49b2-afff-bc8319f550fc", "fitness": -Infinity, "name": "CMAES_with_Archive", "description": "Implement a dynamic population size adjustment strategy based on the success rate of updates and add a mechanism to restart the algorithm if stagnation is detected in the archive.", "code": "import numpy as np\n\nclass CMAES_with_Archive:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=None, c_cov=None, archive_size=100, stagnation_threshold=1000):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = cs\n        self.damps = damp if damp is not None else 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.ccov1 = c_cov[0] if c_cov is not None else 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.ccovmu = c_cov[1] if c_cov is not None else 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2.3)**2 + self.mueff)\n        self.ccovmu = min(1-self.ccov1, self.ccovmu)\n\n        self.mean = None\n        self.sigma = 0.5\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.archive = []\n        self.archive_size = archive_size\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_rate = 0.0\n        self.success_history = []\n        self.stagnation_threshold = stagnation_threshold\n        self.last_improvement = 0\n\n    def initialize(self):\n        self.mean = np.random.uniform(-5, 5, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n    def sample(self):\n        z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n        C_sqrt = np.linalg.cholesky(self.C)\n        x = self.mean[:, np.newaxis] + self.sigma * C_sqrt @ z\n        return x.T\n\n    def update(self, x, f):\n        idx = np.argsort(f)\n        x = x[idx]\n        f = f[idx]\n\n        xmean = np.sum(x[:self.mu] * self.weights[:, np.newaxis], axis=0)\n\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (xmean - self.mean) / self.sigma\n        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.eval_count / self.popsize))) < (1.4 + 2 / (self.dim + 1))\n        self.pc = (1 - 1) * self.pc + hsig * np.sqrt(1 * (2 - 1) * self.mueff) * (xmean - self.mean) / self.sigma\n\n        y = (x[:self.mu] - self.mean) / self.sigma\n        self.C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * (1 - hsig**2)) * self.C \\\n                 + self.ccov1 * np.outer(self.pc, self.pc) \\\n                 + self.ccovmu * np.sum(self.weights[:, np.newaxis, np.newaxis] * y[:, :, np.newaxis] * y[:, np.newaxis, :], axis=0)\n\n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n        self.mean = xmean\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        self.C = self.C + 1e-8 * np.eye(self.dim)\n        \n        # Update success rate\n        num_improvements = np.sum(f < np.array([item[1] for item in self.archive]).min() if self.archive else np.inf)\n        self.success_history.append(num_improvements / len(x))\n        if len(self.success_history) > 10:\n            self.success_history.pop(0)\n        self.success_rate = np.mean(self.success_history)\n\n        # Adjust population size\n        if self.success_rate > 0.3:\n            self.popsize = min(self.popsize + 1, 2 * self.dim)\n            self.mu = self.popsize // 2\n        elif self.success_rate < 0.1 and self.popsize > 4 + int(3 * np.log(self.dim)):\n            self.popsize = max(self.popsize - 1, 4 + int(3 * np.log(self.dim)))\n            self.mu = self.popsize // 2\n\n        for i in range(len(x)):\n            if f[i] < self.f_opt:\n                self.f_opt = f[i]\n                self.x_opt = x[i]\n                self.last_improvement = self.eval_count\n\n    def archive_management(self, x, f):\n        for i in range(len(x)):\n            if len(self.archive) < self.archive_size:\n                self.archive.append((x[i], f[i]))\n            else:\n                # Replace worst element in archive if current element is better\n                worst_idx = np.argmax([item[1] for item in self.archive])\n                if f[i] < self.archive[worst_idx][1]:\n                    self.archive[worst_idx] = (x[i], f[i])\n\n    def check_stagnation(self):\n        if self.eval_count - self.last_improvement > self.stagnation_threshold:\n            return True\n        else:\n            return False\n\n    def restart(self):\n        self.initialize()\n        self.archive = []\n        self.sigma *= 2  # Increase exploration after restart\n        print(\"Restarting CMA-ES\")\n\n    def __call__(self, func):\n        self.initialize()\n\n        while self.eval_count < self.budget:\n            x = self.sample()\n            \n            # Ensure bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.eval_count += len(x)\n\n            self.update(x, f)\n            self.archive_management(x, f)\n\n            if self.check_stagnation():\n                self.restart()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 122, in __call__\n  File \"<string>\", line 51, in update\nValueError: operands could not be broadcast together with shapes (2,2) (3,1) \n.", "error": "", "parent_ids": ["5908a426-e448-4d00-9f48-12f180046988"], "operator": null, "metadata": {}}
{"id": "cf6733a5-d825-4732-b2e1-34c9a16456de", "fitness": -Infinity, "name": "ActiveCMAES", "description": "Implement active covariance matrix adaptation and dynamic population size adjustment based on stagnation detection for improved exploration and exploitation.", "code": "import numpy as np\n\nclass ActiveCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=None, c_cov=None, archive_size=100, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = cs\n        self.damps = damp if damp is not None else 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.ccov1 = c_cov[0] if c_cov is not None else 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.ccovmu = c_cov[1] if c_cov is not None else 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2.3)**2 + self.mueff)\n        self.ccovmu = min(1-self.ccov1, self.ccovmu)\n\n        self.mean = None\n        self.sigma = 0.5\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.archive = []\n        self.archive_size = archive_size\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.stagnation_threshold = stagnation_threshold\n        self.last_f_opt = np.inf\n\n    def initialize(self):\n        self.mean = np.random.uniform(-5, 5, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n    def sample(self):\n        z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n        C_sqrt = np.linalg.cholesky(self.C)\n        x = self.mean[:, np.newaxis] + self.sigma * C_sqrt @ z\n        return x.T\n\n    def update(self, x, f):\n        idx = np.argsort(f)\n        x = x[idx]\n        f = f[idx]\n\n        xmean = np.sum(x[:self.mu] * self.weights[:, np.newaxis], axis=0)\n\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (xmean - self.mean) / self.sigma\n        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.eval_count / self.popsize))) < (1.4 + 2 / (self.dim + 1))\n        self.pc = (1 - 1) * self.pc + hsig * np.sqrt(1 * (2 - 1) * self.mueff) * (xmean - self.mean) / self.sigma\n\n        y = (x[:self.mu] - self.mean) / self.sigma\n\n        # Active CMA update\n        B = np.linalg.cholesky(self.C)\n        z = np.linalg.solve(B, (x[:self.mu] - self.mean).T / self.sigma)\n        w_mask = self.weights > 0\n        \n        C_temp = (1 - self.ccov1 - self.ccovmu + self.ccov1 * (1 - hsig**2)) * self.C \\\n                 + self.ccov1 * np.outer(self.pc, self.pc) \\\n                 + self.ccovmu * np.sum(self.weights[:, np.newaxis, np.newaxis] * z[:, w_mask][:, :, np.newaxis] * z[:, w_mask][:, np.newaxis, :], axis=1)\n\n        self.C = np.triu(C_temp) + np.triu(C_temp, 1).T\n        self.C = self.C + 1e-8 * np.eye(self.dim)\n        \n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n        self.mean = xmean\n\n        for i in range(len(x)):\n            if f[i] < self.f_opt:\n                self.f_opt = f[i]\n                self.x_opt = x[i]\n\n    def archive_management(self, x, f):\n        for i in range(len(x)):\n            if len(self.archive) < self.archive_size:\n                self.archive.append((x[i], f[i]))\n            else:\n                # Replace worst element in archive if current element is better\n                worst_idx = np.argmax([item[1] for item in self.archive])\n                if f[i] < self.archive[worst_idx][1]:\n                    self.archive[worst_idx] = (x[i], f[i])\n\n    def check_stagnation(self):\n        if self.f_opt < self.last_f_opt:\n            self.stagnation_counter = 0\n            self.last_f_opt = self.f_opt\n        else:\n            self.stagnation_counter += 1\n\n        if self.stagnation_counter > self.stagnation_threshold:\n            return True\n        else:\n            return False\n\n    def adjust_popsize(self):\n        if self.check_stagnation():\n            self.popsize = int(self.popsize * 1.5)  # Increase population size\n            self.mu = self.popsize // 2\n            self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n            self.weights = self.weights / np.sum(self.weights)\n            self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n            self.stagnation_counter = 0  # Reset stagnation counter\n        elif self.popsize > 4 + int(3 * np.log(self.dim)) and self.eval_count > self.budget/2 and self.stagnation_counter < self.stagnation_threshold/2:\n             self.popsize = int(self.popsize * 0.9) # Decrease popsize when nearing budget end and not stagnating\n             self.mu = self.popsize // 2\n             self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n             self.weights = self.weights / np.sum(self.weights)\n             self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n    def __call__(self, func):\n        self.initialize()\n\n        while self.eval_count < self.budget:\n            self.adjust_popsize()\n            x = self.sample()\n            \n            # Ensure bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.eval_count += len(x)\n\n            self.update(x, f)\n            self.archive_management(x, f)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 128, in __call__\n  File \"<string>\", line 65, in update\nValueError: operands could not be broadcast together with shapes (3,1,1) (2,3,1) \n.", "error": "", "parent_ids": ["5908a426-e448-4d00-9f48-12f180046988"], "operator": null, "metadata": {}}
{"id": "54be759e-4a5a-49f4-9836-b3e1c167da4e", "fitness": -Infinity, "name": "AdaptiveVelocityPSO", "description": "Adaptive Velocity PSO with improved stagnation detection, dynamic population sizing, and enhanced local search.", "code": "import numpy as np\n\nclass AdaptiveVelocityPSO:\n    def __init__(self, budget=10000, dim=10, pop_size_initial=20, c1=1.49, c2=1.49, w_max=0.9, w_min=0.4, local_search_iterations=5, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_initial = pop_size_initial\n        self.pop_size = pop_size_initial  # Current population size\n        self.c1 = c1\n        self.c2 = c2\n        self.w_max = w_max\n        self.w_min = w_min\n        self.local_search_iterations = local_search_iterations\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.restart_percentage = 0.5\n        self.expansion_rate = 1.2  # Rate at which population size increases after stagnation\n        self.contraction_rate = 0.8  # Rate at which population size decreases if improving\n        self.min_pop_size = 10\n        self.max_pop_size = 50\n        self.last_improvement = 0 # Keep track of the last time gbest improved\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1 * (func.bounds.ub - func.bounds.lb)\n        self.fitness = np.array([func(x) for x in self.population])\n        self.pbest_positions = self.population.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_index = np.argmin(self.fitness)\n        self.gbest_position = self.population[self.gbest_index].copy()\n        self.gbest_fitness = self.fitness[self.gbest_index]\n\n        eval_count = self.pop_size\n        self.last_improvement = 0 # Initialize last improvement\n\n        while eval_count < self.budget:\n            # Adaptive Inertia Weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n            for i in range(self.pop_size):\n                # Update Velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = w * self.velocities[i] + \\\n                                     self.c1 * r1 * (self.pbest_positions[i] - self.population[i]) + \\\n                                     self.c2 * r2 * (self.gbest_position - self.population[i])\n\n                # Limit velocity to avoid explosion\n                v_max = 0.1 * (func.bounds.ub - func.bounds.lb)\n                self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n                # Update Position\n                self.population[i] = self.population[i] + self.velocities[i]\n\n                # Boundary Handling (Clipping)\n                self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate Fitness\n                fitness = func(self.population[i])\n                eval_count += 1\n\n                # Update Personal Best\n                if fitness < self.pbest_fitness[i]:\n                    self.pbest_fitness[i] = fitness\n                    self.pbest_positions[i] = self.population[i].copy()\n\n                    #Update Global Best\n                    if fitness < self.gbest_fitness:\n                        self.gbest_fitness = fitness\n                        self.gbest_position = self.population[i].copy()\n                        self.stagnation_counter = 0  # Reset stagnation counter upon improvement\n                        self.last_improvement = eval_count\n\n                #Local Search with Adaptive Step Size\n                if eval_count < self.budget:\n                    x_current = self.population[i].copy()\n                    f_current = fitness\n                    adaptive_step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n\n                    for _ in range(self.local_search_iterations):\n                        perturbation = np.random.normal(0, adaptive_step_size, size=self.dim)\n                        x_new = x_current + perturbation\n                        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                        f_new = func(x_new)\n                        eval_count += 1\n\n                        if f_new < f_current:\n                            x_current = x_new.copy()\n                            f_current = f_new\n                            adaptive_step_size *= 1.1 # Increase step if improvement\n                        else:\n                            adaptive_step_size *= 0.9 # Reduce step if no improvement\n\n                        if eval_count >= self.budget:\n                            break\n\n                    self.population[i] = x_current\n                    self.fitness[i] = f_current\n\n                    if f_current < self.pbest_fitness[i]:\n                        self.pbest_fitness[i] = f_current\n                        self.pbest_positions[i] = self.population[i].copy()\n\n                        if f_current < self.gbest_fitness:\n                            self.gbest_fitness = f_current\n                            self.gbest_position = self.population[i].copy()\n                            self.stagnation_counter = 0\n                            self.last_improvement = eval_count\n\n            #Stagnation Restart Mechanism and Dynamic Population Size\n            if eval_count - self.last_improvement > self.stagnation_threshold:\n                #Stagnation is detected\n                if self.pop_size < self.max_pop_size:\n                    self.pop_size = min(int(self.pop_size * self.expansion_rate), self.max_pop_size) #Increase population\n                \n                num_to_restart = int(self.restart_percentage * self.pop_size)\n                indices_to_restart = np.random.choice(self.pop_size, size=num_to_restart, replace=False)\n\n                for idx in indices_to_restart:\n                    self.population[idx] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    self.velocities[idx] = np.random.uniform(-1, 1, size=self.dim) * 0.1 * (func.bounds.ub - func.bounds.lb)\n                    self.fitness[idx] = func(self.population[idx])\n                    eval_count += 1\n\n                    self.pbest_positions[idx] = self.population[idx].copy()\n                    self.pbest_fitness[idx] = self.fitness[idx]\n\n                    if self.fitness[idx] < self.gbest_fitness:\n                        self.gbest_fitness = self.fitness[idx]\n                        self.gbest_position = self.population[idx].copy()\n                        self.last_improvement = eval_count\n                        \n                self.stagnation_counter = 0 # Reset stagnation counter after restart\n                self.last_improvement = eval_count\n\n            else:\n                if self.gbest_fitness < self.f_opt:\n                    self.f_opt = self.gbest_fitness\n                    self.x_opt = self.gbest_position.copy()\n                    # Potentially decrease pop size if improvement is good to save budget\n                    if self.pop_size > self.min_pop_size:\n                        self.pop_size = max(int(self.pop_size * self.contraction_rate), self.min_pop_size)\n            \n\n            if self.gbest_fitness < self.f_opt:\n                self.f_opt = self.gbest_fitness\n                self.x_opt = self.gbest_position.copy()\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 49, in __call__\nIndexError: index 20 is out of bounds for axis 0 with size 20\n.", "error": "", "parent_ids": ["6260971a-9c8f-45c9-8110-3a1a347e859e"], "operator": null, "metadata": {}}
{"id": "31ee3470-014a-4f74-88be-03f7fea5619f", "fitness": 0.0, "name": "AdaptiveVelocityPSO_Enhanced", "description": "Enhanced Adaptive Velocity PSO with dynamic parameter adaptation, orthogonal learning, and a more aggressive restart strategy to improve exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveVelocityPSO_Enhanced:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.5, c2=1.5, w_max=0.9, w_min=0.4, local_search_iterations=5, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.w_max = w_max\n        self.w_min = w_min\n        self.local_search_iterations = local_search_iterations\n        self.stagnation_threshold = stagnation_threshold\n        self.restart_percentage = 0.7  # Increase restart percentage\n        self.exploration_probability = 0.1 # Probability of exploration move\n        self.orthogonal_learning_percentage = 0.2  # Percentage of particles for orthogonal learning\n        self.min_velocity = -0.1 * (5.0 - (-5.0))\n        self.max_velocity = 0.1 * (5.0 - (-5.0))\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(self.min_velocity, self.max_velocity, size=(self.pop_size, self.dim)) # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.pbest_positions = self.population.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_index = np.argmin(self.fitness)\n        self.gbest_position = self.population[self.gbest_index].copy()\n        self.gbest_fitness = self.fitness[self.gbest_index]\n\n        eval_count = self.pop_size\n        stagnation_counter = 0\n\n        while eval_count < self.budget:\n            # Adaptive Inertia Weight (linearly decreasing)\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n            # Adaptive Acceleration Coefficients (Experimenting with dynamic adjustment)\n            c1 = self.c1 + (1 - (eval_count / self.budget)) * 0.5  # c1 decreases over time\n            c2 = self.c2 + (eval_count / self.budget) * 0.5      # c2 increases over time\n\n            for i in range(self.pop_size):\n                # Exploration Move (with small probability)\n                if np.random.rand() < self.exploration_probability:\n                    self.population[i] = np.random.uniform(lb, ub, size=self.dim)\n                    self.velocities[i] = np.random.uniform(self.min_velocity, self.max_velocity, size=self.dim)\n                else:\n                    # Update Velocity\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    self.velocities[i] = w * self.velocities[i] + \\\n                                         c1 * r1 * (self.pbest_positions[i] - self.population[i]) + \\\n                                         c2 * r2 * (self.gbest_position - self.population[i])\n\n                    # Limit velocity to avoid explosion\n                    self.velocities[i] = np.clip(self.velocities[i], self.min_velocity, self.max_velocity)\n\n                    # Update Position\n                    self.population[i] = self.population[i] + self.velocities[i]\n\n                    # Boundary Handling (Clipping)\n                    self.population[i] = np.clip(self.population[i], lb, ub)\n\n\n                # Evaluate Fitness\n                fitness = func(self.population[i])\n                eval_count += 1\n\n                # Update Personal Best\n                if fitness < self.pbest_fitness[i]:\n                    self.pbest_fitness[i] = fitness\n                    self.pbest_positions[i] = self.population[i].copy()\n\n                    # Update Global Best\n                    if fitness < self.gbest_fitness:\n                        self.gbest_fitness = fitness\n                        self.gbest_position = self.population[i].copy()\n                        stagnation_counter = 0  # Reset stagnation counter upon improvement\n\n                else:\n                    stagnation_counter += 1  # Increment stagnation counter\n\n                # Local Search\n                if eval_count < self.budget:\n                    x_current = self.population[i].copy()\n                    f_current = fitness\n\n                    for _ in range(self.local_search_iterations):\n                        perturbation = np.random.normal(0, 0.01 * (ub - lb), size=self.dim)\n                        x_new = x_current + perturbation\n                        x_new = np.clip(x_new, lb, ub)\n                        f_new = func(x_new)\n                        eval_count += 1\n\n                        if f_new < f_current:\n                            x_current = x_new.copy()\n                            f_current = f_new\n\n                        if eval_count >= self.budget:\n                            break\n\n                    self.population[i] = x_current\n                    self.fitness[i] = f_current\n\n                    if f_current < self.pbest_fitness[i]:\n                        self.pbest_fitness[i] = f_current\n                        self.pbest_positions[i] = self.population[i].copy()\n\n                        if f_current < self.gbest_fitness:\n                            self.gbest_fitness = f_current\n                            self.gbest_position = self.population[i].copy()\n                            stagnation_counter = 0\n\n            # Orthogonal Learning\n            num_orthogonal = int(self.orthogonal_learning_percentage * self.pop_size)\n            indices_orthogonal = np.random.choice(self.pop_size, size=num_orthogonal, replace=False)\n\n            for idx in indices_orthogonal:\n                basis = np.random.normal(0, 1, size=(self.dim, self.dim))\n                Q, _ = np.linalg.qr(basis)  # Orthogonal basis\n\n                step_sizes = np.random.uniform(-0.05 * (ub - lb), 0.05 * (ub - lb), size=self.dim)  # Smaller step sizes\n\n                for j in range(self.dim):\n                    x_new = self.population[idx] + step_sizes[j] * Q[:, j]\n                    x_new = np.clip(x_new, lb, ub)\n                    f_new = func(x_new)\n                    eval_count += 1\n\n                    if f_new < self.fitness[idx]:\n                        self.population[idx] = x_new.copy()\n                        self.fitness[idx] = f_new\n\n                        if f_new < self.pbest_fitness[idx]:\n                            self.pbest_fitness[idx] = f_new\n                            self.pbest_positions[idx] = self.population[idx].copy()\n\n                            if f_new < self.gbest_fitness:\n                                self.gbest_fitness = f_new\n                                self.gbest_position = self.population[idx].copy()\n                                stagnation_counter = 0\n\n                    if eval_count >= self.budget:\n                        break\n\n                if eval_count >= self.budget:\n                    break\n\n\n            # Stagnation Restart Mechanism (More aggressive)\n            if stagnation_counter > self.stagnation_threshold:\n                num_to_restart = int(self.restart_percentage * self.pop_size)\n                indices_to_restart = np.random.choice(self.pop_size, size=num_to_restart, replace=False)\n\n                for idx in indices_to_restart:\n                    self.population[idx] = np.random.uniform(lb, ub, size=self.dim)\n                    self.velocities[idx] = np.random.uniform(self.min_velocity, self.max_velocity, size=self.dim)  # Reinitialize velocity\n                    self.fitness[idx] = func(self.population[idx])\n                    eval_count += 1\n\n                    self.pbest_positions[idx] = self.population[idx].copy()\n                    self.pbest_fitness[idx] = self.fitness[idx]\n\n                    if self.fitness[idx] < self.gbest_fitness:\n                        self.gbest_fitness = self.fitness[idx]\n                        self.gbest_position = self.population[idx].copy()\n\n                stagnation_counter = 0  # Reset stagnation counter after restart\n\n            if self.gbest_fitness < self.f_opt:\n                self.f_opt = self.gbest_fitness\n                self.x_opt = self.gbest_position.copy()\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveVelocityPSO_Enhanced scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6260971a-9c8f-45c9-8110-3a1a347e859e"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "b2b48276-8086-4aa7-86c7-4df590c19fe1", "fitness": 0.0, "name": "AdaptiveVelocityPSO_Ortho", "description": "Adaptive Velocity PSO with a diversity maintenance strategy based on orthogonal learning and dynamic parameter adjustments.", "code": "import numpy as np\n\nclass AdaptiveVelocityPSO_Ortho(object):\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.49, c2=1.49, w_max=0.9, w_min=0.4, local_search_iterations=5, ortho_group_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.w_max = w_max\n        self.w_min = w_min\n        self.local_search_iterations = local_search_iterations\n        self.stagnation_threshold = 1000\n        self.restart_percentage = 0.5\n        self.ortho_group_size = min(ortho_group_size, pop_size) # Ensure ortho_group_size is valid\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1 * (func.bounds.ub - func.bounds.lb)\n        self.fitness = np.array([func(x) for x in self.population])\n        self.pbest_positions = self.population.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_index = np.argmin(self.fitness)\n        self.gbest_position = self.population[self.gbest_index].copy()\n        self.gbest_fitness = self.fitness[self.gbest_index]\n\n        eval_count = self.pop_size\n        stagnation_counter = 0\n        adaptive_c1 = self.c1\n        adaptive_c2 = self.c2\n\n        while eval_count < self.budget:\n            # Adaptive Inertia Weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n            for i in range(self.pop_size):\n                # Update Velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = w * self.velocities[i] + \\\n                                     adaptive_c1 * r1 * (self.pbest_positions[i] - self.population[i]) + \\\n                                     adaptive_c2 * r2 * (self.gbest_position - self.population[i])\n\n                # Limit velocity to avoid explosion\n                v_max = 0.1 * (func.bounds.ub - func.bounds.lb)\n                self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n                # Update Position\n                self.population[i] = self.population[i] + self.velocities[i]\n\n                # Boundary Handling (Clipping)\n                self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate Fitness\n                fitness = func(self.population[i])\n                eval_count += 1\n\n                # Update Personal Best\n                if fitness < self.pbest_fitness[i]:\n                    self.pbest_fitness[i] = fitness\n                    self.pbest_positions[i] = self.population[i].copy()\n\n                    # Update Global Best\n                    if fitness < self.gbest_fitness:\n                        self.gbest_fitness = fitness\n                        self.gbest_position = self.population[i].copy()\n                        stagnation_counter = 0  # Reset stagnation counter upon improvement\n                        adaptive_c1 = self.c1 # Reset cognitive parameter on global best improvement\n                        adaptive_c2 = self.c2 # Reset social parameter on global best improvement\n\n                else:\n                    stagnation_counter += 1  # Increment stagnation counter\n                    adaptive_c1 *= 0.99  # Reduce cognitive parameter if no improvement\n                    adaptive_c2 *= 1.01  # Increase social parameter if no improvement\n                    adaptive_c1 = np.clip(adaptive_c1, 0.5, 2.0) # Keep parameters in reasonable range\n                    adaptive_c2 = np.clip(adaptive_c2, 0.5, 2.0) # Keep parameters in reasonable range\n                \n                #Local Search\n                if eval_count < self.budget:\n                     x_current = self.population[i].copy()\n                     f_current = fitness\n\n                     for _ in range(self.local_search_iterations):\n                         perturbation = np.random.normal(0, 0.01 * (func.bounds.ub - func.bounds.lb), size=self.dim)\n                         x_new = x_current + perturbation\n                         x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                         f_new = func(x_new)\n                         eval_count+=1\n\n                         if f_new < f_current:\n                            x_current = x_new.copy()\n                            f_current = f_new\n\n                         if eval_count >= self.budget:\n                            break\n                     \n                     self.population[i] = x_current\n                     self.fitness[i] = f_current\n                \n                     if f_current < self.pbest_fitness[i]:\n                         self.pbest_fitness[i] = f_current\n                         self.pbest_positions[i] = self.population[i].copy()\n\n                         if f_current < self.gbest_fitness:\n                            self.gbest_fitness = f_current\n                            self.gbest_position = self.population[i].copy()\n                            stagnation_counter = 0\n\n            # Orthogonal Learning\n            if self.pop_size > 1 and eval_count < self.budget:\n                indices = np.random.choice(self.pop_size, size=self.ortho_group_size, replace=False)\n                group = self.population[indices]\n                \n                # Calculate the mean position of the group\n                mean_position = np.mean(group, axis=0)\n\n                # Generate an orthogonal vector (simplified - could be improved for higher dimensions)\n                orthogonal_vector = np.random.normal(0, 0.05 * (func.bounds.ub - func.bounds.lb), size=self.dim)\n                \n                # Update a randomly selected particle in the group with the orthogonal information\n                idx_to_update = np.random.randint(0, self.ortho_group_size)\n                new_position = mean_position + orthogonal_vector\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                eval_count += 1\n\n                if new_fitness < self.fitness[indices[idx_to_update]]:\n                    self.population[indices[idx_to_update]] = new_position\n                    self.fitness[indices[idx_to_update]] = new_fitness\n\n                    if new_fitness < self.pbest_fitness[indices[idx_to_update]]:\n                        self.pbest_fitness[indices[idx_to_update]] = new_fitness\n                        self.pbest_positions[indices[idx_to_update]] = new_position.copy()\n\n                        if new_fitness < self.gbest_fitness:\n                            self.gbest_fitness = new_fitness\n                            self.gbest_position = new_position.copy()\n                            stagnation_counter = 0\n            \n\n            # Stagnation Restart Mechanism\n            if stagnation_counter > self.stagnation_threshold:\n                num_to_restart = int(self.restart_percentage * self.pop_size)\n                indices_to_restart = np.random.choice(self.pop_size, size=num_to_restart, replace=False)\n\n                for idx in indices_to_restart:\n                    self.population[idx] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    self.velocities[idx] = np.random.uniform(-1, 1, size=self.dim) * 0.1 * (func.bounds.ub - func.bounds.lb)\n                    self.fitness[idx] = func(self.population[idx])\n                    eval_count += 1\n\n                    self.pbest_positions[idx] = self.population[idx].copy()\n                    self.pbest_fitness[idx] = self.fitness[idx]\n\n                    if self.fitness[idx] < self.gbest_fitness:\n                        self.gbest_fitness = self.fitness[idx]\n                        self.gbest_position = self.population[idx].copy()\n\n                stagnation_counter = 0  # Reset stagnation counter after restart\n\n            if self.gbest_fitness < self.f_opt:\n                self.f_opt = self.gbest_fitness\n                self.x_opt = self.gbest_position.copy()\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveVelocityPSO_Ortho scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6260971a-9c8f-45c9-8110-3a1a347e859e"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "22072dfb-8fb0-4f5d-8704-89ca77549968", "fitness": 0.0, "name": "AdaptiveVelocityPSO", "description": "Adaptive Velocity PSO with aging, mutation, and dynamic local search to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveVelocityPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.49, c2=1.49, w_max=0.9, w_min=0.4, local_search_iterations=5,\n                 mutation_rate=0.05, stagnation_threshold=1000, restart_percentage=0.5, age_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.w_max = w_max\n        self.w_min = w_min\n        self.local_search_iterations = local_search_iterations\n        self.mutation_rate = mutation_rate\n        self.stagnation_threshold = stagnation_threshold\n        self.restart_percentage = restart_percentage\n        self.age_threshold = age_threshold\n        self.ages = np.zeros(pop_size) # Initialize ages\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1 * (func.bounds.ub - func.bounds.lb)  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.pbest_positions = self.population.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_index = np.argmin(self.fitness)\n        self.gbest_position = self.population[self.gbest_index].copy()\n        self.gbest_fitness = self.fitness[self.gbest_index]\n\n        eval_count = self.pop_size\n        stagnation_counter = 0\n\n        while eval_count < self.budget:\n            # Adaptive Inertia Weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n            for i in range(self.pop_size):\n                # Update Velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = w * self.velocities[i] + \\\n                                     self.c1 * r1 * (self.pbest_positions[i] - self.population[i]) + \\\n                                     self.c2 * r2 * (self.gbest_position - self.population[i])\n\n                # Limit velocity to avoid explosion\n                v_max = 0.1 * (func.bounds.ub - func.bounds.lb)\n                self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n                # Update Position\n                self.population[i] = self.population[i] + self.velocities[i]\n\n                # Boundary Handling (Clipping)\n                self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n                # Mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.05 * (func.bounds.ub - func.bounds.lb), size=self.dim)\n                    self.population[i] += mutation\n                    self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate Fitness\n                fitness = func(self.population[i])\n                eval_count += 1\n\n                # Update Personal Best\n                if fitness < self.pbest_fitness[i]:\n                    self.pbest_fitness[i] = fitness\n                    self.pbest_positions[i] = self.population[i].copy()\n                    self.ages[i] = 0  # Reset age\n                    #Update Global Best\n                    if fitness < self.gbest_fitness:\n                        self.gbest_fitness = fitness\n                        self.gbest_position = self.population[i].copy()\n                        stagnation_counter = 0  # Reset stagnation counter upon improvement\n\n                else:\n                    stagnation_counter += 1 # Increment stagnation counter\n                    self.ages[i] += 1\n\n                #Dynamic Local Search\n                local_search_iterations = int(self.local_search_iterations * (1 + self.ages[i] / self.age_threshold))\n                local_search_iterations = min(local_search_iterations, 20) # Cap the number of local search iterations\n                if eval_count < self.budget:\n                     x_current = self.population[i].copy()\n                     f_current = fitness\n\n                     for _ in range(local_search_iterations):\n                         perturbation = np.random.normal(0, 0.01 * (func.bounds.ub - func.bounds.lb), size=self.dim)\n                         x_new = x_current + perturbation\n                         x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                         f_new = func(x_new)\n                         eval_count+=1\n\n                         if f_new < f_current:\n                            x_current = x_new.copy()\n                            f_current = f_new\n\n                         if eval_count >= self.budget:\n                            break\n                     \n                     self.population[i] = x_current\n                     self.fitness[i] = f_current\n                \n                     if f_current < self.pbest_fitness[i]:\n                         self.pbest_fitness[i] = f_current\n                         self.pbest_positions[i] = self.population[i].copy()\n                         self.ages[i] = 0 # Reset age\n\n                         if f_current < self.gbest_fitness:\n                            self.gbest_fitness = f_current\n                            self.gbest_position = self.population[i].copy()\n                            stagnation_counter = 0\n\n            #Stagnation Restart Mechanism\n            if stagnation_counter > self.stagnation_threshold:\n                num_to_restart = int(self.restart_percentage * self.pop_size)\n                indices_to_restart = np.random.choice(self.pop_size, size=num_to_restart, replace=False)\n\n                for idx in indices_to_restart:\n                    self.population[idx] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    self.velocities[idx] = np.random.uniform(-1, 1, size=self.dim) * 0.1 * (func.bounds.ub - func.bounds.lb) #Reinitialize velocity\n                    self.fitness[idx] = func(self.population[idx])\n                    self.ages[idx] = 0\n                    eval_count += 1\n\n                    self.pbest_positions[idx] = self.population[idx].copy()\n                    self.pbest_fitness[idx] = self.fitness[idx]\n\n                    if self.fitness[idx] < self.gbest_fitness:\n                        self.gbest_fitness = self.fitness[idx]\n                        self.gbest_position = self.population[idx].copy()\n                        stagnation_counter = 0\n\n                stagnation_counter = 0 # Reset stagnation counter after restart\n            \n            if self.gbest_fitness < self.f_opt:\n                self.f_opt = self.gbest_fitness\n                self.x_opt = self.gbest_position.copy()\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveVelocityPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6260971a-9c8f-45c9-8110-3a1a347e859e"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "086625f1-338a-4c59-bdaf-c39b501bd90d", "fitness": 0.0, "name": "AdaptiveVelocityPSO", "description": "Improved Adaptive Velocity PSO with dynamic parameter adaptation, velocity clamping, and orthogonal learning for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveVelocityPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1_init=2.0, c2_init=2.0, w_init=0.9, w_final=0.4, local_search_iterations=5, stagnation_threshold=500, restart_percentage=0.3, orthogonal_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1_init = c1_init\n        self.c2_init = c2_init\n        self.w_init = w_init\n        self.w_final = w_final\n        self.local_search_iterations = local_search_iterations\n        self.stagnation_threshold = stagnation_threshold\n        self.restart_percentage = restart_percentage\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n        self.eval_count = 0 # Track evaluations\n        self.v_max_factor = 0.1 # Maximum velocity factor\n        \n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.v_max_factor * (ub - lb), self.v_max_factor * (ub - lb), size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n\n        self.pbest_positions = self.population.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_index = np.argmin(self.fitness)\n        self.gbest_position = self.population[self.gbest_index].copy()\n        self.gbest_fitness = self.fitness[self.gbest_index]\n        self.stagnation_counter = 0\n\n        while self.eval_count < self.budget:\n            # Dynamic Parameter Adaptation\n            w = self.w_init - (self.w_init - self.w_final) * (self.eval_count / self.budget)\n            c1 = self.c1_init - (self.c1_init - 0.5) * (self.eval_count / self.budget) #Decay c1\n            c2 = self.c2_init + (2.5 - self.c2_init) * (self.eval_count / self.budget)  #Increase c2\n\n            for i in range(self.pop_size):\n                # Update Velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = w * self.velocities[i] + \\\n                                     c1 * r1 * (self.pbest_positions[i] - self.population[i]) + \\\n                                     c2 * r2 * (self.gbest_position - self.population[i])\n\n                # Velocity Clamping\n                v_max = self.v_max_factor * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n                # Update Position\n                self.population[i] = self.population[i] + self.velocities[i]\n                self.population[i] = np.clip(self.population[i], lb, ub) # Boundary Handling\n\n                # Evaluate Fitness\n                fitness = func(self.population[i])\n                self.eval_count += 1\n\n                # Update Personal Best\n                if fitness < self.pbest_fitness[i]:\n                    self.pbest_fitness[i] = fitness\n                    self.pbest_positions[i] = self.population[i].copy()\n\n                    # Update Global Best\n                    if fitness < self.gbest_fitness:\n                        self.gbest_fitness = fitness\n                        self.gbest_position = self.population[i].copy()\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    self.stagnation_counter += 1\n                \n                # Local Search\n                if self.eval_count < self.budget:\n                    x_current = self.population[i].copy()\n                    f_current = fitness\n                    for _ in range(self.local_search_iterations):\n                        perturbation = np.random.normal(0, 0.01 * (ub - lb), size=self.dim)\n                        x_new = x_current + perturbation\n                        x_new = np.clip(x_new, lb, ub)\n                        f_new = func(x_new)\n                        self.eval_count += 1\n                        if f_new < f_current:\n                            x_current = x_new.copy()\n                            f_current = f_new\n                        if self.eval_count >= self.budget:\n                            break\n                            \n                    self.population[i] = x_current\n                    self.fitness[i] = f_current\n\n                    if f_current < self.pbest_fitness[i]:\n                        self.pbest_fitness[i] = f_current\n                        self.pbest_positions[i] = self.population[i].copy()\n\n                        if f_current < self.gbest_fitness:\n                            self.gbest_fitness = f_current\n                            self.gbest_position = self.population[i].copy()\n                            self.stagnation_counter = 0\n\n                # Orthogonal Learning\n                if self.eval_count < self.budget:\n                    orthogonal_vector = np.random.normal(0, 0.005 * (ub-lb), size=self.dim)\n                    x_orthogonal = self.population[i] + self.orthogonal_learning_rate * orthogonal_vector\n                    x_orthogonal = np.clip(x_orthogonal, lb, ub)\n                    f_orthogonal = func(x_orthogonal)\n                    self.eval_count +=1\n\n                    if f_orthogonal < self.fitness[i]:\n                        self.population[i] = x_orthogonal\n                        self.fitness[i] = f_orthogonal\n                        if f_orthogonal < self.pbest_fitness[i]:\n                            self.pbest_fitness[i] = f_orthogonal\n                            self.pbest_positions[i] = self.population[i].copy()\n                            if f_orthogonal < self.gbest_fitness:\n                                self.gbest_fitness = f_orthogonal\n                                self.gbest_position = self.population[i].copy()\n                                self.stagnation_counter = 0\n\n\n            # Stagnation Restart\n            if self.stagnation_counter > self.stagnation_threshold:\n                num_to_restart = int(self.restart_percentage * self.pop_size)\n                indices_to_restart = np.random.choice(self.pop_size, size=num_to_restart, replace=False)\n\n                for idx in indices_to_restart:\n                    self.population[idx] = np.random.uniform(lb, ub, size=self.dim)\n                    self.velocities[idx] = np.random.uniform(-self.v_max_factor * (ub - lb), self.v_max_factor * (ub - lb), size=self.dim)\n                    self.fitness[idx] = func(self.population[idx])\n                    self.eval_count += 1\n\n                    self.pbest_positions[idx] = self.population[idx].copy()\n                    self.pbest_fitness[idx] = self.fitness[idx]\n\n                    if self.fitness[idx] < self.gbest_fitness:\n                        self.gbest_fitness = self.fitness[idx]\n                        self.gbest_position = self.population[idx].copy()\n\n                self.stagnation_counter = 0\n\n            if self.gbest_fitness < self.f_opt:\n                self.f_opt = self.gbest_fitness\n                self.x_opt = self.gbest_position.copy()\n            \n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveVelocityPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6260971a-9c8f-45c9-8110-3a1a347e859e"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "c7ed2372-402e-45d6-9b1e-a276db237105", "fitness": 0.0, "name": "AdaptiveVelocityPSO", "description": "Adaptive Velocity PSO with orthogonal learning, improved stagnation handling, and parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveVelocityPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.49, c2=1.49, w_max=0.9, w_min=0.4, local_search_iterations=5, stagnation_threshold=500, restart_percentage=0.5, orthogonal_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.w_max = w_max\n        self.w_min = w_min\n        self.local_search_iterations = local_search_iterations\n        self.stagnation_threshold = stagnation_threshold # Number of iterations without improvement before restart\n        self.restart_percentage = restart_percentage # Percentage of population to restart\n        self.orthogonal_learning_rate = orthogonal_learning_rate # Learning rate for orthogonal learning\n        self.success_history = [] # Keep track of success for parameter adaptation\n        self.success_threshold = 0.1 # Threshold for considering an update successful\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1 * (func.bounds.ub - func.bounds.lb)  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.pbest_positions = self.population.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_index = np.argmin(self.fitness)\n        self.gbest_position = self.population[self.gbest_index].copy()\n        self.gbest_fitness = self.fitness[self.gbest_index]\n\n        eval_count = self.pop_size\n        stagnation_counter = 0\n        last_improvement = 0 # Keep track of the last time the global best improved\n\n        while eval_count < self.budget:\n            # Adaptive Inertia Weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n            for i in range(self.pop_size):\n                # Update Velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = w * self.velocities[i] + \\\n                                     self.c1 * r1 * (self.pbest_positions[i] - self.population[i]) + \\\n                                     self.c2 * r2 * (self.gbest_position - self.population[i])\n\n                # Limit velocity to avoid explosion\n                v_max = 0.1 * (func.bounds.ub - func.bounds.lb)\n                self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n\n                # Update Position\n                self.population[i] = self.population[i] + self.velocities[i]\n\n                # Boundary Handling (Clipping)\n                self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n           \n\n                # Evaluate Fitness\n                fitness = func(self.population[i])\n                eval_count += 1\n\n                # Update Personal Best\n                if fitness < self.pbest_fitness[i]:\n                    self.pbest_fitness[i] = fitness\n                    self.pbest_positions[i] = self.population[i].copy()\n\n                    #Update Global Best\n                    if fitness < self.gbest_fitness:\n                        self.gbest_fitness = fitness\n                        self.gbest_position = self.population[i].copy()\n                        last_improvement = eval_count # Update last improvement time\n\n                \n                #Local Search\n                if eval_count < self.budget:\n                     x_current = self.population[i].copy()\n                     f_current = fitness\n\n                     for _ in range(self.local_search_iterations):\n                         perturbation = np.random.normal(0, 0.01 * (func.bounds.ub - func.bounds.lb), size=self.dim)\n                         x_new = x_current + perturbation\n                         x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                         f_new = func(x_new)\n                         eval_count+=1\n\n                         if f_new < f_current:\n                            x_current = x_new.copy()\n                            f_current = f_new\n\n                         if eval_count >= self.budget:\n                            break\n                     \n                     self.population[i] = x_current\n                     self.fitness[i] = f_current\n                \n                     if f_current < self.pbest_fitness[i]:\n                         self.pbest_fitness[i] = f_current\n                         self.pbest_positions[i] = self.population[i].copy()\n\n                         if f_current < self.gbest_fitness:\n                            self.gbest_fitness = f_current\n                            self.gbest_position = self.population[i].copy()\n                            last_improvement = eval_count\n\n            # Orthogonal Learning\n            if eval_count < self.budget:\n                orthogonal_vector = np.random.normal(0, 1, size=self.dim)\n                orthogonal_vector /= np.linalg.norm(orthogonal_vector)  # Normalize\n\n                # Move each particle along the orthogonal direction\n                for i in range(self.pop_size):\n                    step_size = self.orthogonal_learning_rate * (func.bounds.ub - func.bounds.lb)\n                    x_new = self.population[i] + step_size * orthogonal_vector\n                    x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)  # Boundary handling\n\n                    f_new = func(x_new)\n                    eval_count += 1\n\n                    if f_new < self.fitness[i]:\n                        self.population[i] = x_new.copy()\n                        self.fitness[i] = f_new\n                        if f_new < self.pbest_fitness[i]:\n                           self.pbest_fitness[i] = f_new\n                           self.pbest_positions[i] = self.population[i].copy()\n\n                           if f_new < self.gbest_fitness:\n                               self.gbest_fitness = f_new\n                               self.gbest_position = self.population[i].copy()\n                               last_improvement = eval_count\n\n            # Stagnation Detection and Restart Mechanism (Improved)\n            if eval_count - last_improvement > self.stagnation_threshold:\n                # Restart strategy with enhanced exploration\n                num_to_restart = int(self.restart_percentage * self.pop_size)\n                indices_to_restart = np.random.choice(self.pop_size, size=num_to_restart, replace=False)\n\n                for idx in indices_to_restart:\n                    # Restart with a wider range and towards gbest\n                    direction_to_gbest = self.gbest_position - self.population[idx]\n                    self.population[idx] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) + 0.2 * direction_to_gbest\n                    self.population[idx] = np.clip(self.population[idx], func.bounds.lb, func.bounds.ub)\n\n                    self.velocities[idx] = np.random.uniform(-1, 1, size=self.dim) * 0.1 * (func.bounds.ub - func.bounds.lb)  # Reinitialize velocity\n                    self.fitness[idx] = func(self.population[idx])\n                    eval_count += 1\n\n                    self.pbest_positions[idx] = self.population[idx].copy()\n                    self.pbest_fitness[idx] = self.fitness[idx]\n\n                    if self.fitness[idx] < self.gbest_fitness:\n                        self.gbest_fitness = self.fitness[idx]\n                        self.gbest_position = self.population[idx].copy()\n                        last_improvement = eval_count\n\n                last_improvement = eval_count  # Reset last improvement after restart\n\n            # Parameter Adaptation (Example: Adjusting c1 and c2)\n            if len(self.success_history) > 10:  # Only adapt if enough history exists\n                success_rate = np.mean(self.success_history[-10:])\n                if success_rate < self.success_threshold:\n                    # Exploration is needed: increase c1 and decrease c2\n                    self.c1 *= 1.05\n                    self.c2 *= 0.95\n                else:\n                    # Exploitation is needed: decrease c1 and increase c2\n                    self.c1 *= 0.95\n                    self.c2 *= 1.05\n\n                # Ensure parameters stay within reasonable bounds\n                self.c1 = np.clip(self.c1, 1.0, 2.0)\n                self.c2 = np.clip(self.c2, 1.0, 2.0)\n\n\n            if self.gbest_fitness < self.f_opt:\n                self.f_opt = self.gbest_fitness\n                self.x_opt = self.gbest_position.copy()\n                self.success_history.append(1) #Mark success\n            else:\n                self.success_history.append(0)  # Mark failure\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveVelocityPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6260971a-9c8f-45c9-8110-3a1a347e859e"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "c2bbc764-4349-4e06-a097-2b3747af8c88", "fitness": 0.13046762249844762, "name": "CMAES", "description": "CMA-ES with adaptive population size based on budget and dimension, combined with a simple archive-based restart strategy to enhance exploration.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov=None, mu_factor=0.25, sigma0=0.5, memory_size=100, restart_trigger=1e-12):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov = c_cov if c_cov is not None else (1 / self.mu) * (2 / ((self.dim + np.sqrt(2))**2))\n        self.c_cov_mu = 0.25 + self.c_cov\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.evals = 0\n        self.restart_trigger = restart_trigger\n\n    def __call__(self, func):\n        self.evals = 0\n        while self.evals < self.budget:\n            # Adaptive Population Size\n            self.popsize = 4 + int(3 * np.log(self.dim))\n            self.mu = int(self.popsize * 0.25)\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights /= np.sum(self.weights)\n            \n            # Sample population\n            z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ C_sqrt.T\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ np.linalg.inv(C_sqrt).T\n            self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC = (self.c_cov_mu / self.mu) * (self.pc[:, None] @ self.pc[None, :])\n            for i in range(self.mu):\n                dC += (self.c_cov / self.mu) * ((x[i] - m_old)[:, None] @ (x[i] - m_old)[None, :]) / self.sigma**2\n                \n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + dC\n            \n            # Ensure positive definiteness\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Archive for diversity (optional)\n            for xi in x:\n                self.archive.append(xi)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[-self.archive_size:]\n                \n            # Restart mechanism\n            if self.sigma < self.restart_trigger:\n                self.m = np.mean(np.array(self.archive), axis=0) if self.archive else np.zeros(self.dim)\n                self.sigma = sigma0\n                self.ps = np.zeros(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.C = np.eye(self.dim)\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm CMAES scored 0.130 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e5fb7f2a-b9cf-40d4-a947-dcb8d3ec58aa"], "operator": null, "metadata": {"aucs": [0.03466353105034237, 0.11172873259069493, 0.2618041319668456, 0.09266054170065086, 0.0994154752976536, 0.13156100776210367, 0.16883923425651282, 0.1178996396599401, 0.13355529109957265, 0.12887393462470065, 0.14927689260448118, 0.15823176421439167, 0.126666084541316, 0.08883298054635014, 0.1102185496213498, 0.2042072037439573, 0.11372582796798048, 0.1381961284981429, 0.09995056587644158, 0.13904493234552373]}}
{"id": "c5162116-f9c0-47f7-a620-1e38f7a8725d", "fitness": 0.12969188976617413, "name": "CMAES", "description": "CMA-ES with improved covariance update using rank-one update for faster adaptation and simplified archive handling.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov_rank_one=None, c_cov_rank_mu=None, mu_factor=0.25, sigma0=0.5, memory_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 0.15\n        self.c_cov_rank_mu = c_cov_rank_mu if c_cov_rank_mu is not None else 0.15\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n\n    def __call__(self, func):\n        evals = 0\n        while evals < self.budget:\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ C_sqrt.T\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ np.linalg.inv(C_sqrt).T\n            self.pc = (1 - self.c_cov_rank_one) * self.pc + np.sqrt(self.c_cov_rank_one * (2 - self.c_cov_rank_one)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC_rank_one = self.c_cov_rank_one * (self.pc[:, None] @ self.pc[None, :])\n            dC_rank_mu = self.c_cov_rank_mu * np.sum(self.weights[:, None, None] * ((x[:self.mu] - m_old)[:, :, None] @ (x[:self.mu] - m_old)[:, None, :]) / self.sigma**2, axis=0)\n                \n            self.C = (1 - self.c_cov_rank_one - self.c_cov_rank_mu) * self.C + dC_rank_one + dC_rank_mu\n            \n            # Ensure positive definiteness\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Simplified archive handling: keep only best from each generation.\n            self.archive.append(x[0])\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[-self.archive_size:]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm CMAES scored 0.130 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e5fb7f2a-b9cf-40d4-a947-dcb8d3ec58aa"], "operator": null, "metadata": {"aucs": [0.04688181593399099, 0.08848526287574154, 0.24799511382936112, 0.09899676848356198, 0.10434059738527501, 0.13178699908875902, 0.17577296546930632, 0.12129739248902005, 0.13887761902463702, 0.12252443552399617, 0.14918246929072065, 0.16213591269482897, 0.11140010137112955, 0.08416848512051023, 0.11532624338468289, 0.1966382541143643, 0.11342128995107559, 0.13993630499936827, 0.10841930044487891, 0.136250463848274]}}
{"id": "21d63779-0eb7-47c7-97b6-624fd54332de", "fitness": 0.5668967453979933, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with self-adaptive parameters, archive, and stochastic ranking, incorporating a learning mechanism for F and CR values based on previous success.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = None\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutated_population[i] = x1 + self.F * (x2 - x3)\n            \n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n        \n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n            \n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    idx_to_replace = np.random.randint(0, self.archive_size)\n                    self.archive[idx_to_replace] = self.population[i].copy()\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR\n        if self.successful_F:\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * np.mean(self.successful_F)\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * np.mean(self.successful_CR)\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        return new_population, new_fitness\n        \n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.567 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9960101e-622a-41bf-82ee-e45d70838973"], "operator": null, "metadata": {"aucs": [0.19558915895933038, 0.3000498939381596, 0.5561586882384524, 0.7818675712139893, 0.641580059932893, 0.7025139038255609, 0.4622105450152443, 0.5153655328536679, 0.6414094556941581, 0.4703316025565244, 0.7122634208184597, 0.9915010074971211, 0.2852009298323004, 0.5833058813647221, 0.8382047880730095, 0.7155189764071561, 0.4404988762773041, 0.7595462066207419, 0.2309519254379666, 0.5138664834031033]}}
{"id": "f09e21aa-8560-4947-aa62-d4456196904f", "fitness": -Infinity, "name": "CMAES_AdaptiveStepSize", "description": "CMA-ES with adaptive step size control using the variance of the population, and a more robust covariance update mechanism with eigenvalue decomposition to avoid ill-conditioning.", "code": "import numpy as np\n\nclass CMAES_AdaptiveStepSize:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov_rank_one=None, c_cov_rank_mu=None, mu_factor=0.25, sigma0=0.5, memory_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 0.15\n        self.c_cov_rank_mu = c_cov_rank_mu if c_cov_rank_mu is not None else 0.15\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n\n    def __call__(self, func):\n        evals = 0\n        while evals < self.budget:\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ C_sqrt.T\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ np.linalg.inv(C_sqrt).T\n            self.pc = (1 - self.c_cov_rank_one) * self.pc + np.sqrt(self.c_cov_rank_one * (2 - self.c_cov_rank_one)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC_rank_one = self.c_cov_rank_one * (self.pc[:, None] @ self.pc[None, :])\n            dC_rank_mu = self.c_cov_rank_mu * np.sum(self.weights[:, None, None] * ((x[:self.mu] - m_old)[:, :, None] @ (x[:self.mu] - m_old)[:, None, :]) / self.sigma**2, axis=0)\n                \n            C = (1 - self.c_cov_rank_one - self.c_cov_rank_mu) * self.C + dC_rank_one + dC_rank_mu\n            \n            # Eigenvalue decomposition and clipping\n            try:\n                D, B = np.linalg.eigh(C)\n                D = np.clip(D, 1e-10, None)  # Clip small eigenvalues\n                self.C = B @ np.diag(D) @ B.T\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Adaptive step size control using population variance\n            variances = np.var(x, axis=0)\n            mean_variance = np.mean(variances)\n            \n            # Adjust sigma based on the mean variance in the population\n            self.sigma *= np.exp(0.5 * (mean_variance - 1))  # Adjust step size\n\n            # Simplified archive handling: keep only best from each generation.\n            self.archive.append(x[0])\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[-self.archive_size:]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 31, in __call__\n  File \"<__array_function__ internals>\", line 200, in cholesky\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py\", line 756, in cholesky\n    r = gufunc(a, signature=signature, extobj=extobj)\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py\", line 92, in _raise_linalgerror_nonposdef\n    raise LinAlgError(\"Matrix is not positive definite\")\nnumpy.linalg.LinAlgError: Matrix is not positive definite\n.", "error": "", "parent_ids": ["c5162116-f9c0-47f7-a620-1e38f7a8725d"], "operator": null, "metadata": {}}
{"id": "42bfc3f1-4024-45b9-a6d2-0e159549e326", "fitness": -Infinity, "name": "OrthogonalCMAES", "description": "CMA-ES with orthogonal sampling for improved exploration and exploitation, combined with dynamic population sizing and a more robust restart mechanism.", "code": "import numpy as np\n\nclass OrthogonalCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov=None, mu_factor=0.25, sigma0=0.5, memory_size=100, restart_trigger=1e-12, orthogonal_sampling=True):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov = c_cov if c_cov is not None else (1 / self.mu) * (2 / ((self.dim + np.sqrt(2))**2))\n        self.c_cov_mu = 0.25 + self.c_cov\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.evals = 0\n        self.restart_trigger = restart_trigger\n        self.orthogonal_sampling = orthogonal_sampling\n\n    def __call__(self, func):\n        self.evals = 0\n        while self.evals < self.budget:\n            # Adaptive Population Size\n            self.popsize = 4 + int(3 * np.log(self.dim))\n            self.mu = int(self.popsize * 0.25)\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights /= np.sum(self.weights)\n            \n            # Sample population\n            if self.orthogonal_sampling:\n                Z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n                Q, _ = np.linalg.qr(Z)  # Orthogonal basis\n                z = Q\n            else:\n                z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            \n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ C_sqrt.T\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ np.linalg.inv(C_sqrt).T\n            self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC = (self.c_cov_mu / self.mu) * (self.pc[:, None] @ self.pc[None, :])\n            for i in range(self.mu):\n                dC += (self.c_cov / self.mu) * ((x[i] - m_old)[:, None] @ (x[i] - m_old)[None, :]) / self.sigma**2\n                \n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + dC\n            \n            # Ensure positive definiteness\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Archive for diversity (optional)\n            for xi in x:\n                self.archive.append(xi)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[-self.archive_size:]\n                \n            # Restart mechanism: Check stagnation in x_opt or sigma\n            if self.sigma < self.restart_trigger or np.linalg.norm(self.x_opt - self.m) < 1e-8:\n                self.m = np.mean(np.array(self.archive), axis=0) if self.archive else np.zeros(self.dim)\n                self.sigma = sigma0\n                self.ps = np.zeros(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.C = np.eye(self.dim)\n                self.archive = []  # Clear archive after restart\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 101, in __call__\nNameError: name 'sigma0' is not defined. Did you mean: 'hsigma'?\n.", "error": "", "parent_ids": ["c2bbc764-4349-4e06-a097-2b3747af8c88"], "operator": null, "metadata": {}}
{"id": "019e51e4-4785-4467-b98f-286c81bc1150", "fitness": -Infinity, "name": "OrthogonalCMAES", "description": "CMA-ES with orthogonal sampling for better exploration, spectral correction for covariance matrix adaptation, and adaptive restart mechanism based on stagnation detection.", "code": "import numpy as np\n\nclass OrthogonalCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov=None, mu_factor=0.25, sigma0=0.5, memory_size=100, restart_trigger=1e-12, orthogonal_sampling=True, spectral_correction=True):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov = c_cov if c_cov is not None else (1 / self.mu) * (2 / ((self.dim + np.sqrt(2))**2))\n        self.c_cov_mu = 0.25 + self.c_cov\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.evals = 0\n        self.restart_trigger = restart_trigger\n        self.orthogonal_sampling = orthogonal_sampling\n        self.spectral_correction = spectral_correction\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 50\n\n    def __call__(self, func):\n        self.evals = 0\n        self.stagnation_counter = 0\n        last_f_opt = np.Inf\n\n        while self.evals < self.budget:\n            # Adaptive Population Size\n            self.popsize = 4 + int(3 * np.log(self.dim))\n            self.mu = int(self.popsize * 0.25)\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights /= np.sum(self.weights)\n            \n            # Sample population\n            if self.orthogonal_sampling:\n                Z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n                Q, _ = np.linalg.qr(Z)\n                z = Q\n            else:\n                z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ C_sqrt.T\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n            \n            # Stagnation Check\n            if abs(self.f_opt - last_f_opt) < 1e-9:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n            last_f_opt = self.f_opt\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ np.linalg.inv(C_sqrt).T\n            self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC = (self.c_cov_mu / self.mu) * (self.pc[:, None] @ self.pc[None, :])\n            for i in range(self.mu):\n                dC += (self.c_cov / self.mu) * ((x[i] - m_old)[:, None] @ (x[i] - m_old)[None, :]) / self.sigma**2\n                \n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + dC\n            \n            # Spectral Correction\n            if self.spectral_correction:\n                try:\n                    D, B = np.linalg.eig(self.C)\n                    D = np.real(D)\n                    D[D < 1e-10] = 1e-10  # Prevent near-zero eigenvalues\n                    self.C = B @ np.diag(D) @ B.T\n                except np.linalg.LinAlgError:\n                    self.C = np.eye(self.dim)\n\n            # Ensure positive definiteness\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Archive for diversity (optional)\n            for xi in x:\n                self.archive.append(xi)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[-self.archive_size:]\n                \n            # Restart mechanism\n            if self.sigma < self.restart_trigger or self.stagnation_counter > self.stagnation_threshold:\n                self.m = np.mean(np.array(self.archive), axis=0) if self.archive else np.zeros(self.dim)\n                self.sigma = sigma0\n                self.ps = np.zeros(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.C = np.eye(self.dim)\n                self.stagnation_counter = 0 # Reset stagnation counter\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 127, in __call__\nNameError: name 'sigma0' is not defined. Did you mean: 'hsigma'?\n.", "error": "", "parent_ids": ["c2bbc764-4349-4e06-a097-2b3747af8c88"], "operator": null, "metadata": {}}
{"id": "29d31ec6-a8ed-4788-a9a3-648cf58dc559", "fitness": -Infinity, "name": "AdaptiveVelocityPSO_Enhanced", "description": "Enhanced Adaptive Velocity PSO with a novel velocity clamping strategy based on the population diversity and a mutation operator to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveVelocityPSO_Enhanced:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.5, c2=1.5, w_max=0.9, w_min=0.4, local_search_iterations=5, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.w_max = w_max\n        self.w_min = w_min\n        self.local_search_iterations = local_search_iterations\n        self.stagnation_threshold = stagnation_threshold\n        self.restart_percentage = 0.7\n        self.exploration_probability = 0.1\n        self.orthogonal_learning_percentage = 0.2\n        self.velocity_clamping_threshold = 0.9 # Increased for more conservative clamping\n        self.mutation_rate = 0.01 # Probability of mutation\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.zeros((self.pop_size, self.dim)) # Initialize velocities to zero\n        self.fitness = np.array([func(x) for x in self.population])\n        self.pbest_positions = self.population.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_index = np.argmin(self.fitness)\n        self.gbest_position = self.population[self.gbest_index].copy()\n        self.gbest_fitness = self.fitness[self.gbest_index]\n\n        eval_count = self.pop_size\n        stagnation_counter = 0\n\n        while eval_count < self.budget:\n            # Adaptive Inertia Weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n            # Adaptive Acceleration Coefficients\n            c1 = self.c1 + (1 - (eval_count / self.budget)) * 0.5\n            c2 = self.c2 + (eval_count / self.budget) * 0.5\n\n            # Calculate Population Diversity\n            diversity = np.std(self.population)\n\n            # Adaptive Velocity Clamping based on Diversity\n            max_velocity = self.velocity_clamping_threshold * diversity\n            min_velocity = -max_velocity\n\n\n            for i in range(self.pop_size):\n                # Exploration Move\n                if np.random.rand() < self.exploration_probability:\n                    self.population[i] = np.random.uniform(lb, ub, size=self.dim)\n                    self.velocities[i] = np.random.uniform(min_velocity, max_velocity, size=self.dim)\n                else:\n                    # Update Velocity\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    self.velocities[i] = w * self.velocities[i] + \\\n                                         c1 * r1 * (self.pbest_positions[i] - self.population[i]) + \\\n                                         c2 * r2 * (self.gbest_position - self.population[i])\n\n                    # Velocity Clamping\n                    self.velocities[i] = np.clip(self.velocities[i], min_velocity, max_velocity)\n\n                    # Update Position\n                    self.population[i] = self.population[i] + self.velocities[i]\n\n                    # Boundary Handling\n                    self.population[i] = np.clip(self.population[i], lb, ub)\n\n                    # Mutation\n                    for j in range(self.dim):\n                        if np.random.rand() < self.mutation_rate:\n                            self.population[i][j] = np.random.uniform(lb, ub)\n\n                # Evaluate Fitness\n                fitness = func(self.population[i])\n                eval_count += 1\n\n                # Update Personal Best\n                if fitness < self.pbest_fitness[i]:\n                    self.pbest_fitness[i] = fitness\n                    self.pbest_positions[i] = self.population[i].copy()\n\n                    # Update Global Best\n                    if fitness < self.gbest_fitness:\n                        self.gbest_fitness = fitness\n                        self.gbest_position = self.population[i].copy()\n                        stagnation_counter = 0\n\n                else:\n                    stagnation_counter += 1\n\n                # Local Search\n                if eval_count < self.budget:\n                    x_current = self.population[i].copy()\n                    f_current = fitness\n\n                    for _ in range(self.local_search_iterations):\n                        perturbation = np.random.normal(0, 0.01 * (ub - lb), size=self.dim)\n                        x_new = x_current + perturbation\n                        x_new = np.clip(x_new, lb, ub)\n                        f_new = func(x_new)\n                        eval_count += 1\n\n                        if f_new < f_current:\n                            x_current = x_new.copy()\n                            f_current = f_new\n\n                        if eval_count >= self.budget:\n                            break\n\n                    self.population[i] = x_current\n                    self.fitness[i] = f_current\n\n                    if f_current < self.pbest_fitness[i]:\n                        self.pbest_fitness[i] = f_current\n                        self.pbest_positions[i] = self.population[i].copy()\n\n                        if f_current < self.gbest_fitness:\n                            self.gbest_fitness = f_current\n                            self.gbest_position = self.population[i].copy()\n                            stagnation_counter = 0\n\n            # Orthogonal Learning\n            num_orthogonal = int(self.orthogonal_learning_percentage * self.pop_size)\n            indices_orthogonal = np.random.choice(self.pop_size, size=num_orthogonal, replace=False)\n\n            for idx in indices_orthogonal:\n                basis = np.random.normal(0, 1, size=(self.dim, self.dim))\n                Q, _ = np.linalg.qr(basis)\n\n                step_sizes = np.random.uniform(-0.05 * (ub - lb), 0.05 * (ub - lb), size=self.dim)\n\n                for j in range(self.dim):\n                    x_new = self.population[idx] + step_sizes[j] * Q[:, j]\n                    x_new = np.clip(x_new, lb, ub)\n                    f_new = func(x_new)\n                    eval_count += 1\n\n                    if f_new < self.fitness[idx]:\n                        self.population[idx] = x_new.copy()\n                        self.fitness[idx] = f_new\n\n                        if f_new < self.pbest_fitness[idx]:\n                            self.pbest_fitness[idx] = f_new\n                            self.pbest_positions[idx] = self.population[idx].copy()\n\n                            if f_new < self.gbest_fitness:\n                                self.gbest_fitness = f_new\n                                self.gbest_position = self.population[idx].copy()\n                                stagnation_counter = 0\n\n                    if eval_count >= self.budget:\n                        break\n\n                if eval_count >= self.budget:\n                    break\n\n\n            # Stagnation Restart Mechanism\n            if stagnation_counter > self.stagnation_threshold:\n                num_to_restart = int(self.restart_percentage * self.pop_size)\n                indices_to_restart = np.random.choice(self.pop_size, size=num_to_restart, replace=False)\n\n                for idx in indices_to_restart:\n                    self.population[idx] = np.random.uniform(lb, ub, size=self.dim)\n                    self.velocities[idx] = np.random.uniform(min_velocity, max_velocity, size=self.dim)\n                    self.fitness[idx] = func(self.population[idx])\n                    eval_count += 1\n\n                    self.pbest_positions[idx] = self.population[idx].copy()\n                    self.pbest_fitness[idx] = self.fitness[idx]\n\n                    if self.fitness[idx] < self.gbest_fitness:\n                        self.gbest_fitness = self.fitness[idx]\n                        self.gbest_position = self.population[idx].copy()\n\n                stagnation_counter = 0\n\n            if self.gbest_fitness < self.f_opt:\n                self.f_opt = self.gbest_fitness\n                self.x_opt = self.gbest_position.copy()\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occured: TypeError: only size-1 arrays can be converted to Python scalars\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 79, in __call__\nValueError: setting an array element with a sequence.\n.", "error": "", "parent_ids": ["31ee3470-014a-4f74-88be-03f7fea5619f"], "operator": null, "metadata": {}}
{"id": "63d7dfa0-85df-42d3-8c1b-79d4f55ac7f7", "fitness": -Infinity, "name": "CMAES", "description": "Enhanced CMA-ES with adaptive step size control, active covariance matrix adaptation, and a more robust restart strategy based on stagnation detection for improved exploration and exploitation.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov=None, mu_factor=0.25, sigma0=0.5, memory_size=100, restart_trigger=1e-12, stagnation_threshold=10):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov = c_cov if c_cov is not None else (1 / self.mu) * (2 / ((self.dim + np.sqrt(2))**2))\n        self.c_cov_mu = 0.25 + self.c_cov\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.evals = 0\n        self.restart_trigger = restart_trigger\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_f_history = []\n\n    def __call__(self, func):\n        self.evals = 0\n        self.stagnation_counter = 0\n        self.best_f_history = []\n\n        while self.evals < self.budget:\n            # Adaptive Population Size\n            self.popsize = 4 + int(3 * np.log(self.dim))\n            self.mu = int(self.popsize * 0.25)\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights /= np.sum(self.weights)\n            \n            # Sample population\n            z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ C_sqrt.T\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                self.stagnation_counter = 0  # Reset stagnation counter when finding a better solution\n            else:\n                self.stagnation_counter += 1\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ np.linalg.inv(C_sqrt).T\n            self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC = (self.c_cov_mu / self.mu) * (self.pc[:, None] @ self.pc[None, :])\n            \n            # Active CMA\n            w_mask = self.weights > 0\n            \n            for i in range(self.mu):\n                d = (x[i] - m_old) / self.sigma\n                dC += (self.c_cov / self.mu) * self.weights[i] * (d[:, None] @ d[None, :])\n\n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + dC\n            \n            # Ensure positive definiteness\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Adaptive step size control\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Archive for diversity (optional)\n            for xi in x:\n                self.archive.append(xi)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[-self.archive_size:]\n                \n            # Restart mechanism based on stagnation\n            if self.sigma < self.restart_trigger or self.stagnation_counter > self.stagnation_threshold:\n                self.m = np.mean(np.array(self.archive), axis=0) if self.archive else np.zeros(self.dim)\n                self.sigma = sigma0\n                self.ps = np.zeros(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.C = np.eye(self.dim)\n                self.stagnation_counter = 0 # Reset stagnation counter\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 108, in __call__\nNameError: name 'sigma0' is not defined. Did you mean: 'hsigma'?\n.", "error": "", "parent_ids": ["c2bbc764-4349-4e06-a097-2b3747af8c88"], "operator": null, "metadata": {}}
{"id": "2fea5b6b-7b41-44e8-8747-ff042ea0da42", "fitness": 0.0, "name": "AdaptiveVelocityPSO_Enhanced", "description": "Enhanced Adaptive Velocity PSO with orthogonal learning using a dynamically adjusted learning rate, improved stagnation detection and a more effective restart strategy.", "code": "import numpy as np\n\nclass AdaptiveVelocityPSO_Enhanced:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.5, c2=1.5, w_max=0.9, w_min=0.4, local_search_iterations=5, stagnation_threshold=500, stagnation_multiplier=1.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.w_max = w_max\n        self.w_min = w_min\n        self.local_search_iterations = local_search_iterations\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_multiplier = stagnation_multiplier #Factor to increase threshold\n        self.restart_percentage = 0.7\n        self.exploration_probability = 0.1\n        self.orthogonal_learning_percentage = 0.2\n        self.min_velocity = -0.1 * (5.0 - (-5.0))\n        self.max_velocity = 0.1 * (5.0 - (-5.0))\n        self.orthogonal_learning_rate = 0.05 # Initial learning rate for orthogonal learning\n        self.orthogonal_learning_decay = 0.95 # Decay rate for orthogonal learning\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(self.min_velocity, self.max_velocity, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.pbest_positions = self.population.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_index = np.argmin(self.fitness)\n        self.gbest_position = self.population[self.gbest_index].copy()\n        self.gbest_fitness = self.fitness[self.gbest_index]\n\n        eval_count = self.pop_size\n        stagnation_counter = 0\n        current_stagnation_threshold = self.stagnation_threshold\n\n        while eval_count < self.budget:\n            # Adaptive Inertia Weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n            # Adaptive Acceleration Coefficients\n            c1 = self.c1 + (1 - (eval_count / self.budget)) * 0.5\n            c2 = self.c2 + (eval_count / self.budget) * 0.5\n\n            for i in range(self.pop_size):\n                # Exploration Move\n                if np.random.rand() < self.exploration_probability:\n                    self.population[i] = np.random.uniform(lb, ub, size=self.dim)\n                    self.velocities[i] = np.random.uniform(self.min_velocity, self.max_velocity, size=self.dim)\n                else:\n                    # Update Velocity\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    self.velocities[i] = w * self.velocities[i] + \\\n                                         c1 * r1 * (self.pbest_positions[i] - self.population[i]) + \\\n                                         c2 * r2 * (self.gbest_position - self.population[i])\n\n                    # Limit velocity\n                    self.velocities[i] = np.clip(self.velocities[i], self.min_velocity, self.max_velocity)\n\n                    # Update Position\n                    self.population[i] = self.population[i] + self.velocities[i]\n\n                    # Boundary Handling\n                    self.population[i] = np.clip(self.population[i], lb, ub)\n\n\n                # Evaluate Fitness\n                fitness = func(self.population[i])\n                eval_count += 1\n\n                # Update Personal Best\n                if fitness < self.pbest_fitness[i]:\n                    self.pbest_fitness[i] = fitness\n                    self.pbest_positions[i] = self.population[i].copy()\n\n                    # Update Global Best\n                    if fitness < self.gbest_fitness:\n                        self.gbest_fitness = fitness\n                        self.gbest_position = self.population[i].copy()\n                        stagnation_counter = 0\n\n                else:\n                    stagnation_counter += 1\n\n                # Local Search\n                if eval_count < self.budget:\n                    x_current = self.population[i].copy()\n                    f_current = fitness\n\n                    for _ in range(self.local_search_iterations):\n                        perturbation = np.random.normal(0, 0.01 * (ub - lb), size=self.dim)\n                        x_new = x_current + perturbation\n                        x_new = np.clip(x_new, lb, ub)\n                        f_new = func(x_new)\n                        eval_count += 1\n\n                        if f_new < f_current:\n                            x_current = x_new.copy()\n                            f_current = f_new\n\n                        if eval_count >= self.budget:\n                            break\n\n                    self.population[i] = x_current\n                    self.fitness[i] = f_current\n\n                    if f_current < self.pbest_fitness[i]:\n                        self.pbest_fitness[i] = f_current\n                        self.pbest_positions[i] = self.population[i].copy()\n\n                        if f_current < self.gbest_fitness:\n                            self.gbest_fitness = f_current\n                            self.gbest_position = self.population[i].copy()\n                            stagnation_counter = 0\n\n            # Orthogonal Learning\n            num_orthogonal = int(self.orthogonal_learning_percentage * self.pop_size)\n            indices_orthogonal = np.random.choice(self.pop_size, size=num_orthogonal, replace=False)\n\n            for idx in indices_orthogonal:\n                basis = np.random.normal(0, 1, size=(self.dim, self.dim))\n                Q, _ = np.linalg.qr(basis)  # Orthogonal basis\n\n                step_sizes = np.random.uniform(-self.orthogonal_learning_rate * (ub - lb), self.orthogonal_learning_rate * (ub - lb), size=self.dim)  # Smaller step sizes, decaying\n\n                for j in range(self.dim):\n                    x_new = self.population[idx] + step_sizes[j] * Q[:, j]\n                    x_new = np.clip(x_new, lb, ub)\n                    f_new = func(x_new)\n                    eval_count += 1\n\n                    if f_new < self.fitness[idx]:\n                        self.population[idx] = x_new.copy()\n                        self.fitness[idx] = f_new\n\n                        if f_new < self.pbest_fitness[idx]:\n                            self.pbest_fitness[idx] = f_new\n                            self.pbest_positions[idx] = self.population[idx].copy()\n\n                            if f_new < self.gbest_fitness:\n                                self.gbest_fitness = f_new\n                                self.gbest_position = self.population[idx].copy()\n                                stagnation_counter = 0\n\n                    if eval_count >= self.budget:\n                        break\n\n                if eval_count >= self.budget:\n                    break\n                \n            self.orthogonal_learning_rate *= self.orthogonal_learning_decay # Decay learning rate\n\n            # Stagnation Restart Mechanism\n            if stagnation_counter > current_stagnation_threshold:\n                num_to_restart = int(self.restart_percentage * self.pop_size)\n                indices_to_restart = np.random.choice(self.pop_size, size=num_to_restart, replace=False)\n\n                for idx in indices_to_restart:\n                    self.population[idx] = np.random.uniform(lb, ub, size=self.dim)\n                    self.velocities[idx] = np.random.uniform(self.min_velocity, self.max_velocity, size=self.dim)\n                    self.fitness[idx] = func(self.population[idx])\n                    eval_count += 1\n\n                    self.pbest_positions[idx] = self.population[idx].copy()\n                    self.pbest_fitness[idx] = self.fitness[idx]\n\n                    if self.fitness[idx] < self.gbest_fitness:\n                        self.gbest_fitness = self.fitness[idx]\n                        self.gbest_position = self.population[idx].copy()\n\n                stagnation_counter = 0\n                current_stagnation_threshold *= self.stagnation_multiplier  # Increase stagnation threshold\n\n            if self.gbest_fitness < self.f_opt:\n                self.f_opt = self.gbest_fitness\n                self.x_opt = self.gbest_position.copy()\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveVelocityPSO_Enhanced scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["31ee3470-014a-4f74-88be-03f7fea5619f"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "9f1dca90-819d-4e93-93b2-b9461e6147c2", "fitness": 0.1305045905384777, "name": "CMAES", "description": "CMA-ES with dynamic population size adjustment based on the optimization progress and a threshold-based restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov_rank_one=None, c_cov_rank_mu=None, mu_factor=0.25, sigma0=0.5, memory_size=100, popsize_factor=2):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 0.15\n        self.c_cov_rank_mu = c_cov_rank_mu if c_cov_rank_mu is not None else 0.15\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.popsize_factor = popsize_factor\n        self.min_popsize = 4 + int(3 * np.log(self.dim))\n        self.max_popsize = int(self.dim * self.popsize_factor)\n\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 20 # Number of iterations with minimal improvement before triggering restart\n        self.last_f_opt = np.Inf\n\n    def __call__(self, func):\n        evals = 0\n        while evals < self.budget:\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ C_sqrt.T\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                self.stagnation_counter = 0 # Reset stagnation counter\n            else:\n                self.stagnation_counter +=1\n\n            # Dynamic Population Size Adjustment\n            if self.stagnation_counter > self.stagnation_threshold and self.popsize < self.max_popsize:\n                self.popsize = min(self.popsize * 2, self.max_popsize)\n                self.mu = int(self.popsize * 0.25)\n                self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n                self.weights /= np.sum(self.weights)\n                self.stagnation_threshold *=1.2 #increase stagnation threshold\n                self.stagnation_counter = 0 #reset counter\n                \n            if self.stagnation_counter > self.stagnation_threshold * 2 and self.popsize > self.min_popsize: # reduce population size if stagnation continues.\n                self.popsize = max(self.popsize // 2, self.min_popsize)\n                self.mu = int(self.popsize * 0.25)\n                self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n                self.weights /= np.sum(self.weights)\n                self.stagnation_threshold = max(10, self.stagnation_threshold/1.2)\n                self.stagnation_counter = 0 #reset counter\n\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ np.linalg.inv(C_sqrt).T\n            self.pc = (1 - self.c_cov_rank_one) * self.pc + np.sqrt(self.c_cov_rank_one * (2 - self.c_cov_rank_one)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC_rank_one = self.c_cov_rank_one * (self.pc[:, None] @ self.pc[None, :])\n            dC_rank_mu = self.c_cov_rank_mu * np.sum(self.weights[:, None, None] * ((x[:self.mu] - m_old)[:, :, None] @ (x[:self.mu] - m_old)[:, None, :]) / self.sigma**2, axis=0)\n                \n            self.C = (1 - self.c_cov_rank_one - self.c_cov_rank_mu) * self.C + dC_rank_one + dC_rank_mu\n            \n            # Ensure positive definiteness\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Simplified archive handling: keep only best from each generation.\n            self.archive.append(x[0])\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[-self.archive_size:]\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold * 3: # More conservative stagnation check before restart\n                self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Reset to a random point within bounds\n                self.sigma = sigma0 # Reset step size\n                self.ps = np.zeros(self.dim) # Reset evolution paths\n                self.pc = np.zeros(self.dim)\n                self.C = np.eye(self.dim)  # Reset covariance matrix\n                self.stagnation_counter = 0  # Reset stagnation counter\n                self.stagnation_threshold = 20\n\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm CMAES scored 0.131 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c5162116-f9c0-47f7-a620-1e38f7a8725d"], "operator": null, "metadata": {"aucs": [0.040955448344339174, 0.09116528403742885, 0.2650293394503612, 0.10053420422431514, 0.10518169972807478, 0.130019658217585, 0.1508087298473776, 0.12181576920242754, 0.13569142570384995, 0.11796157092453508, 0.1500791957659161, 0.16821826956942443, 0.11774132734564358, 0.10063542865426078, 0.11128078082347004, 0.20929467043408645, 0.11111747891590096, 0.14324397998255067, 0.10256449636638731, 0.1367530532316199]}}
{"id": "a402a240-bb6c-428c-b591-cce73557d65e", "fitness": 0.130570464372129, "name": "CMAES_Adaptive", "description": "CMA-ES with rank-one and rank-mu updates, adaptive covariance matrix decomposition, and a dynamic sigma adaptation based on the fitness landscape curvature, enhanced archive usage with fitness-based selection.", "code": "import numpy as np\n\nclass CMAES_Adaptive:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov_rank_one=None, c_cov_rank_mu=None, mu_factor=0.25, sigma0=0.5, memory_size=100, curvature_adaptation=True):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 0.15\n        self.c_cov_rank_mu = c_cov_rank_mu if c_cov_rank_mu is not None else 0.15\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.curvature_adaptation = curvature_adaptation\n        self.eigenvalues = np.ones(self.dim)  # Initialize eigenvalues\n        self.B = np.eye(self.dim) # Initialize rotation matrix\n\n    def update_decomposition(self):\n        try:\n            self.eigenvalues, self.B = np.linalg.eigh(self.C)  # Eigen decomposition\n            self.eigenvalues = np.maximum(self.eigenvalues, 1e-16)  # Ensure eigenvalues are positive\n        except np.linalg.LinAlgError:\n            self.C = np.eye(self.dim)\n            self.eigenvalues = np.ones(self.dim)\n            self.B = np.eye(self.dim)\n\n    def __call__(self, func):\n        evals = 0\n        while evals < self.budget:\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n\n            # Use rotation matrix and eigenvalues directly\n            x = self.m + self.sigma * (z @ self.B @ np.diag(self.eigenvalues**0.5))\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ self.B @ np.diag(self.eigenvalues**-0.5)\n            self.pc = (1 - self.c_cov_rank_one) * self.pc + np.sqrt(self.c_cov_rank_one * (2 - self.c_cov_rank_one)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC_rank_one = self.c_cov_rank_one * (self.pc[:, None] @ self.pc[None, :])\n            dC_rank_mu = self.c_cov_rank_mu * np.sum(self.weights[:, None, None] * ((x[:self.mu] - m_old)[:, :, None] @ (x[:self.mu] - m_old)[:, None, :]) / self.sigma**2, axis=0)\n                \n            self.C = (1 - self.c_cov_rank_one - self.c_cov_rank_mu) * self.C + dC_rank_one + dC_rank_mu\n            \n            # Ensure positive definiteness and update decomposition\n            self.update_decomposition()\n\n            # Adaptive step size based on curvature\n            if self.curvature_adaptation:\n                condition_number = np.max(self.eigenvalues) / np.min(self.eigenvalues)\n                self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1) + 0.05 * (condition_number - 1)) # Condition number regularization\n\n            else:\n                 self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n\n            # Simplified archive handling: keep only best from each generation.\n            self.archive.append((x[0], f[0])) # Store fitness as well\n            if len(self.archive) > self.archive_size:\n                self.archive.sort(key=lambda item: item[1]) # sort by fitness\n                self.archive = self.archive[:self.archive_size]  # Keep best\n\n        if self.archive:\n            best_archived_solution = min(self.archive, key=lambda item: item[1])\n            if best_archived_solution[1] < self.f_opt:\n                 self.f_opt = best_archived_solution[1]\n                 self.x_opt = best_archived_solution[0]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm CMAES_Adaptive scored 0.131 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c5162116-f9c0-47f7-a620-1e38f7a8725d"], "operator": null, "metadata": {"aucs": [0.03581136466290247, 0.11016541368092747, 0.2521093241433334, 0.09831080651917345, 0.092757109898288, 0.1349170086428394, 0.16594527353348965, 0.12956155279109938, 0.1381442910128059, 0.11483019190282995, 0.14685755897211472, 0.15488227357081763, 0.10933425655754037, 0.09115458861952941, 0.11151495569401393, 0.21577081786754626, 0.12387537643810265, 0.13916991849701732, 0.10589321638375859, 0.14040398805444987]}}
{"id": "0148a31e-1044-47d2-923f-599c3eacae5d", "fitness": 0.12795104929198872, "name": "CMAES", "description": "Improved CMA-ES with a more robust restart mechanism using a CMA-ES-based archive initialization and adaptive step size dampening.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov=None, mu_factor=0.25, sigma0=0.5, memory_size=100, restart_trigger=1e-12, restart_strategy='archive'):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov = c_cov if c_cov is not None else (1 / self.mu) * (2 / ((self.dim + np.sqrt(2))**2))\n        self.c_cov_mu = 0.25 + self.c_cov\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.evals = 0\n        self.restart_trigger = restart_trigger\n        self.restart_strategy = restart_strategy\n        self.damps_adapt = 1.0  # adaptive dampening factor\n\n    def __call__(self, func):\n        self.evals = 0\n        while self.evals < self.budget:\n            # Adaptive Population Size\n            self.popsize = 4 + int(3 * np.log(self.dim))\n            self.mu = int(self.popsize * 0.25)\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights /= np.sum(self.weights)\n            \n            # Sample population\n            z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ C_sqrt.T\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ np.linalg.inv(C_sqrt).T\n            self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC = (self.c_cov_mu / self.mu) * (self.pc[:, None] @ self.pc[None, :])\n            for i in range(self.mu):\n                dC += (self.c_cov / self.mu) * ((x[i] - m_old)[:, None] @ (x[i] - m_old)[None, :]) / self.sigma**2\n                \n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + dC\n            \n            # Ensure positive definiteness\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / (self.damps * self.damps_adapt)) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            \n            # Adaptive Dampening\n            if np.linalg.norm(self.ps) / self.chiN > 1:\n                self.damps_adapt *= 0.8  # Reduce dampening when step size grows too fast\n            else:\n                self.damps_adapt = min(1.0, self.damps_adapt * 1.2) # Increase dampening when step size is shrinking\n\n\n            # Archive for diversity (optional)\n            for xi in x:\n                self.archive.append(xi)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[-self.archive_size:]\n                \n            # Restart mechanism\n            if self.sigma < self.restart_trigger:\n                if self.restart_strategy == 'archive':\n                    if self.archive:\n                        # CMA-ES initialization using archive\n                        archive_array = np.array(self.archive)\n                        self.m = np.mean(archive_array, axis=0)\n                        self.C = np.cov(archive_array, rowvar=False)\n                        # Ensure covariance matrix is positive semi-definite\n                        try:\n                            np.linalg.cholesky(self.C)\n                        except np.linalg.LinAlgError:\n                            self.C = np.eye(self.dim)  # Reset to identity if singular\n                    else:\n                        self.m = np.zeros(self.dim) # Fallback: Reset to zero\n                        self.C = np.eye(self.dim)\n                else:\n                    self.m = np.zeros(self.dim) # Default reset to zero\n                self.sigma = sigma0\n                self.ps = np.zeros(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.damps_adapt = 1.0  # Reset adaptive dampening\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm CMAES scored 0.128 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c2bbc764-4349-4e06-a097-2b3747af8c88"], "operator": null, "metadata": {"aucs": [0.028915091727034103, 0.09315425514498388, 0.26116392221130813, 0.09379802081248634, 0.10899833765659728, 0.13397689266262114, 0.16798915092360456, 0.1272149281510221, 0.13799917563500674, 0.12371769960453949, 0.14694790973539607, 0.1692105640415037, 0.04870026693237761, 0.09254431125770823, 0.11204729239526456, 0.20350732983329878, 0.11601242793202893, 0.1405358977782043, 0.10677743899545711, 0.14581007240933164]}}
{"id": "c5654f3e-ce4f-4d00-a5d9-8615c96c09f5", "fitness": 0.13326260873912213, "name": "CMAES_Enhanced", "description": "CMA-ES with improved exploration through orthogonal sampling, adaptive step size control using a weighted average of past successful steps, and dynamic archive size adjustment based on the optimization progress.", "code": "import numpy as np\n\nclass CMAES_Enhanced:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov=None, mu_factor=0.25, sigma0=0.5, memory_size=100, restart_trigger=1e-12, orthogonal_sampling=True):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov = c_cov if c_cov is not None else (1 / self.mu) * (2 / ((self.dim + np.sqrt(2))**2))\n        self.c_cov_mu = 0.25 + self.c_cov\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.evals = 0\n        self.restart_trigger = restart_trigger\n        self.orthogonal_sampling = orthogonal_sampling\n        self.successful_sigma_updates = []\n\n    def __call__(self, func):\n        self.evals = 0\n        self.successful_sigma_updates = []\n        while self.evals < self.budget:\n            # Adaptive Population Size\n            self.popsize = 4 + int(3 * np.log(self.dim))\n            self.mu = int(self.popsize * 0.25)\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights /= np.sum(self.weights)\n            \n            # Sample population\n            if self.orthogonal_sampling:\n                z = self._orthogonal_sampling(self.popsize, self.dim)\n            else:\n                z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ C_sqrt.T\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ np.linalg.inv(C_sqrt).T\n            self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC = (self.c_cov_mu / self.mu) * (self.pc[:, None] @ self.pc[None, :])\n            for i in range(self.mu):\n                dC += (self.c_cov / self.mu) * ((x[i] - m_old)[:, None] @ (x[i] - m_old)[None, :]) / self.sigma**2\n                \n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + dC\n            \n            # Ensure positive definiteness\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Adaptive step size control\n            old_sigma = self.sigma\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            \n            # Store successful sigma updates\n            if self.f_opt < np.inf: # Check if a better solution has been found\n                self.successful_sigma_updates.append((old_sigma, self.sigma))\n\n            # Weighted average of successful step sizes\n            if len(self.successful_sigma_updates) > 5:\n                 weights = np.exp(-np.arange(len(self.successful_sigma_updates)) / 2.0)\n                 weights /= np.sum(weights)\n                 weighted_sigma = np.sum([w * s[1] for w, s in zip(weights[::-1], self.successful_sigma_updates[-len(weights):])])\n                 self.sigma = weighted_sigma\n\n\n            # Archive for diversity (optional)\n            for xi in x:\n                self.archive.append(xi)\n            \n            # Dynamic archive size\n            self.archive_size = min(int(self.budget / 10), 100 + int(self.evals / self.budget * 200))\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[-self.archive_size:]\n                \n            # Restart mechanism\n            if self.sigma < self.restart_trigger:\n                self.m = np.mean(np.array(self.archive), axis=0) if self.archive else np.zeros(self.dim)\n                self.sigma = sigma0\n                self.ps = np.zeros(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.C = np.eye(self.dim)\n        \n        return self.f_opt, self.x_opt\n\n    def _orthogonal_sampling(self, popsize, dim):\n        # Generate standard normal samples\n        z = np.random.normal(0, 1, size=(popsize, dim))\n\n        # Perform QR decomposition\n        Q, R = np.linalg.qr(z)\n\n        # Normalize columns to have unit length\n        for i in range(popsize):\n            Q[i, :] /= np.linalg.norm(Q[i, :])\n\n        return Q", "configspace": "", "generation": 2, "feedback": "The algorithm CMAES_Enhanced scored 0.133 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c2bbc764-4349-4e06-a097-2b3747af8c88"], "operator": null, "metadata": {"aucs": [0.03453590704788223, 0.08678530976745846, 0.25656997257535963, 0.0912172167275701, 0.09149365302721513, 0.13907193568520182, 0.1600897870763247, 0.11151005266231295, 0.1329334488940589, 0.12332259844454907, 0.14874247280899833, 0.16652126428245317, 0.2480163616947808, 0.08438388983663625, 0.10896367061659418, 0.19899381885033185, 0.10863090513593143, 0.13465416133274433, 0.0991148787271321, 0.13970086958890682]}}
{"id": "abe5970a-f045-4702-aba3-1c4a0746854d", "fitness": 0.30089488598949926, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with momentum-based F/CR updates, a diversity maintenance strategy using crowding distance, and adaptive population sizing.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, pop_adapt_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(4 + 3 * np.log(dim)) # Adaptive population size\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = None\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_beta = 0.9\n        self.pop_adapt_rate = pop_adapt_rate\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutated_population[i] = x1 + self.F * (x2 - x3)\n            \n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n        \n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n            \n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n    \n    def calculate_crowding_distance(self, pop, fitness):\n        distances = np.zeros(len(pop))\n        \n        # Normalize each dimension\n        normalized_pop = (pop - np.min(pop, axis=0)) / (np.max(pop, axis=0) - np.min(pop, axis=0) + 1e-8)\n        \n        for i in range(self.dim):\n            sorted_indices = np.argsort(normalized_pop[:, i])\n            distances[sorted_indices[0]] = np.inf\n            distances[sorted_indices[-1]] = np.inf\n            \n            for j in range(1, len(pop) - 1):\n                distances[sorted_indices[j]] += normalized_pop[sorted_indices[j+1], i] - normalized_pop[sorted_indices[j-1], i]\n        \n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    idx_to_replace = np.random.randint(0, self.archive_size)\n                    self.archive[idx_to_replace] = self.population[i].copy()\n        \n        # Stochastic Ranking Selection\n        combined_population = np.vstack((self.population, crossed_population))\n        combined_fitness = np.concatenate((self.fitness, [func(x) for x in crossed_population]))\n        self.budget -= len(crossed_population)\n        \n        ranked_population, ranked_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n        \n        # Crowding Distance\n        crowding_distances = self.calculate_crowding_distance(ranked_population, ranked_fitness)\n        \n        # Select based on rank and crowding distance\n        selected_indices = np.argsort(-crowding_distances)[:self.pop_size] # Take top pop_size based on crowding distance\n        new_population = ranked_population[selected_indices]\n        new_fitness = ranked_fitness[selected_indices]\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_beta * self.F_momentum + (1 - self.momentum_beta) * mean_F\n            self.CR_momentum = self.momentum_beta * self.CR_momentum + (1 - self.momentum_beta) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Adaptive population size\n        if np.std(new_fitness) < 1e-3:  #Stagnation detection\n            self.pop_size = min(self.pop_size + int(self.pop_adapt_rate * self.dim), 200)\n        else:\n             self.pop_size = max(int(4 + 3 * np.log(self.dim)), int(self.pop_size * (1 - self.pop_adapt_rate)))\n\n        return new_population, new_fitness\n        \n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > self.pop_size:\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.301 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["21d63779-0eb7-47c7-97b6-624fd54332de"], "operator": null, "metadata": {"aucs": [0.1223903010335261, 0.19400780080960245, 0.28926406559497886, 0.2101268366115382, 0.2154668243999136, 0.2718789671562982, 0.2541768664750902, 0.21195917619799431, 0.2029408567361093, 0.1889803762407446, 0.22952515755764447, 0.9987703401251304, 0.22151103824218754, 0.2513949269190435, 0.6315871191269609, 0.3154855583120558, 0.25649619398433665, 0.30714115322973146, 0.172931521061799, 0.4718626399752991]}}
{"id": "57d72ae0-b7d3-41ca-8a47-14d3ef7a6fa8", "fitness": 0.5649496065113633, "name": "AdaptiveDE_Enhanced", "description": "Adaptive Differential Evolution with momentum-based F/CR updates, improved archive handling using crowding distance, and enhanced exploration via a restart mechanism based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveDE_Enhanced:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutated_population[i] = x1 + self.F * (x2 - x3)\n            \n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n        \n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n            \n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > 0:\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            \n            self.best_fitness_history.append(current_best_fitness)\n            \n            if self.check_stagnation():\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE_Enhanced scored 0.565 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["21d63779-0eb7-47c7-97b6-624fd54332de"], "operator": null, "metadata": {"aucs": [0.2051877916363677, 0.28367245938214414, 0.46841305451414683, 0.7629766500628286, 0.6309103496544093, 0.7334103269677481, 0.555195266372871, 0.5521429277730323, 0.6611953200567766, 0.5064588047430707, 0.6618216671945939, 0.9956813019948412, 0.2834038960575209, 0.5531914951727472, 0.7777920399415745, 0.7254690329801905, 0.43252515330188823, 0.7559948735939016, 0.22983490096636894, 0.523714817860243]}}
{"id": "c3507ff3-6dd2-4f87-bd68-74c14abef208", "fitness": -Infinity, "name": "CMAES_Adaptive_Plus", "description": "Adaptive CMA-ES with spectral adaptation, active covariance matrix update, and dynamic population size adjustment based on landscape characteristics, further refining archive usage with age-based diversity.", "code": "import numpy as np\n\nclass CMAES_Adaptive_Plus:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov_rank_one=None, c_cov_rank_mu=None, mu_factor=0.25, sigma0=0.5, memory_size=100, curvature_adaptation=True, active_update=True, dynamic_popsize=True):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 0.15\n        self.c_cov_rank_mu = c_cov_rank_mu if c_cov_rank_mu is not None else 0.15\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.curvature_adaptation = curvature_adaptation\n        self.active_update = active_update\n        self.dynamic_popsize = dynamic_popsize\n        self.eigenvalues = np.ones(self.dim)  # Initialize eigenvalues\n        self.B = np.eye(self.dim) # Initialize rotation matrix\n        self.age = 0 # Age counter\n        self.max_popsize = 2 * self.dim # Dynamic popsize maximum limit\n\n    def update_decomposition(self):\n        try:\n            self.eigenvalues, self.B = np.linalg.eigh(self.C)  # Eigen decomposition\n            self.eigenvalues = np.maximum(self.eigenvalues, 1e-16)  # Ensure eigenvalues are positive\n        except np.linalg.LinAlgError:\n            self.C = np.eye(self.dim)\n            self.eigenvalues = np.ones(self.dim)\n            self.B = np.eye(self.dim)\n\n    def __call__(self, func):\n        evals = 0\n        while evals < self.budget:\n            self.age += 1\n            # Dynamic population size adjustment\n            if self.dynamic_popsize:\n                if self.age % 100 == 0:\n                    if self.sigma < 0.01:  # Check for convergence\n                        self.popsize = min(self.popsize + 1, self.max_popsize)  # Increase if converging\n                    elif self.sigma > 1.0:\n                        self.popsize = max(4 + int(3 * np.log(self.dim)), self.popsize - 1) # Decrease if diverging\n                    self.mu = int(self.popsize * 0.25)\n                    self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n                    self.weights /= np.sum(self.weights)\n\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n\n            # Use rotation matrix and eigenvalues directly\n            x = self.m + self.sigma * (z @ self.B @ np.diag(self.eigenvalues**0.5))\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ self.B @ np.diag(self.eigenvalues**-0.5)\n            self.pc = (1 - self.c_cov_rank_one) * self.pc + np.sqrt(self.c_cov_rank_one * (2 - self.c_cov_rank_one)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC_rank_one = self.c_cov_rank_one * (self.pc[:, None] @ self.pc[None, :])\n            dC_rank_mu = self.c_cov_rank_mu * np.sum(self.weights[:, None, None] * ((x[:self.mu] - m_old)[:, :, None] @ (x[:self.mu] - m_old)[:, None, :]) / self.sigma**2, axis=0)\n            \n            self.C = (1 - self.c_cov_rank_one - self.c_cov_rank_mu) * self.C + dC_rank_one + dC_rank_mu\n\n            # Active Update\n            if self.active_update:\n                w_minus = self.weights * -1\n                w_minus = np.minimum(w_minus, 0)\n                dC_rank_mu_minus = self.c_cov_rank_mu * np.sum(w_minus[:, None, None] * ((x[self.mu:] - m_old)[:, :, None] @ (x[self.mu:] - m_old)[:, None, :]) / self.sigma**2, axis=0)\n                self.C += dC_rank_mu_minus\n\n\n            # Ensure positive definiteness and update decomposition\n            self.update_decomposition()\n\n            # Adaptive step size based on curvature\n            if self.curvature_adaptation:\n                condition_number = np.max(self.eigenvalues) / np.min(self.eigenvalues)\n                self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1) + 0.05 * (condition_number - 1)) # Condition number regularization\n\n            else:\n                 self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n\n            # Simplified archive handling: keep only best from each generation.\n            self.archive.append((x[0], f[0], self.age)) # Store fitness as well and age\n            if len(self.archive) > self.archive_size:\n                # Sort by fitness primarily, then by age (older solutions are penalized)\n                self.archive.sort(key=lambda item: (item[1], -item[2]))\n                self.archive = self.archive[:self.archive_size]  # Keep best\n\n        if self.archive:\n            best_archived_solution = min(self.archive, key=lambda item: item[1])\n            if best_archived_solution[1] < self.f_opt:\n                 self.f_opt = best_archived_solution[1]\n                 self.x_opt = best_archived_solution[0]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 100, in __call__\nValueError: operands could not be broadcast together with shapes (2,1,1) (6,5,5) \n.", "error": "", "parent_ids": ["a402a240-bb6c-428c-b591-cce73557d65e"], "operator": null, "metadata": {}}
{"id": "8b9beecc-b15d-477b-9b35-f1413aed225c", "fitness": -Infinity, "name": "CMAES_Enhanced", "description": "CMA-ES with spectral initialization of the covariance matrix, adaptive learning rate decay, and an enhanced restart strategy based on stagnation and fitness improvement.", "code": "import numpy as np\n\nclass CMAES_Enhanced:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov=None, mu_factor=0.25, sigma0=0.5, memory_size=100, restart_trigger=1e-12, orthogonal_sampling=True, learning_rate_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov = c_cov if c_cov is not None else (1 / self.mu) * (2 / ((self.dim + np.sqrt(2))**2))\n        self.c_cov_mu = 0.25 + self.c_cov\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.evals = 0\n        self.restart_trigger = restart_trigger\n        self.orthogonal_sampling = orthogonal_sampling\n        self.successful_sigma_updates = []\n        self.learning_rate_decay = learning_rate_decay\n        self.eigenvalues = None # Store eigenvalues for spectral initialization\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 10 # Number of iterations without improvement before considering restart\n        self.min_sigma = 1e-16 # Minimum allowed sigma value\n\n\n    def __call__(self, func):\n        self.evals = 0\n        self.successful_sigma_updates = []\n        self.last_f_opt = np.Inf\n        self.stagnation_counter = 0\n        self._spectral_initialization(func) # Initialize covariance matrix based on function landscape\n        \n        while self.evals < self.budget:\n            # Adaptive Population Size\n            self.popsize = 4 + int(3 * np.log(self.dim))\n            self.mu = int(self.popsize * 0.25)\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights /= np.sum(self.weights)\n            \n            # Sample population\n            if self.orthogonal_sampling:\n                z = self._orthogonal_sampling(self.popsize, self.dim)\n            else:\n                z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ C_sqrt.T\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                self.stagnation_counter = 0  # Reset stagnation counter\n            else:\n                self.stagnation_counter += 1\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ np.linalg.inv(C_sqrt).T\n            self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC = (self.c_cov_mu / self.mu) * (self.pc[:, None] @ self.pc[None, :])\n            for i in range(self.mu):\n                dC += (self.c_cov / self.mu) * ((x[i] - m_old)[:, None] @ (x[i] - m_old)[None, :]) / self.sigma**2\n                \n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + dC\n            \n            # Ensure positive definiteness\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n                \n\n            # Adaptive step size control\n            old_sigma = self.sigma\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.sigma = max(self.sigma, self.min_sigma) #Prevent sigma from becoming too small\n\n            # Store successful sigma updates\n            if self.f_opt < np.inf: # Check if a better solution has been found\n                self.successful_sigma_updates.append((old_sigma, self.sigma))\n\n            # Weighted average of successful step sizes\n            if len(self.successful_sigma_updates) > 5:\n                 weights = np.exp(-np.arange(len(self.successful_sigma_updates)) / 2.0)\n                 weights /= np.sum(weights)\n                 weighted_sigma = np.sum([w * s[1] for w, s in zip(weights[::-1], self.successful_sigma_updates[-len(weights):])])\n                 self.sigma = weighted_sigma\n\n\n            # Archive for diversity (optional)\n            for xi in x:\n                self.archive.append(xi)\n            \n            # Dynamic archive size\n            self.archive_size = min(int(self.budget / 10), 100 + int(self.evals / self.budget * 200))\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[-self.archive_size:]\n            \n            #Enhanced Restart mechanism: Stagnation and Fitness Improvement\n            if self.stagnation_counter > self.stagnation_threshold or self.sigma < self.restart_trigger:\n                if self.f_opt < self.last_f_opt: # Significant improvement since last restart\n                    self.last_f_opt = self.f_opt\n                    self.m = self.x_opt.copy() #Keep best solution\n                else:\n                    self.m = np.mean(np.array(self.archive), axis=0) if self.archive else np.zeros(self.dim) #Restart from archive\n\n                self.sigma = self.sigma0 * (self.learning_rate_decay**(self.evals / self.budget)) #Decay sigma\n                self.ps = np.zeros(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.C = np.eye(self.dim)\n                self.stagnation_counter = 0\n\n\n        return self.f_opt, self.x_opt\n\n    def _orthogonal_sampling(self, popsize, dim):\n        # Generate standard normal samples\n        z = np.random.normal(0, 1, size=(popsize, dim))\n\n        # Perform QR decomposition\n        Q, R = np.linalg.qr(z)\n\n        # Normalize columns to have unit length\n        for i in range(popsize):\n            Q[i, :] /= np.linalg.norm(Q[i, :])\n\n        return Q\n    \n    def _spectral_initialization(self, func):\n        # Sample a set of points\n        num_samples = min(1000, self.budget // 10)\n        X = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_samples, self.dim))\n        F = np.array([func(x) for x in X])\n\n        # Compute the gradient at each point (approximate using finite differences)\n        gradients = np.zeros((num_samples, self.dim))\n        h = 1e-5 #Step size for finite differences\n        for i in range(num_samples):\n            for j in range(self.dim):\n                x_plus_h = X[i].copy()\n                x_plus_h[j] += h\n                x_plus_h = np.clip(x_plus_h, func.bounds.lb, func.bounds.ub)\n                gradients[i, j] = (func(x_plus_h) - F[i]) / h\n\n        # Compute the covariance matrix of the gradients\n        try:\n            grad_cov = np.cov(gradients, rowvar=False)\n        except:\n            grad_cov = np.eye(self.dim)\n\n        # Eigendecomposition\n        try:\n            eigenvalues, eigenvectors = np.linalg.eigh(grad_cov)\n        except:\n             eigenvalues = np.ones(self.dim)\n             eigenvectors = np.eye(self.dim)\n\n        #Sort eigenvalues and eigenvectors\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n\n        # Normalize eigenvalues to have a sum equal to dim (trace of covariance matrix)\n        eigenvalues = (eigenvalues / np.sum(eigenvalues)) * self.dim\n        self.eigenvalues = eigenvalues\n\n        # Reconstruct the covariance matrix\n        self.C = eigenvectors @ np.diag(eigenvalues) @ eigenvectors.T\n        \n        #Ensure positive definiteness\n        try:\n            np.linalg.cholesky(self.C)\n        except np.linalg.LinAlgError:\n            self.C = np.eye(self.dim)", "configspace": "", "generation": 3, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 137, in __call__\nAttributeError: 'CMAES_Enhanced' object has no attribute 'sigma0'. Did you mean: 'sigma'?\n.", "error": "", "parent_ids": ["c5654f3e-ce4f-4d00-a5d9-8615c96c09f5"], "operator": null, "metadata": {}}
{"id": "42f4dbce-6649-4c67-8278-56b04d95e073", "fitness": 0.13072870925887659, "name": "CMAES_Adaptive_Plus", "description": "CMA-ES with spectral regularization, adaptive population size, and a more aggressive step-size control using a dynamically adjusted learning rate based on the condition number of the covariance matrix.", "code": "import numpy as np\n\nclass CMAES_Adaptive_Plus:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov_rank_one=None, c_cov_rank_mu=None, mu_factor=0.25, sigma0=0.5, memory_size=100, curvature_adaptation=True, spectral_regularization=True, adaptive_popsize=True):\n        self.budget = budget\n        self.dim = dim\n        self.adaptive_popsize = adaptive_popsize\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 0.15\n        self.c_cov_rank_mu = c_cov_rank_mu if c_cov_rank_mu is not None else 0.15\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.curvature_adaptation = curvature_adaptation\n        self.spectral_regularization = spectral_regularization\n        self.eigenvalues = np.ones(self.dim)  # Initialize eigenvalues\n        self.B = np.eye(self.dim) # Initialize rotation matrix\n\n    def update_decomposition(self):\n        try:\n            self.eigenvalues, self.B = np.linalg.eigh(self.C)  # Eigen decomposition\n            self.eigenvalues = np.maximum(self.eigenvalues, 1e-16)  # Ensure eigenvalues are positive\n            if self.spectral_regularization:\n                # Spectral regularization to prevent ill-conditioning\n                max_eigenvalue = np.max(self.eigenvalues)\n                min_eigenvalue = np.min(self.eigenvalues)\n                condition_number = max_eigenvalue / min_eigenvalue\n                regularization_factor = 1e-6 * max_eigenvalue  # Small regularization factor\n                self.eigenvalues = np.where(self.eigenvalues < regularization_factor, regularization_factor, self.eigenvalues)\n        except np.linalg.LinAlgError:\n            self.C = np.eye(self.dim)\n            self.eigenvalues = np.ones(self.dim)\n            self.B = np.eye(self.dim)\n\n    def __call__(self, func):\n        evals = 0\n        generation = 0\n        while evals < self.budget:\n            generation += 1\n\n            # Adaptive population size adjustment\n            if self.adaptive_popsize:\n                self.popsize = max(4, int(np.floor(4 + 3 * np.log(self.dim) * (1 + 0.1*generation/ (self.budget/self.popsize))))) # scale popsize down towards end\n                self.mu = int(self.popsize * 0.25)  # or another factor\n                self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n                self.weights /= np.sum(self.weights)\n\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n\n            # Use rotation matrix and eigenvalues directly\n            x = self.m + self.sigma * (z @ self.B @ np.diag(self.eigenvalues**0.5))\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ self.B @ np.diag(self.eigenvalues**-0.5)\n            self.pc = (1 - self.c_cov_rank_one) * self.pc + np.sqrt(self.c_cov_rank_one * (2 - self.c_cov_rank_one)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC_rank_one = self.c_cov_rank_one * (self.pc[:, None] @ self.pc[None, :])\n            dC_rank_mu = self.c_cov_rank_mu * np.sum(self.weights[:, None, None] * ((x[:self.mu] - m_old)[:, :, None] @ (x[:self.mu] - m_old)[:, None, :]) / self.sigma**2, axis=0)\n                \n            self.C = (1 - self.c_cov_rank_one - self.c_cov_rank_mu) * self.C + dC_rank_one + dC_rank_mu\n            \n            # Ensure positive definiteness and update decomposition\n            self.update_decomposition()\n\n            # Adaptive step size based on curvature and condition number\n            if self.curvature_adaptation:\n                condition_number = np.max(self.eigenvalues) / np.min(self.eigenvalues)\n                # Dynamic learning rate for sigma adaptation\n                learning_rate = 0.05 * (condition_number - 1)\n                self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1) + learning_rate)\n            else:\n                 self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n\n            # Simplified archive handling: keep only best from each generation.\n            self.archive.append((x[0], f[0])) # Store fitness as well\n            if len(self.archive) > self.archive_size:\n                self.archive.sort(key=lambda item: item[1]) # sort by fitness\n                self.archive = self.archive[:self.archive_size]  # Keep best\n\n        if self.archive:\n            best_archived_solution = min(self.archive, key=lambda item: item[1])\n            if best_archived_solution[1] < self.f_opt:\n                 self.f_opt = best_archived_solution[1]\n                 self.x_opt = best_archived_solution[0]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm CMAES_Adaptive_Plus scored 0.131 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a402a240-bb6c-428c-b591-cce73557d65e"], "operator": null, "metadata": {"aucs": [0.037072525039450244, 0.11053826251400023, 0.26162276098743653, 0.09226727446862282, 0.10001192359296307, 0.14294430655142154, 0.16723599938150657, 0.12518666977747905, 0.13393008441963972, 0.12938170948075334, 0.1473667167691054, 0.1638040559862357, 0.08738834554337371, 0.09542908472224831, 0.1086009945728823, 0.21786819450471773, 0.11936874197793423, 0.14566499517496145, 0.08498825122175857, 0.14390328849104084]}}
{"id": "870fa150-8ead-4098-91b4-92ff6ff6d284", "fitness": 0.13009032264872228, "name": "CMAES_Enhanced", "description": "CMA-ES with orthogonal sampling, weighted step size adaptation using a longer memory, dynamic population size based on function evaluations, and adaptive covariance updates with rank-one updates and limit the condition number of C to prevent premature convergence.", "code": "import numpy as np\n\nclass CMAES_Enhanced:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov=None, mu_factor=0.25, sigma0=0.5, memory_size=100, restart_trigger=1e-12, orthogonal_sampling=True, condition_number_limit=1e14):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov = c_cov if c_cov is not None else (1 / self.mu) * (2 / ((self.dim + np.sqrt(2))**2))\n        self.c_cov_mu = 0.25 + self.c_cov\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.evals = 0\n        self.restart_trigger = restart_trigger\n        self.orthogonal_sampling = orthogonal_sampling\n        self.successful_sigma_updates = []\n        self.condition_number_limit = condition_number_limit\n\n    def __call__(self, func):\n        self.evals = 0\n        self.successful_sigma_updates = []\n        while self.evals < self.budget:\n            # Adaptive Population Size\n            self.popsize = 4 + int(3 * np.log(self.dim) * (1 - self.evals / self.budget) + 4 * (self.evals / self.budget))\n            self.mu = int(self.popsize * 0.25)\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights /= np.sum(self.weights)\n            \n            # Sample population\n            if self.orthogonal_sampling:\n                z = self._orthogonal_sampling(self.popsize, self.dim)\n            else:\n                z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ C_sqrt.T\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ np.linalg.inv(C_sqrt).T\n            self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC = (self.c_cov_mu / self.mu) * (self.pc[:, None] @ self.pc[None, :])\n            for i in range(self.mu):\n                dC += (self.c_cov / self.mu) * ((x[i] - m_old)[:, None] @ (x[i] - m_old)[None, :]) / self.sigma**2\n\n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + dC\n            \n            # Ensure positive definiteness and limit condition number\n            try:\n                D, B = np.linalg.eigh(self.C)\n                condition_number = np.max(D) / np.min(D)\n                if condition_number > self.condition_number_limit:\n                     D = np.maximum(D, np.max(D) / self.condition_number_limit)\n                self.C = B @ np.diag(D) @ B.T\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Adaptive step size control\n            old_sigma = self.sigma\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            \n            # Store successful sigma updates\n            if f[0] < np.inf: # Check if a better solution has been found\n                self.successful_sigma_updates.append((old_sigma, self.sigma))\n\n            # Weighted average of successful step sizes with longer memory\n            if len(self.successful_sigma_updates) > 10:\n                 weights = np.exp(-np.arange(len(self.successful_sigma_updates)) / 3.0)\n                 weights /= np.sum(weights)\n                 weighted_sigma = np.sum([w * s[1] for w, s in zip(weights[::-1], self.successful_sigma_updates[-len(weights):])])\n                 self.sigma = weighted_sigma\n\n\n            # Archive for diversity (optional)\n            for xi in x:\n                self.archive.append(xi)\n            \n            # Dynamic archive size\n            self.archive_size = min(int(self.budget / 10), 100 + int(self.evals / self.budget * 200))\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[-self.archive_size:]\n                \n            # Restart mechanism\n            if self.sigma < self.restart_trigger:\n                self.m = np.mean(np.array(self.archive), axis=0) if self.archive else np.zeros(self.dim)\n                self.sigma = sigma0\n                self.ps = np.zeros(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.C = np.eye(self.dim)\n        \n        return self.f_opt, self.x_opt\n\n    def _orthogonal_sampling(self, popsize, dim):\n        # Generate standard normal samples\n        z = np.random.normal(0, 1, size=(popsize, dim))\n\n        # Perform QR decomposition\n        Q, R = np.linalg.qr(z)\n\n        # Normalize columns to have unit length\n        for i in range(popsize):\n            Q[i, :] /= np.linalg.norm(Q[i, :])\n\n        return Q", "configspace": "", "generation": 3, "feedback": "The algorithm CMAES_Enhanced scored 0.130 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c5654f3e-ce4f-4d00-a5d9-8615c96c09f5"], "operator": null, "metadata": {"aucs": [0.036342032146109204, 0.0872351033941009, 0.26024584951350804, 0.09138350992153788, 0.08899947276432907, 0.14447504336859618, 0.11269831403023778, 0.11734076872232924, 0.1358489111087845, 0.11147268273331412, 0.14891534747152835, 0.14966539297574832, 0.249823762956636, 0.08635778589934506, 0.10718127465177152, 0.19520722236005517, 0.10783117004962128, 0.13481167961526774, 0.10094074949109777, 0.13503037980052746]}}
{"id": "69a9d7ff-4b8f-4fc8-adcf-06c6e058efc4", "fitness": 0.1301327794577282, "name": "CMAES_FocusedRestart", "description": "CMA-ES with orthogonal sampling, weighted step size adaptation, dynamic archive, and a focused restart strategy based on covariance matrix adaptation and local optima detection using fitness variance.", "code": "import numpy as np\n\nclass CMAES_FocusedRestart:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov=None, mu_factor=0.25, sigma0=0.5, memory_size=100, restart_trigger=1e-12, orthogonal_sampling=True, local_optima_detection=True, fitness_variance_threshold=1e-6):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov = c_cov if c_cov is not None else (1 / self.mu) * (2 / ((self.dim + np.sqrt(2))**2))\n        self.c_cov_mu = 0.25 + self.c_cov\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.evals = 0\n        self.restart_trigger = restart_trigger\n        self.orthogonal_sampling = orthogonal_sampling\n        self.successful_sigma_updates = []\n        self.local_optima_detection = local_optima_detection\n        self.fitness_variance_threshold = fitness_variance_threshold\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        self.evals = 0\n        self.successful_sigma_updates = []\n        self.last_improvement = 0\n\n        while self.evals < self.budget:\n            # Adaptive Population Size\n            self.popsize = 4 + int(3 * np.log(self.dim))\n            self.mu = int(self.popsize * 0.25)\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights /= np.sum(self.weights)\n            \n            # Sample population\n            if self.orthogonal_sampling:\n                z = self._orthogonal_sampling(self.popsize, self.dim)\n            else:\n                z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ C_sqrt.T\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                self.last_improvement = self.evals\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ np.linalg.inv(C_sqrt).T\n            self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC = (self.c_cov_mu / self.mu) * (self.pc[:, None] @ self.pc[None, :])\n            for i in range(self.mu):\n                dC += (self.c_cov / self.mu) * ((x[i] - m_old)[:, None] @ (x[i] - m_old)[None, :]) / self.sigma**2\n                \n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + dC\n            \n            # Ensure positive definiteness\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Adaptive step size control\n            old_sigma = self.sigma\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            \n            # Store successful sigma updates\n            if f[0] < np.inf: # Check if a better solution has been found\n                self.successful_sigma_updates.append((old_sigma, self.sigma))\n\n            # Weighted average of successful step sizes\n            if len(self.successful_sigma_updates) > 5:\n                 weights = np.exp(-np.arange(len(self.successful_sigma_updates)) / 2.0)\n                 weights /= np.sum(weights)\n                 weighted_sigma = np.sum([w * s[1] for w, s in zip(weights[::-1], self.successful_sigma_updates[-len(weights):])])\n                 self.sigma = weighted_sigma\n\n\n            # Archive for diversity (optional)\n            for xi in x:\n                self.archive.append(xi)\n            \n            # Dynamic archive size\n            self.archive_size = min(int(self.budget / 10), 100 + int(self.evals / self.budget * 200))\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[-self.archive_size:]\n                \n            # Restart mechanism\n            restart = False\n            if self.sigma < self.restart_trigger:\n                restart = True\n\n            if self.local_optima_detection and self.evals - self.last_improvement > self.popsize * 10:\n                fitness_variance = np.var(f)\n                if fitness_variance < self.fitness_variance_threshold:\n                    restart = True\n\n            if restart:\n                # Focused Restart: Adapt mean based on covariance matrix\n                eigenvalues, eigenvectors = np.linalg.eigh(self.C)\n                strongest_direction = eigenvectors[:, np.argmax(eigenvalues)]\n                self.m = self.x_opt + 0.1 * self.sigma * strongest_direction # Move along the strongest direction\n\n                self.sigma = sigma0\n                self.ps = np.zeros(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.C = np.eye(self.dim)\n        \n        return self.f_opt, self.x_opt\n\n    def _orthogonal_sampling(self, popsize, dim):\n        # Generate standard normal samples\n        z = np.random.normal(0, 1, size=(popsize, dim))\n\n        # Perform QR decomposition\n        Q, R = np.linalg.qr(z)\n\n        # Normalize columns to have unit length\n        for i in range(popsize):\n            Q[i, :] /= np.linalg.norm(Q[i, :])\n\n        return Q", "configspace": "", "generation": 3, "feedback": "The algorithm CMAES_FocusedRestart scored 0.130 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c5654f3e-ce4f-4d00-a5d9-8615c96c09f5"], "operator": null, "metadata": {"aucs": [0.024545192528140802, 0.09269056332586956, 0.25531583098034616, 0.08996340015766235, 0.09197589580279186, 0.1352936744781731, 0.15348162696996093, 0.11839993536368287, 0.1348226338919023, 0.13018126894773396, 0.14818821835060958, 0.1502418501531787, 0.2163992602935355, 0.08601886272360804, 0.10921796046630383, 0.1963989999457899, 0.10814166178656937, 0.1346658663000211, 0.0899395600556665, 0.13677332663301744]}}
{"id": "9322de35-cd67-4265-9952-f25942f8de58", "fitness": 0.1294640355752534, "name": "CMAES_Adaptive_Enhanced", "description": "Enhanced CMA-ES with active covariance matrix adaptation, adaptive population size, and a restart mechanism to escape local optima, further refined with spectral regularization and dynamic condition number control.", "code": "import numpy as np\n\nclass CMAES_Adaptive_Enhanced:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov_rank_one=None, c_cov_rank_mu=None, mu_factor=0.25, sigma0=0.5, memory_size=100, curvature_adaptation=True, active_adaptation=True, restart_strategy='IPOP', ipop_factor=2, condition_number_threshold=1e14, spectral_regularization_factor=1e-8):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 0.15\n        self.c_cov_rank_mu = c_cov_rank_mu if c_cov_rank_mu is not None else 0.15\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.curvature_adaptation = curvature_adaptation\n        self.active_adaptation = active_adaptation\n        self.restart_strategy = restart_strategy\n        self.ipop_factor = ipop_factor\n        self.condition_number_threshold = condition_number_threshold\n        self.spectral_regularization_factor = spectral_regularization_factor\n        self.evals = 0\n        self.generation = 0\n        self.eigenvalues = np.ones(self.dim)  # Initialize eigenvalues\n        self.B = np.eye(self.dim) # Initialize rotation matrix\n        self.original_popsize = self.popsize\n        self.best_history = []\n\n    def update_decomposition(self):\n        try:\n            self.eigenvalues, self.B = np.linalg.eigh(self.C)  # Eigen decomposition\n            self.eigenvalues = np.maximum(self.eigenvalues, self.spectral_regularization_factor)  # Ensure eigenvalues are positive and regularized\n        except np.linalg.LinAlgError:\n            self.C = np.eye(self.dim)\n            self.eigenvalues = np.ones(self.dim)\n            self.B = np.eye(self.dim)\n\n    def update_covariance(self, x, m_old):\n        # Rank-one update\n        self.pc = (1 - self.c_cov_rank_one) * self.pc + np.sqrt(self.c_cov_rank_one * (2 - self.c_cov_rank_one)) * (self.m - m_old) / self.sigma\n        dC_rank_one = self.c_cov_rank_one * (self.pc[:, None] @ self.pc[None, :])\n\n        # Rank-mu update\n        dC_rank_mu = self.c_cov_rank_mu * np.sum(self.weights[:, None, None] * ((x[:self.mu] - m_old)[:, :, None] @ (x[:self.mu] - m_old)[:, None, :]) / self.sigma**2, axis=0)\n\n        # Active CMA\n        if self.active_adaptation:\n            weights_neg = np.minimum(0, self.weights)\n            dC_active = self.c_cov_rank_mu * np.sum(weights_neg[:, None, None] * ((x[:self.mu] - m_old)[:, :, None] @ (x[:self.mu] - m_old)[:, None, :]) / self.sigma**2, axis=0)\n            self.C = (1 - self.c_cov_rank_one - self.c_cov_rank_mu) * self.C + dC_rank_one + dC_rank_mu + dC_active\n        else:\n            self.C = (1 - self.c_cov_rank_one - self.c_cov_rank_mu) * self.C + dC_rank_one + dC_rank_mu\n\n    def adapt_population_size(self):\n        if self.restart_strategy == 'IPOP':\n            self.popsize = int(self.original_popsize * (self.ipop_factor ** (len(self.best_history) // 100)))  # Adjust population size every 100 generations\n            self.mu = int(self.popsize * 0.25)  # Adjust mu accordingly\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights /= np.sum(self.weights)\n\n    def restart(self):\n        if self.restart_strategy == 'IPOP':\n            self.m = np.zeros(self.dim)  # Reset mean\n            self.sigma = 0.5  # Reset step size\n            self.ps = np.zeros(self.dim)  # Reset evolution paths\n            self.pc = np.zeros(self.dim)\n            self.C = np.eye(self.dim)  # Reset covariance matrix\n            self.eigenvalues = np.ones(self.dim)\n            self.B = np.eye(self.dim)\n            self.popsize = self.original_popsize\n            self.mu = int(self.popsize * 0.25)\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights /= np.sum(self.weights)\n\n    def __call__(self, func):\n        while self.evals < self.budget:\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n\n            # Use rotation matrix and eigenvalues directly\n            x = self.m + self.sigma * (z @ self.B @ np.diag(self.eigenvalues**0.5))\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                self.best_history.append(self.f_opt)\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ self.B @ np.diag(self.eigenvalues**-0.5)\n\n            # Update covariance matrix\n            self.update_covariance(x, m_old)\n            \n            # Ensure positive definiteness and update decomposition\n            self.update_decomposition()\n\n            # Adaptive step size based on curvature\n            if self.curvature_adaptation:\n                condition_number = np.max(self.eigenvalues) / np.min(self.eigenvalues)\n                self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1) + 0.05 * (condition_number - 1)) # Condition number regularization\n                if condition_number > self.condition_number_threshold:\n                    self.C += np.eye(self.dim) * self.spectral_regularization_factor\n\n            else:\n                 self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Simplified archive handling: keep only best from each generation.\n            self.archive.append((x[0], f[0])) # Store fitness as well\n            if len(self.archive) > self.archive_size:\n                self.archive.sort(key=lambda item: item[1]) # sort by fitness\n                self.archive = self.archive[:self.archive_size]  # Keep best\n\n            self.generation += 1\n\n            # Restart mechanism\n            if self.restart_strategy == 'IPOP' and self.evals < 0.95 * self.budget and len(self.best_history) > 50: # Don't restart close to budget end\n                if np.std(self.best_history[-50:]) < 1e-9:\n                    self.adapt_population_size() # adapt population size before restart\n                    self.restart()  # Restart if stagnating\n\n        if self.archive:\n            best_archived_solution = min(self.archive, key=lambda item: item[1])\n            if best_archived_solution[1] < self.f_opt:\n                 self.f_opt = best_archived_solution[1]\n                 self.x_opt = best_archived_solution[0]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm CMAES_Adaptive_Enhanced scored 0.129 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a402a240-bb6c-428c-b591-cce73557d65e"], "operator": null, "metadata": {"aucs": [0.04331693854703966, 0.09745626321051437, 0.2599068055693976, 0.10096057802502634, 0.09911913582391896, 0.14194894226861965, 0.16204257942390343, 0.12419582270119922, 0.14297093838208152, 0.12923959400105034, 0.1424563210398535, 0.16189381551231785, 0.06994564941301029, 0.09551050868299626, 0.11230379176164296, 0.2030072893801922, 0.12729803684148988, 0.13798194959024646, 0.09895105377285929, 0.13877469755770855]}}
{"id": "94f2eb34-5668-4b95-aab9-d8ff8528bf69", "fitness": 0.12786496885383208, "name": "CMAES_Enhanced2", "description": "CMA-ES with orthogonal sampling, adaptive step size using a weighted average of successful steps, dynamic archive adjustment, and a novel mechanism for early exploitation detection based on fitness variance to prioritize exploitation.", "code": "import numpy as np\n\nclass CMAES_Enhanced2:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov=None, mu_factor=0.25, sigma0=0.5, memory_size=100, restart_trigger=1e-12, orthogonal_sampling=True, exploitation_threshold=1e-3):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov = c_cov if c_cov is not None else (1 / self.mu) * (2 / ((self.dim + np.sqrt(2))**2))\n        self.c_cov_mu = 0.25 + self.c_cov\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.evals = 0\n        self.restart_trigger = restart_trigger\n        self.orthogonal_sampling = orthogonal_sampling\n        self.successful_sigma_updates = []\n        self.exploitation_threshold = exploitation_threshold\n\n    def __call__(self, func):\n        self.evals = 0\n        self.successful_sigma_updates = []\n        exploitation_phase = False\n\n        while self.evals < self.budget:\n            # Adaptive Population Size\n            self.popsize = 4 + int(3 * np.log(self.dim))\n            self.mu = int(self.popsize * 0.25)\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights /= np.sum(self.weights)\n            \n            # Sample population\n            if self.orthogonal_sampling:\n                z = self._orthogonal_sampling(self.popsize, self.dim)\n            else:\n                z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n\n            if exploitation_phase:\n                # Reduce sigma for exploitation\n                x = self.m + (self.sigma * 0.1) * z @ np.linalg.cholesky(self.C).T\n            else:\n                x = self.m + self.sigma * z @ np.linalg.cholesky(self.C).T\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Check for early exploitation\n            if np.var(f) < self.exploitation_threshold and not exploitation_phase:\n                exploitation_phase = True\n                print(\"Entering exploitation phase\")\n\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ np.linalg.inv(np.linalg.cholesky(self.C)).T\n            self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC = (self.c_cov_mu / self.mu) * (self.pc[:, None] @ self.pc[None, :])\n            for i in range(self.mu):\n                dC += (self.c_cov / self.mu) * ((x[i] - m_old)[:, None] @ (x[i] - m_old)[None, :]) / self.sigma**2\n                \n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + dC\n            \n            # Ensure positive definiteness\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Adaptive step size control\n            old_sigma = self.sigma\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            \n            # Store successful sigma updates\n            if self.f_opt < np.inf: # Check if a better solution has been found\n                self.successful_sigma_updates.append((old_sigma, self.sigma))\n\n            # Weighted average of successful step sizes\n            if len(self.successful_sigma_updates) > 5:\n                 weights = np.exp(-np.arange(len(self.successful_sigma_updates)) / 2.0)\n                 weights /= np.sum(weights)\n                 weighted_sigma = np.sum([w * s[1] for w, s in zip(weights[::-1], self.successful_sigma_updates[-len(weights):])])\n                 self.sigma = weighted_sigma\n\n\n            # Archive for diversity (optional)\n            for xi in x:\n                self.archive.append(xi)\n            \n            # Dynamic archive size\n            self.archive_size = min(int(self.budget / 10), 100 + int(self.evals / self.budget * 200))\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[-self.archive_size:]\n                \n            # Restart mechanism\n            if self.sigma < self.restart_trigger:\n                self.m = np.mean(np.array(self.archive), axis=0) if self.archive else np.zeros(self.dim)\n                self.sigma = sigma0\n                self.ps = np.zeros(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.C = np.eye(self.dim)\n        \n        return self.f_opt, self.x_opt\n\n    def _orthogonal_sampling(self, popsize, dim):\n        # Generate standard normal samples\n        z = np.random.normal(0, 1, size=(popsize, dim))\n\n        # Perform QR decomposition\n        Q, R = np.linalg.qr(z)\n\n        # Normalize columns to have unit length\n        for i in range(popsize):\n            Q[i, :] /= np.linalg.norm(Q[i, :])\n\n        return Q", "configspace": "", "generation": 3, "feedback": "The algorithm CMAES_Enhanced2 scored 0.128 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c5654f3e-ce4f-4d00-a5d9-8615c96c09f5"], "operator": null, "metadata": {"aucs": [0.020296970547072135, 0.08598732048622548, 0.2581503176432035, 0.0913602952381598, 0.09307206965268722, 0.13315811533828747, 0.1480650077317438, 0.12046493641440559, 0.1345343070186127, 0.12353677921043271, 0.14836794074046067, 0.14954950681172108, 0.18116156567031327, 0.0838565781459163, 0.10895468088515681, 0.19768793681561836, 0.11044113326425464, 0.13407681173683927, 0.09424911065630082, 0.14032799306922994]}}
{"id": "3b900ebd-4d6b-46a1-9352-7f9f85994a9b", "fitness": 0.12482513914385789, "name": "CMAES_Enhanced", "description": "CMA-ES with orthogonal sampling, adaptive step size, dynamic archive, and a novel covariance matrix adaptation using a combination of rank-one, rank-mu, and selective past steps.", "code": "import numpy as np\n\nclass CMAES_Enhanced:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov=None, mu_factor=0.25, sigma0=0.5, memory_size=100, restart_trigger=1e-12, orthogonal_sampling=True, selective_c_cov=True):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov = c_cov if c_cov is not None else (1 / self.mu) * (2 / ((self.dim + np.sqrt(2))**2))\n        self.c_cov_mu = 0.25 + self.c_cov\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.evals = 0\n        self.restart_trigger = restart_trigger\n        self.orthogonal_sampling = orthogonal_sampling\n        self.successful_sigma_updates = []\n        self.selective_c_cov = selective_c_cov  # Enable selective covariance update\n        self.past_steps = []  # Store past successful steps\n\n    def __call__(self, func):\n        self.evals = 0\n        self.successful_sigma_updates = []\n        self.past_steps = []\n        while self.evals < self.budget:\n            # Adaptive Population Size\n            self.popsize = 4 + int(3 * np.log(self.dim))\n            self.mu = int(self.popsize * 0.25)\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights /= np.sum(self.weights)\n            \n            # Sample population\n            if self.orthogonal_sampling:\n                z = self._orthogonal_sampling(self.popsize, self.dim)\n            else:\n                z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ C_sqrt.T\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                if len(self.past_steps) < 10: #keep track of last 10 steps\n                    self.past_steps.append((self.m.copy(), x[0].copy()))\n                else:\n                    self.past_steps.pop(0)\n                    self.past_steps.append((self.m.copy(), x[0].copy()))\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ np.linalg.inv(C_sqrt).T\n            self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC = (self.c_cov_mu / self.mu) * (self.pc[:, None] @ self.pc[None, :])\n            for i in range(self.mu):\n                dC += (self.c_cov / self.mu) * ((x[i] - m_old)[:, None] @ (x[i] - m_old)[None, :]) / self.sigma**2\n\n            if self.selective_c_cov and len(self.past_steps) > 1:\n                for old_m, best_x in self.past_steps:\n                    d = (best_x - old_m) / self.sigma\n                    dC += (0.1 * self.c_cov) * (d[:, None] @ d[None, :])  # Selective update using past best steps\n\n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + dC\n            \n            # Ensure positive definiteness\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Adaptive step size control\n            old_sigma = self.sigma\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            \n            # Store successful sigma updates\n            if self.f_opt < np.inf: # Check if a better solution has been found\n                self.successful_sigma_updates.append((old_sigma, self.sigma))\n\n            # Weighted average of successful step sizes\n            if len(self.successful_sigma_updates) > 5:\n                 weights = np.exp(-np.arange(len(self.successful_sigma_updates)) / 2.0)\n                 weights /= np.sum(weights)\n                 weighted_sigma = np.sum([w * s[1] for w, s in zip(weights[::-1], self.successful_sigma_updates[-len(weights):])])\n                 self.sigma = weighted_sigma\n\n\n            # Archive for diversity (optional)\n            for xi in x:\n                self.archive.append(xi)\n            \n            # Dynamic archive size\n            self.archive_size = min(int(self.budget / 10), 100 + int(self.evals / self.budget * 200))\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[-self.archive_size:]\n                \n            # Restart mechanism\n            if self.sigma < self.restart_trigger:\n                self.m = np.mean(np.array(self.archive), axis=0) if self.archive else np.zeros(self.dim)\n                self.sigma = sigma0\n                self.ps = np.zeros(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.C = np.eye(self.dim)\n        \n        return self.f_opt, self.x_opt\n\n    def _orthogonal_sampling(self, popsize, dim):\n        # Generate standard normal samples\n        z = np.random.normal(0, 1, size=(popsize, dim))\n\n        # Perform QR decomposition\n        Q, R = np.linalg.qr(z)\n\n        # Normalize columns to have unit length\n        for i in range(popsize):\n            Q[i, :] /= np.linalg.norm(Q[i, :])\n\n        return Q", "configspace": "", "generation": 3, "feedback": "The algorithm CMAES_Enhanced scored 0.125 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c5654f3e-ce4f-4d00-a5d9-8615c96c09f5"], "operator": null, "metadata": {"aucs": [0.028375445385805165, 0.08641549805212712, 0.25444316574672465, 0.09378764140009987, 0.08865186607401832, 0.14003349490242034, 0.1435629820627703, 0.11298538262234303, 0.13533359611011253, 0.12023499418014416, 0.14848016351606297, 0.1528192375840658, 0.14121765153113852, 0.08479883966232404, 0.10843530670714807, 0.19669005775606851, 0.10249705032884371, 0.1351080261933224, 0.08699321817424588, 0.13563916488737193]}}
{"id": "fc0f961e-4cb7-45ae-9632-409ee0b3b15e", "fitness": 0.14747314672811013, "name": "CMAES_Enhanced", "description": "CMA-ES with pairwise orthogonal mutation to enhance exploration, spectral initialization of covariance matrix to capture initial landscape features, and a moving average recombination strategy to smooth the search trajectory.", "code": "import numpy as np\n\nclass CMAES_Enhanced:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov=None, mu_factor=0.25, sigma0=0.5, memory_size=100, restart_trigger=1e-12, orthogonal_sampling=True, spectral_init=True, moving_average_recombination=True):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov = c_cov if c_cov is not None else (1 / self.mu) * (2 / ((self.dim + np.sqrt(2))**2))\n        self.c_cov_mu = 0.25 + self.c_cov\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.evals = 0\n        self.restart_trigger = restart_trigger\n        self.orthogonal_sampling = orthogonal_sampling\n        self.successful_sigma_updates = []\n        self.spectral_init = spectral_init\n        self.moving_average_recombination = moving_average_recombination\n\n    def __call__(self, func):\n        self.evals = 0\n        self.successful_sigma_updates = []\n        \n        # Spectral Initialization\n        if self.spectral_init:\n            initial_samples = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.popsize, self.dim))\n            initial_fitness = np.array([func(xi) for xi in initial_samples])\n            covariance_matrix = np.cov(initial_samples.T)\n            try:\n                eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n                self.C = eigenvectors @ np.diag(np.maximum(eigenvalues, 1e-6)) @ eigenvectors.T # Ensure positive definite\n                self.sigma = np.std(initial_fitness) # Initialize sigma based on initial fitness variance\n            except np.linalg.LinAlgError:\n                pass # Keep identity if spectral init fails\n\n        while self.evals < self.budget:\n            # Adaptive Population Size\n            self.popsize = 4 + int(3 * np.log(self.dim))\n            self.mu = int(self.popsize * 0.25)\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights /= np.sum(self.weights)\n            \n            # Sample population\n            if self.orthogonal_sampling:\n                z = self._pairwise_orthogonal_sampling(self.popsize, self.dim)\n            else:\n                z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ C_sqrt.T\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.evals += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            m_old = self.m.copy()\n            if self.moving_average_recombination:\n                 self.m = 0.9 * self.m + 0.1 * np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n            else:\n                 self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ np.linalg.inv(C_sqrt).T\n            self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.evals / self.popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC = (self.c_cov_mu / self.mu) * (self.pc[:, None] @ self.pc[None, :])\n            for i in range(self.mu):\n                dC += (self.c_cov / self.mu) * ((x[i] - m_old)[:, None] @ (x[i] - m_old)[None, :]) / self.sigma**2\n                \n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + dC\n            \n            # Ensure positive definiteness\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Adaptive step size control\n            old_sigma = self.sigma\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            \n            # Store successful sigma updates\n            if self.f_opt < np.inf: # Check if a better solution has been found\n                self.successful_sigma_updates.append((old_sigma, self.sigma))\n\n            # Weighted average of successful step sizes\n            if len(self.successful_sigma_updates) > 5:\n                 weights = np.exp(-np.arange(len(self.successful_sigma_updates)) / 2.0)\n                 weights /= np.sum(weights)\n                 weighted_sigma = np.sum([w * s[1] for w, s in zip(weights[::-1], self.successful_sigma_updates[-len(weights):])])\n                 self.sigma = weighted_sigma\n\n\n            # Archive for diversity (optional)\n            for xi in x:\n                self.archive.append(xi)\n            \n            # Dynamic archive size\n            self.archive_size = min(int(self.budget / 10), 100 + int(self.evals / self.budget * 200))\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[-self.archive_size:]\n                \n            # Restart mechanism\n            if self.sigma < self.restart_trigger:\n                self.m = np.mean(np.array(self.archive), axis=0) if self.archive else np.zeros(self.dim)\n                self.sigma = sigma0\n                self.ps = np.zeros(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.C = np.eye(self.dim)\n        \n        return self.f_opt, self.x_opt\n\n    def _pairwise_orthogonal_sampling(self, popsize, dim):\n        z = np.random.normal(0, 1, size=(popsize, dim))\n        \n        for i in range(0, popsize, 2):\n            if i + 1 < popsize:\n                # Create two orthogonal vectors\n                v1 = z[i]\n                v2 = z[i+1] - (np.dot(z[i+1], z[i]) / np.dot(z[i], z[i])) * z[i]\n                \n                # Normalize\n                v1 /= np.linalg.norm(v1)\n                v2 /= np.linalg.norm(v2)\n                \n                z[i] = v1\n                z[i+1] = v2\n        return z", "configspace": "", "generation": 3, "feedback": "The algorithm CMAES_Enhanced scored 0.147 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c5654f3e-ce4f-4d00-a5d9-8615c96c09f5"], "operator": null, "metadata": {"aucs": [0.02837243502040987, 0.0969374387629105, 0.2636767357599643, 0.19003189913050922, 0.16943433154173615, 0.20706239464307463, 0.19156852156273618, 0.11531188100594736, 0.14436216155906423, 0.1145129825252934, 0.14258446813538816, 0.1898923195212956, 0.01659157312689563, 0.16215406576838032, 0.11762434900295615, 0.19750335008802544, 0.15731092687565984, 0.16694176024213225, 0.11078313220867642, 0.16680620808114688]}}
{"id": "bc4a5368-3375-4a16-9edc-c8c73bd79b99", "fitness": 0.14115920686264521, "name": "AdaptiveDE_OrthoAging", "description": "Enhanced Adaptive DE with orthogonal crossover, aging mechanism, and dynamic population size adjustment based on diversity and budget.", "code": "import numpy as np\n\nclass AdaptiveDE_OrthoAging:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, pop_adapt_rate=0.05, aging_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(4 + 3 * np.log(dim))  # Adaptive population size\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = None\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_beta = 0.9\n        self.pop_adapt_rate = pop_adapt_rate\n        self.aging_rate = aging_rate\n        self.age = None # Age of each individual\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n        self.age = np.zeros(self.pop_size)\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def orthogonal_crossover(self, mutated_population):\n        crossed_population = np.copy(self.population)\n        for i in range(self.pop_size):\n            # Select two parents randomly\n            parent1_idx, parent2_idx = np.random.choice(self.pop_size, 2, replace=False)\n            parent1 = self.population[parent1_idx]\n            parent2 = mutated_population[parent2_idx]\n\n            # Generate an orthogonal matrix (Hadamard matrix)\n            H = self.generate_hadamard_matrix(self.dim)\n\n            # Create offspring using orthogonal crossover\n            for j in range(self.dim):\n                crossed_population[i, j] = 0.5 * (parent1[j] + parent2[j]) + 0.5 * H[i % self.dim, j] * (parent1[j] - parent2[j])\n\n        return crossed_population\n\n    def generate_hadamard_matrix(self, n):\n        # Ensure n is a power of 2\n        if n & (n - 1) != 0:\n            n = 2 ** int(np.ceil(np.log2(n)))  # Round up to the nearest power of 2\n\n        if n == 1:\n            return np.array([[1]])\n\n        H = np.array([[1]])\n        while H.shape[0] < n:\n            H = np.kron(H, np.array([[1, 1], [1, -1]]))\n        return H\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def calculate_crowding_distance(self, pop, fitness):\n        distances = np.zeros(len(pop))\n\n        # Normalize each dimension\n        normalized_pop = (pop - np.min(pop, axis=0)) / (np.max(pop, axis=0) - np.min(pop, axis=0) + 1e-8)\n\n        for i in range(self.dim):\n            sorted_indices = np.argsort(normalized_pop[:, i])\n            distances[sorted_indices[0]] = np.inf\n            distances[sorted_indices[-1]] = np.inf\n\n            for j in range(1, len(pop) - 1):\n                distances[sorted_indices[j]] += normalized_pop[sorted_indices[j+1], i] - normalized_pop[sorted_indices[j-1], i]\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                self.age[i] = 0  # Reset age\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    idx_to_replace = np.random.randint(0, self.archive_size)\n                    self.archive[idx_to_replace] = self.population[i].copy()\n            else:\n                self.age[i] += 1  # Increase age\n\n        # Stochastic Ranking Selection\n        combined_population = np.vstack((self.population, crossed_population))\n        combined_fitness = np.concatenate((self.fitness, [func(x) for x in crossed_population]))\n        self.budget -= len(crossed_population)\n\n        ranked_population, ranked_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        # Crowding Distance\n        crowding_distances = self.calculate_crowding_distance(ranked_population, ranked_fitness)\n\n        # Select based on rank and crowding distance\n        selected_indices = np.argsort(-crowding_distances)[:self.pop_size]  # Take top pop_size based on crowding distance\n        new_population = ranked_population[selected_indices]\n        new_fitness = ranked_fitness[selected_indices]\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_beta * self.F_momentum + (1 - self.momentum_beta) * mean_F\n            self.CR_momentum = self.momentum_beta * self.CR_momentum + (1 - self.momentum_beta) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Aging mechanism: replace old individuals\n        for i in range(self.pop_size):\n            if self.age[i] > self.dim * 2:  # Threshold for aging\n                new_population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                new_fitness[i] = func(new_population[i])\n                self.budget -= 1\n                self.age[i] = 0\n\n        # Adaptive population size\n        diversity = np.std(new_fitness)\n        if diversity < 1e-3:  # Stagnation detection\n            self.pop_size = min(self.pop_size + int(self.pop_adapt_rate * self.dim), 200)\n        else:\n            self.pop_size = max(int(4 + 3 * np.log(self.dim)), int(self.pop_size * (1 - self.pop_adapt_rate)))\n\n        return new_population, new_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > self.pop_size:\n            mutated_population = self.mutate()\n            crossed_population = self.orthogonal_crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE_OrthoAging scored 0.141 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["abe5970a-f045-4702-aba3-1c4a0746854d"], "operator": null, "metadata": {"aucs": [0.10416085841850542, 0.15464480648736023, 0.25258763611578416, 0.1944027332915763, 0]}}
{"id": "5e9a3776-5827-431e-b04c-4edacff53e86", "fitness": 0.2067796252265465, "name": "CMAES_Adaptive_Enhanced", "description": "Improved CMA-ES with dynamic population size, local search refinement, and an enhanced archive strategy for better exploration and exploitation.", "code": "import numpy as np\n\nclass CMAES_Adaptive_Enhanced:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov_rank_one=None, c_cov_rank_mu=None, mu_factor=0.25, sigma0=0.5, memory_size=100, curvature_adaptation=True, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 0.15\n        self.c_cov_rank_mu = c_cov_rank_mu if c_cov_rank_mu is not None else 0.15\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.curvature_adaptation = curvature_adaptation\n        self.eigenvalues = np.ones(self.dim)  # Initialize eigenvalues\n        self.B = np.eye(self.dim) # Initialize rotation matrix\n        self.evals = 0\n        self.local_search_probability = local_search_probability\n\n    def update_decomposition(self):\n        try:\n            self.eigenvalues, self.B = np.linalg.eigh(self.C)  # Eigen decomposition\n            self.eigenvalues = np.maximum(self.eigenvalues, 1e-16)  # Ensure eigenvalues are positive\n        except np.linalg.LinAlgError:\n            self.C = np.eye(self.dim)\n            self.eigenvalues = np.ones(self.dim)\n            self.B = np.eye(self.dim)\n\n    def local_search(self, func, x, radius=0.1, num_points=5):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_f = func(x)\n        best_x = x\n        self.evals += 1\n\n        for _ in range(num_points):\n            x_new = x + np.random.uniform(-radius, radius, size=self.dim)\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x_new = np.clip(x_new, lb, ub)\n            f_new = func(x_new)\n            self.evals += 1\n\n            if f_new < best_f:\n                best_f = f_new\n                best_x = x_new\n        return best_f, best_x\n\n\n    def __call__(self, func):\n        self.evals = 0\n        dynamic_popsize = self.popsize\n\n        while self.evals < self.budget:\n            # Dynamic population size adjustment\n            if self.evals > self.budget * 0.5:\n                dynamic_popsize = max(4, int(self.popsize * 0.5))  # Reduce population size later in the search\n            else:\n                dynamic_popsize = self.popsize\n            \n            self.mu = int(dynamic_popsize * 0.25)  #Adjust mu accordingly.\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights /= np.sum(self.weights)\n\n            # Sample population\n            z = np.random.normal(0, 1, size=(dynamic_popsize, self.dim))\n\n            # Use rotation matrix and eigenvalues directly\n            x = self.m + self.sigma * (z @ self.B @ np.diag(self.eigenvalues**0.5))\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.evals += dynamic_popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Local search refinement\n            if np.random.rand() < self.local_search_probability:\n                f_local, x_local = self.local_search(func, self.x_opt)\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ self.B @ np.diag(self.eigenvalues**-0.5)\n            self.pc = (1 - self.c_cov_rank_one) * self.pc + np.sqrt(self.c_cov_rank_one * (2 - self.c_cov_rank_one)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.evals / dynamic_popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC_rank_one = self.c_cov_rank_one * (self.pc[:, None] @ self.pc[None, :])\n            dC_rank_mu = self.c_cov_rank_mu * np.sum(self.weights[:, None, None] * ((x[:self.mu] - m_old)[:, :, None] @ (x[:self.mu] - m_old)[:, None, :]) / self.sigma**2, axis=0)\n                \n            self.C = (1 - self.c_cov_rank_one - self.c_cov_rank_mu) * self.C + dC_rank_one + dC_rank_mu\n            \n            # Ensure positive definiteness and update decomposition\n            self.update_decomposition()\n\n            # Adaptive step size based on curvature\n            if self.curvature_adaptation:\n                condition_number = np.max(self.eigenvalues) / np.min(self.eigenvalues)\n                self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1) + 0.05 * (condition_number - 1)) # Condition number regularization\n\n            else:\n                 self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n\n            # Enhanced archive handling: keep a diverse set of solutions\n            if len(self.archive) < self.archive_size:\n                self.archive.append((x[0].copy(), f[0]))\n            else:\n                # Replace the worst element in the archive with the current best, if it's better\n                worst_index = np.argmax([item[1] for item in self.archive])\n                if f[0] < self.archive[worst_index][1]:\n                    self.archive[worst_index] = (x[0].copy(), f[0])\n\n\n        if self.archive:\n            best_archived_solution = min(self.archive, key=lambda item: item[1])\n            if best_archived_solution[1] < self.f_opt:\n                 self.f_opt = best_archived_solution[1]\n                 self.x_opt = best_archived_solution[0]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm CMAES_Adaptive_Enhanced scored 0.207 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a402a240-bb6c-428c-b591-cce73557d65e"], "operator": null, "metadata": {"aucs": [0.07129074493382237, 0.18625741965664033, 0.4300176964234087, 0.12777434115932995, 0.11401832554236624, 0.1502589759506453, 0.18404167593316423, 0.15614300911578705, 0.14198116867579014, 0.14682964505990725, 0.27728741963792547, 0.18146399789810996, 0.2488804314507682, 0.16495322059722128, 0.17573782239084046, 0.296784219498073, 0.23855868798543856, 0.5188300402600932, 0.16896426248257523, 0.15551939987902208]}}
{"id": "ef825202-e685-447b-aba2-ee64f82025d2", "fitness": 0.4689135410698285, "name": "AdaptiveDE_Ortho", "description": "Adaptive Differential Evolution with self-adaptive population size, orthogonal crossover, and a multi-strategy mutation that combines current-to-best and random differential evolution.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n        \n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n            \n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            \n            self.best_fitness_history.append(current_best_fitness)\n            \n            if self.check_stagnation():\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE_Ortho scored 0.469 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["57d72ae0-b7d3-41ca-8a47-14d3ef7a6fa8"], "operator": null, "metadata": {"aucs": [0.19500710787473985, 0.32718762548945757, 0.4292998808017259, 0.6924085714636845, 0.4012060096813922, 0.5196311493568786, 0.3291054078548451, 0.40955955358402685, 0.4282504164892045, 0.3326294918444427, 0.614092570789206, 0.9985167632546225, 0.3067804026367079, 0.3849727975992777, 0.7419914440999157, 0.542807616099205, 0.3794034734456039, 0.6328776046324516, 0.21025752802279263, 0.5022854063763906]}}
{"id": "1fb74399-9c24-4216-abb2-74da5f844e9f", "fitness": -Infinity, "name": "AdaptiveDE_OrthoEnhanced", "description": "Adaptive Differential Evolution with orthogonal crossover, aging, and dynamic population size, using a more robust stagnation detection and local search refinement.", "code": "import numpy as np\n\nclass AdaptiveDE_OrthoEnhanced:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=500, ortho_group_size=5, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.local_search_probability = local_search_probability\n        self.age = np.zeros(pop_size_max)\n        self.age_limit = 50\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n        self.age = np.zeros(self.pop_size)\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                self.age[i] = 0 # Reset age\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n            else:\n                self.age[i] += 1\n\n        # Aging: Replace old individuals\n        for i in range(self.pop_size):\n            if self.age[i] > self.age_limit:\n                new_population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                new_fitness[i] = func(new_population[i])\n                self.budget -=1\n                self.age[i] = 0\n                \n        # Local search refinement\n        for i in range(self.pop_size):\n            if np.random.rand() < self.local_search_probability:\n                step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                new_x = new_population[i] + np.random.uniform(-step_size, step_size, size=self.dim)\n                new_x = self.handle_bounds(new_x, func)\n                new_f = func(new_x)\n                self.budget -= 1\n                if new_f < new_fitness[i]:\n                    new_population[i] = new_x\n                    new_fitness[i] = new_f\n                    \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n            self.population = np.concatenate([new_population, np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - len(new_population), self.dim))])\n            self.fitness = np.concatenate([new_fitness, np.array([func(x) for x in self.population[len(new_population):]])])\n            self.age = np.concatenate([self.age, np.zeros(self.pop_size - len(new_population))])\n            self.budget -= (self.pop_size - len(new_population))\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n            # Keep the best and reduce population\n            sorted_indices = np.argsort(new_fitness)[:self.pop_size]\n            self.population = new_population[sorted_indices]\n            self.fitness = new_fitness[sorted_indices]\n            self.age = self.age[sorted_indices]\n\n\n        if self.successful_F:\n            self.F = np.mean(self.successful_F)\n            self.CR = np.mean(self.successful_CR)\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        N = min(len(self.best_fitness_history), self.stagnation_threshold)\n        if N < self.stagnation_threshold:\n            return False\n\n        if np.std(self.best_fitness_history[-N:]) < 1e-8:\n            self.stagnation_counter += 1\n        else:\n            self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.age = np.zeros(self.pop_size) # Reset age\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size_min: # Ensure enough budget for minimal population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            \n            self.best_fitness_history.append(current_best_fitness)\n            \n            if self.check_stagnation():\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 173, in __call__\n  File \"<string>\", line 128, in select\nIndexError: index 95 is out of bounds for axis 0 with size 92\n.", "error": "", "parent_ids": ["ef825202-e685-447b-aba2-ee64f82025d2"], "operator": null, "metadata": {}}
{"id": "e9c36247-3464-4ca0-9571-d5fe8233ed35", "fitness": -Infinity, "name": "AdaptiveDE_OrthoAging_NM", "description": "Adaptive Differential Evolution with orthogonal crossover, aging, dynamic population size, and a local search refinement strategy based on the Nelder-Mead simplex method for enhanced exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDE_OrthoAging_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, pop_adapt_rate=0.05, aging_rate=0.01, local_search_frequency=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(4 + 3 * np.log(dim))  # Adaptive population size\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = None\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_beta = 0.9\n        self.pop_adapt_rate = pop_adapt_rate\n        self.aging_rate = aging_rate\n        self.age = None # Age of each individual\n        self.local_search_frequency = local_search_frequency\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n        self.age = np.zeros(self.pop_size)\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def orthogonal_crossover(self, mutated_population):\n        crossed_population = np.copy(self.population)\n        for i in range(self.pop_size):\n            # Select two parents randomly\n            parent1_idx, parent2_idx = np.random.choice(self.pop_size, 2, replace=False)\n            parent1 = self.population[parent1_idx]\n            parent2 = mutated_population[parent2_idx]\n\n            # Generate an orthogonal matrix (Hadamard matrix)\n            H = self.generate_hadamard_matrix(self.dim)\n\n            # Create offspring using orthogonal crossover\n            for j in range(self.dim):\n                crossed_population[i, j] = 0.5 * (parent1[j] + parent2[j]) + 0.5 * H[i % self.dim, j] * (parent1[j] - parent2[j])\n\n        return crossed_population\n\n    def generate_hadamard_matrix(self, n):\n        # Ensure n is a power of 2\n        if n & (n - 1) != 0:\n            n = 2 ** int(np.ceil(np.log2(n)))  # Round up to the nearest power of 2\n\n        if n == 1:\n            return np.array([[1]])\n\n        H = np.array([[1]])\n        while H.shape[0] < n:\n            H = np.kron(H, np.array([[1, 1], [1, -1]]))\n        return H\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def calculate_crowding_distance(self, pop, fitness):\n        distances = np.zeros(len(pop))\n\n        # Normalize each dimension\n        normalized_pop = (pop - np.min(pop, axis=0)) / (np.max(pop, axis=0) - np.min(pop, axis=0) + 1e-8)\n\n        for i in range(self.dim):\n            sorted_indices = np.argsort(normalized_pop[:, i])\n            distances[sorted_indices[0]] = np.inf\n            distances[sorted_indices[-1]] = np.inf\n\n            for j in range(1, len(pop) - 1):\n                distances[sorted_indices[j]] += normalized_pop[sorted_indices[j+1], i] - normalized_pop[sorted_indices[j-1], i]\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                self.age[i] = 0  # Reset age\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    idx_to_replace = np.random.randint(0, self.archive_size)\n                    self.archive[idx_to_replace] = self.population[i].copy()\n            else:\n                self.age[i] += 1  # Increase age\n\n        # Stochastic Ranking Selection\n        combined_population = np.vstack((self.population, crossed_population))\n        combined_fitness = np.concatenate((self.fitness, [func(x) for x in crossed_population]))\n        self.budget -= len(crossed_population)\n\n        ranked_population, ranked_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        # Crowding Distance\n        crowding_distances = self.calculate_crowding_distance(ranked_population, ranked_fitness)\n\n        # Select based on rank and crowding distance\n        selected_indices = np.argsort(-crowding_distances)[:self.pop_size]  # Take top pop_size based on crowding distance\n        new_population = ranked_population[selected_indices]\n        new_fitness = ranked_fitness[selected_indices]\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_beta * self.F_momentum + (1 - self.momentum_beta) * mean_F\n            self.CR_momentum = self.momentum_beta * self.CR_momentum + (1 - self.momentum_beta) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Aging mechanism: replace old individuals\n        for i in range(self.pop_size):\n            if self.age[i] > self.dim * 2:  # Threshold for aging\n                new_population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                new_fitness[i] = func(new_population[i])\n                self.budget -= 1\n                self.age[i] = 0\n\n        # Adaptive population size\n        diversity = np.std(new_fitness)\n        if diversity < 1e-3:  # Stagnation detection\n            self.pop_size = min(self.pop_size + int(self.pop_adapt_rate * self.dim), 200)\n        else:\n            self.pop_size = max(int(4 + 3 * np.log(self.dim)), int(self.pop_size * (1 - self.pop_adapt_rate)))\n\n        return new_population, new_fitness\n\n    def local_search(self, func, x):\n        bounds = func.bounds\n        def wrapper(x):\n            return func(x)\n        result = minimize(wrapper, x, method='Nelder-Mead', bounds=[(bounds.lb, bounds.ub)] * self.dim, options={'maxfev': int(self.budget * 0.01)}) # Reduce budget here\n        self.budget -= result.nfev\n        return result.fun, result.x\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > self.pop_size:\n            mutated_population = self.mutate()\n            crossed_population = self.orthogonal_crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            # Local search refinement\n            if np.random.rand() < self.local_search_frequency:\n                idx = np.argmin(self.fitness)\n                best_x = self.population[idx].copy()\n                f_local, x_local = self.local_search(func, best_x)\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n                \n                if f_local < self.fitness[idx]:\n                    self.fitness[idx] = f_local\n                    self.population[idx] = x_local\n\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 121, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 205, in __call__\n  File \"<string>\", line 185, in local_search\nNameError: name 'minimize' is not defined\n.", "error": "", "parent_ids": ["bc4a5368-3375-4a16-9edc-c8c73bd79b99"], "operator": null, "metadata": {}}
{"id": "ca4373c3-0766-4d06-be66-24019d5c6160", "fitness": -Infinity, "name": "AdaptiveDE_Ortho_LocalSearch", "description": "Adaptive Differential Evolution with orthogonal crossover, self-adaptive learning rate, and a new local search operator to enhance exploitation around promising solutions.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, local_search_prob=0.1, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.local_search_prob = local_search_prob # Probability of performing local search\n        self.local_search_radius = local_search_radius # Radius for local search\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n        \n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n            \n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def local_search(self, func, x):\n        x_new = x.copy()\n        for j in range(self.dim):\n            x_new[j] = x[j] + np.random.uniform(-self.local_search_radius, self.local_search_radius)\n        x_new = self.handle_bounds(x_new, func)\n        f_new = func(x_new)\n        self.budget -= 1\n        return x_new, f_new\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n            \n            # Perform local search with a certain probability\n            if np.random.rand() < self.local_search_prob and self.budget > 0:\n                x_local, f_local = self.local_search(func, new_population[i])\n                if f_local < new_fitness[i]:\n                    new_population[i] = x_local\n                    new_fitness[i] = f_local\n                    improved_count += 1\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            # Adaptive Learning Rate\n            self.F_learning_rate = min(0.5, 1.0 / (1.0 + np.exp(5.0 * (0.5 - np.mean(np.abs(np.array(self.successful_F) - self.F)))) )\n            self.CR_learning_rate = min(0.5, 1.0 / (1.0 + np.exp(5.0 * (0.5 - np.mean(np.abs(np.array(self.successful_CR) - self.CR)))) )\n            \n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            \n            self.best_fitness_history.append(current_best_fitness)\n            \n            if self.check_stagnation():\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 111, in evaluate\n    exec(code, safe_globals, local_env)\n  File \"<string>\", line 158\n    self.F_learning_rate = min(0.5, 1.0 / (1.0 + np.exp(5.0 * (0.5 - np.mean(np.abs(np.array(self.successful_F) - self.F)))) )\n                                    \nSyntaxError: invalid syntax. Perhaps you forgot a comma?\n.", "error": "", "parent_ids": ["ef825202-e685-447b-aba2-ee64f82025d2"], "operator": null, "metadata": {}}
{"id": "18b65982-a88f-4b24-a3ff-3af04a93dc3d", "fitness": -Infinity, "name": "AdaptiveDE_OrthoAgingRestart", "description": "Adaptive Differential Evolution with orthogonal crossover, aging, dynamic population size, and a restart mechanism based on stagnation detection to enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveDE_OrthoAgingRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, pop_adapt_rate=0.05, aging_rate=0.01, stagnation_threshold=1e-4, stagnation_reset_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(4 + 3 * np.log(dim))  # Adaptive population size\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = None\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_beta = 0.9\n        self.pop_adapt_rate = pop_adapt_rate\n        self.aging_rate = aging_rate\n        self.age = None # Age of each individual\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_reset_probability = stagnation_reset_probability\n        self.best_fitness_history = []\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n        self.age = np.zeros(self.pop_size)\n        self.best_fitness_history = [np.min(self.fitness)]\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def orthogonal_crossover(self, mutated_population):\n        crossed_population = np.copy(self.population)\n        for i in range(self.pop_size):\n            # Select two parents randomly\n            parent1_idx, parent2_idx = np.random.choice(self.pop_size, 2, replace=False)\n            parent1 = self.population[parent1_idx]\n            parent2 = mutated_population[parent2_idx]\n\n            # Generate an orthogonal matrix (Hadamard matrix)\n            H = self.generate_hadamard_matrix(self.dim)\n\n            # Create offspring using orthogonal crossover\n            for j in range(self.dim):\n                crossed_population[i, j] = 0.5 * (parent1[j] + parent2[j]) + 0.5 * H[i % self.dim, j] * (parent1[j] - parent2[j])\n\n        return crossed_population\n\n    def generate_hadamard_matrix(self, n):\n        # Ensure n is a power of 2\n        if n & (n - 1) != 0:\n            n = 2 ** int(np.ceil(np.log2(n)))  # Round up to the nearest power of 2\n\n        if n == 1:\n            return np.array([[1]])\n\n        H = np.array([[1]])\n        while H.shape[0] < n:\n            H = np.kron(H, np.array([[1, 1], [1, -1]]))\n        return H\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def calculate_crowding_distance(self, self, pop, fitness):\n        distances = np.zeros(len(pop))\n\n        if len(pop) <= 2:\n            distances[:] = np.inf  # Assign infinite distance to all in small populations\n            return distances\n\n        # Normalize each dimension\n        normalized_pop = (pop - np.min(pop, axis=0)) / (np.max(pop, axis=0) - np.min(pop, axis=0) + 1e-8)\n\n        for i in range(self.dim):\n            sorted_indices = np.argsort(normalized_pop[:, i])\n            distances[sorted_indices[0]] = np.inf\n            distances[sorted_indices[-1]] = np.inf\n\n            for j in range(1, len(pop) - 1):\n                distances[sorted_indices[j]] += normalized_pop[sorted_indices[j+1], i] - normalized_pop[sorted_indices[j-1], i]\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                self.age[i] = 0  # Reset age\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    idx_to_replace = np.random.randint(0, self.archive_size)\n                    self.archive[idx_to_replace] = self.population[i].copy()\n            else:\n                self.age[i] += 1  # Increase age\n\n        # Stochastic Ranking Selection\n        combined_population = np.vstack((self.population, crossed_population))\n        combined_fitness = np.concatenate((self.fitness, [func(x) for x in crossed_population]))\n        self.budget -= len(crossed_population)\n\n        ranked_population, ranked_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        # Crowding Distance\n        crowding_distances = self.calculate_crowding_distance(ranked_population, ranked_fitness)\n\n        # Select based on rank and crowding distance\n        selected_indices = np.argsort(-crowding_distances)[:self.pop_size]  # Take top pop_size based on crowding distance\n        new_population = ranked_population[selected_indices]\n        new_fitness = ranked_fitness[selected_indices]\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_beta * self.F_momentum + (1 - self.momentum_beta) * mean_F\n            self.CR_momentum = self.momentum_beta * self.CR_momentum + (1 - self.momentum_beta) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Aging mechanism: replace old individuals\n        for i in range(self.pop_size):\n            if self.age[i] > self.dim * 2:  # Threshold for aging\n                new_population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                new_fitness[i] = func(new_population[i])\n                self.budget -= 1\n                self.age[i] = 0\n\n        # Adaptive population size\n        diversity = np.std(new_fitness)\n        if diversity < self.stagnation_threshold:  # Stagnation detection\n            self.pop_size = min(self.pop_size + int(self.pop_adapt_rate * self.dim), 200)\n        else:\n            self.pop_size = max(int(4 + 3 * np.log(self.dim)), int(self.pop_size * (1 - self.pop_adapt_rate)))\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        # Check if the optimization has stagnated\n        if len(self.best_fitness_history) > 20:\n            recent_improvements = np.diff(self.best_fitness_history[-20:])\n            if np.max(recent_improvements) < self.stagnation_threshold:\n                return True\n        return False\n\n    def restart_population(self, func):\n        # Restart the population with new random individuals\n        new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        new_fitness = np.array([func(x) for x in new_population])\n        self.budget -= self.pop_size\n        self.population = new_population\n        self.fitness = new_fitness\n        self.age = np.zeros(self.pop_size)\n        self.successful_F = []\n        self.successful_CR = []\n        print(\"Restarting population due to stagnation.\")\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > self.pop_size:\n            mutated_population = self.mutate()\n            crossed_population = self.orthogonal_crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            self.best_fitness_history.append(current_best_fitness)\n\n            # Stagnation check and restart\n            if self.check_stagnation() and np.random.rand() < self.stagnation_reset_probability:\n                self.restart_population(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 111, in evaluate\n    exec(code, safe_globals, local_env)\n  File \"<string>\", line 98\nSyntaxError: duplicate argument 'self' in function definition\n.", "error": "", "parent_ids": ["bc4a5368-3375-4a16-9edc-c8c73bd79b99"], "operator": null, "metadata": {}}
{"id": "61086eb7-c7dc-44ca-983b-954fd3fe334f", "fitness": -Infinity, "name": "CMAES_Adaptive_Enhanced", "description": "Adaptive CMA-ES with spectral preconditioning, improved population diversity management via soft restarts, and a more robust local search strategy, aiming to balance exploration and exploitation effectively.", "code": "import numpy as np\n\nclass CMAES_Adaptive_Enhanced:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov_rank_one=None, c_cov_rank_mu=None, mu_factor=0.25, sigma0=0.5, memory_size=100, curvature_adaptation=True, local_search_probability=0.1, local_search_radius=0.1, local_search_num_points=5, restart_trigger=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.popsize * mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = sigma0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max((0, np.sqrt((self.mu / self.dim) - 1))) + self.cs\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 0.15\n        self.c_cov_rank_mu = c_cov_rank_mu if c_cov_rank_mu is not None else 0.15\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = memory_size\n        self.curvature_adaptation = curvature_adaptation\n        self.eigenvalues = np.ones(self.dim)  # Initialize eigenvalues\n        self.B = np.eye(self.dim) # Initialize rotation matrix\n        self.evals = 0\n        self.local_search_probability = local_search_probability\n        self.local_search_radius = local_search_radius\n        self.local_search_num_points = local_search_num_points\n        self.restart_trigger = restart_trigger\n        self.restart_criterion_met = False # Flag to indicate if restart criterion has been met\n\n    def update_decomposition(self):\n        try:\n            self.eigenvalues, self.B = np.linalg.eigh(self.C)  # Eigen decomposition\n            self.eigenvalues = np.maximum(self.eigenvalues, 1e-16)  # Ensure eigenvalues are positive\n        except np.linalg.LinAlgError:\n            self.C = np.eye(self.dim)\n            self.eigenvalues = np.ones(self.dim)\n            self.B = np.eye(self.dim)\n\n    def local_search(self, func, x, radius=0.1, num_points=5):\n        \"\"\"Performs a local search around x.\"\"\"\n        best_f = func(x)\n        best_x = x\n        self.evals += 1\n\n        for _ in range(num_points):\n            x_new = x + np.random.uniform(-radius, radius, size=self.dim)\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x_new = np.clip(x_new, lb, ub)\n            f_new = func(x_new)\n            self.evals += 1\n\n            if f_new < best_f:\n                best_f = f_new\n                best_x = x_new\n        return best_f, best_x\n\n    def spectral_preconditioning(self, func):\n            \"\"\"Initialize the covariance matrix using spectral analysis of initial samples.\"\"\"\n            num_samples = min(self.budget // 10, 100)  # Take a fraction of budget or up to 100 samples\n            X = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_samples, self.dim))\n            F = np.array([func(x) for x in X])\n            self.evals += num_samples\n\n            # Center the data\n            X_centered = X - np.mean(X, axis=0)\n\n            # Calculate covariance matrix\n            try:\n                covariance_matrix = np.cov(X_centered.T)\n                eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n\n                # Ensure positive definiteness by clipping eigenvalues\n                eigenvalues = np.maximum(eigenvalues, 1e-6)\n\n                # Normalize eigenvectors\n                eigenvectors = eigenvectors / np.linalg.norm(eigenvectors, axis=0)\n\n                # Update CMA-ES internal parameters\n                self.C = covariance_matrix\n                self.eigenvalues = eigenvalues\n                self.B = eigenvectors\n                self.update_decomposition()\n            except np.linalg.LinAlgError:\n                pass # Keep identity\n\n\n    def __call__(self, func):\n        self.evals = 0\n        dynamic_popsize = self.popsize\n\n        # Spectral preconditioning\n        self.spectral_preconditioning(func)\n\n        while self.evals < self.budget:\n            # Dynamic population size adjustment\n            if self.evals > self.budget * self.restart_trigger:\n                dynamic_popsize = max(4, int(self.popsize * 0.5))  # Reduce population size later in the search\n                self.restart_criterion_met = True\n            else:\n                dynamic_popsize = self.popsize\n            \n            self.mu = int(dynamic_popsize * 0.25)  #Adjust mu accordingly.\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights /= np.sum(self.weights)\n\n            # Sample population\n            z = np.random.normal(0, 1, size=(dynamic_popsize, self.dim))\n\n            # Use rotation matrix and eigenvalues directly\n            x = self.m + self.sigma * (z @ self.B @ np.diag(self.eigenvalues**0.5))\n            \n            # Clip to bounds.\n            lb = func.bounds.lb\n            ub = func.bounds.ub\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.evals += dynamic_popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Local search refinement\n            if np.random.rand() < self.local_search_probability:\n                f_local, x_local = self.local_search(func, self.x_opt, radius=self.local_search_radius, num_points=self.local_search_num_points)\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.weights @ self.weights)) * (self.m - m_old) @ self.B @ np.diag(self.eigenvalues**-0.5)\n            self.pc = (1 - self.c_cov_rank_one) * self.pc + np.sqrt(self.c_cov_rank_one * (2 - self.c_cov_rank_one)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            hsigma = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.evals / dynamic_popsize))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            \n            dC_rank_one = self.c_cov_rank_one * (self.pc[:, None] @ self.pc[None, :])\n            dC_rank_mu = self.c_cov_rank_mu * np.sum(self.weights[:, None, None] * ((x[:self.mu] - m_old)[:, :, None] @ (x[:self.mu] - m_old)[:, None, :]) / self.sigma**2, axis=0)\n                \n            self.C = (1 - self.c_cov_rank_one - self.c_cov_rank_mu) * self.C + dC_rank_one + dC_rank_mu\n            \n            # Ensure positive definiteness and update decomposition\n            self.update_decomposition()\n\n            # Adaptive step size based on curvature\n            if self.curvature_adaptation:\n                condition_number = np.max(self.eigenvalues) / np.min(self.eigenvalues)\n                self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1) + 0.05 * (condition_number - 1)) # Condition number regularization\n\n            else:\n                 self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n\n            # Enhanced archive handling: keep a diverse set of solutions\n            if len(self.archive) < self.archive_size:\n                self.archive.append((x[0].copy(), f[0]))\n            else:\n                # Replace the worst element in the archive with the current best, if it's better\n                worst_index = np.argmax([item[1] for item in self.archive])\n                if f[0] < self.archive[worst_index][1]:\n                    self.archive[worst_index] = (x[0].copy(), f[0])\n\n            # Soft restart mechanism\n            if self.restart_criterion_met:\n                self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.sigma = sigma0  # Resetting sigma might be aggressive; consider a smaller adjustment.\n                self.ps = np.zeros(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.C = np.eye(self.dim)\n                self.update_decomposition()\n                self.restart_criterion_met = False  # Reset the flag for the next potential restart\n\n        if self.archive:\n            best_archived_solution = min(self.archive, key=lambda item: item[1])\n            if best_archived_solution[1] < self.f_opt:\n                 self.f_opt = best_archived_solution[1]\n                 self.x_opt = best_archived_solution[0]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 183, in __call__\nNameError: name 'sigma0' is not defined. Did you mean: 'hsigma'?\n.", "error": "", "parent_ids": ["5e9a3776-5827-431e-b04c-4edacff53e86"], "operator": null, "metadata": {}}
{"id": "649e9121-eb82-474a-873d-c674789f5c25", "fitness": 0.0, "name": "AdaptiveDE_OrthoAgingRestart", "description": "Enhanced Adaptive DE with orthogonal crossover, aging, dynamic population size, and a novel restart mechanism based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveDE_OrthoAgingRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, pop_adapt_rate=0.05, aging_rate=0.01, restart_diversity_threshold=1e-4, restart_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(4 + 3 * np.log(dim))  # Adaptive population size\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = None\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_beta = 0.9\n        self.pop_adapt_rate = pop_adapt_rate\n        self.aging_rate = aging_rate\n        self.age = None # Age of each individual\n        self.restart_diversity_threshold = restart_diversity_threshold\n        self.restart_probability = restart_probability\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n        self.age = np.zeros(self.pop_size)\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def orthogonal_crossover(self, mutated_population):\n        crossed_population = np.copy(self.population)\n        for i in range(self.pop_size):\n            # Select two parents randomly\n            parent1_idx, parent2_idx = np.random.choice(self.pop_size, 2, replace=False)\n            parent1 = self.population[parent1_idx]\n            parent2 = mutated_population[parent2_idx]\n\n            # Generate an orthogonal matrix (Hadamard matrix)\n            H = self.generate_hadamard_matrix(self.dim)\n\n            # Create offspring using orthogonal crossover\n            for j in range(self.dim):\n                crossed_population[i, j] = 0.5 * (parent1[j] + parent2[j]) + 0.5 * H[i % self.dim, j] * (parent1[j] - parent2[j])\n\n        return crossed_population\n\n    def generate_hadamard_matrix(self, n):\n        # Ensure n is a power of 2\n        if n & (n - 1) != 0:\n            n = 2 ** int(np.ceil(np.log2(n)))  # Round up to the nearest power of 2\n\n        if n == 1:\n            return np.array([[1]])\n\n        H = np.array([[1]])\n        while H.shape[0] < n:\n            H = np.kron(H, np.array([[1, 1], [1, -1]]))\n        return H\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def calculate_crowding_distance(self, pop, fitness):\n        distances = np.zeros(len(pop))\n\n        # Normalize each dimension\n        normalized_pop = (pop - np.min(pop, axis=0)) / (np.max(pop, axis=0) - np.min(pop, axis=0) + 1e-8)\n\n        for i in range(self.dim):\n            sorted_indices = np.argsort(normalized_pop[:, i])\n            distances[sorted_indices[0]] = np.inf\n            distances[sorted_indices[-1]] = np.inf\n\n            for j in range(1, len(pop) - 1):\n                distances[sorted_indices[j]] += normalized_pop[sorted_indices[j+1], i] - normalized_pop[sorted_indices[j-1], i]\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                self.age[i] = 0  # Reset age\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    idx_to_replace = np.random.randint(0, self.archive_size)\n                    self.archive[idx_to_replace] = self.population[i].copy()\n            else:\n                self.age[i] += 1  # Increase age\n\n        # Stochastic Ranking Selection\n        combined_population = np.vstack((self.population, crossed_population))\n        combined_fitness = np.concatenate((self.fitness, [func(x) for x in crossed_population]))\n        self.budget -= len(crossed_population)\n\n        ranked_population, ranked_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        # Crowding Distance\n        crowding_distances = self.calculate_crowding_distance(ranked_population, ranked_fitness)\n\n        # Select based on rank and crowding distance\n        selected_indices = np.argsort(-crowding_distances)[:self.pop_size]  # Take top pop_size based on crowding distance\n        new_population = ranked_population[selected_indices]\n        new_fitness = ranked_fitness[selected_indices]\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_beta * self.F_momentum + (1 - self.momentum_beta) * mean_F\n            self.CR_momentum = self.momentum_beta * self.CR_momentum + (1 - self.momentum_beta) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Aging mechanism: replace old individuals\n        for i in range(self.pop_size):\n            if self.age[i] > self.dim * 2:  # Threshold for aging\n                new_population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                new_fitness[i] = func(new_population[i])\n                self.budget -= 1\n                self.age[i] = 0\n\n        return new_population, new_fitness\n\n    def check_restart(self):\n        diversity = np.std(self.fitness)\n        if diversity < self.restart_diversity_threshold and np.random.rand() < self.restart_probability:\n            return True\n        return False\n    \n    def restart_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.age = np.zeros(self.pop_size)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > self.pop_size:\n            # Adaptive population size\n            diversity = np.std(self.fitness)\n            if diversity < 1e-3:  # Stagnation detection\n                self.pop_size = min(self.pop_size + int(self.pop_adapt_rate * self.dim), 200)\n            else:\n                self.pop_size = max(int(4 + 3 * np.log(self.dim)), int(self.pop_size * (1 - self.pop_adapt_rate)))\n            \n            if self.check_restart():\n                self.restart_population(func)\n                \n            mutated_population = self.mutate()\n            crossed_population = self.orthogonal_crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE_OrthoAgingRestart scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["bc4a5368-3375-4a16-9edc-c8c73bd79b99"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "d036a2cd-d58e-4e23-abe0-46087d8e9b5f", "fitness": -Infinity, "name": "AdaptiveDE_Ortho", "description": "Adaptive Differential Evolution with a refined population size adaptation strategy based on success rate and diversity, and enhanced exploration through a combined mutation strategy and a new diversity-based restart mechanism.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, pop_size_adaptation_rate=0.2, diversity_threshold=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = pop_size_adaptation_rate # Rate to adjust pop size\n        self.diversity_threshold = diversity_threshold\n        self.pop_size_history = []\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            rand_val = np.random.rand()\n            if rand_val < 0.33: # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            elif rand_val < 0.66: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n            else: # Mutation from archive\n                if self.archive:\n                    archive_idx = np.random.randint(len(self.archive))\n                    idxs = np.random.choice(self.pop_size, 1, replace=False)\n                    x1 = self.population[idxs[0]]\n                    mutated_population[i] = self.archive[archive_idx] + self.F * (self.population[i] - x1)\n                else:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n        \n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n            \n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        return new_population, new_fitness\n\n    def calculate_diversity(self):\n        centroid = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def adjust_population_size(self, improvement_ratio, diversity):\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max and diversity > self.diversity_threshold:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif (improvement_ratio < 0.1 or diversity <= self.diversity_threshold) and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n        self.pop_size_history.append(self.pop_size)\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n    \n    def diversity_based_restart(self, func):\n        diversity = self.calculate_diversity()\n        if diversity < self.diversity_threshold:\n            self.restart(func)\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            \n            self.best_fitness_history.append(current_best_fitness)\n\n            improvement_ratio = np.sum(self.fitness < np.array(self.best_fitness_history[-self.pop_size:]))/self.pop_size if len(self.best_fitness_history) > self.pop_size else 0.0\n            diversity = self.calculate_diversity()\n            self.adjust_population_size(improvement_ratio, diversity)\n\n            if self.check_stagnation() or self.diversity_based_restart(func):\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 218, in __call__\nValueError: operands could not be broadcast together with shapes (100,) (24,) \n.", "error": "", "parent_ids": ["ef825202-e685-447b-aba2-ee64f82025d2"], "operator": null, "metadata": {}}
{"id": "5f08715b-a9cd-447f-a21e-dfdb12e5c44d", "fitness": 0.08646096347960759, "name": "AdaptiveDE_OrthoAgingRestart", "description": "Adaptive Differential Evolution with orthogonal crossover, aging, dynamic population size, and a restart mechanism triggered by stagnation, along with improved parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveDE_OrthoAgingRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, pop_adapt_rate=0.05, aging_rate=0.01, stagnation_threshold=1e-4, restart_patience=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(4 + 3 * np.log(dim))  # Adaptive population size\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = None\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_beta = 0.9\n        self.pop_adapt_rate = pop_adapt_rate\n        self.aging_rate = aging_rate\n        self.age = None # Age of each individual\n        self.stagnation_threshold = stagnation_threshold\n        self.restart_patience = restart_patience\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n        self.age = np.zeros(self.pop_size)\n        self.best_fitness_history = [np.min(self.fitness)]  # Initialize with initial best fitness\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def orthogonal_crossover(self, mutated_population):\n        crossed_population = np.copy(self.population)\n        for i in range(self.pop_size):\n            # Select two parents randomly\n            parent1_idx, parent2_idx = np.random.choice(self.pop_size, 2, replace=False)\n            parent1 = self.population[parent1_idx]\n            parent2 = mutated_population[parent2_idx]\n\n            # Generate an orthogonal matrix (Hadamard matrix)\n            H = self.generate_hadamard_matrix(self.dim)\n\n            # Create offspring using orthogonal crossover\n            for j in range(self.dim):\n                crossed_population[i, j] = 0.5 * (parent1[j] + parent2[j]) + 0.5 * H[i % self.dim, j] * (parent1[j] - parent2[j])\n\n        return crossed_population\n\n    def generate_hadamard_matrix(self, n):\n        # Ensure n is a power of 2\n        if n & (n - 1) != 0:\n            n = 2 ** int(np.ceil(np.log2(n)))  # Round up to the nearest power of 2\n\n        if n == 1:\n            return np.array([[1]])\n\n        H = np.array([[1]])\n        while H.shape[0] < n:\n            H = np.kron(H, np.array([[1, 1], [1, -1]]))\n        return H\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def calculate_crowding_distance(self, pop, fitness):\n        distances = np.zeros(len(pop))\n\n        # Normalize each dimension\n        normalized_pop = (pop - np.min(pop, axis=0)) / (np.max(pop, axis=0) - np.min(pop, axis=0) + 1e-8)\n\n        for i in range(self.dim):\n            sorted_indices = np.argsort(normalized_pop[:, i])\n            distances[sorted_indices[0]] = np.inf\n            distances[sorted_indices[-1]] = np.inf\n\n            for j in range(1, len(pop) - 1):\n                distances[sorted_indices[j]] += normalized_pop[sorted_indices[j+1], i] - normalized_pop[sorted_indices[j-1], i]\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                self.age[i] = 0  # Reset age\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    idx_to_replace = np.random.randint(0, self.archive_size)\n                    self.archive[idx_to_replace] = self.population[i].copy()\n            else:\n                self.age[i] += 1  # Increase age\n\n        # Stochastic Ranking Selection\n        combined_population = np.vstack((self.population, crossed_population))\n        combined_fitness = np.concatenate((self.fitness, [func(x) for x in crossed_population]))\n        self.budget -= len(crossed_population)\n\n        ranked_population, ranked_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        # Crowding Distance\n        crowding_distances = self.calculate_crowding_distance(ranked_population, ranked_fitness)\n\n        # Select based on rank and crowding distance\n        selected_indices = np.argsort(-crowding_distances)[:self.pop_size]  # Take top pop_size based on crowding distance\n        new_population = ranked_population[selected_indices]\n        new_fitness = ranked_fitness[selected_indices]\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_beta * self.F_momentum + (1 - self.momentum_beta) * mean_F\n            self.CR_momentum = self.momentum_beta * self.CR_momentum + (1 - self.momentum_beta) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Aging mechanism: replace old individuals\n        for i in range(self.pop_size):\n            if self.age[i] > self.dim * 2:  # Threshold for aging\n                new_population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                new_fitness[i] = func(new_population[i])\n                self.budget -= 1\n                self.age[i] = 0\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) > self.restart_patience:\n            recent_improvements = np.diff(self.best_fitness_history[-self.restart_patience:])\n            if np.max(recent_improvements) < self.stagnation_threshold:\n                self.stagnation_counter += 1\n                return True\n            else:\n                self.stagnation_counter = 0\n                return False\n        else:\n            return False\n\n    def restart_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.age = np.zeros(self.pop_size)\n        self.F = 0.5\n        self.CR = 0.5\n        self.successful_F = []\n        self.successful_CR = []\n        print(\"Restarting population...\")\n\n    def adapt_population_size(self):\n        diversity = np.std(self.fitness)\n        if diversity < 1e-3:  # Stagnation detection\n            self.pop_size = min(self.pop_size + int(self.pop_adapt_rate * self.dim), 200)\n        else:\n            self.pop_size = max(int(4 + 3 * np.log(self.dim)), int(self.pop_size * (1 - self.pop_adapt_rate)))\n        \n        if self.population.shape[0] != self.pop_size:\n            # Resize population.  Simplest strategy: re-initialize.  More sophisticated would be interpolation/extrapolation.\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population]) # Recalculate fitness after resize\n            self.age = np.zeros(self.pop_size)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > self.pop_size:\n            mutated_population = self.mutate()\n            crossed_population = self.orthogonal_crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(self.f_opt)\n\n            if self.check_stagnation():\n                self.restart_population(func)\n                self.best_fitness_history = [self.f_opt]\n\n            self.adapt_population_size()\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE_OrthoAgingRestart scored 0.086 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["bc4a5368-3375-4a16-9edc-c8c73bd79b99"], "operator": null, "metadata": {"aucs": [0.10192821994828061, 0.15745467049054218, 0]}}
{"id": "9d50ef5d-82a5-413a-96a5-a15d303e2b4e", "fitness": 0.47170684268122776, "name": "AdaptiveDE_Ortho_Archive", "description": "Adaptive Differential Evolution with orthogonal crossover, a combination of 'current-to-best' and 'rand' mutation strategies, stochastic ranking, and adaptive population sizing based on a success rate to balance exploration and exploitation and using an external archive to improve convergence.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        \n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n        \n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n            \n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n            \n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n        \n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n        \n        self.archive = list(combined_population[:self.archive_size]) # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            \n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n            \n            if self.check_stagnation():\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE_Ortho_Archive scored 0.472 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ef825202-e685-447b-aba2-ee64f82025d2"], "operator": null, "metadata": {"aucs": [0.21747962033614043, 0.3640659205518989, 0.4348485671262793, 0.6797193323429807, 0.43051767950415487, 0.5291670811675153, 0.33353785073441256, 0.403503459886948, 0.4328942545584472, 0.34545544887092694, 0.6176545837371135, 0.997528264528402, 0.2889362384858759, 0.386297076119806, 0.7634534761793151, 0.5166727790100705, 0.36171230091228823, 0.6114253511232266, 0.21226536119466344, 0.5070022072540872]}}
{"id": "01c09fe8-1fee-4f9f-aa02-8c4a14d44e69", "fitness": 0.38975955568986803, "name": "AdaptiveDE_Ortho_LARS", "description": "Adaptive Differential Evolution with orthogonal crossover, archive-based mutation, and a self-adjusting restart mechanism using the Landscape Aware Restart Strategy (LARS).", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_LARS:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, lars_threshold=1e-4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.lars_threshold = lars_threshold\n        self.landscape_awareness = []\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Archive-based mutation\n                if self.archive:\n                    archive_idx = np.random.randint(len(self.archive))\n                    archived_vector = self.archive[archive_idx]\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x1, x2 = self.population[idxs]\n                    mutated_population[i] = self.population[i] + self.F * (archived_vector - self.population[i]) + self.F * (x1 - x2)\n                else: # Fallback to random mutation if archive is empty\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutated_population[i] = x1 + self.F * (x2 - x3)\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n        \n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n            \n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n    \n    def assess_landscape_awareness(self):\n        # Measure the diversity of the population\n        diversity = np.mean([np.linalg.norm(x - self.x_opt) for x in self.population])\n\n        # Measure the improvement rate\n        if len(self.best_fitness_history) > 1:\n            improvement = self.best_fitness_history[-1] - self.best_fitness_history[-2]\n        else:\n            improvement = 0\n\n        self.landscape_awareness.append((diversity, improvement))\n\n    def landscape_aware_restart(self, func):\n         # Analyze landscape awareness data to determine restart strategy\n        if len(self.landscape_awareness) > 10:\n            recent_data = self.landscape_awareness[-10:]\n            diversities, improvements = zip(*recent_data)\n\n            avg_diversity = np.mean(diversities)\n            avg_improvement = np.mean(improvements)\n\n            if abs(avg_improvement) < self.lars_threshold: # Stagnation detected\n                # Option 1: Re-initialize population near the best solution\n                self.population = np.random.normal(loc=self.x_opt, scale=0.1, size=(self.pop_size, self.dim))\n                self.population = self.handle_bounds(self.population, func)  # Ensure bounds are respected\n\n            else:\n                # Option 2: More exploration - Re-initialize population randomly\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            self.landscape_awareness = []  # Reset landscape awareness data\n    \n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            \n            self.best_fitness_history.append(current_best_fitness)\n            self.assess_landscape_awareness()\n            \n            if self.check_stagnation():\n                self.landscape_aware_restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE_Ortho_LARS scored 0.390 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ef825202-e685-447b-aba2-ee64f82025d2"], "operator": null, "metadata": {"aucs": [0.16078339246779472, 0.25301986885588, 0.3578285399730383, 0.42362619340486485, 0.30054115008507964, 0.391310955620908, 0.32667602429437925, 0.3348434500652805, 0.33244867754602425, 0.1926926189479642, 0.42743808806852135, 0.9982421636493642, 0.2756076049103554, 0.34279816770947713, 0.7382327999663147, 0.4199513444772006, 0.3424785721431033, 0.46170080400091273, 0.21107967751988266, 0.5038910200910156]}}
{"id": "8ee489b3-5a38-4c3a-8728-79c9038bb275", "fitness": 0.47176534490170485, "name": "AdaptiveDE_Ortho_Mirrored", "description": "Adaptive Differential Evolution with orthogonal crossover, archive-based mutation, and self-adjusting F/CR parameters using a mirrored sampling approach for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Mirrored:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.33: # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            elif np.random.rand() < 0.66 and len(self.archive) > 0: # Archive-based mutation\n                arc_idx = np.random.randint(len(self.archive))\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.archive[arc_idx] - self.population[i]) + self.F * (x1 - x2)\n\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n        \n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n            \n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum and mirrored sampling\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            # Mirrored sampling for F and CR\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n            # Ensure F and CR stay within [0, 1] using mirrored sampling\n            self.F = np.abs(np.sin(self.F))  # Reflect back from 0 and 1\n            self.CR = np.abs(np.cos(self.CR)) # Reflect back from 0 and 1\n\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            \n            self.best_fitness_history.append(current_best_fitness)\n            \n            if self.check_stagnation():\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE_Ortho_Mirrored scored 0.472 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ef825202-e685-447b-aba2-ee64f82025d2"], "operator": null, "metadata": {"aucs": [0.1983137773649266, 0.386462067712514, 0.4749074377263355, 0.7353233748481756, 0.4217191416639443, 0.5191151379719203, 0.32336621730852044, 0.3849082460897887, 0.4140337678272543, 0.21365573257207615, 0.7232878846919497, 0.995260422229386, 0.3119533524605418, 0.40210522925874714, 0.7482709468411309, 0.46709629006002784, 0.3994239057600446, 0.599882843031593, 0.2117452934652153, 0.5044758291500063]}}
{"id": "cbc35095-08b7-4db4-adb8-7e6188394a19", "fitness": 0.46105224874038936, "name": "AdaptiveDE_OrthoArchive", "description": "Adaptive Differential Evolution with orthogonal crossover, archive-based mutation, and a self-regulating strategy adaptation with a penalty-based stochastic ranking.", "code": "import numpy as np\n\nclass AdaptiveDE_OrthoArchive:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=15, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, exploration_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.exploration_prob = exploration_prob  # Probability of using archive-based exploration\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            elif np.random.rand() < self.exploration_prob and len(self.archive) > 0:  # Archive-based mutation\n                archive_idx = np.random.randint(len(self.archive))\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.archive[archive_idx] + self.F * (x1 - x2)\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness, func):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        # Constraint violation penalty.  Modify to fit the problem if needed\n        def constraint_violation(x):\n            return 0 # No constraints in the benchmark\n\n        def compare(i, j):\n            fi = fitness[i] + constraint_violation(pop[i])\n            fj = fitness[j] + constraint_violation(pop[j])\n            \n            return fi - fj\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k] + constraint_violation(pop[k]))\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness, func)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            \n            self.best_fitness_history.append(current_best_fitness)\n            \n            if self.check_stagnation():\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE_OrthoArchive scored 0.461 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ef825202-e685-447b-aba2-ee64f82025d2"], "operator": null, "metadata": {"aucs": [0.1439981893416178, 0.3665522063700668, 0.4232158566276779, 0.6541878947129476, 0.3810855841122317, 0.531198758026999, 0.36462974883254673, 0.4004077862685367, 0.41391994317725844, 0.342604057080099, 0.5033247734124623, 0.9919233944355629, 0.2892827556244054, 0.36732036408845936, 0.7670340494728496, 0.5055004473636686, 0.39654038993826046, 0.614702877135539, 0.2587739639076089, 0.5048419348789892]}}
{"id": "8ef420e0-5dfb-4df6-91be-9d051a3a9e54", "fitness": -Infinity, "name": "AdaptiveDE_OrthoArchive_Neighborhood", "description": "Adaptive Differential Evolution with orthogonal crossover, an archive-based mutation strategy, a landscape aware self-adaptive mechanism for F/CR and population size, and introduces a neighborhood-based mutation operator to intensify local search.", "code": "import numpy as np\n\nclass AdaptiveDE_OrthoArchive_Neighborhood:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=15, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, exploration_prob=0.1, neighborhood_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.exploration_prob = exploration_prob  # Probability of using archive-based exploration\n        self.neighborhood_size = neighborhood_size # Number of neighbors to consider for local search\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.33: # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            elif np.random.rand() < self.exploration_prob and len(self.archive) > 0:  # Archive-based mutation\n                archive_idx = np.random.randint(len(self.archive))\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.archive[archive_idx] + self.F * (x1 - x2)\n            elif np.random.rand() < 0.33: # Neighborhood mutation\n                neighbors_idx = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                neighbors = self.population[neighbors_idx]\n                neighbor_fitness = self.fitness[neighbors_idx]\n                best_neighbor_idx = np.argmin(neighbor_fitness)\n                best_neighbor = neighbors[best_neighbor_idx]\n                mutated_population[i] = self.population[i] + self.F * (best_neighbor - self.population[i])\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness, func):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        # Constraint violation penalty.  Modify to fit the problem if needed\n        def constraint_violation(x):\n            return 0 # No constraints in the benchmark\n\n        def compare(i, j):\n            fi = fitness[i] + constraint_violation(pop[i])\n            fj = fitness[j] + constraint_violation(pop[j])\n            \n            return fi - fj\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k] + constraint_violation(pop[k]))\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, self.population, fitness):\n        distances = np.zeros(len(self.population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = self.population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(self.population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness, func)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            \n            self.best_fitness_history.append(current_best_fitness)\n            \n            if self.check_stagnation():\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 111, in evaluate\n    exec(code, safe_globals, local_env)\n  File \"<string>\", line 103\n    def crowding_distance(self, self.population, fitness):\n                                    ^\nSyntaxError: invalid syntax\n.", "error": "", "parent_ids": ["cbc35095-08b7-4db4-adb8-7e6188394a19"], "operator": null, "metadata": {}}
{"id": "e2afbddb-8714-4b3c-a428-cd08b1f5d08c", "fitness": -Infinity, "name": "AdaptiveDE_OrthoArchive_SVD", "description": "Adaptive Differential Evolution with orthogonal crossover, archive, SVD-based mutation to perturb individuals towards promising directions, and adaptive strategy parameters.", "code": "import numpy as np\nfrom numpy.linalg import svd\n\nclass AdaptiveDE_OrthoArchive_SVD:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=15, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, exploration_prob=0.1, svd_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.exploration_prob = exploration_prob  # Probability of using archive-based exploration\n        self.svd_prob = svd_prob  # Probability of applying SVD-based mutation\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            elif np.random.rand() < self.exploration_prob and len(self.archive) > 0:  # Archive-based mutation\n                archive_idx = np.random.randint(len(self.archive))\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.archive[archive_idx] + self.F * (x1 - x2)\n            elif np.random.rand() < self.svd_prob and len(self.best_fitness_history) > 20: # SVD-based mutation\n                # Perturb individual along the principal components of recent search steps\n                num_steps = min(20, len(self.best_fitness_history) - 1)\n                diffs = np.array([self.population[np.argmin(self.fitness)] - self.best_x_history[-k] for k in range(1, num_steps + 1)]) # corrected the index\n                try:\n                    U, S, V = svd(diffs)\n                    direction = V[0]  # Principal direction\n                    step_size = self.F * np.random.normal() * S[0]  # Adaptive step size\n                    mutated_population[i] = self.population[i] + step_size * direction\n                except np.linalg.LinAlgError:\n                    # SVD failed, fall back to random mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutated_population[i] = x1 + self.F * (x2 - x3)\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zerosLike(self.population)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness, func):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        # Constraint violation penalty.  Modify to fit the problem if needed\n        def constraint_violation(x):\n            return 0 # No constraints in the benchmark\n\n        def compare(i, j):\n            fi = fitness[i] + constraint_violation(pop[i])\n            fj = fitness[j] + constraint_violation(pop[j])\n            \n            return fi - fj\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k] + constraint_violation(pop[k]))\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness, func)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n        self.best_x_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n        self.best_x_history = [self.x_opt]\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            current_best_x = self.population[np.argmin(self.fitness)]\n\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = current_best_x\n\n            self.best_fitness_history.append(current_best_fitness)\n            self.best_x_history.append(current_best_x)\n            \n            if self.check_stagnation():\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                self.best_x_history.append(self.population[np.argmin(self.fitness)])\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 196, in __call__\n  File \"<string>\", line 72, in crossover\n  File \"/home/neocortex/.cache/pypoetry/virtualenvs/blade-xXF9vABH-py3.10/lib/python3.10/site-packages/numpy/__init__.py\", line 320, in __getattr__\n    raise AttributeError(\"module {!r} has no attribute \"\nAttributeError: module 'numpy' has no attribute 'zerosLike'. Did you mean: 'zeros_like'?\n.", "error": "", "parent_ids": ["cbc35095-08b7-4db4-adb8-7e6188394a19"], "operator": null, "metadata": {}}
{"id": "4a930559-1bac-4810-ada9-b386d5d57bca", "fitness": -Infinity, "name": "AdaptiveDE_Ortho_LARS", "description": "Adaptive Differential Evolution with orthogonal crossover, archive-based mutation, self-adjusting F/CR parameters, adaptive population sizing based on fitness variance, and a landscape-aware restart strategy using spectral analysis for enhanced exploration and exploitation.", "code": "import numpy as np\nfrom numpy.linalg import norm, eig\n\nclass AdaptiveDE_Ortho_LARS:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, lars_threshold=1e-4, variance_threshold=1e-6):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max\n        self.archive_size = archive_size\n        self.F = F_initial\n        self.CR = CR_initial\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size\n        self.pop_size_adaptation_rate = 0.1\n        self.lars_threshold = lars_threshold\n        self.landscape_awareness = []\n        self.variance_threshold = variance_threshold\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:\n                if self.archive:\n                    archive_idx = np.random.randint(len(self.archive))\n                    archived_vector = self.archive[archive_idx]\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x1, x2 = self.population[idxs]\n                    mutated_population[i] = self.population[i] + self.F * (archived_vector - self.population[i]) + self.F * (x1 - x2)\n                else:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutated_population[i] = x1 + self.F * (x2 - x3)\n            else:\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n        \n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n            \n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive)))\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy()\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation based on fitness variance\n        fitness_variance = np.var(new_fitness)\n        if fitness_variance > self.variance_threshold and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif fitness_variance <= self.variance_threshold and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n    \n    def assess_landscape_awareness(self):\n        diversity = np.mean([norm(x - self.x_opt) for x in self.population])\n\n        if len(self.best_fitness_history) > 1:\n            improvement = self.best_fitness_history[-1] - self.best_fitness_history[-2]\n        else:\n            improvement = 0\n\n        self.landscape_awareness.append((diversity, improvement))\n\n    def analyze_eigenvalues(self):\n        # Calculate the covariance matrix\n        covariance_matrix = np.cov(self.population.T)\n\n        # Perform eigenvalue decomposition\n        eigenvalues, eigenvectors = eig(covariance_matrix)\n\n        # Sort eigenvalues in descending order\n        eigenvalues = np.sort(eigenvalues)[::-1]\n\n        return eigenvalues\n\n    def landscape_aware_restart(self, func):\n        eigenvalues = self.analyze_eigenvalues()\n        \n        # Calculate condition number (ratio of largest to smallest eigenvalue)\n        condition_number = eigenvalues[0] / eigenvalues[-1] if eigenvalues[-1] != 0 else np.inf\n\n        if len(self.landscape_awareness) > 10:\n            recent_data = self.landscape_awareness[-10:]\n            diversities, improvements = zip(*recent_data)\n\n            avg_diversity = np.mean(diversities)\n            avg_improvement = np.mean(improvements)\n\n            if abs(avg_improvement) < self.lars_threshold or condition_number > 1e6:\n                if avg_diversity < 0.1: #Exploitation\n                    self.population = np.random.normal(loc=self.x_opt, scale=0.05, size=(self.pop_size, self.dim))\n                    self.population = self.handle_bounds(self.population, func)\n                else: # Exploration\n                    self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            else:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n\n\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0\n            self.best_fitness_history = []\n            self.landscape_awareness = []\n    \n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            \n            self.best_fitness_history.append(current_best_fitness)\n            self.assess_landscape_awareness()\n            \n            if self.check_stagnation():\n                self.landscape_aware_restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 251, in __call__\n  File \"<string>\", line 174, in assess_landscape_awareness\n  File \"<string>\", line 174, in <listcomp>\nNameError: name 'norm' is not defined\n.", "error": "", "parent_ids": ["01c09fe8-1fee-4f9f-aa02-8c4a14d44e69"], "operator": null, "metadata": {}}
{"id": "0754e3c1-5631-4f1c-8759-c9f4ea9d3204", "fitness": -Infinity, "name": "AdaptiveDE_Ortho_LARS_NM", "description": "Adaptive Differential Evolution with orthogonal crossover, archive-based mutation, self-adjusting F/CR, and a landscape-aware restart strategy incorporating Nelder-Mead local search for refinement.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDE_Ortho_LARS_NM:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, lars_threshold=1e-4, nm_max_iter=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.lars_threshold = lars_threshold\n        self.landscape_awareness = []\n        self.nm_max_iter = nm_max_iter # Max iterations for Nelder-Mead\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Archive-based mutation\n                if self.archive:\n                    archive_idx = np.random.randint(len(self.archive))\n                    archived_vector = self.archive[archive_idx]\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x1, x2 = self.population[idxs]\n                    mutated_population[i] = self.population[i] + self.F * (archived_vector - self.population[i]) + self.F * (x1 - x2)\n                else: # Fallback to random mutation if archive is empty\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutated_population[i] = x1 + self.F * (x2 - x3)\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n        \n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n            \n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(new_population, new_fitness) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n    \n    def assess_landscape_awareness(self):\n        # Measure the diversity of the population\n        diversity = np.mean([np.linalg.norm(x - self.x_opt) for x in self.population])\n\n        # Measure the improvement rate\n        if len(self.best_fitness_history) > 1:\n            improvement = self.best_fitness_history[-1] - self.best_fitness_history[-2]\n        else:\n            improvement = 0\n\n        self.landscape_awareness.append((diversity, improvement))\n\n    def landscape_aware_restart(self, func):\n         # Analyze landscape awareness data to determine restart strategy\n        if len(self.landscape_awareness) > 10:\n            recent_data = self.landscape_awareness[-10:]\n            diversities, improvements = zip(*recent_data)\n\n            avg_diversity = np.mean(diversities)\n            avg_improvement = np.mean(improvements)\n\n            if abs(avg_improvement) < self.lars_threshold: # Stagnation detected\n                # Option 1: Re-initialize population near the best solution and apply Nelder-Mead\n                # First, re-initialize population near the best solution\n                self.population = np.random.normal(loc=self.x_opt, scale=0.1, size=(self.pop_size, self.dim))\n                self.population = self.handle_bounds(self.population, func)  # Ensure bounds are respected\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n                # Then apply Nelder-Mead to refine the best solution\n                result = minimize(func, self.x_opt, method='Nelder-Mead', options={'maxiter': self.nm_max_iter})\n                if result.success:\n                    self.x_opt = result.x\n                    self.f_opt = result.fun\n                    self.budget -= result.nfev  # Account for function evaluations in Nelder-Mead\n                else:\n                    print(\"Nelder-Mead failed to converge.\")\n            else:\n                # Option 2: More exploration - Re-initialize population randomly\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            self.landscape_awareness = []  # Reset landscape awareness data\n    \n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                \n                # Apply Nelder-Mead to refine the best solution\n                result = minimize(func, self.x_opt, method='Nelder-Mead', options={'maxiter': self.nm_max_iter})\n                if result.success:\n                    self.x_opt = result.x\n                    self.f_opt = result.fun\n                    self.budget -= result.nfev  # Account for function evaluations in Nelder-Mead\n\n            \n            self.best_fitness_history.append(current_best_fitness)\n            self.assess_landscape_awareness()\n            \n            if self.check_stagnation():\n                self.landscape_aware_restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 111, in evaluate\n    exec(code, safe_globals, local_env)\n  File \"<string>\", line 100\nSyntaxError: duplicate argument 'self' in function definition\n.", "error": "", "parent_ids": ["01c09fe8-1fee-4f9f-aa02-8c4a14d44e69"], "operator": null, "metadata": {}}
{"id": "30860f68-62cc-49f2-8523-c1f4e3e4d116", "fitness": -Infinity, "name": "AdaptiveDE_Ortho_Mirrored_Diversity", "description": "Adaptive Differential Evolution with orthogonal crossover, archive and mirrored sampling, employing a diversity-guided mutation strategy and adaptive population size adjustment to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Mirrored_Diversity:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.diversity_threshold = diversity_threshold # Threshold for triggering diversity enhancement\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def calculate_diversity(self):\n        # Calculate the average distance from each individual to the population center\n        center = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - center, axis=1)\n        return np.mean(distances)\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        diversity = self.calculate_diversity()\n\n        for i in range(self.pop_size):\n            if diversity < self.diversity_threshold:  # Enhance exploration if diversity is low\n                if np.random.rand() < 0.5:  # More exploration-focused mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutated_population[i] = x1 + self.F * (x2 - x3)\n                else:\n                    mutated_population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim)) # Random restart\n            else:\n                if np.random.rand() < 0.33: # Current-to-best mutation\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x1, x2 = self.population[idxs]\n                    mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n                elif np.random.rand() < 0.66 and len(self.archive) > 0: # Archive-based mutation\n                    arc_idx = np.random.randint(len(self.archive))\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x1, x2 = self.population[idxs]\n                    mutated_population[i] = self.population[i] + self.F * (self.archive[arc_idx] - self.population[i]) + self.F * (x1 - x2)\n                else: # Random mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n        \n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n            \n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum and mirrored sampling\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            # Mirrored sampling for F and CR\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n            # Ensure F and CR stay within [0, 1] using mirrored sampling\n            self.F = np.abs(np.sin(self.F))  # Reflect back from 0 and 1\n            self.CR = np.abs(np.cos(self.CR)) # Reflect back from 0 and 1\n\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            \n            self.best_fitness_history.append(current_best_fitness)\n            \n            if self.check_stagnation():\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 208, in __call__\n  File \"<string>\", line 54, in mutate\nNameError: name 'func' is not defined\n.", "error": "", "parent_ids": ["8ee489b3-5a38-4c3a-8728-79c9038bb275"], "operator": null, "metadata": {}}
{"id": "1bf01247-929d-4755-a735-5e09e9f28dc6", "fitness": 0.45675458200728325, "name": "AdaptiveDE_Ortho_Archive_Improved", "description": "Improved Adaptive Differential Evolution with orthogonal crossover, a more aggressive archive update, dynamic F/CR adaptation using a smoother with momentum, and a landscape-aware population resizing strategy.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_Improved:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, lars_tolerance=1e-5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.lars_tolerance = lars_tolerance\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i + 1]] - dimension_values[sorted_indices[i - 1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = np.clip((1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum, 0.1, 0.9) # Clip F\n            self.CR = np.clip((1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum, 0.1, 0.9) # Clip CR\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation based on landscape awareness\n        if self.generation > 50:\n            fitness_std = np.std(self.fitness)\n            if fitness_std < self.lars_tolerance and self.pop_size > self.pop_size_min:\n                self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n            elif fitness_std > self.lars_tolerance and self.pop_size < self.pop_size_max:\n                self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        # Select top archive_size individuals + some random individuals to promote diversity\n        num_elite = int(0.8 * self.archive_size)  # Keep top 80%\n        elite_indices = np.arange(num_elite)\n        random_indices = np.random.choice(len(combined_population), self.archive_size - num_elite, replace=False)\n        selected_indices = np.concatenate((elite_indices, random_indices))\n        np.random.shuffle(selected_indices)  # Shuffle to mix elite and random\n        \n        self.archive = list(combined_population[selected_indices])\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            if self.check_stagnation():\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_Improved scored 0.457 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9d50ef5d-82a5-413a-96a5-a15d303e2b4e"], "operator": null, "metadata": {"aucs": [0.1735508624288714, 0.27224877825495175, 0.43524274292427045, 0.6340562525588682, 0.38915518179473996, 0.5378669657968839, 0.33592214074384585, 0.4034611072090707, 0.4352493749189732, 0.24323125902697984, 0.598451716845513, 0.9978070945904383, 0.2915614874958513, 0.3858862576664567, 0.7549942886139651, 0.5047371799076332, 0.37604344586832317, 0.6459999364718289, 0.21942606616095672, 0.5001995008672446]}}
{"id": "d1401dc9-a3a9-4a83-96e5-96e9d753e69d", "fitness": 0.47189653512204294, "name": "AdaptiveDE_Ortho_Archive_LocalSearch", "description": "Introducing local search with a decreasing radius and adaptive restart based on landscape exploration to escape local optima and refine solutions.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        if np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            print(\"Restarting population.\")\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n\n        for _ in range(self.dim * 2): # Budget conscious local search\n            if self.budget <= 0:\n                break\n\n            direction = np.random.uniform(-1, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)  # Normalize\n\n            new_x = best_x + self.local_search_radius * direction\n            new_x = self.handle_bounds(new_x[None, :], func)[0] # Handle bounds for single vector\n\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n\n        self.local_search_radius *= self.local_search_radius_decay # Reduce radius\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            if self.generation % self.local_search_frequency == 0:\n                self.local_search(func)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = 0.1 # Reset radius\n        \n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch scored 0.472 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9d50ef5d-82a5-413a-96a5-a15d303e2b4e"], "operator": null, "metadata": {"aucs": [0.1993094535151516, 0.42349724839638136, 0.437186276076291, 0.7382183574446297, 0.4201697488329207, 0.5209359903656884, 0.3249554882177472, 0.4060572750800432, 0.4420791458843947, 0.31684133310184903, 0.5000478360425539, 0.9995970310852327, 0.2899995773477656, 0.37883049314792694, 0.7332670845464081, 0.5336162639476939, 0.3827979415716046, 0.6259229083238002, 0.25522575379275225, 0.5093754957200263]}}
{"id": "5ec3e4b9-dd73-424c-93c1-3db9709a3312", "fitness": 0.46086257142928133, "name": "AdaptiveDE_OrthoArchive_LocalSearch", "description": "Adaptive Differential Evolution with orthogonal crossover, archive-based mutation, a self-regulating strategy adaptation with stochastic ranking, and a dynamic local search strategy triggered by stagnation to refine promising solutions.", "code": "import numpy as np\n\nclass AdaptiveDE_OrthoArchive_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=15, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, exploration_prob=0.1, local_search_prob=0.1, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.exploration_prob = exploration_prob  # Probability of using archive-based exploration\n        self.local_search_prob = local_search_prob # Probability of performing local search\n        self.local_search_radius = local_search_radius # Radius for local search\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            elif np.random.rand() < self.exploration_prob and len(self.archive) > 0:  # Archive-based mutation\n                archive_idx = np.random.randint(len(self.archive))\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.archive[archive_idx] + self.F * (x1 - x2)\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness, func):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        # Constraint violation penalty.  Modify to fit the problem if needed\n        def constraint_violation(x):\n            return 0 # No constraints in the benchmark\n\n        def compare(i, j):\n            fi = fitness[i] + constraint_violation(pop[i])\n            fj = fitness[j] + constraint_violation(pop[j])\n            \n            return fi - fj\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k] + constraint_violation(pop[k]))\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness, func)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def local_search(self, func, x):\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n\n        for _ in range(5): # Limited local search evaluations\n            neighbor = x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n            f = func(neighbor)\n            self.budget -= 1\n\n            if f < best_f:\n                best_f = f\n                best_x = neighbor.copy()\n        return best_x, best_f\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            best_idx = np.argmin(self.fitness)\n\n            # Local Search around the best solution with a probability\n            if np.random.rand() < self.local_search_prob:\n                best_x_local, best_f_local = self.local_search(func, self.population[best_idx].copy())\n                if best_f_local < current_best_fitness:\n                    self.population[best_idx] = best_x_local\n                    self.fitness[best_idx] = best_f_local\n                    current_best_fitness = best_f_local\n\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            \n            self.best_fitness_history.append(current_best_fitness)\n            \n            if self.check_stagnation():\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE_OrthoArchive_LocalSearch scored 0.461 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cbc35095-08b7-4db4-adb8-7e6188394a19"], "operator": null, "metadata": {"aucs": [0.19537453175471942, 0.3088635403958142, 0.41434173248854933, 0.7089832202385453, 0.35741609189556733, 0.5153084997718291, 0.3169687471724083, 0.4052805695094265, 0.389946863677354, 0.357487522230613, 0.5810088953363541, 0.99063568541381, 0.306280579518306, 0.38723057031438113, 0.746887060722594, 0.541548526172393, 0.3670441437492684, 0.5909910254108606, 0.23475155943473835, 0.5009020633780947]}}
{"id": "0b0e6e46-46f7-452a-bf16-97d35c1d3a78", "fitness": 0.39841346068122646, "name": "AdaptiveDE_Ortho_LARS_LocalSearch", "description": "Adaptive Differential Evolution with orthogonal crossover, archive-based mutation, LARS, and a local search around the best solution when stagnation is detected, enhancing exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_LARS_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, lars_threshold=1e-4, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.lars_threshold = lars_threshold\n        self.landscape_awareness = []\n        self.local_search_radius = local_search_radius\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Archive-based mutation\n                if self.archive:\n                    archive_idx = np.random.randint(len(self.archive))\n                    archived_vector = self.archive[archive_idx]\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x1, x2 = self.population[idxs]\n                    mutated_population[i] = self.population[i] + self.F * (archived_vector - self.population[i]) + self.F * (x1 - x2)\n                else: # Fallback to random mutation if archive is empty\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutated_population[i] = x1 + self.F * (x2 - x3)\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n        \n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n            \n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n    \n    def assess_landscape_awareness(self):\n        # Measure the diversity of the population\n        diversity = np.mean([np.linalg.norm(x - self.x_opt) for x in self.population])\n\n        # Measure the improvement rate\n        if len(self.best_fitness_history) > 1:\n            improvement = self.best_fitness_history[-1] - self.best_fitness_history[-2]\n        else:\n            improvement = 0\n\n        self.landscape_awareness.append((diversity, improvement))\n\n    def local_search(self, func):\n        # Generate candidate solutions around the best solution\n        num_candidates = self.pop_size // 2 # Reduced local search candidates\n\n        candidates = np.random.normal(loc=self.x_opt, scale=self.local_search_radius, size=(num_candidates, self.dim))\n        candidates = self.handle_bounds(candidates, func)\n        \n        candidate_fitness = np.array([func(x) for x in candidates])\n        self.budget -= num_candidates\n\n        # Update best solution if a better candidate is found\n        best_candidate_idx = np.argmin(candidate_fitness)\n        if candidate_fitness[best_candidate_idx] < self.f_opt:\n            self.f_opt = candidate_fitness[best_candidate_idx]\n            self.x_opt = candidates[best_candidate_idx]\n            return True  # Indicate that the best solution has improved\n\n        return False # Indicate that the local search did not improve the best solution\n\n\n    def landscape_aware_restart(self, func):\n         # Analyze landscape awareness data to determine restart strategy\n        if len(self.landscape_awareness) > 10:\n            recent_data = self.landscape_awareness[-10:]\n            diversities, improvements = zip(*recent_data)\n\n            avg_diversity = np.mean(diversities)\n            avg_improvement = np.mean(improvements)\n\n            if abs(avg_improvement) < self.lars_threshold: # Stagnation detected\n                # Perform local search around the best solution\n                if not self.local_search(func):\n                    # Option 1: Re-initialize population near the best solution if local search fails\n                    self.population = np.random.normal(loc=self.x_opt, scale=0.1, size=(self.pop_size, self.dim))\n                    self.population = self.handle_bounds(self.population, func)  # Ensure bounds are respected\n                else:\n                    return # Local search improved solution, no need to restart\n\n            else:\n                # Option 2: More exploration - Re-initialize population randomly\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            self.landscape_awareness = []  # Reset landscape awareness data\n    \n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            \n            self.best_fitness_history.append(current_best_fitness)\n            self.assess_landscape_awareness()\n            \n            if self.check_stagnation():\n                self.landscape_aware_restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE_Ortho_LARS_LocalSearch scored 0.398 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["01c09fe8-1fee-4f9f-aa02-8c4a14d44e69"], "operator": null, "metadata": {"aucs": [0.1646770617838803, 0.32497572745205394, 0.3810257340917286, 0.5385229158475742, 0.3416797837894451, 0.4032405708353065, 0.32549570868058697, 0.3243348958182455, 0.32719429744215345, 0.2946596103068446, 0.3514426543830912, 0.9942721772977494, 0.2786865786065489, 0.31758448619120505, 0.7213573011603227, 0.3997974265255986, 0.32183164086132765, 0.46194737168328515, 0.1987152334978729, 0.49682803736970893]}}
{"id": "e137886b-5c57-45cc-bc0c-3b848af0217e", "fitness": 0.4571533189716009, "name": "AdaptiveDE_OrthoArchive_Diversity", "description": "Adaptive Differential Evolution with orthogonal crossover, archive-based mutation, self-regulating strategy adaptation with a penalty-based stochastic ranking, and a landscape-aware population diversity mechanism to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveDE_OrthoArchive_Diversity:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=15, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, exploration_prob=0.1, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.exploration_prob = exploration_prob  # Probability of using archive-based exploration\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            elif np.random.rand() < self.exploration_prob and len(self.archive) > 0:  # Archive-based mutation\n                archive_idx = np.random.randint(len(self.archive))\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.archive[archive_idx] + self.F * (x1 - x2)\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness, func):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        # Constraint violation penalty.  Modify to fit the problem if needed\n        def constraint_violation(x):\n            return 0 # No constraints in the benchmark\n\n        def compare(i, j):\n            fi = fitness[i] + constraint_violation(pop[i])\n            fj = fitness[j] + constraint_violation(pop[j])\n            \n            return fi - fj\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k] + constraint_violation(pop[k]))\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def calculate_diversity(self):\n        \"\"\"Calculates the mean pairwise Euclidean distance in the population.\"\"\"\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(self.population[i] - self.population[j]))\n        return np.mean(distances) if distances else 0\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness, func)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func, diversify=False):\n        if diversify:\n             # Introduce diversity by re-initializing a fraction of the population\n            num_to_diversify = int(0.5 * self.pop_size)\n            indices_to_diversify = np.random.choice(self.pop_size, num_to_diversify, replace=False)\n            self.population[indices_to_diversify] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_diversify, self.dim))\n            self.fitness[indices_to_diversify] = np.array([func(x) for x in self.population[indices_to_diversify]])\n            self.budget -= num_to_diversify  # Account for new function evaluations\n\n        else:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            \n            self.best_fitness_history.append(current_best_fitness)\n            \n            if self.check_stagnation():\n                diversity = self.calculate_diversity()\n                if diversity < self.diversity_threshold:\n                    self.restart(func, diversify=True) # Restart and diversify if diversity is low\n                else:\n                    self.restart(func) # Otherwise, just restart\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE_OrthoArchive_Diversity scored 0.457 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cbc35095-08b7-4db4-adb8-7e6188394a19"], "operator": null, "metadata": {"aucs": [0.20371582969065516, 0.36132485826107386, 0.4092678152533574, 0.615825648550505, 0.3919837434692627, 0.5171116774662874, 0.3424653711873912, 0.3971172968190049, 0.3940344267645731, 0.3242461377448844, 0.5706759710021678, 0.9954909297664303, 0.2945774239149589, 0.38460959775298154, 0.7334162884374973, 0.4962264871268457, 0.3599251287571327, 0.6280562129689674, 0.21034068016592478, 0.5126548543321174]}}
{"id": "f1497dee-04ac-4a14-a5cb-7a77fbc399e5", "fitness": 0.3961060748080834, "name": "AdaptiveDE_Ortho_Clustering_LARS", "description": "Enhanced Adaptive Differential Evolution with orthogonal crossover, archive-based mutation, landscape-aware restarts using clustering, and dynamic parameter control based on success history.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveDE_Ortho_Clustering_LARS:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, lars_threshold=1e-4, num_clusters=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.lars_threshold = lars_threshold\n        self.landscape_awareness = []\n        self.num_clusters = num_clusters\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Archive-based mutation\n                if self.archive:\n                    archive_idx = np.random.randint(len(self.archive))\n                    archived_vector = self.archive[archive_idx]\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x1, x2 = self.population[idxs]\n                    mutated_population[i] = self.population[i] + self.F * (archived_vector - self.population[i]) + self.F * (x1 - x2)\n                else: # Fallback to random mutation if archive is empty\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutated_population[i] = x1 + self.F * (x2 - x3)\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n        \n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n            \n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n            # Dynamic adjustment of learning rates based on success\n            if len(self.successful_F) / self.pop_size > 0.2:  # High success rate\n                self.F_learning_rate = min(self.F_learning_rate * 1.1, 0.5)  # Increase learning rate\n                self.CR_learning_rate = min(self.CR_learning_rate * 1.1, 0.5)\n            else:\n                self.F_learning_rate = max(self.F_learning_rate * 0.9, 0.01)  # Decrease learning rate\n                self.CR_learning_rate = max(self.CR_learning_rate * 0.9, 0.01)\n\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n    \n    def assess_landscape_awareness(self):\n        # Measure the diversity of the population\n        diversity = np.mean([np.linalg.norm(x - self.x_opt) for x in self.population])\n\n        # Measure the improvement rate\n        if len(self.best_fitness_history) > 1:\n            improvement = self.best_fitness_history[-1] - self.best_fitness_history[-2]\n        else:\n            improvement = 0\n\n        self.landscape_awareness.append((diversity, improvement))\n\n    def landscape_aware_restart(self, func):\n        # Analyze population structure using clustering\n        kmeans = KMeans(n_clusters=self.num_clusters, random_state=0, n_init='auto')  # Specify n_init\n        kmeans.fit(self.population)\n        cluster_centers = kmeans.cluster_centers_\n        cluster_labels = kmeans.labels_\n\n        # Strategy 1: Focused search around best cluster\n        best_cluster = cluster_labels[np.argmin(self.fitness)]\n        cluster_points = self.population[cluster_labels == best_cluster]\n        \n        # Calculate mean and std of the best cluster\n        cluster_mean = np.mean(cluster_points, axis=0)\n        cluster_std = np.std(cluster_points, axis=0)\n\n        # Option 1: Re-initialize population near the best cluster\n        self.population = np.random.normal(loc=cluster_mean, scale=cluster_std, size=(self.pop_size, self.dim))\n        self.population = self.handle_bounds(self.population, func)  # Ensure bounds are respected\n\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n        self.landscape_awareness = []  # Reset landscape awareness data\n        self.F = self.F_initial\n        self.CR = self.CR_initial\n    \n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            \n            self.best_fitness_history.append(current_best_fitness)\n            self.assess_landscape_awareness()\n            \n            if self.check_stagnation():\n                self.landscape_aware_restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE_Ortho_Clustering_LARS scored 0.396 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["01c09fe8-1fee-4f9f-aa02-8c4a14d44e69"], "operator": null, "metadata": {"aucs": [0.16546862823047592, 0.2829778505831887, 0.3680549998980378, 0.4132017310666536, 0.3383819158699052, 0.40981486206919404, 0.3311135458097506, 0.3302170024287703, 0.34770886606630425, 0.27983733115935794, 0.3980648182412414, 0.9994997339816548, 0.26338913302378564, 0.3295280074010467, 0.7302068917332867, 0.380559075644225, 0.33957950164220707, 0.46344916410760917, 0.24634193372995805, 0.5047265034750144]}}
{"id": "95983a70-044d-4e15-91ca-6a73b8756431", "fitness": 0.4397819787911187, "name": "EnhancedAdaptiveDE", "description": "Enhanced Adaptive Differential Evolution with orthogonal crossover, archive-based mutation, adaptive population sizing, and a landscape-aware mutation strategy that dynamically adjusts mutation based on local landscape features to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=15, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, exploration_prob=0.1, landscape_awareness=True):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max\n        self.archive_size = archive_size\n        self.F = F_initial\n        self.CR = CR_initial\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size\n        self.pop_size_adaptation_rate = 0.1\n        self.exploration_prob = exploration_prob\n        self.landscape_awareness = landscape_awareness # Enable/disable landscape awareness\n        self.neighborhood_size = 5 # Neighborhood size for landscape analysis\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if self.landscape_awareness:\n                # Analyze local landscape\n                neighborhood_indices = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                neighborhood_fitness = self.fitness[neighborhood_indices]\n                std_fitness = np.std(neighborhood_fitness)\n\n                # Adaptive F based on landscape variance\n                adaptive_F = self.F * (1 + std_fitness)\n                adaptive_F = np.clip(adaptive_F, 0.1, 1.0)  # Ensure F stays within reasonable bounds\n\n                if np.random.rand() < 0.5: # Current-to-best mutation\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x1, x2 = self.population[idxs]\n                    mutated_population[i] = self.population[i] + adaptive_F * (self.population[best_idx] - self.population[i]) + adaptive_F * (x1 - x2)\n                elif np.random.rand() < self.exploration_prob and len(self.archive) > 0:  # Archive-based mutation\n                    archive_idx = np.random.randint(len(self.archive))\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x1, x2 = self.population[idxs]\n                    mutated_population[i] = self.archive[archive_idx] + adaptive_F * (x1 - x2)\n                else: # Random mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutated_population[i] = x1 + adaptive_F * (x2 - x3)\n            else:\n                if np.random.rand() < 0.5: # Current-to-best mutation\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x1, x2 = self.population[idxs]\n                    mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n                elif np.random.rand() < self.exploration_prob and len(self.archive) > 0:  # Archive-based mutation\n                    archive_idx = np.random.randint(len(self.archive))\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x1, x2 = self.population[idxs]\n                    mutated_population[i] = self.archive[archive_idx] + self.F * (x1 - x2)\n                else: # Random mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness, func):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def constraint_violation(x):\n            return 0\n\n        def compare(i, j):\n            fi = fitness[i] + constraint_violation(pop[i])\n            fj = fitness[j] + constraint_violation(pop[j])\n            \n            return fi - fj\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k] + constraint_violation(pop[k]))\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive)))\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy()\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness, func)\n\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            \n            self.best_fitness_history.append(current_best_fitness)\n            \n            if self.check_stagnation():\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedAdaptiveDE scored 0.440 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cbc35095-08b7-4db4-adb8-7e6188394a19"], "operator": null, "metadata": {"aucs": [0.18880849542482858, 0.2805661602009112, 0.41506187348265333, 0.579853588591279, 0.3871061617842948, 0.49145374390333996, 0.32746625845601796, 0.3824847020089681, 0.39123572779620686, 0.30835715174341904, 0.5422362150818641, 0.9957706910289806, 0.2769912031109376, 0.3678633132201784, 0.7166306911690381, 0.5200311011767286, 0.3455913594635873, 0.5811622152618834, 0.1970873516367837, 0.49988157128047406]}}
{"id": "43dbcb67-5df7-4bff-8db3-64270d628f1f", "fitness": -Infinity, "name": "AdaptiveDE_Ortho_Archive_Improved", "description": "Introducing a dimension-wise learning rate for F/CR adaptation and a more robust restart strategy based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_Improved:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, lars_tolerance=1e-5, restart_diversity_threshold=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = np.full(dim, F_initial)  # Mutation factor for each dimension\n        self.CR = np.full(dim, CR_initial)  # Crossover rate for each dimension\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = [[] for _ in range(dim)]  # Store successful F values for each dimension\n        self.successful_CR = [[] for _ in range(dim)]  # Store successful CR values for each dimension\n        self.F_momentum = np.zeros(dim)\n        self.CR_momentum = np.zeros(dim)\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.lars_tolerance = lars_tolerance\n        self.restart_diversity_threshold = restart_diversity_threshold\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR[j] or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i + 1]] - dimension_values[sorted_indices[i - 1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                for j in range(self.dim):\n                    self.successful_F[j].append(self.F[j])\n                    self.successful_CR[j].append(self.CR[j])\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum, dimension-wise\n        for j in range(self.dim):\n            if self.successful_F[j]:\n                mean_F = np.mean(self.successful_F[j])\n                mean_CR = np.mean(self.successful_CR[j])\n\n                self.F_momentum[j] = self.momentum_coeff * self.F_momentum[j] + (1 - self.momentum_coeff) * mean_F\n                self.CR_momentum[j] = self.momentum_coeff * self.CR_momentum[j] + (1 - self.momentum_coeff) * mean_CR\n\n                self.F[j] = np.clip((1 - self.F_learning_rate) * self.F[j] + self.F_learning_rate * self.F_momentum[j], 0.1, 0.9) # Clip F\n                self.CR[j] = np.clip((1 - self.CR_learning_rate) * self.CR[j] + self.CR_learning_rate * self.CR_momentum[j], 0.1, 0.9) # Clip CR\n\n            self.successful_F[j] = []\n            self.successful_CR[j] = []\n\n        # Population size adaptation based on landscape awareness\n        if self.generation > 50:\n            fitness_std = np.std(self.fitness)\n            if fitness_std < self.lars_tolerance and self.pop_size > self.pop_size_min:\n                self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n            elif fitness_std > self.lars_tolerance and self.pop_size < self.pop_size_max:\n                self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        # Select top archive_size individuals + some random individuals to promote diversity\n        num_elite = int(0.8 * self.archive_size)  # Keep top 80%\n        elite_indices = np.arange(num_elite)\n        random_indices = np.random.choice(len(combined_population), self.archive_size - num_elite, replace=False)\n        selected_indices = np.concatenate((elite_indices, random_indices))\n        np.random.shuffle(selected_indices)  # Shuffle to mix elite and random\n        \n        self.archive = list(combined_population[selected_indices])\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        # Check population diversity before restarting\n        diversity = np.std(self.population)\n        if diversity < self.restart_diversity_threshold:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            # Reset F and CR as well after restart\n            self.F = np.full(self.dim, 0.5)\n            self.CR = np.full(self.dim, 0.5)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            if self.check_stagnation():\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 111, in evaluate\n    exec(code, safe_globals, local_env)\n  File \"<string>\", line 103\nSyntaxError: duplicate argument 'self' in function definition\n.", "error": "", "parent_ids": ["1bf01247-929d-4755-a735-5e09e9f28dc6"], "operator": null, "metadata": {}}
{"id": "bc4be22a-e94a-4790-beaa-344fefedc520", "fitness": -Infinity, "name": "AdaptiveDE_OrthoArchive_Diversity_Enhanced", "description": "Enhance exploration by dynamically adjusting mutation strength based on population diversity and introducing a toroidal boundary handling method.", "code": "import numpy as np\n\nclass AdaptiveDE_OrthoArchive_Diversity_Enhanced:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=15, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, exploration_prob=0.1, diversity_threshold=0.1, diversity_F_scale=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.exploration_prob = exploration_prob  # Probability of using archive-based exploration\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n        self.diversity_F_scale = diversity_F_scale # Scale F based on diversity\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        diversity = self.calculate_diversity()\n        F_diversity_adjusted = self.F * (1 + self.diversity_F_scale * (1 - diversity / (5 * np.sqrt(self.dim))))  # Scale F based on diversity\n        F_diversity_adjusted = np.clip(F_diversity_adjusted, 0.0, 1.0)\n\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + F_diversity_adjusted * (self.population[best_idx] - self.population[i]) + F_diversity_adjusted * (x1 - x2)\n            elif np.random.rand() < self.exploration_prob and len(self.archive) > 0:  # Archive-based mutation\n                archive_idx = np.random.randint(len(self.archive))\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.archive[archive_idx] + F_diversity_adjusted * (x1 - x2)\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + F_diversity_adjusted * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Toroidal handling of boundaries\n        for i in range(len(population)):\n            for j in range(self.dim):\n                if population[i, j] < lb:\n                    population[i, j] = ub - (lb - population[i, j]) % (ub - lb)\n                elif population[i, j] > ub:\n                    population[i, j] = lb + (population[i, j] - ub) % (ub - lb)\n        return population\n    \n    def stochastic_ranking(self, pop, fitness, func):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        # Constraint violation penalty.  Modify to fit the problem if needed\n        def constraint_violation(x):\n            return 0 # No constraints in the benchmark\n\n        def compare(i, j):\n            fi = fitness[i] + constraint_violation(pop[i])\n            fj = fitness[j] + constraint_violation(pop[j])\n            \n            return fi - fj\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k] + constraint_violation(pop[k]))\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, self_population, fitness):\n        distances = np.zeros(len(self_population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = self_population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(self_population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def calculate_diversity(self):\n        \"\"\"Calculates the mean pairwise Euclidean distance in the population.\"\"\"\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(self.population[i] - self.population[j]))\n        return np.mean(distances) if distances else 0\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness, func)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func, diversify=False):\n        if diversify:\n             # Introduce diversity by re-initializing a fraction of the population\n            num_to_diversify = int(0.5 * self.pop_size)\n            indices_to_diversify = np.random.choice(self.pop_size, num_to_diversify, replace=False)\n            self.population[indices_to_diversify] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_diversify, self.dim))\n            self.fitness[indices_to_diversify] = np.array([func(x) for x in self.population[indices_to_diversify]])\n            self.budget -= num_to_diversify  # Account for new function evaluations\n\n        else:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            \n            self.best_fitness_history.append(current_best_fitness)\n            \n            if self.check_stagnation():\n                diversity = self.calculate_diversity()\n                if diversity < self.diversity_threshold:\n                    self.restart(func, diversify=True) # Restart and diversify if diversity is low\n                else:\n                    self.restart(func) # Otherwise, just restart\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 218, in __call__\n  File \"<string>\", line 85, in handle_bounds\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n.", "error": "", "parent_ids": ["e137886b-5c57-45cc-bc0c-3b848af0217e"], "operator": null, "metadata": {}}
{"id": "21d03d7c-d5dc-4d70-bb98-0af321626172", "fitness": -Infinity, "name": "AdaptiveDE_Ortho_Archive_Improved2", "description": "Enhanced Adaptive Differential Evolution with orthogonal crossover, archive, dynamic F/CR adaptation, population resizing, and a new landscape-aware restart mechanism using a weighted average of past best solutions to guide the search.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_Improved2:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, lars_tolerance=1e-5, restart_strategy='weighted_average'):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.best_solution_history = [] # Store best solutions\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.lars_tolerance = lars_tolerance\n        self.restart_strategy = restart_strategy\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i + 1]] - dimension_values[sorted_indices[i - 1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = np.clip((1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum, 0.1, 0.9) # Clip F\n            self.CR = np.clip((1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum, 0.1, 0.9) # Clip CR\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation based on landscape awareness\n        if self.generation > 50:\n            fitness_std = np.std(self.fitness)\n            if fitness_std < self.lars_tolerance and self.pop_size > self.pop_size_min:\n                self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n            elif fitness_std > self.lars_tolerance and self.pop_size < self.pop_size_max:\n                self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        # Select top archive_size individuals + some random individuals to promote diversity\n        num_elite = int(0.8 * self.archive_size)  # Keep top 80%\n        elite_indices = np.arange(num_elite)\n        random_indices = np.random.choice(len(combined_population), self.archive_size - num_elite, replace=False)\n        selected_indices = np.concatenate((elite_indices, random_indices))\n        np.random.shuffle(selected_indices)  # Shuffle to mix elite and random\n        \n        self.archive = list(combined_population[selected_indices])\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        if self.restart_strategy == 'weighted_average':\n            # Weighted average of past best solutions\n            if not self.best_solution_history:\n                new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            else:\n                weights = np.arange(1, len(self.best_solution_history) + 1)\n                weights = weights / np.sum(weights)  # Normalize weights\n                weighted_avg = np.average(self.best_solution_history, axis=0, weights=weights)\n\n                # Generate new population around the weighted average\n                new_population = np.random.normal(loc=weighted_avg, scale=0.1, size=(self.pop_size, self.dim))\n                new_population = self.handle_bounds(new_population, func)  # Ensure bounds\n        else:\n            new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n\n        self.population = new_population\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n        self.best_solution_history.append(self.x_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            current_best_solution = self.population[np.argmin(self.fitness)]\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = current_best_solution\n\n            self.best_fitness_history.append(current_best_fitness)\n            self.best_solution_history.append(current_best_solution)\n\n            # Keep only the last 10 best solutions to prevent memory issues and focus on recent improvements\n            if len(self.best_solution_history) > 10:\n                self.best_solution_history.pop(0)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            if self.check_stagnation():\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                self.best_solution_history.append(self.x_opt) # Append best solution also after restart\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 111, in evaluate\n    exec(code, safe_globals, local_env)\n  File \"<string>\", line 104\nSyntaxError: duplicate argument 'self' in function definition\n.", "error": "", "parent_ids": ["1bf01247-929d-4755-a735-5e09e9f28dc6"], "operator": null, "metadata": {}}
{"id": "01b54037-f4a4-44e1-900c-1e870e66a6f4", "fitness": -Infinity, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced", "description": "Enhance the Adaptive DE with Orthogonal Crossover, Archive, and Local Search by incorporating a more robust stagnation check, adaptive local search radius control, and a polynomial mutation operator for fine-tuning.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=500, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05, polynomial_mutation_eta=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.polynomial_mutation_eta = polynomial_mutation_eta  # Eta parameter for polynomial mutation\n        self.adaptive_local_search_radius = local_search_radius  # Initialize adaptive radius\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        # Apply Polynomial Mutation\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.1:  # Apply polynomial mutation with a probability\n                for j in range(self.dim):\n                    if np.random.rand() < 1 / self.dim:\n                        u = np.random.rand()\n                        if u < 0.5:\n                            delta = (2 * u)**(1 / (self.polynomial_mutation_eta + 1)) - 1\n                        else:\n                            delta = 1 - (2 * (1 - u))**(1 / (self.polynomial_mutation_eta + 1))\n                        mutated_population[i, j] = self.population[i, j] + delta * (func.bounds.ub - func.bounds.lb)\n                        mutated_population[i, j] = np.clip(mutated_population[i, j], func.bounds.lb, func.bounds.ub)\n\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        # More robust stagnation check: check for stagnation in the best fitness *and* population diversity\n        fitness_stagnation = False\n        diversity_stagnation = False\n\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                fitness_stagnation = True\n\n            # Check population diversity (variance of each dimension)\n            diversity = np.mean(np.var(self.population, axis=0))\n            if diversity < 1e-6: # Empirically chosen threshold\n                diversity_stagnation = True\n\n        if fitness_stagnation and diversity_stagnation:\n            self.stagnation_counter += 1\n        else:\n            self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        if np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            print(\"Restarting population.\")\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n\n        # Adaptive local search radius\n        success_count = 0  # Track successful steps to adjust radius\n\n        for _ in range(self.dim * 2): # Budget conscious local search\n            if self.budget <= 0:\n                break\n\n            direction = np.random.uniform(-1, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)  # Normalize\n\n            new_x = best_x + self.adaptive_local_search_radius * direction\n            new_x = self.handle_bounds(new_x[None, :], func)[0] # Handle bounds for single vector\n\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n                success_count += 1\n\n        # Adjust the local search radius adaptively\n        if success_count > self.dim * 0.5: # if many successful steps, increase radius\n            self.adaptive_local_search_radius *= 1.1\n        else:  # Otherwise, decrease radius\n            self.adaptive_local_search_radius *= self.local_search_radius_decay\n\n        self.adaptive_local_search_radius = min(self.adaptive_local_search_radius, self.local_search_radius)  # Cap the radius\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            if self.generation % self.local_search_frequency == 0:\n                self.local_search(func)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.adaptive_local_search_radius = self.local_search_radius # Reset radius\n        \n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 251, in __call__\n  File \"<string>\", line 74, in mutate\nNameError: name 'func' is not defined\n.", "error": "", "parent_ids": ["d1401dc9-a3a9-4a83-96e5-96e9d753e69d"], "operator": null, "metadata": {}}
{"id": "461578e5-786f-4f73-987b-25579d4151c8", "fitness": -Infinity, "name": "AdaptiveDE_Ortho_Archive_Improved_LS", "description": "Introducing a Local Search with Archive Guidance and Adaptive Radius, along with dynamic population control based on success rate, and a landscape analysis-based restart strategy to enhance exploitation and exploration.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_Improved_LS:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, lars_tolerance=1e-5, ls_prob=0.1, ls_radius_initial=0.1, ls_radius_decay=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.lars_tolerance = lars_tolerance\n        self.ls_prob = ls_prob  # Probability of local search\n        self.ls_radius_initial = ls_radius_initial # Initial radius for local search\n        self.ls_radius = ls_radius_initial\n        self.ls_radius_decay = ls_radius_decay\n        self.success_rate_threshold = 0.2 # Threshold for dynamic population control\n        self.success_history = []\n        self.success_window = 20\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i + 1]] - dimension_values[sorted_indices[i - 1]])\n\n        return distances\n\n    def local_search(self, func, x):\n        x_new = x.copy()\n        for i in range(self.dim):\n            delta = np.random.uniform(-self.ls_radius, self.ls_radius)\n            x_new[i] = x[i] + delta\n        x_new = self.handle_bounds(x_new.reshape(1, -1), func).flatten()\n        f_new = func(x_new)\n        self.budget -= 1\n        return f_new, x_new\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            x_candidate = crossed_population[i]\n            f_candidate = func(x_candidate)\n            self.budget -= 1\n\n            # Local Search\n            if np.random.rand() < self.ls_prob and self.budget > 0:\n                f_ls, x_ls = self.local_search(func, x_candidate)\n                if f_ls < f_candidate:\n                    f_candidate = f_ls\n                    x_candidate = x_ls\n            \n            if f_candidate < self.fitness[i]:\n                new_population[i] = x_candidate\n                new_fitness[i] = f_candidate\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = np.clip((1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum, 0.1, 0.9) # Clip F\n            self.CR = np.clip((1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum, 0.1, 0.9) # Clip CR\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation based on success rate\n        success_rate = improved_count / self.pop_size\n        self.success_history.append(success_rate)\n        if len(self.success_history) > self.success_window:\n            self.success_history.pop(0)\n\n        if len(self.success_history) == self.success_window:\n            avg_success_rate = np.mean(self.success_history)\n            if avg_success_rate < self.success_rate_threshold and self.pop_size > self.pop_size_min:\n                self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n                # Resize population\n                self.population = self.population[:self.pop_size]\n                self.fitness = self.fitness[:self.pop_size]\n            elif avg_success_rate > (2 * self.success_rate_threshold) and self.pop_size < self.pop_size_max:\n                self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n                # Resize population. Add random individuals\n                new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - len(self.population), self.dim))\n                new_fitness = np.array([func(x) for x in new_individuals])\n                self.budget -= (self.pop_size - len(self.population))\n                self.population = np.concatenate((self.population, new_individuals))\n                self.fitness = np.concatenate((self.fitness, new_fitness))\n        \n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        # Select top archive_size individuals + some random individuals to promote diversity\n        num_elite = int(0.8 * self.archive_size)  # Keep top 80%\n        elite_indices = np.arange(num_elite)\n        random_indices = np.random.choice(len(combined_population), self.archive_size - num_elite, replace=False)\n        selected_indices = np.concatenate((elite_indices, random_indices))\n        np.random.shuffle(selected_indices)  # Shuffle to mix elite and random\n        \n        self.archive = list(combined_population[selected_indices])\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        # Landscape analysis-based restart\n        if len(self.best_fitness_history) > 10:\n            recent_improvements = np.diff(self.best_fitness_history[-10:])\n            if np.all(recent_improvements > -1e-6): #if there's very little improvement\n                #Increase diversity by sampling from a wider range\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            else:\n                #Keep the best solution and regenerate the rest of the population around it\n                best_idx = np.argmin(self.fitness)\n                best_solution = self.population[best_idx].copy()\n                self.population = np.random.normal(loc=best_solution, scale=self.ls_radius_initial, size=(self.pop_size, self.dim)) #Use initial LS radius as scale\n                self.population = self.handle_bounds(self.population, func)\n\n        else:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        \n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n        self.ls_radius = self.ls_radius_initial # Reset local search radius\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size_min:  # Ensure enough budget for minimal population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            if self.check_stagnation():\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n\n            # Decay local search radius\n            self.ls_radius *= self.ls_radius_decay\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 111, in evaluate\n    exec(code, safe_globals, local_env)\n  File \"<string>\", line 109\nSyntaxError: duplicate argument 'self' in function definition\n.", "error": "", "parent_ids": ["1bf01247-929d-4755-a735-5e09e9f28dc6"], "operator": null, "metadata": {}}
{"id": "4245c893-3301-4c56-920f-ea176cc5307c", "fitness": -Infinity, "name": "AdaptiveDE_Ortho_Archive_MultiStrategy", "description": "Introduce a multi-strategy adaptation based on the success rate of different mutation strategies and an enhanced archive update mechanism that considers fitness improvement for inclusion.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_MultiStrategy:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, lars_tolerance=1e-5, num_strategies=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.lars_tolerance = lars_tolerance\n\n        # Multi-strategy adaptation\n        self.num_strategies = num_strategies\n        self.strategy_success_rates = np.ones(self.num_strategies) / self.num_strategies\n        self.strategy_counts = np.zeros(self.num_strategies)\n        self.strategy_successes = np.zeros(self.num_strategies)\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        strategy_choices = np.random.choice(self.num_strategies, size=self.pop_size, p=self.strategy_success_rates)\n\n        for i in range(self.pop_size):\n            strategy = strategy_choices[i]\n            self.strategy_counts[strategy] += 1\n\n            if strategy == 0:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            elif strategy == 1:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n            else:  # Archive-guided mutation\n                if self.archive:\n                    archive_idx = np.random.randint(len(self.archive))\n                    archived_vector = self.archive[archive_idx]\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x1, x2 = self.population[idxs]\n                    mutated_population[i] = archived_vector + self.F * (x1 - x2)\n                else:\n                    # If archive is empty, default to random mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i + 1]] - dimension_values[sorted_indices[i - 1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n                self.strategy_successes[strategy_choices[i]] += 1\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = np.clip((1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum, 0.1, 0.9) # Clip F\n            self.CR = np.clip((1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum, 0.1, 0.9) # Clip CR\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Update strategy success rates\n        for i in range(self.num_strategies):\n            if self.strategy_counts[i] > 0:\n                self.strategy_success_rates[i] = 0.9 * self.strategy_success_rates[i] + 0.1 * (self.strategy_successes[i] / self.strategy_counts[i])\n            self.strategy_counts[i] = 0\n            self.strategy_successes[i] = 0\n\n        self.strategy_success_rates /= np.sum(self.strategy_success_rates) # Normalize\n\n        # Population size adaptation based on landscape awareness\n        if self.generation > 50:\n            fitness_std = np.std(self.fitness)\n            if fitness_std < self.lars_tolerance and self.pop_size > self.pop_size_min:\n                self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n            elif fitness_std > self.lars_tolerance and self.pop_size < self.pop_size_max:\n                self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n\n\n        return new_population, new_fitness\n\n    def update_archive(self, func):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Stochastic ranking\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        # Add only improving solutions into the archive\n        new_archive = []\n        for i in range(len(combined_population)):\n            if combined_fitness[i] < np.min(self.fitness):  # Check if improving\n                new_archive.append(combined_population[i])\n\n        # Trim archive to size, prioritizing better solutions\n        if len(new_archive) > self.archive_size:\n            fitnesses = [func(x) for x in new_archive]\n            sorted_indices = np.argsort(fitnesses)[:self.archive_size]\n            new_archive = [new_archive[i] for i in sorted_indices]\n\n        self.archive = new_archive\n\n        if len(self.archive) > self.archive_size:\n            self.archive = self.archive[:self.archive_size]\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            strategy_choices = np.zeros(self.pop_size) # Dummy variable\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive(func)\n\n            if self.check_stagnation():\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 238, in __call__\n  File \"<string>\", line 146, in select\nNameError: name 'strategy_choices' is not defined\n.", "error": "", "parent_ids": ["1bf01247-929d-4755-a735-5e09e9f28dc6"], "operator": null, "metadata": {}}
{"id": "f038f41b-430b-4998-9ca1-7e8c68ee630d", "fitness": 0.3169293454526668, "name": "AdaptiveDE_Ortho_Archive_Improved2", "description": "Introduces a convex crossover to enhance exploitation, combined with adaptive population size adjustments based on both landscape features and budget considerations, and an enhanced archive update strategy with diversity preservation.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_Improved2:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, lars_tolerance=1e-5, convex_coeff=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.lars_tolerance = lars_tolerance\n        self.convex_coeff = convex_coeff # Coefficient for convex crossover\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                     # Convex crossover\n                    crossed_population[i, j] = self.convex_coeff * mutated_population[i, j] + (1 - self.convex_coeff) * self.population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i + 1]] - dimension_values[sorted_indices[i - 1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = np.clip((1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum, 0.1, 0.9) # Clip F\n            self.CR = np.clip((1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum, 0.1, 0.9) # Clip CR\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation based on landscape awareness and budget\n        if self.generation > 50:\n            fitness_std = np.std(self.fitness)\n            if fitness_std < self.lars_tolerance and self.pop_size > self.pop_size_min:\n                # Reduce population size only if enough budget remains\n                if self.budget > self.pop_size:\n                     self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n            elif fitness_std > self.lars_tolerance and self.pop_size < self.pop_size_max:\n                self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        # Select top archive_size individuals + some random individuals to promote diversity\n        num_elite = int(0.8 * self.archive_size)  # Keep top 80%\n        elite_indices = np.argsort(combined_fitness)[:num_elite] # Select based on fitness\n        remaining = self.archive_size - num_elite\n        random_indices = np.random.choice(len(combined_population), remaining, replace=False)\n\n        selected_indices = np.concatenate((elite_indices, random_indices))\n        np.random.shuffle(selected_indices)  # Shuffle to mix elite and random\n        \n        self.archive = list(combined_population[selected_indices])\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            if self.check_stagnation():\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_Improved2 scored 0.317 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1bf01247-929d-4755-a735-5e09e9f28dc6"], "operator": null, "metadata": {"aucs": [0.12315132384933347, 0.2327369146060635, 0.3877520648872397, 0.21304930840204295, 0.2543401118596259, 0.2801917819288776, 0.25443384358663734, 0.23270381674318963, 0.246551843694661, 0.1753482796324668, 0.2140788804583773, 0.9988148202224052, 0.29284728176638897, 0.200258189607323, 0.6226154544211867, 0.3022248318772027, 0.2795313613543845, 0.29323715643545734, 0.23405187708336694, 0.5006677666371071]}}
{"id": "5d2344a1-c053-41a6-bcff-d19ed570e3f1", "fitness": 0.46131785713244156, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_v2", "description": "Enhanced Adaptive Differential Evolution with orthogonal crossover, archive and a landscape aware mechanism with a new local search to fine tune the best solutions when the algorithm stagnates.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_v2:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, lars_tolerance=1e-5, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.lars_tolerance = lars_tolerance\n        self.local_search_radius = local_search_radius  # Initial local search radius\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i + 1]] - dimension_values[sorted_indices[i - 1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = np.clip((1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum, 0.1, 0.9) # Clip F\n            self.CR = np.clip((1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum, 0.1, 0.9) # Clip CR\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation based on landscape awareness\n        if self.generation > 50:\n            fitness_std = np.std(self.fitness)\n            if fitness_std < self.lars_tolerance and self.pop_size > self.pop_size_min:\n                self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n            elif fitness_std > self.lars_tolerance and self.pop_size < self.pop_size_max:\n                self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        # Select top archive_size individuals + some random individuals to promote diversity\n        num_elite = int(0.8 * self.archive_size)  # Keep top 80%\n        elite_indices = np.arange(num_elite)\n        random_indices = np.random.choice(len(combined_population), self.archive_size - num_elite, replace=False)\n        selected_indices = np.concatenate((elite_indices, random_indices))\n        np.random.shuffle(selected_indices)  # Shuffle to mix elite and random\n        \n        self.archive = list(combined_population[selected_indices])\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n        self.local_search_radius = 0.1 # Reset the local search radius\n\n    def local_search(self, func, x_opt):\n        # Perform local search around the best solution\n        num_evals = min(self.pop_size, self.budget) # Adaptive local evals depending on budget\n        for _ in range(num_evals):\n            # Generate a random perturbation within the radius\n            perturbation = np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            x_neighbor = x_opt + perturbation\n            x_neighbor = self.handle_bounds(np.array([x_neighbor]), func)[0] # Keep within bounds\n\n            f_neighbor = func(x_neighbor)\n            self.budget -= 1\n\n            if f_neighbor < self.f_opt:\n                self.f_opt = f_neighbor\n                self.x_opt = x_neighbor\n\n        self.local_search_radius *= 0.5  # Reduce the radius after each local search\n        self.local_search_radius = max(self.local_search_radius, 1e-6) # Avoid zero radius\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            if self.check_stagnation():\n                self.local_search(func, self.x_opt)\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n\n        # Final local search at the end\n        if self.budget > 0:\n            self.local_search(func, self.x_opt)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch_v2 scored 0.461 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1bf01247-929d-4755-a735-5e09e9f28dc6"], "operator": null, "metadata": {"aucs": [0.1662478441551153, 0.28055723077212, 0.43494315533410066, 0.662428739832934, 0.3690226766138537, 0.5423993416473716, 0.32755617665111236, 0.40632033229754894, 0.4575946088111942, 0.2562839053638807, 0.6634195030215464, 0.9963919894374534, 0.277013571594233, 0.37094103902125586, 0.7988826830115922, 0.4815151975512777, 0.3774952156265473, 0.6105680304362213, 0.24590135097243027, 0.5008745504970431]}}
{"id": "9e8c6680-7240-4d08-8779-d44e1b3b466d", "fitness": 0.46995322549476526, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced", "description": "Enhanced Adaptive Differential Evolution with orthogonal crossover, archive, shrinking local search radius, adaptive population resizing, and a new landscape-aware restart strategy based on fitness variance and budget consumption to efficiently balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05, restart_fitness_variance_threshold=1e-6):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.restart_fitness_variance_threshold = restart_fitness_variance_threshold\n        self.budget_consumed_threshold = 0.75 # Restart if budget consumed above threshold.\n        self.best_fitness_since_restart = np.inf\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n        self.best_fitness_since_restart = np.min(self.fitness)\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        # Restart if fitness variance is low or budget consumption is high, but only if there's been no recent improvement.\n        budget_consumed = 1 - (self.budget / 10000)\n        fitness_variance_low = len(self.best_fitness_history) >= self.stagnation_threshold and np.std(self.best_fitness_history[-self.stagnation_threshold:]) < self.restart_fitness_variance_threshold\n        budget_exceeded_threshold = budget_consumed > self.budget_consumed_threshold\n\n        no_recent_improvement = self.f_opt >= self.best_fitness_since_restart\n        \n        if (fitness_variance_low or budget_exceeded_threshold) and no_recent_improvement and np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            self.best_fitness_since_restart = np.min(self.fitness)\n\n            print(f\"Restarting population. Budget consumed: {budget_consumed:.2f}, Fitness Variance: {np.std(self.best_fitness_history[-self.stagnation_threshold:]) if len(self.best_fitness_history) >= self.stagnation_threshold else 'N/A'}\")\n\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n\n        for _ in range(self.dim * 2): # Budget conscious local search\n            if self.budget <= 0:\n                break\n\n            direction = np.random.uniform(-1, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)  # Normalize\n\n            new_x = best_x + self.local_search_radius * direction\n            new_x = self.handle_bounds(new_x[None, :], func)[0] # Handle bounds for single vector\n\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n\n        self.local_search_radius *= self.local_search_radius_decay # Reduce radius\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                self.best_fitness_since_restart = self.f_opt # Update best fitness since last restart\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            if self.generation % self.local_search_frequency == 0:\n                self.local_search(func)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = 0.1 # Reset radius\n        \n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced scored 0.470 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d1401dc9-a3a9-4a83-96e5-96e9d753e69d"], "operator": null, "metadata": {"aucs": [0.19362312338955456, 0.4018766376689412, 0.4229382817458963, 0.6126906294013007, 0.40833081461750564, 0.5190671721406719, 0.34316415901363917, 0.40158995113431306, 0.4046316720098886, 0.30507141541073024, 0.5947154415022051, 0.9992420781200958, 0.28747016951386006, 0.39016386700932726, 0.7984974850415416, 0.5316760575807585, 0.3654264799028234, 0.6457683541345915, 0.2656230553143467, 0.5074976652433131]}}
{"id": "f082cddf-61b8-40ee-a4db-81408f0f652d", "fitness": 0.47734405213898834, "name": "AdaptiveDE_Ortho_Archive_LocalSearch", "description": "Introducing an adaptive local search with probabilistic restarts and a self-adaptive learning rate for F and CR, alongside orthogonal crossover, archive, and population diversity management.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05, ls_prob_initial=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.ls_prob = ls_prob_initial # Local search probability\n        self.ls_prob_initial = ls_prob_initial\n        self.ls_success_rate = 0.0\n        self.ls_success_history = []\n        self.ls_history_length = 20\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        if np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            print(\"Restarting population.\")\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n        success = False\n\n        for _ in range(self.dim * 2): # Budget conscious local search\n            if self.budget <= 0:\n                break\n\n            direction = np.random.uniform(-1, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)  # Normalize\n\n            new_x = best_x + self.local_search_radius * direction\n            new_x = self.handle_bounds(new_x[None, :], func)[0] # Handle bounds for single vector\n\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n                success = True\n\n        self.local_search_radius *= self.local_search_radius_decay # Reduce radius\n        return success\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            # Adaptive local search application\n            if np.random.rand() < self.ls_prob:\n                success = self.local_search(func)\n                self.ls_success_history.append(int(success))\n\n                if len(self.ls_success_history) > self.ls_history_length:\n                    self.ls_success_history.pop(0)\n\n                self.ls_success_rate = np.mean(self.ls_success_history)\n                # Adapt local search probability\n                if self.ls_success_rate > 0.4:\n                    self.ls_prob = min(1.0, self.ls_prob * 1.1)\n                else:\n                    self.ls_prob = max(0.01, self.ls_prob * 0.9)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = 0.1 # Reset radius\n                    self.ls_prob = self.ls_prob_initial # Reset ls_prob\n        \n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch scored 0.477 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d1401dc9-a3a9-4a83-96e5-96e9d753e69d"], "operator": null, "metadata": {"aucs": [0.200098070376175, 0.35545420697993346, 0.43675179906752004, 0.6907317165985704, 0.39680194271905345, 0.5395264791496036, 0.3363398539443848, 0.3959025281993228, 0.4441549959467703, 0.343492349891797, 0.5493626962938363, 0.9960957148549359, 0.3259943516287943, 0.3942868899358192, 0.8263889287712077, 0.5491836827755302, 0.3666907524908284, 0.6369052600679541, 0.255179528015247, 0.5075392950724807]}}
{"id": "d89a4474-d644-4f93-9ac2-15459112e861", "fitness": 0.4596196675406651, "name": "AdaptiveDE_OrthoArchive_Diversity_MemoryRestart", "description": "Enhanced Adaptive Differential Evolution with orthogonal crossover, archive-based mutation, self-regulating strategy adaptation, landscape-aware population diversity, and a memory-augmented restart strategy to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDE_OrthoArchive_Diversity_MemoryRestart:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=15, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, exploration_prob=0.1, diversity_threshold=0.1, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.exploration_prob = exploration_prob  # Probability of using archive-based exploration\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n        self.memory_size = memory_size  # Size of the memory to store best solutions\n        self.solution_memory = [] # Stores best solutions encountered\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            elif np.random.rand() < self.exploration_prob and len(self.archive) > 0:  # Archive-based mutation\n                archive_idx = np.random.randint(len(self.archive))\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.archive[archive_idx] + self.F * (x1 - x2)\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness, func):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        # Constraint violation penalty.  Modify to fit the problem if needed\n        def constraint_violation(x):\n            return 0 # No constraints in the benchmark\n\n        def compare(i, j):\n            fi = fitness[i] + constraint_violation(pop[i])\n            fj = fitness[j] + constraint_violation(pop[j])\n            \n            return fi - fj\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k] + constraint_violation(pop[k]))\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def calculate_diversity(self):\n        \"\"\"Calculates the mean pairwise Euclidean distance in the population.\"\"\"\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(self.population[i] - self.population[j]))\n        return np.mean(distances) if distances else 0\n\n    def update_solution_memory(self, x, f):\n        \"\"\"Updates the solution memory with the current solution if it's better than the worst in memory.\"\"\"\n        if len(self.solution_memory) < self.memory_size:\n            self.solution_memory.append((x.copy(), f))\n            self.solution_memory.sort(key=lambda item: item[1])  # Sort by fitness\n        else:\n            if f < self.solution_memory[-1][1]:\n                self.solution_memory[-1] = (x.copy(), f)\n                self.solution_memory.sort(key=lambda item: item[1])\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n                \n                self.update_solution_memory(crossed_population[i], f)\n\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness, func)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func, diversify=False):\n        if diversify:\n             # Introduce diversity by re-initializing a fraction of the population\n            num_to_diversify = int(0.5 * self.pop_size)\n            indices_to_diversify = np.random.choice(self.pop_size, num_to_diversify, replace=False)\n            self.population[indices_to_diversify] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_diversify, self.dim))\n            self.fitness[indices_to_diversify] = np.array([func(x) for x in self.population[indices_to_diversify]])\n            self.budget -= num_to_diversify  # Account for new function evaluations\n\n        else:\n            # Memory-augmented restart: Re-initialize using best solutions from memory\n            if len(self.solution_memory) > 0:\n                num_to_use_memory = min(len(self.solution_memory), self.pop_size)\n                indices_to_use_memory = np.random.choice(len(self.solution_memory), num_to_use_memory, replace=False)\n                \n                new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim)) # Remaining solutions are random\n                \n                for i, idx in enumerate(indices_to_use_memory):\n                    new_population[i] = self.solution_memory[idx][0] # Replace initial population with memory solutions\n\n                self.population = new_population\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n            else:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n        self.update_solution_memory(self.x_opt, self.f_opt)\n\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                self.update_solution_memory(self.x_opt, self.f_opt)\n            \n            self.best_fitness_history.append(current_best_fitness)\n            \n            if self.check_stagnation():\n                diversity = self.calculate_diversity()\n                if diversity < self.diversity_threshold:\n                    self.restart(func, diversify=True) # Restart and diversify if diversity is low\n                else:\n                    self.restart(func) # Otherwise, just restart\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE_OrthoArchive_Diversity_MemoryRestart scored 0.460 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e137886b-5c57-45cc-bc0c-3b848af0217e"], "operator": null, "metadata": {"aucs": [0.19944273175937388, 0.3485900726540635, 0.421491248652762, 0.6016141370697137, 0.35969385578125, 0.5273257717038586, 0.3379492680983225, 0.41541514171608307, 0.4215269304720115, 0.2991633063645476, 0.603066228471411, 0.9834735331858109, 0.33481720155131955, 0.36223526633791936, 0.7767672765985345, 0.5107238187468875, 0.36123469745509296, 0.598942529356901, 0.23560327832340677, 0.49331705651403235]}}
{"id": "dafe91d1-d062-4d09-bc7d-f97dccc05d2a", "fitness": 0.3190743440193728, "name": "AdaptiveDE_OrthoArchive_Diversity_LS", "description": "Introducing a landscape-aware mutation factor adaptation and a probabilistic local search based on the current best solution.", "code": "import numpy as np\n\nclass AdaptiveDE_OrthoArchive_Diversity_LS:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=15, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, exploration_prob=0.1, diversity_threshold=0.1, ls_prob=0.1, ls_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.exploration_prob = exploration_prob  # Probability of using archive-based exploration\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n        self.ls_prob = ls_prob  # Probability of local search\n        self.ls_radius = ls_radius  # Radius of local search\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        # Adapt F based on landscape steepness\n        fitness_diff = np.max(self.fitness) - np.min(self.fitness)\n        F_adapted = self.F * (1 + fitness_diff)\n\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + F_adapted * (self.population[best_idx] - self.population[i]) + F_adapted * (x1 - x2)\n            elif np.random.rand() < self.exploration_prob and len(self.archive) > 0:  # Archive-based mutation\n                archive_idx = np.random.randint(len(self.archive))\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.archive[archive_idx] + F_adapted * (x1 - x2)\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + F_adapted * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness, func):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        # Constraint violation penalty.  Modify to fit the problem if needed\n        def constraint_violation(x):\n            return 0 # No constraints in the benchmark\n\n        def compare(i, j):\n            fi = fitness[i] + constraint_violation(pop[i])\n            fj = fitness[j] + constraint_violation(pop[j])\n            \n            return fi - fj\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k] + constraint_violation(pop[k]))\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def calculate_diversity(self):\n        \"\"\"Calculates the mean pairwise Euclidean distance in the population.\"\"\"\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(self.population[i] - self.population[j]))\n        return np.mean(distances) if distances else 0\n    \n    def local_search(self, func, x_best):\n        \"\"\"Performs local search around the best solution.\"\"\"\n        x_new = x_best + np.random.uniform(-self.ls_radius, self.ls_radius, size=self.dim)\n        x_new = self.handle_bounds(x_new, func)  # Ensure bounds are respected\n        f_new = func(x_new)\n        self.budget -= 1\n        return f_new, x_new\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness, func)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func, diversify=False):\n        if diversify:\n             # Introduce diversity by re-initializing a fraction of the population\n            num_to_diversify = int(0.5 * self.pop_size)\n            indices_to_diversify = np.random.choice(self.pop_size, num_to_diversify, replace=False)\n            self.population[indices_to_diversify] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_diversify, self.dim))\n            self.fitness[indices_to_diversify] = np.array([func(x) for x in self.population[indices_to_diversify]])\n            self.budget -= num_to_diversify  # Account for new function evaluations\n\n        else:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            current_best_idx = np.argmin(self.fitness)\n            current_best_x = self.population[current_best_idx]\n            \n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = current_best_x\n\n                # Perform local search with some probability\n                if np.random.rand() < self.ls_prob and self.budget > 0:\n                    f_ls, x_ls = self.local_search(func, self.x_opt)\n                    if f_ls < self.f_opt:\n                         self.f_opt = f_ls\n                         self.x_opt = x_ls\n                         self.population[current_best_idx] = x_ls #Update current pop.\n\n            \n            self.best_fitness_history.append(current_best_fitness)\n            \n            if self.check_stagnation():\n                diversity = self.calculate_diversity()\n                if diversity < self.diversity_threshold:\n                    self.restart(func, diversify=True) # Restart and diversify if diversity is low\n                else:\n                    self.restart(func) # Otherwise, just restart\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE_OrthoArchive_Diversity_LS scored 0.319 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e137886b-5c57-45cc-bc0c-3b848af0217e"], "operator": null, "metadata": {"aucs": [0.11154344977420005, 0.16100693473698902, 0.3850823147100042, 0.2571180620709502, 0.21436041751122648, 0.3957226665017388, 0.2178189842567566, 0.20689460611254262, 0.19144634214728062, 0.17342475879843156, 0.2530105891450338, 0.9952137328722741, 0.2414753403057589, 0.24461885787832038, 0.6659016848078583, 0.43479396494436895, 0.21530163010545267, 0.3747083092427751, 0.1598833415609795, 0.482160892904513]}}
{"id": "8b9be7b1-2fdd-47a9-a66e-278fc2fe4c7f", "fitness": -Infinity, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced_v2", "description": "Combines Adaptive Differential Evolution with orthogonal crossover, archive, local search guided by fitness variance and a more aggressive population resizing strategy for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced_v2:\n    def __init__(self, budget=10000, dim=10, pop_size_min=15, pop_size_max=75, archive_size=15, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=500, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.05, local_search_radius_decay=0.95, restart_probability=0.05, ls_prob_initial=0.1, fitness_variance_threshold=1e-9, pop_resizing_frequency=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max\n        self.archive_size = archive_size\n        self.F = F_initial\n        self.CR = CR_initial\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size\n        self.pop_size_adaptation_rate = 0.2\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.ls_prob = ls_prob_initial\n        self.ls_prob_initial = ls_prob_initial\n        self.ls_success_rate = 0.0\n        self.ls_success_history = []\n        self.ls_history_length = 20\n        self.fitness_variance_threshold = fitness_variance_threshold\n        self.pop_resizing_frequency = pop_resizing_frequency\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < self.fitness_variance_threshold:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        if np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0\n            self.best_fitness_history = []\n            print(\"Restarting population.\")\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n        success = False\n\n        for _ in range(self.dim * 2):\n            if self.budget <= 0:\n                break\n\n            direction = np.random.uniform(-1, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)\n\n            new_x = best_x + self.local_search_radius * direction\n            new_x = self.handle_bounds(new_x[None, :], func)[0]\n\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n                success = True\n\n        self.local_search_radius *= self.local_search_radius_decay\n        return success\n    \n    def adjust_population_size(self):\n        fitness_std = np.std(self.fitness)\n        \n        if fitness_std < self.fitness_variance_threshold:\n             #Exploitation: Reduce population size to concentrate search\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n            self.population = self.population[:self.pop_size]\n            self.fitness = self.fitness[:self.pop_size]\n        else:\n            #Exploration: Increase population size to diversify search\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n            \n            # Create new random individuals and evaluate their fitness\n            new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - len(self.population), self.dim))\n            new_fitness = np.array([func(x) for x in new_individuals])\n            self.budget -= len(new_individuals)\n        \n            # Concatenate new individuals and fitness values to existing population\n            self.population = np.concatenate((self.population, new_individuals))\n            self.fitness = np.concatenate((self.fitness, new_fitness))\n            \n            #Stochastic Ranking again\n            self.population, self.fitness = self.stochastic_ranking(self.population, self.fitness)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size_min:\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            if np.random.rand() < self.ls_prob:\n                success = self.local_search(func)\n                self.ls_success_history.append(int(success))\n\n                if len(self.ls_success_history) > self.ls_history_length:\n                    self.ls_success_history.pop(0)\n\n                self.ls_success_rate = np.mean(self.ls_success_history)\n                if self.ls_success_rate > 0.4:\n                    self.ls_prob = min(1.0, self.ls_prob * 1.1)\n                else:\n                    self.ls_prob = max(0.01, self.ls_prob * 0.9)\n\n            if self.generation % self.pop_resizing_frequency == 0:\n                self.adjust_population_size()\n\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = 0.05\n                    self.ls_prob = self.ls_prob_initial\n\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 271, in __call__\n  File \"<string>\", line 222, in adjust_population_size\nNameError: name 'func' is not defined\n.", "error": "", "parent_ids": ["f082cddf-61b8-40ee-a4db-81408f0f652d"], "operator": null, "metadata": {}}
{"id": "ddb6717f-8281-4238-b41a-b7a2c66ecf52", "fitness": 0.07851438793007753, "name": "AdaptiveDE_OrthoArchive_Diversity_MemoryRestart_LocalSearch", "description": "Enhanced Adaptive Differential Evolution with improved mutation strategies, a landscape-aware local search integrated into the selection process, dynamic diversity control through population subset replacement, and adaptive parameter adjustments for both exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE_OrthoArchive_Diversity_MemoryRestart_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=15, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, exploration_prob=0.1, diversity_threshold=0.1, memory_size=5, local_search_prob=0.1, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.exploration_prob = exploration_prob  # Probability of using archive-based exploration\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n        self.memory_size = memory_size  # Size of the memory to store best solutions\n        self.solution_memory = [] # Stores best solutions encountered\n        self.local_search_prob = local_search_prob\n        self.local_search_radius = local_search_radius\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            rand = np.random.rand()\n            if rand < 0.33: # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            elif rand < 0.66 and len(self.archive) > 0:  # Archive-based mutation\n                archive_idx = np.random.randint(len(self.archive))\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.archive[archive_idx] + self.F * (x1 - x2)\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness, func):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        # Constraint violation penalty.  Modify to fit the problem if needed\n        def constraint_violation(x):\n            return 0 # No constraints in the benchmark\n\n        def compare(i, j):\n            fi = fitness[i] + constraint_violation(pop[i])\n            fj = fitness[j] + constraint_violation(pop[j])\n            \n            return fi - fj\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k] + constraint_violation(pop[k]))\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def calculate_diversity(self):\n        \"\"\"Calculates the mean pairwise Euclidean distance in the population.\"\"\"\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(self.population[i] - self.population[j]))\n        return np.mean(distances) if distances else 0\n\n    def update_solution_memory(self, x, f):\n        \"\"\"Updates the solution memory with the current solution if it's better than the worst in memory.\"\"\"\n        if len(self.solution_memory) < self.memory_size:\n            self.solution_memory.append((x.copy(), f))\n            self.solution_memory.sort(key=lambda item: item[1])  # Sort by fitness\n        else:\n            if f < self.solution_memory[-1][1]:\n                self.solution_memory[-1] = (x.copy(), f)\n                self.solution_memory.sort(key=lambda item: item[1])\n\n    def local_search(self, func, x, radius):\n        \"\"\"Performs local search around a solution.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n\n        for _ in range(5):  # Limited local search steps\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        return best_x, best_f\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            # Local Search integration\n            if np.random.rand() < self.local_search_prob:\n                crossed_population[i], f = self.local_search(func, crossed_population[i], self.local_search_radius)\n            \n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n                \n                self.update_solution_memory(crossed_population[i], f)\n\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness, func)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        # Dynamic diversity control - replace worst solutions with random ones\n        if np.random.rand() < 0.2:\n            num_to_replace = int(0.1 * self.pop_size)  # Replace 10% of the population\n            worst_indices = np.argsort(new_fitness)[-num_to_replace:]\n            new_population[worst_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_replace, self.dim))\n            new_fitness[worst_indices] = [func(x) for x in new_population[worst_indices]]\n            self.budget -= num_to_replace\n\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func, diversify=False):\n        if diversify:\n             # Introduce diversity by re-initializing a fraction of the population\n            num_to_diversify = int(0.5 * self.pop_size)\n            indices_to_diversify = np.random.choice(self.pop_size, num_to_diversify, replace=False)\n            self.population[indices_to_diversify] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_diversify, self.dim))\n            self.fitness[indices_to_diversify] = np.array([func(x) for x in self.population[indices_to_diversify]])\n            self.budget -= num_to_diversify  # Account for new function evaluations\n\n        else:\n            # Memory-augmented restart: Re-initialize using best solutions from memory\n            if len(self.solution_memory) > 0:\n                num_to_use_memory = min(len(self.solution_memory), self.pop_size)\n                indices_to_use_memory = np.random.choice(len(self.solution_memory), num_to_use_memory, replace=False)\n                \n                new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim)) # Remaining solutions are random\n                \n                for i, idx in enumerate(indices_to_use_memory):\n                    new_population[i] = self.solution_memory[idx][0] # Replace initial population with memory solutions\n\n                self.population = new_population\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n            else:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n        self.update_solution_memory(self.x_opt, self.f_opt)\n\n\n        while self.budget > self.pop_size + 5: # Ensure enough budget for population updates and local search\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                self.update_solution_memory(self.x_opt, self.f_opt)\n            \n            self.best_fitness_history.append(current_best_fitness)\n            \n            if self.check_stagnation():\n                diversity = self.calculate_diversity()\n                if diversity < self.diversity_threshold:\n                    self.restart(func, diversify=True) # Restart and diversify if diversity is low\n                else:\n                    self.restart(func) # Otherwise, just restart\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE_OrthoArchive_Diversity_MemoryRestart_LocalSearch scored 0.079 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d89a4474-d644-4f93-9ac2-15459112e861"], "operator": null, "metadata": {"aucs": [0.15702877586015507, 0]}}
{"id": "ba347ec6-bec0-4053-ad5c-5fb732c219fd", "fitness": -Infinity, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_v3", "description": "Introducing a self-adaptive population size based on success rate, enhanced archive diversity using crowding distance, and a local search intensified by iteratively increasing its radius when stagnation is detected.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_v3:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, lars_tolerance=1e-5, local_search_radius=0.1, ls_radius_increase_factor=1.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.lars_tolerance = lars_tolerance\n        self.local_search_radius = local_search_radius  # Initial local search radius\n        self.ls_radius_increase_factor = ls_radius_increase_factor #Factor to increase the LS radius.\n        self.success_rate_threshold = 0.2 # threshold for population size adaptation\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i + 1]] - dimension_values[sorted_indices[i - 1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        success_rate = improved_count / self.pop_size\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = np.clip((1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum, 0.1, 0.9) # Clip F\n            self.CR = np.clip((1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum, 0.1, 0.9) # Clip CR\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation based on success rate and landscape awareness\n        if self.generation > 50:\n            if success_rate < self.success_rate_threshold and self.pop_size > self.pop_size_min:\n                self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n                self.population = self.population[:self.pop_size]\n                self.fitness = self.fitness[:self.pop_size]\n\n            elif success_rate >= self.success_rate_threshold and self.pop_size < self.pop_size_max:\n                self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n                new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - len(self.population), self.dim))\n                new_fitness_values = [func(x) for x in new_individuals]\n                self.budget -= len(new_fitness_values)\n\n                self.population = np.concatenate((self.population, new_individuals))\n                self.fitness = np.concatenate((self.fitness, new_fitness_values))\n\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n        \n        #Calculate crowding distance\n        crowding_distances = self.crowding_distance(combined_population, combined_fitness)\n        \n        # Sort by fitness and crowding distance\n        sorted_indices = np.argsort(combined_fitness)\n        \n        #Select top archive_size individuals based on fitness and crowding distance\n        selected_indices = sorted_indices[:self.archive_size]\n        \n        self.archive = list(combined_population[selected_indices])\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n        self.local_search_radius = 0.1 # Reset the local search radius\n\n    def local_search(self, func, x_opt):\n        # Perform local search around the best solution\n        num_evals = min(self.pop_size, self.budget) # Adaptive local evals depending on budget\n        for _ in range(num_evals):\n            # Generate a random perturbation within the radius\n            perturbation = np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            x_neighbor = x_opt + perturbation\n            x_neighbor = self.handle_bounds(np.array([x_neighbor]), func)[0] # Keep within bounds\n\n            f_neighbor = func(x_neighbor)\n            self.budget -= 1\n\n            if f_neighbor < self.f_opt:\n                self.f_opt = f_neighbor\n                self.x_opt = x_neighbor\n\n    def intensify_local_search(self):\n        self.local_search_radius *= self.ls_radius_increase_factor  # Increase the radius to escape plateaus\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            if self.check_stagnation():\n                self.intensify_local_search() # Intensify local search when stagnating\n                self.local_search(func, self.x_opt)\n                self.local_search_radius = 0.1 # Reset the local search radius to the default\n                self.restart(func)\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n\n        # Final local search at the end\n        if self.budget > 0:\n            self.local_search(func, self.x_opt)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 239, in __call__\n  File \"<string>\", line 162, in select\n  File \"mtrand.pyx\", line 1154, in numpy.random.mtrand.RandomState.uniform\n  File \"_common.pyx\", line 600, in numpy.random._common.cont\n  File \"_common.pyx\", line 508, in numpy.random._common.cont_broadcast_2\nValueError: negative dimensions are not allowed\n.", "error": "", "parent_ids": ["5d2344a1-c053-41a6-bcff-d19ed570e3f1"], "operator": null, "metadata": {}}
{"id": "ecdf6497-9b7a-4f4d-b7b0-b2ae9e0482c7", "fitness": 0.08976015979718394, "name": "AdaptiveDE_OrthoArchive_Diversity_MemoryRestart_LocalIntensification", "description": "Enhanced Adaptive Differential Evolution with orthogonal crossover, archive-based mutation, self-regulating strategy adaptation, landscape-aware population diversity, memory-augmented restart, and local search intensification around promising solutions.", "code": "import numpy as np\n\nclass AdaptiveDE_OrthoArchive_Diversity_MemoryRestart_LocalIntensification:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=15, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, exploration_prob=0.1, diversity_threshold=0.1, memory_size=5, local_search_radius=0.1, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.exploration_prob = exploration_prob  # Probability of using archive-based exploration\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n        self.memory_size = memory_size  # Size of the memory to store best solutions\n        self.solution_memory = [] # Stores best solutions encountered\n        self.local_search_radius = local_search_radius  # Radius for local search\n        self.local_search_iterations = local_search_iterations  # Iterations for local search\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            elif np.random.rand() < self.exploration_prob and len(self.archive) > 0:  # Archive-based mutation\n                archive_idx = np.random.randint(len(self.archive))\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.archive[archive_idx] + self.F * (x1 - x2)\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness, func):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        # Constraint violation penalty.  Modify to fit the problem if needed\n        def constraint_violation(x):\n            return 0 # No constraints in the benchmark\n\n        def compare(i, j):\n            fi = fitness[i] + constraint_violation(pop[i])\n            fj = fitness[j] + constraint_violation(pop[j])\n            \n            return fi - fj\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k] + constraint_violation(pop[k]))\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def calculate_diversity(self):\n        \"\"\"Calculates the mean pairwise Euclidean distance in the population.\"\"\"\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(self.population[i] - self.population[j]))\n        return np.mean(distances) if distances else 0\n\n    def update_solution_memory(self, x, f):\n        \"\"\"Updates the solution memory with the current solution if it's better than the worst in memory.\"\"\"\n        if len(self.solution_memory) < self.memory_size:\n            self.solution_memory.append((x.copy(), f))\n            self.solution_memory.sort(key=lambda item: item[1])  # Sort by fitness\n        else:\n            if f < self.solution_memory[-1][1]:\n                self.solution_memory[-1] = (x.copy(), f)\n                self.solution_memory.sort(key=lambda item: item[1])\n\n    def local_search(self, func, x):\n        \"\"\"Performs local search around a given solution.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -=1\n        \n        for _ in range(self.local_search_iterations):\n            # Generate a neighbor within the radius\n            neighbor = x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            neighbor = self.handle_bounds(neighbor, func)\n            \n            f = func(neighbor)\n            self.budget -= 1\n            \n            if f < best_f:\n                best_f = f\n                best_x = neighbor.copy()\n        \n        return best_x, best_f\n\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n                \n                #Local Search\n                new_population[i], new_fitness[i] = self.local_search(func, new_population[i])\n                self.update_solution_memory(new_population[i], new_fitness[i])\n\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness, func)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func, diversify=False):\n        if diversify:\n             # Introduce diversity by re-initializing a fraction of the population\n            num_to_diversify = int(0.5 * self.pop_size)\n            indices_to_diversify = np.random.choice(self.pop_size, num_to_diversify, replace=False)\n            self.population[indices_to_diversify] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_diversify, self.dim))\n            self.fitness[indices_to_diversify] = np.array([func(x) for x in self.population[indices_to_diversify]])\n            self.budget -= num_to_diversify  # Account for new function evaluations\n\n        else:\n            # Memory-augmented restart: Re-initialize using best solutions from memory\n            if len(self.solution_memory) > 0:\n                num_to_use_memory = min(len(self.solution_memory), self.pop_size)\n                indices_to_use_memory = np.random.choice(len(self.solution_memory), num_to_use_memory, replace=False)\n                \n                new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim)) # Remaining solutions are random\n                \n                for i, idx in enumerate(indices_to_use_memory):\n                    new_population[i] = self.solution_memory[idx][0] # Replace initial population with memory solutions\n\n                self.population = new_population\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n            else:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n        self.update_solution_memory(self.x_opt, self.f_opt)\n\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                self.update_solution_memory(self.x_opt, self.f_opt)\n            \n            self.best_fitness_history.append(current_best_fitness)\n            \n            if self.check_stagnation():\n                diversity = self.calculate_diversity()\n                if diversity < self.diversity_threshold:\n                    self.restart(func, diversify=True) # Restart and diversify if diversity is low\n                else:\n                    self.restart(func) # Otherwise, just restart\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE_OrthoArchive_Diversity_MemoryRestart_LocalIntensification scored 0.090 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d89a4474-d644-4f93-9ac2-15459112e861"], "operator": null, "metadata": {"aucs": [0.17952031959436787, 0]}}
{"id": "3f00959d-88bb-488f-b079-4479194dcf50", "fitness": 0.4993556065661752, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_v3", "description": "Improves exploration-exploitation balance by dynamically adjusting local search frequency based on stagnation and fitness variance, and adaptively tunes crossover probabilities using a success rate based approach.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_v3:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, lars_tolerance=1e-5, local_search_radius=0.1, local_search_frequency=10, cr_adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.lars_tolerance = lars_tolerance\n        self.local_search_radius = local_search_radius  # Initial local search radius\n        self.local_search_frequency = local_search_frequency # How often to perform local search\n        self.cr_adaptation_rate = cr_adaptation_rate\n        self.cr_success_rate = 0.5\n        self.cr_success_history = []\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i + 1]] - dimension_values[sorted_indices[i - 1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                self.cr_success_history.append(1)\n            else:\n                 self.cr_success_history.append(0)\n                \n            self.successful_F.append(self.F)\n            self.successful_CR.append(self.CR)\n\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = np.clip((1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum, 0.1, 0.9) # Clip F\n            #self.CR = np.clip((1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum, 0.1, 0.9) # Clip CR\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation based on landscape awareness\n        if self.generation > 50:\n            fitness_std = np.std(self.fitness)\n            if fitness_std < self.lars_tolerance and self.pop_size > self.pop_size_min:\n                self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n            elif fitness_std > self.lars_tolerance and self.pop_size < self.pop_size_max:\n                self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n\n        # Update CR based on success rate\n        if self.cr_success_history:\n            success_rate = np.mean(self.cr_success_history)\n            self.cr_success_rate = (1 - self.cr_adaptation_rate) * self.cr_success_rate + self.cr_adaptation_rate * success_rate\n            self.CR = np.clip(self.cr_success_rate, 0.1, 0.9)\n            self.cr_success_history = []\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        # Select top archive_size individuals + some random individuals to promote diversity\n        num_elite = int(0.8 * self.archive_size)  # Keep top 80%\n        elite_indices = np.arange(num_elite)\n        random_indices = np.random.choice(len(combined_population), self.archive_size - num_elite, replace=False)\n        selected_indices = np.concatenate((elite_indices, random_indices))\n        np.random.shuffle(selected_indices)  # Shuffle to mix elite and random\n        \n        self.archive = list(combined_population[selected_indices])\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n        self.local_search_radius = 0.1 # Reset the local search radius\n\n    def local_search(self, func, x_opt):\n        # Perform local search around the best solution\n        num_evals = min(self.pop_size, self.budget) # Adaptive local evals depending on budget\n        for _ in range(num_evals):\n            # Generate a random perturbation within the radius\n            perturbation = np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            x_neighbor = x_opt + perturbation\n            x_neighbor = self.handle_bounds(np.array([x_neighbor]), func)[0] # Keep within bounds\n\n            f_neighbor = func(x_neighbor)\n            self.budget -= 1\n\n            if f_neighbor < self.f_opt:\n                self.f_opt = f_neighbor\n                self.x_opt = x_neighbor\n\n        self.local_search_radius *= 0.5  # Reduce the radius after each local search\n        self.local_search_radius = max(self.local_search_radius, 1e-6) # Avoid zero radius\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            # Adjust local search frequency based on stagnation and fitness variance\n            if self.check_stagnation() or (self.generation % self.local_search_frequency == 0 and np.std(self.best_fitness_history[-min(self.stagnation_threshold, len(self.best_fitness_history)):]) < self.lars_tolerance):\n                self.local_search(func, self.x_opt)\n                if self.check_stagnation():\n                    self.restart(func)\n                    self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n\n\n        # Final local search at the end\n        if self.budget > 0:\n            self.local_search(func, self.x_opt)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch_v3 scored 0.499 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5d2344a1-c053-41a6-bcff-d19ed570e3f1"], "operator": null, "metadata": {"aucs": [0.18393987289216307, 0.30449423389555674, 0.48390152293765254, 0.764789679336311, 0.4218429937535284, 0.6574059121933069, 0.3565536226500804, 0.4484405976323399, 0.4903679307595761, 0.23722031970039814, 0.6663723760298816, 0.9961873568448193, 0.316223517334703, 0.4508358097957522, 0.8082100704526898, 0.5937533005974462, 0.3836052550561133, 0.7317263112895995, 0.19513120661521766, 0.4961102415563695]}}
{"id": "c91c478b-c7fd-4a8c-8b58-da97b05fc99f", "fitness": 0.4808514328758986, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced2", "description": "Enhanced Adaptive Differential Evolution with orthogonal crossover, archive, shrinking local search radius, adaptive population resizing, dynamic F/CR adjustment, and a novel local search trigger based on stagnation and success history for efficient exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced2:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05, ls_prob_initial=0.1, ls_success_threshold=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.ls_prob = ls_prob_initial # Local search probability\n        self.ls_prob_initial = ls_prob_initial\n        self.ls_success_rate = 0.0\n        self.ls_success_history = []\n        self.ls_history_length = 20\n        self.ls_success_threshold = ls_success_threshold # Threshold for triggering local search\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        if np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            print(\"Restarting population.\")\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n        success = False\n\n        for _ in range(self.dim * 2): # Budget conscious local search\n            if self.budget <= 0:\n                break\n\n            direction = np.random.uniform(-1, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)  # Normalize\n\n            new_x = best_x + self.local_search_radius * direction\n            new_x = self.handle_bounds(new_x[None, :], func)[0] # Handle bounds for single vector\n\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n                success = True\n\n        self.local_search_radius *= self.local_search_radius_decay # Reduce radius\n        return success\n\n    def should_trigger_local_search(self):\n        # Check stagnation and success history\n        stagnant = self.check_stagnation()\n        sufficient_success = self.ls_success_rate > self.ls_success_threshold\n        return stagnant or sufficient_success\n        \n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            # Adaptive local search application\n            if self.should_trigger_local_search():\n                success = self.local_search(func)\n                self.ls_success_history.append(int(success))\n\n                if len(self.ls_success_history) > self.ls_history_length:\n                    self.ls_success_history.pop(0)\n\n                self.ls_success_rate = np.mean(self.ls_success_history)\n                # Adapt local search probability\n                if self.ls_success_rate > 0.4:\n                    self.ls_prob = min(1.0, self.ls_prob * 1.1)\n                else:\n                    self.ls_prob = max(0.01, self.ls_prob * 0.9)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = 0.1 # Reset radius\n                    self.ls_prob = self.ls_prob_initial # Reset ls_prob\n        \n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced2 scored 0.481 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f082cddf-61b8-40ee-a4db-81408f0f652d"], "operator": null, "metadata": {"aucs": [0.2140894570536338, 0.3184496051815551, 0.43625968144886496, 0.6907830416293497, 0.42589290192860607, 0.5274525560980192, 0.33246984230629595, 0.40967714186823345, 0.44019454080386844, 0.4458977207936211, 0.6087451532359626, 0.9932915718348103, 0.3203388663585022, 0.40324442136464644, 0.7562241964422337, 0.5315975046435548, 0.37324352660318305, 0.6396559296385106, 0.24236746127895448, 0.5071535370055642]}}
{"id": "8af6e6db-f4d4-415c-9ad0-44cec78d3d7a", "fitness": 0.4860984685239906, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced_v2", "description": "Implements a more aggressive local search with adaptive radius adjustment and orthogonal exploration around the best solution, combined with a new landscape-aware restart mechanism based on the angle between consecutive steps to escape local optima effectively.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced_v2:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05, restart_fitness_variance_threshold=1e-6, angle_threshold=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.restart_fitness_variance_threshold = restart_fitness_variance_threshold\n        self.budget_consumed_threshold = 0.75 # Restart if budget consumed above threshold.\n        self.best_fitness_since_restart = np.inf\n        self.angle_threshold = angle_threshold # Cosine of angle above which restart is considered\n        self.previous_step = None\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n        self.best_fitness_since_restart = np.min(self.fitness)\n        self.previous_step = None\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        # Restart if fitness variance is low or budget consumption is high, or angle between steps is high, but only if there's been no recent improvement.\n        budget_consumed = 1 - (self.budget / 10000)\n        fitness_variance_low = len(self.best_fitness_history) >= self.stagnation_threshold and np.std(self.best_fitness_history[-self.stagnation_threshold:]) < self.restart_fitness_variance_threshold\n        budget_exceeded_threshold = budget_consumed > self.budget_consumed_threshold\n\n        no_recent_improvement = self.f_opt >= self.best_fitness_since_restart\n\n        # Check angle between previous and current steps\n        if self.previous_step is not None:\n            current_step = self.x_opt - self.population[np.argmin(self.fitness)]\n            cos_angle = np.dot(self.previous_step, current_step) / (np.linalg.norm(self.previous_step) * np.linalg.norm(current_step) + 1e-8)  # Adding small value to avoid division by zero\n            similar_direction = cos_angle > self.angle_threshold\n        else:\n            similar_direction = False\n            cos_angle = 0.0\n\n        if (fitness_variance_low or budget_exceeded_threshold or similar_direction) and no_recent_improvement and np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            self.best_fitness_since_restart = np.min(self.fitness)\n            self.previous_step = None\n\n            print(f\"Restarting population. Budget consumed: {budget_consumed:.2f}, Fitness Variance: {np.std(self.best_fitness_history[-self.stagnation_threshold:]) if len(self.best_fitness_history) >= self.stagnation_threshold else 'N/A'}, Cosine Angle: {cos_angle:.2f}\")\n\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n        original_radius = self.local_search_radius\n\n        # Aggressive local search: adapt radius based on success\n        success_count = 0\n        num_iterations = self.dim * 4 #Increased iterations\n        for _ in range(num_iterations):\n            if self.budget <= 0:\n                break\n\n            direction = np.random.uniform(-1, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)  # Normalize\n\n            new_x = best_x + self.local_search_radius * direction\n            new_x = self.handle_bounds(new_x[None, :], func)[0] # Handle bounds for single vector\n\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n                success_count += 1\n                self.local_search_radius *= 1.1  # Increase radius if successful\n            else:\n                self.local_search_radius *= 0.9 # Reduce radius if unsuccessful\n\n            self.local_search_radius = min(self.local_search_radius, original_radius * 2) # Radius cap\n\n        if success_count == 0:\n            self.local_search_radius = original_radius * self.local_search_radius_decay\n        else:\n            self.local_search_radius = original_radius * (1 + (success_count / num_iterations) * (1 - self.local_search_radius_decay))\n            self.local_search_radius = min(self.local_search_radius, 0.1)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            current_best_x = self.population[np.argmin(self.fitness)]\n            if current_best_fitness < self.f_opt:\n                self.previous_step = self.x_opt - current_best_x # Save step\n                self.f_opt = current_best_fitness\n                self.x_opt = current_best_x\n                self.best_fitness_since_restart = self.f_opt # Update best fitness since last restart\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            if self.generation % self.local_search_frequency == 0:\n                self.local_search(func)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = 0.1 # Reset radius\n        \n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced_v2 scored 0.486 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9e8c6680-7240-4d08-8779-d44e1b3b466d"], "operator": null, "metadata": {"aucs": [0.22015071169581413, 0.43153182763688325, 0.43306311338034364, 0.6690699292449795, 0.3680052645748958, 0.5248213241409903, 0.34704085021333764, 0.40515274263017553, 0.45913045199874036, 0.3469157992122286, 0.707755261464438, 0.9950102404196367, 0.2954063284537469, 0.3589649862294164, 0.7733439567048843, 0.5605805809441888, 0.36697720183566573, 0.6628747444184369, 0.2905741089424714, 0.5055999463385388]}}
{"id": "2e3617ec-759f-4b1e-85ff-d0065a4d7a4e", "fitness": 0.477890391684744, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_Improved", "description": "Enhanced Adaptive Differential Evolution with orthogonal crossover, archive, dynamic local search radius, adaptive F/CR, and landscape-aware population resizing based on success rate and budget, focusing local search near promising regions.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_Improved:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05, ls_prob_initial=0.1, ls_radius_min=0.001):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.ls_prob = ls_prob_initial # Local search probability\n        self.ls_prob_initial = ls_prob_initial\n        self.ls_success_rate = 0.0\n        self.ls_success_history = []\n        self.ls_history_length = 20\n        self.ls_radius_min = ls_radius_min\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation based on success rate and remaining budget\n        improvement_ratio = improved_count / self.pop_size\n        budget_ratio = self.budget / 10000  # Assuming initial budget is 10000\n\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max and budget_ratio > 0.2:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        if np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            print(\"Restarting population.\")\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n        success = False\n        num_trials = 0\n\n        while num_trials < self.dim * 2: # Budget conscious local search\n            if self.budget <= 0 or self.local_search_radius < self.ls_radius_min:\n                break\n\n            direction = np.random.uniform(-1, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)  # Normalize\n\n            new_x = best_x + self.local_search_radius * direction\n            new_x = self.handle_bounds(new_x[None, :], func)[0] # Handle bounds for single vector\n\n            new_f = func(new_x)\n            self.budget -= 1\n            num_trials += 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n                success = True\n                num_trials = 0 # Reset trials if improvement is found\n\n        if self.local_search_radius > self.ls_radius_min:\n            self.local_search_radius *= self.local_search_radius_decay # Reduce radius\n        return success\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            # Adaptive local search application\n            if np.random.rand() < self.ls_prob:\n                success = self.local_search(func)\n                self.ls_success_history.append(int(success))\n\n                if len(self.ls_success_history) > self.ls_history_length:\n                    self.ls_success_history.pop(0)\n\n                self.ls_success_rate = np.mean(self.ls_success_history)\n                # Adapt local search probability\n                if self.ls_success_rate > 0.4:\n                    self.ls_prob = min(1.0, self.ls_prob * 1.1)\n                else:\n                    self.ls_prob = max(0.01, self.ls_prob * 0.9)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = 0.1 # Reset radius\n                    self.ls_prob = self.ls_prob_initial # Reset ls_prob\n\n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch_Improved scored 0.478 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f082cddf-61b8-40ee-a4db-81408f0f652d"], "operator": null, "metadata": {"aucs": [0.20015194493941013, 0.3577860469025711, 0.4320739076168576, 0.7067977569031836, 0.40493678641473596, 0.5483703024992006, 0.3521778593308902, 0.3890071492698085, 0.428617426042897, 0.36480818404518567, 0.5975426308837857, 0.9999152406114666, 0.3227070023784616, 0.3718112491885598, 0.762815407598558, 0.5075459435686829, 0.38597052786202635, 0.656925915134478, 0.2544015235754711, 0.5134450289286525]}}
{"id": "8b5f53e5-478f-4d81-87be-5b11a7810fab", "fitness": 0.47375265164068336, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_v3", "description": "Enhanced Adaptive Differential Evolution with orthogonal crossover, archive, landscape-aware local search with adaptive radius and probability, and a dynamic population size strategy tuned by a success rate metric to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_v3:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05, ls_prob_initial=0.1, ls_radius_min = 0.001):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.ls_prob = ls_prob_initial # Local search probability\n        self.ls_prob_initial = ls_prob_initial\n        self.ls_success_rate = 0.0\n        self.ls_success_history = []\n        self.ls_history_length = 20\n        self.ls_radius_min = ls_radius_min\n        self.pop_success_rate = 0.0\n        self.pop_success_history = []\n        self.pop_history_length = 20\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation based on a moving average success rate\n        self.pop_success_history.append(improved_count / self.pop_size)\n        if len(self.pop_success_history) > self.pop_history_length:\n            self.pop_success_history.pop(0)\n\n        self.pop_success_rate = np.mean(self.pop_success_history)\n\n        if self.pop_success_rate > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif self.pop_success_rate < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        if np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            print(\"Restarting population.\")\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n        success = False\n\n        # Adaptive number of local search steps based on ls_success_rate\n        num_steps = int(self.dim * (1 + self.ls_success_rate))  # Increase steps if successful\n\n        for _ in range(num_steps): # Budget conscious local search\n            if self.budget <= 0:\n                break\n\n            direction = np.random.uniform(-1, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)  # Normalize\n\n            new_x = best_x + self.local_search_radius * direction\n            new_x = self.handle_bounds(new_x[None, :], func)[0] # Handle bounds for single vector\n\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n                success = True\n\n        if self.ls_success_rate < 0.2 and self.local_search_radius > self.ls_radius_min:\n            self.local_search_radius *= self.local_search_radius_decay  # Reduce radius if not successful\n\n        return success\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            # Adaptive local search application\n            if np.random.rand() < self.ls_prob:\n                success = self.local_search(func)\n                self.ls_success_history.append(int(success))\n\n                if len(self.ls_success_history) > self.ls_history_length:\n                    self.ls_success_history.pop(0)\n\n                self.ls_success_rate = np.mean(self.ls_success_history)\n                # Adapt local search probability\n                if self.ls_success_rate > 0.4:\n                    self.ls_prob = min(1.0, self.ls_prob * 1.1)\n                else:\n                    self.ls_prob = max(0.01, self.ls_prob * 0.9)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = 0.1 # Reset radius\n                    self.ls_prob = self.ls_prob_initial # Reset ls_prob\n        \n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch_v3 scored 0.474 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f082cddf-61b8-40ee-a4db-81408f0f652d"], "operator": null, "metadata": {"aucs": [0.2006810764889183, 0.3203809361101112, 0.43399607534532947, 0.726086675958912, 0.41425636223935536, 0.5441428713163545, 0.3498363367447246, 0.4012271144188684, 0.4264832803823597, 0.2811621564921446, 0.667000056105741, 0.9993587082269108, 0.3060279017318177, 0.36116011081327826, 0.7943064078550873, 0.5719053645283264, 0.35478279131769874, 0.5928427468828181, 0.22958842842294758, 0.49982763143196185]}}
{"id": "692f6a58-29af-4db2-9478-5512e233276e", "fitness": 0.4748582921962802, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced", "description": "Introducing a Landscape-Aware Mutation based on Fitness Improvement and a Dynamic CR Adjustment with a Success-Rate Adaptation.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05, restart_fitness_variance_threshold=1e-6):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.restart_fitness_variance_threshold = restart_fitness_variance_threshold\n        self.budget_consumed_threshold = 0.75 # Restart if budget consumed above threshold.\n        self.best_fitness_since_restart = np.inf\n        self.cr_history = [] # Track recent CR values\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n        self.best_fitness_since_restart = np.min(self.fitness)\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        # Landscape-Aware Mutation\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.1:\n                idx = np.random.choice(self.pop_size)\n                if self.fitness[i] < self.fitness[idx]:\n                    mutated_population[i] = self.population[i] + np.random.normal(0, 0.01, self.dim)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n        else:\n             self.CR *= 0.9  # Reduce CR if no success\n\n        self.cr_history.append(self.CR)\n        if len(self.cr_history) > 20:\n            self.cr_history.pop(0)\n\n        # Dynamic CR adjustment based on recent history\n        if len(self.cr_history) == 20:\n            if np.std(self.cr_history) < 0.01:\n                self.CR += 0.1  # Increase CR if it's stagnating\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        # Restart if fitness variance is low or budget consumption is high, but only if there's been no recent improvement.\n        budget_consumed = 1 - (self.budget / 10000)\n        fitness_variance_low = len(self.best_fitness_history) >= self.stagnation_threshold and np.std(self.best_fitness_history[-self.stagnation_threshold:]) < self.restart_fitness_variance_threshold\n        budget_exceeded_threshold = budget_consumed > self.budget_consumed_threshold\n\n        no_recent_improvement = self.f_opt >= self.best_fitness_since_restart\n        \n        if (fitness_variance_low or budget_exceeded_threshold) and no_recent_improvement and np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            self.best_fitness_since_restart = np.min(self.fitness)\n\n            print(f\"Restarting population. Budget consumed: {budget_consumed:.2f}, Fitness Variance: {np.std(self.best_fitness_history[-self.stagnation_threshold:]) if len(self.best_fitness_history) >= self.stagnation_threshold else 'N/A'}\")\n\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n\n        for _ in range(self.dim * 2): # Budget conscious local search\n            if self.budget <= 0:\n                break\n\n            direction = np.random.uniform(-1, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)  # Normalize\n\n            new_x = best_x + self.local_search_radius * direction\n            new_x = self.handle_bounds(new_x[None, :], func)[0] # Handle bounds for single vector\n\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n\n        self.local_search_radius *= self.local_search_radius_decay # Reduce radius\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                self.best_fitness_since_restart = self.f_opt # Update best fitness since last restart\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            if self.generation % self.local_search_frequency == 0:\n                self.local_search(func)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = 0.1 # Reset radius\n        \n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced scored 0.475 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9e8c6680-7240-4d08-8779-d44e1b3b466d"], "operator": null, "metadata": {"aucs": [0.19081541293603055, 0.3572159102406197, 0.45036822883041894, 0.6668225288256382, 0.4056339078637565, 0.543515476063682, 0.3319759112759473, 0.4073837189649958, 0.4676300100323083, 0.308033907013727, 0.6221459086460471, 0.9992987343362069, 0.2913640983500214, 0.3861496076731874, 0.8101751597278859, 0.5446482671648009, 0.36500256561811306, 0.6108119077967938, 0.22474758307818332, 0.5134269994872385]}}
{"id": "e0396aed-0a5a-4fd3-a33d-3b5210ff5574", "fitness": 0.46853559481042967, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_v3", "description": "Improved Adaptive Differential Evolution with landscape-aware parameter adaptation, dynamically adjusted local search probability based on recent success, orthogonal crossover, archive, and population diversity management.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_v3:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05, ls_prob_initial=0.1, ls_radius_initial = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.ls_prob = ls_prob_initial # Local search probability\n        self.ls_prob_initial = ls_prob_initial\n        self.ls_success_rate = 0.0\n        self.ls_success_history = []\n        self.ls_history_length = 20\n        self.ls_radius_initial = ls_radius_initial\n        self.min_radius = 1e-6\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n            # Adaptive learning rate decay: reduce learning rate if F and CR are close to 0 or 1\n            if abs(self.F - 0.5) > 0.4:\n                self.F_learning_rate *= 0.95\n            if abs(self.CR - 0.5) > 0.4:\n                self.CR_learning_rate *= 0.95\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        if np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            print(\"Restarting population.\")\n            self.local_search_radius = self.ls_radius_initial # Also reset the local search radius\n            self.ls_prob = self.ls_prob_initial\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n        success = False\n\n        for _ in range(self.dim * 2): # Budget conscious local search\n            if self.budget <= 0:\n                break\n\n            direction = np.random.uniform(-1, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)  # Normalize\n\n            new_x = best_x + self.local_search_radius * direction\n            new_x = self.handle_bounds(new_x[None, :], func)[0] # Handle bounds for single vector\n\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n                success = True\n\n        self.local_search_radius = max(self.local_search_radius * self.local_search_radius_decay, self.min_radius) # Reduce radius, but keep it bounded.\n        return success\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            # Adaptive local search application\n            if np.random.rand() < self.ls_prob:\n                success = self.local_search(func)\n                self.ls_success_history.append(int(success))\n\n                if len(self.ls_success_history) > self.ls_history_length:\n                    self.ls_success_history.pop(0)\n\n                self.ls_success_rate = np.mean(self.ls_success_history)\n                # Adapt local search probability\n                if self.ls_success_rate > 0.4:\n                    self.ls_prob = min(1.0, self.ls_prob * 1.1)\n                else:\n                    self.ls_prob = max(0.01, self.ls_prob * 0.9)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = self.ls_radius_initial # Reset radius to initial after stagnation but no restart.\n                    self.ls_prob = self.ls_prob_initial  # Reset ls_prob\n        \n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch_v3 scored 0.469 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f082cddf-61b8-40ee-a4db-81408f0f652d"], "operator": null, "metadata": {"aucs": [0.2125871423768786, 0.36092912705906743, 0.42071223008494585, 0.6673930290704315, 0.3866112713559502, 0.540319387183398, 0.35474072622871045, 0.4013917080855973, 0.4219218527225356, 0.3427338747059089, 0.5995836088280366, 0.9969290156252769, 0.31577660823142695, 0.3501618353147905, 0.7662133731262968, 0.5020565784668171, 0.35740389209290635, 0.6462469206065418, 0.21511467144162866, 0.511885043601447]}}
{"id": "d55cf93a-a012-48e8-9c3d-85c33966bd72", "fitness": 0.4545009618927055, "name": "AdaptiveDE_OrthoArchive_Diversity_MemoryRestart_v2", "description": "Introducing self-adaptive population size reduction based on a success rate metric, combined with a new memory initialization strategy and a differential evolution mutation based on a pool of the best solutions.", "code": "import numpy as np\n\nclass AdaptiveDE_OrthoArchive_Diversity_MemoryRestart_v2:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=15, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, exploration_prob=0.1, diversity_threshold=0.1, memory_size=5, reduction_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1 # Rate to adjust pop size\n        self.exploration_prob = exploration_prob  # Probability of using archive-based exploration\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n        self.memory_size = memory_size  # Size of the memory to store best solutions\n        self.solution_memory = [] # Stores best solutions encountered\n        self.reduction_factor = reduction_factor # Factor to reduce population size\n        self.success_rate = 0.0 # Success rate of the algorithm\n        self.success_history = [] # History of success rates\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        \n        # Select top solutions to create the mutation pool\n        num_elites = max(2, int(0.1 * self.pop_size)) # Minimum 2 elites\n        elite_indices = np.argsort(self.fitness)[:num_elites]\n        elite_pool = self.population[elite_indices]\n        \n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5: # Current-to-best mutation using the elite pool\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(len(elite_pool), 1, replace=False)\n                x_best = elite_pool[idxs[0]]\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (x_best - self.population[i]) + self.F * (x1 - x2)\n            elif np.random.rand() < self.exploration_prob and len(self.archive) > 0:  # Archive-based mutation\n                archive_idx = np.random.randint(len(self.archive))\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.archive[archive_idx] + self.F * (x1 - x2)\n            else: # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n    \n    def stochastic_ranking(self, pop, fitness, func):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        # Constraint violation penalty.  Modify to fit the problem if needed\n        def constraint_violation(x):\n            return 0 # No constraints in the benchmark\n\n        def compare(i, j):\n            fi = fitness[i] + constraint_violation(pop[i])\n            fj = fitness[j] + constraint_violation(pop[j])\n            \n            return fi - fj\n                \n        ranked_indices = sorted(indices, key=lambda k: fitness[k] + constraint_violation(pop[k]))\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i+1]] - dimension_values[sorted_indices[i-1]])\n\n        return distances\n\n    def calculate_diversity(self):\n        \"\"\"Calculates the mean pairwise Euclidean distance in the population.\"\"\"\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(self.population[i] - self.population[j]))\n        return np.mean(distances) if distances else 0\n\n    def update_solution_memory(self, x, f):\n        \"\"\"Updates the solution memory with the current solution if it's better than the worst in memory.\"\"\"\n        if len(self.solution_memory) < self.memory_size:\n            self.solution_memory.append((x.copy(), f))\n            self.solution_memory.sort(key=lambda item: item[1])  # Sort by fitness\n        else:\n            if f < self.solution_memory[-1][1]:\n                self.solution_memory[-1] = (x.copy(), f)\n                self.solution_memory.sort(key=lambda item: item[1])\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        \n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                \n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n                \n                self.update_solution_memory(crossed_population[i], f)\n\n\n                # Archive update using crowding distance\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    archive_distances = self.crowding_distance(np.array(self.archive), np.zeros(len(self.archive))) # Dummy fitness values for crowding distance\n                    min_distance_idx = np.argmin(archive_distances)\n                    self.archive[min_distance_idx] = self.population[i].copy() # Replace least crowded\n        \n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness, func)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n        \n        # Population size adaptation\n        self.success_rate = improved_count / self.pop_size\n        self.success_history.append(self.success_rate)\n        \n        if self.success_rate < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(int(self.pop_size * self.reduction_factor), self.pop_size_min)\n            # Resize population\n            self.population = self.population[:self.pop_size]\n            self.fitness = self.fitness[:self.pop_size]\n        elif self.success_rate > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n           \n        return new_population, new_fitness\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func, diversify=False):\n        # Memory-augmented restart: Re-initialize using best solutions from memory, biased towards better solutions\n        if len(self.solution_memory) > 0:\n            # Sort memory by fitness\n            self.solution_memory.sort(key=lambda item: item[1])\n\n            # Probability proportional to rank\n            probabilities = np.arange(len(self.solution_memory), 0, -1) / np.sum(np.arange(len(self.solution_memory), 0, -1))\n\n            num_to_use_memory = min(len(self.solution_memory), self.pop_size)\n            indices_to_use_memory = np.random.choice(len(self.solution_memory), num_to_use_memory, replace=False, p=probabilities)\n\n            new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim)) # Remaining solutions are random\n\n            for i, idx in enumerate(indices_to_use_memory):\n                new_population[i] = self.solution_memory[idx][0] # Replace initial population with memory solutions\n\n            self.population = new_population\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n\n        else:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n        \n\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n        self.update_solution_memory(self.x_opt, self.f_opt)\n\n\n        while self.budget > self.pop_size: # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                self.update_solution_memory(self.x_opt, self.f_opt)\n            \n            self.best_fitness_history.append(current_best_fitness)\n            \n            if self.check_stagnation():\n                diversity = self.calculate_diversity()\n                if diversity < self.diversity_threshold:\n                    self.restart(func, diversify=True) # Restart and diversify if diversity is low\n                else:\n                    self.restart(func) # Otherwise, just restart\n                self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE_OrthoArchive_Diversity_MemoryRestart_v2 scored 0.455 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d89a4474-d644-4f93-9ac2-15459112e861"], "operator": null, "metadata": {"aucs": [0.21850332781727688, 0.3775010056843948, 0.4235927797264387, 0.5526163103638806, 0.3475270834800539, 0.5113580022251802, 0.33436972621467953, 0.38851641690745087, 0.4175088996539361, 0.3533489702840885, 0.5672907825549263, 0.9974499157798942, 0.3095634877977439, 0.37138385411147323, 0.7385430085540088, 0.5202897348072903, 0.34448381815302465, 0.5990958517067301, 0.2125063898595817, 0.5045698721720557]}}
{"id": "ab6d84c9-dc89-494c-a971-f7d65101e474", "fitness": -Infinity, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced2_NM", "description": "Integrates a Nelder-Mead simplex-based local search and adjusts population diversity based on clustering to enhance exploration-exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced2_NM:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05, ls_prob_initial=0.1, ls_success_threshold=0.2, nm_iterations=5, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.ls_prob = ls_prob_initial # Local search probability\n        self.ls_prob_initial = ls_prob_initial\n        self.ls_success_rate = 0.0\n        self.ls_success_history = []\n        self.ls_history_length = 20\n        self.ls_success_threshold = ls_success_threshold # Threshold for triggering local search\n        self.nm_iterations = nm_iterations\n        self.diversity_threshold = diversity_threshold\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        if np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            print(\"Restarting population.\")\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n        success = False\n\n        def obj_func(x):\n            return func(x)\n\n        bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n\n        result = minimize(obj_func, best_x, method='Nelder-Mead', bounds=bounds, options={'maxiter': self.nm_iterations})\n\n        if self.budget > 0:\n            self.budget -= result.nit  # Account function evals from Nelder-Mead\n\n        if result.fun < best_f:\n            self.population[best_idx] = result.x\n            self.fitness[best_idx] = result.fun\n            success = True\n\n        return success\n\n    def should_trigger_local_search(self):\n        # Check stagnation and success history\n        stagnant = self.check_stagnation()\n        sufficient_success = self.ls_success_rate > self.ls_success_threshold\n        return stagnant or sufficient_success\n        \n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            # Adaptive local search application\n            if self.should_trigger_local_search():\n                success = self.local_search(func)\n                self.ls_success_history.append(int(success))\n\n                if len(self.ls_success_history) > self.ls_history_length:\n                    self.ls_success_history.pop(0)\n\n                self.ls_success_rate = np.mean(self.ls_success_history)\n                # Adapt local search probability\n                if self.ls_success_rate > 0.4:\n                    self.ls_prob = min(1.0, self.ls_prob * 1.1)\n                else:\n                    self.ls_prob = max(0.01, self.ls_prob * 0.9)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = 0.1 # Reset radius\n                    self.ls_prob = self.ls_prob_initial # Reset ls_prob\n        \n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 263, in __call__\n  File \"<string>\", line 199, in local_search\nNameError: name 'minimize' is not defined\n.", "error": "", "parent_ids": ["c91c478b-c7fd-4a8c-8b58-da97b05fc99f"], "operator": null, "metadata": {}}
{"id": "81eca8d1-35e0-4c9c-8072-afe8cd321953", "fitness": -Infinity, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced3", "description": "Implements a success-history based adaptive local search with a more sophisticated radius and direction adaptation, alongside improved population diversity maintenance using CMA-ES sampling for restarts and orthogonal design for initialization.", "code": "import numpy as np\nimport cma\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced3:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius_initial=0.1, local_search_radius_decay=0.95, restart_probability=0.05, ls_prob_initial=0.1, ls_success_threshold=0.2, ls_radius_success_decay = 0.8, ls_radius_failure_growth = 1.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius_initial\n        self.local_search_radius_initial = local_search_radius_initial\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.ls_prob = ls_prob_initial # Local search probability\n        self.ls_prob_initial = ls_prob_initial\n        self.ls_success_rate = 0.0\n        self.ls_success_history = []\n        self.ls_history_length = 20\n        self.ls_success_threshold = ls_success_threshold # Threshold for triggering local search\n        self.ls_radius_success_decay = ls_radius_success_decay\n        self.ls_radius_failure_growth = ls_radius_failure_growth\n\n    def initialize_population(self, func):\n        # Use orthogonal design for initial population\n        from scipy.stats import qmc\n        engine = qmc.Orthogonal(d=self.dim)\n        samples = qmc.scale(engine.random(self.pop_size), func.bounds.lb, func.bounds.ub)\n        self.population = samples\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        if np.random.rand() < self.restart_probability:\n            # Use CMA-ES sampling for restart\n            es = cma.CMAEvolutionStrategy(self.x_opt, 1.0, {'popsize': self.pop_size})\n            new_population = es.ask()\n            new_population = self.handle_bounds(new_population, func)\n            self.population = new_population\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            print(\"Restarting population with CMA-ES.\")\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n        success = False\n\n        for _ in range(self.dim * 2): # Budget conscious local search\n            if self.budget <= 0:\n                break\n\n            # Adaptive direction sampling: prioritize promising directions\n            if success: # Continue exploitation along the same direction if successful\n                direction = self.last_direction\n            else:\n                direction = np.random.uniform(-1, 1, size=self.dim)\n                direction = direction / np.linalg.norm(direction)  # Normalize\n\n            new_x = best_x + self.local_search_radius * direction\n            new_x = self.handle_bounds(new_x[None, :], func)[0] # Handle bounds for single vector\n\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n                success = True\n                self.last_direction = direction # Store direction\n            else:\n                success = False\n\n        if success:\n             self.local_search_radius *= self.ls_radius_success_decay\n        else:\n            self.local_search_radius *= self.ls_radius_failure_growth\n\n        self.local_search_radius = min(max(self.local_search_radius, self.local_search_radius_initial/100), self.local_search_radius_initial)\n\n        return success\n\n    def should_trigger_local_search(self):\n        # Check stagnation and success history\n        stagnant = self.check_stagnation()\n        sufficient_success = self.ls_success_rate > self.ls_success_threshold\n        return stagnant or sufficient_success\n        \n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            # Adaptive local search application\n            if self.should_trigger_local_search():\n                success = self.local_search(func)\n                self.ls_success_history.append(int(success))\n\n                if len(self.ls_success_history) > self.ls_history_length:\n                    self.ls_success_history.pop(0)\n\n                self.ls_success_rate = np.mean(self.ls_success_history)\n                # Adapt local search probability\n                if self.ls_success_rate > 0.4:\n                    self.ls_prob = min(1.0, self.ls_prob * 1.1)\n                else:\n                    self.ls_prob = max(0.01, self.ls_prob * 0.9)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = self.local_search_radius_initial # Reset radius\n                    self.ls_prob = self.ls_prob_initial # Reset ls_prob\n        \n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 111, in evaluate\n    exec(code, safe_globals, local_env)\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'cma'\n.", "error": "", "parent_ids": ["c91c478b-c7fd-4a8c-8b58-da97b05fc99f"], "operator": null, "metadata": {}}
{"id": "a35316ab-e4a2-4040-8f97-4adf18a73807", "fitness": -Infinity, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced_v3", "description": "Integrates a more robust success-history adaptation for F and CR with exponential smoothing, a landscape-aware Cauchy mutation for enhanced exploration, and adaptive local search refinement with radius and step-size control.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced_v3:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.2, CR_learning_rate=0.2, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05, restart_fitness_variance_threshold=1e-6, angle_threshold=0.9, cauchy_mutation_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_EMA = F_initial # Exponential Moving Average for F\n        self.CR_EMA = CR_initial # Exponential Moving Average for CR\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.restart_fitness_variance_threshold = restart_fitness_variance_threshold\n        self.budget_consumed_threshold = 0.75 # Restart if budget consumed above threshold.\n        self.best_fitness_since_restart = np.inf\n        self.angle_threshold = angle_threshold # Cosine of angle above which restart is considered\n        self.previous_step = None\n        self.cauchy_mutation_prob = cauchy_mutation_prob\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n        self.best_fitness_since_restart = np.min(self.fitness)\n        self.previous_step = None\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n                \n            if np.random.rand() < self.cauchy_mutation_prob: # Cauchy Mutation\n                scale = 0.1 * (func.bounds.ub - func.bounds.lb)\n                cauchy_values = np.random.standard_cauchy(size=self.dim) * scale\n                mutated_population[i] += cauchy_values\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR using EMA\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n            \n            self.F_EMA = (1 - self.F_learning_rate) * self.F_EMA + self.F_learning_rate * mean_F\n            self.CR_EMA = (1 - self.CR_learning_rate) * self.CR_EMA + self.CR_learning_rate * mean_CR\n            \n            self.F = self.F_EMA\n            self.CR = self.CR_EMA\n            \n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        # Restart if fitness variance is low or budget consumption is high, or angle between steps is high, but only if there's been no recent improvement.\n        budget_consumed = 1 - (self.budget / 10000)\n        fitness_variance_low = len(self.best_fitness_history) >= self.stagnation_threshold and np.std(self.best_fitness_history[-self.stagnation_threshold:]) < self.restart_fitness_variance_threshold\n        budget_exceeded_threshold = budget_consumed > self.budget_consumed_threshold\n\n        no_recent_improvement = self.f_opt >= self.best_fitness_since_restart\n\n        # Check angle between previous and current steps\n        if self.previous_step is not None:\n            current_step = self.x_opt - self.population[np.argmin(self.fitness)]\n            cos_angle = np.dot(self.previous_step, current_step) / (np.linalg.norm(self.previous_step) * np.linalg.norm(current_step) + 1e-8)  # Adding small value to avoid division by zero\n            similar_direction = cos_angle > self.angle_threshold\n        else:\n            similar_direction = False\n            cos_angle = 0.0\n\n        if (fitness_variance_low or budget_exceeded_threshold or similar_direction) and no_recent_improvement and np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            self.best_fitness_since_restart = np.min(self.fitness)\n            self.previous_step = None\n\n            print(f\"Restarting population. Budget consumed: {budget_consumed:.2f}, Fitness Variance: {np.std(self.best_fitness_history[-self.stagnation_threshold:]) if len(self.best_fitness_history) >= self.stagnation_threshold else 'N/A'}, Cosine Angle: {cos_angle:.2f}\")\n\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n        original_radius = self.local_search_radius\n\n        # Aggressive local search: adapt radius based on success\n        success_count = 0\n        num_iterations = self.dim * 4 #Increased iterations\n        \n        step_size = self.local_search_radius / 5.0 # Introduce a step size\n        \n        for _ in range(num_iterations):\n            if self.budget <= 0:\n                break\n\n            direction = np.random.uniform(-1, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)  # Normalize\n\n            new_x = best_x + step_size * direction  # Use step size\n            new_x = self.handle_bounds(new_x[None, :], func)[0] # Handle bounds for single vector\n\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n                success_count += 1\n                self.local_search_radius *= 1.05  # Slightly increase radius if successful\n                step_size *= 1.05 # Increase step size too\n\n            else:\n                self.local_search_radius *= 0.95 # Reduce radius if unsuccessful\n                step_size *= 0.95 # Reduce step size too\n\n            self.local_search_radius = min(self.local_search_radius, original_radius * 2) # Radius cap\n            step_size = min(step_size, self.local_search_radius / 5.0) # Step size cap\n\n        if success_count == 0:\n            self.local_search_radius = original_radius * self.local_search_radius_decay\n        else:\n            self.local_search_radius = original_radius * (1 + (success_count / num_iterations) * (1 - self.local_search_radius_decay))\n            self.local_search_radius = min(self.local_search_radius, 0.1)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            current_best_x = self.population[np.argmin(self.fitness)]\n            if current_best_fitness < self.f_opt:\n                self.previous_step = self.x_opt - current_best_x # Save step\n                self.f_opt = current_best_fitness\n                self.x_opt = current_best_x\n                self.best_fitness_since_restart = self.f_opt # Update best fitness since last restart\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            if self.generation % self.local_search_frequency == 0:\n                self.local_search(func)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = 0.1 # Reset radius\n        \n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 269, in __call__\n  File \"<string>\", line 63, in mutate\nNameError: name 'func' is not defined\n.", "error": "", "parent_ids": ["8af6e6db-f4d4-415c-9ad0-44cec78d3d7a"], "operator": null, "metadata": {}}
{"id": "64bc71ab-e65d-4ec8-a416-6ea95d40ea3c", "fitness": -Infinity, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_Reinforcement", "description": "Integrates a novel landscape-aware mutation strategy, adaptive population diversity control using clustering, and a reinforcement-learning-based local search with dynamic radius adaptation to balance exploration and exploitation effectively.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_Reinforcement:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05, ls_prob_initial=0.1, ls_radius_min=0.001, diversity_threshold=0.2, ls_reward_decay=0.9, ls_success_reward=1.0, ls_failure_penalty=-0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.ls_prob = ls_prob_initial # Local search probability\n        self.ls_prob_initial = ls_prob_initial\n        self.ls_success_rate = 0.0\n        self.ls_success_history = []\n        self.ls_history_length = 20\n        self.ls_radius_min = ls_radius_min\n        self.diversity_threshold = diversity_threshold\n        self.ls_reward = 0.0 # Reinforcement learning reward for local search\n        self.ls_reward_decay = ls_reward_decay\n        self.ls_success_reward = ls_success_reward\n        self.ls_failure_penalty = ls_failure_penalty\n        self.landscape_awareness = 0.0 # Track the correlation between step size and fitness improvement.\n        self.landscape_history_length = 20\n        self.landscape_history = []\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Landscape-aware mutation: Adapt mutation strength based on recent performance\n            F_adaptive = self.F * (1 + self.landscape_awareness)\n            F_adaptive = np.clip(F_adaptive, 0.1, 1.0)\n\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + F_adaptive * (self.population[best_idx] - self.population[i]) + F_adaptive * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + F_adaptive * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + F_adaptive * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n        step_sizes = []\n        fitness_improvements = []\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                step_size = np.linalg.norm(crossed_population[i] - self.population[i])\n                fitness_improvement = self.fitness[i] - f\n                step_sizes.append(step_size)\n                fitness_improvements.append(fitness_improvement)\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        # Update landscape awareness\n        if step_sizes and fitness_improvements:\n            correlation = np.corrcoef(step_sizes, fitness_improvements)[0, 1]\n            self.landscape_history.append(correlation)\n            if len(self.landscape_history) > self.landscape_history_length:\n                self.landscape_history.pop(0)\n            self.landscape_awareness = np.mean(self.landscape_history)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation based on success rate and remaining budget\n        improvement_ratio = improved_count / self.pop_size\n        budget_ratio = self.budget / 10000  # Assuming initial budget is 10000\n\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max and budget_ratio > 0.2:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        # Diversity control using clustering\n        if self.generation % 5 == 0:\n            kmeans = KMeans(n_clusters=int(self.pop_size * self.diversity_threshold), random_state=0, n_init=10)\n            clusters = kmeans.fit_predict(self.population)\n            cluster_sizes = np.bincount(clusters)\n            small_clusters = np.where(cluster_sizes < self.dim)[0] # Target small clusters\n            for cluster_id in small_clusters:\n                cluster_indices = np.where(clusters == cluster_id)[0]\n                for idx in cluster_indices:\n                    self.population[idx] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    f = func(self.population[idx])\n                    self.budget -= 1\n                    new_fitness[idx] = f\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        if np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            print(\"Restarting population.\")\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n        success = False\n        num_trials = 0\n        initial_radius = self.local_search_radius\n\n        while num_trials < self.dim * 2: # Budget conscious local search\n            if self.budget <= 0 or self.local_search_radius < self.ls_radius_min:\n                break\n\n            direction = np.random.uniform(-1, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)  # Normalize\n\n            new_x = best_x + self.local_search_radius * direction\n            new_x = self.handle_bounds(new_x[None, :], func)[0] # Handle bounds for single vector\n\n            new_f = func(new_x)\n            self.budget -= 1\n            num_trials += 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n                success = True\n                num_trials = 0 # Reset trials if improvement is found\n                self.ls_reward = self.ls_reward_decay * self.ls_reward + self.ls_success_reward # Update reward\n            else:\n                self.ls_reward = self.ls_reward_decay * self.ls_reward + self.ls_failure_penalty # Update reward\n\n        # Radius adaptation based on reward\n        if self.ls_reward > 0.2:\n            self.local_search_radius = min(initial_radius * 2, 0.5) # Increase radius if successful\n        else:\n            self.local_search_radius = max(self.local_search_radius * self.local_search_radius_decay, self.ls_radius_min) # Decrease radius if unsuccessful\n\n        return success\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            # Adaptive local search application\n            if np.random.rand() < self.ls_prob:\n                success = self.local_search(func)\n                self.ls_success_history.append(int(success))\n\n                if len(self.ls_success_history) > self.ls_history_length:\n                    self.ls_success_history.pop(0)\n\n                self.ls_success_rate = np.mean(self.ls_success_history)\n                # Adapt local search probability based on reward\n                self.ls_prob = np.clip(self.ls_prob + 0.1 * self.ls_reward, 0.01, 1.0)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = 0.1 # Reset radius\n                    self.ls_prob = self.ls_prob_initial # Reset ls_prob\n\n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/neocortex/repos/BLADE/blade/problem.py\", line 40, in __call__\n    solution = self.evaluate(solution)\n  File \"/home/neocortex/repos/BLADE/blade/problems/mabbob.py\", line 144, in evaluate\n    algorithm(f_new)\n  File \"<string>\", line 280, in __call__\n  File \"<string>\", line 183, in select\nNameError: name 'KMeans' is not defined\n.", "error": "", "parent_ids": ["2e3617ec-759f-4b1e-85ff-d0065a4d7a4e"], "operator": null, "metadata": {}}
{"id": "7e318ca5-f05e-469f-b7a8-1572a9243657", "fitness": 0.0, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_Improved_v2", "description": "Enhances exploration and exploitation by integrating a fitness-based population splitting strategy with dynamic sub-population F/CR adaptation, and combines it with orthogonal design, archiving, and adaptive local search for efficient black-box optimization.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_Improved_v2:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05, ls_prob_initial=0.1, ls_radius_min=0.001, num_sub_populations=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.ls_prob = ls_prob_initial # Local search probability\n        self.ls_prob_initial = ls_prob_initial\n        self.ls_success_rate = 0.0\n        self.ls_success_history = []\n        self.ls_history_length = 20\n        self.ls_radius_min = ls_radius_min\n        self.num_sub_populations = num_sub_populations\n        self.sub_populations = []\n        self.sub_fitness = []\n        self.sub_F = [F_initial] * self.num_sub_populations\n        self.sub_CR = [CR_initial] * self.num_sub_populations\n        self.sub_successful_F = [[] for _ in range(self.num_sub_populations)]\n        self.sub_successful_CR = [[] for _ in range(self.num_sub_populations)]\n        self.sub_F_momentum = [0.0] * self.num_sub_populations\n        self.sub_CR_momentum = [0.0] * self.num_sub_populations\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n        # Split population into sub-populations based on fitness\n        sorted_indices = np.argsort(self.fitness)\n        sub_pop_size = self.pop_size // self.num_sub_populations\n        self.sub_populations = []\n        self.sub_fitness = []\n        for i in range(self.num_sub_populations):\n            start_idx = i * sub_pop_size\n            end_idx = (i + 1) * sub_pop_size if i < self.num_sub_populations - 1 else self.pop_size\n            self.sub_populations.append(self.population[sorted_indices[start_idx:end_idx]])\n            self.sub_fitness.append(self.fitness[sorted_indices[start_idx:end_idx]])\n\n    def mutate(self, sub_pop, F):\n        mutated_population = np.zeros_like(sub_pop)\n        pop_size = len(sub_pop)\n        for i in range(pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.sub_fitness[self.current_sub_pop_idx])\n                idxs = np.random.choice(pop_size, 2, replace=False)\n                x1, x2 = sub_pop[idxs]\n                mutated_population[i] = sub_pop[i] + F * (sub_pop[best_idx] - sub_pop[i]) + F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(pop_size, 3, replace=False)\n                x1, x2, x3 = sub_pop[idxs]\n                mutated_population[i] = x1 + F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(pop_size, 2, replace=False)\n            x1, x2 = sub_pop[idxs]\n            mutated_population[np.random.randint(pop_size)] = archived_vector + F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population, CR, sub_pop):\n        crossed_population = np.zeros_like(mutated_population)\n        pop_size = len(sub_pop)\n        for i in range(pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = sub_pop[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population, sub_pop, sub_fitness, sub_idx):\n        pop_size = len(sub_pop)\n        new_population = np.copy(sub_pop)\n        new_fitness = np.copy(sub_fitness)\n\n        improved_count = 0\n\n        for i in range(pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < sub_fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.sub_successful_F[sub_idx].append(self.sub_F[sub_idx])\n                self.sub_successful_CR[sub_idx].append(self.sub_CR[sub_idx])\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n        return new_population, new_fitness, improved_count\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        if np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            print(\"Restarting population.\")\n            self.initialize_population(func)\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n        success = False\n        num_trials = 0\n\n        while num_trials < self.dim * 2: # Budget conscious local search\n            if self.budget <= 0 or self.local_search_radius < self.ls_radius_min:\n                break\n\n            direction = np.random.uniform(-1, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)  # Normalize\n\n            new_x = best_x + self.local_search_radius * direction\n            new_x = self.handle_bounds(new_x[None, :], func)[0] # Handle bounds for single vector\n\n            new_f = func(new_x)\n            self.budget -= 1\n            num_trials += 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n                success = True\n                num_trials = 0 # Reset trials if improvement is found\n\n        if self.local_search_radius > self.ls_radius_min:\n            self.local_search_radius *= self.local_search_radius_decay # Reduce radius\n        return success\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size // self.num_sub_populations:  # Ensure enough budget for sub-population updates\n            for sub_idx in range(self.num_sub_populations):\n                self.current_sub_pop_idx = sub_idx\n                sub_pop = self.sub_populations[sub_idx]\n                sub_fitness = self.sub_fitness[sub_idx]\n\n                mutated_population = self.mutate(sub_pop, self.sub_F[sub_idx])\n                crossed_population = self.crossover(mutated_population, self.sub_CR[sub_idx], sub_pop)\n                crossed_population = self.handle_bounds(crossed_population, func)\n                new_sub_pop, new_sub_fitness, improved_count = self.select(func, crossed_population, sub_pop, sub_fitness, sub_idx)\n\n                self.sub_populations[sub_idx] = new_sub_pop\n                self.sub_fitness[sub_idx] = new_sub_fitness\n                \n                # Update F and CR for the sub-population with momentum\n                if self.sub_successful_F[sub_idx]:\n                    mean_F = np.mean(self.sub_successful_F[sub_idx])\n                    mean_CR = np.mean(self.sub_successful_CR[sub_idx])\n\n                    self.sub_F_momentum[sub_idx] = self.momentum_coeff * self.sub_F_momentum[sub_idx] + (1 - self.momentum_coeff) * mean_F\n                    self.sub_CR_momentum[sub_idx] = self.momentum_coeff * self.sub_CR_momentum[sub_idx] + (1 - self.momentum_coeff) * mean_CR\n\n                    self.sub_F[sub_idx] = (1 - self.F_learning_rate) * self.sub_F[sub_idx] + self.F_learning_rate * self.sub_F_momentum[sub_idx]\n                    self.sub_CR[sub_idx] = (1 - self.CR_learning_rate) * self.sub_CR[sub_idx] + self.CR_learning_rate * self.sub_CR_momentum[sub_idx]\n\n                self.sub_successful_F[sub_idx] = []\n                self.sub_successful_CR[sub_idx] = []\n\n            # Combine sub-populations\n            self.population = np.concatenate(self.sub_populations)\n            self.fitness = np.concatenate(self.sub_fitness)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            # Adaptive local search application\n            if np.random.rand() < self.ls_prob:\n                success = self.local_search(func)\n                self.ls_success_history.append(int(success))\n\n                if len(self.ls_success_history) > self.ls_history_length:\n                    self.ls_success_history.pop(0)\n\n                self.ls_success_rate = np.mean(self.ls_success_history)\n                # Adapt local search probability\n                if self.ls_success_rate > 0.4:\n                    self.ls_prob = min(1.0, self.ls_prob * 1.1)\n                else:\n                    self.ls_prob = max(0.01, self.ls_prob * 0.9)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = 0.1 # Reset radius\n                    self.ls_prob = self.ls_prob_initial # Reset ls_prob\n\n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch_Improved_v2 scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2e3617ec-759f-4b1e-85ff-d0065a4d7a4e"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "cbb45cea-5ba6-4d46-92c1-edc6633d6459", "fitness": 0.5145839631577028, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_Gradient", "description": "Enhanced Adaptive Differential Evolution with orthogonal crossover, archive, adaptive local search radius, adaptive F/CR with a memory-based adaptation, landscape-aware population resizing, and gradient-based local search to refine solutions using estimated gradients for improved exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_Gradient:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05, restart_fitness_variance_threshold=1e-6, angle_threshold=0.9, memory_size=10, gradient_estimation_steps=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max\n        self.archive_size = archive_size\n        self.F = F_initial\n        self.CR = CR_initial\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_memory = np.full(memory_size, F_initial)\n        self.CR_memory = np.full(memory_size, CR_initial)\n        self.memory_index = 0\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size\n        self.pop_size_adaptation_rate = 0.1\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.restart_fitness_variance_threshold = restart_fitness_variance_threshold\n        self.budget_consumed_threshold = 0.75\n        self.best_fitness_since_restart = np.inf\n        self.angle_threshold = angle_threshold\n        self.previous_step = None\n        self.gradient_estimation_steps = gradient_estimation_steps\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n        self.best_fitness_since_restart = np.min(self.fitness)\n        self.previous_step = None\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        if self.successful_F:\n            self.F_memory[self.memory_index] = np.mean(self.successful_F)\n            self.CR_memory[self.memory_index] = np.mean(self.successful_CR)\n            self.memory_index = (self.memory_index + 1) % len(self.F_memory)\n\n            self.F = np.mean(self.F_memory)\n            self.CR = np.mean(self.CR_memory)\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        budget_consumed = 1 - (self.budget / 10000)\n        fitness_variance_low = len(self.best_fitness_history) >= self.stagnation_threshold and np.std(self.best_fitness_history[-self.stagnation_threshold:]) < self.restart_fitness_variance_threshold\n        budget_exceeded_threshold = budget_consumed > self.budget_consumed_threshold\n\n        no_recent_improvement = self.f_opt >= self.best_fitness_since_restart\n\n        if self.previous_step is not None:\n            current_step = self.x_opt - self.population[np.argmin(self.fitness)]\n            cos_angle = np.dot(self.previous_step, current_step) / (np.linalg.norm(self.previous_step) * np.linalg.norm(current_step) + 1e-8)\n            similar_direction = cos_angle > self.angle_threshold\n        else:\n            similar_direction = False\n            cos_angle = 0.0\n\n        if (fitness_variance_low or budget_exceeded_threshold or similar_direction) and no_recent_improvement and np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0\n            self.best_fitness_history = []\n            self.best_fitness_since_restart = np.min(self.fitness)\n            self.previous_step = None\n\n            print(f\"Restarting population. Budget consumed: {budget_consumed:.2f}, Fitness Variance: {np.std(self.best_fitness_history[-self.stagnation_threshold:]) if len(self.best_fitness_history) >= self.stagnation_threshold else 'N/A'}, Cosine Angle: {cos_angle:.2f}\")\n\n            return True\n        return False\n\n    def estimate_gradient(self, func, x, delta=1e-3):\n        gradient = np.zeros(self.dim)\n        for i in range(self.dim):\n            x_plus = x.copy()\n            x_minus = x.copy()\n            x_plus[i] += delta\n            x_minus[i] -= delta\n            x_plus = self.handle_bounds(x_plus[None, :], func)[0]\n            x_minus = self.handle_bounds(x_minus[None, :], func)[0]\n            \n            f_plus = func(x_plus)\n            self.budget -= 1\n            f_minus = func(x_minus)\n            self.budget -= 1\n\n            gradient[i] = (f_plus - f_minus) / (2 * delta)\n            \n            if self.budget <= 0:\n                break\n\n        return gradient\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n        original_radius = self.local_search_radius\n\n        gradient = self.estimate_gradient(func, best_x)\n        if self.budget <= 0:\n            return\n        \n        norm_gradient = np.linalg.norm(gradient)\n        if norm_gradient > 0:\n             direction = -gradient / norm_gradient\n        else:\n             direction = np.random.uniform(-1, 1, size=self.dim)\n             direction = direction / np.linalg.norm(direction)\n        \n\n        success_count = 0\n        num_iterations = self.gradient_estimation_steps * self.dim\n        for _ in range(num_iterations):\n            if self.budget <= 0:\n                break\n\n            new_x = best_x + self.local_search_radius * direction\n            new_x = self.handle_bounds(new_x[None, :], func)[0]\n\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n                success_count += 1\n                self.local_search_radius *= 1.1\n            else:\n                self.local_search_radius *= 0.9\n\n            self.local_search_radius = min(self.local_search_radius, original_radius * 2)\n\n        if success_count == 0:\n            self.local_search_radius = original_radius * self.local_search_radius_decay\n        else:\n            self.local_search_radius = original_radius * (1 + (success_count / num_iterations) * (1 - self.local_search_radius_decay))\n            self.local_search_radius = min(self.local_search_radius, 0.1)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size + 2*self.dim*self.gradient_estimation_steps:\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            current_best_x = self.population[np.argmin(self.fitness)]\n            if current_best_fitness < self.f_opt:\n                self.previous_step = self.x_opt - current_best_x\n                self.f_opt = current_best_fitness\n                self.x_opt = current_best_x\n                self.best_fitness_since_restart = self.f_opt\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            if self.generation % self.local_search_frequency == 0:\n                self.local_search(func)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = 0.1\n\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch_Gradient scored 0.515 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8af6e6db-f4d4-415c-9ad0-44cec78d3d7a"], "operator": null, "metadata": {"aucs": [0.20304341872046394, 0.4574820808811977, 0.4849336601610257, 0.7447598830650228, 0.48319399928227835, 0.5784011512152002, 0.35219536982447475, 0.44953561780829754, 0.4938122049222857, 0.37674643904699723, 0.645904444555484, 0.9869406731103861, 0.3694597820805773, 0.44282159730207726, 0.8279450020221022, 0.5747525910123207, 0.40169924420538194, 0.6762715084887134, 0.24210827209109653, 0.49967232335867307]}}
{"id": "c7d7b450-a7d8-42de-9134-6fc6fdccb1c1", "fitness": 0.48468651155688214, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_v4", "description": "Dynamically adjusts population size and local search radius based on success rate, incorporating a diversity-promoting selection mechanism and an enhanced archive update strategy.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_v4:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, lars_tolerance=1e-5, local_search_radius=0.1, local_search_frequency=10, cr_adaptation_rate=0.1, diversity_selection_rate=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.lars_tolerance = lars_tolerance\n        self.local_search_radius = local_search_radius  # Initial local search radius\n        self.local_search_frequency = local_search_frequency # How often to perform local search\n        self.cr_adaptation_rate = cr_adaptation_rate\n        self.cr_success_rate = 0.5\n        self.cr_success_history = []\n        self.diversity_selection_rate = diversity_selection_rate\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i + 1]] - dimension_values[sorted_indices[i - 1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                self.cr_success_history.append(1)\n            else:\n                self.cr_success_history.append(0)\n                \n            self.successful_F.append(self.F)\n            self.successful_CR.append(self.CR)\n\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Diversity Selection: Select a portion of the population based on crowding distance\n        if self.diversity_selection_rate > 0:\n            num_diversity = int(self.diversity_selection_rate * self.pop_size)\n            distances = self.crowding_distance(new_population, new_fitness)\n            diversity_indices = np.argsort(distances)[-num_diversity:]  # Select individuals with highest crowding distance\n\n            # Replace worst individuals with diverse individuals\n            worst_indices = np.argsort(new_fitness)[-num_diversity:]\n\n            for k in range(num_diversity):\n                new_population[worst_indices[k]] = new_population[diversity_indices[k]]\n                new_fitness[worst_indices[k]] = func(new_population[diversity_indices[k]]) # Evaluate new individual\n                self.budget -=1 # Update budget\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = np.clip((1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum, 0.1, 0.9) # Clip F\n            #self.CR = np.clip((1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum, 0.1, 0.9) # Clip CR\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation based on landscape awareness and budget\n        if self.generation > 50:\n            fitness_std = np.std(self.fitness)\n            if fitness_std < self.lars_tolerance and self.pop_size > self.pop_size_min:\n                self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n            elif fitness_std > self.lars_tolerance and self.pop_size < self.pop_size_max and self.budget > self.pop_size_max:\n                self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n                \n                # Add new random individuals if population grows\n                num_new = self.pop_size - len(new_population)\n                if num_new > 0:\n                    new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new, self.dim))\n                    new_fitness_values = [func(x) for x in new_individuals]\n                    self.budget -= num_new\n                    new_population = np.concatenate((new_population, new_individuals))\n                    new_fitness = np.concatenate((new_fitness, new_fitness_values))\n\n        # Update CR based on success rate\n        if self.cr_success_history:\n            success_rate = np.mean(self.cr_success_history)\n            self.cr_success_rate = (1 - self.cr_adaptation_rate) * self.cr_success_rate + self.cr_adaptation_rate * success_rate\n            self.CR = np.clip(self.cr_success_rate, 0.1, 0.9)\n            self.cr_success_history = []\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Rank based on fitness only for archive selection\n        ranked_indices = np.argsort(combined_fitness)\n        combined_population = combined_population[ranked_indices]\n        combined_fitness = combined_fitness[ranked_indices]\n\n        # Select top archive_size individuals + some random individuals to promote diversity\n        num_elite = int(0.8 * self.archive_size)  # Keep top 80%\n        elite_indices = np.arange(num_elite)\n        remaining_indices = np.arange(len(combined_population))\n        remaining_indices = np.setdiff1d(remaining_indices, elite_indices)  # Exclude elite indices\n        \n        if len(remaining_indices) > 0:  # Ensure there are remaining individuals to choose from\n            num_random = min(self.archive_size - num_elite, len(remaining_indices))  # Ensure we don't try to select more than available\n            random_indices = np.random.choice(remaining_indices, num_random, replace=False)\n            selected_indices = np.concatenate((elite_indices, random_indices))\n        else:\n            selected_indices = elite_indices  # If no remaining individuals, only select elite\n\n        np.random.shuffle(selected_indices)  # Shuffle to mix elite and random\n        self.archive = list(combined_population[selected_indices])\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n        self.local_search_radius = 0.1 # Reset the local search radius\n\n    def local_search(self, func, x_opt):\n        # Perform local search around the best solution\n        num_evals = min(self.pop_size, self.budget) # Adaptive local evals depending on budget\n        \n        # Adapt local search radius based on recent success\n        if len(self.best_fitness_history) > 10:\n            improvement = self.best_fitness_history[-11] - self.best_fitness_history[-1]\n            if improvement > 0:\n                self.local_search_radius *= 1.1  # Increase radius if improvement\n            else:\n                self.local_search_radius *= 0.9  # Decrease if no improvement\n            self.local_search_radius = np.clip(self.local_search_radius, 1e-6, 0.5)  # Keep within bounds\n\n        for _ in range(num_evals):\n            # Generate a random perturbation within the radius\n            perturbation = np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            x_neighbor = x_opt + perturbation\n            x_neighbor = self.handle_bounds(np.array([x_neighbor]), func)[0] # Keep within bounds\n\n            f_neighbor = func(x_neighbor)\n            self.budget -= 1\n\n            if f_neighbor < self.f_opt:\n                self.f_opt = f_neighbor\n                self.x_opt = x_neighbor\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            # Adjust local search frequency based on stagnation and fitness variance\n            if self.check_stagnation() or (self.generation % self.local_search_frequency == 0 and np.std(self.best_fitness_history[-min(self.stagnation_threshold, len(self.best_fitness_history)):]) < self.lars_tolerance):\n                self.local_search(func, self.x_opt)\n                if self.check_stagnation():\n                    self.restart(func)\n                    self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n\n\n        # Final local search at the end\n        if self.budget > 0:\n            self.local_search(func, self.x_opt)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch_v4 scored 0.485 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3f00959d-88bb-488f-b079-4479194dcf50"], "operator": null, "metadata": {"aucs": [0.17949259669067763, 0.3065546915459968, 0.456956772165532, 0.655123605563219, 0.4078643280810188, 0.6261051615700498, 0.3481480428834557, 0.4176304893967733, 0.4659143869614685, 0.23459492707461904, 0.6313908634172662, 0.9871144859078811, 0.3098787254467479, 0.3858005962066402, 0.7975719087470899, 0.6460554687423408, 0.3855480947358063, 0.6918756929841638, 0.26572377783141654, 0.4943856151854791]}}
{"id": "7ef2d674-eb3a-438c-b8dc-6b164188ba7f", "fitness": 0.4493296733452133, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_CMAES", "description": "Integrates a self-adaptive covariance matrix adaptation evolution strategy (sa-CMA-ES) inspired mutation operator to better adapt to the problem landscape and improve search efficiency.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05, ls_prob_initial=0.1, ls_success_threshold=0.2, cmaes_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.ls_prob = ls_prob_initial # Local search probability\n        self.ls_prob_initial = ls_prob_initial\n        self.ls_success_rate = 0.0\n        self.ls_success_history = []\n        self.ls_history_length = 20\n        self.ls_success_threshold = ls_success_threshold # Threshold for triggering local search\n\n        # CMA-ES parameters\n        self.cmaes_learning_rate = cmaes_learning_rate\n        self.mean = None  # Mean of the search distribution\n        self.covariance = None  # Covariance matrix\n        self.step_size = 0.1  # Overall step size\n        self.c_sigma = 0.3  # Learning rate for step size\n        self.d_sigma = 1.0  # Damping factor for step size\n        self.c_cov = 0.1 # Learning rate for covariance matrix\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.covariance = np.eye(self.dim)  # Identity matrix as initial covariance\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # CMA-ES inspired mutation\n            z = np.random.randn(self.dim)  # Sample from standard normal distribution\n            mutated_population[i] = self.mean + self.step_size * np.dot(np.linalg.cholesky(self.covariance), z)\n\n            # Original DE mutation (less frequent, for diversity)\n            if np.random.rand() < 0.1: # Reduced frequency\n                if np.random.rand() < 0.5:  # Current-to-best mutation\n                    best_idx = np.argmin(self.fitness)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x1, x2 = self.population[idxs]\n                    mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n                else:  # Random mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        # CMA-ES parameter update\n        diff = new_population[np.argmin(new_fitness)] - self.mean\n        self.mean = (1 - self.cmaes_learning_rate) * self.mean + self.cmaes_learning_rate * new_population[np.argmin(new_fitness)]\n        self.covariance = (1 - self.c_cov) * self.covariance + self.c_cov * (np.outer(diff, diff) / (self.step_size**2))\n        self.step_size *= np.exp(self.c_sigma / self.d_sigma * (np.linalg.norm(diff) / self.step_size - 1))\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        if np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            print(\"Restarting population.\")\n\n            # Re-initialize CMA-ES parameters\n            self.mean = np.mean(self.population, axis=0)\n            self.covariance = np.eye(self.dim)\n            self.step_size = 0.1\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n        success = False\n\n        for _ in range(self.dim * 2): # Budget conscious local search\n            if self.budget <= 0:\n                break\n\n            direction = np.random.uniform(-1, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)  # Normalize\n\n            new_x = best_x + self.local_search_radius * direction\n            new_x = self.handle_bounds(new_x[None, :], func)[0] # Handle bounds for single vector\n\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n                success = True\n\n        self.local_search_radius *= self.local_search_radius_decay # Reduce radius\n        return success\n\n    def should_trigger_local_search(self):\n        # Check stagnation and success history\n        stagnant = self.check_stagnation()\n        sufficient_success = self.ls_success_rate > self.ls_success_threshold\n        return stagnant or sufficient_success\n        \n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            # Adaptive local search application\n            if self.should_trigger_local_search():\n                success = self.local_search(func)\n                self.ls_success_history.append(int(success))\n\n                if len(self.ls_success_history) > self.ls_history_length:\n                    self.ls_success_history.pop(0)\n\n                self.ls_success_rate = np.mean(self.ls_success_history)\n                # Adapt local search probability\n                if self.ls_success_rate > 0.4:\n                    self.ls_prob = min(1.0, self.ls_prob * 1.1)\n                else:\n                    self.ls_prob = max(0.01, self.ls_prob * 0.9)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = 0.1 # Reset radius\n                    self.ls_prob = self.ls_prob_initial # Reset ls_prob\n        \n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch_CMAES scored 0.449 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c91c478b-c7fd-4a8c-8b58-da97b05fc99f"], "operator": null, "metadata": {"aucs": [0.1807712447656017, 0.2152862583471863, 0.41306239730298167, 0.6752595887555177, 0.3801468732783799, 0.6634704541422543, 0.31350063561563024, 0.44458627666335937, 0.30255505450627906, 0.5295579247083103, 0.5008639084404573, 0.9946395687203594, 0.2863325130822394, 0.3068536412868693, 0.6621726940151708, 0.498338369001862, 0.30671404280766723, 0.602158806166546, 0.1997096132485786, 0.5106136020490144]}}
{"id": "fd749747-c86f-4a10-904a-8c708e839bb5", "fitness": 0.43929215165592234, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_v4", "description": "Integrates a Cauchy mutation operator, enhances local search with adaptive step size control based on success rate, and implements a landscape-aware population diversity maintenance strategy using dynamic population size adjustment and a re-initialization scheme focused on diversifying the population around the best solution when stagnation is detected.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_v4:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, lars_tolerance=1e-5, local_search_radius=0.1, local_search_frequency=10, cr_adaptation_rate=0.1, ls_success_threshold=0.25, ls_step_size_reduction=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.lars_tolerance = lars_tolerance\n        self.local_search_radius = local_search_radius  # Initial local search radius\n        self.local_search_frequency = local_search_frequency # How often to perform local search\n        self.cr_adaptation_rate = cr_adaptation_rate\n        self.cr_success_rate = 0.5\n        self.cr_success_history = []\n        self.ls_success_threshold = ls_success_threshold # Threshold to reduce local search step size\n        self.ls_step_size_reduction = ls_step_size_reduction # Reduction factor for local search step size\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            rand = np.random.rand()\n            if rand < 0.33:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            elif rand < 0.66:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n            else:  # Cauchy mutation\n                scale = 0.1 * self.F  # Adjust scale as needed\n                cauchy_vector = scale * np.random.standard_cauchy(size=self.dim)\n                mutated_population[i] = self.population[i] + cauchy_vector\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(len(population))\n        for m in range(self.dim):  # Consider each dimension\n            dimension_values = population[:, m]\n            sorted_indices = np.argsort(dimension_values)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf  # Boundary individuals\n\n            for i in range(1, len(population) - 1):\n                distances[sorted_indices[i]] += (dimension_values[sorted_indices[i + 1]] - dimension_values[sorted_indices[i - 1]])\n\n        return distances\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n                self.cr_success_history.append(1)\n            else:\n                 self.cr_success_history.append(0)\n                \n            self.successful_F.append(self.F)\n            self.successful_CR.append(self.CR)\n\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = np.clip((1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum, 0.1, 0.9) # Clip F\n            #self.CR = np.clip((1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum, 0.1, 0.9) # Clip CR\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation based on landscape awareness\n        if self.generation > 50:\n            fitness_std = np.std(self.fitness)\n            if fitness_std < self.lars_tolerance and self.pop_size > self.pop_size_min:\n                self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n            elif fitness_std > self.lars_tolerance and self.pop_size < self.pop_size_max:\n                self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n\n        # Update CR based on success rate\n        if self.cr_success_history:\n            success_rate = np.mean(self.cr_success_history)\n            self.cr_success_rate = (1 - self.cr_adaptation_rate) * self.cr_success_rate + self.cr_adaptation_rate * success_rate\n            self.CR = np.clip(self.cr_success_rate, 0.1, 0.9)\n            self.cr_success_history = []\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        # Select top archive_size individuals + some random individuals to promote diversity\n        num_elite = int(0.8 * self.archive_size)  # Keep top 80%\n        elite_indices = np.arange(num_elite)\n        random_indices = np.random.choice(len(combined_population), self.archive_size - num_elite, replace=False)\n        selected_indices = np.concatenate((elite_indices, random_indices))\n        np.random.shuffle(selected_indices)  # Shuffle to mix elite and random\n        \n        self.archive = list(combined_population[selected_indices])\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        # Re-initialize population around the best solution with added noise\n        best_x = self.population[np.argmin(self.fitness)]\n        self.population = np.random.normal(loc=best_x, scale=0.5, size=(self.pop_size, self.dim))  # Gaussian distribution around best\n        self.population = self.handle_bounds(self.population, func)\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.stagnation_counter = 0  # Reset stagnation counter\n        self.best_fitness_history = []\n        self.local_search_radius = 0.1 # Reset the local search radius\n\n    def local_search(self, func, x_opt):\n        # Perform local search around the best solution\n        num_evals = min(self.pop_size, self.budget) # Adaptive local evals depending on budget\n        success_count = 0\n        for _ in range(num_evals):\n            # Generate a random perturbation within the radius\n            perturbation = np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            x_neighbor = x_opt + perturbation\n            x_neighbor = self.handle_bounds(np.array([x_neighbor]), func)[0] # Keep within bounds\n\n            f_neighbor = func(x_neighbor)\n            self.budget -= 1\n\n            if f_neighbor < self.f_opt:\n                self.f_opt = f_neighbor\n                self.x_opt = x_neighbor\n                success_count += 1\n        \n        success_rate = success_count / num_evals if num_evals > 0 else 0\n\n        if success_rate < self.ls_success_threshold:\n            self.local_search_radius *= self.ls_step_size_reduction  # Reduce step size if not successful\n        \n        self.local_search_radius = max(self.local_search_radius, 1e-6) # Avoid zero radius\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            # Adjust local search frequency based on stagnation and fitness variance\n            if self.check_stagnation() or (self.generation % self.local_search_frequency == 0 and np.std(self.best_fitness_history[-min(self.stagnation_threshold, len(self.best_fitness_history)):]) < self.lars_tolerance):\n                self.local_search(func, self.x_opt)\n                if self.check_stagnation():\n                    self.restart(func)\n                    self.best_fitness_history.append(np.min(self.fitness))  # Record new best fitness after restart\n\n\n        # Final local search at the end\n        if self.budget > 0:\n            self.local_search(func, self.x_opt)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch_v4 scored 0.439 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3f00959d-88bb-488f-b079-4479194dcf50"], "operator": null, "metadata": {"aucs": [0.1744718962652474, 0.292270193608128, 0.4264643395092371, 0.5753024231219045, 0.3443530432957561, 0.48111967527811605, 0.30846839925779945, 0.38806619869214587, 0.3441293856559471, 0.24789637970535727, 0.6765069689104487, 0.9984092782967015, 0.304064077927808, 0.3285062156838261, 0.7344754633863793, 0.48028516429579116, 0.3273483597192892, 0.6011176147684979, 0.2596287133130758, 0.4929592424269903]}}
{"id": "b71d5d63-1f2b-4834-adf7-d610bcf303d4", "fitness": 0.4688792073201653, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_Improved_v2", "description": "Improves exploitation by introducing a neighborhood-based mutation and dynamic F/CR adaptation considering the fitness landscape curvature.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_Improved_v2:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05, ls_prob_initial=0.1, ls_radius_min=0.001, curvature_threshold=1e-6):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.ls_prob = ls_prob_initial # Local search probability\n        self.ls_prob_initial = ls_prob_initial\n        self.ls_success_rate = 0.0\n        self.ls_success_history = []\n        self.ls_history_length = 20\n        self.ls_radius_min = ls_radius_min\n        self.curvature_threshold = curvature_threshold # Threshold for landscape curvature\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.33:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            elif np.random.rand() < 0.66: # Neighborhood mutation\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (x1 - self.population[i]) + self.F * (x2 - self.population[i])\n\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Calculate fitness landscape curvature\n        curvature = self.calculate_curvature(self.fitness)\n\n        # Update F and CR with momentum and curvature awareness\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            # Adjust F and CR based on curvature\n            if curvature > self.curvature_threshold:  # High curvature, favor exploration\n                self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * max(self.F_momentum, 0.7)\n                self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * min(self.CR_momentum, 0.3)\n            else:  # Low curvature, favor exploitation\n                self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * min(self.F_momentum, 0.5)\n                self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * max(self.CR_momentum, 0.7)\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation based on success rate and remaining budget\n        improvement_ratio = improved_count / self.pop_size\n        budget_ratio = self.budget / 10000  # Assuming initial budget is 10000\n\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max and budget_ratio > 0.2:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        if np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            print(\"Restarting population.\")\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n        success = False\n        num_trials = 0\n\n        while num_trials < self.dim * 2: # Budget conscious local search\n            if self.budget <= 0 or self.local_search_radius < self.ls_radius_min:\n                break\n\n            direction = np.random.uniform(-1, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)  # Normalize\n\n            new_x = best_x + self.local_search_radius * direction\n            new_x = self.handle_bounds(new_x[None, :], func)[0] # Handle bounds for single vector\n\n            new_f = func(new_x)\n            self.budget -= 1\n            num_trials += 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n                success = True\n                num_trials = 0 # Reset trials if improvement is found\n\n        if self.local_search_radius > self.ls_radius_min:\n            self.local_search_radius *= self.local_search_radius_decay # Reduce radius\n        return success\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            # Adaptive local search application\n            if np.random.rand() < self.ls_prob:\n                success = self.local_search(func)\n                self.ls_success_history.append(int(success))\n\n                if len(self.ls_success_history) > self.ls_history_length:\n                    self.ls_success_history.pop(0)\n\n                self.ls_success_rate = np.mean(self.ls_success_history)\n                # Adapt local search probability\n                if self.ls_success_rate > 0.4:\n                    self.ls_prob = min(1.0, self.ls_prob * 1.1)\n                else:\n                    self.ls_prob = max(0.01, self.ls_prob * 0.9)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = 0.1 # Reset radius\n                    self.ls_prob = self.ls_prob_initial # Reset ls_prob\n\n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt\n\n    def calculate_curvature(self, fitness):\n        \"\"\"Estimates the curvature of the fitness landscape.\"\"\"\n        if len(fitness) < 3:\n            return 0.0\n\n        # Calculate differences between consecutive fitness values\n        diffs = np.diff(fitness)\n        # Calculate differences between consecutive differences\n        curvature = np.mean(np.abs(np.diff(diffs))) # average absolute change in gradient\n\n        return curvature", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch_Improved_v2 scored 0.469 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2e3617ec-759f-4b1e-85ff-d0065a4d7a4e"], "operator": null, "metadata": {"aucs": [0.19728796000106363, 0.32882045052259923, 0.41877017181248155, 0.7289488786588942, 0.35077300157175395, 0.5183614792119481, 0.3449693286109716, 0.37976143195916345, 0.39605910058634997, 0.29601183230775363, 0.6004842256458535, 0.9989186067875419, 0.294946329615999, 0.3846734763894998, 0.8227912802786994, 0.5267332980695091, 0.3742688359268894, 0.6023210100683383, 0.30708568389642155, 0.5055977644815753]}}
{"id": "cf9b386b-3d78-4752-b977-00fb8c3245f7", "fitness": 0.4717104197870271, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced3", "description": "Implements a self-adaptive radius-free local search that leverages the population diversity to estimate search directions and step sizes, dynamically adjusting the search intensity based on recent improvements.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced3:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05, ls_prob_initial=0.1, ls_success_threshold=0.2, ls_history_length=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.ls_prob = ls_prob_initial # Local search probability\n        self.ls_prob_initial = ls_prob_initial\n        self.ls_success_rate = 0.0\n        self.ls_success_history = []\n        self.ls_history_length = ls_history_length\n        self.ls_success_threshold = ls_success_threshold # Threshold for triggering local search\n        self.previous_best_fitness = np.inf\n        self.ls_intensity = 1.0 # Initial local search intensity\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.5:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            else:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        # Archive-guided mutation\n        if self.archive:\n            archive_idx = np.random.randint(len(self.archive))\n            archived_vector = self.archive[archive_idx]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutated_population[np.random.randint(self.pop_size)] = archived_vector + self.F * (x1 - x2)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Perform orthogonal crossover in groups\n            group_idx = i // self.ortho_group_size\n            start_idx = group_idx * self.ortho_group_size\n            end_idx = min((group_idx + 1) * self.ortho_group_size, self.pop_size)\n\n            group = np.arange(start_idx, end_idx)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            if f < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        if np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            print(\"Restarting population.\")\n            return True\n        return False\n\n    def adaptive_local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n        success = False\n        \n        # Estimate search direction and step size based on population diversity\n        if self.pop_size > 1:\n            # Calculate the mean of vectors pointing from other individuals to the best\n            search_direction = np.zeros(self.dim)\n            for i in range(self.pop_size):\n                if i != best_idx:\n                    search_direction += (best_x - self.population[i])\n            search_direction /= (self.pop_size - 1)\n            \n            # Adjust step size based on the magnitude of the search direction\n            step_size = self.ls_intensity * np.linalg.norm(search_direction)\n            \n            # Normalize the search direction\n            if np.linalg.norm(search_direction) > 0:\n                search_direction = search_direction / np.linalg.norm(search_direction)\n\n            # Budget-conscious local search\n            for _ in range(int(self.dim * self.ls_intensity)): # Adjust search iterations based on intensity\n                if self.budget <= 0:\n                    break\n                \n                new_x = best_x + step_size * search_direction\n                new_x = self.handle_bounds(new_x[None, :], func)[0]\n                \n                new_f = func(new_x)\n                self.budget -= 1\n                \n                if new_f < best_f:\n                    self.population[best_idx] = new_x\n                    self.fitness[best_idx] = new_f\n                    best_x = new_x\n                    best_f = new_f\n                    success = True\n\n        return success\n\n    def should_trigger_local_search(self):\n        # Check stagnation and success history\n        stagnant = self.check_stagnation()\n        sufficient_success = self.ls_success_rate > self.ls_success_threshold\n        return stagnant or sufficient_success\n        \n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n        self.previous_best_fitness = self.f_opt\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            # Adaptive local search application\n            if self.should_trigger_local_search():\n                success = self.adaptive_local_search(func)\n                self.ls_success_history.append(int(success))\n\n                if len(self.ls_success_history) > self.ls_history_length:\n                    self.ls_success_history.pop(0)\n\n                self.ls_success_rate = np.mean(self.ls_success_history)\n                # Adapt local search probability\n                if self.ls_success_rate > 0.4:\n                    self.ls_prob = min(1.0, self.ls_prob * 1.1)\n                else:\n                    self.ls_prob = max(0.01, self.ls_prob * 0.9)\n            \n            # Adjust local search intensity based on recent improvements\n            if current_best_fitness < self.previous_best_fitness:\n                self.ls_intensity = min(2.0, self.ls_intensity * 1.1)  # Increase intensity if improving\n            else:\n                self.ls_intensity = max(0.1, self.ls_intensity * 0.9)  # Decrease if not improving\n            \n            self.previous_best_fitness = current_best_fitness\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.ls_prob = self.ls_prob_initial # Reset ls_prob\n        \n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.adaptive_local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced3 scored 0.472 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c91c478b-c7fd-4a8c-8b58-da97b05fc99f"], "operator": null, "metadata": {"aucs": [0.1994379400393398, 0.3131333459384943, 0.43297598368176626, 0.6554746299669052, 0.4090365380630958, 0.5377507352690631, 0.3396627905822057, 0.3899339583396598, 0.41416777616913525, 0.3989051091082745, 0.5570900626549191, 0.9983010282900862, 0.33139150299891373, 0.4017022437865315, 0.7806878017698038, 0.5381739231637344, 0.35898411576731504, 0.6378561868105519, 0.23089364171221283, 0.5086490816285345]}}
{"id": "60947d71-6dfc-4a5d-8703-b9382854ba52", "fitness": 0.47508510755911776, "name": "AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced3", "description": "Implements a combined mutation strategy with dynamic F/CR adaptation, self-adaptive local search triggering based on stagnation and diversity, and explicit diversity maintenance using a distance-based penalty, to enhance exploration and exploitation while avoiding premature convergence.", "code": "import numpy as np\n\nclass AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced3:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, F_initial=0.5, CR_initial=0.5, F_learning_rate=0.1, CR_learning_rate=0.1, stagnation_threshold=1000, ortho_group_size=5, archive_update_frequency=5, local_search_frequency=10, local_search_radius=0.1, local_search_radius_decay=0.95, restart_probability=0.05, ls_prob_initial=0.1, ls_success_threshold=0.2, diversity_penalty_coeff=0.01, distance_metric='euclidean'):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = F_initial  # Mutation factor\n        self.CR = CR_initial  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.F_learning_rate = F_learning_rate\n        self.CR_learning_rate = CR_learning_rate\n        self.successful_F = []\n        self.successful_CR = []\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_coeff = 0.9\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.ortho_group_size = ortho_group_size  # Size of groups for orthogonal crossover\n        self.pop_size_adaptation_rate = 0.1  # Rate to adjust pop size\n        self.archive_update_frequency = archive_update_frequency\n        self.generation = 0\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.local_search_radius_decay = local_search_radius_decay\n        self.restart_probability = restart_probability\n        self.ls_prob = ls_prob_initial # Local search probability\n        self.ls_prob_initial = ls_prob_initial\n        self.ls_success_rate = 0.0\n        self.ls_success_history = []\n        self.ls_history_length = 20\n        self.ls_success_threshold = ls_success_threshold # Threshold for triggering local search\n        self.diversity_penalty_coeff = diversity_penalty_coeff\n        self.distance_metric = distance_metric\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.archive = []\n\n    def mutate(self):\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            rand = np.random.rand()\n            if rand < 0.33:  # Current-to-best mutation\n                best_idx = np.argmin(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                mutated_population[i] = self.population[i] + self.F * (self.population[best_idx] - self.population[i]) + self.F * (x1 - x2)\n            elif rand < 0.66:  # Random mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutated_population[i] = x1 + self.F * (x2 - x3)\n            else: # Archive-guided mutation\n                if self.archive:\n                    archive_idx = np.random.randint(len(self.archive))\n                    archived_vector = self.archive[archive_idx]\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x1, x2 = self.population[idxs]\n                    mutated_population[i] = archived_vector + self.F * (x1 - x2)\n                else:\n                    # Fallback to random mutation if archive is empty\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutated_population[i] = x1 + self.F * (x2 - x3)\n\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == np.random.randint(0, self.dim):\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n\n        return crossed_population\n\n    def handle_bounds(self, population, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        return np.clip(population, lb, ub)\n\n    def stochastic_ranking(self, pop, fitness):\n        N = len(pop)\n        indices = np.arange(N)\n        np.random.shuffle(indices)\n\n        def compare(i, j):\n            fi = fitness[i]\n            fj = fitness[j]\n\n            if (fi < 0 and fj < 0) or (fi >= 0 and fj >= 0):\n                return fi - fj\n            elif fi < 0 and fj >= 0:\n                return -1\n            else:\n                return 1\n\n        ranked_indices = sorted(indices, key=lambda k: fitness[k])\n        return pop[ranked_indices], fitness[ranked_indices]\n\n    def calculate_diversity_penalty(self):\n        penalty = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            distances = []\n            for j in range(self.pop_size):\n                if i != j:\n                    if self.distance_metric == 'euclidean':\n                        dist = np.linalg.norm(self.population[i] - self.population[j])\n                    else:  # Manhattan\n                        dist = np.sum(np.abs(self.population[i] - self.population[j]))\n                    distances.append(dist)\n            penalty[i] = self.diversity_penalty_coeff * np.mean(distances)  # Average distance to others\n\n        return penalty\n\n    def select(self, func, crossed_population):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        diversity_penalty = self.calculate_diversity_penalty()\n\n        improved_count = 0\n\n        for i in range(self.pop_size):\n            f = func(crossed_population[i])\n            self.budget -= 1\n\n            fitness_with_penalty = f + diversity_penalty[i]\n\n            if fitness_with_penalty < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f\n                improved_count += 1\n\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n        new_population, new_fitness = self.stochastic_ranking(new_population, new_fitness)\n\n        # Update F and CR with momentum\n        if self.successful_F:\n            mean_F = np.mean(self.successful_F)\n            mean_CR = np.mean(self.successful_CR)\n\n            self.F_momentum = self.momentum_coeff * self.F_momentum + (1 - self.momentum_coeff) * mean_F\n            self.CR_momentum = self.momentum_coeff * self.CR_momentum + (1 - self.momentum_coeff) * mean_CR\n\n            self.F = (1 - self.F_learning_rate) * self.F + self.F_learning_rate * self.F_momentum\n            self.CR = (1 - self.CR_learning_rate) * self.CR + self.CR_learning_rate * self.CR_momentum\n\n        self.successful_F = []\n        self.successful_CR = []\n\n        # Population size adaptation\n        improvement_ratio = improved_count / self.pop_size\n        if improvement_ratio > 0.3 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size + int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_max)\n        elif improvement_ratio < 0.1 and self.pop_size > self.pop_size_min:\n            self.pop_size = max(self.pop_size - int(self.pop_size_adaptation_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n        return new_population, new_fitness\n\n    def update_archive(self):\n        combined_population = np.concatenate((self.population, np.array(self.archive) if self.archive else self.population[:0]))\n        combined_fitness = np.concatenate((self.fitness, np.array([np.inf] * len(self.archive)) if self.archive else self.fitness[:0]))\n\n        # Use stochastic ranking to improve archive diversity\n        combined_population, combined_fitness = self.stochastic_ranking(combined_population, combined_fitness)\n\n        self.archive = list(combined_population[:self.archive_size])  # Select top archive_size individuals\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) >= self.stagnation_threshold:\n            if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter >= 3:\n            return True\n        return False\n\n    def restart(self, func):\n        if np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            self.stagnation_counter = 0  # Reset stagnation counter\n            self.best_fitness_history = []\n            print(\"Restarting population.\")\n            return True\n        return False\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_x = self.population[best_idx].copy()\n        best_f = self.fitness[best_idx]\n        success = False\n\n        for _ in range(self.dim * 2): # Budget conscious local search\n            if self.budget <= 0:\n                break\n\n            direction = np.random.uniform(-1, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)  # Normalize\n\n            new_x = best_x + self.local_search_radius * direction\n            new_x = self.handle_bounds(new_x[None, :], func)[0] # Handle bounds for single vector\n\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                self.population[best_idx] = new_x\n                self.fitness[best_idx] = new_f\n                best_x = new_x\n                best_f = new_f\n                success = True\n\n        self.local_search_radius *= self.local_search_radius_decay # Reduce radius\n        return success\n\n    def should_trigger_local_search(self):\n        # Check stagnation and success history\n        stagnant = self.check_stagnation()\n        sufficient_success = self.ls_success_rate > self.ls_success_threshold\n        diversity = np.std(self.fitness)\n        return stagnant or sufficient_success or diversity < 1e-6\n        \n    def __call__(self, func):\n        self.initialize_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > self.pop_size:  # Ensure enough budget for population updates\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.handle_bounds(crossed_population, func)\n            self.population, self.fitness = self.select(func, crossed_population)\n\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            self.generation += 1\n            if self.generation % self.archive_update_frequency == 0:\n                self.update_archive()\n\n            # Adaptive local search application\n            if self.should_trigger_local_search():\n                success = self.local_search(func)\n                self.ls_success_history.append(int(success))\n\n                if len(self.ls_success_history) > self.ls_history_length:\n                    self.ls_success_history.pop(0)\n\n                self.ls_success_rate = np.mean(self.ls_success_history)\n                # Adapt local search probability\n                if self.ls_success_rate > 0.4:\n                    self.ls_prob = min(1.0, self.ls_prob * 1.1)\n                else:\n                    self.ls_prob = max(0.01, self.ls_prob * 0.9)\n\n            if self.check_stagnation():\n                if not self.restart(func):\n                    self.local_search_radius = 0.1 # Reset radius\n                    self.ls_prob = self.ls_prob_initial # Reset ls_prob\n        \n        # Final local search at the end, if budget allows:\n        if self.budget > 0:\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE_Ortho_Archive_LocalSearch_Enhanced3 scored 0.475 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c91c478b-c7fd-4a8c-8b58-da97b05fc99f"], "operator": null, "metadata": {"aucs": [0.21145017987084824, 0.41002122678037045, 0.4615371642832422, 0.681267156162974, 0.46746625102723327, 0.5381708999737362, 0.38199960864431515, 0.41075969874171947, 0.4900680875012229, 0.28292253878489537, 0.6346153455402365, 0.9955315625119274, 0.28639897335758946, 0.38527565895086713, 0.6730833852669915, 0.5009228019860155, 0.3929567241292471, 0.5596177174846173, 0.25704903747068253, 0.480588132713623]}}
