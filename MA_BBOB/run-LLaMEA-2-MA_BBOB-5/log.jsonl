{"id": "baca005a-c768-4f9f-91dc-2c94ac9ea4fa", "fitness": -Infinity, "name": "CMAES", "description": "Covariance matrix adaptation evolution strategy with a simplified adaptation rule based on success history and a population size proportional to the problem dimension.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, mu_factor=1/4):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(dim * mu_factor)  # Number of parents\n        self.lamb = 4 * self.mu       # Population size\n        self.weights = np.log(self.mu + 1) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * np.max([0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1]) + self.cs\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)\n        self.mean = np.zeros(self.dim)\n        self.sigma = 0.5  # Overall standard deviation\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.success_history = []\n\n    def __call__(self, func):\n        evals = 0\n        while evals < self.budget:\n            # Generate population\n            z = np.random.normal(0, 1, size=(self.dim, self.lamb))\n            x = self.mean[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            f = np.array([func(xi) for xi in x.T])\n            evals += self.lamb\n\n            # Sort population\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n\n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n\n            # Update mean\n            xmean = np.dot(x[:, :self.mu], self.weights)\n            y = xmean - self.mean\n            self.mean = xmean\n\n            # Update evolution path\n            self.pc = (1 - self.cs) * self.pc + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * y / self.sigma\n\n            # Update covariance matrix\n            self.C = (1 - 1/self.damps) * self.C + 1/self.damps * np.outer(self.pc, self.pc)\n\n            # Success history adaptation\n            success_rate = np.mean(f[:self.mu] < f[self.mu:].min())\n            self.success_history.append(success_rate)\n            \n            if len(self.success_history) > 10:\n              recent_success = np.mean(self.success_history[-10:])\n              if recent_success > 0.6:\n                  self.sigma *= np.exp(0.05 + 0.2*(recent_success - 0.6)/0.4)\n              elif recent_success < 0.4:\n                  self.sigma *= np.exp(-0.05 + 0.2*(recent_success - 0.4)/0.4)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,0) (2,) (2,) .", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "e668b3bb-9217-48ad-99fd-67c053f3e925", "fitness": 0.0, "name": "AdaptiveDE", "description": "An adaptive Differential Evolution strategy with self-adaptive parameters and a local search component triggered based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, local_search_freq=0.1, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_freq = local_search_freq\n        self.local_search_radius = local_search_radius\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.population[self.best_idx]\n\n        stagnation_counter = 0\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = self.population[i] + self.F * (x_r1 - x_r2)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Boundary handling\n                x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter +=1\n                \n                if self.budget <= 0:\n                    break\n\n            # Adaptive F and CR\n            self.F = 0.5 * (1 + np.random.normal(0, 0.1))  # Add some noise\n            self.CR = min(1.0, abs(np.random.normal(0.9, 0.1))) #CR should be between 0 and 1\n\n            # Local Search (triggered based on stagnation)\n            if stagnation_counter > self.budget * self.local_search_freq:\n              \n              best_idx = np.argmin(self.fitness)\n              x_local = self.population[best_idx]\n              x_local_new = x_local + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n              x_local_new = np.clip(x_local_new, func.bounds.lb, func.bounds.ub)\n              f_local_new = func(x_local_new)\n              self.budget -= 1\n              \n              if f_local_new < self.f_opt:\n                self.f_opt = f_local_new\n                self.x_opt = x_local_new\n                self.fitness[best_idx] = f_local_new\n                self.population[best_idx] = x_local_new\n                stagnation_counter = 0\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}}
{"id": "246aa8ad-187d-418d-b911-b4888914a6b1", "fitness": -Infinity, "name": "CMAES_Restart", "description": "Covariance Matrix Adaptation Evolution Strategy with Biased Sampling and Restart Mechanism: Adapts the search distribution using covariance matrix estimation, introduces bias towards promising regions, and restarts when stagnation is detected.", "code": "import numpy as np\n\nclass CMAES_Restart:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=1, c_cov_mu=0.1, c_cov_1=0.1, restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = cs\n        self.damps = damps\n        self.c_cov_mu = c_cov_mu\n        self.c_cov_1 = c_cov_1\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.restarts = restarts\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        evals = 0\n        \n        for r in range(self.restarts):\n            # Initialization\n            mean = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n            sigma = 0.5\n            C = np.eye(self.dim)\n            pc = np.zeros(self.dim)\n            ps = np.zeros(self.dim)\n            B = np.eye(self.dim)\n            D = np.ones(self.dim)\n            \n            while evals < self.budget:\n                # Sampling\n                z = np.random.randn(self.dim, self.popsize)\n                x = mean[:, np.newaxis] + sigma * (B @ (D[:, np.newaxis] * z))\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                \n                f = np.array([func(xi) for xi in x.T])\n                evals += self.popsize\n\n                # Selection and Recombination\n                idx = np.argsort(f)\n                x_sorted = x[:, idx]\n                f_sorted = f[idx]\n                \n                if f_sorted[0] < self.f_opt:\n                    self.f_opt = f_sorted[0]\n                    self.x_opt = x_sorted[:,0]\n\n                mean_old = mean.copy()\n                mean = x_sorted[:, :self.mu] @ self.weights\n                \n                # Update Evolution Path\n                ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (B @ (mean - mean_old) @ np.linalg.solve(np.diag(D), B.T)) / sigma\n                hsig = np.linalg.norm(ps) / np.sqrt(1 - (1 - self.cs)**(2 * evals / self.popsize)) < (1.4 + 2/(self.dim + 1)) * self.chiN\n                damps = 1 + self.damps * hsig\n                \n                pc = (1 - self.c_cov_1) * pc + np.sqrt(self.c_cov_1 * (2 - self.c_cov_1) * self.mueff) * (mean - mean_old) / sigma\n                \n                # Update Covariance Matrix\n                artmp = (1/sigma) * (x_sorted[:, :self.mu] - mean_old[:, np.newaxis])\n                C = (1 - self.c_cov_mu - self.c_cov_1) * C + self.c_cov_1 * (pc[:, np.newaxis] @ pc[np.newaxis, :]) \\\n                    + self.c_cov_mu * artmp @ np.diag(self.weights) @ artmp.T\n                \n                # Eigen decomposition and Update B and D\n                if evals % (self.popsize * 10) == 0:\n                    C = np.triu(C) + np.triu(C, 1).T\n                    D, B = np.linalg.eigh(C)\n                    D = np.sqrt(D)\n                \n                # Adapt stepsize sigma\n                sigma = sigma * np.exp((self.cs/self.damps) * (np.linalg.norm(ps)/self.chiN - 1))\n                if sigma < 1e-10:\n                    sigma = 0.5\n                \n                if evals >= self.budget:\n                    break\n\n            if self.f_opt == np.Inf:  # All restarts failed to improve\n                mean = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n                f = func(mean)\n                if f < self.f_opt:\n                   self.f_opt = f\n                   self.x_opt = mean\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "2785198e-00c2-4f56-aca4-9b03a911c07c", "fitness": 0.7227947268673344, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Archive and stochastic ranking for constraint handling.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.archive_size = archive_size\n        self.archive = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.pop[np.argmin(self.fitness)]\n            \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                if len(self.archive) > 0:\n                    candidates = np.concatenate([self.pop, self.archive])\n                    idxs = np.random.choice(candidates.shape[0], 4, replace=False)\n                    x_r1, x_r2, x_r3, x_r4 = candidates[idxs]\n                    x_best = self.pop[np.argmin(self.fitness)]\n                    mutant = x_best + self.F * (x_r1 - x_r2) + self.F * (x_r3 - x_r4)\n                else:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n\n                # Ensure bounds\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n                \n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f_trial < self.fitness[i]:\n                    # Add replaced vector to archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(0, self.archive_size)\n                        self.archive[idx_to_replace] = self.pop[i].copy()\n\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                elif len(self.archive) < self.archive_size:\n                    self.archive.append(trial.copy())\n                else:\n                     idx_to_replace = np.random.randint(0, self.archive_size)\n                     self.archive[idx_to_replace] = trial.copy()\n                        \n                if self.budget <= 0:\n                   break\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.723 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.22820617433475265, 0.2334218233893255, 0.7974696029821584, 0.9048799037679506, 0.8548243924759786, 0.8587878637089911, 0.33597580411690053, 0.7638714524087109, 0.8274632783774336, 0.785008963804192, 0.8989951018502553, 0.9986736865997816, 0.6130127619529782, 0.8098310170096564, 0.9429591915289942, 0.8450297656215087, 0.7156317429942349, 0.8906433473743933, 0.6526044939491142, 0.4986041690993771]}}
{"id": "fd5dcd95-068e-4e0e-a49f-a70895ae2495", "fitness": -Infinity, "name": "HybridPSO", "description": "A hybrid algorithm combining particle swarm optimization (PSO) with a local search strategy based on Nelder-Mead simplex.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSO:\n    def __init__(self, budget=10000, dim=10, popsize=40, w=0.7, c1=1.5, c2=1.5, local_search_freq=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.local_search_freq = local_search_freq\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        evals = 0\n\n        # Initialize particles and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.popsize, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.popsize, self.dim))\n        \n        # Evaluate initial particles\n        fitness = np.array([func(particles[i]) for i in range(self.popsize)])\n        evals += self.popsize\n        \n        # Initialize personal best positions and fitness\n        personal_best_positions = particles.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = particles[global_best_index].copy()\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = global_best_position.copy()\n\n        iteration = 0\n        while evals < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.popsize, self.dim)\n            r2 = np.random.rand(self.popsize, self.dim)\n            \n            velocities = self.w * velocities + self.c1 * r1 * (personal_best_positions - particles) + self.c2 * r2 * (global_best_position - particles)\n            particles = particles + velocities\n            \n            # Clip particles to bounds\n            particles = np.clip(particles, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate new positions\n            fitness = np.array([func(particles[i]) for i in range(self.popsize)])\n            evals += self.popsize\n            \n            # Update personal best positions and fitness\n            for i in range(self.popsize):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = particles[i].copy()\n            \n            # Update global best position and fitness\n            current_global_best_index = np.argmin(fitness)\n            if fitness[current_global_best_index] < self.f_opt:\n                self.f_opt = fitness[current_global_best_index]\n                self.x_opt = particles[current_global_best_index].copy()\n                global_best_position = particles[current_global_best_index].copy() #Update global best postion too\n            \n            # Local search using Nelder-Mead on the current best solution\n            if iteration % self.local_search_freq == 0:\n                \n                bounds = [(func.bounds.lb, func.bounds.ub) for _ in range(self.dim)]\n\n                res = minimize(func, self.x_opt, method='Nelder-Mead', bounds=bounds, options={'maxfev': self.local_search_freq})\n                \n                if res.success:\n                    if res.fun < self.f_opt:\n                         self.f_opt = res.fun\n                         self.x_opt = res.x\n                evals += res.nfev # Count the evaluations done by the local search\n\n            if evals >= self.budget:\n                break\n            \n            iteration += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["246aa8ad-187d-418d-b911-b4888914a6b1"], "operator": null, "metadata": {}}
{"id": "022789c6-88c3-4f41-a358-1d2af340bed9", "fitness": 0.0879598108497342, "name": "DynamicAdaptiveDE", "description": "A differential evolution strategy with a dynamically adjusted population size based on performance feedback and a more aggressive local search using a shrinking hypersphere.", "code": "import numpy as np\n\nclass DynamicAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F=0.5, CR=0.9, local_search_freq=0.1, initial_local_search_radius=0.1, pop_size_adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.initial_pop_size = initial_pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_freq = local_search_freq\n        self.local_search_radius = initial_local_search_radius\n        self.initial_local_search_radius = initial_local_search_radius\n        self.pop_size_adaptation_rate = pop_size_adaptation_rate\n        self.success_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.population[self.best_idx]\n\n        stagnation_counter = 0\n        generation = 0\n\n        while self.budget > 0:\n            generation += 1\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = self.population[i] + self.F * (x_r1 - x_r2)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Boundary handling\n                x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        stagnation_counter = 0  # Reset stagnation counter\n                        self.success_history.append(True)\n                else:\n                    stagnation_counter += 1\n                    self.success_history.append(False)\n\n                if self.budget <= 0:\n                    break\n\n            # Adaptive F and CR\n            self.F = 0.5 * (1 + np.random.normal(0, 0.1))  # Add some noise\n            self.CR = min(1.0, abs(np.random.normal(0.9, 0.1))) #CR should be between 0 and 1\n            \n            # Population Size Adaptation\n            if generation % 10 == 0:\n                success_rate = np.mean(self.success_history[-min(len(self.success_history), self.pop_size):]) if self.success_history else 0.5\n                \n                if success_rate > 0.6 and self.pop_size < 2 * self.initial_pop_size:\n                    self.pop_size = min(2 * self.initial_pop_size, int(self.pop_size * (1 + self.pop_size_adaptation_rate)))\n                    self.population = np.vstack((self.population, np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - len(self.population), self.dim))))\n                    self.fitness = np.concatenate((self.fitness, np.array([func(x) for x in self.population[len(self.fitness):]])))\n                    self.budget -= (self.pop_size - len(self.fitness) + len(self.success_history))\n                elif success_rate < 0.2 and self.pop_size > self.initial_pop_size // 2:\n                    self.pop_size = max(self.initial_pop_size // 2, int(self.pop_size * (1 - self.pop_size_adaptation_rate)))\n                    self.population = self.population[:self.pop_size]\n                    self.fitness = self.fitness[:self.pop_size]\n                    \n            # Local Search (triggered based on stagnation)\n            if stagnation_counter > self.budget * self.local_search_freq:\n                best_idx = np.argmin(self.fitness)\n                x_local = self.population[best_idx]\n                \n                # Shrinking Hypersphere Local Search\n                for _ in range(5): # Number of local search iterations\n                    x_local_new = x_local + np.random.normal(0, self.local_search_radius, size=self.dim)\n                    x_local_new = np.clip(x_local_new, func.bounds.lb, func.bounds.ub)\n                    f_local_new = func(x_local_new)\n                    self.budget -= 1\n\n                    if f_local_new < self.f_opt:\n                        self.f_opt = f_local_new\n                        self.x_opt = x_local_new\n                        self.fitness[best_idx] = f_local_new\n                        self.population[best_idx] = x_local_new\n                        stagnation_counter = 0\n                        \n                    if self.budget <= 0:\n                        break\n                self.local_search_radius *= 0.8 # Reduce radius\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm DynamicAdaptiveDE scored 0.088 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e668b3bb-9217-48ad-99fd-67c053f3e925"], "operator": null, "metadata": {"aucs": [0.1759196216994684, 0]}}
{"id": "59e6268e-30d1-4bf0-81f2-01aae8906c07", "fitness": -Infinity, "name": "HybridCMAES_NelderMead", "description": "A hybrid algorithm combining a simplified CMA-ES for exploration with a Nelder-Mead simplex for exploitation, switching based on stagnation detection.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridCMAES_NelderMead:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=1, c_cov_mu=0.1, c_cov_1=0.1, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = cs\n        self.damps = damps\n        self.c_cov_mu = c_cov_mu\n        self.c_cov_1 = c_cov_1\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.stagnation_threshold = stagnation_threshold\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        evals = 0\n        \n        # Initialization\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n        sigma = 0.5\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        B = np.eye(self.dim)\n        D = np.ones(self.dim)\n        \n        while evals < self.budget:\n            # Sampling\n            z = np.random.randn(self.dim, self.popsize)\n            x = mean[:, np.newaxis] + sigma * (B @ (D[:, np.newaxis] * z))\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x.T])\n            evals += self.popsize\n\n            # Selection and Recombination\n            idx = np.argsort(f)\n            x_sorted = x[:, idx]\n            f_sorted = f[idx]\n            \n            if f_sorted[0] < self.f_opt:\n                self.f_opt = f_sorted[0]\n                self.x_opt = x_sorted[:,0]\n                self.stagnation_counter = 0  # Reset stagnation counter\n            else:\n                self.stagnation_counter += self.popsize\n            \n            if self.stagnation_counter > self.stagnation_threshold:\n                # Trigger Nelder-Mead local search\n                res = minimize(func, self.x_opt, method='Nelder-Mead', bounds=func.bounds)\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n                evals += res.nfev\n                self.stagnation_counter = 0 # Reset after NM\n                \n                # Reinitialize CMA-ES after Nelder-Mead\n                mean = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n                sigma = 0.5\n                C = np.eye(self.dim)\n                pc = np.zeros(self.dim)\n                ps = np.zeros(self.dim)\n                B = np.eye(self.dim)\n                D = np.ones(self.dim)\n\n\n            if evals >= self.budget:\n                break\n\n            mean_old = mean.copy()\n            mean = x_sorted[:, :self.mu] @ self.weights\n            \n            # Update Evolution Path\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (B @ (mean - mean_old)) / sigma\n            hsig = np.linalg.norm(ps) / np.sqrt(1 - (1 - self.cs)**(2 * evals / self.popsize)) < (1.4 + 2/(self.dim + 1)) * self.chiN\n            damps = 1 + self.damps * hsig\n            \n            pc = (1 - self.c_cov_1) * pc + np.sqrt(self.c_cov_1 * (2 - self.c_cov_1) * self.mueff) * (mean - mean_old) / sigma\n            \n            # Update Covariance Matrix\n            artmp = (1/sigma) * (x_sorted[:, :self.mu] - mean_old[:, np.newaxis])\n            C = (1 - self.c_cov_mu - self.c_cov_1) * C + self.c_cov_1 * (pc[:, np.newaxis] @ pc[np.newaxis, :]) \\\n                + self.c_cov_mu * artmp @ np.diag(self.weights) @ artmp.T\n            \n            # Eigen decomposition and Update B and D\n            if evals % (self.popsize * 10) == 0:\n                C = np.triu(C) + np.triu(C, 1).T\n                try:\n                   D, B = np.linalg.eigh(C)\n                   D = np.sqrt(D)\n                except np.linalg.LinAlgError:\n                   #If matrix is not positive definite\n                   C = C + 1e-8 * np.eye(self.dim)\n                   D, B = np.linalg.eigh(C)\n                   D = np.sqrt(D)\n            \n            # Adapt stepsize sigma\n            sigma = sigma * np.exp((self.cs/self.damps) * (np.linalg.norm(ps)/self.chiN - 1))\n            if sigma < 1e-10:\n                sigma = 0.5\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["246aa8ad-187d-418d-b911-b4888914a6b1"], "operator": null, "metadata": {}}
{"id": "9e511b27-6bfd-4a9f-80cf-aa895c05e1bd", "fitness": 0.0, "name": "AdaptiveDE_Levy_Shrink", "description": "An adaptive Differential Evolution strategy incorporating a shrinking hypersphere local search and Lévy flight mutation.", "code": "import numpy as np\n\nclass AdaptiveDE_Levy_Shrink:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, local_search_freq=0.1, initial_radius=0.5, levy_exponent=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_freq = local_search_freq\n        self.radius = initial_radius\n        self.levy_exponent = levy_exponent\n\n    def levy_flight(self, size):\n        w = np.random.normal(0, 1, size=size)\n        v = np.random.normal(0, 1, size=size)\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) / (np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * (2 ** ((self.levy_exponent - 1) / 2)))) ** (1 / self.levy_exponent)\n        step = sigma * w / (np.abs(v) ** (1 / self.levy_exponent))\n        return step\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.population[self.best_idx]\n\n        stagnation_counter = 0\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                \n                # Lévy flight mutation\n                levy_steps = self.levy_flight(self.dim)\n                x_mutated = self.population[i] + self.F * (x_r1 - x_r2) + 0.01 * levy_steps  # Adding levy flight\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Boundary handling\n                x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter +=1\n                \n                if self.budget <= 0:\n                    break\n\n            # Adaptive F and CR\n            self.F = 0.5 * (1 + np.random.normal(0, 0.1))  # Add some noise\n            self.CR = min(1.0, abs(np.random.normal(0.9, 0.1))) #CR should be between 0 and 1\n\n            # Local Search (triggered based on stagnation) - Shrinking Hypersphere\n            if stagnation_counter > self.budget * self.local_search_freq:\n              best_idx = np.argmin(self.fitness)\n              x_local = self.population[best_idx]\n              \n              # Generate a random point within the shrinking hypersphere\n              r = np.random.uniform(0, self.radius)\n              direction = np.random.normal(0, 1, size=self.dim)\n              direction = direction / np.linalg.norm(direction)  # Normalize\n              x_local_new = x_local + r * direction\n\n              x_local_new = np.clip(x_local_new, func.bounds.lb, func.bounds.ub)\n              f_local_new = func(x_local_new)\n              self.budget -= 1\n              \n              if f_local_new < self.f_opt:\n                self.f_opt = f_local_new\n                self.x_opt = x_local_new\n                self.fitness[best_idx] = f_local_new\n                self.population[best_idx] = x_local_new\n                stagnation_counter = 0\n              \n              # Shrink the radius\n              self.radius *= 0.95  # Reduce the radius\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE_Levy_Shrink scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e668b3bb-9217-48ad-99fd-67c053f3e925"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "cc4c1f19-cc9d-4e18-ae8c-2af31c91987f", "fitness": 0.5659336927566045, "name": "PSO", "description": "A particle swarm optimization algorithm with velocity clamping and dynamic inertia weight adaptation.", "code": "import numpy as np\n\nclass PSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, c1=1.5, c2=1.5, v_max_factor=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.v_max_factor = v_max_factor  # Maximum velocity as a fraction of the search space\n\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def __call__(self, func):\n        # Initialize particles and velocities\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb) * self.v_max_factor, abs(ub - lb) * self.v_max_factor, size=(self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = np.array([func(x) for x in self.particles])\n\n        self.global_best_position = self.personal_best_positions[np.argmin(self.personal_best_fitness)].copy()\n        self.global_best_fitness = np.min(self.personal_best_fitness)\n\n        evals = self.pop_size\n\n        while evals < self.budget:\n            # Update inertia weight (linearly decreasing)\n            inertia = self.inertia - (self.inertia - 0.4) * (evals / self.budget)\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions - self.particles)\n            social_component = self.c2 * r2 * (self.global_best_position - self.particles)\n\n            self.velocities = inertia * self.velocities + cognitive_component + social_component\n\n            # Velocity clamping\n            v_max = abs(ub - lb) * self.v_max_factor\n            self.velocities = np.clip(self.velocities, -v_max, v_max)\n\n            self.particles += self.velocities\n\n            # Boundary handling (clip to the search space)\n            self.particles = np.clip(self.particles, lb, ub)\n\n            # Evaluate new positions\n            fitness = np.array([func(x) for x in self.particles])\n            evals += self.pop_size\n\n            # Update personal bests\n            improved_mask = fitness < self.personal_best_fitness\n            self.personal_best_positions[improved_mask] = self.particles[improved_mask].copy()\n            self.personal_best_fitness[improved_mask] = fitness[improved_mask]\n\n            # Update global best\n            best_index = np.argmin(self.personal_best_fitness)\n            if self.personal_best_fitness[best_index] < self.global_best_fitness:\n                self.global_best_fitness = self.personal_best_fitness[best_index]\n                self.global_best_position = self.personal_best_positions[best_index].copy()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm PSO scored 0.566 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["baca005a-c768-4f9f-91dc-2c94ac9ea4fa"], "operator": null, "metadata": {"aucs": [0.2628346541863644, 0.3962394560697985, 0.8879947460425173, 0.9552794300481235, 0.27056612199872443, 0.20564962653067753, 0.8403203033815259, 0.6615382057952425, 0.8973538268597939, 0.2049109030079056, 0.9175569431800272, 0.9946387351984365, 0.24738270657685812, 0.3419806032251589, 0.9406261760771136, 0.9090719039216593, 0.31226527942547677, 0.3797840618966597, 0.19583906471170076, 0.49684110699832584]}}
{"id": "f27b6389-ea5d-4353-9592-abb1ad1810b9", "fitness": 0.3797542571305577, "name": "SimplePSO", "description": "A population-based algorithm that uses a simplified Particle Swarm Optimization (PSO) variant with velocity clamping and dynamic parameter adaptation based on population diversity.", "code": "import numpy as np\n\nclass SimplePSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia=0.7, c1=1.5, c2=1.5, velocity_clamp=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.velocity_clamp = velocity_clamp\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_values = None\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def initialize_swarm(self, func):\n        self.particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.swarm_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_values = np.array([func(x) for x in self.particles])\n        self.global_best_position = self.personal_best_positions[np.argmin(self.personal_best_values)]\n        self.global_best_value = np.min(self.personal_best_values)\n        \n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n        evals = self.swarm_size  #initialization cost\n        \n        while evals < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n            \n            self.velocities = (self.inertia * self.velocities +\n                               self.c1 * r1 * (self.personal_best_positions - self.particles) +\n                               self.c2 * r2 * (self.global_best_position - self.particles))\n            \n            # Clamp velocities\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            \n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate new positions\n            fitness_values = np.array([func(x) for x in self.particles])\n            evals += self.swarm_size\n            \n            # Update personal bests\n            better_indices = fitness_values < self.personal_best_values\n            self.personal_best_positions[better_indices] = self.particles[better_indices]\n            self.personal_best_values[better_indices] = fitness_values[better_indices]\n            \n            # Update global best\n            if np.min(fitness_values) < self.global_best_value:\n                best_index = np.argmin(fitness_values)\n                self.global_best_position = self.particles[best_index]\n                self.global_best_value = fitness_values[best_index]\n                \n            # Adapt parameters based on population diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < 0.1:\n                self.inertia *= 0.95\n                self.c1 *= 1.05\n                self.c2 *= 1.05\n            elif diversity > 1.0:\n                self.inertia *= 1.05\n                self.c1 *= 0.95\n                self.c2 *= 0.95\n\n        return self.global_best_value, self.global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm SimplePSO scored 0.380 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["baca005a-c768-4f9f-91dc-2c94ac9ea4fa"], "operator": null, "metadata": {"aucs": [0.12626069893290437, 0.2219036825902181, 0.43586354259695526, 0.46327645727537226, 0.3597936495738623, 0.3516590614374492, 0.295158131293458, 0.31661479161989425, 0.2976810475025713, 0.17257425603589494, 0.43056329770235136, 0.993996532687946, 0.27397840415244124, 0.2783014594607456, 0.7125696422322201, 0.37506538717489635, 0.3457168124941802, 0.4511603711039889, 0.19358027592979765, 0.4993676408140062]}}
{"id": "8e4356cc-ab16-4431-950f-70e6e20fbfd9", "fitness": 0.4101025443838194, "name": "PSO_CMAES", "description": "Population-based algorithm that uses a combination of particle swarm optimization principles with covariance matrix adaptation to adapt the search trajectory.", "code": "import numpy as np\n\nclass PSO_CMAES:\n    def __init__(self, budget=10000, dim=10, population_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.particles = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, size=(population_size, dim))\n        self.pbest_positions = self.particles.copy()\n        self.pbest_values = np.full(population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_value = np.inf\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.C = np.eye(dim) # Covariance matrix\n        self.mean = np.zeros(dim)\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        evals = 0\n        while evals < self.budget:\n            for i in range(self.population_size):\n                f = func(self.particles[i])\n                evals += 1\n\n                if f < self.pbest_values[i]:\n                    self.pbest_values[i] = f\n                    self.pbest_positions[i] = self.particles[i].copy()\n\n                    if f < self.gbest_value:\n                        self.gbest_value = f\n                        self.gbest_position = self.particles[i].copy()\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                inertia = self.inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand() * (self.pbest_positions[i] - self.particles[i])\n                social = self.social_coeff * np.random.rand() * (self.gbest_position - self.particles[i])\n                self.velocities[i] = inertia + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)\n\n            # CMA-ES like update to adapt search\n            diff = self.gbest_position - self.mean\n            self.C = (1 - self.learning_rate) * self.C + self.learning_rate * np.outer(diff, diff)\n            self.mean = self.gbest_position.copy()\n\n\n            if evals >= self.budget:\n                break\n\n        return self.gbest_value, self.gbest_position", "configspace": "", "generation": 1, "feedback": "The algorithm PSO_CMAES scored 0.410 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["baca005a-c768-4f9f-91dc-2c94ac9ea4fa"], "operator": null, "metadata": {"aucs": [0.2073116543680522, 0.18497805345936236, 0.5530206907205931, 0.9414841810000303, 0.24893387689599522, 0.28981939658467104, 0.22123488155741344, 0.35342086390597394, 0.576365124982136, 0.23025251622280707, 0.418920240610685, 0.9943072913103358, 0.22919294204548613, 0.2875027610630736, 0.7377011680961063, 0.5324722353652862, 0.2530123224957732, 0.29062644816139416, 0.19579251419528054, 0.45570172463593295]}}
{"id": "aed8d3af-7183-4d1c-b6fe-e2ccff67afbb", "fitness": 0.612162855429952, "name": "AdaptiveDERestart", "description": "Adaptive Differential Evolution with a dynamically adjusted population size and a restart mechanism based on fitness improvement stagnation.", "code": "import numpy as np\n\nclass AdaptiveDERestart:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F=0.5, Cr=0.9, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.initial_pop_size = initial_pop_size\n        self.F = F\n        self.Cr = Cr\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n        \n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n\n                # Ensure bounds\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n                \n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                    else:\n                        self.stagnation_counter += 1\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation counter even if not improving\n                        \n                if self.budget <= 0:\n                   break\n            \n            self.best_fitness_history.append(self.f_opt)\n\n            # Restart mechanism and population size adaptation\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.pop_size = int(self.pop_size * 0.8) # Reduce population size\n                if self.pop_size < 10:\n                    self.pop_size = self.initial_pop_size\n                \n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.budget -= self.pop_size\n\n                if np.min(self.fitness) < self.f_opt:\n                    self.f_opt = np.min(self.fitness)\n                    self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n                \n                self.stagnation_counter = 0 # Reset counter\n                print(\"Restarted with population size:\", self.pop_size)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDERestart scored 0.612 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2785198e-00c2-4f56-aca4-9b03a911c07c"], "operator": null, "metadata": {"aucs": [0.19729641727531566, 0.3438734271252998, 0.7166351841072357, 0.8669793399794247, 0.7350930967784274, 0.7978043522482388, 0.3274386720681005, 0.6549035348163543, 0.6486729322631264, 0.26322600629316917, 0.8333869745706133, 0.9978516020625523, 0.4239096460252736, 0.699138284674666, 0.902880211748191, 0.7775263136787609, 0.6019623088219439, 0.842515948632393, 0]}}
{"id": "eafa1537-d161-462c-8c03-701128fe6cbe", "fitness": 0.2870972941284428, "name": "PSO_DE", "description": "A population-based algorithm that combines aspects of particle swarm optimization and differential evolution, using velocity updates influenced by both the global best and differential vectors within the population.", "code": "import numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, popsize=None, w=0.7, c1=1.5, c2=1.5, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 * dim\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.f = f  # Differential evolution factor\n        self.cr = cr  # Crossover rate\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.popsize, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.popsize, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        evals = self.popsize\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index].copy()\n        \n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        while evals < self.budget:\n            for i in range(self.popsize):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - population[i])\n                social_component = self.c2 * r2 * (global_best_position - population[i])\n\n                # Differential Evolution part\n                idxs = [idx for idx in range(self.popsize) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                diff_vector = population[a] + self.f * (population[b] - population[c])\n\n                velocities[i] = self.w * velocities[i] + cognitive_component + social_component + self.f * (diff_vector - population[i])\n\n                # Update position\n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                evals += 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n                        if new_fitness < self.f_opt:\n                            self.f_opt = new_fitness\n                            self.x_opt = new_position\n\n                population[i] = new_position.copy() # Update population\n\n                if evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm PSO_DE scored 0.287 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["246aa8ad-187d-418d-b911-b4888914a6b1"], "operator": null, "metadata": {"aucs": [0.12277252085199963, 0.16370890144510375, 0.25133623599774413, 0.23391794997136828, 0.22050887916297046, 0.2402166387223228, 0.24476366031744123, 0.2122658702852095, 0.19856553805179178, 0.18040428205038173, 0.2135450719442381, 0.9975851827464952, 0.21893183261347826, 0.2284823062612632, 0.6184991435723888, 0.28138419088962785, 0.20996559028631168, 0.2855945733010028, 0.16331427978862778, 0.4561832343090898]}}
{"id": "c172b29d-9b87-445f-bfee-190e95164cf0", "fitness": 0.7074407370483123, "name": "AdaptiveDE_SelfLearning", "description": "An adaptive differential evolution strategy that dynamically adjusts mutation factor F and crossover rate Cr based on the success rate of previous generations and incorporates a self-learning mechanism to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE_SelfLearning:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, archive_size=10, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.archive_size = archive_size\n        self.archive = []\n        self.learning_rate = learning_rate\n        self.success_F = []\n        self.success_Cr = []\n        self.memory_F = [F_init] * 10  # Memory for past F values\n        self.memory_Cr = [Cr_init] * 10  # Memory for past Cr values\n        self.memory_index = 0\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.pop[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            successful_F = []\n            successful_Cr = []\n            for i in range(self.pop_size):\n                # Mutation\n                if len(self.archive) > 0:\n                    candidates = np.concatenate([self.pop, self.archive])\n                    idxs = np.random.choice(candidates.shape[0], 4, replace=False)\n                    x_r1, x_r2, x_r3, x_r4 = candidates[idxs]\n                    x_best = self.pop[np.argmin(self.fitness)]\n                    mutant = x_best + self.F * (x_r1 - x_r2) + self.F * (x_r3 - x_r4)\n                else:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n\n                # Ensure bounds\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    successful_F.append(self.F)\n                    successful_Cr.append(self.Cr)\n\n                    # Add replaced vector to archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(0, self.archive_size)\n                        self.archive[idx_to_replace] = self.pop[i].copy()\n\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                elif len(self.archive) < self.archive_size:\n                    self.archive.append(trial.copy())\n                else:\n                    idx_to_replace = np.random.randint(0, self.archive_size)\n                    self.archive[idx_to_replace] = trial.copy()\n\n                if self.budget <= 0:\n                    break\n\n            # Adapt F and Cr based on success\n            if successful_F:\n                mean_F = np.mean(successful_F)\n                self.F = (1 - self.learning_rate) * self.F + self.learning_rate * mean_F\n            else:\n                self.F = (1 - self.learning_rate) * self.F + self.learning_rate * np.random.rand() # Exploration if no success\n\n            if successful_Cr:\n                mean_Cr = np.mean(successful_Cr)\n                self.Cr = (1 - self.learning_rate) * self.Cr + self.learning_rate * mean_Cr\n            else:\n                self.Cr = (1 - self.learning_rate) * self.Cr + self.learning_rate * np.random.rand() # Exploration if no success\n\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n            self.memory_F[self.memory_index] = self.F\n            self.memory_Cr[self.memory_index] = self.Cr\n            self.memory_index = (self.memory_index + 1) % len(self.memory_F)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE_SelfLearning scored 0.707 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2785198e-00c2-4f56-aca4-9b03a911c07c"], "operator": null, "metadata": {"aucs": [0.19320861126912403, 0.6599783256149989, 0.8002783248491495, 0.9126359935956889, 0.8048523687710186, 0.8690753917236359, 0.5690523840245987, 0.7704080879888685, 0.8163790169526288, 0.2571697267471915, 0.9145996761981292, 0.9993195895418536, 0.5946691414566766, 0.8031682820565866, 0.9395368423910477, 0.848747165286645, 0.7230489928767427, 0.8895646597455551, 0.27890164597176126, 0.5042205139043447]}}
{"id": "f4dabe64-2be7-4956-bee2-4481bc385d86", "fitness": 0.0, "name": "SelfOrganizingSearch", "description": "A self-organizing search method that adapts its step size and search direction based on the success rate of previous steps, biasing exploration towards promising regions.", "code": "import numpy as np\n\nclass SelfOrganizingSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, success_threshold=0.6, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.success_threshold = success_threshold\n        self.adaptation_rate = adaptation_rate\n        self.x_current = None\n        self.f_current = np.Inf\n        self.success_count = 0\n        self.iteration = 0\n\n    def __call__(self, func):\n        self.x_current = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n        self.f_current = func(self.x_current)\n        self.f_opt = self.f_current\n        self.x_opt = self.x_current\n\n        for i in range(1, self.budget + 1):\n            self.iteration += 1\n            # Generate a candidate solution\n            direction = np.random.randn(self.dim)\n            direction /= np.linalg.norm(direction)  # Normalize direction\n            x_candidate = self.x_current + self.step_size * direction\n            x_candidate = np.clip(x_candidate, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate the candidate\n            f_candidate = func(x_candidate)\n            \n            # Check for improvement\n            if f_candidate < self.f_current:\n                self.success_count += 1\n                self.x_current = x_candidate\n                self.f_current = f_candidate\n\n                if f_candidate < self.f_opt:\n                    self.f_opt = f_candidate\n                    self.x_opt = x_candidate\n\n            # Adapt step size\n            success_rate = self.success_count / self.iteration\n            if success_rate > self.success_threshold:\n                self.step_size *= (1 + self.adaptation_rate)  # Increase step size\n            else:\n                self.step_size *= (1 - self.adaptation_rate)  # Decrease step size\n            \n            self.step_size = np.clip(self.step_size, 1e-6, 1.0) # Ensure step size within reasonable bounds\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm SelfOrganizingSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["246aa8ad-187d-418d-b911-b4888914a6b1"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "e2f49ae5-ff6b-4da6-adc4-fcd8326e74ed", "fitness": -Infinity, "name": "AdaptiveDE_OL", "description": "An adaptive differential evolution with a self-adjusting mutation factor based on the success rate of the individuals, and orthogonal learning.", "code": "import numpy as np\n\nclass AdaptiveDE_OL:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr=0.9, archive_size=10, F_adapt_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = np.full(pop_size, F_init)  # Individual mutation factors\n        self.Cr = Cr\n        self.archive_size = archive_size\n        self.archive = []\n        self.F_adapt_rate = F_adapt_rate\n        self.success_history = np.zeros(pop_size)  # Keep track of success rate\n        self.orthogonal_matrix = self.generate_orthogonal_matrix(dim)\n\n\n    def generate_orthogonal_matrix(self, dim):\n        if dim == 1:\n            return np.array([[1]])\n        \n        n = int(np.power(2, np.ceil(np.log2(dim))))\n        hadamard_matrix = self.hadamard(n)\n        return hadamard_matrix[:dim, :dim]\n\n    def hadamard(self, n):\n      if n == 1:\n        return np.array([[1]])\n      H = self.hadamard(n // 2)\n      return np.vstack((np.hstack((H, H)), np.hstack((H, -H))))\n\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.pop[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                if len(self.archive) > 0:\n                    candidates = np.concatenate([self.pop, self.archive])\n                    idxs = np.random.choice(candidates.shape[0], 4, replace=False)\n                    x_r1, x_r2, x_r3, x_r4 = candidates[idxs]\n                    x_best = self.pop[np.argmin(self.fitness)]\n                    mutant = x_best + self.F[i] * (x_r1 - x_r2) + self.F[i] * (x_r3 - x_r4)\n                else:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs]\n                    mutant = x_r1 + self.F[i] * (x_r2 - x_r3)\n\n                # Ensure bounds\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Orthogonal learning\n                trial = self.orthogonal_learning(trial, self.pop[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    # Update success history\n                    self.success_history[i] = 1.0\n\n                    # Add replaced vector to archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(0, self.archive_size)\n                        self.archive[idx_to_replace] = self.pop[i].copy()\n\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                else:\n                    self.success_history[i] *= (1 - self.F_adapt_rate) # Decay success if not improving\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(trial.copy())\n                    else:\n                        idx_to_replace = np.random.randint(0, self.archive_size)\n                        self.archive[idx_to_replace] = trial.copy()\n\n                # Adapt mutation factor\n                self.F[i] = np.clip(self.F[i] * (1 + self.F_adapt_rate * (self.success_history[i] - 0.5)), 0.1, 1.0)\n\n\n                if self.budget <= 0:\n                    break\n\n            # Normalize success history\n            self.success_history = self.success_history / (np.sum(self.success_history) + 1e-8)\n\n        return self.f_opt, self.x_opt\n    \n    def orthogonal_learning(self, trial, current, lb, ub):\n        # Generate a set of orthogonal trials based on the current trial\n        orthogonal_trials = []\n        for i in range(self.dim):\n            new_trial = trial.copy()\n            new_trial[i] = current[i] + 0.1 * (ub - lb) * self.orthogonal_matrix[i, i]\n            new_trial = np.clip(new_trial, lb, ub)\n            orthogonal_trials.append(new_trial)\n\n        orthogonal_trials.append(trial)\n        # Evaluate the orthogonal trials using a dummy objective function\n        # Select the best trial among the orthogonal trials\n        best_trial = trial\n        return best_trial", "configspace": "", "generation": 1, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["2785198e-00c2-4f56-aca4-9b03a911c07c"], "operator": null, "metadata": {}}
{"id": "ced3ab20-aac8-49b4-9120-957d65cf17d8", "fitness": -Infinity, "name": "CMAES_NelderMead", "description": "Combines a simplified CMA-ES with a Nelder-Mead simplex-based local search to refine solutions found by CMA-ES.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CMAES_NelderMead:\n    def __init__(self, budget=10000, dim=10, population_size=10, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.initial_sigma = initial_sigma\n        self.mean = np.zeros(dim)\n        self.C = np.eye(dim)\n        self.evals = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        while self.evals < self.budget:\n            # 1. Sample population\n            z = np.random.normal(0, 1, size=(self.population_size, self.dim))\n            samples = self.mean + self.initial_sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n            samples = np.clip(samples, func.bounds.lb, func.bounds.ub)\n\n            # 2. Evaluate samples\n            fitness_values = np.array([func(x) for x in samples])\n            self.evals += self.population_size\n\n            # Keep track of best solution\n            best_index = np.argmin(fitness_values)\n            if fitness_values[best_index] < self.f_opt:\n                self.f_opt = fitness_values[best_index]\n                self.x_opt = samples[best_index].copy()\n\n            # 3. Update CMA-ES parameters (simplified)\n            weights = np.sort(fitness_values)\n            elite_indices = np.argsort(fitness_values)[:min(self.population_size // 2, self.dim)]  # Select top individuals\n            elite_samples = samples[elite_indices]\n\n            self.mean = np.mean(elite_samples, axis=0)\n            diff = elite_samples - self.mean\n            self.C = np.cov(diff.T) if len(elite_samples) > 1 else np.eye(self.dim) #Covariance needs at least two samples\n\n            # 4. Local search with Nelder-Mead on best solution\n            if self.evals < self.budget:\n                try:\n                    res = minimize(func, self.x_opt, method='Nelder-Mead', bounds=func.bounds, options={'maxfev': min(50, self.budget - self.evals)})\n                    if res.success and res.fun < self.f_opt:\n                         self.f_opt = res.fun\n                         self.x_opt = res.x\n                    self.evals += res.nfev\n                except Exception as e:\n                    pass\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: Matrix is not positive definite.", "error": "", "parent_ids": ["8e4356cc-ab16-4431-950f-70e6e20fbfd9"], "operator": null, "metadata": {}}
{"id": "d3708c1c-dd39-4378-bd1e-e9c3804806fb", "fitness": -Infinity, "name": "ToroidalDE", "description": "A differential evolution strategy with a novel self-adaptation mechanism using a distribution of F and CR values sampled from a Beta distribution and a toroidal topology.", "code": "import numpy as np\nfrom scipy.stats import beta\n\nclass ToroidalDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, beta_alpha=1.5, beta_beta=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.beta_alpha = beta_alpha\n        self.beta_beta = beta_beta\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def toroidal_mutation(self, i):\n        phi = np.random.randint(1, self.pop_size // 2)  # Random toroidal distance\n\n        # Toroidal neighbors\n        p1 = (i - phi) % self.pop_size\n        p2 = (i + phi) % self.pop_size\n        p3 = np.random.randint(0, self.pop_size)\n        while p3 == i or p3 == p1 or p3 == p2:\n             p3 = np.random.randint(0, self.pop_size)\n\n        return p1, p2, p3\n\n\n    def __call__(self, func):\n        # Initialization\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Sample F and CR from Beta distributions\n                F = beta.rvs(self.beta_alpha, self.beta_beta)\n                Cr = beta.rvs(self.beta_alpha, self.beta_beta)\n\n\n                # Toroidal Mutation\n                p1, p2, p3 = self.toroidal_mutation(i)\n                mutant = self.pop[p1] + F * (self.pop[p2] - self.pop[p3])\n\n                # Ensure bounds\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: name 'beta' is not defined.", "error": "", "parent_ids": ["c172b29d-9b87-445f-bfee-190e95164cf0"], "operator": null, "metadata": {}}
{"id": "1ca10835-05fe-4291-9d3a-ca1f6de1f191", "fitness": -Infinity, "name": "DE_BFGS", "description": "Hybrid optimization algorithm combining the exploration of differential evolution with the exploitation capabilities of a gradient-based method (BFGS) to refine promising solutions.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DE_BFGS:\n    def __init__(self, budget=10000, dim=10, population_size=20, F=0.5, Cr=0.7, bfgs_iterations=3):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.bfgs_iterations = bfgs_iterations\n        self.population = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.values = np.full(population_size, np.inf)\n        self.best_position = None\n        self.best_value = np.inf\n        self.evals = 0\n\n    def __call__(self, func):\n        # Evaluate initial population\n        for i in range(self.population_size):\n            self.values[i] = func(self.population[i])\n            self.evals += 1\n            if self.values[i] < self.best_value:\n                self.best_value = self.values[i]\n                self.best_position = self.population[i].copy()\n\n        while self.evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                # BFGS refinement on the trial vector\n                bounds = [(func.bounds.lb[j], func.bounds.ub[j]) for j in range(self.dim)]\n                result = minimize(func, trial, method='L-BFGS-B', bounds=bounds, options={'maxiter': self.bfgs_iterations})\n\n                trial_value = result.fun\n                trial_position = result.x\n\n                if self.evals + self.bfgs_iterations <= self.budget:\n\n                    self.evals += 1 # Account for the BFGS evaluation as a single evaluation\n\n                    if trial_value < self.values[i]:\n                        self.population[i] = trial_position.copy()\n                        self.values[i] = trial_value\n                        if self.values[i] < self.best_value:\n                            self.best_value = self.values[i]\n                            self.best_position = self.population[i].copy()\n                else:\n                    break\n\n\n            if self.evals >= self.budget:\n                break\n\n        return self.best_value, self.best_position", "configspace": "", "generation": 2, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["8e4356cc-ab16-4431-950f-70e6e20fbfd9"], "operator": null, "metadata": {}}
{"id": "b3750451-6d51-48a1-b4f2-f618c207265e", "fitness": -Infinity, "name": "AdaptiveSwarm", "description": "An adaptive swarm optimization algorithm that dynamically adjusts its parameters (inertia, cognitive, and social coefficients) based on the swarm's diversity and progress, incorporating a mutation operator to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_range=(0.4, 0.9), c1_range=(1.5, 2.5), c2_range=(1.5, 2.5), mutation_rate=0.05, v_max_factor=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_range = inertia_range\n        self.c1_range = c1_range\n        self.c2_range = c2_range\n        self.mutation_rate = mutation_rate\n        self.v_max_factor = v_max_factor\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.evals = 0\n\n    def __call__(self, func):\n        # Initialize particles and velocities\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb) * self.v_max_factor, abs(ub - lb) * self.v_max_factor, size=(self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = np.array([func(x) for x in self.particles])\n        self.evals += self.pop_size\n\n        self.global_best_position = self.personal_best_positions[np.argmin(self.personal_best_fitness)].copy()\n        self.global_best_fitness = np.min(self.personal_best_fitness)\n\n        while self.evals < self.budget:\n            # Adaptive parameter adjustment based on swarm diversity\n            diversity = self.calculate_diversity()\n            inertia = self.inertia_range[0] + (self.inertia_range[1] - self.inertia_range[0]) * (1 - diversity)\n            c1 = self.c1_range[0] + (self.c1_range[1] - self.c1_range[0]) * diversity\n            c2 = self.c2_range[0] + (self.c2_range[1] - self.c2_range[0]) * diversity\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n\n            cognitive_component = c1 * r1 * (self.personal_best_positions - self.particles)\n            social_component = c2 * r2 * (self.global_best_position - self.particles)\n\n            self.velocities = inertia * self.velocities + cognitive_component + social_component\n\n            # Velocity clamping\n            v_max = abs(ub - lb) * self.v_max_factor\n            self.velocities = np.clip(self.velocities, -v_max, v_max)\n\n            self.particles += self.velocities\n\n            # Boundary handling (clip to the search space)\n            self.particles = np.clip(self.particles, lb, ub)\n\n            # Mutation operator to escape local optima\n            for i in range(self.pop_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_dim = np.random.randint(0, self.dim)\n                    self.particles[i, mutation_dim] = np.random.uniform(lb, ub)\n\n            # Evaluate new positions\n            fitness = np.array([func(x) for x in self.particles])\n            self.evals += self.pop_size\n\n            # Update personal bests\n            improved_mask = fitness < self.personal_best_fitness\n            self.personal_best_positions[improved_mask] = self.particles[improved_mask].copy()\n            self.personal_best_fitness[improved_mask] = fitness[improved_mask]\n\n            # Update global best\n            best_index = np.argmin(self.personal_best_fitness)\n            if self.personal_best_fitness[best_index] < self.global_best_fitness:\n                self.global_best_fitness = self.personal_best_fitness[best_index]\n                self.global_best_position = self.personal_best_positions[best_index].copy()\n\n        return self.global_best_fitness, self.global_best_position\n\n    def calculate_diversity(self):\n        # Calculate the average distance of each particle from the swarm's center\n        center = np.mean(self.particles, axis=0)\n        distances = np.linalg.norm(self.particles - center, axis=1)\n        diversity = np.mean(distances) / (np.abs(func.bounds.ub[0] - func.bounds.lb[0]))  # Normalize by search space range\n        return np.clip(diversity, 0, 1)", "configspace": "", "generation": 2, "feedback": "An exception occurred: name 'func' is not defined.", "error": "", "parent_ids": ["cc4c1f19-cc9d-4e18-ae8c-2af31c91987f"], "operator": null, "metadata": {}}
{"id": "d0bd3162-d084-47e6-9a17-683228b0767c", "fitness": -Infinity, "name": "CooperativeSwarmOptimization", "description": "Cooperative Swarm Optimization with Lévy Flight, where multiple swarms explore the search space cooperatively, leveraging Lévy flights for enhanced exploration and exchanging information to improve convergence.", "code": "import numpy as np\n\nclass CooperativeSwarmOptimization:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, pop_size=20, w=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.swarms = []\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n\n        for _ in range(self.num_swarms):\n            self.swarms.append({\n                'positions': np.random.uniform(-5, 5, size=(self.pop_size, self.dim)),\n                'velocities': np.random.uniform(-1, 1, size=(self.pop_size, self.dim)),\n                'personal_best_positions': np.random.uniform(-5, 5, size=(self.pop_size, self.dim)),\n                'personal_best_fitnesses': np.full(self.pop_size, np.inf),\n                'swarm_best_position': None,\n                'swarm_best_fitness': np.inf\n            })\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / (abs(v) ** (1 / beta))\n        return step\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        # Initialization\n        for swarm in self.swarms:\n            for i in range(self.pop_size):\n                fitness = func(swarm['positions'][i])\n                self.budget -= 1\n\n                if fitness < swarm['personal_best_fitnesses'][i]:\n                    swarm['personal_best_fitnesses'][i] = fitness\n                    swarm['personal_best_positions'][i] = swarm['positions'][i].copy()\n\n                if fitness < swarm['swarm_best_fitness']:\n                    swarm['swarm_best_fitness'] = fitness\n                    swarm['swarm_best_position'] = swarm['positions'][i].copy()\n                \n                if fitness < self.global_best_fitness:\n                    self.global_best_fitness = fitness\n                    self.global_best_position = swarm['positions'][i].copy()\n                    self.f_opt = fitness\n                    self.x_opt = swarm['positions'][i].copy()\n\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n\n        # Optimization loop\n        while self.budget > 0:\n            for swarm in self.swarms:\n                for i in range(self.pop_size):\n                    # Update velocity\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n\n                    # Social component: Attract towards global best, not just swarm best\n                    swarm['velocities'][i] = (self.w * swarm['velocities'][i]\n                                            + self.c1 * r1 * (swarm['personal_best_positions'][i] - swarm['positions'][i])\n                                            + self.c2 * r2 * (self.global_best_position - swarm['positions'][i]))\n\n                    # Apply Lévy flight for enhanced exploration\n                    levy_step = self.levy_flight()\n                    swarm['velocities'][i] += 0.01 * levy_step  # Scale the Levy flight step\n\n                    # Update position\n                    swarm['positions'][i] += swarm['velocities'][i]\n\n                    # Ensure bounds\n                    swarm['positions'][i] = np.clip(swarm['positions'][i], -5, 5)\n\n                    # Evaluate fitness\n                    fitness = func(swarm['positions'][i])\n                    self.budget -= 1\n\n                    if fitness < swarm['personal_best_fitnesses'][i]:\n                        swarm['personal_best_fitnesses'][i] = fitness\n                        swarm['personal_best_positions'][i] = swarm['positions'][i].copy()\n\n                    if fitness < swarm['swarm_best_fitness']:\n                        swarm['swarm_best_fitness'] = fitness\n                        swarm['swarm_best_position'] = swarm['positions'][i].copy()\n\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = swarm['positions'][i].copy()\n                        self.f_opt = fitness\n                        self.x_opt = swarm['positions'][i].copy()\n\n                    if self.budget <= 0:\n                        return self.f_opt, self.x_opt\n\n                # Swarm communication: Exchange best positions (simplified)\n                # Each swarm replaces its worst particle with the best particle from another random swarm\n                worst_index = np.argmax(swarm['personal_best_fitnesses'])\n                other_swarm_index = np.random.randint(self.num_swarms)\n                if other_swarm_index != self.swarms.index(swarm):\n                    swarm['positions'][worst_index] = self.swarms[other_swarm_index]['swarm_best_position'].copy()\n                    swarm['personal_best_positions'][worst_index] = self.swarms[other_swarm_index]['swarm_best_position'].copy()\n                    swarm['personal_best_fitnesses'][worst_index] = self.swarms[other_swarm_index]['swarm_best_fitness']\n                    \n            # After each cycle, update swarm bests again:\n            for swarm in self.swarms:\n                swarm['swarm_best_fitness'] = np.min(swarm['personal_best_fitnesses'])\n                swarm['swarm_best_position'] = swarm['personal_best_positions'][np.argmin(swarm['personal_best_fitnesses'])].copy()\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["c172b29d-9b87-445f-bfee-190e95164cf0"], "operator": null, "metadata": {}}
{"id": "19a4a986-38f8-4eac-b598-2b414fa76100", "fitness": 0.5352060889575788, "name": "AdaptiveDE_Tournament", "description": "A differential evolution strategy with a self-adaptive population size and a tournament selection mechanism to improve diversity and convergence.", "code": "import numpy as np\n\nclass AdaptiveDE_Tournament:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, F=0.5, Cr=0.9, tournament_size=3, pop_size_adapt_freq=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.pop = None\n        self.fitness = None\n        self.F = F\n        self.Cr = Cr\n        self.tournament_size = tournament_size\n        self.pop_size_adapt_freq = pop_size_adapt_freq\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.generation = 0\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n\n                # Ensure bounds\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Tournament Selection\n                competitors_idx = np.random.choice(self.pop_size, self.tournament_size, replace=False)\n                competitors_fitness = self.fitness[competitors_idx]\n                winner_idx = competitors_idx[np.argmin(competitors_fitness)]\n\n                if f_trial < self.fitness[winner_idx]:\n                    self.pop[winner_idx] = trial\n                    self.fitness[winner_idx] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n            \n            self.generation += 1\n\n            # Adapt population size\n            if self.generation % self.pop_size_adapt_freq == 0:\n                if np.std(self.fitness) < 1e-3:  # Stagnation\n                    self.pop_size = int(self.pop_size * 1.2)  # Increase population size\n                else:\n                    self.pop_size = int(self.pop_size * 0.9) # Decrease population size to converge faster\n                \n                self.pop_size = np.clip(self.pop_size, 10, 100) # Keep population size within reasonable bounds\n                \n                # Resize population. Add random individuals if growing, remove worst if shrinking\n                if self.pop_size > self.pop.shape[0]:\n                    num_new = self.pop_size - self.pop.shape[0]\n                    new_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new, self.dim))\n                    new_fitness = np.array([func(x) for x in new_pop])\n                    self.budget -= num_new\n                    self.pop = np.concatenate([self.pop, new_pop])\n                    self.fitness = np.concatenate([self.fitness, new_fitness])\n                elif self.pop_size < self.pop.shape[0]:\n                    num_remove = self.pop.shape[0] - self.pop_size\n                    remove_idx = np.argsort(self.fitness)[-num_remove:] #remove worst\n                    mask = np.ones(self.pop.shape[0], dtype=bool)\n                    mask[remove_idx] = False\n                    self.pop = self.pop[mask]\n                    self.fitness = self.fitness[mask]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE_Tournament scored 0.535 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c172b29d-9b87-445f-bfee-190e95164cf0"], "operator": null, "metadata": {"aucs": [0.28802815752944666, 0.514650263252067, 0.5348227888505033, 0.8027413206768446, 0.6371563074621736, 0.7481939168383722, 0.5547749519702119, 0.4012851250889816, 0.5865431880126531, 0.5675860576638971, 0.7866909901457937, 0]}}
{"id": "a319c0cf-d26b-45f1-a24c-05dac367a553", "fitness": 0.687692982169622, "name": "DE_CMAES", "description": "A hybrid algorithm combining Differential Evolution with a Covariance Matrix Adaptation strategy, where DE explores the search space and CMA refines the search around promising solutions.", "code": "import numpy as np\n\nclass DE_CMAES:\n    def __init__(self, budget=10000, dim=10, population_size=20, F=0.5, Cr=0.9, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.learning_rate = learning_rate\n        self.population = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.values = np.full(population_size, np.inf)\n        self.best_value = np.inf\n        self.best_solution = None\n        self.C = np.eye(dim)  # Covariance matrix for CMA-ES\n        self.mean = np.zeros(dim)\n\n    def __call__(self, func):\n        evals = 0\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                for d in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[d] = mutant[d]\n\n                # Evaluate trial vector\n                f = func(trial)\n                evals += 1\n\n                # Update population\n                if f < self.values[i]:\n                    self.values[i] = f\n                    self.population[i] = trial.copy()\n\n                    if f < self.best_value:\n                        self.best_value = f\n                        self.best_solution = trial.copy()\n            \n            # CMA-ES update using the best solution found so far\n            diff = self.best_solution - self.mean\n            self.C = (1 - self.learning_rate) * self.C + self.learning_rate * np.outer(diff, diff)\n            self.mean = self.best_solution.copy()\n\n            # Sample new candidate solutions from a multivariate Gaussian distribution\n            if evals < self.budget:  # only create the new points if within budget.\n                try:\n                    new_samples = np.random.multivariate_normal(self.mean, self.C, self.population_size//4) #reduce population size\n                    new_samples = np.clip(new_samples, func.bounds.lb, func.bounds.ub)\n                    \n                    for j in range(len(new_samples)):\n                        f = func(new_samples[j])\n                        evals +=1\n                        if f < self.best_value:\n                            self.best_value = f\n                            self.best_solution = new_samples[j].copy()\n\n\n                    # replace some of the population\n                    replace_indices = np.random.choice(self.population_size, len(new_samples), replace=False)\n                    self.population[replace_indices] = new_samples\n                    self.values[replace_indices] = np.full(len(new_samples), np.inf)\n                    \n\n                except np.linalg.LinAlgError:\n                    #If covariance matrix is not positive semi-definite\n                    pass  # Handle the exception, e.g., by resetting C\n            if evals >= self.budget:\n                break\n        return self.best_value, self.best_solution", "configspace": "", "generation": 2, "feedback": "The algorithm DE_CMAES scored 0.688 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8e4356cc-ab16-4431-950f-70e6e20fbfd9"], "operator": null, "metadata": {"aucs": [0.4118892230963004, 0.7463937267916625, 0.7239003869841203, 0.8916479311405474, 0.7627767356382906, 0.774530451327959, 0.3489980420477701, 0.6325600252550715, 0.7494979602992264, 0.6986330648358395, 0.8672511326846499, 0.9964051717967186, 0.4169007701553922, 0.7459793816324574, 0.9351974153811133, 0.7810878210221297, 0.6605914875220469, 0.8472567747453106, 0.22837574461367616, 0.5339863964221581]}}
{"id": "de3a39d6-7252-4320-84bf-c8805196d72a", "fitness": 0.6724289593325984, "name": "DE_CMAES", "description": "A hybrid algorithm combining differential evolution's mutation and crossover with covariance matrix adaptation to efficiently explore the search space.", "code": "import numpy as np\n\nclass DE_CMAES:\n    def __init__(self, budget=10000, dim=10, population_size=20, F=0.5, Cr=0.9, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.learning_rate = learning_rate\n        self.population = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.fitness = np.full(population_size, np.inf)\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.C = np.eye(dim)  # Covariance matrix for CMA-ES\n        self.mean = np.zeros(dim)  # Mean for CMA-ES\n        self.eigen_decomposition_required = True\n        self.eigenvalues = None\n        self.eigenvectors = None\n\n    def __call__(self, func):\n        evals = 0\n        for i in range(self.population_size):\n            self.fitness[i] = func(self.population[i])\n            evals += 1\n\n            if self.fitness[i] < self.best_fitness:\n                self.best_fitness = self.fitness[i]\n                self.best_solution = self.population[i].copy()\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution part\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                f = func(trial)\n                evals += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial.copy()\n\n                    if f < self.best_fitness:\n                        self.best_fitness = f\n                        self.best_solution = self.population[i].copy()\n\n            # CMA-ES like update (simplified)\n            diff = self.best_solution - self.mean\n            self.C = (1 - self.learning_rate) * self.C + self.learning_rate * np.outer(diff, diff)\n            self.mean = self.best_solution.copy()\n\n            if evals >= self.budget:\n                break\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 2, "feedback": "The algorithm DE_CMAES scored 0.672 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8e4356cc-ab16-4431-950f-70e6e20fbfd9"], "operator": null, "metadata": {"aucs": [0.34994075984648776, 0.4147264952444394, 0.6200230437280758, 0.9396356986017758, 0.8934662040158602, 0.9037116940374893, 0.8667376871400088, 0.574382070702719, 0.6398524983824484, 0.8846849022372829, 0.9458468819461684, 0.9983177600728631, 0.32483248935927267, 0.8867455442817451, 0.8182881697593508, 0.8725612768017532, 0.33988425576778614, 0.44156095293463415, 0.23233873208411548, 0.501042069707692]}}
{"id": "33eedcfd-1bfe-4598-b792-65a8a4f9fe22", "fitness": 0.579953461696984, "name": "AdaptiveDEMirrorAging", "description": "A differential evolution strategy with self-adaptive parameters, a mirroring boundary handling technique, and an aging mechanism to promote diversity.", "code": "import numpy as np\n\nclass AdaptiveDEMirrorAging:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F_min=0.1, F_max=0.9, Cr_min=0.1, Cr_max=0.9, age_threshold=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.F_min = F_min\n        self.F_max = F_max\n        self.Cr_min = Cr_min\n        self.Cr_max = Cr_max\n        self.age_threshold = age_threshold\n        self.pop = None\n        self.fitness = None\n        self.age = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.age = np.zeros(self.pop_size)\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                F = np.random.uniform(self.F_min, self.F_max)\n                Cr = np.random.uniform(self.Cr_min, self.Cr_max)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + F * (x_r2 - x_r3)\n\n                # Mirror boundary handling\n                for j in range(self.dim):\n                    if mutant[j] < func.bounds.lb[j]:\n                        mutant[j] = func.bounds.lb[j] + (func.bounds.lb[j] - mutant[j])\n                    elif mutant[j] > func.bounds.ub[j]:\n                        mutant[j] = func.bounds.ub[j] - (mutant[j] - func.bounds.ub[j])\n                \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    self.age[i] = 0  # Reset age\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    self.age[i] += 1 # Increment age if not improving\n\n                if self.budget <= 0:\n                    break\n            \n            # Aging mechanism: replace old individuals\n            for i in range(self.pop_size):\n                if self.age[i] > self.age_threshold:\n                    self.pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    self.fitness[i] = func(self.pop[i])\n                    self.budget -= 1\n                    self.age[i] = 0 # Reset age after replacement\n\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.pop[i].copy()\n                \n                if self.budget <= 0:\n                    break\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDEMirrorAging scored 0.580 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["aed8d3af-7183-4d1c-b6fe-e2ccff67afbb"], "operator": null, "metadata": {"aucs": [0.20898226134054787, 0.29394589385389625, 0.518814905118006, 0.8159536201914498, 0.633614556908612, 0.7146283266858544, 0.5577119566810316, 0.4973467876111274, 0.591023406983326, 0.5542758275630718, 0.7665661178727976, 0.9952408228423655, 0.2885249867538129, 0.5742025920956639, 0.8344791533312774, 0.7047299264818166, 0.4672452441716871, 0.7565841711931903, 0.31128496015444684, 0.5139137161056975]}}
{"id": "bc9552f7-3f58-4c82-88d3-584d7e996ae4", "fitness": 0.45634331980473225, "name": "AdaptiveDEProbabilistic", "description": "An adaptive differential evolution strategy employing a probabilistic selection of mutation strategies and a self-adaptive crossover rate based on the individual's improvement.", "code": "import numpy as np\n\nclass AdaptiveDEProbabilistic:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, mutation_strategies = [\"DE/rand/1\", \"DE/best/1\", \"DE/current-to-best/1\"]):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.mutation_strategies = mutation_strategies\n        self.strategy_probabilities = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies) # Initialize probabilities equally\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Strategy selection\n                strategy_index = np.random.choice(len(self.mutation_strategies), p=self.strategy_probabilities)\n                strategy = self.mutation_strategies[strategy_index]\n\n                # Mutation\n                if strategy == \"DE/rand/1\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n                elif strategy == \"DE/best/1\":\n                    x_best = self.pop[np.argmin(self.fitness)]\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[idxs]\n                    mutant = x_best + self.F * (x_r1 - x_r2)\n                elif strategy == \"DE/current-to-best/1\":\n                    x_best = self.pop[np.argmin(self.fitness)]\n                    idxs = np.random.choice(self.pop_size, 1, replace=False)\n                    x_r1 = self.pop[idxs[0]]\n                    mutant = self.pop[i] + self.F * (x_best - self.pop[i]) + self.F * (x_r1 - self.pop[i])\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Ensure bounds\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Adaptive Crossover\n                Cr_individual = np.random.normal(self.Cr, 0.1)\n                Cr_individual = np.clip(Cr_individual, 0, 1)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < Cr_individual\n                trial = np.where(cross_mask, mutant, self.pop[i])\n                \n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f_trial < self.fitness[i]:\n                    # Update strategy probabilities based on success (simple reward)\n                    self.strategy_probabilities[strategy_index] *= 1.1\n                    self.strategy_probabilities /= np.sum(self.strategy_probabilities)  # Normalize\n\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    # Penalize the used strategy\n                    self.strategy_probabilities[strategy_index] *= 0.9\n                    self.strategy_probabilities /= np.sum(self.strategy_probabilities) # Normalize\n\n                if self.budget <= 0:\n                   break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDEProbabilistic scored 0.456 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["aed8d3af-7183-4d1c-b6fe-e2ccff67afbb"], "operator": null, "metadata": {"aucs": [0.2002216852312294, 0.16814337579684946, 0.2884404999376249, 0.9782261181587968, 0.278617081270109, 0.18376255524913543, 0.9012399252656044, 0.24866868085018867, 0.2894586912919368, 0.17573949089326124, 0.18104780147483968, 0.9952646229251909, 0.23989169311053316, 0.2130090490396661, 0.839619460324805, 0.39103668083794707, 0.9113754889332759, 0.9536750984353648, 0.19095518975901282, 0.4984732073092728]}}
{"id": "ffc4bc01-3ace-41cf-bede-33c8a6532ff2", "fitness": -Infinity, "name": "CMAES_NelderMead", "description": "Combines a simplified CMA-ES with Nelder-Mead for local search refinement around the CMA-ES's mean.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CMAES_NelderMead:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, pop_size=None):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.mean = np.random.uniform(-5, 5, size=dim)\n        self.C = np.eye(dim)\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.evals = 0\n        self.x_opt = None\n        self.f_opt = np.inf\n\n    def sample_population(self):\n        eigenvalues, eigenvectors = np.linalg.eigh(self.C)\n        A = eigenvectors @ np.diag(np.sqrt(eigenvalues))  # Matrix square root of C\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        x = self.mean + self.initial_sigma * z @ A.T\n        return x\n\n    def __call__(self, func):\n        while self.evals < self.budget:\n            # CMA-ES Sampling and Evaluation\n            x = self.sample_population()\n            f_vals = np.array([func(xi) for xi in x])\n            self.evals += self.pop_size\n\n            # Update best solution\n            best_idx = np.argmin(f_vals)\n            if f_vals[best_idx] < self.f_opt:\n                self.f_opt = f_vals[best_idx]\n                self.x_opt = x[best_idx]\n                \n            # Selection and Update of Mean\n            idx = np.argsort(f_vals)\n            x_selected = x[idx[:self.pop_size // 2]]  # Select top half\n            self.mean = np.mean(x_selected, axis=0)\n\n            # Rank-one update of Covariance Matrix\n            diff = x_selected[0] - self.mean # Use only the best sample to update C\n            self.C = (1 - 0.1) * self.C + 0.1 * np.outer(diff, diff)\n            \n            # Nelder-Mead Local Search around mean\n            if self.evals < self.budget:\n                nm_budget = min(500, self.budget - self.evals)  # Limit Nelder-Mead evals\n                res = minimize(func, self.mean, method='Nelder-Mead', options={'maxfev': nm_budget})\n                self.evals += res.nfev\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["8e4356cc-ab16-4431-950f-70e6e20fbfd9"], "operator": null, "metadata": {}}
{"id": "333be18d-3b23-4b26-abb9-b4e8b9857c8d", "fitness": 0.3936232881136764, "name": "CooperativeSwarmOptimization", "description": "Cooperative Swarm Optimization with Lévy flights and adaptive step size, where particles exchange information and explore the search space with a combination of swarm intelligence and stochastic jumps.", "code": "import numpy as np\n\nclass CooperativeSwarmOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=40, c1=1.5, c2=0.5, w_init=0.9, levy_exponent=1.5, step_size_init=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1  # Cognitive component\n        self.c2 = c2  # Social component\n        self.w = w_init  # Inertia weight\n        self.levy_exponent = levy_exponent\n        self.step_size = step_size_init\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.Inf\n\n    def levy_flight(self, beta, dimension):\n        \"\"\"\n        Generate a Lévy flight step.\n        \"\"\"\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, dimension)\n        v = np.random.normal(0, 1, dimension)\n        step = u / (np.abs(v) ** (1 / beta))\n        return step\n\n    def __call__(self, func):\n        # Initialization\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.pop.copy()\n        self.personal_best_fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        self.global_best_position = self.personal_best_positions[np.argmin(self.personal_best_fitness)].copy()\n        self.global_best_fitness = np.min(self.personal_best_fitness)\n        self.f_opt = self.global_best_fitness\n        self.x_opt = self.global_best_position.copy()\n        \n        while self.budget > 0:\n            # Adaptive step size\n            self.step_size = self.step_size * np.exp(-10 * (self.global_best_fitness - self.f_opt) / abs(self.f_opt)) if abs(self.f_opt) > 1e-6 else self.step_size * 0.95\n            self.step_size = np.clip(self.step_size, 0.001, 0.1)\n            \n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.pop[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.pop[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n\n                # Apply Lévy flight\n                levy_step = self.levy_flight(self.levy_exponent, self.dim) * self.step_size\n                self.pop[i] = self.pop[i] + self.velocities[i] + levy_step\n\n                # Ensure bounds\n                self.pop[i] = np.clip(self.pop[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                fitness = func(self.pop[i])\n                self.budget -= 1\n                \n                if fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = fitness\n                    self.personal_best_positions[i] = self.pop[i].copy()\n\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = self.pop[i].copy()\n                        self.f_opt = fitness\n                        self.x_opt = self.pop[i].copy()\n\n                # Cooperative learning: share information with a random particle\n                j = np.random.randint(0, self.pop_size)\n                if self.personal_best_fitness[i] < self.personal_best_fitness[j]:\n                     self.personal_best_positions[j] = self.personal_best_positions[i].copy()\n                     self.personal_best_fitness[j] = self.personal_best_fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update inertia weight (linearly decreasing)\n            self.w = 0.9 - (0.9 - 0.4) * (1 - self.budget / 10000)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm CooperativeSwarmOptimization scored 0.394 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c172b29d-9b87-445f-bfee-190e95164cf0"], "operator": null, "metadata": {"aucs": [0.13467674835981447, 0.3427378185873964, 0.3819127981019751, 0.4471032285346399, 0.31278695376878796, 0.3859188421780948, 0.2930822127245237, 0.3183548074507485, 0.29982654947075216, 0.1873586108431392, 0.40630797794990836, 0.9984529213949428, 0.36616445132654074, 0.32371491960764165, 0.7495659592984409, 0.3846656896685393, 0.3241359428088483, 0.4543978751572575, 0.2621905852790921, 0.499110869762444]}}
{"id": "b516a2fc-d5d0-44cf-bf71-c5bad41ad955", "fitness": -Infinity, "name": "PSO_NelderMead", "description": "A hybrid algorithm that combines a simplified Particle Swarm Optimization with a Nelder-Mead simplex method for local search refinement.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PSO_NelderMead:\n    def __init__(self, budget=10000, dim=10, population_size=20, w=0.5, c1=1, c2=1, local_search_interval=50):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.local_search_interval = local_search_interval\n        self.population = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, size=(population_size, dim))\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_values = np.full(population_size, np.inf)\n        self.global_best_value = np.inf\n        self.global_best_position = None\n        self.evals = 0\n\n    def __call__(self, func):\n        while self.evals < self.budget:\n            for i in range(self.population_size):\n                f = func(self.population[i])\n                self.evals += 1\n\n                if f < self.personal_best_values[i]:\n                    self.personal_best_values[i] = f\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n                    if f < self.global_best_value:\n                        self.global_best_value = f\n                        self.global_best_position = self.population[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.personal_best_positions - self.population) +\n                               self.c2 * r2 * (self.global_best_position - self.population))\n            self.population = self.population + self.velocities\n            self.population = np.clip(self.population, func.bounds.lb, func.bounds.ub)\n            \n            # Local search with Nelder-Mead every local_search_interval iterations\n            if self.evals % self.local_search_interval == 0 and self.evals < self.budget:\n                 for i in range(self.population_size):\n                    # Use Nelder-Mead to refine each particle's position\n                    initial_simplex = self.population[i] + 0.1*np.random.randn(self.dim) # Initialize with a random simplex\n                    \n                    def objective_function(x):\n                        # Check if within budget before evaluating\n                        if self.evals < self.budget:\n                            f = func(x)\n                            self.evals += 1\n                            return f\n                        else:\n                            return np.inf  # Return a high value if budget exceeded\n\n                    res = minimize(objective_function, self.population[i], method='Nelder-Mead', options={'maxiter': 20}) #Reduced maxiter\n                    \n                    if self.evals >= self.budget:\n                        break\n\n                    if res.fun < self.personal_best_values[i]:\n                        self.personal_best_values[i] = res.fun\n                        self.personal_best_positions[i] = res.x.copy()\n                        self.population[i] = res.x.copy() # update the population\n\n                        if res.fun < self.global_best_value:\n                            self.global_best_value = res.fun\n                            self.global_best_position = res.x.copy()\n            if self.evals >= self.budget:\n                break\n        return self.global_best_value, self.global_best_position", "configspace": "", "generation": 3, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["a319c0cf-d26b-45f1-a24c-05dac367a553"], "operator": null, "metadata": {}}
{"id": "c47b9da7-a6a4-4214-abef-bd6e193ae05d", "fitness": 0.05820425205372293, "name": "SelfOrganizingScoutBee", "description": "A self-organizing scout bee algorithm with adaptive step size and probabilistic global relocation to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass SelfOrganizingScoutBee:\n    def __init__(self, budget=10000, dim=10, n_bees=50, scout_rate=0.1, adapt_rate=0.1, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.n_bees = n_bees\n        self.scout_rate = scout_rate\n        self.adapt_rate = adapt_rate\n        self.step_size = initial_step_size * np.ones(dim)\n        self.positions = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialization\n        self.positions = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_bees, self.dim))\n        self.fitness = np.array([func(x) for x in self.positions])\n        self.budget -= self.n_bees\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.positions[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            for i in range(self.n_bees):\n                # Exploration Phase\n                neighbor_idx = np.random.randint(0, self.n_bees)\n                while neighbor_idx == i:\n                    neighbor_idx = np.random.randint(0, self.n_bees)\n\n                direction = self.positions[neighbor_idx] - self.positions[i]\n                new_position = self.positions[i] + self.step_size * direction\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.fitness[i]:\n                    self.positions[i] = new_position\n                    self.fitness[i] = new_fitness\n\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position.copy()\n\n                # Step Size Adaptation\n                if self.fitness[i] < np.mean(self.fitness):\n                    self.step_size *= (1 + self.adapt_rate)  # Increase step size\n                else:\n                    self.step_size *= (1 - self.adapt_rate)  # Decrease step size\n\n                self.step_size = np.clip(self.step_size, 0.01, 2.0) # bound the stepsize\n\n                if self.budget <= 0:\n                    break\n                    \n            # Scout Phase (Probabilistic Relocation)\n            for i in range(self.n_bees):\n                if np.random.rand() < self.scout_rate:\n                    self.positions[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    self.fitness[i] = func(self.positions[i])\n                    self.budget -= 1\n                    \n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.positions[i].copy()\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm SelfOrganizingScoutBee scored 0.058 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["19a4a986-38f8-4eac-b598-2b414fa76100"], "operator": null, "metadata": {"aucs": [0.11640850410744585, 0]}}
{"id": "21aa99d7-e629-47b8-9b19-dff77ff57c7d", "fitness": 0.5363603260288551, "name": "DE_PSO", "description": "Combines Differential Evolution with a simplified Particle Swarm Optimization (PSO) for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass DE_PSO:\n    def __init__(self, budget=10000, dim=10, population_size=20, F=0.5, Cr=0.9, w=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F\n        self.Cr = Cr\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.population = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.velocities = np.zeros((population_size, dim))\n        self.values = np.full(population_size, np.inf)\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_values = np.full(population_size, np.inf)\n        self.global_best_value = np.inf\n        self.global_best_position = None\n\n    def __call__(self, func):\n        evals = 0\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Evaluate current position\n                f = func(self.population[i])\n                evals += 1\n\n                # Update personal best\n                if f < self.personal_best_values[i]:\n                    self.personal_best_values[i] = f\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n                    # Update global best\n                    if f < self.global_best_value:\n                        self.global_best_value = f\n                        self.global_best_position = self.population[i].copy()\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                for d in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[d] = mutant[d]\n\n                # Evaluate trial vector\n                f_trial = func(trial)\n                evals += 1\n\n                # Selection: Replace if trial is better\n                if f_trial < self.values[i]:\n                    self.values[i] = f_trial\n                    self.population[i] = trial.copy()\n                    \n                    # Update personal best after DE\n                    if f_trial < self.personal_best_values[i]:\n                        self.personal_best_values[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n\n                        if f_trial < self.global_best_value:\n                            self.global_best_value = f_trial\n                            self.global_best_position = trial.copy()\n                \n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                                      self.c2 * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = self.population[i] + self.velocities[i]\n                self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            if evals >= self.budget:\n                break\n\n        return self.global_best_value, self.global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm DE_PSO scored 0.536 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a319c0cf-d26b-45f1-a24c-05dac367a553"], "operator": null, "metadata": {"aucs": [0.316693988295769, 0.35282222075838876, 0.678098526136104, 0.8962764348966252, 0.2540354063215231, 0.7774168222686135, 0.3289033200042195, 0.5048100201467964, 0.7256480469490161, 0.2341931354832555, 0.23633146663739146, 0.9967091686584684, 0.30788425696058974, 0.6015667537930247, 0.5851509757604973, 0.77097645005899, 0.5674624900266267, 0.8493489489386719, 0.22689641585362352, 0.5159816726289066]}}
{"id": "d9784245-496f-4c34-bdba-5db51c113f0f", "fitness": 0.7463803902430728, "name": "DE_CMAES_Orthogonal", "description": "A hybrid algorithm combining differential evolution with a simplified rank-one covariance matrix update and orthogonal learning for improved exploration and exploitation.", "code": "import numpy as np\n\nclass DE_CMAES_Orthogonal:\n    def __init__(self, budget=10000, dim=10, population_size=20, F=0.5, Cr=0.9, learning_rate=0.1, orthogonal_learning_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.learning_rate = learning_rate\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n        self.population = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.fitness = np.full(population_size, np.inf)\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.C = np.eye(dim)  # Covariance matrix for CMA-ES (Rank-1 update)\n        self.mean = np.zeros(dim)  # Mean for CMA-ES\n        self.eigen_decomposition_required = True\n        self.eigenvalues = None\n        self.eigenvectors = None\n        self.evals = 0\n\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.population_size):\n            self.fitness[i] = func(self.population[i])\n            self.evals += 1\n\n            if self.fitness[i] < self.best_fitness:\n                self.best_fitness = self.fitness[i]\n                self.best_solution = self.population[i].copy()\n\n        while self.evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution part\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                f = func(trial)\n                self.evals += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial.copy()\n\n                    if f < self.best_fitness:\n                        self.best_fitness = f\n                        self.best_solution = self.population[i].copy()\n\n            # CMA-ES like update (simplified Rank-1 update)\n            diff = self.best_solution - self.mean\n            self.C = (1 - self.learning_rate) * self.C + self.learning_rate * np.outer(diff, diff)\n            self.mean = self.best_solution.copy()\n\n            # Orthogonal learning: generate orthogonal vector and update\n            orthogonal_vector = np.random.randn(self.dim)\n            orthogonal_vector -= orthogonal_vector.dot(diff) * diff / np.linalg.norm(diff)**2  # Ensure orthogonality\n            orthogonal_vector /= np.linalg.norm(orthogonal_vector)\n\n            # Generate a new solution based on the orthogonal vector\n            new_solution = self.best_solution + self.orthogonal_learning_rate * orthogonal_vector\n            new_solution = np.clip(new_solution, func.bounds.lb, func.bounds.ub)\n            f_new = func(new_solution)\n            self.evals += 1\n\n            if f_new < self.best_fitness:\n                self.best_fitness = f_new\n                self.best_solution = new_solution.copy()\n\n            if self.evals >= self.budget:\n                break\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 3, "feedback": "The algorithm DE_CMAES_Orthogonal scored 0.746 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["de3a39d6-7252-4320-84bf-c8805196d72a"], "operator": null, "metadata": {"aucs": [0.36637114907099577, 0.8932464850117539, 0.6509857815975033, 0.9521598333723098, 0.8904510409580819, 0.9151213546559294, 0.8696017092329079, 0.8595096822208457, 0.8987098768896999, 0.889611175409518, 0.9269946535385929, 0.9945763129260172, 0.3771921620845695, 0.8864979553635842, 0.7167471077551175, 0.9079168204475421, 0.21418918200757675, 0.9332780585192639, 0.26811149661798717, 0.5163359671816614]}}
{"id": "f894a729-b8e2-42ab-b22a-ca6ac6b4df02", "fitness": 0.6846166976774424, "name": "SOS_DE", "description": "A self-organizing scouts differential evolution algorithm with a dynamic archive to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass SOS_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, archive_size=10, scout_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.F = F\n        self.Cr = Cr\n        self.archive = []\n        self.archive_size = archive_size\n        self.scout_rate = scout_rate  # Percentage of population that are scouts\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Scout behavior: replace scout_rate % of individuals with random solutions\n                if np.random.rand() < self.scout_rate:\n                    scout = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    f_scout = func(scout)\n                    self.budget -= 1\n                    if f_scout < self.fitness[i]:\n                        self.pop[i] = scout\n                        self.fitness[i] = f_scout\n                        if f_scout < self.f_opt:\n                            self.f_opt = f_scout\n                            self.x_opt = scout.copy()\n\n                else:\n                    # Mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n\n                    # Ensure bounds\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    cross_mask = np.random.rand(self.dim) < self.Cr\n                    trial = np.where(cross_mask, mutant, self.pop[i])\n\n                    # Evaluation\n                    f_trial = func(trial)\n                    self.budget -= 1\n\n                    # Selection\n                    if f_trial < self.fitness[i]:\n                        # Replace individual\n                        self.pop[i] = trial\n                        self.fitness[i] = f_trial\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.pop[i].copy())\n                        else:\n                            # Replace a random archive member\n                            idx_replace = np.random.randint(0, self.archive_size)\n                            self.archive[idx_replace] = self.pop[i].copy()\n\n                        # Update optimal solution\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm SOS_DE scored 0.685 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["19a4a986-38f8-4eac-b598-2b414fa76100"], "operator": null, "metadata": {"aucs": [0.3255205940433662, 0.617616459073175, 0.6596461467709547, 0.8585078788982468, 0.7165808981686231, 0.7948293120506327, 0.6438225482741013, 0.6185231957263538, 0.7038604303551965, 0.6279423385508263, 0.8449685710091135, 0.9881564203974543, 0.6236346631455862, 0.7218054188144423, 0.9180903466867332, 0.7728609646725271, 0.5909886955124488, 0.8406128709700889, 0.31613470052572423, 0.5082314999032526]}}
{"id": "80987e19-6f35-4169-8129-d98d26da6152", "fitness": 0.7005620218862009, "name": "AdaptiveDEPopSizeRestart", "description": "A differential evolution strategy with a dynamically adjusted population size based on stagnation detection and a restart mechanism with a new promising population.", "code": "import numpy as np\n\nclass AdaptiveDEPopSizeRestart:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F=0.5, Cr=0.9, stagnation_threshold=50, pop_size_factor=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.F = F\n        self.Cr = Cr\n        self.stagnation_threshold = stagnation_threshold\n        self.pop_size_factor = pop_size_factor\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n            \n            # Stagnation detection\n            if self.f_opt <= self.best_fitness_history[-1]:\n               self.stagnation_counter = 0\n            else:\n                self.stagnation_counter +=1\n\n            self.best_fitness_history.append(self.f_opt)\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Adjust population size\n                delta_pop_size = int(self.pop_size * self.pop_size_factor)\n                self.pop_size = max(10, self.pop_size - delta_pop_size) # Ensure minimal population size\n\n                # Restart with new promising population around the current best\n                new_pop = np.random.normal(loc=self.x_opt, scale=0.1, size=(self.pop_size, self.dim))\n                new_pop = np.clip(new_pop, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = np.array([func(x) for x in new_pop])\n                self.budget -= self.pop_size\n\n                self.pop = new_pop\n                self.fitness = new_fitness\n                \n                if np.min(self.fitness) < self.f_opt:\n                    self.f_opt = np.min(self.fitness)\n                    self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n                \n                self.stagnation_counter = 0 # Reset stagnation counter\n\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDEPopSizeRestart scored 0.701 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["33eedcfd-1bfe-4598-b792-65a8a4f9fe22"], "operator": null, "metadata": {"aucs": [0.32191510042692817, 0.6005953617834393, 0.6573719127951434, 0.8728173224727372, 0.740349299895473, 0.7896552401396837, 0.6551095163365253, 0.6534211042713893, 0.7333667912537005, 0.6607295200117773, 0.8793945970802222, 0.9965747159409947, 0.6385282644791734, 0.7337560460945789, 0.9028084864967649, 0.7807497473546414, 0.6386810295737237, 0.8285837618930415, 0.39925384125831, 0.5275787781657701]}}
{"id": "77c7adda-8a09-4887-bf85-e26a39888802", "fitness": 0.2780202514731388, "name": "AdaptiveDE_CMAES", "description": "An adaptive hybrid algorithm combining Differential Evolution with a simplified CMA-ES-like update, dynamically adjusting mutation strength and crossover rate based on population diversity and success rate.", "code": "import numpy as np\n\nclass AdaptiveDE_CMAES:\n    def __init__(self, budget=10000, dim=10, population_size=20, F=0.5, Cr=0.9, learning_rate=0.1, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.learning_rate = learning_rate\n        self.diversity_threshold = diversity_threshold\n        self.population = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.fitness = np.full(population_size, np.inf)\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.C = np.eye(dim)  # Covariance matrix for CMA-ES\n        self.mean = np.zeros(dim)  # Mean for CMA-ES\n        self.success_rate = 0.0\n        self.success_history = []\n\n    def calculate_diversity(self):\n        \"\"\"Calculates the average distance of each individual from the population mean.\"\"\"\n        mean_position = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - mean_position, axis=1)\n        return np.mean(distances)\n\n    def adjust_parameters(self):\n        \"\"\"Adjusts F and Cr based on diversity and success rate.\"\"\"\n        diversity = self.calculate_diversity()\n        if diversity < self.diversity_threshold:\n            self.F *= 1.1  # Increase mutation strength if diversity is low\n            self.Cr *= 0.9  # Reduce crossover rate to focus on exploitation\n        else:\n            self.F *= 0.9  # Decrease mutation strength if diversity is high\n            self.Cr *= 1.1 # Increase crossover rate to explore more\n\n        # Adjust based on success rate\n        if self.success_rate > 0.2:  # Higher success, exploit more\n            self.F *= 0.95\n            self.Cr *= 1.05\n        elif self.success_rate < 0.05: # Lower success, explore more\n            self.F *= 1.05\n            self.Cr *= 0.95\n\n        self.F = np.clip(self.F, 0.1, 1.0)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n    def __call__(self, func):\n        evals = 0\n        for i in range(self.population_size):\n            self.fitness[i] = func(self.population[i])\n            evals += 1\n\n            if self.fitness[i] < self.best_fitness:\n                self.best_fitness = self.fitness[i]\n                self.best_solution = self.population[i].copy()\n\n        while evals < self.budget:\n            successful_trials = 0\n            for i in range(self.population_size):\n                # Differential Evolution part\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                f = func(trial)\n                evals += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial.copy()\n                    successful_trials += 1\n\n                    if f < self.best_fitness:\n                        self.best_fitness = f\n                        self.best_solution = self.population[i].copy()\n\n            # CMA-ES like update (simplified)\n            diff = self.best_solution - self.mean\n            self.C = (1 - self.learning_rate) * self.C + self.learning_rate * np.outer(diff, diff)\n            self.mean = self.best_solution.copy()\n\n            # Adaptive parameter adjustment\n            self.success_rate = successful_trials / self.population_size\n            self.success_history.append(self.success_rate)\n            if len(self.success_history) > 10:\n                self.success_history.pop(0)\n            self.success_rate = np.mean(self.success_history)\n\n            self.adjust_parameters()\n\n\n            if evals >= self.budget:\n                break\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE_CMAES scored 0.278 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["de3a39d6-7252-4320-84bf-c8805196d72a"], "operator": null, "metadata": {"aucs": [0.1676391309947528, 0.18387640543685435, 0.2876888058576773, 0.31827460097195304, 0.22641440204255303, 0.28865551510261134, 0.33228692014122896, 0.19085003775507725, 0.17460932280217767, 0.17333548169334367, 0.19645616312269398, 0.27083774776262726, 0.3037575808166997, 0.1767813118260244, 0.6537784061556351, 0.2971955363045856, 0.24693375868861145, 0.4358247095260015, 0.20209181808410326, 0.4331173743775637]}}
{"id": "f93385c3-8372-4fb0-aa7a-0390c0cdc934", "fitness": 0.6398833948056687, "name": "PSO_DE", "description": "A hybrid algorithm combining a simplified Particle Swarm Optimization (PSO) with a self-adaptive mutation strategy inspired by Differential Evolution (DE) for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, population_size=20, w=0.7, c1=1.5, c2=1.5, F=0.5, Cr=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.F = F  # Mutation factor for DE\n        self.Cr = Cr  # Crossover rate for DE\n        self.population = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, size=(population_size, dim))\n        self.fitness = np.full(population_size, np.inf)\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = np.full(population_size, np.inf)\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n\n    def __call__(self, func):\n        evals = 0\n        for i in range(self.population_size):\n            self.fitness[i] = func(self.population[i])\n            evals += 1\n            self.personal_best_fitness[i] = self.fitness[i]\n            self.personal_best_positions[i] = self.population[i].copy()\n\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_position = self.population[i].copy()\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.population[i] = self.population[i] + self.velocities[i]\n                self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n                # DE mutation\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                f = func(trial)\n                evals += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial.copy()\n\n                    if f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f\n                        self.personal_best_positions[i] = self.population[i].copy()\n\n                        if f < self.global_best_fitness:\n                            self.global_best_fitness = f\n                            self.global_best_position = self.population[i].copy()\n\n            if evals >= self.budget:\n                break\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm PSO_DE scored 0.640 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["de3a39d6-7252-4320-84bf-c8805196d72a"], "operator": null, "metadata": {"aucs": [0.25835970017128074, 0.19530129840118848, 0.8080899315097317, 0.9288088544059712, 0.8477626841341193, 0.2544851708611029, 0.7796287707424193, 0.7574456816189181, 0.8390140918480513, 0.7781103809762834, 0.913793769567482, 0.9983492319299301, 0.23008938932671574, 0.3282891075218668, 0.5888281254357774, 0.8858976786566335, 0.7223951202255012, 0.9085069861250367, 0.259430625672182, 0.515081296983184]}}
{"id": "44358683-d4f0-4188-8899-5651f50512a3", "fitness": 0.5186924662334992, "name": "AdaptiveDEReflectionRestart", "description": "A differential evolution strategy with self-adaptive parameters, a reflecting boundary handling technique, and a restart mechanism based on population concentration to maintain diversity and prevent premature convergence.", "code": "import numpy as np\n\nclass AdaptiveDEReflectionRestart:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F_min=0.1, F_max=0.9, Cr_min=0.1, Cr_max=0.9, concentration_threshold=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.F_min = F_min\n        self.F_max = F_max\n        self.Cr_min = Cr_min\n        self.Cr_max = Cr_max\n        self.concentration_threshold = concentration_threshold\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                F = np.random.uniform(self.F_min, self.F_max)\n                Cr = np.random.uniform(self.Cr_min, self.Cr_max)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + F * (x_r2 - x_r3)\n\n                # Reflection boundary handling\n                for j in range(self.dim):\n                    if mutant[j] < func.bounds.lb[j]:\n                        mutant[j] = func.bounds.lb[j] + abs(func.bounds.lb[j] - mutant[j])\n                    elif mutant[j] > func.bounds.ub[j]:\n                        mutant[j] = func.bounds.ub[j] - abs(mutant[j] - func.bounds.ub[j])\n                \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n\n            # Check population concentration\n            if self.is_concentrated():\n                # Restart the population\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.budget -= self.pop_size\n\n                if np.min(self.fitness) < self.f_opt:\n                    self.f_opt = np.min(self.fitness)\n                    self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n                    \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n    \n    def is_concentrated(self):\n        # Calculate the standard deviation of each dimension\n        std_devs = np.std(self.pop, axis=0)\n        \n        # Check if the standard deviation is below the threshold for all dimensions\n        return np.all(std_devs < self.concentration_threshold)", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDEReflectionRestart scored 0.519 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["33eedcfd-1bfe-4598-b792-65a8a4f9fe22"], "operator": null, "metadata": {"aucs": [0.22261954862402578, 0.42190033264271853, 0.4719352348012602, 0.8116692164691687, 0.4503070112316122, 0.520193184802358, 0.4199116286992276, 0.4376945403801067, 0.47389873548716943, 0.3610344684119995, 0.7392617283630114, 0.9961406787639591, 0.32109134480058044, 0.45270331576502754, 0.8522485930494041, 0.5942546237260109, 0.4334082216771018, 0.6607318455721936, 0.2098392136541115, 0.5230058577489356]}}
{"id": "dc7cd9e6-d54c-45c4-9e26-6538ed9c0be9", "fitness": 0.36444791827343703, "name": "AdaptiveDELocalSearch", "description": "An adaptive differential evolution algorithm that adjusts its mutation strategy and crossover probability based on the success rate of recent generations and incorporates a local search phase to refine solutions.", "code": "import numpy as np\n\nclass AdaptiveDELocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.5, adapt_rate=0.1, local_search_prob=0.1, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = np.full(pop_size, F_init)\n        self.Cr = np.full(pop_size, Cr_init)\n        self.adapt_rate = adapt_rate\n        self.local_search_prob = local_search_prob\n        self.local_search_radius = local_search_radius\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.success_history = []\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            successful_mutations = 0\n            for i in range(self.pop_size):\n                # Mutation strategy adaptation\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        self.F[i] *= (1 - self.adapt_rate)\n                        self.Cr[i] *= (1 + self.adapt_rate)\n                    else:\n                        self.F[i] *= (1 + self.adapt_rate)\n                        self.Cr[i] *= (1 - self.adapt_rate)\n\n                    self.F[i] = np.clip(self.F[i], 0.1, 0.9)\n                    self.Cr[i] = np.clip(self.Cr[i], 0.1, 0.9)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F[i] * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr[i]\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    successful_mutations += 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob and self.budget > 0:\n                    x_local = self.pop[i].copy()\n                    for j in range(self.dim):\n                        x_local[j] += np.random.uniform(-self.local_search_radius, self.local_search_radius)\n                        x_local[j] = np.clip(x_local[j], func.bounds.lb[j], func.bounds.ub[j])\n\n                    f_local = func(x_local)\n                    self.budget -= 1\n\n                    if f_local < self.fitness[i]:\n                        self.pop[i] = x_local\n                        self.fitness[i] = f_local\n                        if f_local < self.f_opt:\n                            self.f_opt = f_local\n                            self.x_opt = x_local.copy()\n                \n                if self.budget <= 0:\n                    break\n\n            self.success_history.append(successful_mutations / self.pop_size)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDELocalSearch scored 0.364 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["33eedcfd-1bfe-4598-b792-65a8a4f9fe22"], "operator": null, "metadata": {"aucs": [0.14964005290284454, 0.22714809088356347, 0.34774334130067575, 0.3280552023773252, 0.29006201282749666, 0.36691995559175705, 0.2968156890164949, 0.3145849865382385, 0.27813985614789494, 0.19253526456732128, 0.35161388981873876, 0.9995988358629002, 0.2615979457555345, 0.30229880630037986, 0.7361745841346603, 0.3902963364112978, 0.29662552718217117, 0.47131099270776433, 0.19286999141420536, 0.49492700372747445]}}
{"id": "a54e75f6-0af7-46f5-a0a2-b9e94f6a8e41", "fitness": -Infinity, "name": "AdaptiveDERestartLocalSearch", "description": "Implements a differential evolution strategy with a self-adaptive mutation factor and crossover rate, incorporating a restart mechanism based on population stagnation and a local search using Nelder-Mead simplex method for promising individuals.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDERestartLocalSearch:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F_min=0.1, F_max=0.9, Cr_min=0.1, Cr_max=0.9, stagnation_threshold=50, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.F_min = F_min\n        self.F_max = F_max\n        self.Cr_min = Cr_min\n        self.Cr_max = Cr_max\n        self.stagnation_threshold = stagnation_threshold\n        self.local_search_prob = local_search_prob\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            old_f_opt = self.f_opt\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                F = np.random.uniform(self.F_min, self.F_max)\n                Cr = np.random.uniform(self.Cr_min, self.Cr_max)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, lb, ub)\n\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                \n\n                if self.budget <= 0:\n                    break\n            \n            # Local Search\n            if np.random.rand() < self.local_search_prob:\n               \n                idx = np.argmin(self.fitness)\n                x_local = self.pop[idx].copy()\n\n                def local_func(x):\n                    return func(x)\n\n                bounds = [(lb[i], ub[i]) for i in range(self.dim)]\n                res = minimize(local_func, x_local, method='Nelder-Mead', bounds=bounds, options={'maxiter': min(50, self.budget)})\n                \n                if res.fun < self.fitness[idx]:\n                    self.pop[idx] = res.x\n                    self.fitness[idx] = res.fun\n                    self.budget -= res.nit \n\n                    if res.fun < self.f_opt:\n                        self.f_opt = res.fun\n                        self.x_opt = res.x.copy()\n                \n                self.budget = max(0, self.budget - res.nit)\n            \n            # Stagnation Check and Restart\n            if self.f_opt == old_f_opt:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.budget -= self.pop_size\n                self.stagnation_counter = 0\n                \n                if np.min(self.fitness) < self.f_opt:\n                    self.f_opt = np.min(self.fitness)\n                    self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["33eedcfd-1bfe-4598-b792-65a8a4f9fe22"], "operator": null, "metadata": {}}
{"id": "b522fcc1-743b-495f-b203-1ba89075b07a", "fitness": 0.7464048017984106, "name": "RankDE_CMAES", "description": "Combines Differential Evolution with a rank-based selection and covariance matrix adaptation, adapting mutation strength based on rank and using CMA-ES for local refinement.", "code": "import numpy as np\n\nclass RankDE_CMAES:\n    def __init__(self, budget=10000, dim=10, population_size=20, F=0.5, Cr=0.9, learning_rate=0.1, rank_cutoff=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.learning_rate = learning_rate\n        self.rank_cutoff = rank_cutoff # Percentage of top individuals to consider for CMA update\n        self.population = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.fitness = np.full(population_size, np.inf)\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.C = np.eye(dim)  # Covariance matrix for CMA-ES\n        self.mean = np.zeros(dim)  # Mean for CMA-ES\n        self.eigen_decomposition_required = True\n        self.eigenvalues = None\n        self.eigenvectors = None\n\n    def __call__(self, func):\n        evals = 0\n        for i in range(self.population_size):\n            self.fitness[i] = func(self.population[i])\n            evals += 1\n\n            if self.fitness[i] < self.best_fitness:\n                self.best_fitness = self.fitness[i]\n                self.best_solution = self.population[i].copy()\n\n        while evals < self.budget:\n            ranked_indices = np.argsort(self.fitness)\n            top_k = int(self.population_size * self.rank_cutoff)\n            top_individuals = self.population[ranked_indices[:top_k]]\n            \n            for i in range(self.population_size):\n                # Differential Evolution part\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                # Adaptive F based on rank\n                rank = np.where(ranked_indices == i)[0][0] / self.population_size\n                adaptive_F = self.F * (1 + rank)  # Higher rank, higher mutation strength.\n\n                mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                f = func(trial)\n                evals += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial.copy()\n\n                    if f < self.best_fitness:\n                        self.best_fitness = f\n                        self.best_solution = self.population[i].copy()\n\n            # CMA-ES like update (using top individuals)\n            diffs = top_individuals - self.mean\n            self.C = (1 - self.learning_rate) * self.C + self.learning_rate * np.mean([np.outer(diff, diff) for diff in diffs], axis=0)\n            self.mean = np.mean(top_individuals, axis=0) # Update mean using top individuals.\n\n            if evals >= self.budget:\n                break\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 3, "feedback": "The algorithm RankDE_CMAES scored 0.746 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["de3a39d6-7252-4320-84bf-c8805196d72a"], "operator": null, "metadata": {"aucs": [0.44954373283309046, 0.715249762617419, 0.7675472448613551, 0.9037676023200635, 0.8151888483929459, 0.8455139942121787, 0.7063909806144714, 0.7124178046513114, 0.7919377890450195, 0.6980990065475127, 0.9106107650575186, 0.9988462381595296, 0.758381911849819, 0.7635360862098618, 0.9449917537874206, 0.8251280315494749, 0.6877601866537397, 0.8957175845648717, 0.21534716108985308, 0.5221195509507537]}}
{"id": "ef1a1095-1825-48cc-bac7-08f911d2c414", "fitness": -Infinity, "name": "DE_Neighborhood_CMAES_BFGS", "description": "Combines differential evolution with a neighborhood-based mutation, covariance matrix adaptation based on successful mutations, and a local search using a quasi-Newton method.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DE_Neighborhood_CMAES_BFGS:\n    def __init__(self, budget=10000, dim=10, population_size=20, F=0.5, Cr=0.9, neighborhood_size=5, learning_rate=0.1, bfgs_iterations=3):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F\n        self.Cr = Cr\n        self.neighborhood_size = neighborhood_size\n        self.learning_rate = learning_rate\n        self.bfgs_iterations = bfgs_iterations\n        self.population = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.fitness = np.full(population_size, np.inf)\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.C = np.eye(dim)  # Covariance matrix for CMA-ES (Rank-1 update)\n        self.evals = 0\n        self.success_vectors = []\n        self.success_probabilities = []\n\n\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.population_size):\n            self.fitness[i] = func(self.population[i])\n            self.evals += 1\n\n            if self.fitness[i] < self.best_fitness:\n                self.best_fitness = self.fitness[i]\n                self.best_solution = self.population[i].copy()\n\n        while self.evals < self.budget:\n            for i in range(self.population_size):\n                # Neighborhood-based Differential Evolution\n                neighbors_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                neighbors = self.population[neighbors_indices]\n                \n                a, b = np.random.choice(self.neighborhood_size, 2, replace=False)\n                \n                mutant = self.population[i] + self.F * (neighbors[a] - neighbors[b])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n\n                # Crossover\n                trial = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                f = func(trial)\n                self.evals += 1\n\n                if f < self.fitness[i]:\n                    self.success_vectors.append(trial - self.population[i])\n                    self.fitness[i] = f\n                    self.population[i] = trial.copy()\n\n                    if f < self.best_fitness:\n                        self.best_fitness = f\n                        self.best_solution = self.population[i].copy()\n\n            # CMA-ES like update based on successful mutations\n            if self.success_vectors:\n                success_vectors = np.array(self.success_vectors)\n                # Calculate probabilities for each vector\n                distances = np.linalg.norm(success_vectors, axis=1)\n                probabilities = np.exp(-distances / np.mean(distances))\n                probabilities /= np.sum(probabilities)\n                self.success_probabilities = probabilities\n                \n                # Choose a vector based on calculated probabilities\n                chosen_index = np.random.choice(len(success_vectors), p=self.success_probabilities)\n                chosen_vector = success_vectors[chosen_index]\n                \n                self.C = (1 - self.learning_rate) * self.C + self.learning_rate * np.outer(chosen_vector, chosen_vector)\n                self.success_vectors = []\n                self.success_probabilities = [] # Reset probabilities\n\n            # Local search using BFGS\n            for _ in range(self.bfgs_iterations):\n                res = minimize(func, self.best_solution, method='BFGS', bounds=[func.bounds.lb, func.bounds.ub])\n                if res.fun < self.best_fitness:\n                    self.best_fitness = res.fun\n                    self.best_solution = res.x.copy()\n                    \n                self.evals += res.nfev # BFGS evaluation numbers.\n                if self.evals >= self.budget:\n                    break\n\n            if self.evals >= self.budget:\n                break\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 4, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["d9784245-496f-4c34-bdba-5db51c113f0f"], "operator": null, "metadata": {}}
{"id": "52422fde-bf87-40b7-b5cf-cc8608108bca", "fitness": 0.0, "name": "DE_NeighborhoodCMAES_AdaptiveLR", "description": "Combines differential evolution with a neighborhood-based covariance matrix adaptation and a self-adaptive learning rate for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass DE_NeighborhoodCMAES_AdaptiveLR:\n    def __init__(self, budget=10000, dim=10, population_size=20, F=0.5, Cr=0.9, initial_learning_rate=0.1, neighborhood_size=5, learning_rate_decay=0.999):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.learning_rate = initial_learning_rate\n        self.initial_learning_rate = initial_learning_rate\n        self.learning_rate_decay = learning_rate_decay\n        self.neighborhood_size = neighborhood_size\n        self.population = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.fitness = np.full(population_size, np.inf)\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.C = np.array([np.eye(dim) for _ in range(population_size)])  # Covariance matrix for each individual\n        self.evals = 0\n\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.population_size):\n            self.fitness[i] = func(self.population[i])\n            self.evals += 1\n\n            if self.fitness[i] < self.best_fitness:\n                self.best_fitness = self.fitness[i]\n                self.best_solution = self.population[i].copy()\n\n        while self.evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution part\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                f = func(trial)\n                self.evals += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial.copy()\n\n                    if f < self.best_fitness:\n                        self.best_fitness = f\n                        self.best_solution = self.population[i].copy()\n\n                # Neighborhood CMA-ES like update\n                neighborhood_indices = np.argsort(np.linalg.norm(self.population - self.population[i], axis=1))[:self.neighborhood_size]\n                neighborhood = self.population[neighborhood_indices]\n                neighborhood_mean = np.mean(neighborhood, axis=0)\n\n                diff = self.population[i] - neighborhood_mean\n                self.C[i] = (1 - self.learning_rate) * self.C[i] + self.learning_rate * np.outer(diff, diff)\n\n                # Sample from the CMA-ES distribution in the neighborhood\n                try:\n                    sampled_solution = neighborhood_mean + np.random.multivariate_normal(np.zeros(self.dim), self.C[i])\n                except:\n                    sampled_solution = neighborhood_mean + np.random.normal(0, np.sqrt(np.diag(self.C[i])))\n\n                sampled_solution = np.clip(sampled_solution, func.bounds.lb, func.bounds.ub)\n                f_sampled = func(sampled_solution)\n                self.evals += 1\n                \n                if f_sampled < self.fitness[i]:\n                    self.fitness[i] = f_sampled\n                    self.population[i] = sampled_solution.copy()\n\n                    if f_sampled < self.best_fitness:\n                        self.best_fitness = f_sampled\n                        self.best_solution = self.population[i].copy()\n            # Adaptive learning rate\n            self.learning_rate = self.initial_learning_rate * (self.learning_rate_decay**(self.evals/self.population_size))\n\n            if self.evals >= self.budget:\n                break\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 4, "feedback": "The algorithm DE_NeighborhoodCMAES_AdaptiveLR scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d9784245-496f-4c34-bdba-5db51c113f0f"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "c2014de9-00c5-4f41-a6e9-d64f53196df8", "fitness": 0.0, "name": "SaDE_Neighborhood", "description": "Combines a self-adaptive Differential Evolution with a Neighborhood Search using Gaussian perturbations, focusing on local exploitation around promising solutions.", "code": "import numpy as np\n\nclass SaDE_Neighborhood:\n    def __init__(self, budget=10000, dim=10, population_size=20, F=0.5, Cr=0.9, neighborhood_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.neighborhood_size = neighborhood_size # Size of the neighborhood for local search\n        self.population = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.fitness = np.full(population_size, np.inf)\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.mutation_strategies = ['rand1', 'current_to_best']\n        self.strategy_probabilities = np.array([0.5, 0.5])  # Initial probabilities for each strategy\n        self.success_memory_F = np.full(len(self.mutation_strategies), self.F)\n        self.success_memory_Cr = np.full(len(self.mutation_strategies), self.Cr)\n        self.strategy_success_counts = np.zeros(len(self.mutation_strategies))\n        self.strategy_selection_counts = np.zeros(len(self.mutation_strategies))\n\n\n    def __call__(self, func):\n        evals = 0\n        for i in range(self.population_size):\n            self.fitness[i] = func(self.population[i])\n            evals += 1\n\n            if self.fitness[i] < self.best_fitness:\n                self.best_fitness = self.fitness[i]\n                self.best_solution = self.population[i].copy()\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Strategy selection based on probabilities\n                strategy_index = np.random.choice(len(self.mutation_strategies), p=self.strategy_probabilities)\n                self.strategy_selection_counts[strategy_index] += 1\n\n                # Differential Evolution part\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                if self.mutation_strategies[strategy_index] == 'rand1':\n                    mutant = self.population[a] + self.success_memory_F[strategy_index] * (self.population[b] - self.population[c])\n                elif self.mutation_strategies[strategy_index] == 'current_to_best':\n                    mutant = self.population[i] + self.success_memory_F[strategy_index] * (self.best_solution - self.population[i]) + self.success_memory_F[strategy_index] * (self.population[a] - self.population[b])\n                \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.success_memory_Cr[strategy_index]:\n                        trial[j] = mutant[j]\n\n                f = func(trial)\n                evals += 1\n\n                if f < self.fitness[i]:\n                    self.strategy_success_counts[strategy_index] += 1\n                    self.fitness[i] = f\n                    self.population[i] = trial.copy()\n\n                    if f < self.best_fitness:\n                        self.best_fitness = f\n                        self.best_solution = self.population[i].copy()\n                else:\n                    # Neighborhood search around the current solution\n                    neighborhood_solution = self.population[i] + np.random.normal(0, self.neighborhood_size, self.dim)\n                    neighborhood_solution = np.clip(neighborhood_solution, func.bounds.lb, func.bounds.ub)\n                    f_neighborhood = func(neighborhood_solution)\n                    evals += 1\n\n                    if f_neighborhood < self.fitness[i]:\n                        self.fitness[i] = f_neighborhood\n                        self.population[i] = neighborhood_solution.copy()\n\n                        if f_neighborhood < self.best_fitness:\n                            self.best_fitness = f_neighborhood\n                            self.best_solution = self.population[i].copy()\n\n            # Update strategy probabilities based on success rates\n            for k in range(len(self.mutation_strategies)):\n                if self.strategy_selection_counts[k] > 0:\n                    success_rate = self.strategy_success_counts[k] / self.strategy_selection_counts[k]\n                    self.strategy_probabilities[k] = 0.1 + 0.9 * success_rate\n                else:\n                    self.strategy_probabilities[k] = 0.1\n\n            self.strategy_probabilities /= np.sum(self.strategy_probabilities) # Normalize\n\n            # Update F and Cr values for successful strategies (simple adaptation)\n            for k in range(len(self.mutation_strategies)):\n                if self.strategy_success_counts[k] > 0:\n                    self.success_memory_F[k] = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n                    self.success_memory_Cr[k] = np.clip(np.random.normal(self.Cr, 0.1), 0.1, 1.0)\n                self.strategy_success_counts[k] = 0\n                self.strategy_selection_counts[k] = 0\n\n            if evals >= self.budget:\n                break\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 4, "feedback": "The algorithm SaDE_Neighborhood scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b522fcc1-743b-495f-b203-1ba89075b07a"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "aebd0af2-7156-46a2-9ef7-815a456e81e3", "fitness": 0.6710747917461285, "name": "AdaptiveDEAgeElitism", "description": "Adaptive Differential Evolution with Aging and Elitism, where population diversity is maintained through an aging mechanism that replaces older individuals and elitism preserves the best solutions.", "code": "import numpy as np\n\nclass AdaptiveDEAgeElitism:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, age_threshold=50, elite_count=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.age_threshold = age_threshold\n        self.elite_count = elite_count\n        self.pop = None\n        self.fitness = None\n        self.ages = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population, fitness, and ages\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.ages = np.zeros(self.pop_size, dtype=int)\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            # Sort population based on fitness (for elitism)\n            sorted_indices = np.argsort(self.fitness)\n            elites_indices = sorted_indices[:self.elite_count]\n            elites = self.pop[elites_indices].copy()\n            elites_fitness = self.fitness[elites_indices].copy()\n\n            for i in range(self.pop_size):\n                if i in elites_indices:\n                    continue # Skip elites for mutation/crossover\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    self.ages[i] = 0 # Reset age if improved\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    self.ages[i] += 1 # Increment age if not improved\n\n                if self.budget <= 0:\n                    break\n            \n            # Aging mechanism: replace old individuals\n            for i in range(self.pop_size):\n                if self.ages[i] > self.age_threshold:\n                    self.pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    self.fitness[i] = func(self.pop[i])\n                    self.ages[i] = 0\n                    self.budget -= 1 # Account for replacement evaluation\n\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.pop[i].copy()\n\n                    if self.budget <= 0:\n                        break\n\n            # Reinstate Elites\n            self.pop[elites_indices] = elites\n            self.fitness[elites_indices] = elites_fitness\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDEAgeElitism scored 0.671 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["80987e19-6f35-4169-8129-d98d26da6152"], "operator": null, "metadata": {"aucs": [0.3141745500296813, 0.6498028518437466, 0.6956902127878849, 0.8789039643388816, 0.7532195552175293, 0.7931937884691747, 0.6367254712072559, 0.6851829400837353, 0.7551360452670605, 0.6655137542749858, 0.8665348585522452, 0.9920920638035582, 0.6494249036289863, 0.7305269166872022, 0]}}
{"id": "771bffb7-0cc9-46a7-a9e7-11213bdc61df", "fitness": 0.47140658643795835, "name": "MirroredSamplingDE", "description": "Implements a self-adaptive differential evolution with a mirrored sampling strategy and local search to balance exploration and exploitation.", "code": "import numpy as np\n\nclass MirroredSamplingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, local_search_prob=0.1, local_search_radius=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.local_search_prob = local_search_prob\n        self.local_search_radius = local_search_radius\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n\n                # Mirrored Sampling\n                mirror = self.pop[i] + (self.x_opt - self.pop[i]) \n                \n                mutant = np.where(np.random.rand(self.dim) < 0.5, mutant, mirror)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = np.clip(trial + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim), func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm MirroredSamplingDE scored 0.471 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["80987e19-6f35-4169-8129-d98d26da6152"], "operator": null, "metadata": {"aucs": [0.14077244115714727, 0.1797075950855218, 0.5462066648994621, 0.9241207589322195, 0.37238191477353244, 0.829013235576516, 0.313812634945953, 0.4627476879381275, 0.29788416481899505, 0.20702190543065624, 0.7546856209854224, 0.9986987632718806, 0.25039594293643364, 0.3786759283593434, 0.7946853557350234, 0.33512382880518377, 0.2733474261322405, 0.7141532622344101, 0.18102356617672688, 0.4736730305643724]}}
{"id": "4f520cf7-0ee4-4719-8da1-f50563122d5b", "fitness": 0.7216075353084942, "name": "DualPopulationDE", "description": "A differential evolution variant that utilizes a dual population approach, with one population focused on exploitation around the current best solution and the other on exploration of the search space.", "code": "import numpy as np\n\nclass DualPopulationDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, exploit_ratio=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.exploit_size = int(pop_size * exploit_ratio)\n        self.explore_size = pop_size - self.exploit_size\n        self.F = F\n        self.Cr = Cr\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize populations\n        self.explore_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.explore_size, self.dim))\n        self.exploit_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.exploit_size, self.dim))\n        \n        # Initial evaluation\n        explore_fitness = np.array([func(x) for x in self.explore_pop])\n        exploit_fitness = np.array([func(x) for x in self.exploit_pop])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_explore_idx = np.argmin(explore_fitness)\n        best_exploit_idx = np.argmin(exploit_fitness)\n\n        if explore_fitness[best_explore_idx] < exploit_fitness[best_exploit_idx]:\n            self.f_opt = explore_fitness[best_explore_idx]\n            self.x_opt = self.explore_pop[best_explore_idx].copy()\n        else:\n            self.f_opt = exploit_fitness[best_exploit_idx]\n            self.x_opt = self.exploit_pop[best_exploit_idx].copy()\n\n        while self.budget > 0:\n            # Explore population DE\n            for i in range(self.explore_size):\n                idxs = np.random.choice(self.explore_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.explore_pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.explore_pop[i])\n                f_trial = func(trial)\n                self.budget -= 1\n                if f_trial < explore_fitness[i]:\n                    self.explore_pop[i] = trial\n                    explore_fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n                    \n            if self.budget <= 0:\n                break\n            # Exploit population DE - biased towards x_opt\n            for i in range(self.exploit_size):\n                idxs = np.random.choice(self.exploit_size, 2, replace=False)\n                x_r1, x_r2 = self.exploit_pop[idxs]\n                mutant = self.x_opt + self.F * (x_r1 - x_r2) # Bias towards x_opt\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.exploit_pop[i])\n                f_trial = func(trial)\n                self.budget -= 1\n                if f_trial < exploit_fitness[i]:\n                    self.exploit_pop[i] = trial\n                    exploit_fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                        \n                if self.budget <= 0:\n                    break\n            \n            # Migrate individuals:  Replace worst explore with best exploit\n            worst_explore_idx = np.argmax(explore_fitness)\n            best_exploit_idx = np.argmin(exploit_fitness)\n            \n            if exploit_fitness[best_exploit_idx] < explore_fitness[worst_explore_idx]:\n                self.explore_pop[worst_explore_idx] = self.exploit_pop[best_exploit_idx].copy()\n                explore_fitness[worst_explore_idx] = exploit_fitness[best_exploit_idx]\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm DualPopulationDE scored 0.722 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f894a729-b8e2-42ab-b22a-ca6ac6b4df02"], "operator": null, "metadata": {"aucs": [0.25495588199946684, 0.3230003463514387, 0.8499618007450278, 0.9436379588927465, 0.8994495555187475, 0.9111987055711828, 0.7751056324433159, 0.7803180949805701, 0.8540942003430835, 0.8712647130660391, 0.9329004673728433, 0.9999186962647538, 0.40179203128326935, 0.3905123819738925, 0.958252308166686, 0.8777649500226365, 0.7311828883177853, 0.9354972741442664, 0.24966985531867714, 0.4916729633934537]}}
{"id": "063fe260-be60-46dc-a1e2-151b7fac625e", "fitness": 0.7118095248857518, "name": "AdaptiveDEArchive", "description": "An adaptive differential evolution algorithm with a self-adaptive mutation factor and an archive-based strategy to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDEArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, F_initial=0.5, Cr=0.9, F_adapt_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = F_initial\n        self.Cr = Cr\n        self.F_adapt_prob = F_adapt_prob\n        self.pop = None\n        self.fitness = None\n        self.archive = []\n        self.archive_fitness = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: Use archive with a small probability\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    idx_archive = np.random.randint(len(self.archive))\n                    x_archive = self.archive[idx_archive]\n                    \n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[idxs]\n                    mutant = self.pop[i] + self.F * (x_archive - self.pop[i]) + self.F * (x_r1 - x_r2)\n\n                else:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    # Add replaced individual to archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        # Replace the worst element in the archive\n                        max_archive_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[max_archive_idx]:\n                            self.archive[max_archive_idx] = self.pop[i].copy()\n                            self.archive_fitness[max_archive_idx] = self.fitness[i]\n\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                # Self-adaptive F\n                if np.random.rand() < self.F_adapt_prob:\n                    self.F = np.random.normal(loc=0.5, scale=0.3)\n                    self.F = np.clip(self.F, 0.1, 1.0)\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDEArchive scored 0.712 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["80987e19-6f35-4169-8129-d98d26da6152"], "operator": null, "metadata": {"aucs": [0.33920569551691293, 0.6482181702616469, 0.7045314733095371, 0.8541592528306348, 0.7472061762413003, 0.7755558538497761, 0.6645659183246224, 0.6748367975427771, 0.7545072597470456, 0.7108056046871292, 0.8525896285649022, 0.9951042030044385, 0.6394891902640358, 0.7201103058068412, 0.9145872071840786, 0.7928499150402256, 0.6067105787736438, 0.8275296391485951, 0.48890443482403545, 0.524723192792858]}}
{"id": "9d37b963-14c4-4998-9984-f6c9dcd91aa4", "fitness": 0.4398063400366568, "name": "MirroredCauchyDE", "description": "Combines differential evolution with a mirrored sampling strategy and a Cauchy mutation to escape local optima.", "code": "import numpy as np\n\nclass MirroredCauchyDE:\n    def __init__(self, budget=10000, dim=10, population_size=20, F=0.5, Cr=0.9, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.cauchy_scale = cauchy_scale # Scale parameter for Cauchy distribution\n        self.population = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.fitness = np.full(population_size, np.inf)\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.evals = 0\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.population_size):\n            self.fitness[i] = func(self.population[i])\n            self.evals += 1\n\n            if self.fitness[i] < self.best_fitness:\n                self.best_fitness = self.fitness[i]\n                self.best_solution = self.population[i].copy()\n\n        while self.evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution part\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n\n                # Mirrored sampling: Reflect if out of bounds, and re-evaluate only if the reflection makes sense\n                reflected_mutant = np.copy(mutant)\n                for j in range(self.dim):\n                    if mutant[j] < func.bounds.lb[j]:\n                        reflected_mutant[j] = 2 * func.bounds.lb[j] - mutant[j]\n                    elif mutant[j] > func.bounds.ub[j]:\n                        reflected_mutant[j] = 2 * func.bounds.ub[j] - mutant[j]\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                trial = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                # Cauchy mutation to escape local optima\n                cauchy_noise = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n                trial = trial + cauchy_noise\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f = func(trial)\n                self.evals += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial.copy()\n\n                    if f < self.best_fitness:\n                        self.best_fitness = f\n                        self.best_solution = self.population[i].copy()\n\n            if self.evals >= self.budget:\n                break\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 4, "feedback": "The algorithm MirroredCauchyDE scored 0.440 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d9784245-496f-4c34-bdba-5db51c113f0f"], "operator": null, "metadata": {"aucs": [0.18722229120975253, 0.3584753280677777, 0.4168057039029477, 0.8082405357080856, 0.36918080803314857, 0.41256791479017096, 0.29742086968094883, 0.35425690862583925, 0.34908289702889683, 0.27190425226752524, 0.46973374472357865, 0.9957431323740843, 0.3335856506594369, 0.32452748132181986, 0.8148415038635011, 0.4110544383315744, 0.3526109391537201, 0.5220756742234173, 0.24726046177242889, 0.4995362649944798]}}
{"id": "f4e25a4e-d945-47ef-8d8b-19c5802e77db", "fitness": 0.630968332359103, "name": "DE_Neighborhood_CMAES", "description": "Combines Differential Evolution with a neighborhood-based mutation and covariance matrix adaptation, focusing on local search around promising solutions within a defined radius.", "code": "import numpy as np\n\nclass DE_Neighborhood_CMAES:\n    def __init__(self, budget=10000, dim=10, population_size=20, F=0.5, Cr=0.9, learning_rate=0.1, neighborhood_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.learning_rate = learning_rate\n        self.neighborhood_size = neighborhood_size\n        self.population = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.fitness = np.full(population_size, np.inf)\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.C = np.eye(dim)  # Covariance matrix for CMA-ES (Rank-1 update)\n        self.mean = np.zeros(dim)  # Mean for CMA-ES\n        self.evals = 0\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.population_size):\n            self.fitness[i] = func(self.population[i])\n            self.evals += 1\n\n            if self.fitness[i] < self.best_fitness:\n                self.best_fitness = self.fitness[i]\n                self.best_solution = self.population[i].copy()\n\n        while self.evals < self.budget:\n            for i in range(self.population_size):\n                # Neighborhood-based Differential Evolution part\n                # Select neighbors within a certain radius of the current individual\n                distances = np.linalg.norm(self.population - self.population[i], axis=1)\n                neighbors = np.where(distances < self.neighborhood_size)[0]\n\n                # Ensure there are at least 3 neighbors (including the current individual)\n                if len(neighbors) < 4:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    if len(idxs) >= 3:\n                      a, b, c = np.random.choice(idxs, 3, replace=False)\n                      neighbors = np.concatenate(([i], [a, b, c]))\n                    else:\n                      neighbors = np.array([i])\n\n\n                if len(neighbors) > 3:\n                    neighbors = np.random.choice(neighbors, 4, replace=False)  # select 4 random neighbors\n\n                if len(neighbors) > 0:\n                    neighbors = [n for n in neighbors if n != i]\n                    a, b, c = np.random.choice(neighbors, min(3, len(neighbors)), replace=False)\n                    mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    trial = self.population[i].copy()\n                    for j in range(self.dim):\n                        if np.random.rand() < self.Cr:\n                            trial[j] = mutant[j]\n\n                    f = func(trial)\n                    self.evals += 1\n\n                    if f < self.fitness[i]:\n                        self.fitness[i] = f\n                        self.population[i] = trial.copy()\n\n                        if f < self.best_fitness:\n                            self.best_fitness = f\n                            self.best_solution = self.population[i].copy()\n                else:\n                    f = self.fitness[i]\n                    \n\n            # CMA-ES like update (simplified Rank-1 update)\n            diff = self.best_solution - self.mean\n            self.C = (1 - self.learning_rate) * self.C + self.learning_rate * np.outer(diff, diff)\n            self.mean = self.best_solution.copy()\n\n            if self.evals >= self.budget:\n                break\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 4, "feedback": "The algorithm DE_Neighborhood_CMAES scored 0.631 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d9784245-496f-4c34-bdba-5db51c113f0f"], "operator": null, "metadata": {"aucs": [0.25901147876969044, 0.22493800665779873, 0.7840603133593893, 0.9265488286756103, 0.3381830749798549, 0.9192164486964822, 0.8071466093060282, 0.8521823224448684, 0.9050027469196147, 0.22126294312076744, 0.9518465745387789, 1.0, 0.3788377346920476, 0.3310174356316904, 0.7759743047940183, 0.630041957620896, 0.6505300533998619, 0.926258527588927, 0.23534659261153879, 0.5019606933741965]}}
{"id": "9b6af86a-17d4-4241-9307-8ad4405d1017", "fitness": 0.3657084410241006, "name": "AdaptiveDESA", "description": "Adaptive Differential Evolution with Simulated Annealing-inspired acceptance and dynamic parameter adaptation based on success history.", "code": "import numpy as np\n\nclass AdaptiveDESA:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F=0.5, Cr=0.9, temp_init=1.0, temp_decay=0.995, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.F = F\n        self.Cr = Cr\n        self.temp = temp_init\n        self.temp_decay = temp_decay\n        self.archive_size = archive_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_fitness = []\n        self.success_F = []\n        self.success_Cr = []\n        self.memory_F = [self.F] * self.archive_size\n        self.memory_Cr = [self.Cr] * self.archive_size\n        self.memory_idx = 0\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history\n                self.F = np.random.choice(self.memory_F)\n                self.Cr = np.random.choice(self.memory_Cr)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Simulated Annealing acceptance criterion\n                delta_E = f_trial - self.fitness[i]\n                if delta_E < 0:\n                    accept = True\n                else:\n                    try:\n                        accept = np.random.rand() < np.exp(-delta_E / self.temp)\n                    except OverflowError:\n                        accept = False\n\n                # Selection\n                if accept:\n                    if f_trial < self.fitness[i]:\n                        self.success_F.append(self.F)\n                        self.success_Cr.append(self.Cr)\n                        \n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n\n            # Update temperature\n            self.temp *= self.temp_decay\n\n            # Update memory of successful F and Cr values\n            if self.success_F:\n                self.memory_F[self.memory_idx] = np.mean(self.success_F)\n                self.memory_Cr[self.memory_idx] = np.mean(self.success_Cr)\n                self.memory_idx = (self.memory_idx + 1) % self.archive_size\n                self.success_F = []\n                self.success_Cr = []\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDESA scored 0.366 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["80987e19-6f35-4169-8129-d98d26da6152"], "operator": null, "metadata": {"aucs": [0.21738304529933694, 0.3352165589278403, 0.29692049436032664, 0.3728792438535603, 0.28006322231868075, 0.3168390785825901, 0.28101451371015884, 0.28226123227634303, 0.2784425113852379, 0.27873738834176187, 0.3664291924706564, 0.9926859343741027, 0.3539839112562987, 0.30974500599439303, 0.6368067183491792, 0.316561718800371, 0.305267859543908, 0.36622377371280634, 0.2696497874449778, 0.4570576294794825]}}
{"id": "d71e627a-5ba6-44fe-bff1-03d53404de7b", "fitness": -Infinity, "name": "AdaptiveDELocalSearch", "description": "An adaptive differential evolution with a self-adjusting mutation factor and a local search component triggered by stagnation, using a reduced budget.", "code": "import numpy as np\n\nclass AdaptiveDELocalSearch:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F_initial=0.5, Cr=0.9, stagnation_threshold=50, local_search_iterations=100, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.F = F_initial\n        self.Cr = Cr\n        self.stagnation_threshold = stagnation_threshold\n        self.local_search_iterations = local_search_iterations\n        self.local_search_radius = local_search_radius\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > 0:\n            # Adjust mutation factor F\n            self.F = self.F_initial * np.exp(np.random.normal(0, 0.1))\n            self.F = np.clip(self.F, 0.1, 1.0)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n            \n            # Stagnation detection\n            if self.f_opt <= self.best_fitness_history[-1]:\n               self.stagnation_counter = 0\n            else:\n                self.stagnation_counter +=1\n\n            self.best_fitness_history.append(self.f_opt)\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Local search around the best solution, using a fraction of the budget\n                local_budget = min(self.local_search_iterations, self.budget // 4)  # Limit local search budget\n                if local_budget > 0:\n                    x_local_opt, f_local_opt = self.local_search(func, self.x_opt, local_budget)\n                    if f_local_opt < self.f_opt:\n                        self.f_opt = f_local_opt\n                        self.x_opt = x_local_opt.copy()\n                    self.budget -= local_budget\n\n                self.stagnation_counter = 0 # Reset stagnation counter\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x_center, budget):\n        x_opt = x_center.copy()\n        f_opt = func(x_opt)\n        budget -= 1\n\n        while budget > 0:\n            x = np.random.normal(loc=x_center, scale=self.local_search_radius, size=self.dim)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            f = func(x)\n            budget -= 1\n\n            if f < f_opt:\n                f_opt = f\n                x_opt = x.copy()\n            \n            if budget <= 0:\n                break\n\n        return x_opt, f_opt", "configspace": "", "generation": 4, "feedback": "An exception occurred: 'AdaptiveDELocalSearch' object has no attribute 'F_initial'.", "error": "", "parent_ids": ["80987e19-6f35-4169-8129-d98d26da6152"], "operator": null, "metadata": {}}
{"id": "84d16c09-0dab-4b6c-8598-a25147a5eff1", "fitness": 0.4950728833857877, "name": "NeighborhoodDE_CMAES", "description": "Combines differential evolution with a neighborhood-based mutation and a self-adaptive covariance matrix adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass NeighborhoodDE_CMAES:\n    def __init__(self, budget=10000, dim=10, population_size=20, F=0.5, Cr=0.9, learning_rate=0.1, neighborhood_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.learning_rate = learning_rate\n        self.neighborhood_size = neighborhood_size\n        self.population = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.fitness = np.full(population_size, np.inf)\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.C = np.eye(dim)  # Covariance matrix for CMA-ES (Rank-1 update), initialized with identity\n        self.mean = np.zeros(dim)  # Mean for CMA-ES\n        self.evals = 0\n        self.tau = 1 / np.sqrt(2 * self.dim) # Learning rate for step size\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.population_size):\n            self.fitness[i] = func(self.population[i])\n            self.evals += 1\n\n            if self.fitness[i] < self.best_fitness:\n                self.best_fitness = self.fitness[i]\n                self.best_solution = self.population[i].copy()\n\n        while self.evals < self.budget:\n            for i in range(self.population_size):\n                # Neighborhood-based Differential Evolution\n                neighbors = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                best_neighbor_idx = neighbors[np.argmin(self.fitness[neighbors])]\n\n                idxs = [idx for idx in range(self.population_size) if idx not in [i, best_neighbor_idx]]\n                a, b = np.random.choice(idxs, 2, replace=False)\n                mutant = self.population[i] + self.F * (self.population[best_neighbor_idx] - self.population[a]) + self.F * (self.population[b] - self.population[i])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                f = func(trial)\n                self.evals += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial.copy()\n\n                    if f < self.best_fitness:\n                        self.best_fitness = f\n                        self.best_solution = self.population[i].copy()\n\n            # CMA-ES like update (self-adaptive)\n            diff = self.best_solution - self.mean\n            \n            # Update covariance matrix with a faster update rule and self-adaptive learning rate\n            self.C = (1 - self.learning_rate) * self.C + self.learning_rate * np.outer(diff, diff) / np.linalg.norm(diff)**2 if np.linalg.norm(diff) > 0 else self.C\n            self.learning_rate *= np.exp(self.tau * np.random.normal(0, 1))\n            self.mean = self.best_solution.copy()\n\n            if self.evals >= self.budget:\n                break\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 4, "feedback": "The algorithm NeighborhoodDE_CMAES scored 0.495 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d9784245-496f-4c34-bdba-5db51c113f0f"], "operator": null, "metadata": {"aucs": [0.12322489218977228, 0.4372601473444563, 0.30189727581670234, 0.19947299276443786, 0.935160094853724, 0.318703762358854, 0.8899042170839987, 0.32419856214761356, 0.48639140777602907, 0.5296326891602725, 0.48176940148158975, 0.9935897756016534, 0.33458077812030773, 0.23624262666421803, 0.7909869296367735, 0.33557781924247443, 0.6187707136309076, 0.8936959376139118, 0.19618239307402408, 0.4742152511540355]}}
{"id": "26adcc1b-fa0f-41a2-9bb7-048e61fe9102", "fitness": -Infinity, "name": "SelfOrganizingScouts", "description": "Self-organizing scouts with dynamic radius adjustment, where scouts explore the space and adapt their search radius based on local fitness landscape information.", "code": "import numpy as np\n\nclass SelfOrganizingScouts:\n    def __init__(self, budget=10000, dim=10, num_scouts=10, initial_radius=0.5, radius_decay=0.95, radius_increase=1.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_scouts = num_scouts\n        self.initial_radius = initial_radius\n        self.radius_decay = radius_decay\n        self.radius_increase = radius_increase\n        self.scouts = None\n        self.fitness = None\n        self.radius = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def initialize_scouts(self, func):\n        self.scouts = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_scouts, self.dim))\n        self.fitness = np.array([func(x) for x in self.scouts])\n        self.radius = np.full(self.num_scouts, self.initial_radius)\n        self.budget -= self.num_scouts\n\n        best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_idx]\n        self.x_opt = self.scouts[best_idx].copy()\n    \n    def scout_movement(self, func, i):\n        new_scout = self.scouts[i] + np.random.uniform(-self.radius[i], self.radius[i], size=self.dim)\n        new_scout = np.clip(new_scout, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_scout)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.scouts[i] = new_scout\n            self.fitness[i] = f_new\n            self.radius[i] *= self.radius_decay  # Reduce radius if better\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = new_scout.copy()\n\n        else:\n            self.radius[i] *= self.radius_increase # Increase radius if worse\n        \n        self.radius[i] = np.clip(self.radius[i], 1e-6, (func.bounds.ub - func.bounds.lb)/2) # Keep radius within bounds\n\n    def __call__(self, func):\n        self.initialize_scouts(func)\n\n        while self.budget > 0:\n            for i in range(self.num_scouts):\n                if self.budget <= 0:\n                    break\n                self.scout_movement(func, i)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["4f520cf7-0ee4-4719-8da1-f50563122d5b"], "operator": null, "metadata": {}}
{"id": "95cbeb23-6596-425c-bc24-2b2cf4b2c04b", "fitness": -Infinity, "name": "DE_GradientSearch", "description": "A hybrid algorithm combining Differential Evolution with a Gradient-based local search, adaptively switching between global exploration and local refinement based on the search progress.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DE_GradientSearch:\n    def __init__(self, budget=10000, dim=10, population_size=20, F=0.5, Cr=0.9, grad_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F\n        self.Cr = Cr\n        self.grad_prob = grad_prob  # Probability of performing gradient search\n        self.population = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.fitness = np.full(population_size, np.inf)\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.evals = 0\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.population_size):\n            self.fitness[i] = func(self.population[i])\n            self.evals += 1\n\n            if self.fitness[i] < self.best_fitness:\n                self.best_fitness = self.fitness[i]\n                self.best_solution = self.population[i].copy()\n\n        while self.evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                if len(idxs) >= 3:\n                  a, b, c = np.random.choice(idxs, 3, replace=False)\n                  mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                  mutant = np.clip(mutant, self.lb, self.ub)\n\n                  # Crossover\n                  trial = self.population[i].copy()\n                  for j in range(self.dim):\n                      if np.random.rand() < self.Cr:\n                          trial[j] = mutant[j]\n\n                  trial = np.clip(trial, self.lb, self.ub)\n\n                  f = func(trial)\n                  self.evals += 1\n\n                  if f < self.fitness[i]:\n                      self.fitness[i] = f\n                      self.population[i] = trial.copy()\n\n                      if f < self.best_fitness:\n                          self.best_fitness = f\n                          self.best_solution = self.population[i].copy()\n                else:\n                    f = self.fitness[i]\n\n\n                # Gradient-based local search\n                if np.random.rand() < self.grad_prob:\n                    bounds = [(self.lb, self.ub) for _ in range(self.dim)]\n                    res = minimize(func, self.population[i], method='L-BFGS-B', bounds=bounds, options={'maxiter': 5})  # Limited iterations\n                    \n                    if res.fun < self.fitness[i]:\n                        self.fitness[i] = res.fun\n                        self.population[i] = res.x.copy()\n                        self.evals += res.nfev \n\n                        if res.fun < self.best_fitness:\n                            self.best_fitness = res.fun\n                            self.best_solution = self.population[i].copy()\n                    \n                    if self.evals > self.budget:\n                      break\n\n            if self.evals >= self.budget:\n                break\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 5, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["f4e25a4e-d945-47ef-8d8b-19c5802e77db"], "operator": null, "metadata": {}}
{"id": "d890db02-09d0-4eb0-93a5-5c930a77df07", "fitness": -Infinity, "name": "DE_GP", "description": "A hybrid algorithm combining Differential Evolution with a Gaussian Process surrogate model to guide the search towards promising regions.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass DE_GP:\n    def __init__(self, budget=10000, dim=10, population_size=20, F=0.5, Cr=0.9, gp_n_restarts=3):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F\n        self.Cr = Cr\n        self.gp_n_restarts = gp_n_restarts\n        self.population = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.fitness = np.full(population_size, np.inf)\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.evals = 0\n        self.X = []  # Training data for GP (solutions evaluated)\n        self.y = []  # Training data for GP (function values)\n        self.gp = GaussianProcessRegressor(kernel=C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-3, 1e3)), n_restarts_optimizer=self.gp_n_restarts)\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.population_size):\n            self.fitness[i] = func(self.population[i])\n            self.evals += 1\n            self.X.append(self.population[i])\n            self.y.append(self.fitness[i])\n\n            if self.fitness[i] < self.best_fitness:\n                self.best_fitness = self.fitness[i]\n                self.best_solution = self.population[i].copy()\n        \n        self.X = np.array(self.X)\n        self.y = np.array(self.y)\n\n        while self.evals < self.budget:\n            # Train GP model\n            self.gp.fit(self.X, self.y)\n\n            for i in range(self.population_size):\n                # Differential Evolution part\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                # GP exploitation: Evaluate using GP's predicted value and uncertainty\n                trial_fitness_pred, trial_fitness_std = self.gp.predict(trial.reshape(1, -1), return_std=True)\n\n                # Exploration-exploitation balance: Probability of evaluating the true function\n                exploration_prob = 0.1 # Adjust as needed\n\n                if np.random.rand() < exploration_prob:\n                    f = func(trial)\n                    self.evals += 1\n\n                    self.X = np.vstack((self.X, trial))\n                    self.y = np.append(self.y, f)\n                    \n                    if f < self.fitness[i]:\n                        self.fitness[i] = f\n                        self.population[i] = trial.copy()\n\n                        if f < self.best_fitness:\n                            self.best_fitness = f\n                            self.best_solution = self.population[i].copy()\n\n                else:\n                    # Accept trial based on GP prediction\n                    if trial_fitness_pred[0] - trial_fitness_std[0] < self.fitness[i]:\n                        self.population[i] = trial.copy()\n\n\n            if self.evals >= self.budget:\n                break\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 5, "feedback": "An exception occurred: name 'GaussianProcessRegressor' is not defined.", "error": "", "parent_ids": ["f4e25a4e-d945-47ef-8d8b-19c5802e77db"], "operator": null, "metadata": {}}
{"id": "0ea34975-c033-4355-a645-a80e0c43c8cd", "fitness": -Infinity, "name": "AdaptiveDE_GradientSearch", "description": "A hybrid algorithm combining Differential Evolution with a Gradient-based local search, adaptively switching between global exploration and local refinement based on stagnation detection.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDE_GradientSearch:\n    def __init__(self, budget=10000, dim=10, population_size=20, F=0.5, Cr=0.9, local_search_prob=0.1, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F\n        self.Cr = Cr\n        self.local_search_prob = local_search_prob\n        self.stagnation_threshold = stagnation_threshold\n        self.population = np.random.uniform(-5, 5, size=(population_size, dim))\n        self.fitness = np.full(population_size, np.inf)\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.evals = 0\n        self.stagnation_counter = 0\n        self.last_best_fitness = np.inf\n\n    def __local_search(self, func, x0, bounds):\n        \"\"\"Performs a local search using L-BFGS-B.\"\"\"\n        res = minimize(func, x0, method='L-BFGS-B', bounds=bounds, options={'maxiter': 5})  # Limit iterations\n        return res.fun, res.x\n\n    def __call__(self, func):\n        bounds = [(func.bounds.lb, func.bounds.ub)] * self.dim\n\n        # Initial evaluation\n        for i in range(self.population_size):\n            self.fitness[i] = func(self.population[i])\n            self.evals += 1\n\n            if self.fitness[i] < self.best_fitness:\n                self.best_fitness = self.fitness[i]\n                self.best_solution = self.population[i].copy()\n\n        self.last_best_fitness = self.best_fitness\n\n        while self.evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution part\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                # Local search with probability\n                if np.random.rand() < self.local_search_prob:\n                    f, trial = self.__local_search(func, trial, bounds)\n                    self.evals += 5 # Approx func evals by local search.\n\n                else:\n                    f = func(trial)\n                    self.evals += 1\n                    \n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial.copy()\n\n                    if f < self.best_fitness:\n                        self.best_fitness = f\n                        self.best_solution = self.population[i].copy()\n                        self.stagnation_counter = 0 # Reset stagnation\n\n            # Stagnation check and adaptive local search probability\n            if self.best_fitness >= self.last_best_fitness:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.local_search_prob = min(1.0, self.local_search_prob + 0.1)  # Increase local search\n            else:\n                self.local_search_prob = max(0.1, self.local_search_prob - 0.05)  # Decrease local search\n\n            self.last_best_fitness = self.best_fitness\n\n            if self.evals >= self.budget:\n                break\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 5, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["f4e25a4e-d945-47ef-8d8b-19c5802e77db"], "operator": null, "metadata": {}}
{"id": "983370c0-f25c-47b9-be34-19d63374d242", "fitness": 0.16067948855585912, "name": "AdaptiveDERestart", "description": "An adaptive differential evolution algorithm that dynamically adjusts its mutation strategy based on the success rate of recent mutations, incorporating a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDERestart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_initial=0.5, Cr_initial=0.9, adapt_interval=50, success_threshold=0.2, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_initial\n        self.Cr = Cr_initial\n        self.adapt_interval = adapt_interval\n        self.success_threshold = success_threshold\n        self.restart_prob = restart_prob\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.success_count = 0\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n        self.eval_count += self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.success_count += 1\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n\n            # Adapt F and Cr every adapt_interval iterations\n            if self.eval_count % self.adapt_interval == 0:\n                success_rate = self.success_count / self.adapt_interval\n                if success_rate > self.success_threshold:\n                    self.F *= 0.9\n                    self.Cr *= 1.1\n                else:\n                    self.F *= 1.1\n                    self.Cr *= 0.9\n\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.Cr = np.clip(self.Cr, 0.1, 1.0)\n                self.success_count = 0\n                \n            # Restart mechanism\n            if np.random.rand() < self.restart_prob:\n                i = np.random.randint(0, self.pop_size)\n                self.pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                self.fitness[i] = func(self.pop[i])\n                self.budget -= 1\n                self.eval_count += 1\n                \n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.pop[i].copy()\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDERestart scored 0.161 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["aebd0af2-7156-46a2-9ef7-815a456e81e3"], "operator": null, "metadata": {"aucs": [0.32135897711171824, 0]}}
{"id": "c13bf825-d21a-47c1-b118-4b4740fc79c1", "fitness": 0.0, "name": "AdaptiveDEPopulationSize", "description": "An adaptive differential evolution algorithm that dynamically adjusts the population size based on the convergence rate and utilizes a weighted mutation strategy favoring better solutions.", "code": "import numpy as np\n\nclass AdaptiveDEPopulationSize:\n    def __init__(self, budget=10000, dim=10, pop_size_initial=50, pop_size_min=10, pop_size_max=100, F_initial=0.5, Cr=0.9, adapt_frequency=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_initial\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.F = F_initial\n        self.Cr = Cr\n        self.adapt_frequency = adapt_frequency\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.generation = 0\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Weighted Mutation\n                weights = np.exp(-np.abs(self.fitness - np.min(self.fitness)) / (np.max(self.fitness) - np.min(self.fitness) + 1e-8))\n                weights /= np.sum(weights)\n                \n                idxs = np.random.choice(self.pop_size, 3, replace=False, p=weights)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n            # Adapt Population Size\n            if self.generation % self.adapt_frequency == 0:\n                convergence_rate = np.std(self.fitness) / (np.mean(self.fitness) + 1e-8)\n                \n                if convergence_rate < 0.01:  # If converged, increase population\n                    self.pop_size = min(self.pop_size + 5, self.pop_size_max)\n                elif convergence_rate > 0.1: # If not converging, decrease population\n                    self.pop_size = max(self.pop_size - 5, self.pop_size_min)\n                \n                # Regenerate population if size changed\n                if self.pop_size != self.pop.shape[0]:\n                    new_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    \n                    # Carry over best solutions\n                    num_carry = min(self.pop_size, self.pop.shape[0])\n                    best_indices = np.argsort(self.fitness)[:num_carry]\n                    new_pop[:num_carry] = self.pop[best_indices]\n                    \n                    self.pop = new_pop\n                    self.fitness = np.array([func(x) for x in self.pop])\n                    self.budget -= (self.pop_size - num_carry) #Account for additional evals\n\n            # Adapt F and Cr (optional - can be added for further improvement)\n            self.F = np.random.normal(loc=0.5, scale=0.3)\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.Cr = np.random.uniform(0.5, 1.0)\n\n            self.generation += 1\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDEPopulationSize scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["063fe260-be60-46dc-a1e2-151b7fac625e"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "5b127e38-e64c-417e-90a0-1593fe8253b5", "fitness": 0.7684959751404643, "name": "AdaptiveDEMutateDiversity", "description": "Adaptive Differential Evolution with a modified mutation strategy that combines global exploration and local exploitation based on a diversity metric.", "code": "import numpy as np\n\nclass AdaptiveDEMutateDiversity:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population and fitness\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            # Calculate population diversity (standard deviation along each dimension)\n            diversity = np.std(self.pop, axis=0)\n            mean_diversity = np.mean(diversity)\n\n            for i in range(self.pop_size):\n                # Mutation strategy based on diversity\n                if mean_diversity > 0.1:  # High diversity: global exploration\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n                else:  # Low diversity: local exploitation around the best\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[idxs]\n                    mutant = self.x_opt + self.F * (x_r1 - x_r2)\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDEMutateDiversity scored 0.768 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["aebd0af2-7156-46a2-9ef7-815a456e81e3"], "operator": null, "metadata": {"aucs": [0.5436158509520987, 0.7051563195324607, 0.8156445101977203, 0.8798576958496154, 0.8511848621443008, 0.8504264334888139, 0.7104927452192863, 0.759278786949318, 0.8317459054021394, 0.7389194219634493, 0.8629102185466184, 0.9980130602957473, 0.7208294854100536, 0.7935593018896299, 0.9194862746264417, 0.8489304929385779, 0.4339182022650627, 0.8862181600918658, 0.5250142618952327, 0.694717513150853]}}
{"id": "5a203846-46a2-4bfb-9896-bab877ad91f8", "fitness": 0.4205472478289146, "name": "DiversityAdaptiveDE", "description": "Differential Evolution with a dynamically adjusted F parameter based on population diversity and a tournament selection for increased exploration.", "code": "import numpy as np\n\nclass DiversityAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.Cr = Cr\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = None\n        self.fitness = None\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_idx]\n        self.x_opt = self.pop[best_idx].copy()\n\n        while self.budget > 0:\n            # Calculate diversity (standard deviation) for each dimension\n            diversity = np.std(self.pop, axis=0)\n            \n            # Dynamically adjust F based on diversity; higher diversity, higher F (more exploration)\n            F = 0.1 + 0.9 * np.mean(diversity) / (func.bounds.ub - func.bounds.lb)  # Scale diversity to [0, 1]\n\n            for i in range(self.pop_size):\n                # Tournament Selection\n                tournament_size = 3\n                candidates = np.random.choice(self.pop_size, tournament_size, replace=False)\n                winner = candidates[np.argmin(self.fitness[candidates])]\n\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                \n                # Mutation\n                mutant = self.pop[winner] + F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm DiversityAdaptiveDE scored 0.421 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4f520cf7-0ee4-4719-8da1-f50563122d5b"], "operator": null, "metadata": {"aucs": [0.22490141791050522, 0.335687367263623, 0.3714228850366841, 0.512565611309592, 0.2887527925833079, 0.5380702248344362, 0.357649810938647, 0.37004914646999876, 0.36855800878384026, 0.2854174123334581, 0.43006286276600303, 0.9981464633913262, 0.292477881940961, 0.3532424352714978, 0.74679913120823, 0.37366400585062765, 0.2878519974655913, 0.48845576844301186, 0.2916699028394292, 0.49549982993752273]}}
{"id": "bf2fbc24-1bc0-4122-91ad-a4dfa5aef599", "fitness": 0.640348665237621, "name": "MirroredDualPopulationDE", "description": "A differential evolution variant that uses a mirrored population to enhance exploration and exploitation, combining information from both the original and mirrored search spaces.", "code": "import numpy as np\n\nclass MirroredDualPopulationDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, exploit_ratio=0.3, mirror_ratio = 0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.exploit_size = int(pop_size * exploit_ratio)\n        self.explore_size = pop_size - self.exploit_size\n        self.F = F\n        self.Cr = Cr\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.mirror_ratio = mirror_ratio #probability to mirror an individual\n\n    def __call__(self, func):\n        # Initialize populations\n        self.explore_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.explore_size, self.dim))\n        self.exploit_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.exploit_size, self.dim))\n        \n        # Initial evaluation\n        explore_fitness = np.array([func(x) for x in self.explore_pop])\n        exploit_fitness = np.array([func(x) for x in self.exploit_pop])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_explore_idx = np.argmin(explore_fitness)\n        best_exploit_idx = np.argmin(exploit_fitness)\n\n        if explore_fitness[best_explore_idx] < exploit_fitness[best_exploit_idx]:\n            self.f_opt = explore_fitness[best_explore_idx]\n            self.x_opt = self.explore_pop[best_explore_idx].copy()\n        else:\n            self.f_opt = exploit_fitness[best_exploit_idx]\n            self.x_opt = self.exploit_pop[best_exploit_idx].copy()\n\n        while self.budget > 0:\n            # Explore population DE\n            for i in range(self.explore_size):\n\n                #Mirror individual with some probability\n                if np.random.rand() < self.mirror_ratio:\n                    mirrored_x = - self.explore_pop[i]\n                    mirrored_x = np.clip(mirrored_x, func.bounds.lb, func.bounds.ub)\n                else:\n                    mirrored_x = self.explore_pop[i] #Otherwise, use original individual\n                \n                idxs = np.random.choice(self.explore_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.explore_pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, mirrored_x) #Use mirrored individual in crossover\n                f_trial = func(trial)\n                self.budget -= 1\n                if f_trial < explore_fitness[i]:\n                    self.explore_pop[i] = trial\n                    explore_fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n                    \n            if self.budget <= 0:\n                break\n            # Exploit population DE - biased towards x_opt\n            for i in range(self.exploit_size):\n\n                #Mirror individual with some probability\n                if np.random.rand() < self.mirror_ratio:\n                    mirrored_x = - self.exploit_pop[i]\n                    mirrored_x = np.clip(mirrored_x, func.bounds.lb, func.bounds.ub)\n                else:\n                    mirrored_x = self.exploit_pop[i] #Otherwise, use original individual\n                    \n                idxs = np.random.choice(self.exploit_size, 2, replace=False)\n                x_r1, x_r2 = self.exploit_pop[idxs]\n                mutant = self.x_opt + self.F * (x_r1 - x_r2) # Bias towards x_opt\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, mirrored_x) #Use mirrored individual in crossover\n                f_trial = func(trial)\n                self.budget -= 1\n                if f_trial < exploit_fitness[i]:\n                    self.exploit_pop[i] = trial\n                    exploit_fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                        \n                if self.budget <= 0:\n                    break\n            \n            # Migrate individuals:  Replace worst explore with best exploit\n            worst_explore_idx = np.argmax(explore_fitness)\n            best_exploit_idx = np.argmin(exploit_fitness)\n            \n            if exploit_fitness[best_exploit_idx] < explore_fitness[worst_explore_idx]:\n                self.explore_pop[worst_explore_idx] = self.exploit_pop[best_exploit_idx].copy()\n                explore_fitness[worst_explore_idx] = exploit_fitness[best_exploit_idx]\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm MirroredDualPopulationDE scored 0.640 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4f520cf7-0ee4-4719-8da1-f50563122d5b"], "operator": null, "metadata": {"aucs": [0.20447369729196796, 0.2265523426328151, 0.8027038623472841, 0.9178922209683068, 0.8548071411794349, 0.8579622985563183, 0.3204242262626672, 0.7644635277281127, 0.8262630839419405, 0.2338033679019461, 0.9077204772812779, 0.9879476990427263, 0.40133175492300577, 0.3642033248302706, 0.943773595946553, 0.8761888902110639, 0.578823738770021, 0.8967602362164891, 0.32748372005298565, 0.5133940986672346]}}
{"id": "fc7f0cfa-a316-4864-bd38-0f4d861adbf9", "fitness": 0.8431733748501034, "name": "DynamicPopulationDE", "description": "A differential evolution variant employing a dynamic population size adjustment based on the success rate of each subpopulation, encouraging better resource allocation between exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicPopulationDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, initial_exploit_ratio=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.exploit_ratio = initial_exploit_ratio\n        self.explore_size = int(pop_size * (1 - self.exploit_ratio))\n        self.exploit_size = pop_size - self.explore_size\n        self.F = F\n        self.Cr = Cr\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.adaptation_rate = adaptation_rate  # How quickly the population ratio adapts\n        self.explore_success_rate = 0.0\n        self.exploit_success_rate = 0.0\n\n    def __call__(self, func):\n        # Initialize populations\n        self.explore_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.explore_size, self.dim))\n        self.exploit_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.exploit_size, self.dim))\n        \n        # Initial evaluation\n        explore_fitness = np.array([func(x) for x in self.explore_pop])\n        exploit_fitness = np.array([func(x) for x in self.exploit_pop])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_explore_idx = np.argmin(explore_fitness)\n        best_exploit_idx = np.argmin(exploit_fitness)\n\n        if explore_fitness[best_explore_idx] < exploit_fitness[best_exploit_idx]:\n            self.f_opt = explore_fitness[best_explore_idx]\n            self.x_opt = self.explore_pop[best_explore_idx].copy()\n        else:\n            self.f_opt = exploit_fitness[best_exploit_idx]\n            self.x_opt = self.exploit_pop[best_exploit_idx].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            explore_successes = 0\n            exploit_successes = 0\n\n            # Explore population DE\n            for i in range(self.explore_size):\n                idxs = np.random.choice(self.explore_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.explore_pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.explore_pop[i])\n                f_trial = func(trial)\n                self.budget -= 1\n                if f_trial < explore_fitness[i]:\n                    self.explore_pop[i] = trial\n                    explore_fitness[i] = f_trial\n                    explore_successes += 1\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n                    \n            if self.budget <= 0:\n                break\n            # Exploit population DE - biased towards x_opt\n            for i in range(self.exploit_size):\n                idxs = np.random.choice(self.exploit_size, 2, replace=False)\n                x_r1, x_r2 = self.exploit_pop[idxs]\n                mutant = self.x_opt + self.F * (x_r1 - x_r2) # Bias towards x_opt\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.exploit_pop[i])\n                f_trial = func(trial)\n                self.budget -= 1\n                if f_trial < exploit_fitness[i]:\n                    self.exploit_pop[i] = trial\n                    exploit_fitness[i] = f_trial\n                    exploit_successes += 1\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                        \n                if self.budget <= 0:\n                    break\n            \n            # Adapt population sizes based on success rates\n            self.explore_success_rate = explore_successes / self.explore_size\n            self.exploit_success_rate = exploit_successes / self.exploit_size\n\n            if self.explore_success_rate > self.exploit_success_rate:\n                # Increase explore, decrease exploit\n                self.exploit_ratio -= self.adaptation_rate * (1 - self.exploit_ratio)\n            else:\n                # Increase exploit, decrease explore\n                self.exploit_ratio += self.adaptation_rate * self.exploit_ratio\n            \n            self.exploit_ratio = np.clip(self.exploit_ratio, 0.1, 0.9)  # Keep ratio within bounds\n            new_exploit_size = int(self.pop_size * self.exploit_ratio)\n            new_explore_size = self.pop_size - new_exploit_size\n            \n            # Resize populations: simple reallocation (can be improved with more sophisticated migration)\n            if new_explore_size != self.explore_size or new_exploit_size != self.exploit_size:\n                # Resize populations (crude reallocation)\n                # Combine populations\n                combined_pop = np.vstack((self.explore_pop, self.exploit_pop))\n                combined_fitness = np.concatenate((explore_fitness, exploit_fitness))\n\n                # Sort by fitness\n                sorted_indices = np.argsort(combined_fitness)\n                combined_pop = combined_pop[sorted_indices]\n                combined_fitness = combined_fitness[sorted_indices]\n\n                # Split into new populations\n                self.explore_pop = combined_pop[:new_explore_size]\n                self.exploit_pop = combined_pop[new_explore_size:]\n                explore_fitness = combined_fitness[:new_explore_size]\n                exploit_fitness = combined_fitness[new_explore_size:]\n\n                # If the new sizes are bigger than current populations, fill with random individuals\n                if new_explore_size > self.explore_pop.shape[0]:\n                   num_new_individuals = new_explore_size - self.explore_pop.shape[0]\n                   new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new_individuals, self.dim))\n                   self.explore_pop = np.vstack((self.explore_pop, new_individuals))\n                   explore_fitness = np.concatenate((explore_fitness, np.array([func(x) for x in new_individuals])))\n                   self.budget -= num_new_individuals\n                if new_exploit_size > self.exploit_pop.shape[0]:\n                   num_new_individuals = new_exploit_size - self.exploit_pop.shape[0]\n                   new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new_individuals, self.dim))\n                   self.exploit_pop = np.vstack((self.exploit_pop, new_individuals))\n                   exploit_fitness = np.concatenate((exploit_fitness, np.array([func(x) for x in new_individuals])))\n                   self.budget -= num_new_individuals\n                \n                self.explore_size = new_explore_size\n                self.exploit_size = new_exploit_size\n\n            # Ensure populations are not empty: if so fill with random individuals\n            if self.explore_size == 0:\n                self.explore_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                explore_fitness = np.array([func(x) for x in self.explore_pop])\n                self.explore_size = self.pop_size\n                self.exploit_size = 0\n                self.budget -= self.pop_size\n            if self.exploit_size == 0:\n                self.exploit_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                exploit_fitness =  np.array([func(x) for x in self.exploit_pop])\n                self.exploit_size = self.pop_size\n                self.explore_size = 0\n                self.budget -= self.pop_size\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm DynamicPopulationDE scored 0.843 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4f520cf7-0ee4-4719-8da1-f50563122d5b"], "operator": null, "metadata": {"aucs": [0.2692557556990629, 0.8567057405785188, 0.9008606673175029, 0.9469888047824857, 0.9073939137114833, 0.9218564846697891, 0.8888904292818385, 0.6648160433486568, 0.9031725913029498, 0.899480938700964, 0.9330059916915304, 0.9930627629352403, 0.8299497288256164, 0.902153577173924, 0.9579578208788148, 0.9205640690366751, 0.8486951142348732, 0.9349831644420858, 0.8725479462776969, 0.5111259521123587]}}
{"id": "f4aa9959-2068-4565-98ce-fad71680dcd7", "fitness": 0.46203859576871587, "name": "SelfOrganizingDE", "description": "A self-organizing algorithm that dynamically adjusts mutation strength and crossover probability based on individual success rates, incorporating a local search operator triggered by stagnation.", "code": "import numpy as np\n\nclass SelfOrganizingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, learning_rate=0.1, stagnation_threshold=50, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = np.full(pop_size, F_init)\n        self.Cr = np.full(pop_size, Cr_init)\n        self.learning_rate = learning_rate\n        self.stagnation_threshold = stagnation_threshold\n        self.local_search_radius = local_search_radius\n        self.pop = None\n        self.fitness = None\n        self.success_counts = np.zeros(pop_size)\n        self.stagnation_counters = np.zeros(pop_size)\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F[i] * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr[i]\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.success_counts[i] += 1\n                    self.stagnation_counters[i] = 0\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update F and Cr based on success\n                    self.F[i] = np.clip(self.F[i] + self.learning_rate * (1 - self.F[i]), 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] + self.learning_rate * (1 - self.Cr[i]), 0.1, 1.0)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    self.stagnation_counters[i] += 1\n                    # Reduce F and Cr if no improvement\n                    self.F[i] = np.clip(self.F[i] - self.learning_rate * self.F[i], 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] - self.learning_rate * self.Cr[i], 0.1, 1.0)\n\n                # Local Search Operator (triggered by stagnation)\n                if self.stagnation_counters[i] > self.stagnation_threshold:\n                    # Apply local search around the individual\n                    neighbor = self.pop[i] + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                    neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n                    f_neighbor = func(neighbor)\n                    self.budget -= 1\n\n                    if f_neighbor < self.fitness[i]:\n                        self.pop[i] = neighbor\n                        self.fitness[i] = f_neighbor\n                        self.stagnation_counters[i] = 0\n                        if f_neighbor < self.f_opt:\n                            self.f_opt = f_neighbor\n                            self.x_opt = neighbor.copy()\n                    else:\n                        self.stagnation_counters[i] += 1 # Continue counting stagnation\n\n                if self.budget <= 0:\n                    break\n\n            # Reset success counts at each generation\n            self.success_counts[:] = 0\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm SelfOrganizingDE scored 0.462 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["aebd0af2-7156-46a2-9ef7-815a456e81e3"], "operator": null, "metadata": {"aucs": [0.15608526098997666, 0.30752745760838074, 0.43917169801571554, 0.48003571820863655, 0.40291850550767927, 0.6406487152378357, 0.3413706387511335, 0.43933415719803526, 0.5001562607213839, 0.24499783679770581, 0.4378200033389573, 0.9981201423498983, 0.25710114057546496, 0.39304531619164607, 0.7151156105905301, 0.7033431893281898, 0.3601849304902748, 0.663995771284062, 0.2493399566644955, 0.5104596055243158]}}
{"id": "19625d58-7106-4a47-a6da-af94433dc19b", "fitness": -Infinity, "name": "RepulsiveAdaptiveDE", "description": "An adaptive differential evolution algorithm with a repulsive factor that pushes solutions away from crowded regions to enhance exploration and maintain diversity.", "code": "import numpy as np\n\nclass RepulsiveAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_base=0.5, Cr_base=0.9, repulsive_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_base = F_base\n        self.Cr_base = Cr_base\n        self.repulsive_factor = repulsive_factor\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        self.population = None\n        self.fitness = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_idx]\n        self.x_opt = self.population[best_idx].copy()\n\n    def calculate_crowding_distance(self):\n        # Normalize population within [0, 1] for each dimension\n        normalized_population = (self.population - np.min(self.population, axis=0)) / (np.max(self.population, axis=0) - np.min(self.population, axis=0) + 1e-8)  # Avoid division by zero\n        \n        crowding_distances = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            distance = 0\n            for j in range(self.pop_size):\n                if i != j:\n                    distance += np.linalg.norm(normalized_population[i] - normalized_population[j])\n            crowding_distances[i] = distance\n        return crowding_distances\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            crowding_distances = self.calculate_crowding_distance()\n            \n            for i in range(self.pop_size):\n                # Adaptive F and Cr\n                F = self.F_base * np.random.uniform(0.5, 1.5)\n                Cr = self.Cr_base * np.random.uniform(0.5, 1.5)\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Repulsive force calculation\n                repulsive_force = np.zeros(self.dim)\n                for j in range(self.pop_size):\n                    if i != j:\n                        direction = self.population[i] - self.population[j]\n                        distance = np.linalg.norm(direction)\n                        if distance > 0:\n                            repulsive_force += direction / (distance + 1e-8)  # Add a small constant to avoid division by zero\n                repulsive_force = repulsive_force / (self.pop_size - 1 + 1e-8)  # Normalize\n\n                mutant = x_r1 + F * (x_r2 - x_r3) + self.repulsive_factor * repulsive_force * crowding_distances[i]\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                cross_mask = np.random.rand(self.dim) < Cr\n                trial = np.where(cross_mask, mutant, self.population[i])\n\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occurred: Evaluation timed out after 60 seconds..", "error": "", "parent_ids": ["4f520cf7-0ee4-4719-8da1-f50563122d5b"], "operator": null, "metadata": {}}
{"id": "c89e21c4-42b7-4366-a47b-ae51e74913cb", "fitness": -Infinity, "name": "AdaptiveDEMutationRestart", "description": "A differential evolution strategy with a dynamically adjusted mutation factor based on the population's diversity and progress, coupled with a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDEMutationRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_initial=0.5, Cr=0.9, restart_trigger=0.1, diversity_threshold=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_initial\n        self.Cr = Cr\n        self.restart_trigger = restart_trigger  # Percentage of budget remaining to trigger restart\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = None\n        self.fitness = None\n        self.initial_F = F_initial\n\n    def __call__(self, func):\n        # Initialize population\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        # Find initial best\n        best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_idx]\n        self.x_opt = self.population[best_idx].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            # Adaptive F based on population diversity\n            diversity = self.calculate_diversity()\n            if diversity > self.diversity_threshold:\n                self.F = self.initial_F  # High diversity, maintain initial F\n            else:\n                self.F = self.initial_F + 0.5  # Low diversity, increase F for exploration\n            self.F = np.clip(self.F, 0.1, 1.0)\n\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                \n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.population[i])\n\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n            \n            # Restart mechanism\n            if self.budget <= self.restart_trigger * 10000: # restart_trigger is the percentage of initial budget\n                # Re-initialize population around current best solution with shrinking radius\n                radius = 0.1 * (func.bounds.ub - func.bounds.lb) * (self.budget / (self.restart_trigger * 10000)) # Shrinking radius\n                new_population = np.random.uniform(np.maximum(func.bounds.lb, self.x_opt - radius), np.minimum(func.bounds.ub, self.x_opt + radius), size=(self.pop_size, self.dim))\n\n                new_fitness = np.array([func(x) for x in new_population])\n                self.budget -= self.pop_size\n\n                # Combine old and new populations, keep the best\n                combined_population = np.vstack((self.population, new_population))\n                combined_fitness = np.concatenate((self.fitness, new_fitness))\n                \n                sorted_indices = np.argsort(combined_fitness)[:self.pop_size] # Keep top pop_size\n                self.population = combined_population[sorted_indices]\n                self.fitness = combined_fitness[sorted_indices]\n                \n                best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.population[best_idx].copy()\n\n            if self.budget <= 0:\n                break\n        return self.f_opt, self.x_opt\n\n    def calculate_diversity(self):\n        # Calculate the average distance of each individual from the population mean\n        mean_position = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - mean_position, axis=1)\n        diversity = np.mean(distances) / (func.bounds.ub - func.bounds.lb)  # Normalize by search space range\n        return diversity", "configspace": "", "generation": 6, "feedback": "An exception occurred: name 'func' is not defined.", "error": "", "parent_ids": ["fc7f0cfa-a316-4864-bd38-0f4d861adbf9"], "operator": null, "metadata": {}}
{"id": "f7dfcb2a-ecc6-4eed-a38b-a2aaf80769c3", "fitness": -Infinity, "name": "AdaptiveDEHistoryRestart", "description": "An adaptive Differential Evolution algorithm with a history-based mutation strategy and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDEHistoryRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, history_length=10, restart_threshold=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.history_length = history_length\n        self.restart_threshold = restart_threshold\n        self.fitness_history = []\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_idx]\n        self.x_opt = self.pop[best_idx].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_pop = np.zeros_like(self.pop)\n            new_fitness = np.zeros_like(self.fitness)\n\n            for i in range(self.pop_size):\n                # History-based mutation\n                if len(self.fitness_history) > 0:\n                    # Select best individual from recent history with probability proportional to fitness improvement\n                    fitness_improvements = np.diff(self.fitness_history)\n                    probs = np.maximum(fitness_improvements, 0)  # Only positive improvements\n                    if np.sum(probs) > 0:\n                        probs /= np.sum(probs)\n                        history_idx = np.random.choice(len(self.fitness_history) - 1, p=probs) # Prevent index error\n                        x_best_history = self.pop[np.argmin(self.fitness_history[history_idx])]\n                        \n                        idxs = np.random.choice(self.pop_size, 2, replace=False)\n                        x_r1, x_r2 = self.pop[idxs]\n                        mutant = x_best_history + self.F * (x_r1 - x_r2)\n                    else: # If no improvements\n                         idxs = np.random.choice(self.pop_size, 3, replace=False)\n                         x_r1, x_r2, x_r3 = self.pop[idxs]\n                         mutant = x_r1 + self.F * (x_r2 - x_r3)\n                else: # If no history\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n                \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    new_pop[i] = trial\n                    new_fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    new_pop[i] = self.pop[i]\n                    new_fitness[i] = self.fitness[i]\n                \n                if self.budget <= 0:\n                    break\n\n            self.pop = new_pop\n            self.fitness = new_fitness\n\n            # Restart mechanism: if no improvement for restart_threshold generations, reinitialize\n            self.fitness_history.append(self.fitness.copy())\n            if len(self.fitness_history) > self.history_length:\n                self.fitness_history.pop(0)\n\n            if len(self.fitness_history) == self.history_length:\n                best_fitness_history = [np.min(f) for f in self.fitness_history]\n                if np.std(best_fitness_history) < 1e-6:  #Stagnation: low standard deviation in best fitness\n                     # Reinitialize a portion of the population\n                     num_reinitialize = int(self.pop_size * 0.5)\n                     idx_reinitialize = np.random.choice(self.pop_size, num_reinitialize, replace=False)\n                     self.pop[idx_reinitialize] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reinitialize, self.dim))\n                     self.fitness[idx_reinitialize] = np.array([func(x) for x in self.pop[idx_reinitialize]])\n                     self.budget -= num_reinitialize\n                     \n                     best_idx = np.argmin(self.fitness)\n                     self.f_opt = self.fitness[best_idx]\n                     self.x_opt = self.pop[best_idx].copy()\n                     self.fitness_history = []\n                     \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occurred: a must be greater than 0 unless no samples are taken.", "error": "", "parent_ids": ["fc7f0cfa-a316-4864-bd38-0f4d861adbf9"], "operator": null, "metadata": {}}
{"id": "f771ba61-82d0-4476-b6e1-a136af81f779", "fitness": 0.13344807228718386, "name": "AdaptiveDERestartLocalSearch", "description": "Adaptive Differential Evolution with a restart mechanism based on population diversity and a local search operator triggered when diversity falls below a threshold.", "code": "import numpy as np\n\nclass AdaptiveDERestartLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, diversity_threshold=0.1, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.diversity_threshold = diversity_threshold\n        self.local_search_probability = local_search_probability\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = None\n        self.fitness = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_idx]\n        self.x_opt = self.population[best_idx].copy()\n\n    def calculate_diversity(self):\n        \"\"\"Calculates the average pairwise Euclidean distance in the population.\"\"\"\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(self.population[i] - self.population[j]))\n        return np.mean(distances) if distances else 0.0\n\n    def local_search(self, x, func):\n        \"\"\"Performs a simple local search around x.\"\"\"\n        delta = np.random.uniform(-0.1, 0.1, size=self.dim)  # Small perturbation\n        x_new = x + delta\n        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n        f_new = func(x_new)\n        self.budget -= 1\n        if f_new < self.f_opt:\n            self.f_opt = f_new\n            self.x_opt = x_new.copy()\n        return x_new, f_new\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            diversity = self.calculate_diversity()\n\n            if diversity < self.diversity_threshold:\n                # Restart the population to introduce more diversity\n                self.initialize_population(func)\n                continue\n\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                \n                # Adaptive F: Adjust F based on the current best fitness\n                F_adaptive = self.F * (1.0 + 0.5 * np.random.randn())  # Add some noise to F\n                F_adaptive = np.clip(F_adaptive, 0.1, 1.0)  # Keep F within reasonable bounds\n\n                mutant = x_r1 + F_adaptive * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.population[i])\n                \n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                \n                #Local search around the best solution with some probability\n                if np.random.rand() < self.local_search_probability:\n                    self.x_opt, self.f_opt = self.local_search(self.x_opt, func)\n\n                if self.budget <= 0:\n                    break\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDERestartLocalSearch scored 0.133 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["bf2fbc24-1bc0-4122-91ad-a4dfa5aef599"], "operator": null, "metadata": {"aucs": [0.2668961445743677, 0]}}
{"id": "c109ac7a-7423-425c-8d2b-c819015fadfe", "fitness": 0.0929631891004849, "name": "AgingSelfOrganizingDE", "description": "Implements a self-organizing differential evolution with a dynamically adjusted population size and aging mechanism to promote exploration and exploitation balance.", "code": "import numpy as np\n\nclass AgingSelfOrganizingDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, F_init=0.5, Cr_init=0.9, learning_rate=0.1, stagnation_threshold=50, local_search_radius=0.1, age_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_init = pop_size_init\n        self.pop_size = pop_size_init  # Dynamic population size\n        self.F = np.full(pop_size_init, F_init)\n        self.Cr = np.full(pop_size_init, Cr_init)\n        self.learning_rate = learning_rate\n        self.stagnation_threshold = stagnation_threshold\n        self.local_search_radius = local_search_radius\n        self.age_threshold = age_threshold\n        self.pop = None\n        self.fitness = None\n        self.ages = None # Track the age of each individual\n        self.success_counts = np.zeros(pop_size_init)\n        self.stagnation_counters = np.zeros(pop_size_init)\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.ages = np.zeros(self.pop_size) # Initialize ages\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F[i] * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr[i]\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.success_counts[i] += 1\n                    self.stagnation_counters[i] = 0\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    self.ages[i] = 0  # Reset age upon improvement\n\n                    # Update F and Cr based on success\n                    self.F[i] = np.clip(self.F[i] + self.learning_rate * (1 - self.F[i]), 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] + self.learning_rate * (1 - self.Cr[i]), 0.1, 1.0)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    self.stagnation_counters[i] += 1\n                    self.ages[i] += 1  # Increment age\n                    # Reduce F and Cr if no improvement\n                    self.F[i] = np.clip(self.F[i] - self.learning_rate * self.F[i], 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] - self.learning_rate * self.Cr[i], 0.1, 1.0)\n\n                # Local Search Operator (triggered by stagnation)\n                if self.stagnation_counters[i] > self.stagnation_threshold:\n                    # Apply local search around the individual\n                    neighbor = self.pop[i] + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                    neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n                    f_neighbor = func(neighbor)\n                    self.budget -= 1\n\n                    if f_neighbor < self.fitness[i]:\n                        self.pop[i] = neighbor\n                        self.fitness[i] = f_neighbor\n                        self.stagnation_counters[i] = 0\n                        self.ages[i] = 0 #Reset age upon improvement from local search\n\n                        if f_neighbor < self.f_opt:\n                            self.f_opt = f_neighbor\n                            self.x_opt = neighbor.copy()\n                    else:\n                        self.stagnation_counters[i] += 1 # Continue counting stagnation\n                        self.ages[i] += 1 # Increment age\n\n                if self.budget <= 0:\n                    break\n\n            # Reset success counts at each generation\n            self.success_counts[:] = 0\n\n            # Aging Mechanism: Replace old individuals with new random ones\n            for i in range(self.pop_size):\n                if self.ages[i] > self.age_threshold:\n                    self.pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    self.fitness[i] = func(self.pop[i])\n                    self.budget -= 1\n                    self.ages[i] = 0  # Reset age\n                    self.stagnation_counters[i] = 0\n\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.pop[i].copy()\n\n            # Dynamic population size adjustment (example, keep it simple)\n            if np.mean(self.success_counts) > 0.2 and self.pop_size < 2*self.pop_size_init: #If enough success, increase population\n                self.pop_size = min(2*self.pop_size_init, self.pop_size + 5) #Increment population size by 5, up to double the initial size.\n                #Resize arrays: Careful here, only append at the end!\n                self.pop = np.vstack((self.pop, np.random.uniform(func.bounds.lb, func.bounds.ub, size=(5, self.dim)))) #Add 5 new individuals\n                self.fitness = np.concatenate((self.fitness, np.array([func(x) for x in self.pop[-5:]]))) #Evaluate new individuals\n                self.ages = np.concatenate((self.ages, np.zeros(5))) #Initialize ages to 0.\n                self.success_counts = np.concatenate((self.success_counts, np.zeros(5)))\n                self.stagnation_counters = np.concatenate((self.stagnation_counters, np.zeros(5)))\n                self.budget -= 5\n\n            elif np.mean(self.success_counts) < 0.05 and self.pop_size > self.pop_size_init: #If not enough success, reduce population\n                self.pop_size = max(self.pop_size_init, self.pop_size - 5) #Decrement population size by 5, down to initial size.\n\n                #Remove the worst individuals.\n                worst_indices = np.argsort(self.fitness)[-5:] #Find indices of worst individuals\n                keep_indices = np.array([i for i in range(len(self.fitness)) if i not in worst_indices])\n                self.pop = self.pop[keep_indices]\n                self.fitness = self.fitness[keep_indices]\n                self.ages = self.ages[keep_indices]\n                self.success_counts = self.success_counts[keep_indices]\n                self.stagnation_counters = self.stagnation_counters[keep_indices]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AgingSelfOrganizingDE scored 0.093 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f4aa9959-2068-4565-98ce-fad71680dcd7"], "operator": null, "metadata": {"aucs": [0.1859263782009698, 0]}}
{"id": "1b87fa1a-5ae7-4d97-90f0-b33b60caefd1", "fitness": 0.3271329870903987, "name": "AdaptiveDEOrthogonal", "description": "Differential Evolution with a self-adaptive mutation strategy based on fitness improvement and orthogonal learning for efficient search.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonal:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, orthogonal_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_init = F_init\n        self.Cr_init = Cr_init\n        self.orthogonal_trials = orthogonal_trials\n        self.pop = None\n        self.fitness = None\n        self.F = None\n        self.Cr = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population, fitness, F, and Cr\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.F = np.full(self.pop_size, self.F_init)\n        self.Cr = np.full(self.pop_size, self.Cr_init)\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive F and Cr\n                if np.random.rand() < 0.1:  # Exploration: Randomly adjust F and Cr\n                    self.F[i] = np.random.uniform(0.1, 0.9)\n                    self.Cr[i] = np.random.uniform(0.1, 0.9)\n                else:  # Exploitation: Fine-tune based on past success (simplified)\n                    if self.fitness[i] < np.mean(self.fitness):\n                        self.F[i] *= np.random.uniform(0.9, 1.1)  # Adjust F slightly\n                        self.Cr[i] *= np.random.uniform(0.9, 1.1)  # Adjust Cr slightly\n                    self.F[i] = np.clip(self.F[i], 0.1, 0.9)\n                    self.Cr[i] = np.clip(self.Cr[i], 0.1, 0.9)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F[i] * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr[i]\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Orthogonal Learning\n                best_trial = trial\n                f_best_trial = np.Inf\n                for _ in range(self.orthogonal_trials):\n                    orthogonal_trial = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    f_orthogonal_trial = func(orthogonal_trial)\n                    self.budget -= 1\n                    if f_orthogonal_trial < f_best_trial:\n                        f_best_trial = f_orthogonal_trial\n                        best_trial = orthogonal_trial\n                    if self.budget <= 0:\n                        break\n                if self.budget <= 0:\n                    break\n\n                # Evaluation of original trial\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection (compare both trial and orthogonal)\n                if f_best_trial < f_trial and f_best_trial < self.fitness[i]:\n                    self.pop[i] = best_trial\n                    self.fitness[i] = f_best_trial\n                    if f_best_trial < self.f_opt:\n                        self.f_opt = f_best_trial\n                        self.x_opt = best_trial.copy()\n\n                elif f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDEOrthogonal scored 0.327 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5b127e38-e64c-417e-90a0-1593fe8253b5"], "operator": null, "metadata": {"aucs": [0.13530169367907796, 0.20032256545142735, 0.3087706580452736, 0.327530560593154, 0.23955204051467371, 0.31125805277845875, 0.27321465665233713, 0.2799025806893515, 0.2534010050969331, 0.17564676055898365, 0.27543144927697716, 0.9890200844801489, 0.2644523273182452, 0.24745150993347154, 0.6459242002139196, 0.32474531265374784, 0.2790015465005604, 0.362429671420212, 0.1740874271147984, 0.47521563883622175]}}
{"id": "75ce44d3-feaa-468c-92e1-dd728fe65e4c", "fitness": 0.38386173941258594, "name": "AdaptiveDEStagnation", "description": "A differential evolution strategy with a dynamically adjusted mutation factor based on the population's stagnation and the individual's improvement rate.", "code": "import numpy as np\n\nclass AdaptiveDEStagnation(object):\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_initial=0.5, Cr=0.9, stagnation_threshold=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_initial = F_initial\n        self.Cr = Cr\n        self.stagnation_threshold = stagnation_threshold\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.F = np.full(pop_size, F_initial)  # Individual mutation factors\n        self.improvement_counts = np.zeros(pop_size)\n        self.stagnation_counts = np.zeros(pop_size)\n\n    def __call__(self, func):\n        # Initialize population and fitness\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = self.pop[i] + self.F[i] * (x_r1 - x_r2)\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.improvement_counts[i] += 1\n                    self.stagnation_counts[i] = 0  # Reset stagnation count\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    self.stagnation_counts[i] += 1 # Increment stagnation count\n\n                # Adjust mutation factor based on stagnation\n                if self.stagnation_counts[i] > self.stagnation_threshold:\n                   self.F[i] = min(1.0, self.F[i] * 1.2)  # Increase mutation factor if stagnant\n                else:\n                   self.F[i] = max(0.1, self.F[i] * 0.9)  # Reduce mutation factor if improving\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDEStagnation scored 0.384 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5b127e38-e64c-417e-90a0-1593fe8253b5"], "operator": null, "metadata": {"aucs": [0.14120407841781957, 0.2957225449018761, 0.38622729821764057, 0.4108355313889963, 0.2525863863903468, 0.3918461520679364, 0.2793998567149081, 0.3241118538460974, 0.3075556857045455, 0.1987641639713401, 0.40254477522190824, 0.9996800550049779, 0.38255350054734494, 0.30892798881378825, 0.7602375841335596, 0.3610766486410335, 0.3143925024913684, 0.4766809896389623, 0.19410594521242586, 0.4887812469248427]}}
{"id": "74f14c29-d7fa-47d7-a519-1684f062af37", "fitness": 0.5524986579976884, "name": "SelfAdaptiveRestartDE", "description": "A differential evolution strategy with self-adaptive parameters and a restart mechanism triggered by population stagnation.", "code": "import numpy as np\n\nclass SelfAdaptiveRestartDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, restart_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_init = F_init\n        self.Cr_init = Cr_init\n        self.restart_threshold = restart_threshold  # Number of iterations without improvement before restart\n        self.pop = None\n        self.fitness = None\n        self.F = None\n        self.Cr = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.no_improvement_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.F = np.full(self.pop_size, self.F_init)\n        self.Cr = np.full(self.pop_size, self.Cr_init)\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n        self.no_improvement_count = 0\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            f_opt_prev = self.f_opt  # Store previous best fitness\n            \n            for i in range(self.pop_size):\n                # Self-adaptive parameter update\n                self.F[i] = np.clip(np.random.normal(self.F[i], 0.1), 0.1, 1.0)\n                self.Cr[i] = np.clip(np.random.normal(self.Cr[i], 0.1), 0.1, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F[i] * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr[i]\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n            \n            # Stagnation check and restart\n            if self.f_opt >= f_opt_prev:\n                self.no_improvement_count += 1\n            else:\n                self.no_improvement_count = 0\n\n            if self.no_improvement_count > self.restart_threshold:\n                self.initialize_population(func)  # Restart the population\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm SelfAdaptiveRestartDE scored 0.552 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5b127e38-e64c-417e-90a0-1593fe8253b5"], "operator": null, "metadata": {"aucs": [0.1940945083194483, 0.3289055447598487, 0.5301715690317399, 0.8008681777935143, 0.5022830289191962, 0.6467222153518573, 0.4566915557274719, 0.4649065011731516, 0.5328504232995089, 0.517639300179392, 0.76694553797002, 0.9941932164865517, 0.33989572114658817, 0.5048170981436737, 0.8438909687083821, 0.6934663676006656, 0.4398848088366222, 0.7649740246977687, 0.2312872617910342, 0.4954853300173335]}}
{"id": "b556badf-77c2-4510-a225-4d522e15c4d1", "fitness": 0.3939272379851781, "name": "AdaptiveConvergenceDE", "description": "An adaptive Differential Evolution algorithm that adjusts its mutation strategy based on the population's convergence state, using a convergence detection mechanism to switch between exploration and exploitation phases.", "code": "import numpy as np\n\nclass AdaptiveConvergenceDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, learning_rate=0.1, convergence_threshold=1e-5, convergence_window=50, exploration_factor=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = np.full(pop_size, F_init)\n        self.Cr = np.full(pop_size, Cr_init)\n        self.learning_rate = learning_rate\n        self.convergence_threshold = convergence_threshold\n        self.convergence_window = convergence_window\n        self.exploration_factor = exploration_factor\n        self.pop = None\n        self.fitness = None\n        self.best_fitness_history = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.is_converged = False\n\n    def detect_convergence(self):\n        if len(self.best_fitness_history) < self.convergence_window:\n            return False\n        \n        window_values = self.best_fitness_history[-self.convergence_window:]\n        return np.std(window_values) < self.convergence_threshold\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > 0:\n            self.is_converged = self.detect_convergence()\n\n            for i in range(self.pop_size):\n                # Mutation Strategy\n                if self.is_converged:\n                    # Exploitation: Use smaller F and local search\n                    F_mutation = self.F[i]\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs]\n                    mutant = self.pop[i] + F_mutation * (x_r2 - x_r3)  # Perturb around current individual\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                else:\n                    # Exploration: Use larger F and global search\n                    F_mutation = self.F[i] * self.exploration_factor  # Increase mutation strength\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs]\n                    mutant = x_r1 + F_mutation * (x_r2 - x_r3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr[i]\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update F and Cr based on success\n                    self.F[i] = np.clip(self.F[i] + self.learning_rate * (1 - self.F[i]), 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] + self.learning_rate * (1 - self.Cr[i]), 0.1, 1.0)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    # Reduce F and Cr if no improvement\n                    self.F[i] = np.clip(self.F[i] - self.learning_rate * self.F[i], 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] - self.learning_rate * self.Cr[i], 0.1, 1.0)\n                \n                if self.budget <= 0:\n                    break\n            \n            self.best_fitness_history.append(self.f_opt)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveConvergenceDE scored 0.394 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f4aa9959-2068-4565-98ce-fad71680dcd7"], "operator": null, "metadata": {"aucs": [0.1525065507046688, 0.21135546429415553, 0.4045018792151157, 0.2896739658109285, 0.34695014834066173, 0.5053451106884188, 0.30640542462426423, 0.37601695494569576, 0.3838108719727915, 0.2217484351495329, 0.27599984567936375, 0.9978283227405399, 0.26603925827012465, 0.3274146193262961, 0.7160402314511688, 0.5596978527251797, 0.3076755897509712, 0.5549136040723976, 0.1853586817386449, 0.4892619482026421]}}
{"id": "2ad28d33-1c36-46c5-b82b-e4fc166a8544", "fitness": 0.7072575130754813, "name": "AdaptiveRestartDE", "description": "An adaptive DE algorithm with a restart mechanism triggered by population convergence and adaptive mutation scaling based on fitness variance.", "code": "import numpy as np\n\nclass AdaptiveRestartDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr=0.9, convergence_threshold=1e-6, restart_patience=50, adaptive_F_decay=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr\n        self.convergence_threshold = convergence_threshold\n        self.restart_patience = restart_patience\n        self.adaptive_F_decay = adaptive_F_decay\n        self.pop = None\n        self.fitness = None\n        self.best_fitness_history = []\n        self.stagnation_counter = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness_history = [self.f_opt]\n        self.stagnation_counter = 0\n\n    def check_convergence(self):\n        if len(self.best_fitness_history) > self.restart_patience:\n            std = np.std(self.best_fitness_history[-self.restart_patience:])\n            return std < self.convergence_threshold\n        return False\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n\n                # Adaptive F scaling based on fitness variance in the population\n                fitness_variance = np.var(self.fitness)\n                adaptive_F = self.F * (1 + 0.1 * np.random.randn()) #Adding some noise\n                if fitness_variance > 1e-3: #Only adapt if variance is above threshold\n                    adaptive_F = np.clip(adaptive_F, 0.1, 1.0) #Clamp values to be within range\n\n                mutant = x_r1 + adaptive_F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n            # Convergence check and restart\n            if self.check_convergence():\n                self.F *= self.adaptive_F_decay  # Reduce F to promote local search\n                self.initialize_population(func) # Restart the population\n                self.budget -= self.pop_size  # Account for the new population\n                \n\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > 2 * self.restart_patience:\n                self.best_fitness_history.pop(0)\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveRestartDE scored 0.707 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f4aa9959-2068-4565-98ce-fad71680dcd7"], "operator": null, "metadata": {"aucs": [0.2721753665891907, 0.6467954840367769, 0.70521630402464, 0.8481040291381654, 0.7572095709584041, 0.7807392048539163, 0.6450778845209497, 0.672567176501967, 0.7115348433574462, 0.7190988329747339, 0.8735716047115577, 0.993036323082413, 0.6446575527588152, 0.7305830633625796, 0.9051042952618846, 0.7825621204003352, 0.5880344867894061, 0.8427576662787473, 0.44227294107673354, 0.5840515108309665]}}
{"id": "947535b4-fb37-48e9-b897-729428011b33", "fitness": 0.6462130049794504, "name": "AdaptiveDEWeighted", "description": "An adaptive differential evolution strategy that dynamically adjusts both the mutation factor and crossover rate based on the population's convergence state and individual performance, using a weighted combination of global and local search.", "code": "import numpy as np\n\nclass AdaptiveDEWeighted:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_init = F_init\n        self.Cr_init = Cr_init\n        self.pop = None\n        self.fitness = None\n        self.F = None\n        self.Cr = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []  # Archive for storing discarded solutions\n\n    def __call__(self, func):\n        # Initialize population and fitness\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initialize F and Cr for each individual\n        self.F = np.full(self.pop_size, self.F_init)\n        self.Cr = np.full(self.pop_size, self.Cr_init)\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive F and Cr based on individual performance\n                if self.fitness[i] < np.mean(self.fitness):\n                    self.F[i] = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)  # Smaller F for better individuals\n                    self.Cr[i] = np.clip(np.random.normal(0.9, 0.2), 0.1, 1.0) # Higher Cr for better individuals\n                else:\n                    self.F[i] = np.clip(np.random.normal(0.8, 0.3), 0.1, 1.0)  # Larger F for worse individuals\n                    self.Cr[i] = np.clip(np.random.normal(0.5, 0.2), 0.1, 1.0) # Smaller Cr for worse individuals\n                    \n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                \n                # Weighted combination of global and local search\n                global_mutant = x_r1 + self.F[i] * (x_r2 - x_r3)\n                local_mutant = self.x_opt + self.F[i] * (x_r1 - x_r2)\n                \n                # Adaptive weight based on convergence\n                convergence_ratio = np.std(self.fitness) / (np.max(self.fitness) - np.min(self.fitness) + 1e-8)  # Avoid division by zero\n                weight = np.clip(convergence_ratio, 0.0, 1.0)  # Normalize between 0 and 1\n                \n                mutant = weight * global_mutant + (1 - weight) * local_mutant\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr[i]\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    # Archive discarded solutions\n                    self.archive.append(self.pop[i])\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    # Perturb trial solution if it's not better\n                    trial = self.pop[i] + 0.01 * np.random.randn(self.dim) * (func.bounds.ub - func.bounds.lb)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                    \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDEWeighted scored 0.646 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5b127e38-e64c-417e-90a0-1593fe8253b5"], "operator": null, "metadata": {"aucs": [0.2597412287802954, 0.8615191675622595, 0.8817482629356882, 0.18873382480116385, 0.2932601611534138, 0.9164353853973016, 0.8907408800706975, 0.8662290721312726, 0.8893613824873369, 0.30773523203336406, 0.9421519780549057, 0.9999156671262918, 0.31874473186180063, 0.41033062897816497, 0.9632192709559413, 0.898628097986191, 0.3994979532830426, 0.9355648120159233, 0.2102191856030552, 0.4904831763709]}}
{"id": "60c026ec-3853-49be-a95b-d5d334c440b2", "fitness": 0.3862236805968403, "name": "OrthogonalAdaptiveDE", "description": "Adaptive Differential Evolution with orthogonal learning, where individuals learn from orthogonal directions to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass OrthogonalAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, orthogonal_components=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.orthogonal_components = orthogonal_components\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = self.pop[best_idx].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # DE mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Orthogonal Learning:\n                orthogonal_dirs = np.random.randn(self.orthogonal_components, self.dim)\n                orthogonal_dirs /= np.linalg.norm(orthogonal_dirs, axis=1, keepdims=True)\n                \n                best_orthogonal_trial = trial.copy()\n                best_orthogonal_fitness = np.Inf\n\n                for j in range(self.orthogonal_components):\n                  orthogonal_trial = trial + np.random.uniform(-self.F, self.F) * orthogonal_dirs[j] # Adjust step size for orthogonal exploration\n                  orthogonal_trial = np.clip(orthogonal_trial, func.bounds.lb, func.bounds.ub)\n                  orthogonal_fitness = func(orthogonal_trial)\n                  self.budget -= 1\n                  \n                  if orthogonal_fitness < best_orthogonal_fitness:\n                    best_orthogonal_fitness = orthogonal_fitness\n                    best_orthogonal_trial = orthogonal_trial.copy()\n\n                  if self.budget <= 0:\n                    break\n\n                if best_orthogonal_fitness < fitness[i]:\n                    self.pop[i] = best_orthogonal_trial\n                    fitness[i] = best_orthogonal_fitness\n\n                    if best_orthogonal_fitness < self.f_opt:\n                        self.f_opt = best_orthogonal_fitness\n                        self.x_opt = best_orthogonal_trial.copy()\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm OrthogonalAdaptiveDE scored 0.386 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["bf2fbc24-1bc0-4122-91ad-a4dfa5aef599"], "operator": null, "metadata": {"aucs": [0.16014492909121159, 0.2827821141367616, 0.3726181973154745, 0.535044314994046, 0.30213493557843674, 0.39554430532268503, 0.2879612945407851, 0.32827248797064035, 0.2949235716695533, 0.23227296169512723, 0.40069332792314916, 0.9685623370417491, 0.31245334116537227, 0.3101710987837121, 0.7500524375192732, 0.37293206890305497, 0.3062591153516846, 0.4449533935172497, 0.18293518043792223, 0.4837621989789179]}}
{"id": "755cf16b-70b3-4e8a-b81c-8198e93e713b", "fitness": 0.37433907074519585, "name": "AdaptiveMutationDEDE", "description": "A differential evolution strategy with a dynamically adapting mutation factor based on population diversity and individual success.", "code": "import numpy as np\n\nclass AdaptiveMutationDEDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, Cr=0.9, initial_F=0.5, F_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.Cr = Cr\n        self.initial_F = initial_F\n        self.F_decay = F_decay\n        self.F = initial_F  # Initialize mutation factor\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = None\n        self.fitness = None\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_idx]\n        self.x_opt = self.pop[best_idx].copy()\n        \n        archive = [] #Archive for storing solutions that have been replaced\n\n        while self.budget > 0:\n            # Calculate population diversity\n            diversity = np.std(self.pop)\n            \n            # Update mutation factor based on diversity\n            self.F = self.initial_F * (diversity / (func.bounds.ub[0] - func.bounds.lb[0]))\n\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                \n                # Apply DE mutation\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    # Archive replaced solution\n                    archive.append(self.pop[i].copy())\n                    \n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n                    \n            # Reduce mutation strength\n            self.F *= self.F_decay\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveMutationDEDE scored 0.374 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["bf2fbc24-1bc0-4122-91ad-a4dfa5aef599"], "operator": null, "metadata": {"aucs": [0.17179807387836954, 0.19614249320686283, 0.34786963141182614, 0.362253516143097, 0.3327029720614215, 0.234211487753478, 0.5297356445909003, 0.25787100895272175, 0.26765501810039827, 0.19328130771914298, 0.33692243951263656, 0.9923611107699367, 0.260233112264588, 0.7890573749161628, 0.3040204334956965, 0.45531309096520634, 0.30402323574993684, 0.3945847368601707, 0.29358622329413697, 0.46315850325722574]}}
{"id": "929d679c-7335-4b9d-97d9-0be6aa72409d", "fitness": -Infinity, "name": "DualPopulationDE", "description": "A differential evolution strategy with a dual population approach, where one population focuses on exploration and the other on exploitation, with periodic information exchange.", "code": "import numpy as np\n\nclass DualPopulationDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, exchange_interval=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.exchange_interval = exchange_interval\n        self.exploration_pop = None\n        self.exploitation_pop = None\n        self.exploration_fitness = None\n        self.exploitation_fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.generation = 0\n\n    def initialize_population(self, func):\n        exploration_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        exploitation_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        exploration_fitness = np.array([func(x) for x in exploration_pop])\n        exploitation_fitness = np.array([func(x) for x in exploitation_pop])\n        return exploration_pop, exploitation_fitness, exploitation_pop, exploitation_fitness\n\n    def evolve_population(self, pop, fitness, func, F, Cr, strategy=\"rand1\"):\n        new_pop = np.copy(pop)\n        new_fitness = np.copy(fitness)\n        for i in range(self.pop_size):\n            if strategy == \"rand1\":\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                mutant = x_r1 + F * (x_r2 - x_r3)\n            elif strategy == \"current_to_best\":\n                best_idx = np.argmin(fitness)\n                x_best = pop[best_idx]\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = pop[idxs]\n                mutant = pop[i] + F * (x_best - pop[i]) + F * (x_r1 - x_r2)\n            else:  # strategy == \"current_to_rand\":\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = pop[idxs]\n                mutant = pop[i] + np.random.rand() * (x_r1 - pop[i]) + F * (x_r1 - x_r2) #try current to rand\n\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n            cross_mask = np.random.rand(self.dim) < Cr\n            trial = np.where(cross_mask, mutant, pop[i])\n            f_trial = func(trial)\n            self.budget -= 1\n\n            if f_trial < fitness[i]:\n                new_pop[i] = trial\n                new_fitness[i] = f_trial\n            \n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial.copy()\n        return new_pop, new_fitness\n\n    def exchange_information(self):\n        # Replace worst individuals in exploitation pop with best from exploration pop\n        num_exchange = self.pop_size // 5\n        exploration_best_idx = np.argsort(self.exploration_fitness)[:num_exchange]\n        exploitation_worst_idx = np.argsort(self.exploitation_fitness)[-num_exchange:]\n\n        self.exploitation_pop[exploitation_worst_idx] = self.exploration_pop[exploration_best_idx]\n        self.exploitation_fitness[exploitation_worst_idx] = self.exploration_fitness[exploration_best_idx]\n\n    def __call__(self, func):\n        self.exploration_pop, self.exploration_fitness, self.exploitation_pop, self.exploitation_fitness = self.initialize_population(func)\n        self.f_opt = np.min(np.min(self.exploration_fitness), np.min(self.exploitation_fitness))\n        self.x_opt = self.exploration_pop[np.argmin(self.exploration_fitness)].copy() if np.min(self.exploration_fitness) < np.min(self.exploitation_fitness) else self.exploitation_pop[np.argmin(self.exploitation_fitness)].copy()\n        self.budget -= 2 * self.pop_size\n        \n        while self.budget > 0:\n            # Evolve each population with different strategies\n            self.exploration_pop, self.exploration_fitness = self.evolve_population(self.exploration_pop, self.exploration_fitness, func, self.F, self.Cr, strategy=\"rand1\")\n            self.exploitation_pop, self.exploitation_fitness = self.evolve_population(self.exploitation_pop, self.exploitation_fitness, func, self.F, self.Cr, strategy=\"current_to_best\")\n\n            self.generation += 1\n            if self.generation % self.exchange_interval == 0:\n                self.exchange_information()\n            \n            if np.min(self.exploration_fitness) < self.f_opt:\n                self.f_opt = np.min(self.exploration_fitness)\n                self.x_opt = self.exploration_pop[np.argmin(self.exploration_fitness)].copy()\n            if np.min(self.exploitation_fitness) < self.f_opt:\n                self.f_opt = np.min(self.exploitation_fitness)\n                self.x_opt = self.exploitation_pop[np.argmin(self.exploitation_fitness)].copy()\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "An exception occurred: 'numpy.float64' object cannot be interpreted as an integer.", "error": "", "parent_ids": ["b556badf-77c2-4510-a225-4d522e15c4d1"], "operator": null, "metadata": {}}
{"id": "12751999-3be3-4e29-8550-5e671659e9b6", "fitness": 0.0, "name": "DynamicPopulationDE", "description": "A differential evolution strategy with a dynamic population size and a local search operator triggered upon convergence detection.", "code": "import numpy as np\n\nclass DynamicPopulationDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, F=0.5, Cr=0.9, convergence_threshold=1e-5, convergence_window=50, local_search_probability=0.1, local_search_radius=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.F = F\n        self.Cr = Cr\n        self.convergence_threshold = convergence_threshold\n        self.convergence_window = convergence_window\n        self.local_search_probability = local_search_probability\n        self.local_search_radius = local_search_radius\n        self.pop = None\n        self.fitness = None\n        self.best_fitness_history = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.is_converged = False\n\n    def detect_convergence(self):\n        if len(self.best_fitness_history) < self.convergence_window:\n            return False\n        \n        window_values = self.best_fitness_history[-self.convergence_window:]\n        return np.std(window_values) < self.convergence_threshold\n\n    def adjust_population_size(self):\n        if self.is_converged:\n            # Reduce population size to focus on exploitation\n            self.pop_size = max(self.min_pop_size, int(self.pop_size * 0.8))\n        else:\n            # Increase population size to enhance exploration\n            self.pop_size = min(self.max_pop_size, int(self.pop_size * 1.2))\n        \n        self.pop_size = int(self.pop_size) # Ensure it's an integer\n\n    def local_search(self, x, func):\n        # Perturb each dimension with a small random value\n        x_new = x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n        return x_new\n    \n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > 0:\n            self.is_converged = self.detect_convergence()\n            self.adjust_population_size()\n            \n            # Repopulate if population size changed significantly\n            if self.pop.shape[0] != self.pop_size:\n                new_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                new_fitness = np.array([func(x) for x in new_pop])\n                self.budget -= (self.pop_size - self.pop.shape[0])\n                \n                #Elitism: Keep the best from previous pop\n                num_keep = min(self.pop.shape[0], self.pop_size)\n                best_idx = np.argsort(self.fitness)[:num_keep]\n\n                new_pop[:num_keep] = self.pop[best_idx]\n                new_fitness[:num_keep] = self.fitness[best_idx]\n\n                self.pop = new_pop\n                self.fitness = new_fitness\n\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Local Search (only when converged)\n                if self.is_converged and np.random.rand() < self.local_search_probability:\n                    trial = self.local_search(trial, func)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                \n                if self.budget <= 0:\n                    break\n            \n            self.best_fitness_history.append(self.f_opt)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm DynamicPopulationDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b556badf-77c2-4510-a225-4d522e15c4d1"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "5bba4af4-c794-4ee3-b510-0d63ca87d176", "fitness": 0.0, "name": "AdaptivePopulationDE", "description": "An adaptive Differential Evolution (DE) algorithm with a dynamically adjusted population size based on the improvement rate and a migration operator to introduce diversity.", "code": "import numpy as np\n\nclass AdaptivePopulationDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F=0.5, Cr=0.9, pop_size_adapt_freq=100, migration_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.initial_pop_size = initial_pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop_size_adapt_freq = pop_size_adapt_freq\n        self.migration_rate = migration_rate\n        self.eval_count = 0\n        self.improvement_history = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n        self.improvement_history.append(self.f_opt)\n\n    def adjust_population_size(self):\n        if len(self.improvement_history) < 2:\n            return\n\n        improvement_rate = (self.improvement_history[-2] - self.improvement_history[-1]) / abs(self.improvement_history[-2]) if self.improvement_history[-2] != 0 else 0\n\n        if improvement_rate > 0.01:\n            self.pop_size = min(self.pop_size + 1, 2 * self.initial_pop_size)  # Increase population if improving\n        elif improvement_rate < 0.001:\n            self.pop_size = max(self.pop_size - 1, self.initial_pop_size // 2)  # Decrease if stagnating\n        \n        # Resize population\n        if self.pop_size != self.pop.shape[0]:\n            if self.pop_size > self.pop.shape[0]:\n                # Add random individuals\n                num_new = self.pop_size - self.pop.shape[0]\n                new_pop = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=(num_new, self.dim))\n                new_fitness = np.array([self.func(x) for x in new_pop])\n                self.eval_count += num_new\n                self.pop = np.vstack((self.pop, new_pop))\n                self.fitness = np.concatenate((self.fitness, new_fitness))\n            else:\n                # Remove worst individuals\n                num_remove = self.pop.shape[0] - self.pop_size\n                worst_indices = np.argsort(self.fitness)[-num_remove:]\n                mask = np.ones(self.pop.shape[0], dtype=bool)\n                mask[worst_indices] = False\n                self.pop = self.pop[mask]\n                self.fitness = self.fitness[mask]\n    \n    def perform_migration(self):\n        num_migrants = int(self.pop_size * self.migration_rate)\n        if num_migrants > 0:\n            # Identify worst individuals\n            worst_indices = np.argsort(self.fitness)[-num_migrants:]\n\n            # Replace with random individuals\n            new_migrants = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, size=(num_migrants, self.dim))\n            new_fitness = np.array([self.func(x) for x in new_migrants])\n            self.eval_count += num_migrants\n\n            self.pop[worst_indices] = new_migrants\n            self.fitness[worst_indices] = new_fitness\n\n    def __call__(self, func):\n        self.func = func # Store the function\n        self.initialize_population(func)\n\n        generation = 0\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n            if generation % self.pop_size_adapt_freq == 0:\n                self.adjust_population_size()\n                self.perform_migration()\n                self.improvement_history.append(self.f_opt)\n\n            generation += 1\n            if self.eval_count >= self.budget:\n                break\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptivePopulationDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2ad28d33-1c36-46c5-b82b-e4fc166a8544"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "da9425d4-7cf5-44db-a7f7-5b2564dde287", "fitness": -Infinity, "name": "FuzzyAdaptiveDE", "description": "An adaptive DE algorithm that uses a fuzzy logic controller to adjust mutation factor F and crossover rate Cr based on population diversity and fitness improvement rate, aiming to balance exploration and exploitation.", "code": "import numpy as np\nimport skfuzzy as fuzz\nfrom skfuzzy import control as ctrl\n\nclass FuzzyAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = np.full(pop_size, F_init)\n        self.Cr = np.full(pop_size, Cr_init)\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        # Fuzzy Logic Controller Setup\n        self.setup_fuzzy_controller()\n\n    def setup_fuzzy_controller(self):\n        # Input: Population Diversity (std of fitness)\n        diversity = ctrl.Antecedent(np.linspace(0, 1, 100), 'diversity')\n        diversity['low'] = fuzz.trimf(diversity.universe, [0, 0, 0.5])\n        diversity['medium'] = fuzz.trimf(diversity.universe, [0, 0.5, 1])\n        diversity['high'] = fuzz.trimf(diversity.universe, [0.5, 1, 1])\n\n        # Input: Fitness Improvement Rate (change in best fitness over time)\n        improvement = ctrl.Antecedent(np.linspace(-1, 1, 100), 'improvement') # allow negative improvement\n        improvement['negative'] = fuzz.trimf(improvement.universe, [-1, -1, 0])\n        improvement['zero'] = fuzz.trimf(improvement.universe, [-0.2, 0, 0.2])\n        improvement['positive'] = fuzz.trimf(improvement.universe, [0, 1, 1])\n\n        # Output: Mutation Factor (F) Adjustment\n        f_adjust = ctrl.Consequent(np.linspace(-0.5, 0.5, 100), 'f_adjust')\n        f_adjust['decrease'] = fuzz.trimf(f_adjust.universe, [-0.5, -0.5, 0])\n        f_adjust['maintain'] = fuzz.trimf(f_adjust.universe, [-0.1, 0, 0.1])\n        f_adjust['increase'] = fuzz.trimf(f_adjust.universe, [0, 0.5, 0.5])\n\n        # Output: Crossover Rate (Cr) Adjustment\n        cr_adjust = ctrl.Consequent(np.linspace(-0.5, 0.5, 100), 'cr_adjust')\n        cr_adjust['decrease'] = fuzz.trimf(cr_adjust.universe, [-0.5, -0.5, 0])\n        cr_adjust['maintain'] = fuzz.trimf(cr_adjust.universe, [-0.1, 0, 0.1])\n        cr_adjust['increase'] = fuzz.trimf(cr_adjust.universe, [0, 0.5, 0.5])\n\n        # Rules\n        rule1 = ctrl.Rule(diversity['low'] & improvement['negative'], [f_adjust['increase'], cr_adjust['increase']])\n        rule2 = ctrl.Rule(diversity['low'] & improvement['zero'], [f_adjust['increase'], cr_adjust['maintain']])\n        rule3 = ctrl.Rule(diversity['low'] & improvement['positive'], [f_adjust['maintain'], cr_adjust['maintain']])\n        rule4 = ctrl.Rule(diversity['medium'] & improvement['negative'], [f_adjust['increase'], cr_adjust['increase']])\n        rule5 = ctrl.Rule(diversity['medium'] & improvement['zero'], [f_adjust['maintain'], cr_adjust['maintain']])\n        rule6 = ctrl.Rule(diversity['medium'] & improvement['positive'], [f_adjust['decrease'], cr_adjust['decrease']])\n        rule7 = ctrl.Rule(diversity['high'] & improvement['negative'], [f_adjust['maintain'], cr_adjust['maintain']])\n        rule8 = ctrl.Rule(diversity['high'] & improvement['zero'], [f_adjust['decrease'], cr_adjust['decrease']])\n        rule9 = ctrl.Rule(diversity['high'] & improvement['positive'], [f_adjust['decrease'], cr_adjust['decrease']])\n\n        self.control_system = ctrl.ControlSystem([rule1, rule2, rule3, rule4, rule5, rule6, rule7, rule8, rule9])\n        self.control_simulation = ctrl.ControlSystemSimulation(self.control_system)\n\n    def adjust_parameters(self, diversity, improvement):\n        self.control_simulation.input['diversity'] = diversity\n        self.control_simulation.input['improvement'] = improvement\n        self.control_simulation.compute()\n        f_adjustment = self.control_simulation.output['f_adjust']\n        cr_adjustment = self.control_simulation.output['cr_adjust']\n        return f_adjustment, cr_adjustment\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n        best_fitness_history = [self.f_opt]\n\n        while self.budget > 0:\n            # Calculate population diversity (std of fitness values, normalized)\n            diversity = np.std(self.fitness) / (np.max(self.fitness) - np.min(self.fitness) + 1e-8) # avoid division by zero\n\n            # Calculate fitness improvement rate (change in best fitness)\n            if len(best_fitness_history) > 1:\n                improvement = (best_fitness_history[-1] - self.f_opt) / best_fitness_history[-1] #relative improvement\n            else:\n                improvement = 0\n\n            for i in range(self.pop_size):\n                # Fuzzy Logic Parameter Adjustment\n                f_adjust, cr_adjust = self.adjust_parameters(diversity, improvement)\n                self.F[i] = np.clip(self.F[i] + f_adjust, 0.1, 1.0)\n                self.Cr[i] = np.clip(self.Cr[i] + cr_adjust, 0.1, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F[i] * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr[i]\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n            \n            best_fitness_history.append(self.f_opt)\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "An exception occurred: No module named 'skfuzzy'.", "error": "", "parent_ids": ["b556badf-77c2-4510-a225-4d522e15c4d1"], "operator": null, "metadata": {}}
{"id": "21898c4a-7f9e-4519-a680-d4b3bf658812", "fitness": -Infinity, "name": "FuzzyAdaptiveDE", "description": "An adaptive differential evolution algorithm with a fuzzy logic controller to adjust mutation and crossover rates based on population diversity and individual fitness improvement.", "code": "import numpy as np\nimport skfuzzy as fuzz\nfrom skfuzzy import control as ctrl\n\nclass FuzzyAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = np.full(pop_size, F_init)\n        self.Cr = np.full(pop_size, Cr_init)\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.fuzzy_system = self.create_fuzzy_system()\n\n    def create_fuzzy_system(self):\n        # Define fuzzy input variables\n        diversity = ctrl.Antecedent(np.arange(0, 1.01, 0.01), 'diversity')\n        improvement = ctrl.Antecedent(np.arange(-1, 1.01, 0.01), 'improvement') # allow negative values\n\n        # Define fuzzy output variables\n        adjust_F = ctrl.Consequent(np.arange(-0.5, 0.51, 0.01), 'adjust_F')\n        adjust_Cr = ctrl.Consequent(np.arange(-0.5, 0.51, 0.01), 'adjust_Cr')\n\n        # Define membership functions for input variables\n        diversity['low'] = fuzz.trimf(diversity.universe, [0, 0, 0.5])\n        diversity['medium'] = fuzz.trimf(diversity.universe, [0, 0.5, 1])\n        diversity['high'] = fuzz.trimf(diversity.universe, [0.5, 1, 1])\n\n        improvement['negative'] = fuzz.trimf(improvement.universe, [-1, -1, 0])\n        improvement['zero'] = fuzz.trimf(improvement.universe, [-0.2, 0, 0.2])\n        improvement['positive'] = fuzz.trimf(improvement.universe, [0, 1, 1])\n\n        # Define membership functions for output variables\n        adjust_F['decrease'] = fuzz.trimf(adjust_F.universe, [-0.5, -0.5, 0])\n        adjust_F['none'] = fuzz.trimf(adjust_F.universe, [-0.1, 0, 0.1])\n        adjust_F['increase'] = fuzz.trimf(adjust_F.universe, [0, 0.5, 0.5])\n\n        adjust_Cr['decrease'] = fuzz.trimf(adjust_Cr.universe, [-0.5, -0.5, 0])\n        adjust_Cr['none'] = fuzz.trimf(adjust_Cr.universe, [-0.1, 0, 0.1])\n        adjust_Cr['increase'] = fuzz.trimf(adjust_Cr.universe, [0, 0.5, 0.5])\n\n        # Define rules\n        rule1 = ctrl.Rule(diversity['low'] & improvement['negative'], (adjust_F['increase'], adjust_Cr['increase']))\n        rule2 = ctrl.Rule(diversity['low'] & improvement['zero'], (adjust_F['increase'], adjust_Cr['none']))\n        rule3 = ctrl.Rule(diversity['low'] & improvement['positive'], (adjust_F['none'], adjust_Cr['decrease']))\n        rule4 = ctrl.Rule(diversity['medium'] & improvement['negative'], (adjust_F['increase'], adjust_Cr['none']))\n        rule5 = ctrl.Rule(diversity['medium'] & improvement['zero'], (adjust_F['none'], adjust_Cr['none']))\n        rule6 = ctrl.Rule(diversity['medium'] & improvement['positive'], (adjust_F['decrease'], adjust_Cr['increase']))\n        rule7 = ctrl.Rule(diversity['high'] & improvement['negative'], (adjust_F['none'], adjust_Cr['decrease']))\n        rule8 = ctrl.Rule(diversity['high'] & improvement['zero'], (adjust_F['decrease'], adjust_Cr['none']))\n        rule9 = ctrl.Rule(diversity['high'] & improvement['positive'], (adjust_F['decrease'], adjust_Cr['decrease']))\n\n        # Create control system\n        adjust_ctrl = ctrl.ControlSystem([rule1, rule2, rule3, rule4, rule5, rule6, rule7, rule8, rule9])\n        adjusting = ctrl.ControlSystemSimulation(adjust_ctrl)\n        \n        return adjusting\n\n    def calculate_diversity(self):\n        # Calculate population diversity (e.g., average distance from centroid)\n        centroid = np.mean(self.pop, axis=0)\n        distances = np.linalg.norm(self.pop - centroid, axis=1)\n        diversity = np.mean(distances)\n        # Normalize diversity to [0, 1] based on the bounds\n        max_possible_diversity = np.linalg.norm(np.full(self.dim, 5) - np.full(self.dim, -5)) #max dist from origin if centered\n        \n        return diversity / max_possible_diversity\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            diversity = self.calculate_diversity()\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F[i] * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr[i]\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    improvement = (self.fitness[i] - f_trial) / self.fitness[i]  # calculate improvement\n\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update F and Cr using fuzzy logic\n                    self.fuzzy_system.input['diversity'] = diversity\n                    self.fuzzy_system.input['improvement'] = improvement\n                    self.fuzzy_system.compute()\n\n                    adjust_F = self.fuzzy_system.output['adjust_F']\n                    adjust_Cr = self.fuzzy_system.output['adjust_Cr']\n\n                    self.F[i] = np.clip(self.F[i] + adjust_F, 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] + adjust_Cr, 0.1, 1.0)\n                    \n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                     # If no improvement, penalize F and Cr slightly\n                    self.F[i] = np.clip(self.F[i] - 0.01, 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] - 0.01, 0.1, 1.0)\n\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "An exception occurred: No module named 'skfuzzy'.", "error": "", "parent_ids": ["b556badf-77c2-4510-a225-4d522e15c4d1"], "operator": null, "metadata": {}}
{"id": "27e340bd-371c-426b-ba7f-397ce7aaec65", "fitness": 0.43359989975056845, "name": "DynamicPopSizeDE", "description": "A differential evolution strategy with a dynamically adjusted population size based on the fitness landscape and an aging mechanism to promote diversity.", "code": "import numpy as np\n\nclass DynamicPopSizeDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, F=0.5, Cr=0.9, age_limit=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.pop_size_init = pop_size_init\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.ages = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.age_limit = age_limit\n\n    def __call__(self, func):\n        # Initialize population and fitness\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.ages = np.zeros(self.pop_size)  # Initialize ages\n\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            # Adjust population size based on fitness variance\n            fitness_std = np.std(self.fitness)\n            if fitness_std > 0.1 * (np.max(self.fitness) - np.min(self.fitness)):  # High variance: increase pop size\n                self.pop_size = min(self.pop_size + 5, 2 * self.pop_size_init)\n                new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(5, self.dim))\n                new_fitness = np.array([func(x) for x in new_individuals])\n                self.budget -= 5\n\n                self.pop = np.vstack((self.pop, new_individuals))\n                self.fitness = np.concatenate((self.fitness, new_fitness))\n                self.ages = np.concatenate((self.ages, np.zeros(5)))\n            elif fitness_std < 0.01 * (np.max(self.fitness) - np.min(self.fitness)) and self.pop_size > self.pop_size_init:  # Low variance: decrease pop size\n                self.pop_size = max(self.pop_size - 5, self.pop_size_init)\n                \n                #Remove worst individuals\n                worst_indices = np.argsort(self.fitness)[-5:]\n                keep_indices = np.array([i for i in range(len(self.fitness)) if i not in worst_indices])\n\n                self.pop = self.pop[keep_indices]\n                self.fitness = self.fitness[keep_indices]\n                self.ages = self.ages[keep_indices]\n\n            for i in range(self.pop.shape[0]):\n                # Mutation\n                idxs = np.random.choice(self.pop.shape[0], 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    self.ages[i] = 0  # Reset age\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    self.ages[i] += 1  # Increment age\n\n                # Aging mechanism: replace old individuals with new random ones\n                if self.ages[i] > self.age_limit:\n                    self.pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    self.fitness[i] = func(self.pop[i])\n                    self.ages[i] = 0\n                    self.budget -= 1\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.pop[i].copy()\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm DynamicPopSizeDE scored 0.434 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["947535b4-fb37-48e9-b897-729428011b33"], "operator": null, "metadata": {"aucs": [0.17163348743926454, 0.27175413075379706, 0.38446772439166466, 0.6878800011043775, 0.3938983941167724, 0.4425503814821363, 0.3316064699169955, 0.37687723698478226, 0.3715992369460288, 0.23467055368180323, 0.5684543723829847, 0.9988513696870145, 0.3391821971377399, 0.34816590475861153, 0.7679965311010519, 0.45775237858219975, 0.34014669312740176, 0.5106301854388843, 0.18636263125906227, 0.4875181147187958]}}
{"id": "1fad8165-0308-4fc2-85b0-a447cc7c4008", "fitness": 0.3870473383429553, "name": "MirroredCauchyADE", "description": "A differential evolution strategy that uses a mirrored sampling technique to enhance exploration and exploitation, combined with a Cauchy mutation operator and adaptive restart.", "code": "import numpy as np\n\nclass MirroredCauchyADE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, restart_threshold=100, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_init = F_init\n        self.Cr_init = Cr_init\n        self.restart_threshold = restart_threshold\n        self.cauchy_scale = cauchy_scale\n        self.pop = None\n        self.fitness = None\n        self.F = None\n        self.Cr = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.no_improvement_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.F = np.full(self.pop_size, self.F_init)\n        self.Cr = np.full(self.pop_size, self.Cr_init)\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n        self.no_improvement_count = 0\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            f_opt_prev = self.f_opt\n\n            for i in range(self.pop_size):\n                # Self-adaptive parameter update\n                self.F[i] = np.clip(np.random.normal(self.F[i], 0.1), 0.1, 1.0)\n                self.Cr[i] = np.clip(np.random.normal(self.Cr[i], 0.1), 0.1, 1.0)\n\n                # Mutation (Cauchy)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                cauchy_noise = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n                mutant = x_r1 + self.F[i] * (x_r2 - x_r3) + cauchy_noise\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Mirrored sampling\n                trial = mutant.copy()\n                trial_mirrored = 2 * np.mean(self.pop, axis=0) - mutant\n                trial_mirrored = np.clip(trial_mirrored, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr[i]\n                trial = np.where(cross_mask, trial, self.pop[i])\n                trial_mirrored = np.where(cross_mask, trial_mirrored, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                f_trial_mirrored = func(trial_mirrored)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n                \n                # Selection (choose best between original and mirrored trial)\n                if f_trial <= f_trial_mirrored and f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                elif f_trial_mirrored < f_trial and f_trial_mirrored < self.fitness[i]:\n                     self.pop[i] = trial_mirrored\n                     self.fitness[i] = f_trial_mirrored\n\n                     if f_trial_mirrored < self.f_opt:\n                         self.f_opt = f_trial_mirrored\n                         self.x_opt = trial_mirrored.copy()\n            \n\n            # Stagnation check and restart\n            if self.f_opt >= f_opt_prev:\n                self.no_improvement_count += 1\n            else:\n                self.no_improvement_count = 0\n\n            if self.no_improvement_count > self.restart_threshold:\n                self.initialize_population(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm MirroredCauchyADE scored 0.387 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["74f14c29-d7fa-47d7-a519-1684f062af37"], "operator": null, "metadata": {"aucs": [0.17610663273336047, 0.26078512629972406, 0.3719490310425213, 0.43507198114633006, 0.3007681109484567, 0.389324719705172, 0.29901839983227385, 0.31060710445407125, 0.2887251624308531, 0.2531533310381888, 0.43843350182592034, 0.9943621506870983, 0.2865944964705518, 0.3210466386765132, 0.7405798200767129, 0.39557327491622596, 0.30519257982037273, 0.48702059480281434, 0.1856204200598387, 0.5010136898921062]}}
{"id": "e567d03a-5eee-4e91-8076-ff2fb67061b4", "fitness": 0.44877010204102125, "name": "LandscapeAwareDE", "description": "A differential evolution strategy that dynamically adjusts its search behavior based on a landscape analysis using fitness variance and gradient estimation.", "code": "import numpy as np\n\nclass LandscapeAwareDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, learning_rate=0.1, landscape_analysis_interval=50, gradient_estimation_samples=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = np.full(pop_size, F_init)\n        self.Cr = np.full(pop_size, Cr_init)\n        self.learning_rate = learning_rate\n        self.landscape_analysis_interval = landscape_analysis_interval\n        self.gradient_estimation_samples = gradient_estimation_samples\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.iteration = 0\n        self.flatness_threshold = 1e-6 # Threshold to detect flatness. Adjust as needed.\n\n    def estimate_gradient(self, func, x, delta=1e-3):\n        \"\"\"Estimates the gradient at a given point using finite differences.\"\"\"\n        gradient = np.zeros(self.dim)\n        for i in range(self.dim):\n            x_plus = x.copy()\n            x_minus = x.copy()\n            x_plus[i] += delta\n            x_minus[i] -= delta\n            x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n            x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n            gradient[i] = (func(x_plus) - func(x_minus)) / (2 * delta)\n            self.budget -= 2 # Account for function evaluations in gradient estimation\n            if self.budget <= 0:\n              break\n        return gradient\n\n    def analyze_landscape(self, func):\n        \"\"\"Analyzes the fitness landscape to determine search strategy.\"\"\"\n        fitness_variance = np.var(self.fitness)\n        \n        # Estimate average gradient magnitude across the population\n        avg_gradient_magnitude = 0.0\n        for i in range(min(self.pop_size, self.gradient_estimation_samples)): # sample subset of pop. for gradient est.\n          if self.budget > 0:\n            gradient = self.estimate_gradient(func, self.pop[i])\n            avg_gradient_magnitude += np.linalg.norm(gradient)\n          else:\n            break\n        avg_gradient_magnitude /= min(self.pop_size, self.gradient_estimation_samples)\n\n        # Strategy selection based on landscape analysis\n        if fitness_variance < self.flatness_threshold and avg_gradient_magnitude < self.flatness_threshold:\n            # Flat landscape: Increase exploration\n            strategy = \"exploration\"\n        elif fitness_variance > self.flatness_threshold and avg_gradient_magnitude > self.flatness_threshold:\n            # Rugged landscape: Focus on exploitation\n            strategy = \"exploitation\"\n        else:\n            # Balanced landscape: Maintain balance\n            strategy = \"balanced\"\n            \n        return strategy\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            self.iteration += 1\n            \n            # Landscape analysis every landscape_analysis_interval iterations\n            if self.iteration % self.landscape_analysis_interval == 0:\n                strategy = self.analyze_landscape(func)\n            else:\n                strategy = \"balanced\"  # Default strategy\n\n            for i in range(self.pop_size):\n                # Mutation Strategy Selection\n                if strategy == \"exploration\":\n                    # Exploration: Larger F, global search\n                    F_mutation = self.F[i] * 1.5 # Increase mutation strength\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs]\n                    mutant = x_r1 + F_mutation * (x_r2 - x_r3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                elif strategy == \"exploitation\":\n                    # Exploitation: Smaller F, local search\n                    F_mutation = self.F[i] * 0.5 # Reduce mutation strength\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs]\n                    mutant = self.pop[i] + F_mutation * (x_r2 - x_r3)  # Perturb around current individual\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                else:  # balanced\n                    # Balanced strategy: Standard DE\n                    F_mutation = self.F[i]\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs]\n                    mutant = x_r1 + F_mutation * (x_r2 - x_r3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr[i]\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update F and Cr based on success\n                    self.F[i] = np.clip(self.F[i] + self.learning_rate * (1 - self.F[i]), 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] + self.learning_rate * (1 - self.Cr[i]), 0.1, 1.0)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    # Reduce F and Cr if no improvement\n                    self.F[i] = np.clip(self.F[i] - self.learning_rate * self.F[i], 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] - self.learning_rate * self.Cr[i], 0.1, 1.0)\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm LandscapeAwareDE scored 0.449 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b556badf-77c2-4510-a225-4d522e15c4d1"], "operator": null, "metadata": {"aucs": [0.1639720582620321, 0.2668592044161402, 0.4135867387295217, 0.50676382313977, 0.34548453408404933, 0.6231200292656409, 0.3451251173318175, 0.45244453902057546, 0.41405375746470985, 0.26202412678521503, 0.3925559518865459, 0.9892675926900271, 0.2554433529837681, 0.3726799330547047, 0.7382144768791975, 0.7107173224801584, 0.34437837243005587, 0.6936421521036789, 0.19140347366083488, 0.4936654841519821]}}
{"id": "2fc83f1e-a986-47b8-a4fd-0986b511b234", "fitness": 0.5342655325076818, "name": "DecayingExplorationDE", "description": "An enhanced Differential Evolution strategy that uses a decaying exploration factor and adaptive population size to balance exploration and exploitation over the optimization process.", "code": "import numpy as np\n\nclass DecayingExplorationDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, F_init=0.5, Cr_init=0.9, learning_rate=0.1, exploration_factor_init=2.0, exploration_decay_rate=0.999, pop_size_decay_rate=0.995, min_pop_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.pop_size_init = pop_size_init\n        self.F = np.full(pop_size_init, F_init)\n        self.Cr = np.full(pop_size_init, Cr_init)\n        self.learning_rate = learning_rate\n        self.exploration_factor = exploration_factor_init\n        self.exploration_factor_init = exploration_factor_init\n        self.exploration_decay_rate = exploration_decay_rate\n        self.pop_size_decay_rate = pop_size_decay_rate\n        self.min_pop_size = min_pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.exploration_factor * self.F[i] * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr[i]\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update F and Cr based on success\n                    self.F[i] = np.clip(self.F[i] + self.learning_rate * (1 - self.F[i]), 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] + self.learning_rate * (1 - self.Cr[i]), 0.1, 1.0)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    # Reduce F and Cr if no improvement\n                    self.F[i] = np.clip(self.F[i] - self.learning_rate * self.F[i], 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] - self.learning_rate * self.Cr[i], 0.1, 1.0)\n\n                if self.budget <= 0:\n                    break\n            \n            # Decay exploration factor and population size\n            self.exploration_factor *= self.exploration_decay_rate\n            self.pop_size = max(int(self.pop_size * self.pop_size_decay_rate), self.min_pop_size)\n\n            # Resize population if needed\n            if self.pop_size < self.pop.shape[0]:\n                 indices = np.argsort(self.fitness)[:self.pop_size]\n                 self.pop = self.pop[indices]\n                 self.fitness = self.fitness[indices]\n                 self.F = self.F[indices]\n                 self.Cr = self.Cr[indices]\n            elif self.pop_size > self.pop.shape[0]:\n                num_new_individuals = self.pop_size - self.pop.shape[0]\n                new_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new_individuals, self.dim))\n                new_fitness = np.array([func(x) for x in new_pop])\n                self.budget -= num_new_individuals\n                \n                self.pop = np.concatenate((self.pop, new_pop))\n                self.fitness = np.concatenate((self.fitness, new_fitness))\n                self.F = np.concatenate((self.F, np.full(num_new_individuals, np.mean(self.F))))\n                self.Cr = np.concatenate((self.Cr, np.full(num_new_individuals, np.mean(self.Cr))))\n           \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm DecayingExplorationDE scored 0.534 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b556badf-77c2-4510-a225-4d522e15c4d1"], "operator": null, "metadata": {"aucs": [0.21810503230091238, 0.2757856466014962, 0.39161639574834495, 0.8072371087366614, 0.503432905719412, 0.8349992988335294, 0.46586443543602174, 0.4483703380948858, 0.5844629050607928, 0.4542050318522993, 0.5683823915616172, 0.9937155600337475, 0.23926323080393985, 0.35714304520447604, 0.7332145935424823, 0.8583022808176739, 0.38647870827258024, 0.8399089583964143, 0.2287863229811271, 0.49603646015522185]}}
{"id": "061291f6-1bec-4f03-a9f7-1c25a0b16023", "fitness": 0.3944147993642498, "name": "AdaptiveCauchyDE", "description": "An adaptive Differential Evolution strategy that uses a Cauchy mutation operator and dynamically adjusts parameters based on the success rate of individual agents.", "code": "import numpy as np\n\nclass AdaptiveCauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, learning_rate=0.1, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = np.full(pop_size, F_init)\n        self.Cr = np.full(pop_size, Cr_init)\n        self.learning_rate = learning_rate\n        self.cauchy_scale = cauchy_scale\n        self.pop = None\n        self.fitness = None\n        self.success_history = np.zeros(pop_size)  # Keep track of individual success\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation using Cauchy distribution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                cauchy_values = np.random.standard_cauchy(size=self.dim)\n                mutant = x_r1 + self.F[i] * (x_r2 - x_r3) + self.cauchy_scale * cauchy_values\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr[i]\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    # Update population\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    # Update success history\n                    self.success_history[i] += 1\n                    \n                    # Update F and Cr based on success\n                    self.F[i] = np.clip(self.F[i] + self.learning_rate * (1 - self.F[i]), 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] + self.learning_rate * (1 - self.Cr[i]), 0.1, 1.0)\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    # Reduce F and Cr if no improvement\n                    self.F[i] = np.clip(self.F[i] - self.learning_rate * self.F[i], 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] - self.learning_rate * self.Cr[i], 0.1, 1.0)\n                    self.success_history[i] = max(0, self.success_history[i] - 0.5)\n\n\n                # Dynamically adjust Cauchy scale based on overall success\n                success_rate = np.mean(self.success_history)\n                self.cauchy_scale = 0.1 + 0.4 * (1 - success_rate)  # Reduce scale if success is high\n                self.cauchy_scale = max(0.01, self.cauchy_scale)  # Ensure a minimal scale\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveCauchyDE scored 0.394 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b556badf-77c2-4510-a225-4d522e15c4d1"], "operator": null, "metadata": {"aucs": [0.1500763691759801, 0.21803394625392458, 0.3799700546258987, 0.38467216837094353, 0.30844007450097366, 0.4598296895713413, 0.3275786155175465, 0.37783327743211925, 0.31399791466096727, 0.19881896932742238, 0.3631728199034878, 0.9983920843357983, 0.2534895088841872, 0.42015948512799095, 0.7214993711104757, 0.48791267275013783, 0.3210128627980747, 0.4977437419681836, 0.21734288371386346, 0.48831947725567926]}}
{"id": "7f615ce3-0eaa-40ee-a76e-936264b04238", "fitness": 0.7254352064574725, "name": "DynamicPopulationDE", "description": "A differential evolution strategy with dynamically adjusted population size based on stagnation detection and a fitness-entropy-based diversity maintenance mechanism.", "code": "import numpy as np\n\nclass DynamicPopulationDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, F=0.5, Cr=0.9, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.F = F\n        self.Cr = Cr\n        self.stagnation_threshold = stagnation_threshold\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.stagnation_counter = 0\n        self.entropy_history = []\n\n    def __call__(self, func):\n        # Initialize population and fitness\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            \n            # Stagnation detection\n            if np.std(self.fitness) < 1e-6:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            # Dynamic population size adjustment\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Increase population size to introduce diversity\n                self.pop_size = int(self.pop_size * 1.2)  # Increase by 20%\n                self.pop_size = min(self.pop_size, 200) # Cap the pop size\n\n                new_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - self.pop.shape[0], self.dim))\n                new_fitness = np.array([func(x) for x in new_pop])\n                self.budget -= new_pop.shape[0]\n                \n                self.pop = np.concatenate((self.pop, new_pop), axis=0)\n                self.fitness = np.concatenate((self.fitness, new_fitness))\n\n                self.stagnation_counter = 0  # Reset stagnation counter\n                print(f\"Population size increased to {self.pop_size}\")\n            \n            elif self.pop_size > 20 and np.std(self.fitness) > 0.1: # Reduce population if not stagnated and good progress\n                self.pop_size = int(self.pop_size * 0.9)\n                \n                # Keep the best individuals and reduce the pop\n                idx = np.argsort(self.fitness)[:self.pop_size]\n                self.pop = self.pop[idx]\n                self.fitness = self.fitness[idx]\n                \n                print(f\"Population size reduced to {self.pop_size}\")\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                # Diversity maintenance based on fitness entropy\n                fitness_probs = np.exp(-self.fitness / np.std(self.fitness))  # Softmax-like transformation\n                fitness_probs /= np.sum(fitness_probs)\n                entropy = -np.sum(fitness_probs * np.log(fitness_probs + 1e-8))\n                self.entropy_history.append(entropy)\n                \n                if entropy < 0.5:  # Low entropy indicates low diversity\n                    # Introduce a random perturbation to a random individual\n                    idx_to_perturb = np.random.randint(0, self.pop_size)\n                    self.pop[idx_to_perturb] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    self.fitness[idx_to_perturb] = func(self.pop[idx_to_perturb])\n                    self.budget -= 1\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm DynamicPopulationDE scored 0.725 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["947535b4-fb37-48e9-b897-729428011b33"], "operator": null, "metadata": {"aucs": [0.19070373525218176, 0.8223582188178308, 0.43201965046871815, 0.9475439949288859, 0.8974474101380668, 0.9172097420777281, 0.37500091040013805, 0.8616108140370096, 0.905612697022953, 0.870264128488464, 0.931186640269689, 0.9863358431706786, 0.3438419499200046, 0.86869411089479, 0.9671532731216435, 0.8901587214051017, 0.6319536233814584, 0.932428807109872, 0.23265871412521233, 0.504521144119024]}}
{"id": "9440f4b4-4665-464a-8909-9e3623101d6e", "fitness": 0.6425126130317157, "name": "SHADENeighborDE", "description": "A DE variant employing a success-history based adaptation of F and CR parameters, coupled with a diversity maintenance strategy utilizing a nearest neighbor-based perturbation.", "code": "import numpy as np\n\nclass SHADENeighborDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_F = np.full(self.memory_size, 0.5)\n        self.memory_CR = np.full(self.memory_size, 0.5)\n        self.pop = None\n        self.fitness = None\n        self.archive = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population and fitness\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            memory_index = generation % self.memory_size\n\n            for i in range(self.pop_size):\n                # Sample F and CR from memory\n                F = np.random.choice(self.memory_F)\n                Cr = np.random.choice(self.memory_CR)\n                \n                F = np.clip(np.random.normal(F, 0.1), 0.1, 1.0)\n                Cr = np.clip(np.random.normal(Cr, 0.1), 0.1, 1.0)\n                \n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    # Update memory with success\n                    self.memory_F[memory_index] = F\n                    self.memory_CR[memory_index] = Cr\n\n                    # Archive discarded solutions\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(0, self.archive_size)\n                        self.archive[idx_to_replace] = self.pop[i].copy()\n\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    # Diversity maintenance using nearest neighbor perturbation\n                    distances = np.sum((self.pop - self.pop[i])**2, axis=1)\n                    nearest_neighbor_idx = np.argsort(distances)[1]  # Exclude self\n                    neighbor = self.pop[nearest_neighbor_idx]\n                    \n                    # Perturb the trial solution towards the nearest neighbor\n                    trial = trial + 0.05 * (neighbor - trial) * np.random.rand(self.dim)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                    \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm SHADENeighborDE scored 0.643 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["947535b4-fb37-48e9-b897-729428011b33"], "operator": null, "metadata": {"aucs": [0.2455826429801955, 0.31350656434479995, 0.5843768405615934, 0.8314325128330822, 0.5994482627420078, 0.7801191192438668, 0.5721989470743812, 0.6180310762930599, 0.7081547823470513, 0.46754681411252363, 0.8779792010504012, 0.9925507400308836, 0.5397673388564737, 0.6739382299153662, 0.8140546923420091, 0.7590913553523988, 0.4528438362218584, 0.8521703951260057, 0.6619050943757018, 0.5055538148306546]}}
{"id": "ff6e6ab6-f7d8-46ff-8047-3f88f06d5d11", "fitness": -Infinity, "name": "AdaptiveLandscapeDE", "description": "A Differential Evolution strategy with adaptive landscape mapping, utilizing a local search with gradient estimation to refine promising solutions.", "code": "import numpy as np\n\nclass AdaptiveLandscapeDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9, local_search_prob=0.1, local_search_step=0.01, gradient_estimation_radius=0.001):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.local_search_prob = local_search_prob\n        self.local_search_step = local_search_step\n        self.gradient_estimation_radius = gradient_estimation_radius\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.local_search(trial, func)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func):\n        # Estimate gradient\n        gradient = np.zeros(self.dim)\n        for j in range(self.dim):\n            x_plus = x.copy()\n            x_minus = x.copy()\n\n            x_plus[j] += self.gradient_estimation_radius\n            x_minus[j] -= self.gradient_estimation_radius\n\n            x_plus[j] = np.clip(x_plus[j], func.bounds.lb, func.bounds.ub)\n            x_minus[j] = np.clip(x_minus[j], func.bounds.lb, func.bounds.ub)\n\n            f_plus = func(x_plus)\n            f_minus = func(x_minus)\n            self.budget -= 2  # Account for gradient estimation evaluations\n            gradient[j] = (f_plus - f_minus) / (2 * self.gradient_estimation_radius)\n\n        # Move in the direction of the negative gradient\n        x_new = x - self.local_search_step * gradient\n        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n        return x_new", "configspace": "", "generation": 8, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["2fc83f1e-a986-47b8-a4fd-0986b511b234"], "operator": null, "metadata": {}}
{"id": "5359f7c1-f4e4-4aa3-a304-3ef2d329ab6a", "fitness": -Infinity, "name": "SOMAdaptiveDE", "description": "A differential evolution strategy that leverages a self-organizing map (SOM) to dynamically adjust crossover rate (CR) and mutation factor (F) based on the local landscape structure.", "code": "import numpy as np\nfrom minisom import MiniSom  # Requires: pip install MiniSom\n\nclass SOMAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, som_grid_size=10, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.som_grid_size = som_grid_size\n        self.memory_size = memory_size\n        self.memory_F = np.full(self.memory_size, 0.5)\n        self.memory_CR = np.full(self.memory_size, 0.5)\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.som = None\n\n    def __call__(self, func):\n        # Initialize population and fitness\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        # Initialize SOM\n        self.som = MiniSom(self.som_grid_size, self.som_grid_size, self.dim, sigma=0.3, learning_rate=0.5)\n        self.som.train(self.pop, num_iteration=100)\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            memory_index = generation % self.memory_size\n\n            # Map individuals to SOM nodes and determine F/CR adaptation\n            som_assignments = [self.som.winner(x) for x in self.pop]\n\n            for i in range(self.pop_size):\n                # Adapt F and CR based on SOM node\n                node_x, node_y = som_assignments[i]\n                \n                # Simple example: use node coordinates to influence F/CR\n                F = 0.1 + (node_x / self.som_grid_size) * 0.9  # F ranges from 0.1 to 1.0\n                Cr = node_y / self.som_grid_size  # CR ranges from 0.0 to 1.0\n                \n                F = np.clip(np.random.normal(F, 0.1), 0.1, 1.0)\n                Cr = np.clip(np.random.normal(Cr, 0.1), 0.1, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    # Update memory with success\n                    self.memory_F[memory_index] = F\n                    self.memory_CR[memory_index] = Cr\n\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                \n                if self.budget <= 0:\n                    break\n\n            # Retrain SOM periodically \n            if generation % 10 == 0:\n                self.som.train(self.pop, num_iteration=100)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occurred: No module named 'minisom'.", "error": "", "parent_ids": ["9440f4b4-4665-464a-8909-9e3623101d6e"], "operator": null, "metadata": {}}
{"id": "58dcf82b-d6e8-493f-a9d5-cb0ee2d28fa6", "fitness": 0.0, "name": "OrthogonalDE", "description": "An adaptive differential evolution algorithm that leverages orthogonal learning to enhance exploration by projecting individuals onto orthogonal subspaces and uses a restart mechanism triggered by stagnation.", "code": "import numpy as np\n\nclass OrthogonalDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, stagnation_threshold=100, orthogonal_components=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.stagnation_threshold = stagnation_threshold\n        self.orthogonal_components = orthogonal_components # Number of orthogonal directions to explore\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.stagnation_counter = 0\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        # Initialize population and fitness\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            # Stagnation detection\n            if np.std(self.fitness) < 1e-6:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.budget -= self.pop_size\n                self.stagnation_counter = 0\n                print(\"Restarting population due to stagnation.\")\n\n                # Update best solution after restart\n                f_min = np.min(self.fitness)\n                if f_min < self.f_opt:\n                    self.f_opt = f_min\n                    self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Orthogonal Learning\n                orthogonal_trials = []\n                for _ in range(self.orthogonal_components):\n                    direction = np.random.randn(self.dim)\n                    direction /= np.linalg.norm(direction)  # Normalize\n                    step_size = np.random.uniform(-0.1, 0.1) # Adaptive step size\n                    orthogonal_trial = trial + step_size * direction\n                    orthogonal_trial = np.clip(orthogonal_trial, self.lb, self.ub)\n                    orthogonal_trials.append(orthogonal_trial)\n\n                # Evaluate trials\n                f_trial = func(trial)\n                self.budget -= 1\n                orthogonal_fitnesses = [func(ot) for ot in orthogonal_trials]\n                self.budget -= self.orthogonal_components\n\n                # Selection\n                best_orthogonal_index = np.argmin(orthogonal_fitnesses) if orthogonal_fitnesses else -1\n\n                if best_orthogonal_index != -1 and orthogonal_fitnesses[best_orthogonal_index] < f_trial and orthogonal_fitnesses[best_orthogonal_index] < self.fitness[i]:\n                    best_trial = orthogonal_trials[best_orthogonal_index]\n                    f_best_trial = orthogonal_fitnesses[best_orthogonal_index]\n                    self.pop[i] = best_trial\n                    self.fitness[i] = f_best_trial\n                    if f_best_trial < self.f_opt:\n                        self.f_opt = f_best_trial\n                        self.x_opt = best_trial.copy()\n                elif f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                \n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm OrthogonalDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7f615ce3-0eaa-40ee-a76e-936264b04238"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "6606746d-17c1-4275-8ba5-4157fb1174b9", "fitness": 0.0, "name": "AdaptiveDE", "description": "An adaptive differential evolution algorithm that dynamically adjusts both its population size and mutation strategy based on the observed fitness landscape and uses a local search operator to enhance exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            \n            # Adapt population size based on fitness variance\n            fitness_std = np.std(self.fitness)\n            if fitness_std > 0.1:  # High variance, increase exploration (larger pop)\n                self.pop_size = min(self.pop_size + 5, self.max_pop_size)\n            elif fitness_std < 0.01:  # Low variance, increase exploitation (smaller pop)\n                self.pop_size = max(self.pop_size - 5, self.min_pop_size)\n\n            # Ensure population size is within bounds and re-initialize if changed significantly\n            if self.pop_size != self.pop.shape[0]:\n                self.pop_size = int(np.clip(self.pop_size, self.min_pop_size, self.max_pop_size))\n                new_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                if self.pop is not None:\n                    # Keep the best individuals from the old population\n                    num_to_keep = min(self.pop_size, self.pop.shape[0])\n                    best_indices = np.argsort(self.fitness)[:num_to_keep]\n                    new_pop[:num_to_keep] = self.pop[best_indices]\n\n                self.pop = new_pop\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.budget -= self.pop.shape[0] - (num_to_keep if self.pop is not None else 0)\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n                \n            for i in range(self.pop_size):\n                # Adaptive mutation strategy\n                if np.random.rand() < 0.5:  # DE/rand/1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs]\n                    F = np.random.uniform(0.5, 1.0)\n                    mutant = x_r1 + F * (x_r2 - x_r3)\n                else:  # DE/current-to-best/1\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[idxs]\n                    F = np.random.uniform(0.0, 0.5)\n                    mutant = self.pop[i] + F * (self.x_opt - self.pop[i]) + F * (x_r1 - x_r2)\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                Cr = np.random.uniform(0.3, 0.9)\n                cross_mask = np.random.rand(self.dim) < Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Local Search\n                if np.random.rand() < self.local_search_probability:\n                    trial = self.local_search(trial, func, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func, lb, ub, step_size=0.1, num_steps=5):\n        \"\"\"Performs a simple local search around a given solution.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n\n        for _ in range(num_steps):\n            # Generate a neighbor by perturbing each dimension\n            neighbor = x.copy()\n            for d in range(self.dim):\n                neighbor[d] += np.random.uniform(-step_size, step_size)\n            neighbor = np.clip(neighbor, lb, ub)\n            \n            f_neighbor = func(neighbor)\n            if f_neighbor < best_f:\n                best_f = f_neighbor\n                best_x = neighbor.copy()\n        return best_x", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9440f4b4-4665-464a-8909-9e3623101d6e"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "86b6ff68-aec5-453f-b4fe-016a2c51e91c", "fitness": 0.0, "name": "OrthogonalDE", "description": "A differential evolution strategy with self-adaptive parameters, population diversity maintenance using orthogonal learning, and dynamic resource allocation based on performance.", "code": "import numpy as np\n\nclass OrthogonalDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, learning_rate=0.1, orthogonal_decay=0.99, min_pop_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = np.full(pop_size, F_init)\n        self.Cr = np.full(pop_size, Cr_init)\n        self.learning_rate = learning_rate\n        self.orthogonal_decay = orthogonal_decay\n        self.min_pop_size = min_pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.success_F = []\n        self.success_Cr = []\n        self.archive = []\n\n    def generate_orthogonal_array(self, levels, factors):\n        # A simplified orthogonal array generation (for illustration).  For real use, employ a proper OA library.\n        # This assumes levels are a power of prime.\n        if levels == 2:\n            if factors > 0 and factors <= 3:\n                if factors == 1:\n                    return np.array([[0], [1]])\n                elif factors == 2:\n                     return np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n                else:  # factors == 3\n                    return np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 0]])\n\n        return np.random.randint(0, levels, size=(levels**2, factors)) # very crude approximation for higher levels.\n\n    def orthogonal_crossover(self, x, mutant, func):\n        levels = 3 # low, medium, high\n        factors = self.dim\n        oa = self.generate_orthogonal_array(levels, factors)\n        \n        trial_population = []\n        for row in oa:\n          trial = np.zeros(self.dim)\n          for j in range(self.dim):\n            if row[j] == 0:\n              trial[j] = x[j]\n            elif row[j] == 1:\n              trial[j] = mutant[j]\n            else: #row[j] == 2: create a random value between x[j] and mutant[j]\n               trial[j] = np.random.uniform(min(x[j], mutant[j]), max(x[j], mutant[j]))\n          trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n          trial_population.append(trial)\n        \n        fitnesses = [func(trial) for trial in trial_population]\n        self.budget -= len(fitnesses)\n\n        best_index = np.argmin(fitnesses)\n        best_trial = trial_population[best_index]\n        best_fitness = fitnesses[best_index]\n\n        return best_trial, best_fitness\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F[i] * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                trial, f_trial = self.orthogonal_crossover(self.pop[i], mutant, func)\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update F and Cr based on success\n                    self.success_F.append(self.F[i])\n                    self.success_Cr.append(self.Cr[i])\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    self.archive.append(self.pop[i].copy())\n\n                if self.budget <= 0:\n                    break\n\n            # Update F and CR\n            if self.success_F:\n                self.F = np.clip(0.9 * self.F + 0.1 * np.mean(self.success_F), 0.1, 1.0)\n                self.Cr = np.clip(0.9 * self.Cr + 0.1 * np.mean(self.success_Cr), 0.1, 1.0)\n                self.success_F = []\n                self.success_Cr = []\n\n            # Diversity maintenance (remove duplicates, add random if too similar)\n            unique_pop = np.unique(self.pop, axis=0)\n            if len(unique_pop) < self.pop_size:\n                num_missing = self.pop_size - len(unique_pop)\n                new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_missing, self.dim))\n                new_fitness = np.array([func(x) for x in new_individuals])\n                self.budget -= num_missing\n                self.pop = np.concatenate((unique_pop, new_individuals))\n                self.fitness = np.concatenate((self.fitness[np.argsort(self.fitness)[:len(unique_pop)]], new_fitness))\n\n            #Dynamic Resource Allocation (simplified - reduce pop size if stagnant)\n            if generation % 10 == 0:\n                if np.std(self.fitness) < 1e-6:\n                    self.pop_size = max(int(self.pop_size * 0.95), self.min_pop_size)\n                    if self.pop_size < self.pop.shape[0]:\n                        indices = np.argsort(self.fitness)[:self.pop_size]\n                        self.pop = self.pop[indices]\n                        self.fitness = self.fitness[indices]\n                        self.F = self.F[indices]\n                        self.Cr = self.Cr[indices]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm OrthogonalDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2fc83f1e-a986-47b8-a4fd-0986b511b234"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "4a15456e-e52c-4e5b-a194-da4967183dd5", "fitness": 0.0, "name": "AdaptiveHerdingDE", "description": "Adaptive Differential Evolution with orthogonal learning, population herding and restart strategy based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveHerdingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, learning_rate=0.1, stagnation_threshold=100, herding_probability=0.1, orthogonal_learning_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = np.full(pop_size, F_init)\n        self.Cr = np.full(pop_size, Cr_init)\n        self.learning_rate = learning_rate\n        self.stagnation_threshold = stagnation_threshold\n        self.herding_probability = herding_probability\n        self.orthogonal_learning_probability = orthogonal_learning_probability\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.iteration = 0\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def orthogonal_learning(self, func, x):\n        \"\"\"Performs orthogonal learning to generate a new solution.\"\"\"\n        basis = np.random.randn(self.dim, self.dim)  # Generate a random orthogonal basis\n        Q, _ = np.linalg.qr(basis)  # Orthonormalize the basis using QR decomposition\n        new_x = x.copy()\n\n        for i in range(self.dim):\n            # Project the current solution onto the basis vector\n            projection = np.dot(x, Q[:, i])\n            \n            # Generate a random step along the basis vector\n            step = np.random.uniform(-1, 1)\n            \n            # Create a candidate solution\n            candidate = x + step * Q[:, i]\n            candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate the candidate solution\n            f_candidate = func(candidate)\n            self.budget -= 1\n            \n            if self.budget <= 0:\n                return new_x #Early Termination\n            \n            # If the candidate is better, update the solution\n            if f_candidate < func(new_x):\n                new_x = candidate\n                \n        return new_x\n\n\n    def herd_towards_best(self, x_i, x_best):\n        \"\"\"Moves the solution x_i towards the best solution x_best.\"\"\"\n        direction = x_best - x_i\n        step_size = np.random.rand() * self.learning_rate # Random step size towards best\n        new_x = x_i + step_size * direction\n        return new_x\n\n    def restart_population(self, func):\n        \"\"\"Restarts the population with new random individuals.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n        self.stagnation_counter = 0\n        self.best_fitness_history = [self.f_opt]\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness_history.append(self.f_opt)\n\n\n        while self.budget > 0:\n            self.iteration += 1\n\n            for i in range(self.pop_size):\n                # Standard DE mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F[i] * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr[i]\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Herding Behavior\n                if np.random.rand() < self.herding_probability:\n                    trial = self.herd_towards_best(trial, self.x_opt)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Learning\n                if np.random.rand() < self.orthogonal_learning_probability:\n                   trial = self.orthogonal_learning(func, trial)\n                   trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update F and Cr based on success\n                    self.F[i] = np.clip(self.F[i] + self.learning_rate * (1 - self.F[i]), 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] + self.learning_rate * (1 - self.Cr[i]), 0.1, 1.0)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                        self.stagnation_counter = 0 # Reset stagnation counter when finding a better solution\n                else:\n                    # Reduce F and Cr if no improvement\n                    self.F[i] = np.clip(self.F[i] - self.learning_rate * self.F[i], 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] - self.learning_rate * self.Cr[i], 0.1, 1.0)\n\n                if self.budget <= 0:\n                    break\n            \n            #Stagnation Check\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n              self.best_fitness_history.pop(0) #remove the oldest element\n              if abs(self.best_fitness_history[-1] - self.best_fitness_history[0]) < 1e-8: #check if the improvement stagnates\n                self.stagnation_counter +=1\n              else:\n                self.stagnation_counter = 0\n            \n              if self.stagnation_counter >= self.stagnation_threshold:\n                  self.restart_population(func)\n                  self.stagnation_counter = 0\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveHerdingDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e567d03a-5eee-4e91-8076-ff2fb67061b4"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "25e31fc4-759b-4a55-b3c6-af52bf942e32", "fitness": 0.7057593168152944, "name": "MirroredAdaptiveDE", "description": "An adaptive differential evolution strategy that uses a mirrored sampling technique and dynamic parameter adaptation based on the success rate of past generations.", "code": "import numpy as np\n\nclass MirroredAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, learning_rate=0.1, mirror_rate=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = np.full(pop_size, F_init)\n        self.Cr = np.full(pop_size, Cr_init)\n        self.learning_rate = learning_rate\n        self.mirror_rate = mirror_rate  # Probability of using mirrored sampling\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.success_history_F = []\n        self.success_history_Cr = []\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        generation = 0\n        while self.budget > 0:\n            successful_F = []\n            successful_Cr = []\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n\n                # Mirrored sampling\n                if np.random.rand() < self.mirror_rate:\n                    mutant = self.pop[i] + self.F[i] * (x_r1 - self.pop[i]) + self.F[i] * (x_r2 - x_r3)\n                else:\n                     mutant = x_r1 + self.F[i] * (x_r2 - x_r3)\n                \n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr[i]\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    successful_F.append(self.F[i])\n                    successful_Cr.append(self.Cr[i])\n\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n            \n            # Parameter adaptation based on success history\n            if successful_F:\n                mean_successful_F = np.mean(successful_F)\n                self.F = np.clip(self.F + self.learning_rate * (mean_successful_F - self.F), 0.1, 1.0)\n\n            if successful_Cr:\n                mean_successful_Cr = np.mean(successful_Cr)\n                self.Cr = np.clip(self.Cr + self.learning_rate * (mean_successful_Cr - self.Cr), 0.1, 1.0)\n\n            generation += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm MirroredAdaptiveDE scored 0.706 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2fc83f1e-a986-47b8-a4fd-0986b511b234"], "operator": null, "metadata": {"aucs": [0.3226587148779134, 0.6755152945665001, 0.6704952577786389, 0.8763128985247616, 0.768171232155534, 0.8138564313191383, 0.6729156232017275, 0.6802413807895851, 0.7540876853759801, 0.6583990887792416, 0.8605032696816262, 0.9818448901722555, 0.6810748121551037, 0.7618134006891579, 0.9110836367475791, 0.7869631380056041, 0.6371330594247069, 0.8565391891249723, 0.23593161627639825, 0.5096457166594626]}}
{"id": "09c6a30c-20c3-4080-bae8-174f297f2685", "fitness": 0.5196529071262374, "name": "AdaptiveArchiveDE", "description": "A differential evolution strategy employing a dynamically updated archive with fitness-based replacement and a self-adaptive step size control using a combination of global and local information.", "code": "import numpy as np\n\nclass AdaptiveArchiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.pop = None\n        self.fitness = None\n        self.archive = []\n        self.archive_fitness = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.step_size = 0.1  # Initial step size\n\n    def __call__(self, func):\n        # Initialize population and fitness\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            # Adaptive step size adjustment based on fitness variance\n            fitness_variance = np.var(self.fitness)\n            self.step_size = np.clip(self.step_size * (1 + 0.1 * (fitness_variance - 0.5)), 0.01, 0.5)\n\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.step_size * (x_r2 - x_r3)  # Adjusted mutation\n\n                # Optionally use archive for mutation\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    archive_idx = np.random.randint(0, len(self.archive))\n                    mutant = x_r1 + self.step_size * (self.archive[archive_idx] - x_r3)\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                Cr = np.random.rand()  # Fixed CR for simplicity\n                cross_mask = np.random.rand(self.dim) < Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    # Update archive with fitness-based replacement\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                        self.archive_fitness.append(self.fitness[i])\n                    else:\n                        # Replace worst element in archive\n                        max_fitness_idx = np.argmax(self.archive_fitness)\n                        if self.fitness[i] < self.archive_fitness[max_fitness_idx]:\n                            self.archive[max_fitness_idx] = self.pop[i].copy()\n                            self.archive_fitness[max_fitness_idx] = self.fitness[i]\n\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                else:\n                    # Local search around current best (exploitation)\n                    if np.random.rand() < 0.05:\n                        trial = self.pop[i] + np.random.normal(0, self.step_size/5, self.dim)\n                        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                        f_trial = func(trial)\n                        self.budget -= 1\n\n                        if f_trial < self.fitness[i]:\n                            self.pop[i] = trial\n                            self.fitness[i] = f_trial\n                            if f_trial < self.f_opt:\n                                self.f_opt = f_trial\n                                self.x_opt = trial.copy()\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveArchiveDE scored 0.520 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9440f4b4-4665-464a-8909-9e3623101d6e"], "operator": null, "metadata": {"aucs": [0.19158151212467922, 0.36533254645831126, 0.3659021530565504, 0.7800032634008209, 0.5721071801867442, 0.6107556003503216, 0.36185517833877734, 0.4108429213333241, 0.5429886850422785, 0.46627916165772354, 0.7643586193879244, 0.997540338670234, 0.34820572602933997, 0.5394904329719907, 0.7453835260230615, 0.5527570430262636, 0.42183699483857184, 0.6438752653333157, 0.1973846593920311, 0.514577334902486]}}
{"id": "283770ea-ff86-4759-b7d6-c74f6cb25f3d", "fitness": 0.49968562358797086, "name": "SelfAdaptiveDE", "description": "A differential evolution strategy with a self-adaptive exploration factor controlled by the success rate of previous generations and adaptive population diversity controlled by the fitness distribution.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, F_init=0.5, Cr_init=0.9, learning_rate=0.1, exploration_factor_init=2.0, exploration_factor_decay=0.995, min_pop_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.pop_size_init = pop_size_init\n        self.F = np.full(pop_size_init, F_init)\n        self.Cr = np.full(pop_size_init, Cr_init)\n        self.learning_rate = learning_rate\n        self.exploration_factor = exploration_factor_init\n        self.exploration_factor_init = exploration_factor_init\n        self.exploration_factor_decay = exploration_factor_decay\n        self.min_pop_size = min_pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.success_rate = 0.0\n        self.success_history = []\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            successful_mutations = 0\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.exploration_factor * self.F[i] * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr[i]\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    successful_mutations += 1\n\n                    # Update F and Cr based on success\n                    self.F[i] = np.clip(self.F[i] + self.learning_rate * (1 - self.F[i]), 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] + self.learning_rate * (1 - self.Cr[i]), 0.1, 1.0)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    # Reduce F and Cr if no improvement\n                    self.F[i] = np.clip(self.F[i] - self.learning_rate * self.F[i], 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] - self.learning_rate * self.Cr[i], 0.1, 1.0)\n\n                if self.budget <= 0:\n                    break\n            \n            # Adjust exploration factor based on success rate\n            self.success_rate = successful_mutations / self.pop_size\n            self.success_history.append(self.success_rate)\n            if len(self.success_history) > 10:\n                self.success_history.pop(0)\n            \n            avg_success = np.mean(self.success_history)\n\n            if avg_success > 0.5:\n                self.exploration_factor *= self.exploration_factor_decay  # Reduce exploration if doing well\n            else:\n                self.exploration_factor /= self.exploration_factor_decay  # Increase exploration if stagnating\n            \n            self.exploration_factor = np.clip(self.exploration_factor, 0.1, self.exploration_factor_init * 2)\n\n\n            # Adjust population size based on fitness distribution\n            fitness_std = np.std(self.fitness)\n            if fitness_std < 1e-3:  #Stagnation\n                self.pop_size = min(self.pop_size + 5, self.pop_size_init * 2) #Increase population if stagnant\n            else:\n                self.pop_size = max(int(self.pop_size * 0.995), self.min_pop_size) # Reduce pop size otherwise\n                \n            self.pop_size = int(self.pop_size)\n\n            # Resize population if needed\n            if self.pop_size < self.pop.shape[0]:\n                 indices = np.argsort(self.fitness)[:self.pop_size]\n                 self.pop = self.pop[indices]\n                 self.fitness = self.fitness[indices]\n                 self.F = self.F[indices]\n                 self.Cr = self.Cr[indices]\n            elif self.pop_size > self.pop.shape[0]:\n                num_new_individuals = self.pop_size - self.pop.shape[0]\n                new_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new_individuals, self.dim))\n                new_fitness = np.array([func(x) for x in new_pop])\n                self.budget -= num_new_individuals\n                \n                self.pop = np.concatenate((self.pop, new_pop))\n                self.fitness = np.concatenate((self.fitness, new_fitness))\n                self.F = np.concatenate((self.F, np.full(num_new_individuals, np.mean(self.F))))\n                self.Cr = np.concatenate((self.Cr, np.full(num_new_individuals, np.mean(self.Cr))))\n\n           \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm SelfAdaptiveDE scored 0.500 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2fc83f1e-a986-47b8-a4fd-0986b511b234"], "operator": null, "metadata": {"aucs": [0.18954116162539814, 0.28885542492852334, 0.4880128332894075, 0.7783952777617651, 0.5234951271382262, 0.7069437479829113, 0.3183963536946347, 0.44796987344054406, 0.44330690823592644, 0.37300162764977995, 0.5590724876749958, 0.9987324540279297, 0.2566688928281067, 0.3611810586451041, 0.6858520147937855, 0.7709508379328902, 0.3668738372817397, 0.7188533109646809, 0.2246052730873377, 0.49300396877573016]}}
{"id": "14e55d76-56dc-4c5c-b454-ac8ade80c005", "fitness": 0.4519125300751806, "name": "OLOADE", "description": "A differential evolution strategy that adapts its mutation operator and population diversity using a combination of orthogonal learning and opposition-based learning.", "code": "import numpy as np\n\nclass OLOADE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, learning_rate=0.1, orthogonal_learning_interval=50, opposition_learning_interval=75):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = np.full(pop_size, F_init)\n        self.Cr = np.full(pop_size, Cr_init)\n        self.learning_rate = learning_rate\n        self.orthogonal_learning_interval = orthogonal_learning_interval\n        self.opposition_learning_interval = opposition_learning_interval\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.iteration = 0\n\n    def orthogonal_learning(self, func):\n        \"\"\"Implements orthogonal learning to generate diverse candidate solutions.\"\"\"\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n\n            # Select two random indices (excluding current individual)\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x_r1, x_r2 = self.pop[idxs]\n\n            # Generate orthogonal direction\n            orthogonal_direction = x_r2 - x_r1\n            \n            # Generate new candidate solution\n            candidate = self.pop[i] + np.random.uniform(-1, 1) * orthogonal_direction\n            candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate the candidate\n            f_candidate = func(candidate)\n            self.budget -= 1\n\n            # Selection: Replace individual if the candidate is better\n            if f_candidate < self.fitness[i]:\n                self.pop[i] = candidate\n                self.fitness[i] = f_candidate\n\n                if f_candidate < self.f_opt:\n                    self.f_opt = f_candidate\n                    self.x_opt = candidate.copy()\n\n    def opposition_based_learning(self, func):\n        \"\"\"Implements opposition-based learning to enhance population diversity.\"\"\"\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n            \n            # Generate opposite point\n            opposite_point = func.bounds.lb + func.bounds.ub - self.pop[i]\n\n            # Clip the opposite point to ensure it stays within the bounds\n            opposite_point = np.clip(opposite_point, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate the opposite point\n            f_opposite = func(opposite_point)\n            self.budget -= 1\n\n            # Selection: Replace individual if the opposite point is better\n            if f_opposite < self.fitness[i]:\n                self.pop[i] = opposite_point\n                self.fitness[i] = f_opposite\n\n                if f_opposite < self.f_opt:\n                    self.f_opt = f_opposite\n                    self.x_opt = opposite_point.copy()\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n\n        while self.budget > 0:\n            self.iteration += 1\n\n            # Apply orthogonal learning every orthogonal_learning_interval iterations\n            if self.iteration % self.orthogonal_learning_interval == 0:\n                self.orthogonal_learning(func)\n\n            # Apply opposition-based learning every opposition_learning_interval iterations\n            if self.iteration % self.opposition_learning_interval == 0:\n                self.opposition_based_learning(func)\n                \n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F[i] * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr[i]\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update F and Cr based on success\n                    self.F[i] = np.clip(self.F[i] + self.learning_rate * (1 - self.F[i]), 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] + self.learning_rate * (1 - self.Cr[i]), 0.1, 1.0)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    # Reduce F and Cr if no improvement\n                    self.F[i] = np.clip(self.F[i] - self.learning_rate * self.F[i], 0.1, 1.0)\n                    self.Cr[i] = np.clip(self.Cr[i] - self.learning_rate * self.Cr[i], 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm OLOADE scored 0.452 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e567d03a-5eee-4e91-8076-ff2fb67061b4"], "operator": null, "metadata": {"aucs": [0.20361942767301866, 0.2221123639081951, 0.43773050632303456, 0.4220707029020381, 0.4037312133667518, 0.6091274571959291, 0.36996485757058895, 0.4187995560992752, 0.4374532661276713, 0.24062862944099261, 0.41634777017327895, 0.9989183258913352, 0.2773728232366892, 0.3630231762817281, 0.738275072907318, 0.7037604623731587, 0.3627309023875793, 0.6874349705980085, 0.22170157657599687, 0.5034475404710234]}}
{"id": "d1ef6e73-53c4-4d33-b442-af31229f19d3", "fitness": -Infinity, "name": "SOM_ADE", "description": "Adaptive Differential Evolution with a self-organizing map (SOM) for population distribution and restart strategy to escape local optima.", "code": "import numpy as np\nfrom minisom import MiniSom  # Ensure minisom is installed: pip install MiniSom\n\nclass SOM_ADE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, som_grid_size=10, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.som_grid_size = som_grid_size\n        self.stagnation_threshold = stagnation_threshold\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.stagnation_counter = 0\n        self.som = None\n        self.som_initialized = False\n\n    def initialize_som(self):\n        \"\"\"Initializes the SOM if not already initialized.\"\"\"\n        if not self.som_initialized:\n            self.som = MiniSom(self.som_grid_size, self.som_grid_size, self.dim, sigma=0.3, learning_rate=0.5)\n            self.som.train_random(self.pop, 1000)  # Train SOM on initial population\n            self.som_initialized = True\n\n    def distribute_population(self, func):\n        \"\"\"Distributes the population based on the SOM.\"\"\"\n        new_pop = np.zeros_like(self.pop)\n        new_fitness = np.zeros_like(self.fitness)\n\n        for i in range(self.pop_size):\n            winner = self.som.winner(self.pop[i])  # Find the best matching unit (BMU)\n            \n            # Sample a new individual from the neighborhood of the BMU\n            neighborhood = []\n            for x in range(max(0, winner[0]-1), min(self.som_grid_size, winner[0]+2)):\n                for y in range(max(0, winner[1]-1), min(self.som_grid_size, winner[1]+2)):\n                    neighborhood.append((x, y))\n            \n            selected_node = neighborhood[np.random.randint(len(neighborhood))]\n            new_individual = self.som.get_weights()[selected_node[0], selected_node[1]] + np.random.normal(0, 0.1, self.dim) # Add noise\n            new_individual = np.clip(new_individual, func.bounds.lb, func.bounds.ub)\n\n            new_pop[i] = new_individual\n            new_fitness[i] = func(new_individual)\n            self.budget -= 1\n\n        self.pop = new_pop\n        self.fitness = new_fitness\n\n    def __call__(self, func):\n        # Initialize population and fitness\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        # Initial best solution\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n        \n        self.initialize_som() # Initialize SOM\n\n        while self.budget > 0:\n            # Stagnation detection\n            if np.std(self.fitness) < 1e-6:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n            \n            # Restart strategy\n            if self.stagnation_counter > self.stagnation_threshold:\n                print(\"Restarting population...\")\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.budget -= self.pop_size\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n                self.stagnation_counter = 0\n                self.som = MiniSom(self.som_grid_size, self.som_grid_size, self.dim, sigma=0.3, learning_rate=0.5)\n                self.som.train_random(self.pop, 1000)\n                continue  # Skip the DE step and redistribute\n            \n            #DE step\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.pop[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n            \n            self.distribute_population(func) # Redistribute the population based on SOM\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occurred: No module named 'minisom'.", "error": "", "parent_ids": ["7f615ce3-0eaa-40ee-a76e-936264b04238"], "operator": null, "metadata": {}}
{"id": "99db6e96-de88-4d38-b5e7-453cd3037c49", "fitness": 0.2760334169730696, "name": "AdaptiveRestartCMAESDE", "description": "Implements a Differential Evolution strategy with adaptive restart and covariance matrix adaptation to improve search direction and step size.", "code": "import numpy as np\n\nclass AdaptiveRestartCMAESDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, restart_trigger=10, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # Default CMA-ES population size\n        self.restart_trigger = restart_trigger # Number of iterations before restart check\n        self.learning_rate = learning_rate\n\n        self.mean = np.zeros(dim)  # Initialize mean to zero\n        self.covariance = np.eye(dim)  # Initialize covariance matrix to identity\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.iteration = 0\n        self.success_history = []\n\n    def generate_population(self, func):\n        population = np.random.multivariate_normal(self.mean, self.covariance, self.pop_size)\n        population = np.clip(population, func.bounds.lb, func.bounds.ub)\n        return population\n\n    def update_covariance(self, successful_steps):\n        \"\"\"Updates the covariance matrix based on successful steps.\"\"\"\n        if not successful_steps:\n            return  # No updates if no successful steps\n\n        successful_steps = np.array(successful_steps)\n        d_vectors = successful_steps - self.mean  # Vectors from mean to successful points\n        \n        # Rank-one update: simple and robust way to incorporate information\n        delta = d_vectors[0]  # Simplest: use only the most recent successful step\n        self.covariance = (1 - self.learning_rate) * self.covariance + self.learning_rate * np.outer(delta, delta)\n        \n        # Ensure covariance matrix remains positive definite\n        try:\n            np.linalg.cholesky(self.covariance)\n        except np.linalg.LinAlgError:\n            # If not positive definite, regularize by adding a small identity matrix\n            self.covariance += 1e-6 * np.eye(self.dim)\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim) # Initialize mean randomly within bounds\n        self.covariance = np.eye(self.dim) * (func.bounds.ub - func.bounds.lb)**2 / 12 # Initialize to cover the range\n\n        while self.budget > 0:\n            self.iteration += 1\n            population = self.generate_population(func)\n            fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                mutant = x_r1 + 0.5 * (x_r2 - x_r3)  # Standard DE mutation\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                cross_mask = np.random.rand(self.dim) < 0.9 # Fixed Cr for simplicity\n                trial = np.where(cross_mask, mutant, population[i])\n\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    self.success_history.append(trial)  # Keep track of successful steps\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n            \n            # Adaptive Restart Mechanism and Covariance Adaptation\n            if self.iteration % self.restart_trigger == 0:\n                # Covariance matrix adaptation based on success history\n                self.update_covariance(self.success_history)\n                self.success_history = [] # Reset history\n\n                # Check for stagnation (small fitness improvement)\n                if np.abs(self.f_opt - np.min(fitness)) < 1e-8:\n                    # Restart from a new random location if stagnating\n                    self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n                    self.covariance = np.eye(self.dim) * (func.bounds.ub - func.bounds.lb)**2 / 12 # Re-initialize\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveRestartCMAESDE scored 0.276 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e567d03a-5eee-4e91-8076-ff2fb67061b4"], "operator": null, "metadata": {"aucs": [0.10101165221195729, 0.16952039305057387, 0.2524456436370629, 0.17320607547427047, 0.1913761041496569, 0.25645356899894167, 0.22436686576844989, 0.18967533942332382, 0.18908326584323853, 0.16434197051078503, 0.23765074886676407, 0.9976907427690173, 0.21081508198580923, 0.11660373694431714, 0.6669837811074846, 0.2630683645509997, 0.23275425043999576, 0.25709630530319605, 0.1629838201861299, 0.463540628239418]}}
