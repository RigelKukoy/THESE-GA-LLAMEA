{"id": "676348f9-5d01-43f8-9656-ad795c8920d9", "fitness": -Infinity, "name": "CMAES", "description": "Covariance matrix adaptation evolution strategy with a population size of 4 + floor(3*log(D)), where D is the dimensionality.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2  # Number of parents/elite members\n        self.c_m = 1  # Step size for the mean\n        self.c_sigma = (self.mu + 2) / (self.dim + self.mu + 5)  # Step size for sigma\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (4 + self.mu / self.dim) / (self.dim + 4 + 2 * self.mu / self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.D = np.ones(self.dim)\n        self.B = np.eye(self.dim)\n        self.m = None\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        evals = 0\n        while evals < self.budget:\n            # Generate population\n            z = np.random.randn(self.dim, self.popsize)\n            x = self.m[:, np.newaxis] + self.sigma0 * (self.B @ (self.D[:, np.newaxis] * z))\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(x[:, i]) for i in range(self.popsize)])\n            evals += self.popsize\n\n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n\n            # Update optimal values\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.mean(x[:, :self.mu], axis=1)\n            \n            # Update evolution path for covariance matrix\n            zmean = np.mean(z[:, :self.mu], axis=1)\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (self.B @ zmean)\n            \n            # Dampen sigma\n            norm_ps = np.linalg.norm(self.ps) / self.chiN\n            self.sigma0 *= np.exp(self.c_sigma / self.d_sigma * (norm_ps - 1))\n\n            # Update evolution path for mean\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n\n            # Update covariance matrix\n            self.C = (1 - self.c_c) * self.C + self.c_c * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :])\n            \n            try: \n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(np.abs(self.D))\n            except np.linalg.LinAlgError:\n                # If the covariance matrix is close to singular, add a small value to the diagonal\n                self.C += 1e-8 * np.eye(self.dim)\n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(np.abs(self.D))\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "1bb22413-71e7-4739-b8a5-7d5029a0f2fa", "fitness": -Infinity, "name": "CMAES", "description": "Covariance matrix adaptation evolution strategy (CMA-ES) with restarts and active population size adaptation.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, dsigma=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = cs\n        self.dsigma = dsigma\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.count = 0\n        self.restarts = 0\n        self.max_restarts = 10\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.sigma = 0.1 * (func.bounds.ub - func.bounds.lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n        self.invC = np.eye(self.dim)\n\n        while self.count < self.budget and self.restarts < self.max_restarts:\n            \n            # Sample population\n            z = np.random.normal(size=(self.popsize, self.dim))\n            x = self.mean + self.sigma * (self.B @ (self.D * z.T)).T\n            \n            # Clip to bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            f = np.array([func(xi) for xi in x])\n            self.count += self.popsize\n\n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update CMA-ES parameters\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n            zmean = np.sum(self.weights[:, None] * z[idx[:self.mu]], axis=0)\n            \n            self.ps = (1 - self.cs) * self.ps + (self.cs * (2 - self.cs) * self.mueff)**0.5 * self.invC @ (xmean - self.mean) / self.sigma\n            hsig = (np.sum(self.ps**2) / (1 - (1 - self.cs)**(2*self.count/self.popsize))/self.dim) < 2 + 4/(self.dim+1)\n            self.pc = (1 - self.cc) * self.pc + hsig * (self.cc * (2 - self.cc) * self.mueff)**0.5 * (xmean - self.mean) / self.sigma\n            \n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (self.pc[:, None] @ self.pc[None, :]) + \\\n                       self.cmu * (self.weights[:, None] * (x[:self.mu] - self.mean).T) @ ((x[:self.mu] - self.mean) / self.sigma).T / self.sigma\n            \n            self.sigma *= np.exp((self.cs/self.dsigma) * (np.linalg.norm(self.ps)/self.chiN - 1))\n            self.mean = xmean\n\n            try:\n                self.C = np.triu(self.C) + np.triu(self.C, 1).T\n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(self.D)\n                self.invC = self.B @ np.diag(self.D**-1) @ self.B.T\n            except np.linalg.LinAlgError:\n                self.restarts += 1\n                self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.sigma = 0.1 * (func.bounds.ub - func.bounds.lb)\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.B = np.eye(self.dim)\n                self.D = np.ones(self.dim)\n                self.invC = np.eye(self.dim)\n                continue\n\n            # Adjust population size\n            if self.count > self.budget / 2 and self.popsize > 6:\n                self.popsize -= 2\n                self.mu = self.popsize // 2\n                self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n                self.weights /= np.sum(self.weights)\n                self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n                self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n                self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n                self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff))\n\n            if np.any(self.D < 1e-10):\n                 self.restarts += 1\n                 self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                 self.sigma = 0.1 * (func.bounds.ub - func.bounds.lb)\n                 self.C = np.eye(self.dim)\n                 self.pc = np.zeros(self.dim)\n                 self.ps = np.zeros(self.dim)\n                 self.B = np.eye(self.dim)\n                 self.D = np.ones(self.dim)\n                 self.invC = np.eye(self.dim)\n                 continue\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,) (2,6) .", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "194f008f-847c-4e1e-b3bc-c6ef7b8b1b63", "fitness": 0.18366956684277164, "name": "NovelAlgorithm", "description": "Population-based algorithm with a central moving mean, stochastic individual learning, and a diversity mechanism using a repulsive force.", "code": "import numpy as np\n\nclass NovelAlgorithm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1, repulsion_strength=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.repulsion_strength = repulsion_strength\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # reduce budget\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Calculate the mean of the population\n            mean = np.mean(population, axis=0)\n\n            # Update population based on the mean and individual learning\n            for i in range(self.pop_size):\n                # Individual learning: move towards a random other individual\n                random_index = np.random.randint(self.pop_size)\n                individual_learning_direction = population[random_index] - population[i]\n                \n                # Move towards the mean\n                mean_direction = mean - population[i]\n\n                # Repulsion from the best solution (diversity mechanism)\n                repulsion_direction = population[i] - self.x_opt\n                \n                # Normalize the repulsion direction, handle the edge case where population[i] is identical to self.x_opt\n                norm = np.linalg.norm(repulsion_direction)\n                if norm > 0:\n                    repulsion_direction = repulsion_direction / norm\n                \n                # Update the individual with a combination of mean, individual learning and repulsion\n                new_position = population[i] + self.lr * mean_direction + self.lr * individual_learning_direction + self.repulsion_strength * repulsion_direction\n                \n                # Clip to bounds\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                new_fitness = func(new_position)\n                self.budget -= 1 # reduce budget\n\n                # Update if the new position is better\n                if new_fitness < fitness[i]:\n                    population[i] = new_position\n                    fitness[i] = new_fitness\n\n                    # Update global best\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm NovelAlgorithm scored 0.184 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.0753910681348039, 0.14188239501078892, 0.26618734956970225, 0.15676475383762023, 0.13445361139891188, 0.15164395319347745, 0.21075232274564548, 0.1956122232274482, 0.16951455660563675, 0.14034038779634683, 0.1293387965007632, 0.2180908196460698, 0.2455682938083792, 0.09759446174454711, 0.13379176150946515, 0.2889713834749702, 0.16774551685792216, 0.2006063922629885, 0.15389473337893322, 0.39524655615101223]}}
{"id": "645dbd1c-3ad0-4d6c-9e2b-127301825437", "fitness": 0.7303713369745779, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Archive and Elitism, dynamically adjusting parameters based on success.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7 # Initial crossover rate\n        self.F_history = []\n        self.CR_history = []\n        self.archive = []\n        self.archive_fitness = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n        \n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n\n            for j in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                u = np.copy(self.population[j])\n                j_rand = np.random.randint(self.dim)\n                for k in range(self.dim):\n                    if np.random.rand() < self.CR or k == j_rand:\n                        u[k] = v[k]\n\n                # Selection\n                f_u = func(u)\n                self.budget -= 1\n                if f_u < self.fitness[j]:\n                    new_population[j] = u\n                    new_fitness[j] = f_u\n\n                    # Add to archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[j])\n                        self.archive_fitness.append(self.fitness[j])\n                    else:\n                        idx_worst = np.argmax(self.archive_fitness)\n                        if self.fitness[j] < self.archive_fitness[idx_worst]:\n                            self.archive[idx_worst] = self.population[j]\n                            self.archive_fitness[idx_worst] = self.fitness[j]\n\n                    self.F_history.append(self.F)\n                    self.CR_history.append(self.CR)\n                else:\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(u)\n                        self.archive_fitness.append(f_u)\n                    else:\n                        idx_worst = np.argmax(self.archive_fitness)\n                        if f_u < self.archive_fitness[idx_worst]:\n                            self.archive[idx_worst] = u\n                            self.archive_fitness[idx_worst] = f_u\n\n\n                if f_u < self.f_opt:\n                    self.f_opt = f_u\n                    self.x_opt = u\n\n            # Elitism: Keep the best individual from the previous generation\n            best_idx = np.argmin(self.fitness)\n            worst_new_idx = np.argmax(new_fitness)\n            if self.fitness[best_idx] < new_fitness[worst_new_idx]:\n                new_population[worst_new_idx] = self.population[best_idx]\n                new_fitness[worst_new_idx] = self.fitness[best_idx]\n            \n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Adaptive F and CR (simplified)\n            if len(self.F_history) > 50:\n                self.F = np.mean(self.F_history[-50:])\n                self.CR = np.mean(self.CR_history[-50:])\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.730 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.24962368246643718, 0.7418875879331899, 0.7756103576180575, 0.9038116640398697, 0.8055510852939611, 0.8507660735610953, 0.7641037189394568, 0.7394786294429977, 0.7974064943919957, 0.7836505698022611, 0.8952839112380847, 0.9981240521751165, 0.32683980082730146, 0.8084332641241891, 0.9372410829112994, 0.8287807115316449, 0.7279353341585142, 0.868244244518726, 0.30235504844546746, 0.5022994260718927]}}
{"id": "cb01d6db-1f5e-46fd-88de-f187ae6ac3fb", "fitness": -Infinity, "name": "SimplifiedCMAES", "description": "A simplified CMA-ES variant with adaptive sigma and a restart mechanism, focusing on computational efficiency by reducing the complexity of covariance matrix adaptation.", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, dsigma=0.2, max_restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = cs\n        self.dsigma = dsigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.count = 0\n        self.restarts = 0\n        self.max_restarts = max_restarts\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.mean = np.random.uniform(lb, ub, size=self.dim)\n        self.sigma = 0.1 * (ub - lb)\n\n        while self.count < self.budget and self.restarts < self.max_restarts:\n            \n            # Sample population\n            z = np.random.normal(size=(self.popsize, self.dim))\n            x = self.mean + self.sigma * z\n            \n            # Clip to bounds\n            x = np.clip(x, lb, ub)\n\n            # Evaluate population\n            f = np.array([func(xi) for xi in x])\n            self.count += self.popsize\n\n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update CMA-ES parameters\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n            \n            # Simplified rank-mu update\n            self.sigma *= np.exp((self.cs/self.dsigma) * (np.linalg.norm(xmean - self.mean)/(self.sigma*self.chiN) - 1))\n            self.mean = xmean\n\n            if self.sigma < 1e-10:\n                self.restarts += 1\n                self.mean = np.random.uniform(lb, ub, size=self.dim)\n                self.sigma = 0.1 * (ub - lb)\n                continue\n\n            if np.any(np.isnan(self.mean)):\n                self.restarts += 1\n                self.mean = np.random.uniform(lb, ub, size=self.dim)\n                self.sigma = 0.1 * (ub - lb)\n                continue\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["1bb22413-71e7-4739-b8a5-7d5029a0f2fa"], "operator": null, "metadata": {}}
{"id": "151143a4-1518-463e-a028-77cf4c891fcb", "fitness": -Infinity, "name": "CMAES", "description": "Improved CMA-ES with rank-one update and handling of singular covariance matrix.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2  # Number of parents/elite members\n        self.c_m = 1  # Step size for the mean\n        self.c_sigma = (self.mu + 2) / (self.dim + self.mu + 5)  # Step size for sigma\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (4 + self.mu / self.dim) / (self.dim + 4 + 2 * self.mu / self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.D = np.ones(self.dim)\n        self.B = np.eye(self.dim)\n        self.m = None\n        self.evals = 0  # Track function evaluations\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.evals = 0\n        while self.evals < self.budget:\n            # Generate population\n            z = np.random.randn(self.dim, self.popsize)\n            x = self.m[:, np.newaxis] + self.sigma0 * (self.B @ (self.D[:, np.newaxis] * z))\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(x[:, i]) for i in range(self.popsize)])\n            self.evals += self.popsize\n            if self.evals > self.budget: # Correct the number of function evaluations and break if needed.\n                f = f[:self.budget - (self.evals - self.popsize)]\n                x = x[:, :self.budget - (self.evals - self.popsize)]\n                self.evals = self.budget\n                \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n\n            # Update optimal values\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.mean(x[:, :self.mu], axis=1)\n            \n            # Update evolution path for covariance matrix\n            zmean = np.mean(z[:, :self.mu], axis=1)\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (self.B @ zmean)\n            \n            # Dampen sigma\n            norm_ps = np.linalg.norm(self.ps) / self.chiN\n            self.sigma0 *= np.exp(self.c_sigma / self.d_sigma * (norm_ps - 1))\n\n            # Update evolution path for mean\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma0\n\n            # Update covariance matrix\n            self.C = (1 - self.c_c) * self.C + self.c_c * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :])\n            \n            try: \n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(np.abs(self.D))\n            except np.linalg.LinAlgError:\n                # If the covariance matrix is close to singular, add a small value to the diagonal\n                self.C += 1e-8 * np.eye(self.dim)\n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(np.abs(self.D))\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["676348f9-5d01-43f8-9656-ad795c8920d9"], "operator": null, "metadata": {}}
{"id": "9f18c02d-e4c4-44b9-a025-c30f933a8006", "fitness": 0.0, "name": "NovelAlgorithm", "description": "Enhanced population-based algorithm with adaptive learning rates, velocity clamping, and dynamic repulsion strength for improved exploration and exploitation.", "code": "import numpy as np\n\nclass NovelAlgorithm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr_mean=0.1, lr_individual=0.1, repulsion_strength=0.01, velocity_clamp=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr_mean = lr_mean\n        self.lr_individual = lr_individual\n        self.repulsion_strength = repulsion_strength\n        self.velocity_clamp = velocity_clamp\n        self.archive = [] # Add archive for storing good solutions\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # reduce budget\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        velocities = np.zeros_like(population) # Initialize velocities\n\n        while self.budget > 0:\n            # Calculate the mean of the population\n            mean = np.mean(population, axis=0)\n\n            # Adaptive learning rates based on success\n            if len(self.archive) > 0:\n                archive_fitness = np.array([func(x) for x in self.archive])\n                best_archive_fitness = np.min(archive_fitness)\n\n                if best_archive_fitness < self.f_opt:\n                    self.lr_mean *= 1.1  # Increase learning rate if archive has better solutions\n                    self.lr_individual *= 1.1\n                else:\n                    self.lr_mean *= 0.95  # Decrease learning rate if archive is not helpful\n                    self.lr_individual *= 0.95\n            \n            self.lr_mean = np.clip(self.lr_mean, 0.01, 0.3)\n            self.lr_individual = np.clip(self.lr_individual, 0.01, 0.3)\n            \n\n            # Update population based on the mean and individual learning\n            for i in range(self.pop_size):\n                # Individual learning: move towards a random other individual\n                random_index = np.random.randint(self.pop_size)\n                individual_learning_direction = population[random_index] - population[i]\n                \n                # Move towards the mean\n                mean_direction = mean - population[i]\n\n                # Repulsion from the best solution (diversity mechanism)\n                repulsion_direction = population[i] - self.x_opt\n\n                # Adaptive repulsion strength\n                repulsion_strength = self.repulsion_strength * np.exp(-i / self.pop_size) # Individuals closer to the start repel more\n                \n                # Normalize the repulsion direction, handle the edge case where population[i] is identical to self.x_opt\n                norm = np.linalg.norm(repulsion_direction)\n                if norm > 0:\n                    repulsion_direction = repulsion_direction / norm\n                \n                # Update the individual with a combination of mean, individual learning and repulsion\n                new_velocity = (self.lr_mean * mean_direction + self.lr_individual * individual_learning_direction + repulsion_strength * repulsion_direction)\n                \n                # Velocity clamping\n                new_velocity = np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n\n                velocities[i] = new_velocity\n                new_position = population[i] + velocities[i]\n                \n                # Clip to bounds\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                new_fitness = func(new_position)\n                self.budget -= 1 # reduce budget\n\n                # Update if the new position is better\n                if new_fitness < fitness[i]:\n                    # Add old position to archive\n                    self.archive.append(population[i].copy()) #add copy to avoid modification\n                    population[i] = new_position\n                    fitness[i] = new_fitness\n\n                    # Update global best\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm NovelAlgorithm scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["194f008f-847c-4e1e-b3bc-c6ef7b8b1b63"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "56baf5a2-81d7-45b6-ad7b-ba870e6de885", "fitness": -Infinity, "name": "AdaptiveMirroredCMAES", "description": "An adaptive CMA-ES that adjusts the population size and learning rates based on the function evaluation results, using a mirrored sampling strategy for exploration.", "code": "import numpy as np\n\nclass AdaptiveMirroredCMAES:\n    def __init__(self, budget=10000, dim=10, sigma0=0.5, popsize_multiplier=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize_multiplier = popsize_multiplier\n        self.popsize = int(4 + np.floor(3 * np.log(self.dim)) * self.popsize_multiplier)\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.D = np.ones(self.dim)\n        self.B = np.eye(self.dim)\n        self.m = None\n\n        self.success_rate = 0.5  # Adaptive success rate\n        self.learning_rate_success = 1.1\n        self.learning_rate_failure = 0.9\n        self.mirrored_sampling = True\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        evals = 0\n        \n        while evals < self.budget:\n            z = np.random.randn(self.dim, self.popsize // 2)  # Generate half the population\n            if self.mirrored_sampling:\n                z = np.concatenate([z, -z], axis=1) # Mirror sampling for exploration\n            else:\n                 z_new = np.random.randn(self.dim, self.popsize - z.shape[1])\n                 z = np.concatenate([z, z_new], axis=1)\n\n\n            x = self.m[:, np.newaxis] + self.sigma0 * (self.B @ (self.D[:, np.newaxis] * z))\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(x[:, i]) for i in range(self.popsize)])\n            evals += self.popsize\n\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n\n            m_old = self.m.copy()\n            self.m = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n            \n\n            zmean = np.sum(z[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (self.B @ zmean)\n            norm_ps = np.linalg.norm(self.ps) / self.chiN\n\n            success = norm_ps < (1.4 + 2/(self.dim + 1)) \n            self.success_rate = 0.25 * success + 0.75 * self.success_rate #smoothed\n\n            if self.success_rate > 0.9:\n                self.sigma0 *= self.learning_rate_success\n            elif self.success_rate < 0.2:\n                self.sigma0 *= self.learning_rate_failure\n\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (self.m - m_old) / self.sigma0\n\n            delta = (x[:, :self.mu] - m_old[:, np.newaxis]) / self.sigma0\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :])\n            for i in range(self.mu):\n                self.C += self.c_mu * self.weights[i] * (delta[:, i:i+1] @ delta[:, i:i+1].T)\n            \n            try:\n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(np.abs(self.D))\n            except np.linalg.LinAlgError:\n                self.C += 1e-8 * np.eye(self.dim)\n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(np.abs(self.D))\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["676348f9-5d01-43f8-9656-ad795c8920d9"], "operator": null, "metadata": {}}
{"id": "aba8e6a0-5c9e-4ebc-a567-28a34cda7c35", "fitness": -Infinity, "name": "CMAES", "description": "CMA-ES with restarts, active population size adaptation, and improved handling of singular covariance matrices using eigenvalue clipping.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, dsigma=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = cs\n        self.dsigma = dsigma\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.count = 0\n        self.restarts = 0\n        self.max_restarts = 10\n        self.min_sigma = 1e-12  # Minimum allowed sigma\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.sigma = 0.1 * (func.bounds.ub - func.bounds.lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n        self.invC = np.eye(self.dim)\n\n        while self.count < self.budget and self.restarts < self.max_restarts:\n            \n            # Sample population\n            z = np.random.normal(size=(self.popsize, self.dim))\n            x = self.mean + self.sigma * (self.B @ (self.D * z.T)).T\n            \n            # Clip to bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            f = np.array([func(xi) for xi in x.T]).reshape(-1) # fix for the error\n            self.count += self.popsize\n\n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n\n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n\n            # Update CMA-ES parameters\n            xmean = np.sum(self.weights * x[:, :self.mu], axis=1)\n            zmean = np.sum(self.weights * z[idx[:self.mu]], axis=0)\n            \n            self.ps = (1 - self.cs) * self.ps + (self.cs * (2 - self.cs) * self.mueff)**0.5 * self.invC @ (xmean - self.mean) / self.sigma\n            hsig = (np.sum(self.ps**2) / (1 - (1 - self.cs)**(2*self.count/self.popsize))/self.dim) < 2 + 4/(self.dim+1)\n            self.pc = (1 - self.cc) * self.pc + hsig * (self.cc * (2 - self.cc) * self.mueff)**0.5 * (xmean - self.mean) / self.sigma\n            \n            diff = x[:, :self.mu] - self.mean[:, None]\n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (self.pc[:, None] @ self.pc[None, :]) + \\\n                       self.cmu * (diff @ np.diag(self.weights) @ diff.T) / self.sigma**2\n            \n            self.sigma *= np.exp((self.cs/self.dsigma) * (np.linalg.norm(self.ps)/self.chiN - 1))\n            self.sigma = max(self.sigma, self.min_sigma) # prevent sigma from becoming too small\n            self.mean = xmean\n\n            try:\n                self.C = np.triu(self.C) + np.triu(self.C, 1).T\n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(np.maximum(self.D, 1e-8))  # Clip eigenvalues to avoid singularity\n                self.invC = self.B @ np.diag(self.D**-1) @ self.B.T\n            except np.linalg.LinAlgError:\n                self.restarts += 1\n                self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.sigma = 0.1 * (func.bounds.ub - func.bounds.lb)\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.B = np.eye(self.dim)\n                self.D = np.ones(self.dim)\n                self.invC = np.eye(self.dim)\n                continue\n\n            # Adjust population size\n            if self.count > self.budget / 2 and self.popsize > 6:\n                self.popsize -= 2\n                self.mu = self.popsize // 2\n                self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n                self.weights /= np.sum(self.weights)\n                self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n                self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n                self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n                self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff))\n\n            if np.any(self.D < 1e-10):\n                 self.restarts += 1\n                 self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                 self.sigma = 0.1 * (func.bounds.ub - func.bounds.lb)\n                 self.C = np.eye(self.dim)\n                 self.pc = np.zeros(self.dim)\n                 self.ps = np.zeros(self.dim)\n                 self.B = np.eye(self.dim)\n                 self.D = np.ones(self.dim)\n                 self.invC = np.eye(self.dim)\n                 continue\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,) (2,6) .", "error": "", "parent_ids": ["1bb22413-71e7-4739-b8a5-7d5029a0f2fa"], "operator": null, "metadata": {}}
{"id": "3a7e1564-db2c-4e32-895f-8a1008a9cd46", "fitness": -Infinity, "name": "AdaptiveCMAES", "description": "An adaptive CMA-ES variant that adjusts population size and covariance matrix adaptation based on stagnation detection using consecutive similar best function values.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, dsigma=0.2, stagnation_threshold=10):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = cs\n        self.dsigma = dsigma\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.count = 0\n        self.restarts = 0\n        self.max_restarts = 10\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.previous_best_f = np.Inf\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.sigma = 0.1 * (func.bounds.ub - func.bounds.lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n        self.invC = np.eye(self.dim)\n\n        while self.count < self.budget and self.restarts < self.max_restarts:\n            \n            # Sample population\n            z = np.random.normal(size=(self.popsize, self.dim))\n            x = self.mean + self.sigma * (self.B @ (self.D * z.T)).T\n            \n            # Clip to bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            f = np.array([func(xi) for xi in x])\n            self.count += self.popsize\n\n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                if abs(self.f_opt - self.previous_best_f) < 1e-9:\n                    self.stagnation_counter += 1\n                else:\n                    self.stagnation_counter = 0\n                self.previous_best_f = self.f_opt\n            else:\n                self.stagnation_counter +=1\n\n            # Update CMA-ES parameters\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n            zmean = np.sum(self.weights[:, None] * z[idx[:self.mu]], axis=0)\n            \n            self.ps = (1 - self.cs) * self.ps + (self.cs * (2 - self.cs) * self.mueff)**0.5 * self.invC @ (xmean - self.mean) / self.sigma\n            hsig = (np.sum(self.ps**2) / (1 - (1 - self.cs)**(2*self.count/self.popsize))/self.dim) < 2 + 4/(self.dim+1)\n            self.pc = (1 - self.cc) * self.pc + hsig * (self.cc * (2 - self.cc) * self.mueff)**0.5 * (xmean - self.mean) / self.sigma\n            \n            y = (x[:self.mu] - self.mean) / self.sigma\n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (self.pc[:, None] @ self.pc[None, :]) + \\\n                       self.cmu * np.sum(self.weights[:, None, None] * y[:, :, None] * y[:, None, :], axis=0)\n            \n            self.sigma *= np.exp((self.cs/self.dsigma) * (np.linalg.norm(self.ps)/self.chiN - 1))\n            self.mean = xmean\n\n            try:\n                self.C = np.triu(self.C) + np.triu(self.C, 1).T\n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(self.D)\n                self.invC = self.B @ np.diag(self.D**-1) @ self.B.T\n            except np.linalg.LinAlgError:\n                self.restarts += 1\n                self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.sigma = 0.1 * (func.bounds.ub - func.bounds.lb)\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.B = np.eye(self.dim)\n                self.D = np.ones(self.dim)\n                self.invC = np.eye(self.dim)\n                self.stagnation_counter = 0\n                self.previous_best_f = np.Inf\n                continue\n\n            # Adjust population size based on stagnation\n            if self.stagnation_counter > self.stagnation_threshold:\n                if self.popsize > 6:\n                    self.popsize -= 2\n                    self.mu = self.popsize // 2\n                    self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n                    self.weights /= np.sum(self.weights)\n                    self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n                    self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n                    self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n                    self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff))\n                else:\n                    self.restarts += 1\n                    self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    self.sigma = 0.1 * (func.bounds.ub - func.bounds.lb)\n                    self.C = np.eye(self.dim)\n                    self.pc = np.zeros(self.dim)\n                    self.ps = np.zeros(self.dim)\n                    self.B = np.eye(self.dim)\n                    self.D = np.ones(self.dim)\n                    self.invC = np.eye(self.dim)\n                    self.stagnation_counter = 0\n                    self.previous_best_f = np.Inf\n                    \n            if np.any(self.D < 1e-10):\n                 self.restarts += 1\n                 self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                 self.sigma = 0.1 * (func.bounds.ub - func.bounds.lb)\n                 self.C = np.eye(self.dim)\n                 self.pc = np.zeros(self.dim)\n                 self.ps = np.zeros(self.dim)\n                 self.B = np.eye(self.dim)\n                 self.D = np.ones(self.dim)\n                 self.invC = np.eye(self.dim)\n                 self.stagnation_counter = 0\n                 self.previous_best_f = np.Inf\n                 continue\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,) (2,6) .", "error": "", "parent_ids": ["1bb22413-71e7-4739-b8a5-7d5029a0f2fa"], "operator": null, "metadata": {}}
{"id": "766128fb-ddb5-43a5-a8a6-9f5c7f9dd9b8", "fitness": 0.4690358648363789, "name": "SelfAdaptiveDE", "description": "A differential evolution strategy with a self-adaptive population size and a modified mutation strategy incorporating information from the best solution found so far.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = 10\n        self.max_pop_size = 100\n        self.F = 0.5\n        self.CR = 0.7\n        self.success_F = []\n        self.success_CR = []\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.adaptation_rate = 0.1\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.best_solution = self.population[np.argmin(self.fitness)]\n        self.best_fitness = np.min(self.fitness)\n\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n\n            for j in range(self.pop_size):\n                # Mutation with best solution guidance\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n\n                # Modified mutation: incorporating best solution\n                v = self.population[j] + self.F * (self.best_solution - self.population[j]) + self.F * (x1 - x2)\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.copy(self.population[j])\n                j_rand = np.random.randint(self.dim)\n                for k in range(self.dim):\n                    if np.random.rand() < self.CR or k == j_rand:\n                        u[k] = v[k]\n\n                # Selection\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[j]:\n                    new_population[j] = u\n                    new_fitness[j] = f_u\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n\n                    if f_u < self.best_fitness:\n                        self.best_fitness = f_u\n                        self.best_solution = u\n\n                if f_u < self.f_opt:\n                    self.f_opt = f_u\n                    self.x_opt = u\n            \n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Self-adaptive population size\n            if generation % 10 == 0:\n                if len(self.success_F) > 0:\n                    mean_success = np.mean(self.fitness)\n                    mean_population = np.mean(self.fitness)\n                    if mean_success < mean_population:\n                         self.pop_size = int(min(self.pop_size * (1 + self.adaptation_rate), self.max_pop_size))\n                    else:\n                         self.pop_size = int(max(self.pop_size * (1 - self.adaptation_rate), self.min_pop_size))\n                    self.success_F = []\n                    self.success_CR = []\n\n\n            # Adaptation of F and CR (using success history)\n            if len(self.success_F) > 0:\n                self.F = np.mean(self.success_F) if len(self.success_F) > 0 else 0.5\n                self.CR = np.mean(self.success_CR) if len(self.success_CR) > 0 else 0.7\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm SelfAdaptiveDE scored 0.469 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["645dbd1c-3ad0-4d6c-9e2b-127301825437"], "operator": null, "metadata": {"aucs": [0.24314227408244615, 0.7914071890959103, 0.841593996167159, 0]}}
{"id": "20528bce-25d4-465d-96a2-9b668abe7467", "fitness": 0.19570921525884405, "name": "NovelAlgorithm", "description": "Population-based algorithm with a central moving mean, stochastic individual learning, and a diversity mechanism using a repulsive force, enhanced with adaptive learning rate decay and adaptive repulsion strength.", "code": "import numpy as np\n\nclass NovelAlgorithm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1, repulsion_strength=0.01, lr_decay=0.99, repulsion_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.repulsion_strength = repulsion_strength\n        self.lr_decay = lr_decay\n        self.repulsion_decay = repulsion_decay\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # reduce budget\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Calculate the mean of the population\n            mean = np.mean(population, axis=0)\n\n            # Update population based on the mean and individual learning\n            for i in range(self.pop_size):\n                # Individual learning: move towards a random other individual\n                random_index = np.random.randint(self.pop_size)\n                individual_learning_direction = population[random_index] - population[i]\n                \n                # Move towards the mean\n                mean_direction = mean - population[i]\n\n                # Repulsion from the best solution (diversity mechanism)\n                repulsion_direction = population[i] - self.x_opt\n                \n                # Normalize the repulsion direction, handle the edge case where population[i] is identical to self.x_opt\n                norm = np.linalg.norm(repulsion_direction)\n                if norm > 0:\n                    repulsion_direction = repulsion_direction / norm\n                \n                # Update the individual with a combination of mean, individual learning and repulsion\n                new_position = population[i] + self.lr * mean_direction + self.lr * individual_learning_direction + self.repulsion_strength * repulsion_direction\n                \n                # Clip to bounds\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                new_fitness = func(new_position)\n                self.budget -= 1 # reduce budget\n\n                # Update if the new position is better\n                if new_fitness < fitness[i]:\n                    population[i] = new_position\n                    fitness[i] = new_fitness\n\n                    # Update global best\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n            \n            # Decay learning rate and repulsion strength\n            self.lr *= self.lr_decay\n            self.repulsion_strength *= self.repulsion_decay\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm NovelAlgorithm scored 0.196 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["194f008f-847c-4e1e-b3bc-c6ef7b8b1b63"], "operator": null, "metadata": {"aucs": [0.08968823750531918, 0.18237994182498873, 0.2642790331935524, 0.15417964508817072, 0.14948530797205584, 0.19575462144007716, 0.22601407769190796, 0.16830172266349674, 0.18776724056189686, 0.16422734280744722, 0.16331905532124635, 0.20788091403626863, 0.23981854719292583, 0.19252100594750632, 0.13536478826841636, 0.24294828945253355, 0.19149989831832104, 0.16365917579797784, 0.15467301401477507, 0.44042244607799685]}}
{"id": "6b14a2e3-776d-46b0-a357-96e4a3f960ac", "fitness": 0.18779604571009184, "name": "NovelAlgorithm", "description": "Population-based algorithm with central moving mean, stochastic individual learning, a diversity mechanism using repulsive force, and adaptive learning rate for exploration/exploitation balance.", "code": "import numpy as np\n\nclass NovelAlgorithm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr_initial=0.1, repulsion_strength=0.01, lr_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr_initial = lr_initial\n        self.lr = lr_initial\n        self.repulsion_strength = repulsion_strength\n        self.lr_decay = lr_decay # Decay rate for learning rate\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # reduce budget\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Calculate the mean of the population\n            mean = np.mean(population, axis=0)\n\n            # Update population based on the mean and individual learning\n            for i in range(self.pop_size):\n                # Individual learning: move towards a random other individual\n                random_index = np.random.randint(self.pop_size)\n                individual_learning_direction = population[random_index] - population[i]\n                \n                # Move towards the mean\n                mean_direction = mean - population[i]\n\n                # Repulsion from the best solution (diversity mechanism)\n                repulsion_direction = population[i] - self.x_opt\n                \n                # Normalize the repulsion direction, handle the edge case where population[i] is identical to self.x_opt\n                norm = np.linalg.norm(repulsion_direction)\n                if norm > 0:\n                    repulsion_direction = repulsion_direction / norm\n                \n                # Update the individual with a combination of mean, individual learning and repulsion\n                new_position = population[i] + self.lr * mean_direction + self.lr * individual_learning_direction + self.repulsion_strength * repulsion_direction\n                \n                # Clip to bounds\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                new_fitness = func(new_position)\n                self.budget -= 1 # reduce budget\n\n                # Update if the new position is better\n                if new_fitness < fitness[i]:\n                    population[i] = new_position\n                    fitness[i] = new_fitness\n\n                    # Update global best\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n            \n            # Decay the learning rate\n            self.lr *= self.lr_decay\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm NovelAlgorithm scored 0.188 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["194f008f-847c-4e1e-b3bc-c6ef7b8b1b63"], "operator": null, "metadata": {"aucs": [0.10129420789699195, 0.16659901235127839, 0.2771640320892894, 0.13437289987722323, 0.1280633577739394, 0.1923773970181879, 0.20691452813380407, 0.16313253788488147, 0.16218672746687768, 0.15065497267344508, 0.157364295295221, 0.19474297800075324, 0.24823084738681922, 0.1571317484881436, 0.1405886674028548, 0.25526239756129887, 0.19372014989625697, 0.1838817201628552, 0.1576195736912781, 0.38461886315043725]}}
{"id": "760e4eef-70b3-4b83-9d1b-a03ec787d07a", "fitness": 0.6852175596652014, "name": "HybridDE", "description": "A population-based algorithm that combines differential evolution with a local search strategy based on Gaussian perturbations around the best solution found so far.", "code": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, local_search_prob=0.1, local_search_sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution scaling factor\n        self.Cr = Cr  # Crossover rate\n        self.local_search_prob = local_search_prob\n        self.local_search_sigma = local_search_sigma  # Std dev for Gaussian perturbation\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search around best\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.x_opt + self.local_search_sigma * np.random.normal(0, 1, self.dim)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm HybridDE scored 0.685 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["194f008f-847c-4e1e-b3bc-c6ef7b8b1b63"], "operator": null, "metadata": {"aucs": [0.31933017966609534, 0.23785930982028936, 0.6390021723834336, 0.9655724596210538, 0.9126904798841883, 0.9119177301202446, 0.869997123134702, 0.872194393684987, 0.7914810281501554, 0.20568820604425841, 0.844164009920978, 0.9955147746539921, 0.2838203216485311, 0.8020064301364966, 0.9308115502391374, 0.9315488979663574, 0.5746329477706613, 0.9193571028098897, 0.18654853404981198, 0.5102135415987638]}}
{"id": "17bc7377-8fa2-4b57-b13c-6ece25a77242", "fitness": 0.0, "name": "EnhancedAlgorithm", "description": "An enhanced population-based algorithm with velocity-based movement, adaptive learning rates, and a local search component around the best solution.", "code": "import numpy as np\n\nclass EnhancedAlgorithm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr_mean=0.1, lr_individual=0.05, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr_mean = lr_mean\n        self.lr_individual = lr_individual\n        self.local_search_radius = local_search_radius\n        self.velocities = None  # Initialize velocities\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # reduce budget\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        # Initialize velocities\n        self.velocities = np.zeros_like(population)\n\n        while self.budget > 0:\n            # Calculate the mean of the population\n            mean = np.mean(population, axis=0)\n\n            # Update population based on the mean and individual learning\n            for i in range(self.pop_size):\n                # Individual learning: move towards a random other individual\n                random_index = np.random.randint(self.pop_size)\n                individual_learning_direction = population[random_index] - population[i]\n\n                # Move towards the mean\n                mean_direction = mean - population[i]\n\n                # Update velocity\n                self.velocities[i] = 0.5 * self.velocities[i] + self.lr_mean * mean_direction + self.lr_individual * individual_learning_direction\n\n                # Update the individual with velocity\n                new_position = population[i] + self.velocities[i]\n\n                # Clip to bounds\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Local search around the best solution\n                if np.random.rand() < 0.1:  # Probability of local search\n                    local_point = self.x_opt + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                    local_point = np.clip(local_point, func.bounds.lb, func.bounds.ub)\n                    local_fitness = func(local_point)\n                    self.budget -= 1\n\n                    if local_fitness < self.f_opt:\n                        self.f_opt = local_fitness\n                        self.x_opt = local_point\n                \n                # Evaluate the new position\n                new_fitness = func(new_position)\n                self.budget -= 1 # reduce budget\n\n                # Update if the new position is better\n                if new_fitness < fitness[i]:\n                    population[i] = new_position\n                    fitness[i] = new_fitness\n                    self.velocities[i] = np.zeros_like(self.velocities[i]) # Reset velocity after improvement\n\n                    # Update global best\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n\n            # Adaptive learning rate adjustment\n            if np.random.rand() < 0.05:  # Adjust learning rates occasionally\n                self.lr_mean = np.random.uniform(0.01, 0.2)\n                self.lr_individual = np.random.uniform(0.005, 0.1)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedAlgorithm scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["194f008f-847c-4e1e-b3bc-c6ef7b8b1b63"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "89df6992-bdaa-48ec-8ca8-d5f709ba2b88", "fitness": 0.449570864442941, "name": "AdaptiveVarianceScaling", "description": "An Adaptive Variance Scaling (AVS) algorithm that dynamically adjusts the variance of the search distribution based on the success rate of finding better solutions.", "code": "import numpy as np\n\nclass AdaptiveVarianceScaling:\n    def __init__(self, budget=10000, dim=10, initial_variance=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.variance = initial_variance\n        self.success_rate = 0.0\n        self.success_history = []\n        self.learning_rate = 0.1 \n        self.x_best = None\n        self.f_best = np.inf\n\n    def __call__(self, func):\n        evals = 0\n        while evals < self.budget:\n            # Generate a new candidate solution\n            if self.x_best is None:\n                x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            else:\n                x = self.x_best + np.random.normal(0, np.sqrt(self.variance), size=self.dim)\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            f = func(x)\n            evals += 1\n\n            # Check for improvement\n            if f < self.f_best:\n                self.f_best = f\n                self.x_best = x\n                self.success_history.append(1)\n            else:\n                self.success_history.append(0)\n\n            # Update success rate\n            if len(self.success_history) > 100:\n                self.success_history = self.success_history[-100:]\n            self.success_rate = np.mean(self.success_history)\n\n            # Adjust variance\n            if self.success_rate > 0.2:\n                self.variance *= (1 + self.learning_rate)\n            else:\n                self.variance *= (1 - self.learning_rate)\n            self.variance = max(self.variance, 1e-6) # Ensure variance is not too small\n\n        return self.f_best, self.x_best", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveVarianceScaling scored 0.450 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["676348f9-5d01-43f8-9656-ad795c8920d9"], "operator": null, "metadata": {"aucs": [0.0829253642095813, 0.17180855465006917, 0.33273332501784736, 0.9707751931299328, 0.3526034259731221, 0.7918160956924782, 0.28236162578625723, 0.24873152945630572, 0.390628680361768, 0.1404173503749453, 0.985396021445303, 0.9998364654551934, 0.22028135985243824, 0.21034353315787535, 0.9091056295013549, 0.29928211697363694, 0.34569817492983357, 0.934480919456615, 0.17271829706239683, 0.14947362637186512]}}
{"id": "620c4362-b92f-4462-8214-b377f8d9fb0e", "fitness": -Infinity, "name": "AdaptiveHybridDE", "description": "Hybrid DE with adaptive parameters, including population size and local search probability, based on performance feedback.", "code": "import numpy as np\n\nclass AdaptiveHybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=20, F_init=0.5, Cr_init=0.9, local_search_prob_init=0.1, local_search_sigma=0.1, pop_size_adapt=True, ls_prob_adapt=True):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.pop_size_init = pop_size_init\n        self.F = F_init  # Differential evolution scaling factor\n        self.Cr = Cr_init  # Crossover rate\n        self.local_search_prob = local_search_prob_init\n        self.local_search_prob_init = local_search_prob_init\n        self.local_search_sigma = local_search_sigma  # Std dev for Gaussian perturbation\n        self.pop_size_adapt = pop_size_adapt\n        self.ls_prob_adapt = ls_prob_adapt\n        self.success_memory = []\n        self.success_memory_size = 10\n\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        generation = 0\n\n        while self.budget > 0:\n            generation += 1\n            \n            if self.pop_size_adapt:\n                # Adjust population size based on recent success\n                success_rate = np.mean(self.success_memory) if self.success_memory else 0.5\n                self.pop_size = int(np.clip(self.pop_size_init * (1 + 2 * (success_rate - 0.5)), 5, 100))  # Adjust pop size\n            \n            \n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search around best\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.x_opt + self.local_search_sigma * np.random.normal(0, 1, self.dim)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                \n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    success = True\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    success = False\n\n                #Adapt local search probability\n                if self.ls_prob_adapt:\n                    if success:\n                        self.local_search_prob = min(1.0, self.local_search_prob * 1.1)\n                    else:\n                        self.local_search_prob = max(0.01, self.local_search_prob * 0.9)\n                \n                self.success_memory.append(int(success))\n                if len(self.success_memory) > self.success_memory_size:\n                    self.success_memory.pop(0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: index 20 is out of bounds for axis 0 with size 20.", "error": "", "parent_ids": ["760e4eef-70b3-4b83-9d1b-a03ec787d07a"], "operator": null, "metadata": {}}
{"id": "4df93da5-878e-4982-bfbf-64b64bca286f", "fitness": 0.0, "name": "NovelAlgorithm", "description": "Combines a central moving mean with stochastic individual learning, repulsive force for diversity, adaptive learning rate and repulsion strength, enhanced with orthogonal learning for improved exploration.", "code": "import numpy as np\n\nclass NovelAlgorithm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1, repulsion_strength=0.01, lr_decay=0.99, repulsion_decay=0.99, orthogonal_learning_rate = 0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.repulsion_strength = repulsion_strength\n        self.lr_decay = lr_decay\n        self.repulsion_decay = repulsion_decay\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # reduce budget\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Calculate the mean of the population\n            mean = np.mean(population, axis=0)\n\n            # Update population based on the mean and individual learning\n            for i in range(self.pop_size):\n                # Individual learning: move towards a random other individual\n                random_index = np.random.randint(self.pop_size)\n                individual_learning_direction = population[random_index] - population[i]\n                \n                # Move towards the mean\n                mean_direction = mean - population[i]\n\n                # Repulsion from the best solution (diversity mechanism)\n                repulsion_direction = population[i] - self.x_opt\n                \n                # Normalize the repulsion direction, handle the edge case where population[i] is identical to self.x_opt\n                norm = np.linalg.norm(repulsion_direction)\n                if norm > 0:\n                    repulsion_direction = repulsion_direction / norm\n                \n                # Update the individual with a combination of mean, individual learning and repulsion\n                new_position = population[i] + self.lr * mean_direction + self.lr * individual_learning_direction + self.repulsion_strength * repulsion_direction\n                \n                # Orthogonal Learning: Create an orthogonal direction\n                orthogonal_direction = np.random.normal(0, 1, self.dim)\n                orthogonal_direction -= np.dot(orthogonal_direction, new_position) / np.dot(new_position, new_position) * new_position if np.linalg.norm(new_position) > 0 else 0\n                orthogonal_direction /= np.linalg.norm(orthogonal_direction) if np.linalg.norm(orthogonal_direction) > 0 else 1  # Normalize\n\n                # Create a new position using orthogonal learning\n                orthogonal_new_position = new_position + self.orthogonal_learning_rate * orthogonal_direction\n                orthogonal_new_position = np.clip(orthogonal_new_position, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate the new positions\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.budget -= 1  # reduce budget\n                \n                orthogonal_new_fitness = func(orthogonal_new_position)\n                self.budget -= 1 # Reduce budget\n\n                # Update if the new position is better\n                if new_fitness < fitness[i] and orthogonal_new_fitness >= new_fitness:\n                    population[i] = new_position\n                    fitness[i] = new_fitness\n\n                    # Update global best\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n                elif orthogonal_new_fitness < fitness[i] and orthogonal_new_fitness < new_fitness:\n                    population[i] = orthogonal_new_position\n                    fitness[i] = orthogonal_new_fitness\n\n                    # Update global best\n                    if orthogonal_new_fitness < self.f_opt:\n                        self.f_opt = orthogonal_new_fitness\n                        self.x_opt = orthogonal_new_position\n\n            # Decay learning rate and repulsion strength\n            self.lr *= self.lr_decay\n            self.repulsion_strength *= self.repulsion_decay\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm NovelAlgorithm scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["20528bce-25d4-465d-96a2-9b668abe7467"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "ba9aabdc-9749-4c37-af92-8e5ac6317a55", "fitness": -Infinity, "name": "CovarianceMatrixAdaptationEvolutionStrategy", "description": "An algorithm that combines a population-based approach with covariance matrix adaptation and restarts based on stagnation detection to balance exploration and exploitation.", "code": "import numpy as np\n\nclass CovarianceMatrixAdaptationEvolutionStrategy:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_sigma=0.1, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = initial_sigma\n        self.mean = None\n        self.C = np.eye(dim)  # Covariance matrix\n        self.pc = np.zeros(dim) # Evolution path for C\n        self.ps = np.zeros(dim) # Evolution path for sigma\n        self.chiN = dim**0.5 * (1 - (1/(4*dim)) + 1/(21*dim**2))\n        self.c_sigma = (self.pop_size + 2) / (dim + 5)\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.c_sigma * (2 - self.c_sigma)) * (self.pop_size - 1)) - 1) / self.chiN\n        self.c_c = 4 / (dim + 4)\n        self.c_1 = 4 / ((dim + 1.4)**2 + 2*dim)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size)) / ((dim + 2)**2 + 2*self.pop_size/5))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.f_best = np.inf\n        self.x_best = None\n        self.evals = 0\n        self.stagnation_counter = 0\n        self.stagnation_threshold = stagnation_threshold\n        self.last_f_best = np.inf\n\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n        while self.evals < self.budget:\n            # Generate population\n            z = np.random.normal(0, 1, size=(self.dim, self.pop_size))\n            x = self.mean[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            f = np.array([func(xi) for xi in x.T])\n            self.evals += self.pop_size\n\n            # Sort population\n            idx = np.argsort(f)\n            f = f[idx]\n            x = x[:, idx]\n\n            # Update best solution\n            if f[0] < self.f_best:\n                self.f_best = f[0]\n                self.x_best = x[:, 0]\n                self.stagnation_counter = 0 # Reset stagnation counter when finding a better solution\n            else:\n                self.stagnation_counter += self.pop_size # Increase stagnation counter if no better solution is found\n\n            # CMA-ES update\n            y = x[:, :self.mu] - self.mean[:, np.newaxis]\n            z = np.linalg.solve(np.linalg.cholesky(self.C), y)\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * np.dot(z, self.weights)\n            \n            if np.linalg.norm(self.ps) / np.sqrt(1-(1-self.c_sigma)**(2*self.evals/self.pop_size))/self.chiN < 1.4 + 2/(self.dim+1):\n                self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * np.dot(y, self.weights)\n                self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (np.outer(self.pc, self.pc) + (1-self.c_1)/np.linalg.norm(self.ps)**2 * self.c_1 * self.C) + self.c_mu * np.dot(y, np.dot(np.diag(self.weights), y.T))\n            else:\n                self.ps = (1 - self.c_sigma) * self.ps\n                self.pc = (1 - self.c_c) * self.pc\n                self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (np.outer(self.pc, self.pc) + (1-self.c_1)/np.linalg.norm(self.ps)**2 * self.c_1 * self.C) + self.c_mu * np.dot(y, np.dot(np.diag(self.weights), y.T))\n            \n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.mean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n            \n            # Ensure C is positive definite\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            #Restart if stagnation is detected\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.sigma = 0.1  # Reset sigma\n                self.C = np.eye(self.dim)  # Reset covariance matrix\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.stagnation_counter = 0 # Reset counter\n                \n\n        return self.f_best, self.x_best", "configspace": "", "generation": 2, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["89df6992-bdaa-48ec-8ca8-d5f709ba2b88"], "operator": null, "metadata": {}}
{"id": "ce74fa3a-9645-4954-a971-b9423aeb1e72", "fitness": 0.0738993719541825, "name": "SelfAdaptiveDE", "description": "A differential evolution strategy with self-adaptive parameters, population size adjustment based on fitness improvement and orthogonal learning to refine promising solutions.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = 10\n        self.max_pop_size = 100\n        self.F = 0.5\n        self.CR = 0.7\n        self.success_F = []\n        self.success_CR = []\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.adaptation_rate = 0.1\n        self.orthogonal_learning_rate = 0.05  # Probability of orthogonal learning\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.best_solution = self.population[np.argmin(self.fitness)]\n        self.best_fitness = np.min(self.fitness)\n\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n\n            for j in range(self.pop_size):\n                # Mutation with best solution guidance\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n\n                # Modified mutation: incorporating best solution\n                v = self.population[j] + self.F * (self.best_solution - self.population[j]) + self.F * (x1 - x2)\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.copy(self.population[j])\n                j_rand = np.random.randint(self.dim)\n                for k in range(self.dim):\n                    if np.random.rand() < self.CR or k == j_rand:\n                        u[k] = v[k]\n\n                # Selection\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[j]:\n                    new_population[j] = u\n                    new_fitness[j] = f_u\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n\n                    if f_u < self.best_fitness:\n                        self.best_fitness = f_u\n                        self.best_solution = u\n\n                if f_u < self.f_opt:\n                    self.f_opt = f_u\n                    self.x_opt = u\n                    \n                # Orthogonal Learning\n                if np.random.rand() < self.orthogonal_learning_rate:\n                    # Select dimensions to learn from (e.g., 3 dimensions)\n                    num_dims_to_learn = min(3, self.dim) #Learn at most 3 dimensions\n                    dims_to_learn = np.random.choice(self.dim, num_dims_to_learn, replace=False)\n                    \n                    # Create an orthogonal array (example using L9, assuming levels are -1, 0, 1)\n                    # We will use the best solution and the current solution as levels.\n                    levels = np.array([self.population[j][dims_to_learn], self.best_solution[dims_to_learn]])\n                    \n                    # Generate a random orthogonal array (L9 can be hardcoded or generated). This is just an example.\n                    orthogonal_array = np.random.choice([0, 1], size=(num_dims_to_learn+1, num_dims_to_learn))\n                    \n                    # Evaluate all combinations based on the orthogonal array\n                    for row in range(orthogonal_array.shape[0]):\n                        temp_solution = np.copy(self.population[j])\n                        for col in range(orthogonal_array.shape[1]):\n                            temp_solution[dims_to_learn[col]] = levels[orthogonal_array[row, col], col]\n\n                        temp_solution = np.clip(temp_solution, func.bounds.lb, func.bounds.ub)\n                        f_temp = func(temp_solution)\n                        self.budget -= 1\n                        \n                        if f_temp < new_fitness[j]:\n                            new_population[j] = temp_solution\n                            new_fitness[j] = f_temp\n\n                            if f_temp < self.best_fitness:\n                                self.best_fitness = f_temp\n                                self.best_solution = temp_solution\n\n                            if f_temp < self.f_opt:\n                                self.f_opt = f_temp\n                                self.x_opt = temp_solution\n            \n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Self-adaptive population size\n            if generation % 10 == 0:\n                if len(self.success_F) > 0:\n                    mean_success = np.mean(self.fitness)\n                    mean_population = np.mean(self.fitness)\n                    if mean_success < mean_population:\n                         self.pop_size = int(min(self.pop_size * (1 + self.adaptation_rate), self.max_pop_size))\n                    else:\n                         self.pop_size = int(max(self.pop_size * (1 - self.adaptation_rate), self.min_pop_size))\n                    self.success_F = []\n                    self.success_CR = []\n\n\n            # Adaptation of F and CR (using success history)\n            if len(self.success_F) > 0:\n                self.F = np.mean(self.success_F) if len(self.success_F) > 0 else 0.5\n                self.CR = np.mean(self.success_CR) if len(self.success_CR) > 0 else 0.7\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm SelfAdaptiveDE scored 0.074 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["766128fb-ddb5-43a5-a8a6-9f5c7f9dd9b8"], "operator": null, "metadata": {"aucs": [0.147798743908365, 0]}}
{"id": "865c4838-878d-4cf5-a28d-41ef6b957b12", "fitness": 0.20696499846896432, "name": "CentralForceDynamicRange", "description": "A population-based algorithm that combines a central force optimization approach with a dynamic adjustment of the attraction range based on population diversity and fitness improvement.", "code": "import numpy as np\n\nclass CentralForceDynamicRange:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_range=1.0, range_decay=0.995, diversity_threshold=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.range = initial_range\n        self.range_decay = range_decay\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        while self.budget > 0:\n            # Calculate the center of mass (mean) of the population\n            center_of_mass = np.mean(population, axis=0)\n            \n            # Calculate population diversity\n            diversity = np.std(fitness)\n\n            # Adjust the attraction range dynamically based on diversity and fitness improvement\n            if diversity < self.diversity_threshold:\n                self.range *= 1.1  # Increase range if diversity is low\n            else:\n                self.range *= self.range_decay  # Decrease range otherwise\n            self.range = np.clip(self.range, 0.01, 2.0)\n\n            # Move each individual towards the center of mass\n            for i in range(self.pop_size):\n                # Calculate the distance to the center of mass\n                distance = center_of_mass - population[i]\n\n                # Normalize the distance vector\n                norm = np.linalg.norm(distance)\n                if norm > 0:\n                    direction = distance / norm\n                else:\n                    direction = np.zeros(self.dim)  # If individual is at the center, no movement\n\n                # Calculate the force (proportional to the inverse square of the distance, capped by the range)\n                force_magnitude = min(self.range / (norm + 1e-8), self.range)  # Adding a small value to prevent division by zero\n                \n                # Update the position\n                new_position = population[i] + force_magnitude * direction\n\n                # Clip to bounds\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                # Update if the new position is better\n                if new_fitness < fitness[i]:\n                    population[i] = new_position\n                    fitness[i] = new_fitness\n\n                    # Update global best\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n                        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm CentralForceDynamicRange scored 0.207 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["20528bce-25d4-465d-96a2-9b668abe7467"], "operator": null, "metadata": {"aucs": [0.07683988943763709, 0.1874424615185959, 0.2575714957472347, 0.13154373563712485, 0.15110336029647187, 0.14801910609520896, 0.1890547313442995, 0.15419786179484163, 0.1510498640263126, 0.11311981313492891, 0.15828648840740966, 0.18644680526339008, 0.1831561711730466, 0.1755150209855325, 0.5723000064462912, 0.295439297127974, 0.23036840830351135, 0.24599452301599045, 0.12792347665907433, 0.4039274529644101]}}
{"id": "2521c447-8d1a-4450-a8fc-7c5d9385e9ff", "fitness": 0.6356975333150304, "name": "SelfAdaptiveDE", "description": "Self-adaptive differential evolution with orthogonal learning and improved parameter adaptation.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = 10\n        self.max_pop_size = 100\n        self.F = 0.5\n        self.CR = 0.7\n        self.success_F = []\n        self.success_CR = []\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.adaptation_rate = 0.1\n        self.memory_size = 10\n        self.archive_F = np.ones(self.memory_size) * 0.5\n        self.archive_CR = np.ones(self.memory_size) * 0.7\n        self.archive_idx = 0\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.best_solution = self.population[np.argmin(self.fitness)]\n        self.best_fitness = np.min(self.fitness)\n\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n\n            for j in range(self.pop_size):\n                # Mutation with best solution guidance\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n\n                # Modified mutation: incorporating best solution\n                v = self.population[j] + self.F * (self.best_solution - self.population[j]) + self.F * (x1 - x2)\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.copy(self.population[j])\n                j_rand = np.random.randint(self.dim)\n                for k in range(self.dim):\n                    if np.random.rand() < self.CR or k == j_rand:\n                        u[k] = v[k]\n\n                # Orthogonal learning\n                if np.random.rand() < 0.1:\n                    orthogonal_sample = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    u = 0.5 * (u + orthogonal_sample)\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[j]:\n                    new_population[j] = u\n                    new_fitness[j] = f_u\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n\n                    if f_u < self.best_fitness:\n                        self.best_fitness = f_u\n                        self.best_solution = u\n\n                if f_u < self.f_opt:\n                    self.f_opt = f_u\n                    self.x_opt = u\n            \n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Self-adaptive population size\n            if generation % 10 == 0:\n                if len(self.success_F) > 0:\n                    mean_success = np.mean(self.fitness)\n                    mean_population = np.mean(self.fitness)\n                    if mean_success < mean_population:\n                         self.pop_size = int(min(self.pop_size * (1 + self.adaptation_rate), self.max_pop_size))\n                    else:\n                         self.pop_size = int(max(self.pop_size * (1 - self.adaptation_rate), self.min_pop_size))\n                    self.success_F = []\n                    self.success_CR = []\n\n\n            # Adaptation of F and CR (using success history and archive)\n            if len(self.success_F) > 0:\n                # Update archive\n                self.archive_F[self.archive_idx] = np.mean(self.success_F)\n                self.archive_CR[self.archive_idx] = np.mean(self.success_CR)\n                self.archive_idx = (self.archive_idx + 1) % self.memory_size\n\n                # Sample from archive\n                p = np.exp(0.1 * np.random.randn(self.memory_size))\n                p = p / np.sum(p)\n                sampled_idx = np.random.choice(self.memory_size, p=p)\n\n                self.F = self.archive_F[sampled_idx] + 0.1 * np.random.randn()\n                self.CR = self.archive_CR[sampled_idx] + 0.1 * np.random.randn()\n\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n            \n            self.success_F = []\n            self.success_CR = []\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm SelfAdaptiveDE scored 0.636 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["766128fb-ddb5-43a5-a8a6-9f5c7f9dd9b8"], "operator": null, "metadata": {"aucs": [0.22295065731116792, 0.7079563650615452, 0.7336855708189771, 0.8986572183333061, 0.8479403602276676, 0.8548480624939716, 0.35505370930890634, 0.7129497542489484, 0.8365404034608908, 0.5573363349674627, 0.9004519635475215, 0]}}
{"id": "93d2873c-ba67-4459-9903-4875cc9d20d8", "fitness": 0.3434763502697566, "name": "DynamicDE", "description": "A differential evolution strategy with a dynamically adjusted F parameter based on the distribution of function values in the population and a crossover rate that increases with generation to promote exploration early and exploitation later.", "code": "import numpy as np\n\nclass DynamicDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_initial = 0.5\n        self.CR_initial = 0.1\n        self.CR_final = 0.9\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        self.best_solution = population[np.argmin(fitness)]\n        self.best_fitness = np.min(fitness)\n\n        for i in range(self.pop_size):\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = population[i]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Dynamic F adaptation based on fitness distribution\n            fitness_std = np.std(fitness)\n            F = self.F_initial * (1 + fitness_std) # Adjust F based on population diversity\n\n            # Increase CR over time\n            CR = self.CR_initial + (self.CR_final - self.CR_initial) * (generation / (self.budget / self.pop_size + generation))\n            CR = np.clip(CR, 0.1, 0.9)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n                v = population[i] + F * (x1 - x2) + F * (self.best_solution - x3)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        u[j] = v[j]\n\n                # Selection\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < fitness[i]:\n                    new_population[i] = u\n                    new_fitness[i] = f_u\n\n                    if f_u < self.best_fitness:\n                        self.best_fitness = f_u\n                        self.best_solution = u\n                        \n                if f_u < self.f_opt:\n                    self.f_opt = f_u\n                    self.x_opt = u\n            \n            population = new_population\n            fitness = new_fitness\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm DynamicDE scored 0.343 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["766128fb-ddb5-43a5-a8a6-9f5c7f9dd9b8"], "operator": null, "metadata": {"aucs": [0.09365768505610705, 0.16266085144376397, 0.3765405714886234, 0.282114495386689, 0.2746299575931803, 0.3983445006722087, 0.26374342625588776, 0.30617567313010363, 0.25742686490423805, 0.1907679006375249, 0.28650407230474206, 0.9964582969566665, 0.1914656761548602, 0.30188693943225775, 0.6755794852048004, 0.41049129111786853, 0.28959559223137976, 0.45811377213336535, 0.17460138713135331, 0.4787685661595117]}}
{"id": "2b2f1e5c-8669-4e71-834d-91fec98adb89", "fitness": 0.6157379254098111, "name": "HybridDE", "description": "Hybrid DE with adaptive parameters, stagnation detection, and a restart mechanism to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, local_search_prob=0.1, local_search_sigma=0.1, stagnation_iter=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution scaling factor\n        self.Cr = Cr  # Crossover rate\n        self.local_search_prob = local_search_prob\n        self.local_search_sigma = local_search_sigma  # Std dev for Gaussian perturbation\n        self.stagnation_iter = stagnation_iter\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search around best\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.x_opt + self.local_search_sigma * np.random.normal(0, 1, self.dim)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                    else:\n                        self.stagnation_counter += 1\n                else:\n                    self.stagnation_counter += 1\n            \n            self.best_fitness_history.append(self.f_opt)\n            # Adaptive F and Cr (adjust based on success)\n            if np.random.rand() < 0.1:  # Small probability to change parameters\n                self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n                self.Cr = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)\n                self.local_search_sigma = np.clip(np.random.normal(0.1, 0.05), 0.01, 0.5)  # Adaptive local search sigma\n\n            # Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_iter:\n                # Restart: Re-initialize a portion of the population\n                num_restarts = int(self.pop_size * 0.2) # Restart 20% of population\n                restart_indices = np.random.choice(self.pop_size, num_restarts, replace=False)\n                population[restart_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_restarts, self.dim))\n                fitness[restart_indices] = np.array([func(x) for x in population[restart_indices]])\n                self.budget -= num_restarts\n                \n                # Update global best after restart\n                current_best_index = np.argmin(fitness)\n                if fitness[current_best_index] < self.f_opt:\n                    self.f_opt = fitness[current_best_index]\n                    self.x_opt = population[current_best_index]\n                \n                self.stagnation_counter = 0  # Reset stagnation counter\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm HybridDE scored 0.616 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["760e4eef-70b3-4b83-9d1b-a03ec787d07a"], "operator": null, "metadata": {"aucs": [0.4080560782974987, 0.6249103409186856, 0.6041562403811878, 0.9267921358408727, 0.5658612531947647, 0.24722677626746914, 0.7772441839963903, 0.584870724419597, 0.8945285737734676, 0.20200924235090878, 0.9560127936689781, 0.9968813434912247, 0.29618768446070676, 0.7894132257764669, 0.8944580937869914, 0.5545027971600811, 0.30368048756998134, 0.9061553293946653, 0.30204490457713784, 0.479766298869149]}}
{"id": "fc4871ba-aa35-48d0-acfb-702d33f3e949", "fitness": 0.6473065930712852, "name": "EnhancedDE", "description": "An enhanced Differential Evolution algorithm with a dynamically adjusted scaling factor, combined with a restart mechanism based on population diversity.", "code": "import numpy as np\n\nclass EnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_initial=0.5, Cr=0.9, diversity_threshold=0.1, restart_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_initial = F_initial  # Initial Differential evolution scaling factor\n        self.Cr = Cr  # Crossover rate\n        self.diversity_threshold = diversity_threshold\n        self.restart_probability = restart_probability\n        self.F = self.F_initial  # Dynamic scaling factor\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Adaptive F: Adjust scaling factor based on progress\n                self.F = self.F_initial * np.exp(np.random.normal(0, 0.1))  # Introduce randomness\n                self.F = np.clip(self.F, 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Diversity Check and Restart\n            if self.population_diversity(population) < self.diversity_threshold and np.random.rand() < self.restart_probability:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size  # Account for new evaluations\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n\n        return self.f_opt, self.x_opt\n\n    def population_diversity(self, population):\n        \"\"\"\n        Calculates the average distance of individuals from the population mean.\n        A low value indicates low diversity.\n        \"\"\"\n        mean_position = np.mean(population, axis=0)\n        distances = np.linalg.norm(population - mean_position, axis=1)\n        return np.mean(distances)", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedDE scored 0.647 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["760e4eef-70b3-4b83-9d1b-a03ec787d07a"], "operator": null, "metadata": {"aucs": [0.2612095661254916, 0.5823249889189719, 0.5787996205489984, 0.8654272153099735, 0.5888373134752087, 0.8566982122720447, 0.5547903473839646, 0.5617403233837093, 0.7233775057493073, 0.49683293270484585, 0.9466415492094552, 0.9981311230892506, 0.36452899828288887, 0.6575109792941913, 0.9429832751700514, 0.8380856423123928, 0.48366707769225425, 0.8067750958337744, 0.31593873229862757, 0.5218313623703013]}}
{"id": "f9fa5531-c3ad-469b-b93b-6d0723bae5d3", "fitness": 0.5457794063270262, "name": "HybridDE", "description": "Hybrid DE with adaptive parameters (F, Cr, local search probability and sigma), using success history to adjust them, and an improved local search.", "code": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, local_search_prob=0.1, local_search_sigma=0.1, F_decay=0.99, Cr_decay=0.99, ls_prob_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution scaling factor\n        self.Cr = Cr  # Crossover rate\n        self.local_search_prob = local_search_prob\n        self.local_search_sigma = local_search_sigma  # Std dev for Gaussian perturbation\n        self.F_decay = F_decay\n        self.Cr_decay = Cr_decay\n        self.ls_prob_decay = ls_prob_decay\n        self.success_F = []\n        self.success_Cr = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search around best - Improved version\n                if np.random.rand() < self.local_search_prob:\n                    # Adaptive sigma, scale with budget left\n                    ls_sigma = self.local_search_sigma * (self.budget / 10000) # Reduce sigma as budget decreases\n                    trial = self.x_opt + ls_sigma * np.random.normal(0, 1, self.dim)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            #Adapt parameters\n            if len(self.success_F) > 0:\n                self.F = np.mean(self.success_F)\n                self.Cr = np.mean(self.success_Cr)\n                self.success_F = []\n                self.success_Cr = []\n\n            self.F *= self.F_decay\n            self.Cr *= self.Cr_decay\n            self.local_search_prob *= self.ls_prob_decay\n\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n            self.local_search_prob = np.clip(self.local_search_prob, 0.01, 0.5)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm HybridDE scored 0.546 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["760e4eef-70b3-4b83-9d1b-a03ec787d07a"], "operator": null, "metadata": {"aucs": [0.2711136616289971, 0.3527172552515101, 0.2810098662066335, 0.2377648132989164, 0.6583024480469396, 0.8937560212250159, 0.33432173404028265, 0.24988585428193943, 0.7771865165741988, 0.8555122453757306, 0.9450304800045588, 0.9956686061914956, 0.2701732027061913, 0.6594855946440751, 0.9470254214148411, 0.4301405813465172, 0.3969508839150869, 0.616170770709217, 0.24201453756609526, 0.501357632112279]}}
{"id": "febd856e-418b-4258-a359-29aa8f6d8da0", "fitness": 0.51139175915247, "name": "HybridDE", "description": "Combines differential evolution with a self-adaptive local search, dynamically adjusting search intensity based on improvement rate and adding a perturbation vector.", "code": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, local_search_prob=0.1, initial_local_search_sigma=0.1, sigma_decay=0.99, perturbation_strength=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution scaling factor\n        self.Cr = Cr  # Crossover rate\n        self.local_search_prob = local_search_prob\n        self.local_search_sigma = initial_local_search_sigma  # Initial std dev for Gaussian perturbation\n        self.sigma_decay = sigma_decay  # Decay rate for sigma\n        self.perturbation_strength = perturbation_strength # Strength of random perturbation\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        improvement_rate = 0.0\n\n        while self.budget > 0:\n            num_improvements = 0\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n                \n                #Perturbation vector\n                trial += self.perturbation_strength * np.random.normal(0, 1, self.dim)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n\n                # Local Search around best, adaptively\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.x_opt + self.local_search_sigma * np.random.normal(0, 1, self.dim)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    num_improvements += 1\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            #Adaptive local search\n            improvement_rate = num_improvements / self.pop_size\n            if improvement_rate < 0.1:\n                self.local_search_sigma *= (1/self.sigma_decay) #Increase sigma if improvement rate low\n            else:\n                 self.local_search_sigma *= self.sigma_decay # Decrease sigma if improvement rate high\n            \n            self.local_search_sigma = np.clip(self.local_search_sigma, 0.0001, 0.5) #Prevent sigma from becoming too large or small\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm HybridDE scored 0.511 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["760e4eef-70b3-4b83-9d1b-a03ec787d07a"], "operator": null, "metadata": {"aucs": [0.29930670094856293, 0.45119484532235643, 0.49462408756125575, 0.1795070240744603, 0.5405315834763499, 0.640062014314299, 0.3364747120166338, 0.4962642636510912, 0.561903676414978, 0.5086176880306443, 0.9560903224502849, 0.996137173712419, 0.29697155797869845, 0.5795068647941153, 0.8920380876467383, 0.360683169203622, 0.23103448298027707, 0.7537465494292672, 0.17950983443816515, 0.4736305446051785]}}
{"id": "a82aca1e-605c-47f8-a81b-4e25676288e4", "fitness": -Infinity, "name": "OrthogonalDE", "description": "An enhanced Differential Evolution algorithm that incorporates orthogonal learning to improve search efficiency and uses a self-adaptive mechanism to adjust the mutation factor based on the diversity of the population.", "code": "import numpy as np\n\nclass OrthogonalDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, orthogonal_levels=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.orthogonal_levels = orthogonal_levels  # Levels for orthogonal design\n        self.population = None\n        self.fitness = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_solution = self.population[np.argmin(self.fitness)]\n        self.best_fitness = np.min(self.fitness)\n        self.diversity = self.calculate_diversity()\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n        while self.budget > 0:\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x1 - x2)\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                # Orthogonal learning\n                u = self.orthogonal_crossover(u, self.population, func.bounds.lb, func.bounds.ub)\n                \n                # Selection\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    new_population[i] = u\n                    new_fitness[i] = f_u\n\n                    if f_u < self.best_fitness:\n                        self.best_fitness = f_u\n                        self.best_solution = u\n\n                if f_u < self.f_opt:\n                    self.f_opt = f_u\n                    self.x_opt = u\n            \n            self.population = new_population\n            self.fitness = new_fitness\n            self.diversity = self.calculate_diversity()\n\n            # Self-adaptive F based on diversity\n            if self.diversity < 0.1:  # Low diversity, increase exploration\n                self.F = min(self.F + 0.1, 0.9)\n            elif self.diversity > 0.5:  # High diversity, increase exploitation\n                self.F = max(self.F - 0.1, 0.1)\n\n        return self.f_opt, self.x_opt\n\n    def orthogonal_crossover(self, individual, population, lower_bound, upper_bound):\n        \"\"\"\n        Applies orthogonal crossover to an individual using other population members.\n        \"\"\"\n        design = self.create_orthogonal_design(self.dim, self.orthogonal_levels)\n        num_combinations = design.shape[0]\n        \n        candidates = []\n        for i in range(num_combinations):\n            new_vector = np.copy(individual)\n            for j in range(self.dim):\n                if design[i, j] > 0:  # Use other population members\n                    idx = np.random.randint(0, self.pop_size)\n                    new_vector[j] = population[idx, j]\n\n            new_vector = np.clip(new_vector, lower_bound, upper_bound)\n            candidates.append(new_vector)\n\n        # Select best candidate\n        best_candidate = individual\n        best_fitness = np.inf  # Assume function evaluations are handled outside\n\n        return best_candidate #Return candidate without fitness evaluation since func(x) needs to be called outside\n\n    def create_orthogonal_design(self, num_factors, num_levels):\n      \n        if num_levels == 2:\n            if num_factors <= 3:\n                if num_factors == 1:\n                    design = np.array([[0], [1]])\n                if num_factors == 2:\n                     design = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n                if num_factors == 3:\n                    design = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 0]])\n            else:\n                design = np.random.randint(0, num_levels, size=(num_levels**2, num_factors))\n\n        elif num_levels == 3:\n            if num_factors <= 4:\n                if num_factors == 1:\n                    design = np.array([[0], [1], [2]])\n                if num_factors == 2:\n                    design = np.array([[0, 0], [0, 1], [0, 2], [1, 0], [1, 1], [1, 2], [2, 0], [2, 1], [2, 2]])\n                if num_factors == 3:\n                    design = np.array([[0, 0, 0], [0, 1, 1], [0, 2, 2], [1, 0, 1], [1, 1, 2], [1, 2, 0], [2, 0, 2], [2, 1, 0], [2, 2, 1]])\n                if num_factors == 4:\n                    design = np.array([[0, 0, 0, 0], [0, 1, 1, 1], [0, 2, 2, 2], [1, 0, 1, 2], [1, 1, 2, 0], [1, 2, 0, 1], [2, 0, 2, 1], [2, 1, 0, 2], [2, 2, 1, 0]])\n            else:\n                 design = np.random.randint(0, num_levels, size=(num_levels**2, num_factors))\n        else:\n             design = np.random.randint(0, num_levels, size=(num_levels**2, num_factors))\n\n        return design\n\n\n    def calculate_diversity(self):\n        \"\"\"\n        Calculates the diversity of the population based on the average distance\n        from the centroid.\n        \"\"\"\n        centroid = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - centroid, axis=1)\n        return np.mean(distances)", "configspace": "", "generation": 2, "feedback": "An exception occurred: Evaluation timed out after 60 seconds..", "error": "", "parent_ids": ["766128fb-ddb5-43a5-a8a6-9f5c7f9dd9b8"], "operator": null, "metadata": {}}
{"id": "b56789c3-8b09-4ff8-9109-e54877cb1a20", "fitness": -Infinity, "name": "AdaptiveDELocalSearch", "description": "A Differential Evolution algorithm with a self-adjusting scaling factor based on fitness improvement and a local search phase using Nelder-Mead simplex method for promising individuals.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDELocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_initial=0.5, Cr=0.9, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_initial = F_initial\n        self.Cr = Cr\n        self.local_search_prob = local_search_prob\n\n        self.F = self.F_initial  # Adaptive scaling factor\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive F: Adjust scaling factor based on fitness improvement\n                if fitness[i] < self.f_opt:\n                      self.F = self.F_initial * np.exp(np.random.normal(0, 0.1))  # Introduce randomness\n                else:\n                      self.F = self.F_initial * np.exp(np.random.normal(0, 0.3)) # Introduce larger randomness if no improvement\n                self.F = np.clip(self.F, 0.1, 1.0)\n\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Local Search\n            for i in range(self.pop_size):\n                if np.random.rand() < self.local_search_prob:\n                    \n                    def obj_for_minimize(x):\n                        val = func(x)\n                        self.budget -= 1\n                        return val\n\n                    if self.budget > self.dim + 1:\n                        bounds = [(func.bounds.lb, func.bounds.ub) for _ in range(self.dim)]\n                        res = minimize(obj_for_minimize, population[i], method='Nelder-Mead', bounds=bounds, options={'maxfev': self.dim+1})\n                        \n                        if self.budget <= 0:\n                           break\n                        if res.fun < fitness[i]:\n                            population[i] = res.x\n                            fitness[i] = res.fun\n\n                            if res.fun < self.f_opt:\n                                self.f_opt = res.fun\n                                self.x_opt = res.x\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["fc4871ba-aa35-48d0-acfb-702d33f3e949"], "operator": null, "metadata": {}}
{"id": "a6e40f89-91d6-4063-bd5a-a845c4612008", "fitness": -Infinity, "name": "EnhancedDE_MirroredSampling", "description": "Enhanced DE with a mirrored sampling strategy, adaptive crossover rate, and a more robust diversity check using percentiles to trigger restarts.", "code": "import numpy as np\n\nclass EnhancedDE_MirroredSampling:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_initial=0.5, Cr_initial=0.9, diversity_threshold=0.1, restart_probability=0.05, percentile_threshold=25):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_initial = F_initial  # Initial Differential evolution scaling factor\n        self.Cr_initial = Cr_initial  # Initial Crossover rate\n        self.diversity_threshold = diversity_threshold\n        self.restart_probability = restart_probability\n        self.F = self.F_initial  # Dynamic scaling factor\n        self.Cr = self.Cr_initial #Dynamic Crossover Rate\n        self.percentile_threshold = percentile_threshold # Percentile to consider for diversity check\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Adaptive F: Adjust scaling factor based on progress\n                self.F = self.F_initial * np.exp(np.random.normal(0, 0.1))  # Introduce randomness\n                self.F = np.clip(self.F, 0.1, 1.0)\n\n                #Adaptive Cr: Adjust Crossover Rate\n                self.Cr = self.Cr_initial * np.exp(np.random.normal(0,0.1))\n                self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n                # Differential Evolution Mutation - Mirrored Sampling\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n\n                # Mirrored sampling to handle boundary violations more effectively\n                mutant = population[a] + self.F * (population[b] - population[c])\n                \n                # Reflect mutant if it goes beyond boundaries\n                mutant = np.where(mutant < func.bounds.lb, 2 * func.bounds.lb - mutant, mutant)\n                mutant = np.where(mutant > func.bounds.ub, 2 * func.bounds.ub - mutant, mutant)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub) #Ensure clip\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Diversity Check and Restart using Percentile\n            diversity_metric = self.population_diversity(population)\n            if diversity_metric < np.percentile(diversity_metric, self.percentile_threshold) and np.random.rand() < self.restart_probability:\n\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size  # Account for new evaluations\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n\n        return self.f_opt, self.x_opt\n\n    def population_diversity(self, population):\n        \"\"\"\n        Calculates the average distance of individuals from the population mean.\n        A low value indicates low diversity.\n        \"\"\"\n        mean_position = np.mean(population, axis=0)\n        distances = np.linalg.norm(population - mean_position, axis=1)\n        return distances", "configspace": "", "generation": 3, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["fc4871ba-aa35-48d0-acfb-702d33f3e949"], "operator": null, "metadata": {}}
{"id": "fb34f95a-dd6a-4fa5-ba02-a6f086d9a90c", "fitness": -Infinity, "name": "SelfAdaptiveDE", "description": "Enhanced self-adaptive differential evolution with orthogonal learning, improved parameter adaptation using a truncated levy flight, and population size adaptation based on fitness improvement stagnation.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = 10\n        self.max_pop_size = 100\n        self.F = 0.5\n        self.CR = 0.7\n        self.success_F = []\n        self.success_CR = []\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.adaptation_rate = 0.1\n        self.memory_size = 10\n        self.archive_F = np.ones(self.memory_size) * 0.5\n        self.archive_CR = np.ones(self.memory_size) * 0.7\n        self.archive_idx = 0\n        self.stagnation_counter = 0\n        self.max_stagnation = 50\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.best_solution = self.population[np.argmin(self.fitness)]\n        self.best_fitness = np.min(self.fitness)\n        self.previous_best_fitness = self.best_fitness\n\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n\n            for j in range(self.pop_size):\n                # Mutation with best solution guidance\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = self.population[idxs]\n\n                # Modified mutation: incorporating best solution\n                v = self.population[j] + self.F * (self.best_solution - self.population[j]) + self.F * (x1 - x2)\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.copy(self.population[j])\n                j_rand = np.random.randint(self.dim)\n                for k in range(self.dim):\n                    if np.random.rand() < self.CR or k == j_rand:\n                        u[k] = v[k]\n\n                # Orthogonal learning\n                if np.random.rand() < 0.1:\n                    orthogonal_sample = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    u = 0.5 * (u + orthogonal_sample)\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Truncated Levy Flight\n                if np.random.rand() < 0.05:  # Apply Levy flight with a small probability\n                    step_size = self.levy_flight(1, self.dim, beta=1.5)\n                    u = u + 0.01 * step_size * (func.bounds.ub - func.bounds.lb) # Scale step size\n                    u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n\n                # Selection\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[j]:\n                    new_population[j] = u\n                    new_fitness[j] = f_u\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n\n                    if f_u < self.best_fitness:\n                        self.best_fitness = f_u\n                        self.best_solution = u\n\n                if f_u < self.f_opt:\n                    self.f_opt = f_u\n                    self.x_opt = u\n            \n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Stagnation Check\n            if self.best_fitness < self.previous_best_fitness:\n                self.stagnation_counter = 0\n                self.previous_best_fitness = self.best_fitness\n            else:\n                self.stagnation_counter += 1\n\n            # Self-adaptive population size\n            if generation % 10 == 0:\n                if len(self.success_F) > 0:\n                    mean_success = np.mean(self.fitness)\n                    mean_population = np.mean(self.fitness)\n                    if mean_success < mean_population:\n                         self.pop_size = int(min(self.pop_size * (1 + self.adaptation_rate), self.max_pop_size))\n                    else:\n                         self.pop_size = int(max(self.pop_size * (1 - self.adaptation_rate), self.min_pop_size))\n                    self.success_F = []\n                    self.success_CR = []\n            \n            # Population size increase if stagnation is detected\n            if self.stagnation_counter > self.max_stagnation:\n                self.pop_size = int(min(self.pop_size * (1 + self.adaptation_rate), self.max_pop_size))\n                self.stagnation_counter = 0\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n\n            # Adaptation of F and CR (using success history and archive)\n            if len(self.success_F) > 0:\n                # Update archive\n                self.archive_F[self.archive_idx] = np.mean(self.success_F)\n                self.archive_CR[self.archive_idx] = np.mean(self.success_CR)\n                self.archive_idx = (self.archive_idx + 1) % self.memory_size\n\n                # Sample from archive\n                p = np.exp(0.1 * np.random.randn(self.memory_size))\n                p = p / np.sum(p)\n                sampled_idx = np.random.choice(self.memory_size, p=p)\n\n                self.F = self.archive_F[sampled_idx] + 0.1 * np.random.randn()\n                self.CR = self.archive_CR[sampled_idx] + 0.1 * np.random.randn()\n\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n            \n            self.success_F = []\n            self.success_CR = []\n\n        return self.f_opt, self.x_opt\n\n    def levy_flight(self, n, num_variables, beta=1.5):\n        \"\"\"\n        Generate Levy flights\n        \"\"\"\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.randn(n, num_variables) * sigma\n        v = np.random.randn(n, num_variables)\n        step = u / abs(v) ** (1 / beta)\n        return step", "configspace": "", "generation": 3, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["2521c447-8d1a-4450-a8fc-7c5d9385e9ff"], "operator": null, "metadata": {}}
{"id": "d38af840-83a4-4b9b-bc70-e633f3d880a4", "fitness": 0.19252658966834074, "name": "HybridDE", "description": "Hybrid DE with adaptive parameters and covariance matrix adaptation local search around the best solution.", "code": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, local_search_prob=0.1, local_search_sigma=0.1, stagnation_iter=50, CMA_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution scaling factor\n        self.Cr = Cr  # Crossover rate\n        self.local_search_prob = local_search_prob\n        self.local_search_sigma = local_search_sigma  # Initial std dev for Gaussian perturbation\n        self.stagnation_iter = stagnation_iter\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.CMA_samples = CMA_samples # Number of samples used to estimate covariance matrix in local search\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                    else:\n                        self.stagnation_counter += 1\n                else:\n                    self.stagnation_counter += 1\n\n            self.best_fitness_history.append(self.f_opt)\n            # Adaptive F and Cr (adjust based on success)\n            if np.random.rand() < 0.1:  # Small probability to change parameters\n                self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n                self.Cr = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)\n                self.local_search_sigma = np.clip(np.random.normal(0.1, 0.05), 0.01, 0.5)  # Adaptive local search sigma\n\n            # Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_iter:\n                # Restart: Re-initialize a portion of the population\n                num_restarts = int(self.pop_size * 0.2) # Restart 20% of population\n                restart_indices = np.random.choice(self.pop_size, num_restarts, replace=False)\n                population[restart_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_restarts, self.dim))\n                fitness[restart_indices] = np.array([func(x) for x in population[restart_indices]])\n                self.budget -= num_restarts\n\n                # Update global best after restart\n                current_best_index = np.argmin(fitness)\n                if fitness[current_best_index] < self.f_opt:\n                    self.f_opt = fitness[current_best_index]\n                    self.x_opt = population[current_best_index]\n\n                self.stagnation_counter = 0  # Reset stagnation counter\n\n            # Covariance matrix adaptation based local search around the best solution.\n            if np.random.rand() < self.local_search_prob:\n                # Sample around the best solution\n                samples = np.random.normal(self.x_opt, self.local_search_sigma, size=(self.CMA_samples, self.dim))\n                samples = np.clip(samples, func.bounds.lb, func.bounds.ub)\n                fitness_samples = np.array([func(x) for x in samples])\n                self.budget -= self.CMA_samples\n                if self.budget <= 0:\n                    break\n\n                # Update best solution if a better one is found\n                best_sample_index = np.argmin(fitness_samples)\n                if fitness_samples[best_sample_index] < self.f_opt:\n                    self.f_opt = fitness_samples[best_sample_index]\n                    self.x_opt = samples[best_sample_index]\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm HybridDE scored 0.193 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2b2f1e5c-8669-4e71-834d-91fec98adb89"], "operator": null, "metadata": {"aucs": [0.3850531793366815, 0]}}
{"id": "dfb40e60-7f73-479b-853d-9c517e54818c", "fitness": -Infinity, "name": "AdaptiveHybridDE", "description": "Adaptive Hybrid DE with orthogonal crossover, success-based parameter adaptation, and a niching strategy to maintain population diversity.", "code": "import numpy as np\n\nclass AdaptiveHybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, local_search_prob=0.1, local_search_sigma=0.1, stagnation_iter=50, archive_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution scaling factor\n        self.Cr = Cr  # Crossover rate\n        self.local_search_prob = local_search_prob\n        self.local_search_sigma = local_search_sigma  # Std dev for Gaussian perturbation\n        self.stagnation_iter = stagnation_iter\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.archive_size = archive_size  # Size of archive for storing promising solutions\n        self.archive = [] # stores solutions\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        success_F = []\n        success_Cr = []\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                trial = self.orthogonal_crossover(population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Local Search around best\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.x_opt + self.local_search_sigma * np.random.normal(0, 1, self.dim)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    success_F.append(self.F)\n                    success_Cr.append(self.Cr)\n                    \n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                        \n                        # Update Archive\n                        self.update_archive(trial)\n                    else:\n                        self.stagnation_counter += 1\n                else:\n                    self.stagnation_counter += 1\n            \n            self.best_fitness_history.append(self.f_opt)\n            # Adaptive F and Cr (adjust based on success history)\n            if len(success_F) > 0:\n                self.F = np.mean(success_F)\n                self.Cr = np.mean(success_Cr)\n            \n            self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n            self.Cr = np.clip(np.random.normal(self.Cr, 0.1), 0.1, 1.0)\n            self.local_search_sigma = np.clip(np.random.normal(0.1, 0.05), 0.01, 0.5)  # Adaptive local search sigma\n\n            success_F = []  # Reset success history\n            success_Cr = []\n\n            # Stagnation Check and Restart (Niching)\n            if self.stagnation_counter > self.stagnation_iter:\n                # Restart: Re-initialize a portion of the population, favoring archive solutions\n                num_restarts = int(self.pop_size * 0.2)  # Restart 20% of population\n                restart_indices = np.random.choice(self.pop_size, num_restarts, replace=False)\n                \n                for idx in restart_indices:\n                    if len(self.archive) > 0 and np.random.rand() < 0.5:\n                        # Select from archive with 50% probability\n                        archived_solution = self.archive[np.random.randint(len(self.archive))]\n                        population[idx] = archived_solution\n                    else:\n                        # Otherwise, random initialization\n                        population[idx] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                \n                fitness[restart_indices] = np.array([func(x) for x in population[restart_indices]])\n                self.budget -= num_restarts\n                \n                # Update global best after restart\n                current_best_index = np.argmin(fitness)\n                if fitness[current_best_index] < self.f_opt:\n                    self.f_opt = fitness[current_best_index]\n                    self.x_opt = population[current_best_index]\n                    # Update Archive\n                    self.update_archive(self.x_opt)\n                    \n                self.stagnation_counter = 0  # Reset stagnation counter\n        return self.f_opt, self.x_opt\n    \n    def orthogonal_crossover(self, x, mutant):\n        # Create orthogonal design matrix (example using a simple Hadamard matrix for 2 dimensions)\n        if self.dim == 2:\n            H = np.array([[1, 1], [1, -1]])\n            trial = x.copy()\n            for j in range(self.dim):\n                trial[j] = 0.5 * (x[j] + mutant[j] + H[0,j] * (x[j]-mutant[j])) #Simplified computation using Hadamard matrix values\n            return trial\n        \n        # For higher dimensions, revert to standard crossover\n        else:\n            trial = np.copy(x)\n            mask = np.random.rand(self.dim) < self.Cr\n            trial[mask] = mutant[mask]\n            return trial\n            \n    def update_archive(self, x):\n        if len(self.archive) < self.archive_size:\n            self.archive.append(x)\n        else:\n            # Replace the worst solution in the archive with the new one\n            fitnesses = [func(member) for member in self.archive]\n            worst_index = np.argmax(fitnesses) # Assuming minimization, maximize fitnesses to find the worst\n            \n            if func(x) < fitnesses[worst_index]:\n                self.archive[worst_index] = x", "configspace": "", "generation": 3, "feedback": "An exception occurred: name 'func' is not defined.", "error": "", "parent_ids": ["2b2f1e5c-8669-4e71-834d-91fec98adb89"], "operator": null, "metadata": {}}
{"id": "d3fb2f85-d062-42f3-a812-7e45021eedcb", "fitness": 0.5857513307899296, "name": "DynamicDE", "description": "A Differential Evolution variant with a dynamically adjusting population size and a Cauchy mutation operator, coupled with a local search guided by a decaying step size.", "code": "import numpy as np\n\nclass DynamicDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=20, F=0.5, Cr=0.9, local_search_prob=0.1, initial_local_search_sigma=0.1, pop_size_adjust_freq=50, pop_size_adjust_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.initial_pop_size = initial_pop_size\n        self.F = F  # Differential evolution scaling factor\n        self.Cr = Cr  # Crossover rate\n        self.local_search_prob = local_search_prob\n        self.local_search_sigma = initial_local_search_sigma  # Initial std dev for Gaussian perturbation\n        self.initial_local_search_sigma = initial_local_search_sigma\n        self.pop_size_adjust_freq = pop_size_adjust_freq\n        self.pop_size_adjust_rate = pop_size_adjust_rate\n        self.generation_counter = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation (Cauchy)\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c]) * np.random.standard_cauchy(size=self.dim)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search around best with decaying sigma\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.x_opt + self.local_search_sigma * np.random.normal(0, 1, self.dim)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Adjust population size periodically\n            self.generation_counter += 1\n            if self.generation_counter % self.pop_size_adjust_freq == 0:\n                improvement = False\n                N = 5\n                if len(np.unique(fitness[:N])) < N:\n                  improvement = True\n\n                if improvement:\n                    self.pop_size = min(int(self.pop_size * (1 + self.pop_size_adjust_rate)), self.initial_pop_size * 2)  # Increase pop size\n                else:\n                    self.pop_size = max(int(self.pop_size * (1 - self.pop_size_adjust_rate)), self.initial_pop_size // 2)  # Decrease pop size\n\n                # Regenerate the population based on the new size\n                new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                new_fitness = np.array([func(x) for x in new_population])\n                self.budget -= new_population.shape[0]\n                \n                #Elitism: Retain the best individual from the previous population\n                best_index = np.argmin(fitness)\n                new_population[0] = population[best_index]\n                new_fitness[0] = fitness[best_index]\n\n                population = new_population\n                fitness = new_fitness\n                \n                \n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n\n\n            # Decay local search sigma\n            self.local_search_sigma = self.initial_local_search_sigma * (1 - self.generation_counter / (self.budget + self.generation_counter))\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm DynamicDE scored 0.586 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2b2f1e5c-8669-4e71-834d-91fec98adb89"], "operator": null, "metadata": {"aucs": [0.2865048781278168, 0.4226497208023854, 0.5702975423928835, 0.9453102323109994, 0.6123765969280166, 0.6719042180910804, 0.46269283572604714, 0.4774901350455527, 0.5785282321675473, 0.5462989233210391, 0.9079490385872473, 0.9956924373189547, 0.2500843423045047, 0.5363672216448658, 0.8495323757456887, 0.653875897875216, 0.4367098137175892, 0.8014838350073288, 0.22137203457797028, 0.4879063041058572]}}
{"id": "88a1024e-e993-438b-9400-3e7e3c9c39f5", "fitness": 0.5888666136317744, "name": "AdaptiveArchiveDE", "description": "Adaptive Differential Evolution with a Novel Archive-based Learning strategy, incorporating successful solutions from past generations to guide future search directions.", "code": "import numpy as np\n\nclass AdaptiveArchiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10, F=0.5, Cr=0.9, local_search_prob=0.1, local_search_sigma=0.1, F_decay=0.99, Cr_decay=0.99, ls_prob_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = F  # Differential evolution scaling factor\n        self.Cr = Cr  # Crossover rate\n        self.local_search_prob = local_search_prob\n        self.local_search_sigma = local_search_sigma  # Std dev for Gaussian perturbation\n        self.F_decay = F_decay\n        self.Cr_decay = Cr_decay\n        self.ls_prob_decay = ls_prob_decay\n        self.archive = [] # Store successful solutions\n        self.success_F = []\n        self.success_Cr = []\n\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n\n                # Archive-based learning: with a small probability, use a solution from the archive\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    archive_idx = np.random.randint(0, len(self.archive))\n                    mutant = population[a] + self.F * (population[b] - self.archive[archive_idx])\n                \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search around best - Improved version\n                if np.random.rand() < self.local_search_prob:\n                    # Adaptive sigma, scale with budget left\n                    ls_sigma = self.local_search_sigma * (self.budget / 10000) # Reduce sigma as budget decreases\n                    trial = self.x_opt + ls_sigma * np.random.normal(0, 1, self.dim)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy()) # add the old individual\n                    else:\n                        # Replace a random archive member\n                        replace_idx = np.random.randint(0, self.archive_size)\n                        self.archive[replace_idx] = population[i].copy()\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            #Adapt parameters\n            if len(self.success_F) > 0:\n                self.F = np.mean(self.success_F)\n                self.Cr = np.mean(self.success_Cr)\n                self.success_F = []\n                self.success_Cr = []\n\n            self.F *= self.F_decay\n            self.Cr *= self.Cr_decay\n            self.local_search_prob *= self.ls_prob_decay\n\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n            self.local_search_prob = np.clip(self.local_search_prob, 0.01, 0.5)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveArchiveDE scored 0.589 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f9fa5531-c3ad-469b-b93b-6d0723bae5d3"], "operator": null, "metadata": {"aucs": [0.2419546304017105, 0.8696443476130289, 0.4677638518170415, 0.25149687398508247, 0.8917210520883447, 0.569054893765485, 0.37053077873030993, 0.6145142377236201, 0.9103115613847534, 0.20045073677794356, 0.9661357547138895, 0.9972520207494717, 0.28230298978171064, 0.7511990314912635, 0.6442988694343126, 0.8742759551892969, 0.22278530037195576, 0.9266356937738142, 0.22792384002279098, 0.4970798528196576]}}
{"id": "e4a4e9fa-71b3-46df-af01-aa62688f9049", "fitness": 0.6779790996046524, "name": "NeighborhoodDE", "description": "Population-based DE with a decaying exploration rate, velocity clamping, and a neighborhood-based mutation strategy that leverages the best solutions in the population while gradually reducing exploration over time.", "code": "import numpy as np\n\nclass NeighborhoodDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, neighborhood_size=3, initial_exploration_rate=0.2, exploration_decay=0.995, velocity_clamping=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.neighborhood_size = neighborhood_size\n        self.initial_exploration_rate = initial_exploration_rate\n        self.exploration_rate = initial_exploration_rate\n        self.exploration_decay = exploration_decay\n        self.velocity_clamping = velocity_clamping\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Sort population based on fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            for i in range(self.pop_size):\n                # Neighborhood selection\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood = population[neighborhood_indices]\n\n                # Select best individuals from neighborhood\n                best_index = np.argmin(fitness[neighborhood_indices])\n                best_neighbor = neighborhood[best_index]\n\n                # Differential Evolution with neighborhood information and exploration rate\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n\n                # Apply exploration rate\n                if np.random.rand() < self.exploration_rate:\n                    mutant = population[i] + self.F * (population[a] - population[b])\n                else:\n                    mutant = population[i] + self.F * (best_neighbor - population[i]) + self.F * (population[a] - population[b])\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n                \n                # Velocity Clamping\n                velocity = trial - population[i]\n                norm = np.linalg.norm(velocity)\n                if norm > self.velocity_clamping:\n                  velocity = velocity * (self.velocity_clamping / norm)\n                  trial = population[i] + velocity\n                  trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Decay exploration rate\n            self.exploration_rate *= self.exploration_decay\n            self.exploration_rate = max(self.exploration_rate, 0.01)  # Ensure minimum exploration\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm NeighborhoodDE scored 0.678 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2b2f1e5c-8669-4e71-834d-91fec98adb89"], "operator": null, "metadata": {"aucs": [0.30561125463570926, 0.35741345306527506, 0.8458782242399018, 0.9337520958177531, 0.8223389660468334, 0.9141438953901352, 0.6861719874448835, 0.851399667381025, 0.7796582871990668, 0.2029721130805744, 0.9346876641021036, 0.9993308631861958, 0.3411941718128043, 0.7878818667539936, 0.9486610856607677, 0.7957090441112806, 0.44330639718947484, 0.9089911693878998, 0.19741735913614555, 0.5030624264512225]}}
{"id": "e9b105df-a69f-4f1c-9561-b63ba0486adf", "fitness": 0.6185573122362588, "name": "EnhancedDE", "description": "Enhanced Differential Evolution with adaptive scaling factor, crossover rate, and an aging mechanism to promote exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_initial=0.5, Cr_initial=0.9, diversity_threshold=0.1, restart_probability=0.05, age_limit=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_initial = F_initial  # Initial Differential evolution scaling factor\n        self.Cr_initial = Cr_initial  # Initial Crossover rate\n        self.diversity_threshold = diversity_threshold\n        self.restart_probability = restart_probability\n        self.F = self.F_initial  # Dynamic scaling factor\n        self.Cr = self.Cr_initial  # Dynamic Crossover rate\n        self.age_limit = age_limit\n        self.ages = np.zeros(pop_size, dtype=int)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Adaptive F and Cr: Adjust scaling factor and crossover rate based on progress and age\n                self.F = self.F_initial * np.exp(np.random.normal(0, 0.1)) * (1 - self.ages[i] / self.age_limit) # Age reduces F\n                self.F = np.clip(self.F, 0.1, 1.0)\n                \n                self.Cr = self.Cr_initial * np.exp(np.random.normal(0, 0.1)) * (1 - self.ages[i] / self.age_limit) # Age reduces Cr\n                self.Cr = np.clip(self.Cr, 0.1, 1.0)\n                \n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    self.ages[i] = 0 # Reset age\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.ages[i] += 1 # Increment age\n\n            # Diversity Check and Restart\n            if self.population_diversity(population) < self.diversity_threshold and np.random.rand() < self.restart_probability:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size  # Account for new evaluations\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n                self.ages = np.zeros(self.pop_size, dtype=int) # Reset ages\n\n\n            # Aging mechanism: Replace old individuals\n            for i in range(self.pop_size):\n                if self.ages[i] > self.age_limit:\n                     population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim))\n                     fitness[i] = func(population[i])\n                     self.budget -= 1\n                     if self.budget <= 0:\n                         break\n                     self.ages[i] = 0\n                     if fitness[i] < self.f_opt:\n                         self.f_opt = fitness[i]\n                         self.x_opt = population[i]\n\n\n        return self.f_opt, self.x_opt\n\n    def population_diversity(self, population):\n        \"\"\"\n        Calculates the average distance of individuals from the population mean.\n        A low value indicates low diversity.\n        \"\"\"\n        mean_position = np.mean(population, axis=0)\n        distances = np.linalg.norm(population - mean_position, axis=1)\n        return np.mean(distances)", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedDE scored 0.619 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["fc4871ba-aa35-48d0-acfb-702d33f3e949"], "operator": null, "metadata": {"aucs": [0.31547655322725365, 0.7405221013878971, 0.46391439034416093, 0.949227158489818, 0.609258664868541, 0.7068894393308789, 0.6438583685729535, 0.4926080482017332, 0.6009521378100507, 0.28741034985454894, 0.9364439759071415, 0.9959959934269109, 0.4077187544765477, 0.5479520878845705, 0.8185953775162198, 0.7871997229997463, 0.5565518845095074, 0.8920139236804362, 0]}}
{"id": "2975e878-d0ff-4970-af12-4a0fe8b9eed6", "fitness": 0.6483426589342411, "name": "EnhancedDE", "description": "Improved Differential Evolution with a mirrored boundary handling, covariance matrix adaptation scaling factor, and a more robust restart mechanism.", "code": "import numpy as np\n\nclass EnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_initial=0.5, Cr=0.9, diversity_threshold=0.1, restart_probability=0.05, mirror_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_initial = F_initial  # Initial Differential evolution scaling factor\n        self.Cr = Cr  # Crossover rate\n        self.diversity_threshold = diversity_threshold\n        self.restart_probability = restart_probability\n        self.mirror_prob = mirror_prob\n        self.F = self.F_initial  # Dynamic scaling factor\n        self.cov = np.eye(dim)  # Covariance matrix for CMA-ES like F adaptation\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Adaptive F: Adjust scaling factor based on progress using CMA-ES-like adaptation\n                z = np.random.multivariate_normal(np.zeros(self.dim), self.cov)\n                self.F = self.F_initial * np.exp(0.1 * np.linalg.norm(z))\n                self.F = np.clip(self.F, 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n\n                # Mirrored Boundary Handling\n                for j in range(self.dim):\n                    if mutant[j] < func.bounds.lb[j]:\n                        if np.random.rand() < self.mirror_prob:\n                            mutant[j] = func.bounds.lb[j] + (func.bounds.lb[j] - mutant[j])\n                        else:\n                            mutant[j] = np.random.uniform(func.bounds.lb[j], func.bounds.ub[j])\n                    elif mutant[j] > func.bounds.ub[j]:\n                        if np.random.rand() < self.mirror_prob:\n                            mutant[j] = func.bounds.ub[j] - (mutant[j] - func.bounds.ub[j])\n                        else:\n                            mutant[j] = np.random.uniform(func.bounds.lb[j], func.bounds.ub[j])\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        \n                        # Update covariance matrix based on successful step (simplified CMA-ES update)\n                        diff = trial - population[a]\n                        self.cov = (1 - 0.1) * self.cov + 0.1 * np.outer(diff, diff)\n\n            # Diversity Check and Restart (more robust check)\n            if self.population_diversity(population) < self.diversity_threshold and np.random.rand() < self.restart_probability:\n                # Option 1: Restart around the best solution\n                population = np.random.normal(loc=self.x_opt, scale=0.1*(func.bounds.ub[0]-func.bounds.lb[0]), size=(self.pop_size, self.dim)) #Restart around best\n                population = np.clip(population, func.bounds.lb, func.bounds.ub)\n                \n                # Option 2: Full restart\n                # population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size  # Account for new evaluations\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n                self.cov = np.eye(self.dim) #Reset covariance matrix\n\n        return self.f_opt, self.x_opt\n\n    def population_diversity(self, population):\n        \"\"\"\n        Calculates the average distance of individuals from the population mean.\n        A low value indicates low diversity.\n        \"\"\"\n        mean_position = np.mean(population, axis=0)\n        distances = np.linalg.norm(population - mean_position, axis=1)\n        return np.mean(distances)", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedDE scored 0.648 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["fc4871ba-aa35-48d0-acfb-702d33f3e949"], "operator": null, "metadata": {"aucs": [0.28612925492348096, 0.6660661532249874, 0.5221440307813516, 0.9337044822008147, 0.49450017371563126, 0.7149811056432929, 0.6146632293346315, 0.5192411161324018, 0.5920908735190007, 0.5130228327103876, 0.8928019938458056, 0.9977392029311302, 0.5662170246796507, 0.7311937953126695, 0.9336160679815043, 0.7455188899020171, 0.4937793190957517, 0.838929320164527, 0.3793974066897958, 0.5311169058959926]}}
{"id": "6a782bd2-7ea9-4e2c-95ce-2b4e7b1a0a8b", "fitness": 0.29059799813247733, "name": "VelocityAdaptiveOptimizer", "description": "Population-based algorithm with velocity-based movement, adaptive exploration-exploitation balance using a success rate adaptation of exploration radius and a local search around the best solution.", "code": "import numpy as np\n\nclass VelocityAdaptiveOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_velocity=0.1, exploration_radius=0.5, local_search_prob=0.1, local_search_sigma=0.1, success_history_length=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_velocity = initial_velocity\n        self.exploration_radius = exploration_radius\n        self.local_search_prob = local_search_prob\n        self.local_search_sigma = local_search_sigma\n        self.success_history_length = success_history_length\n        self.success_history = []\n        self.velocity = np.full((pop_size, dim), initial_velocity)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Velocity-based movement\n                exploration_vector = np.random.uniform(-self.exploration_radius, self.exploration_radius, size=self.dim)\n                new_position = population[i] + self.velocity[i] * exploration_vector\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Local Search around the best solution\n                if np.random.rand() < self.local_search_prob:\n                    local_search_vector = self.local_search_sigma * np.random.normal(0, 1, size=self.dim)\n                    new_position_local = self.x_opt + local_search_vector\n                    new_position_local = np.clip(new_position_local, func.bounds.lb, func.bounds.ub)\n\n                    f_local = func(new_position_local)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if f_local < fitness[i]:\n                        new_position = new_position_local\n                        \n                # Evaluate the new position\n                f_new = func(new_position)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_new < fitness[i]:\n                    self.success_history.append(1)\n                    population[i] = new_position\n                    fitness[i] = f_new\n\n                    # Update global best\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = new_position\n                else:\n                    self.success_history.append(0)\n\n                # Velocity update (dampen velocity if no improvement)\n                if f_new >= fitness[i]:\n                    self.velocity[i] *= 0.9  # Reduce velocity if no improvement\n                else:\n                    self.velocity[i] = self.initial_velocity # Reset velocity on success\n\n                # Exploration radius adaptation\n                if len(self.success_history) > self.success_history_length:\n                    success_rate = np.mean(self.success_history[-self.success_history_length:])\n                    self.exploration_radius = np.clip(self.exploration_radius * (1 + 0.2 * (success_rate - 0.5)), 0.01, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm VelocityAdaptiveOptimizer scored 0.291 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2b2f1e5c-8669-4e71-834d-91fec98adb89"], "operator": null, "metadata": {"aucs": [0.09917157864625337, 0.17705476047327917, 0.3272968012271492, 0.16432923674221234, 0.16633076991809936, 0.18740598181161705, 0.2032411926226949, 0.15651108587332785, 0.1481181973456701, 0.13853095164291518, 0.2485633779142239, 0.999682683367572, 0.22206805650482686, 0.16006971898971423, 0.6682059509773319, 0.3212678857942679, 0.3167085490049274, 0.5035878078497948, 0.17467322377068284, 0.429142152172987]}}
{"id": "f2d34704-f669-4285-8f7b-a890c100b4b4", "fitness": 0.7187793194869163, "name": "AdaptiveDEwithLocalSearch", "description": "A differential evolution strategy that adapts both scaling factor and crossover rate using a success-history based adaptation and integrates a local search based on a Gaussian perturbation.", "code": "import numpy as np\n\nclass AdaptiveDEwithLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = local_search_prob\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.F = 0.5\n        self.Cr = 0.9\n        self.archive = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history\n                F = np.random.choice(self.F_memory)\n                Cr = np.random.choice(self.Cr_memory)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = trial + np.random.normal(0, 0.05, self.dim)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.archive.append(population[i])\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    self.update_memory(F, Cr)\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt\n\n    def update_memory(self, F, Cr):\n        self.F_memory = np.roll(self.F_memory, 1)\n        self.Cr_memory = np.roll(self.Cr_memory, 1)\n        self.F_memory[0] = F\n        self.Cr_memory[0] = Cr", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDEwithLocalSearch scored 0.719 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["fc4871ba-aa35-48d0-acfb-702d33f3e949"], "operator": null, "metadata": {"aucs": [0.2465883039051585, 0.830144880025685, 0.6691518966832639, 0.9045155590390017, 0.8871452419773482, 0.6869838462635274, 0.8547810487397776, 0.657833572729507, 0.892524338461678, 0.48316380628861066, 0.7728570248056459, 1.0, 0.33492078566647865, 0.8873963582100133, 0.921950853016458, 0.9197169634951676, 0.7661577158981471, 0.9231284681489024, 0.21236808408363372, 0.5242576423003193]}}
{"id": "9db3c5bb-eca8-42a2-9c10-4c648b5d3143", "fitness": -Infinity, "name": "SelfOrganizingDE", "description": "A self-organizing differential evolution that dynamically adjusts population diversity using a clustering-based approach and adaptive parameter control.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass SelfOrganizingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, num_clusters=5, diversity_threshold=0.1, F_adaptive=True, Cr_adaptive=True):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.num_clusters = num_clusters\n        self.diversity_threshold = diversity_threshold\n        self.F_adaptive = F_adaptive\n        self.Cr_adaptive = Cr_adaptive\n        self.archive = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Clustering to assess diversity\n            kmeans = KMeans(n_clusters=self.num_clusters, random_state=0, n_init='auto').fit(population)\n            labels = kmeans.labels_\n            cluster_sizes = np.bincount(labels)\n            diversity = np.std(cluster_sizes) / self.pop_size  # Normalized standard deviation\n\n            # Adjust population diversity if needed\n            if diversity < self.diversity_threshold:\n                # Introduce new random individuals to increase diversity\n                num_new = int(self.pop_size * 0.1)  # Introduce 10% new random individuals\n                new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new, self.dim))\n                new_fitness = np.array([func(x) for x in new_individuals])\n                self.budget -= num_new\n                if self.budget <= 0:\n                    break\n                \n                worst_indices = np.argsort(fitness)[-num_new:]\n                population[worst_indices] = new_individuals\n                fitness[worst_indices] = new_fitness\n            \n\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n\n                # Adaptive F and Cr\n                if self.F_adaptive:\n                    self.F = np.clip(np.random.normal(0.5, 0.3), 0.0, 1.0)\n                if self.Cr_adaptive:\n                    self.Cr = np.clip(np.random.normal(0.9, 0.1), 0.0, 1.0)\n\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occurred: name 'KMeans' is not defined.", "error": "", "parent_ids": ["e4a4e9fa-71b3-46df-af01-aa62688f9049"], "operator": null, "metadata": {}}
{"id": "a27b28ed-83f9-4e56-a451-cc8e97410db2", "fitness": -Infinity, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with a self-adaptive population size and a restart strategy based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_initial=50, F_initial=0.5, Cr_initial=0.9, stagnation_threshold=100, pop_size_adaptation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_initial\n        self.F_initial = F_initial\n        self.Cr_initial = Cr_initial\n        self.stagnation_threshold = stagnation_threshold\n        self.pop_size_adaptation_rate = pop_size_adaptation_rate\n        self.F = self.F_initial\n        self.Cr = self.Cr_initial\n        self.stagnation_counter = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.function_calls = 0  # Track function evaluations\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.function_calls += self.pop_size\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        last_improvement = 0\n\n\n        while self.budget > 0:\n            \n            for i in range(self.pop_size):\n                # Adaptive F and Cr\n                self.F = self.F_initial * np.random.normal(1, 0.1)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.Cr = self.Cr_initial * np.random.normal(1, 0.1)\n                self.Cr = np.clip(self.Cr, 0.1, 1.0)\n                \n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.function_calls += 1\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        last_improvement = self.function_calls\n\n            # Stagnation Check\n            if self.function_calls - last_improvement > self.stagnation_threshold:\n                self.stagnation_counter += 1\n                # Restart strategy: re-initialize population around the best solution\n                population = np.random.normal(self.x_opt, scale=0.1, size=(self.pop_size, self.dim))\n                population = np.clip(population, func.bounds.lb, func.bounds.ub)\n                fitness = np.array([func(x) for x in population])\n                self.function_calls += self.pop_size\n                self.budget -= self.pop_size\n\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                    last_improvement = self.function_calls\n                self.stagnation_counter = 0  # Reset stagnation counter\n                \n                # Adaptive population size\n                if np.random.rand() < 0.5:\n                  self.pop_size = int(self.pop_size * (1 - self.pop_size_adaptation_rate))\n                else:\n                  self.pop_size = int(self.pop_size * (1 + self.pop_size_adaptation_rate))\n                self.pop_size = max(10, min(self.pop_size, 100)) # Limit pop size\n            else:\n                self.stagnation_counter = 0\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occurred: index 48 is out of bounds for axis 0 with size 47.", "error": "", "parent_ids": ["e9b105df-a69f-4f1c-9561-b63ba0486adf"], "operator": null, "metadata": {}}
{"id": "2167151e-2ed8-460b-9e1f-ec0450e7b46b", "fitness": -Infinity, "name": "EnhancedDE", "description": "Enhanced Differential Evolution with orthogonal design for parameter tuning, and a memory-based mutation strategy.", "code": "import numpy as np\nimport smt.sampling_methods as smt\n\nclass EnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_initial=0.5, Cr_initial=0.9, diversity_threshold=0.1, restart_probability=0.05, age_limit=50, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_initial = F_initial  # Initial Differential evolution scaling factor\n        self.Cr_initial = Cr_initial  # Initial Crossover rate\n        self.diversity_threshold = diversity_threshold\n        self.restart_probability = restart_probability\n        self.F = self.F_initial  # Dynamic scaling factor\n        self.Cr = self.Cr_initial  # Dynamic Crossover rate\n        self.age_limit = age_limit\n        self.ages = np.zeros(pop_size, dtype=int)\n        self.memory_size = memory_size\n        self.memory_F = np.ones(memory_size) * self.F_initial\n        self.memory_Cr = np.ones(memory_size) * self.Cr_initial\n        self.memory_idx = 0\n        self.archive = []\n\n        # Orthogonal array for parameter tuning\n        self.sampling = smt.LHS(xlimits=np.array([[0.1, 1.0], [0.1, 1.0]]), criterion='m')\n        self.num_samples = 5\n        self.parameter_samples = self.sampling(self.num_samples)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Parameter tuning using orthogonal design\n                param_idx = generation % self.num_samples\n                self.F = self.parameter_samples[param_idx, 0]\n                self.Cr = self.parameter_samples[param_idx, 1]\n\n                # Memory-based mutation strategy: Select F and Cr from memory\n                idx_F = np.random.randint(0, self.memory_size)\n                idx_Cr = np.random.randint(0, self.memory_size)\n                self.F = self.memory_F[idx_F]\n                self.Cr = self.memory_Cr[idx_Cr]\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n\n                # Incorporate archive information if available\n                if len(self.archive) > 0 and np.random.rand() < 0.1:  # 10% chance to use archive\n                    arc_idx = np.random.randint(0, len(self.archive))\n                    mutant = population[a] + self.F * (self.archive[arc_idx] - population[c])\n                else:\n                     mutant = population[a] + self.F * (population[b] - population[c])\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update memory with successful F and Cr\n                    self.memory_F[self.memory_idx] = self.F\n                    self.memory_Cr[self.memory_idx] = self.Cr\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    self.ages[i] = 0 # Reset age\n\n                    # Add replaced individual to archive\n                    if len(self.archive) < 2 * self.pop_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(0, len(self.archive))\n                        self.archive[idx_to_replace] = population[i].copy()\n                    \n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.ages[i] += 1 # Increment age\n\n            # Diversity Check and Restart\n            if self.population_diversity(population) < self.diversity_threshold and np.random.rand() < self.restart_probability:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size  # Account for new evaluations\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n                self.ages = np.zeros(self.pop_size, dtype=int) # Reset ages\n                self.archive = [] # Clear Archive\n\n\n            # Aging mechanism: Replace old individuals\n            for i in range(self.pop_size):\n                if self.ages[i] > self.age_limit:\n                     population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim))\n                     fitness[i] = func(population[i])\n                     self.budget -= 1\n                     if self.budget <= 0:\n                         break\n                     self.ages[i] = 0\n                     if fitness[i] < self.f_opt:\n                         self.f_opt = fitness[i]\n                         self.x_opt = population[i]\n\n\n        return self.f_opt, self.x_opt\n\n    def population_diversity(self, population):\n        \"\"\"\n        Calculates the average distance of individuals from the population mean.\n        A low value indicates low diversity.\n        \"\"\"\n        mean_position = np.mean(population, axis=0)\n        distances = np.linalg.norm(population - mean_position, axis=1)\n        return np.mean(distances)", "configspace": "", "generation": 4, "feedback": "An exception occurred: No module named 'smt'.", "error": "", "parent_ids": ["e9b105df-a69f-4f1c-9561-b63ba0486adf"], "operator": null, "metadata": {}}
{"id": "de63f38c-ea43-4d0e-afaf-9cd8563138f6", "fitness": -Infinity, "name": "EnhancedDE", "description": "Enhanced Differential Evolution with orthogonal design for parameter tuning and a local search based on adaptive step size.", "code": "import numpy as np\nfrom scipy.stats import norm\n\nclass EnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_initial=0.5, Cr_initial=0.9, diversity_threshold=0.1, restart_probability=0.05, age_limit=50, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_initial = F_initial  # Initial Differential evolution scaling factor\n        self.Cr_initial = Cr_initial  # Initial Crossover rate\n        self.diversity_threshold = diversity_threshold\n        self.restart_probability = restart_probability\n        self.F = self.F_initial  # Dynamic scaling factor\n        self.Cr = self.Cr_initial  # Dynamic Crossover rate\n        self.age_limit = age_limit\n        self.ages = np.zeros(pop_size, dtype=int)\n        self.local_search_probability = local_search_probability\n        self.ls_step_size = 0.1  # Initial step size for local search\n\n        # Orthogonal Design for F and Cr (simplified - can be extended for more parameters)\n        self.orthogonal_design = np.array([[0.3, 0.7], [0.7, 0.3]])  # Example L4 design\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Orthogonal Design Parameter Tuning\n                design_index = generation % len(self.orthogonal_design)\n                F = self.orthogonal_design[design_index][0]\n                Cr = self.orthogonal_design[design_index][1]\n\n                F = self.F_initial * np.exp(np.random.normal(0, 0.1)) * (1 - self.ages[i] / self.age_limit) # Age reduces F\n                F = np.clip(F, 0.1, 1.0)\n                \n                Cr = self.Cr_initial * np.exp(np.random.normal(0, 0.1)) * (1 - self.ages[i] / self.age_limit) # Age reduces Cr\n                Cr = np.clip(Cr, 0.1, 1.0)\n                \n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    self.ages[i] = 0 # Reset age\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.ls_step_size = min(0.1, self.ls_step_size * 1.1) # Increase step size if improvement is found\n                else:\n                    self.ages[i] += 1 # Increment age\n                    self.ls_step_size = max(0.0001, self.ls_step_size * 0.9) # Decrease step size if no improvement\n\n                # Local Search\n                if np.random.rand() < self.local_search_probability:\n                    trial_ls = np.copy(population[i])\n                    for d in range(self.dim):\n                        # Gaussian perturbation with adaptive step size\n                        trial_ls[d] += np.random.normal(0, self.ls_step_size)\n                        trial_ls[d] = np.clip(trial_ls[d], func.bounds.lb, func.bounds.ub)\n\n                    f_trial_ls = func(trial_ls)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if f_trial_ls < fitness[i]:\n                        population[i] = trial_ls\n                        fitness[i] = f_trial_ls\n                        self.ages[i] = 0\n                        if f_trial_ls < self.f_opt:\n                            self.f_opt = f_trial_ls\n                            self.x_opt = trial_ls\n                            self.ls_step_size = min(0.1, self.ls_step_size * 1.1)  # Increase step size if improvement is found\n                    else:\n                         self.ls_step_size = max(0.0001, self.ls_step_size * 0.9)   # Decrease step size if no improvement\n\n\n            # Diversity Check and Restart\n            if self.population_diversity(population) < self.diversity_threshold and np.random.rand() < self.restart_probability:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size  # Account for new evaluations\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n                self.ages = np.zeros(self.pop_size, dtype=int) # Reset ages\n                self.ls_step_size = 0.1 # Reset local search step size\n\n            # Aging mechanism: Replace old individuals\n            for i in range(self.pop_size):\n                if self.ages[i] > self.age_limit:\n                     population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim))\n                     fitness[i] = func(population[i])\n                     self.budget -= 1\n                     if self.budget <= 0:\n                         break\n                     self.ages[i] = 0\n                     if fitness[i] < self.f_opt:\n                         self.f_opt = fitness[i]\n                         self.x_opt = population[i]\n                     self.ls_step_size = 0.1 # Reset local search step size\n\n\n        return self.f_opt, self.x_opt\n\n    def population_diversity(self, population):\n        \"\"\"\n        Calculates the average distance of individuals from the population mean.\n        A low value indicates low diversity.\n        \"\"\"\n        mean_position = np.mean(population, axis=0)\n        distances = np.linalg.norm(population - mean_position, axis=1)\n        return np.mean(distances)", "configspace": "", "generation": 4, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["e9b105df-a69f-4f1c-9561-b63ba0486adf"], "operator": null, "metadata": {}}
{"id": "05f04814-dc2d-41f8-b19f-721b111a8134", "fitness": -Infinity, "name": "EnhancedDE", "description": "Enhanced Differential Evolution with a mirrored boundary handling, covariance matrix adaptation scaling factor, a more robust restart mechanism, and adaptive population size.", "code": "import numpy as np\n\nclass EnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size_initial=20, F_initial=0.5, Cr=0.9, diversity_threshold=0.1, restart_probability=0.05, mirror_prob=0.1, pop_size_adapt_freq=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_initial = pop_size_initial\n        self.pop_size = pop_size_initial  # Initial population size\n        self.F_initial = F_initial  # Initial Differential evolution scaling factor\n        self.Cr = Cr  # Crossover rate\n        self.diversity_threshold = diversity_threshold\n        self.restart_probability = restart_probability\n        self.mirror_prob = mirror_prob\n        self.F = self.F_initial  # Dynamic scaling factor\n        self.cov = np.eye(dim)  # Covariance matrix for CMA-ES like F adaptation\n        self.pop_size_adapt_freq = pop_size_adapt_freq\n        self.success_history = [] #Keeps track of successful F and Cr values\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            #Adapt population size every few generations\n            if generation % self.pop_size_adapt_freq == 0:\n                self.adapt_pop_size(fitness)\n\n            for i in range(self.pop_size):\n                # Adaptive F: Adjust scaling factor based on progress using CMA-ES-like adaptation\n                z = np.random.multivariate_normal(np.zeros(self.dim), self.cov)\n                self.F = self.F_initial * np.exp(0.1 * np.linalg.norm(z))\n                self.F = np.clip(self.F, 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n\n                # Mirrored Boundary Handling\n                for j in range(self.dim):\n                    if mutant[j] < func.bounds.lb[j]:\n                        if np.random.rand() < self.mirror_prob:\n                            mutant[j] = func.bounds.lb[j] + (func.bounds.lb[j] - mutant[j])\n                        else:\n                            mutant[j] = np.random.uniform(func.bounds.lb[j], func.bounds.ub[j])\n                    elif mutant[j] > func.bounds.ub[j]:\n                        if np.random.rand() < self.mirror_prob:\n                            mutant[j] = func.bounds.ub[j] - (mutant[j] - func.bounds.ub[j])\n                        else:\n                            mutant[j] = np.random.uniform(func.bounds.lb[j], func.bounds.ub[j])\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    \n                    #Update successful F and Cr values\n                    self.success_history.append((self.F, self.Cr))\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        \n                        # Update covariance matrix based on successful step (simplified CMA-ES update)\n                        diff = trial - population[a]\n                        self.cov = (1 - 0.1) * self.cov + 0.1 * np.outer(diff, diff)\n\n            # Diversity Check and Restart (more robust check)\n            if self.population_diversity(population) < self.diversity_threshold and np.random.rand() < self.restart_probability:\n                # Option 1: Restart around the best solution\n                population = np.random.normal(loc=self.x_opt, scale=0.1*(func.bounds.ub[0]-func.bounds.lb[0]), size=(self.pop_size, self.dim)) #Restart around best\n                population = np.clip(population, func.bounds.lb, func.bounds.ub)\n                \n                # Option 2: Full restart\n                # population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size  # Account for new evaluations\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n                self.cov = np.eye(self.dim) #Reset covariance matrix\n                self.success_history = [] #Clear success history\n\n        return self.f_opt, self.x_opt\n\n    def population_diversity(self, population):\n        \"\"\"\n        Calculates the average distance of individuals from the population mean.\n        A low value indicates low diversity.\n        \"\"\"\n        mean_position = np.mean(population, axis=0)\n        distances = np.linalg.norm(population - mean_position, axis=1)\n        return np.mean(distances)\n    \n    def adapt_pop_size(self, fitness):\n        \"\"\"\n        Adapts the population size based on the performance.\n        If improvement is stagnating, increase pop size, else decrease.\n        \"\"\"\n        \n        if len(self.success_history) > 5 and len(set(self.success_history[-5:])) <= 1: #Stagnation detected\n            self.pop_size = int(min(self.pop_size * 1.2, self.budget / 2)) #Increase pop size, but ensure it remains feasible\n        else:\n            self.pop_size = int(max(self.pop_size * 0.9, 10)) #Decrease pop size gradually\n            \n        #Resize the population if necessary\n        if self.pop_size != len(fitness):\n            \n            if self.pop_size > len(fitness):\n                #Add new random individuals\n                num_new = self.pop_size - len(fitness)\n                new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new, self.dim))\n                new_fitness = np.array([func(x) for x in new_population])\n                self.budget -= num_new\n                \n                population = np.concatenate([population, new_population])\n                fitness = np.concatenate([fitness, new_fitness])\n                \n            else:\n                #Remove the worst individuals\n                indices_to_remove = np.argsort(fitness)[self.pop_size:]\n                population = np.delete(population, indices_to_remove, axis=0)\n                fitness = np.delete(fitness, indices_to_remove)\n                \n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n            \n            print(f\"Population size adapted to {self.pop_size}\")", "configspace": "", "generation": 4, "feedback": "An exception occurred: local variable 'population' referenced before assignment.", "error": "", "parent_ids": ["2975e878-d0ff-4970-af12-4a0fe8b9eed6"], "operator": null, "metadata": {}}
{"id": "0015b48e-79ce-4058-a721-e93b6126b181", "fitness": 0.7030587599524206, "name": "OrthogonalDE", "description": "DE with orthogonal learning to enhance population diversity and convergence speed, while employing a Cauchy mutation to escape local optima.", "code": "import numpy as np\n\nclass OrthogonalDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, orthogonal_components=5, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution scaling factor\n        self.Cr = Cr  # Crossover rate\n        self.orthogonal_components = orthogonal_components\n        self.cauchy_scale = cauchy_scale\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Orthogonal Learning: Sample around the trial vector\n                orthogonal_sample = self.orthogonal_sampling(trial, func.bounds.lb, func.bounds.ub)\n\n                # Cauchy Mutation (occasionally)\n                if np.random.rand() < 0.1:\n                    trial += self.cauchy_mutation(self.dim, self.cauchy_scale, func.bounds.lb, func.bounds.ub)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                f_orthogonal = func(orthogonal_sample)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i] and f_trial <= f_orthogonal:\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                elif f_orthogonal < fitness[i] and f_orthogonal < f_trial:\n                    population[i] = orthogonal_sample\n                    fitness[i] = f_orthogonal\n                    if f_orthogonal < self.f_opt:\n                        self.f_opt = f_orthogonal\n                        self.x_opt = orthogonal_sample\n\n\n        return self.f_opt, self.x_opt\n\n    def orthogonal_sampling(self, x, lb, ub):\n        \"\"\"\n        Samples around the given vector x using orthogonal components.\n        \"\"\"\n        sample = np.copy(x)\n        for _ in range(self.orthogonal_components):\n            direction = np.random.normal(0, 1, size=self.dim)\n            direction /= np.linalg.norm(direction)  # Normalize\n            step_size = np.random.uniform(-0.1, 0.1)  # Small step\n            new_sample = x + step_size * direction\n            new_sample = np.clip(new_sample, lb, ub)  # Keep in bounds\n            sample = new_sample # Directly replace, aiming for quick orthogonal learning.\n        return sample\n\n    def cauchy_mutation(self, dim, scale, lb, ub):\n        \"\"\"\n        Applies Cauchy mutation.\n        \"\"\"\n        mutation = np.random.standard_cauchy(size=dim) * scale\n        mutation = np.clip(mutation, lb-5, ub+5) # Bound large values to avoid numerical problems.\n        return mutation", "configspace": "", "generation": 4, "feedback": "The algorithm OrthogonalDE scored 0.703 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e9b105df-a69f-4f1c-9561-b63ba0486adf"], "operator": null, "metadata": {"aucs": [0.3730020601231949, 0.43089887733655796, 0.6329799387788115, 0.883906144515407, 0.8238433079800731, 0.8352282558205247, 0.6070722416774799, 0.7506626408339452, 0.8137321875123114, 0.7275507524005145, 0.911479658760125, 0.9986421617625031, 0.3833891010080839, 0.8014906297744446, 0.8468178176667628, 0.8549201659425847, 0.6996531144192301, 0.8920065078724773, 0.2618554526267688, 0.5320441822366128]}}
{"id": "aae034fb-c188-4dc5-a023-fb589031ecd3", "fitness": 0.5670886214453402, "name": "CMAES_DE", "description": "An adaptive Differential Evolution with a covariance matrix adaptation (CMA) inspired mutation and selection strategy.", "code": "import numpy as np\n\nclass CMAES_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, local_search_prob=0.05, cma_lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = local_search_prob\n        self.cma_lr = cma_lr  # Learning rate for CMA update\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.mean = None\n        self.C = None # Covariance Matrix\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def __call__(self, func):\n        # Initialize population\n        if self.mean is None:\n            self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        if self.C is None:\n            self.C = np.eye(self.dim)  # Identity matrix\n\n        population = np.random.multivariate_normal(self.mean, self.C, size=self.pop_size)\n        population = np.clip(population, func.bounds.lb, func.bounds.ub)\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            old_population = np.copy(population)\n            old_fitness = np.copy(fitness)\n\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history\n                F = np.random.choice(self.F_memory)\n                Cr = np.random.choice(self.Cr_memory)\n\n                # Differential Evolution Mutation with CMA-inspired adaptation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = trial + np.random.normal(0, 0.05, self.dim)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.archive.append(population[i])\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    self.update_memory(F, Cr)\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # CMA-ES like update of mean and covariance matrix\n            if len(self.archive) > 0:\n\n                delta_x = population[np.argmin(fitness)] - self.mean\n                self.mean = population[np.argmin(fitness)]\n                self.C = (1 - self.cma_lr) * self.C + self.cma_lr * np.outer(delta_x, delta_x)\n\n\n        return self.f_opt, self.x_opt\n\n    def update_memory(self, F, Cr):\n        self.F_memory = np.roll(self.F_memory, 1)\n        self.Cr_memory = np.roll(self.Cr_memory, 1)\n        self.F_memory[0] = F\n        self.Cr_memory[0] = Cr", "configspace": "", "generation": 4, "feedback": "The algorithm CMAES_DE scored 0.567 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f2d34704-f669-4285-8f7b-a890c100b4b4"], "operator": null, "metadata": {"aucs": [0.17892182262528245, 0.1987665649284006, 0.7066861576714816, 0.17938820467574645, 0.26018106794179297, 0.8150138711341784, 0.7777134186646839, 0.4155067406514875, 0.895349289943223, 0.2165768912984165, 0.34402627568602584, 0.9941462301898791, 0.428984521734323, 0.8545076394956382, 0.49278592164992174, 0.9207426568078831, 0.4195847299956329, 0.8527565615860109, 0.7319870040934398, 0.6581468581333553]}}
{"id": "90f93079-b926-4135-a5ba-6ecc91396e7e", "fitness": 0.6368649461662137, "name": "AdaptiveNeighborhoodDE", "description": "Adaptive Neighborhood DE with stochastic ranking to balance exploration and exploitation in the neighborhood search.", "code": "import numpy as np\n\nclass AdaptiveNeighborhoodDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, neighborhood_size=3, initial_exploration_rate=0.2, exploration_decay=0.995, velocity_clamping=2.0, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.neighborhood_size = neighborhood_size\n        self.initial_exploration_rate = initial_exploration_rate\n        self.exploration_rate = initial_exploration_rate\n        self.exploration_decay = exploration_decay\n        self.velocity_clamping = velocity_clamping\n        self.archive_size = archive_size\n        self.archive = []\n        self.archive_fitness = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Sort population based on fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            for i in range(self.pop_size):\n                # Neighborhood selection\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood = population[neighborhood_indices]\n\n                # Select best individuals from neighborhood\n                best_index = np.argmin(fitness[neighborhood_indices])\n                best_neighbor = neighborhood[best_index]\n\n                # Differential Evolution with neighborhood information and exploration rate\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n\n                # Apply exploration rate\n                if np.random.rand() < self.exploration_rate:\n                    mutant = population[i] + self.F * (population[a] - population[b])\n                else:\n                    mutant = population[i] + self.F * (best_neighbor - population[i]) + self.F * (population[a] - population[b])\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n                \n                # Velocity Clamping\n                velocity = trial - population[i]\n                norm = np.linalg.norm(velocity)\n                if norm > self.velocity_clamping:\n                  velocity = velocity * (self.velocity_clamping / norm)\n                  trial = population[i] + velocity\n                  trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Stochastic Ranking\n                p_rank = 0.45  # Probability of ranking based on fitness\n                if np.random.rand() < p_rank or (fitness[i] <= self.f_opt and f_trial <= self.f_opt) or (fitness[i] > self.f_opt and f_trial > self.f_opt):\n                    if f_trial < fitness[i]:\n                        population[i] = trial\n                        fitness[i] = f_trial\n\n                        # Update global best\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                     if np.random.rand() < 0.5:\n                         population[i] = trial\n                         fitness[i] = f_trial\n\n            \n            # Decay exploration rate\n            self.exploration_rate *= self.exploration_decay\n            self.exploration_rate = max(self.exploration_rate, 0.01)  # Ensure minimum exploration\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveNeighborhoodDE scored 0.637 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e4a4e9fa-71b3-46df-af01-aa62688f9049"], "operator": null, "metadata": {"aucs": [0.189734952985658, 0.4011294549173785, 0.7122058797725681, 0.8542061560882559, 0.8396825647339767, 0.6571426871480298, 0.5868039285865349, 0.8258355774313892, 0.8814999418706957, 0.18973260731312047, 0.9271183159638154, 0.9994792867692205, 0.4386755225841098, 0.7356355067944447, 0.744280527275117, 0.6372048233061403, 0.5200943475472322, 0.9263802194033812, 0.1730873918664303, 0.49736923096677654]}}
{"id": "c9d32af6-1abf-4ecc-a04b-f33a00f6337d", "fitness": 0.8048809921471932, "name": "AdaptiveDEwithLocalSearch2", "description": "Adaptive Differential Evolution with a larger archive, covariance matrix adaptation for local search, and improved parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveDEwithLocalSearch2:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, local_search_prob=0.1, archive_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = local_search_prob\n        self.archive_size = archive_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.F = 0.5\n        self.Cr = 0.9\n        self.CMA_sigma = 0.1  # Initial step size for CMA\n        self.CMA_C = 0.1     # Learning rate for covariance matrix\n        self.CMA_d = 1       # Damping factor for step size\n        self.CMA_mu = pop_size // 4  # Number of selected parents\n        self.CMA_weights = np.log(self.CMA_mu + 0.5) - np.log(np.arange(1, self.CMA_mu + 1))\n        self.CMA_weights /= np.sum(self.CMA_weights)\n        self.CMA_B = np.eye(dim)  # Eigenvectors of covariance matrix\n        self.CMA_D = np.ones(dim) # Eigenvalues of covariance matrix\n        self.CMA_C_mu = 0          # Cumulation for mean\n        self.CMA_C_sigma = 0       # Cumulation for step size\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history\n                F = np.random.choice(self.F_memory)\n                Cr = np.random.choice(self.Cr_memory)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search with CMA-ES\n                if np.random.rand() < self.local_search_prob:\n                    z = np.random.normal(0, 1, self.dim)\n                    trial = trial + self.CMA_sigma * (self.CMA_B @ (self.CMA_D * z))\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.archive.append(population[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    # Update CMA parameters based on successful step\n                    delta = trial - population[i]\n                    self.CMA_C_mu = (1 - self.CMA_C) * self.CMA_C_mu + np.sqrt(self.CMA_C * (2 - self.CMA_C)) * delta / self.CMA_sigma\n                    self.CMA_sigma *= np.exp(self.CMA_C / self.CMA_d * (np.linalg.norm(self.CMA_C_mu) / np.sqrt(self.dim) - 1))\n                    \n                    population[i] = trial\n                    fitness[i] = f_trial\n                    self.update_memory(F, Cr, (fitness[i]-f_trial))  #incorporate fitness change to update_memory\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n        \n        return self.f_opt, self.x_opt\n\n    def update_memory(self, F, Cr, fitness_diff):\n        self.F_memory = np.roll(self.F_memory, 1)\n        self.Cr_memory = np.roll(self.Cr_memory, 1)\n        self.F_memory[0] = F\n        self.Cr_memory[0] = Cr\n        #You can add additional logic based on fitness_diff to adjust F and Cr memory.\n        #For example, if fitness improved a lot, increase the corresponding Cr value.\n", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDEwithLocalSearch2 scored 0.805 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f2d34704-f669-4285-8f7b-a890c100b4b4"], "operator": null, "metadata": {"aucs": [0.5135177244819842, 0.839654738494026, 0.86374366911356, 0.9419082763346016, 0.8851580385540089, 0.9013929834057418, 0.8439771640935803, 0.8455199861496573, 0.8816536297268915, 0.886467978910945, 0.9045157597478304, 0.9962702860064709, 0.4844954083279611, 0.8826551927320553, 0.9005047548069912, 0.9000366252749383, 0.8372011610621919, 0.9150947206936646, 0.36255058065024115, 0.5113011643765224]}}
{"id": "efd1cc97-cbb0-4f71-971c-fb1192fcf969", "fitness": 0.5293045975315678, "name": "EnhancedDE", "description": "Enhanced DE with adaptive F and Cr, mirrored boundary handling, CMA-ES-like covariance adaptation, and orthogonal initialization with periodic restart.", "code": "import numpy as np\n\nclass EnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_initial=0.5, Cr_initial=0.9, diversity_threshold=0.1, restart_probability=0.05, mirror_prob=0.1, cma_learning_rate = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_initial = F_initial  # Initial Differential evolution scaling factor\n        self.Cr_initial = Cr_initial  # Initial Crossover rate\n        self.Cr = Cr_initial\n        self.diversity_threshold = diversity_threshold\n        self.restart_probability = restart_probability\n        self.mirror_prob = mirror_prob\n        self.F = self.F_initial  # Dynamic scaling factor\n        self.cov = np.eye(dim)  # Covariance matrix for CMA-ES like F adaptation\n        self.cma_learning_rate = cma_learning_rate\n        self.generation = 0\n\n    def __call__(self, func):\n        # Orthogonal initialization\n        population = self.orthogonal_initialization(func)\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            self.generation += 1\n\n            # Adaptive Cr\n            self.Cr = self.Cr_initial * np.exp(-self.generation / (self.budget / (2 * self.pop_size)))  # Decay Cr over time\n\n            for i in range(self.pop_size):\n                # Adaptive F: Adjust scaling factor based on progress using CMA-ES-like adaptation\n                z = np.random.multivariate_normal(np.zeros(self.dim), self.cov)\n                self.F = self.F_initial * np.exp(0.1 * np.linalg.norm(z))\n                self.F = np.clip(self.F, 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n\n                # Mirrored Boundary Handling\n                for j in range(self.dim):\n                    if mutant[j] < func.bounds.lb[j]:\n                        if np.random.rand() < self.mirror_prob:\n                            mutant[j] = func.bounds.lb[j] + (func.bounds.lb[j] - mutant[j])\n                        else:\n                            mutant[j] = np.random.uniform(func.bounds.lb[j], func.bounds.ub[j])\n                    elif mutant[j] > func.bounds.ub[j]:\n                        if np.random.rand() < self.mirror_prob:\n                            mutant[j] = func.bounds.ub[j] - (mutant[j] - func.bounds.ub[j])\n                        else:\n                            mutant[j] = np.random.uniform(func.bounds.lb[j], func.bounds.ub[j])\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                        # Update covariance matrix based on successful step (simplified CMA-ES update)\n                        diff = trial - population[a]\n                        self.cov = (1 - self.cma_learning_rate) * self.cov + self.cma_learning_rate * np.outer(diff, diff)\n\n            # Diversity Check and Restart (more robust check)\n            if self.population_diversity(population) < self.diversity_threshold or self.generation % 100 == 0:\n                if np.random.rand() < self.restart_probability or self.generation % 100 == 0: #Periodic restart\n                    # Option 1: Restart around the best solution\n                    population = np.random.normal(loc=self.x_opt, scale=0.1*(func.bounds.ub[0]-func.bounds.lb[0]), size=(self.pop_size, self.dim)) #Restart around best\n                    population = np.clip(population, func.bounds.lb, func.bounds.ub)\n                \n                    # Option 2: Full restart\n                    # population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n\n                    fitness = np.array([func(x) for x in population])\n                    self.budget -= self.pop_size  # Account for new evaluations\n                    self.f_opt = np.min(fitness)\n                    self.x_opt = population[np.argmin(fitness)]\n                    self.cov = np.eye(self.dim) #Reset covariance matrix\n\n        return self.f_opt, self.x_opt\n\n    def population_diversity(self, population):\n        \"\"\"\n        Calculates the average distance of individuals from the population mean.\n        A low value indicates low diversity.\n        \"\"\"\n        mean_position = np.mean(population, axis=0)\n        distances = np.linalg.norm(population - mean_position, axis=1)\n        return np.mean(distances)\n\n    def orthogonal_initialization(self, func):\n        \"\"\"\n        Initializes the population using an orthogonal design.\n        \"\"\"\n        from scipy.stats import qmc\n        sampler = qmc.LatinHypercube(d=self.dim)\n        sample = sampler.random(n=self.pop_size)\n        population = func.bounds.lb + sample * (func.bounds.ub - func.bounds.lb)\n        return population", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedDE scored 0.529 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2975e878-d0ff-4970-af12-4a0fe8b9eed6"], "operator": null, "metadata": {"aucs": [0.18789278536028864, 0.3354034353059353, 0.4276924180090912, 0.9348728620045413, 0.4900109633526356, 0.49893101429907205, 0.4175782926320557, 0.40654825462300836, 0.5919409285290743, 0.2627818817953256, 0.9050410655715105, 0.9969399310261122, 0.3047713297002459, 0.46990074360708, 0.8006197572284101, 0.6316392910708883, 0.47704518894666037, 0.6973692996145897, 0.2337647668926608, 0.5153477410621718]}}
{"id": "ef7c79af-7d1c-40d3-a936-bc41f2718aee", "fitness": 0.6220682843839461, "name": "AdaptiveNeighborhoodDE", "description": "Neighborhood-based Differential Evolution with adaptive F and Cr, tournament selection, and a learning rate for the exploration decay.", "code": "import numpy as np\n\nclass AdaptiveNeighborhoodDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, neighborhood_size=3, initial_exploration_rate=0.2, exploration_decay=0.995, velocity_clamping=2.0, decay_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.neighborhood_size = neighborhood_size\n        self.initial_exploration_rate = initial_exploration_rate\n        self.exploration_rate = initial_exploration_rate\n        self.exploration_decay = exploration_decay\n        self.velocity_clamping = velocity_clamping\n        self.decay_learning_rate = decay_learning_rate\n\n        self.archive_F = []\n        self.archive_Cr = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Sort population based on fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            for i in range(self.pop_size):\n                # Neighborhood selection\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood = population[neighborhood_indices]\n\n                # Select best individuals from neighborhood\n                best_index = np.argmin(fitness[neighborhood_indices])\n                best_neighbor = neighborhood[best_index]\n\n                # Adaptive F and Cr\n                if self.archive_F and self.archive_Cr:\n                    self.F = np.random.choice(self.archive_F)\n                    self.Cr = np.random.choice(self.archive_Cr)\n                else:\n                    self.F = np.random.normal(0.5, 0.1)\n                    self.Cr = np.random.normal(0.9, 0.1)\n                    self.F = np.clip(self.F, 0.1, 1.0)\n                    self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n                # Differential Evolution with neighborhood information and exploration rate\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n\n                # Apply exploration rate\n                if np.random.rand() < self.exploration_rate:\n                    mutant = population[i] + self.F * (population[a] - population[b])\n                else:\n                    mutant = population[i] + self.F * (best_neighbor - population[i]) + self.F * (population[a] - population[b])\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n                \n                # Velocity Clamping\n                velocity = trial - population[i]\n                norm = np.linalg.norm(velocity)\n                if norm > self.velocity_clamping:\n                  velocity = velocity * (self.velocity_clamping / norm)\n                  trial = population[i] + velocity\n                  trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Tournament selection\n                if f_trial < fitness[i]:\n                    new_population[i] = trial\n                    new_fitness[i] = f_trial\n                    self.archive_F.append(self.F)\n                    self.archive_Cr.append(self.Cr)\n                    if len(self.archive_F) > 100:\n                        self.archive_F.pop(0)\n                        self.archive_Cr.pop(0)\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n            \n            population = new_population\n            fitness = new_fitness\n\n            # Decay exploration rate with learning rate\n            self.exploration_decay *= (1 - self.decay_learning_rate * (1 - (self.exploration_rate / self.initial_exploration_rate)))\n            self.exploration_rate *= self.exploration_decay\n            self.exploration_rate = max(self.exploration_rate, 0.01)  # Ensure minimum exploration\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveNeighborhoodDE scored 0.622 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e4a4e9fa-71b3-46df-af01-aa62688f9049"], "operator": null, "metadata": {"aucs": [0.14269413525876518, 0.38873890488647367, 0.34725883426232307, 0.8683477702707746, 0.8410724527129718, 0.9019303728574646, 0.7328109552292985, 0.35873661949084923, 0.7607370529035309, 0.20463319847817285, 0.9230578077926923, 0.9931485664793287, 0.5240771021686159, 0.24452910074668632, 0.9531392055816571, 0.8228239799566301, 0.8069795524080707, 0.9203349587989907, 0.19494790941797868, 0.511367207977648]}}
{"id": "1874f8b0-f072-49bd-916e-75c2eb3386b0", "fitness": 0.7430735808989226, "name": "AdaptiveDEwithLocalSearch2", "description": "Adaptive Differential Evolution with Local Search, Archive, and Improved Parameter Adaptation using weighted averages based on fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveDEwithLocalSearch2:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, local_search_prob=0.1, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = local_search_prob\n        self.archive_size = archive_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.archive_fitness = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history - weighted average\n                weights = np.abs(np.random.randn(self.memory_size))\n                weights /= weights.sum()\n                F = np.sum(self.F_memory * weights)\n                Cr = np.sum(self.Cr_memory * weights)\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n                \n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n\n                # Add archive component to mutation\n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += F * (self.archive[arc_idx] - population[i]) * 0.1  # Scale down the archive influence\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = trial + np.random.normal(0, 0.05, self.dim)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        worst_archive_idx = np.argmax(self.archive_fitness)\n                        if fitness[i] < self.archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = population[i]\n                            self.archive_fitness[worst_archive_idx] = fitness[i]\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    self.update_memory(F, Cr, fitness[i] - fitness[i]) # send zero change to update memory\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.update_memory(F, Cr, 0) # zero change in fitness if not updated\n\n        return self.f_opt, self.x_opt\n\n    def update_memory(self, F, Cr, delta_fitness):\n        self.F_memory = np.roll(self.F_memory, 1)\n        self.Cr_memory = np.roll(self.Cr_memory, 1)\n        self.F_memory[0] = F\n        self.Cr_memory[0] = Cr", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDEwithLocalSearch2 scored 0.743 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f2d34704-f669-4285-8f7b-a890c100b4b4"], "operator": null, "metadata": {"aucs": [0.4177653616386868, 0.8770792831879387, 0.8328737423555854, 0.9377501790487305, 0.8936452852067862, 0.906770493915785, 0.7976593090998164, 0.8541007402821387, 0.9063824411825361, 0.4273789682752722, 0.9382217967027936, 0.9951503792173199, 0.6266395925124058, 0.47852127871029604, 0.588526369125153, 0.9151082702185381, 0.756046650153181, 0.9295797560778845, 0.26675866928057246, 0.5155130517870313]}}
{"id": "41cee4a3-7ed7-46f9-9edf-77fa40315bab", "fitness": -Infinity, "name": "DynNbrAdaptiveDE", "description": "A Differential Evolution strategy with dynamically adjusted neighborhood size based on population diversity and a self-adaptive mutation factor.", "code": "import numpy as np\n\nclass DynNbrAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_init=0.5, Cr=0.9, neighborhood_size_init=5, neighborhood_size_min=2, neighborhood_size_max=10, exploration_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_init = F_init\n        self.Cr = Cr\n        self.neighborhood_size_init = neighborhood_size_init\n        self.neighborhood_size = neighborhood_size_init\n        self.neighborhood_size_min = neighborhood_size_min\n        self.neighborhood_size_max = neighborhood_size_max\n        self.exploration_prob = exploration_prob\n\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            # Adjust neighborhood size based on population diversity\n            if generation % 10 == 0:\n                diversity = np.std(population)\n                # Dynamically adjust neighborhood size\n                self.neighborhood_size = int(self.neighborhood_size_init * (1 - diversity))\n                self.neighborhood_size = np.clip(self.neighborhood_size, self.neighborhood_size_min, self.neighborhood_size_max)\n\n\n            for i in range(self.pop_size):\n                # Neighborhood selection\n                idxs = np.arange(self.pop_size)\n                np.random.shuffle(idxs)\n                neighborhood_indices = idxs[:self.neighborhood_size]\n                neighborhood = population[neighborhood_indices]\n                \n                # Select random individuals from neighborhood\n                a, b, c = np.random.choice(neighborhood_indices, 3, replace=False)\n\n                # Self-adaptive mutation factor F\n                F = self.F_init * np.exp(np.random.normal(0, 0.1))\n                F = np.clip(F, 0.0, 1.0)\n                \n                # Exploration Strategy with probability exploration_prob\n                if np.random.rand() < self.exploration_prob:\n                    mutant = population[i] + F * (population[a] - population[b]) #original\n                else:\n                    mutant = population[i] + F * (population[a] - population[b]) + F * (population[c] - population[i])\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occurred: Cannot take a larger sample than population when 'replace=False'.", "error": "", "parent_ids": ["90f93079-b926-4135-a5ba-6ecc91396e7e"], "operator": null, "metadata": {}}
{"id": "6bcb8a5c-d38b-4cbf-8188-6c3046a90c6c", "fitness": -Infinity, "name": "AdaptiveDEwithRepulsiveArchiveAndCMAES", "description": "Adaptive Differential Evolution with a repulsive archive, local search using CMA-ES, and adaptive population size reduction.", "code": "import numpy as np\nimport cma\n\nclass AdaptiveDEwithRepulsiveArchiveAndCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, local_search_prob=0.1, cmaes_sigma=0.1, reduction_factor=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.local_search_prob = local_search_prob\n        self.cmaes_sigma = cmaes_sigma\n        self.reduction_factor = reduction_factor\n        self.archive = []\n        self.archive_fitness = []\n        self.population_size = pop_size # dynamic population size\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                F = np.random.uniform(0.1, 1.0)\n                mutant = population[a] + F * (population[b] - population[c])\n\n                # Repulsive Archive component.  Push away from bad solutions\n                if len(self.archive) > 0:\n                    distances = np.linalg.norm(self.archive - population[i], axis=1)\n                    closest_archive_idx = np.argmin(distances)\n                    mutant -= 0.1 * (self.archive[closest_archive_idx] - population[i]) # Repulsion force\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                Cr = np.random.uniform(0.1, 1.0)\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search using CMA-ES\n                if np.random.rand() < self.local_search_prob:\n                    es = cma.CMAEvolutionStrategy(trial, self.cmaes_sigma,\n                                                  {'bounds': [func.bounds.lb, func.bounds.ub],\n                                                   'verbose': -9})  # Suppress output\n                    \n                    x_local = es.ask(1)[0]\n                    f_local = func(x_local)\n                    self.budget -= 1\n\n                    if f_local < func(trial) and self.budget > 0:  #Evaluate only if within budget\n                        trial = x_local\n                        \n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                    \n                    #Replace individual\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    \n                # Archive update (Repulsive archive - store bad solutions)\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(population[i])\n                    self.archive_fitness.append(fitness[i])\n                else:\n                    best_archive_idx = np.argmin(self.archive_fitness) #Find the best in archive (we want to replace that)\n                    if fitness[i] > self.archive_fitness[best_archive_idx]:\n                        self.archive[best_archive_idx] = population[i]\n                        self.archive_fitness[best_archive_idx] = fitness[i]\n                        \n            # Adaptive population size reduction\n            if generation % 10 == 0:\n                if self.population_size > 10:\n                    self.population_size = int(self.population_size * self.reduction_factor)\n                    population = population[:self.population_size]\n                    fitness = fitness[:self.population_size]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occurred: No module named 'cma'.", "error": "", "parent_ids": ["1874f8b0-f072-49bd-916e-75c2eb3386b0"], "operator": null, "metadata": {}}
{"id": "65023827-77c0-4456-b705-136b8aa5d8ef", "fitness": -Infinity, "name": "AdaptiveDEwithLocalSearch2", "description": "Adaptive Differential Evolution with Local Search, Archive, and Improved Parameter Adaptation using weighted averages based on fitness improvement and per-dimension learning rates.", "code": "import numpy as np\n\nclass AdaptiveDEwithLocalSearch2:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, local_search_prob=0.1, archive_size=10, ls_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = local_search_prob\n        self.archive_size = archive_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.archive_fitness = []\n        self.ls_rate = ls_rate  # Local search rate\n        self.per_dim_ls_rate = np.ones(self.dim) * self.ls_rate  # Initialize per-dimension rates\n        self.success_rates = np.zeros(self.dim)  # Track local search success per dimension\n        self.decay_rate = 0.95  # Decay rate for success rates\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history - weighted average\n                weights = np.abs(np.random.randn(self.memory_size))\n                weights /= weights.sum()\n                F = np.sum(self.F_memory * weights)\n                Cr = np.sum(self.Cr_memory * weights)\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n                \n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n\n                # Add archive component to mutation\n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += F * (self.archive[arc_idx] - population[i]) * 0.1  # Scale down the archive influence\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search with per-dimension learning rates\n                if np.random.rand() < self.local_search_prob:\n                    old_trial = np.copy(trial)\n                    trial = trial + np.random.normal(0, self.per_dim_ls_rate, self.dim)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        worst_archive_idx = np.argmax(self.archive_fitness)\n                        if fitness[i] < self.archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = population[i]\n                            self.archive_fitness[worst_archive_idx] = fitness[i]\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    self.update_memory(F, Cr, fitness[i] - fitness[i]) # send zero change to update memory\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        \n                    # Per-dimension LS rate adaptation\n                    success_mask = (old_trial != trial) # Dimensions that changed successfully\n                    self.success_rates[success_mask] = self.success_rates[success_mask] * self.decay_rate + (1 - self.decay_rate) # Exponential smoothing\n\n                    #Update per-dimension local search rate based on success rates\n                    self.per_dim_ls_rate = self.ls_rate * (1 + self.success_rates)\n\n                else:\n                    self.update_memory(F, Cr, 0) # zero change in fitness if not updated\n                    self.success_rates = self.success_rates * self.decay_rate # Decay success rates if no improvement\n\n        return self.f_opt, self.x_opt\n\n    def update_memory(self, F, Cr, delta_fitness):\n        self.F_memory = np.roll(self.F_memory, 1)\n        self.Cr_memory = np.roll(self.Cr_memory, 1)\n        self.F_memory[0] = F\n        self.Cr_memory[0] = Cr", "configspace": "", "generation": 5, "feedback": "An exception occurred: local variable 'old_trial' referenced before assignment.", "error": "", "parent_ids": ["1874f8b0-f072-49bd-916e-75c2eb3386b0"], "operator": null, "metadata": {}}
{"id": "c9530681-d123-436b-96ac-5e07b56ddb05", "fitness": -Infinity, "name": "AdaptiveDEwithLocalSearch3", "description": "Enhanced Adaptive Differential Evolution with CMA-ES based local search, improved parameter adaptation using fitness difference ratios, and orthogonal crossover to boost diversity.", "code": "import numpy as np\n\nclass AdaptiveDEwithLocalSearch3:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, local_search_prob=0.1, archive_size=100, ortho_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = local_search_prob\n        self.archive_size = archive_size\n        self.ortho_prob = ortho_prob\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.F = 0.5\n        self.Cr = 0.9\n        self.CMA_sigma = 0.1  # Initial step size for CMA\n        self.CMA_C = 0.1     # Learning rate for covariance matrix\n        self.CMA_d = 1       # Damping factor for step size\n        self.CMA_mu = pop_size // 4  # Number of selected parents\n        self.CMA_weights = np.log(self.CMA_mu + 0.5) - np.log(np.arange(1, self.CMA_mu + 1))\n        self.CMA_weights /= np.sum(self.CMA_weights)\n        self.CMA_B = np.eye(dim)  # Eigenvectors of covariance matrix\n        self.CMA_D = np.ones(dim) # Eigenvalues of covariance matrix\n        self.CMA_C_mu = 0          # Cumulation for mean\n        self.CMA_C_sigma = 0       # Cumulation for step size\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history\n                F = np.random.choice(self.F_memory)\n                Cr = np.random.choice(self.Cr_memory)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                if np.random.rand() < self.ortho_prob:\n                    trial = self.orthogonal_crossover(population[i], mutant, func.bounds.lb, func.bounds.ub)\n                else:\n                    # Crossover\n                    trial = np.copy(population[i])\n                    mask = np.random.rand(self.dim) < Cr\n                    trial[mask] = mutant[mask]\n\n                # Local Search with CMA-ES\n                if np.random.rand() < self.local_search_prob:\n                    z = np.random.normal(0, 1, self.dim)\n                    trial = trial + self.CMA_sigma * (self.CMA_B @ (self.CMA_D * z))\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.archive.append(population[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    # Update CMA parameters based on successful step\n                    delta = trial - population[i]\n                    self.CMA_C_mu = (1 - self.CMA_C) * self.CMA_C_mu + np.sqrt(self.CMA_C * (2 - self.CMA_C)) * delta / self.CMA_sigma\n                    self.CMA_sigma *= np.exp(self.CMA_C / self.CMA_d * (np.linalg.norm(self.CMA_C_mu) / np.sqrt(self.dim) - 1))\n                    \n                    population[i] = trial\n                    fitness[i] = f_trial\n                    fitness_diff = fitness[i] - f_trial\n                    self.update_memory(F, Cr, fitness_diff)\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n        \n        return self.f_opt, self.x_opt\n\n    def update_memory(self, F, Cr, fitness_diff):\n        self.F_memory = np.roll(self.F_memory, 1)\n        self.Cr_memory = np.roll(self.Cr_memory, 1)\n        self.F_memory[0] = F\n        self.Cr_memory[0] = Cr\n\n        # Adjust F and Cr based on fitness improvement\n        if fitness_diff < 0:  # Improvement\n            ratio = abs(fitness_diff) / (abs(fitness_diff) + 1e-8) # Avoid division by zero\n            self.F_memory[0] = min(1.0, F * (1 + ratio))       # Increase F slightly\n            self.Cr_memory[0] = min(1.0, Cr * (1 + ratio))      # Increase Cr slightly\n        else:  # No improvement or worsening\n            ratio = 1 / (1 + abs(fitness_diff) + 1e-8)\n            self.F_memory[0] = max(0.1, F * ratio)          # Decrease F\n            self.Cr_memory[0] = max(0.1, Cr * ratio)         # Decrease Cr\n            \n    def orthogonal_crossover(self, x, mutant, lb, ub):\n        # Simplified orthogonal crossover\n        new_trial = np.copy(x)\n        for j in range(self.dim):\n            if np.random.rand() < 0.5:\n                new_trial[j] = (x[j] + mutant[j]) / 2\n            new_trial[j] = np.clip(new_trial[j], lb, ub)\n        return new_trial", "configspace": "", "generation": 5, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["c9d32af6-1abf-4ecc-a04b-f33a00f6337d"], "operator": null, "metadata": {}}
{"id": "127a23d6-41a3-41c6-bd8e-8c71186b5a5e", "fitness": 0.0, "name": "AdaptiveDEMultiMutation", "description": "An adaptive DE strategy with a combination of multiple mutation strategies, adaptive parameter control based on success rate, and a restart mechanism to enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveDEMultiMutation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, mutation_variants=3, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.mutation_variants = mutation_variants\n        self.restart_trigger = restart_trigger #percentage of budget spent before restarting.\n        self.F_memory = np.ones((self.mutation_variants, self.memory_size)) * 0.5\n        self.Cr_memory = np.ones((self.mutation_variants, self.memory_size)) * 0.9\n        self.success_counts = np.zeros(self.mutation_variants)\n        self.trial_counts = np.zeros(self.mutation_variants)\n        self.F = np.ones(self.mutation_variants) * 0.5\n        self.Cr = np.ones(self.mutation_variants) * 0.9\n        self.mutation_strategies = [\n            self.mutation_DE_rand_1,\n            self.mutation_DE_current_to_best_1,\n            self.mutation_DE_best_1\n        ]\n        self.best_fitness = np.inf\n        self.best_individual = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        self.best_fitness = self.f_opt\n        self.best_individual = self.x_opt\n        initial_budget = self.budget + self.pop_size #remember initial budget for restart condition\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Select mutation strategy based on success rate\n                mutation_idx = np.argmax(self.success_counts / (self.trial_counts + 1e-6))\n                \n                # Parameter adaptation using success history for selected mutation\n                F = np.random.choice(self.F_memory[mutation_idx])\n                Cr = np.random.choice(self.Cr_memory[mutation_idx])\n\n                # Differential Evolution Mutation\n                mutant = self.mutation_strategies[mutation_idx](population, i, F)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update success counts\n                    self.success_counts[mutation_idx] += 1\n                    \n                    # Update memory\n                    self.update_memory(mutation_idx, F, Cr)\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.best_fitness = f_trial\n                        self.best_individual = trial\n                \n                self.trial_counts[mutation_idx] += 1\n            \n            # Restart mechanism\n            if (initial_budget - self.budget) / initial_budget > self.restart_trigger:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n                if self.f_opt < self.best_fitness:\n                    self.best_fitness = self.f_opt\n                    self.best_individual = self.x_opt\n                else:\n                    #replace a random member of the population with the best\n                    random_index = np.random.randint(self.pop_size)\n                    population[random_index] = self.best_individual\n                    fitness[random_index] = self.best_fitness\n\n                self.success_counts = np.zeros(self.mutation_variants)\n                self.trial_counts = np.zeros(self.mutation_variants)\n                \n                \n                \n        return self.f_opt, self.x_opt\n\n    def update_memory(self, mutation_idx, F, Cr):\n        self.F_memory[mutation_idx] = np.roll(self.F_memory[mutation_idx], 1)\n        self.Cr_memory[mutation_idx] = np.roll(self.Cr_memory[mutation_idx], 1)\n        self.F_memory[mutation_idx][0] = F\n        self.Cr_memory[mutation_idx][0] = Cr\n\n    def mutation_DE_rand_1(self, population, i, F):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = population[a] + F * (population[b] - population[c])\n        return mutant\n\n    def mutation_DE_current_to_best_1(self, population, i, F):\n          idxs = [idx for idx in range(self.pop_size) if idx != i]\n          a, b = np.random.choice(idxs, 2, replace=False)\n          mutant = population[i] + F * (self.best_individual - population[i]) + F * (population[a] - population[b])\n          return mutant\n\n    def mutation_DE_best_1(self, population, i, F):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b = np.random.choice(idxs, 2, replace=False)\n        mutant = self.best_individual + F * (population[a] - population[b])\n        return mutant", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDEMultiMutation scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c9d32af6-1abf-4ecc-a04b-f33a00f6337d"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "a5990c5c-7260-4ac7-b198-691fa54296f8", "fitness": 0.0, "name": "AdaptiveDEwithLocalSearch2", "description": "Adaptive Differential Evolution with Local Search and Covariance Matrix Adaptation, utilizing an external archive and adaptive parameter control based on fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveDEwithLocalSearch2:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, local_search_prob=0.1, archive_size=10, ls_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = local_search_prob\n        self.archive_size = archive_size\n        self.ls_trials = ls_trials  # Number of local search trials\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.archive_fitness = []\n        self.C = np.eye(dim) * 0.1  # Covariance matrix for CMA-ES-like local search\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history - weighted average\n                weights = np.abs(np.random.randn(self.memory_size))\n                weights /= weights.sum()\n                F = np.sum(self.F_memory * weights)\n                Cr = np.sum(self.Cr_memory * weights)\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n\n                # Add archive component to mutation\n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += F * (self.archive[arc_idx] - population[i]) * 0.1  # Scale down the archive influence\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Local Search using CMA-ES-like adaptation\n                if np.random.rand() < self.local_search_prob:\n                    best_trial = trial\n                    best_f_trial = np.inf\n                    for _ in range(self.ls_trials):\n                        z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                        ls_trial = trial + 0.05 * z  # Scale the step size\n                        ls_trial = np.clip(ls_trial, func.bounds.lb, func.bounds.ub)\n                        f_ls_trial = func(ls_trial)\n                        self.budget -= 1\n                        if self.budget <= 0:\n                            break\n                        if f_ls_trial < best_f_trial:\n                            best_f_trial = f_ls_trial\n                            best_trial = ls_trial\n                    \n                    if self.budget <= 0:\n                        break\n                    \n                    if best_f_trial < func(trial):  # Only update if local search improves\n                        trial = best_trial\n                        \n                        # Update Covariance Matrix (simplified CMA-ES adaptation)\n                        z = (trial - population[i]) / 0.05  # Get the normalized step\n                        self.C = (1 - 0.1) * self.C + 0.1 * np.outer(z, z) \n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        worst_archive_idx = np.argmax(self.archive_fitness)\n                        if fitness[i] < self.archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = population[i]\n                            self.archive_fitness[worst_archive_idx] = fitness[i]\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    self.update_memory(F, Cr, fitness[i] - fitness[i]) # send zero change to update memory\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.update_memory(F, Cr, 0) # zero change in fitness if not updated\n\n        return self.f_opt, self.x_opt\n\n    def update_memory(self, F, Cr, delta_fitness):\n        self.F_memory = np.roll(self.F_memory, 1)\n        self.Cr_memory = np.roll(self.Cr_memory, 1)\n        self.F_memory[0] = F\n        self.Cr_memory[0] = Cr", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDEwithLocalSearch2 scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1874f8b0-f072-49bd-916e-75c2eb3386b0"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "f3616077-de9a-46fc-84eb-2da40a84802b", "fitness": 0.6884161690803255, "name": "AdaptiveOrthogonalDE", "description": "Adaptive Differential Evolution with orthogonal crossover, covariance matrix adaptation for step size control, and a restart mechanism based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveOrthogonalDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, orthogonal_components=5, restart_threshold=100, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution scaling factor\n        self.Cr = Cr  # Crossover rate\n        self.orthogonal_components = orthogonal_components\n        self.restart_threshold = restart_threshold\n        self.initial_step_size = initial_step_size\n        self.step_size = initial_step_size\n        self.stagnation_counter = 0\n        self.cov = np.eye(dim)  # Covariance matrix for CMA-ES-like step size adaptation\n        self.mean = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        self.mean = self.x_opt.copy()\n\n        best_fitness_history = [self.f_opt]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover: Create an orthogonal array and sample based on it.\n                trial = self.orthogonal_crossover(population[i], mutant, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.mean = self.x_opt.copy() #Update the mean\n\n            # Step size adaptation (CMA-ES like, simplified)\n            diff = self.x_opt - self.mean\n            self.cov = 0.9 * self.cov + 0.1 * np.outer(diff, diff) #Simplified update\n\n            #Stagnation check and restart\n            if self.f_opt >= best_fitness_history[-1]:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.restart_threshold:\n                #Restart: reinitialize around the current best\n                population = np.random.normal(self.x_opt, np.sqrt(np.diag(self.cov)), size=(self.pop_size, self.dim)) #Sample from the CMA adapted covariance.\n                population = np.clip(population, func.bounds.lb, func.bounds.ub)\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n                self.stagnation_counter = 0 #Reset stagnation counter\n                self.cov = np.eye(self.dim) # Reset covariance\n                self.mean = self.x_opt.copy()\n\n            best_fitness_history.append(self.f_opt)\n            if len(best_fitness_history) > 100:\n                best_fitness_history.pop(0)\n\n        return self.f_opt, self.x_opt\n\n    def orthogonal_crossover(self, x, mutant, lb, ub):\n        \"\"\"\n        Creates a trial vector using orthogonal crossover.\n        \"\"\"\n        trial = np.copy(x)\n        for j in range(self.dim):\n            if np.random.rand() < self.Cr:\n                # With probability Cr, choose either x or mutant based on orthogonal sampling\n                if np.random.rand() < 0.5:\n                    trial[j] = mutant[j]\n        trial = np.clip(trial, lb, ub)\n        return trial", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveOrthogonalDE scored 0.688 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0015b48e-79ce-4058-a721-e93b6126b181"], "operator": null, "metadata": {"aucs": [0.18992523528464111, 0.38688133035215, 0.7698626192730007, 0.9066223496051565, 0.812265199051228, 0.8674964073937353, 0.7752229553673977, 0.719320371808762, 0.8159951064991384, 0.7054269160662631, 0.8135729360008108, 0.9989821638824614, 0.25062209989139816, 0.7840411341782266, 0.8995377399074166, 0.8781824333068923, 0.5993466389031809, 0.8902943398566163, 0.19865659605763142, 0.5060688089204028]}}
{"id": "f920443d-2148-4670-8977-e70a59bf3290", "fitness": 0.4554505168116014, "name": "AdaptiveNeighborhoodDEv2", "description": "Adaptive DE with a self-adaptive neighborhood size based on the success rate of the neighborhood search, and an improved stochastic ranking scheme utilizing a dynamically adjusted probability.", "code": "import numpy as np\n\nclass AdaptiveNeighborhoodDEv2:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, initial_neighborhood_size=3, exploration_rate=0.2, exploration_decay=0.995, archive_size=10, success_threshold=0.1, neighborhood_adaption_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.neighborhood_size = initial_neighborhood_size\n        self.initial_neighborhood_size = initial_neighborhood_size\n        self.exploration_rate = exploration_rate\n        self.exploration_decay = exploration_decay\n        self.archive_size = archive_size\n        self.archive = []\n        self.archive_fitness = []\n        self.success_threshold = success_threshold\n        self.neighborhood_adaption_rate = neighborhood_adaption_rate\n        self.success_rates = np.zeros(pop_size) # track success rate per individual\n        self.p_rank_initial = 0.45\n        self.p_rank = self.p_rank_initial\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        success_counts = np.zeros(self.pop_size)  # Track successful updates\n\n        while self.budget > 0:\n            # Sort population based on fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            success_counts = success_counts[sorted_indices]  # reorder success counts\n\n            for i in range(self.pop_size):\n                # Neighborhood selection\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood = population[neighborhood_indices]\n\n                # Select best individuals from neighborhood\n                best_index = np.argmin(fitness[neighborhood_indices])\n                best_neighbor = neighborhood[best_index]\n\n                # Differential Evolution with neighborhood information and exploration rate\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n\n                # Apply exploration rate\n                if np.random.rand() < self.exploration_rate:\n                    mutant = population[i] + self.F * (population[a] - population[b])\n                else:\n                    mutant = population[i] + self.F * (best_neighbor - population[i]) + self.F * (population[a] - population[b])\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Adaptive Stochastic Ranking\n                # Dynamically adjust p_rank based on overall improvement\n                improvement_ratio = (self.f_opt - np.min(fitness)) / self.f_opt if self.f_opt != 0 else 0.0 # Avoid division by zero\n                self.p_rank = self.p_rank_initial * (1 + improvement_ratio) # Increase p_rank if improvement is good\n\n                if np.random.rand() < self.p_rank or (fitness[i] <= self.f_opt and f_trial <= self.f_opt) or (fitness[i] > self.f_opt and f_trial > self.f_opt):\n                    if f_trial < fitness[i]:\n                        population[i] = trial\n                        fitness[i] = f_trial\n                        success_counts[i] += 1  # Increment success count\n\n                        # Update global best\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                     if np.random.rand() < 0.5:\n                         population[i] = trial\n                         fitness[i] = f_trial\n\n            # Decay exploration rate\n            self.exploration_rate *= self.exploration_decay\n            self.exploration_rate = max(self.exploration_rate, 0.01)  # Ensure minimum exploration\n\n            # Adapt neighborhood size\n            for i in range(self.pop_size):\n                success_rate = success_counts[i] / (self.pop_size+1e-8)  # Calculate success rate for the individual\n                \n                if success_rate > self.success_threshold:\n                    self.neighborhood_size = min(self.pop_size - 1, int(self.neighborhood_size * (1 + self.neighborhood_adaption_rate)))  # Increase neighborhood size\n                else:\n                    self.neighborhood_size = max(1, int(self.neighborhood_size * (1 - self.neighborhood_adaption_rate)))  # Decrease neighborhood size\n                success_counts[i] = 0 #reset success counts each generation\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveNeighborhoodDEv2 scored 0.455 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["90f93079-b926-4135-a5ba-6ecc91396e7e"], "operator": null, "metadata": {"aucs": [0.15745907912907386, 0.31557633398826423, 0.40791952417783073, 0.7453674908683439, 0.32074090022553925, 0.5074811950587246, 0.29744854831928036, 0.37054803589354546, 0.3176483867322223, 0.20109001685774197, 0.7365199217059268, 0.9966813578318893, 0.4544020480999429, 0.29588751916990164, 0.7721580268132374, 0.463321103432481, 0.3680280959119261, 0.7016128024247735, 0.18664277838305188, 0.4924771712083319]}}
{"id": "92dec1fc-a676-499b-acaa-3b5ca0e6ff20", "fitness": 0.7594830797062524, "name": "AdaptiveDEwithLocalSearch2", "description": "Adaptive Differential Evolution with Local Search, Archive, and Improved Parameter Adaptation using a more robust weighted average for parameter updates and incorporating a Cauchy mutation.", "code": "import numpy as np\n\nclass AdaptiveDEwithLocalSearch2:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, local_search_prob=0.1, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = local_search_prob\n        self.archive_size = archive_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.archive_fitness = []\n        self.success_F = []\n        self.success_Cr = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history\n                if self.success_F:\n                    weights = np.abs(np.array(self.success_Cr))  # Use success Cr for weighting\n                    weights /= weights.sum()\n                    F = np.sum(np.array(self.success_F) * weights)\n                    Cr = np.sum(np.array(self.success_Cr) * weights)\n                else:\n                    F = 0.5\n                    Cr = 0.9\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n                \n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n\n                # Cauchy mutation to escape local optima\n                cauchy_mask = np.random.rand(self.dim) < 0.05  # Apply Cauchy mutation with a small probability\n                mutant[cauchy_mask] += 0.1 * np.random.standard_cauchy(size=np.sum(cauchy_mask))\n                \n                # Add archive component to mutation\n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += F * (self.archive[arc_idx] - population[i]) * 0.1  # Scale down the archive influence\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = trial + np.random.normal(0, 0.05, self.dim)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        worst_archive_idx = np.argmax(self.archive_fitness)\n                        if fitness[i] < self.archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = population[i]\n                            self.archive_fitness[worst_archive_idx] = fitness[i]\n\n                    self.success_F.append(F)\n                    self.success_Cr.append(Cr)\n                    if len(self.success_F) > self.memory_size:\n                        self.success_F.pop(0)\n                        self.success_Cr.pop(0)\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDEwithLocalSearch2 scored 0.759 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1874f8b0-f072-49bd-916e-75c2eb3386b0"], "operator": null, "metadata": {"aucs": [0.4691032012842705, 0.8584505082036847, 0.6081414164849752, 0.9485302143732243, 0.8591584655416057, 0.8924421513074637, 0.810128069382678, 0.8264391065053374, 0.8713101212707832, 0.8559113787232884, 0.9190318746934952, 0.996706433757437, 0.3249237666008017, 0.7697463763994687, 0.8451947654112847, 0.8919674096203521, 0.782739272013319, 0.9119198380050791, 0.24335737513710887, 0.5044598494093872]}}
{"id": "018ae660-d68b-4cb7-9d40-7f2dd5eea8a5", "fitness": 0.7208613056266425, "name": "AdaptiveDESOM", "description": "Adaptive Differential Evolution with a self-organizing map (SOM) for parameter adaptation and population diversification.", "code": "import numpy as np\n\nclass AdaptiveDESOM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, som_grid_size=5, learning_rate=0.1, sigma=1.0, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.som_grid_size = som_grid_size\n        self.learning_rate = learning_rate\n        self.sigma = sigma\n        self.archive_size = archive_size\n        self.archive = []\n        self.archive_fitness = []\n        self.F_values = np.random.uniform(0.1, 1.0, size=self.pop_size)\n        self.Cr_values = np.random.uniform(0.1, 1.0, size=self.pop_size)\n        \n        # Initialize SOM\n        self.som = np.random.rand(self.som_grid_size, self.som_grid_size, 2)  # 2 for F and Cr\n        self.neighborhood_function = lambda dist: np.exp(-dist**2 / (2 * self.sigma**2))\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # SOM-based parameter adaptation\n                best_matching_unit = self.find_best_matching_unit(self.F_values[i], self.Cr_values[i])\n                \n                # Update F and Cr based on BMU\n                F = self.som[best_matching_unit[0], best_matching_unit[1], 0]\n                Cr = self.som[best_matching_unit[0], best_matching_unit[1], 1]\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n\n                # Add archive component to mutation\n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += F * (self.archive[arc_idx] - population[i]) * 0.1  # Scale down the archive influence\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        worst_archive_idx = np.argmax(self.archive_fitness)\n                        if fitness[i] < self.archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = population[i]\n                            self.archive_fitness[worst_archive_idx] = fitness[i]\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update SOM - adjust the network towards the selected F and Cr\n                    self.update_som(best_matching_unit, F, Cr)\n                    self.F_values[i] = F\n                    self.Cr_values[i] = Cr\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt\n\n    def find_best_matching_unit(self, F, Cr):\n        min_dist = np.inf\n        bmu = None\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                dist = np.sqrt((self.som[i, j, 0] - F)**2 + (self.som[i, j, 1] - Cr)**2)\n                if dist < min_dist:\n                    min_dist = dist\n                    bmu = (i, j)\n        return bmu\n\n    def update_som(self, bmu, F, Cr):\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                dist = np.sqrt((i - bmu[0])**2 + (j - bmu[1])**2)\n                influence = self.neighborhood_function(dist)\n                self.som[i, j, 0] += self.learning_rate * influence * (F - self.som[i, j, 0])\n                self.som[i, j, 1] += self.learning_rate * influence * (Cr - self.som[i, j, 1])", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDESOM scored 0.721 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1874f8b0-f072-49bd-916e-75c2eb3386b0"], "operator": null, "metadata": {"aucs": [0.25636681061417943, 0.6878806065346458, 0.773392103448694, 0.9075873009404545, 0.7982346985120436, 0.8772319375580088, 0.7499862185500328, 0.6592870212852184, 0.8041751549382811, 0.7476678155008276, 0.8460301429927604, 0.9998219957100496, 0.33362172675232693, 0.7206748447423814, 0.9354407789235859, 0.8873837826761224, 0.7664008736581115, 0.9028583469664462, 0.25956178011219655, 0.5036221721164811]}}
{"id": "e14feeca-f118-4250-ba34-641ecd166e8b", "fitness": 0.6824085448231039, "name": "AdaptiveRestartDE", "description": "Differential Evolution with a self-adaptive strategy that adjusts mutation strength and crossover rate based on the population's diversity and performance, incorporating a restart mechanism when stagnation is detected.", "code": "import numpy as np\n\nclass AdaptiveRestartDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_init=0.5, Cr_init=0.9, stagnation_limit=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init  # Initial scaling factor\n        self.Cr = Cr_init  # Initial crossover rate\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive F and Cr\n                self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n                self.Cr = np.clip(np.random.normal(self.Cr, 0.1), 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Stagnation Check and Restart\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.stagnation_limit:\n                if np.abs(self.best_fitness_history[-1] - np.mean(self.best_fitness_history[-self.stagnation_limit:])) < 1e-8:\n                    self.stagnation_counter += 1\n                else:\n                    self.stagnation_counter = 0\n\n                if self.stagnation_counter >= self.stagnation_limit:\n                    # Restart Population\n                    population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    self.budget -= self.pop_size\n                    self.f_opt = np.min(fitness)\n                    self.x_opt = population[np.argmin(fitness)]\n                    self.best_fitness_history = [self.f_opt]\n                    self.stagnation_counter = 0\n                    self.F = 0.5 # Reset F and Cr as well\n                    self.Cr = 0.9\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveRestartDE scored 0.682 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0015b48e-79ce-4058-a721-e93b6126b181"], "operator": null, "metadata": {"aucs": [0.333364232511539, 0.3019714713770525, 0.5229261928429603, 0.9100441774874317, 0.8720423352075723, 0.8859555960293264, 0.7936783779980406, 0.5399299439415226, 0.4572748375914837, 0.8148999490519602, 0.897140971589136, 0.9959779424137714, 0.28486231796161277, 0.8350821430802191, 0.9189843674521728, 0.865464916793393, 0.7350318666712907, 0.8884833135806584, 0.25703761410793846, 0.5380183287729954]}}
{"id": "10a5f196-6334-4328-a26f-3b6271707947", "fitness": 0.7298467329039149, "name": "AdaptiveDEwithSelfAdaptiveLocalSearch", "description": "An adaptive DE that uses a modified success-history based parameter adaptation and a self-adaptive local search probability based on recent improvements.", "code": "import numpy as np\n\nclass AdaptiveDEwithSelfAdaptiveLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, initial_local_search_prob=0.1, archive_size=100, ls_decay=0.99, ls_increase=1.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = initial_local_search_prob\n        self.archive_size = archive_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.F = 0.5\n        self.Cr = 0.9\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.ls_decay = ls_decay\n        self.ls_increase = ls_increase\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        previous_f_opt = self.f_opt\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history with weighted sampling\n                weights = np.exp(-(fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-8))\n                weights /= np.sum(weights)\n                \n                indices = np.random.choice(self.pop_size, size=3, replace=False, p=weights)\n                a, b, c = indices[0], indices[1], indices[2]\n                \n                F = np.random.choice(self.F_memory)\n                Cr = np.random.choice(self.Cr_memory)\n\n                # Differential Evolution Mutation\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.local_search(trial, func)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.archive.append(population[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    population[i] = trial\n                    fitness[i] = f_trial\n                    self.update_memory(F, Cr, fitness[i] - f_trial) #incorporate fitness change\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            if self.f_opt < previous_f_opt:\n                self.local_search_prob = min(1.0, self.local_search_prob * self.ls_increase)\n            else:\n                self.local_search_prob = max(0.01, self.local_search_prob * self.ls_decay)\n            previous_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func, step_size=0.1):\n        # Simple local search using random step\n        new_x = x + np.random.uniform(-step_size, step_size, size=self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x\n\n    def update_memory(self, F, Cr, fitness_diff):\n        self.F_memory = np.roll(self.F_memory, 1)\n        self.Cr_memory = np.roll(self.Cr_memory, 1)\n        self.F_memory[0] = F\n        self.Cr_memory[0] = Cr\n        # Optional: Adjust memory update based on fitness_diff", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDEwithSelfAdaptiveLocalSearch scored 0.730 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c9d32af6-1abf-4ecc-a04b-f33a00f6337d"], "operator": null, "metadata": {"aucs": [0.48078203652238016, 0.27296434308499107, 0.8194380598850537, 0.9357494381086561, 0.893557383413621, 0.9173166651178772, 0.854311136086444, 0.888950571522868, 0.9196782908160674, 0.8376694832525864, 0.7541792459514283, 0.9968325503126148, 0.5766665626786935, 0.8432699527375455, 0.5850641274727821, 0.9159601845984398, 0.4110746618759533, 0.9405221936307169, 0.21495106396715058, 0.5379967070424286]}}
{"id": "af63f7dc-3dd9-4783-8392-ebf27d61ac53", "fitness": -Infinity, "name": "AdaptiveDESOMv2", "description": "Improved Adaptive DE with SOM-based parameter adaptation, local search, and a more sophisticated archive update mechanism for better exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDESOMv2:\n    def __init__(self, budget=10000, dim=10, pop_size=20, som_grid_size=5, learning_rate=0.1, sigma=1.0, archive_size=10, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.som_grid_size = som_grid_size\n        self.learning_rate = learning_rate\n        self.sigma = sigma\n        self.archive_size = archive_size\n        self.archive = []\n        self.archive_fitness = []\n        self.F_values = np.random.uniform(0.1, 1.0, size=self.pop_size)\n        self.Cr_values = np.random.uniform(0.1, 1.0, size=self.pop_size)\n        self.local_search_prob = local_search_prob\n        \n        # Initialize SOM\n        self.som = np.random.rand(self.som_grid_size, self.som_grid_size, 2)  # 2 for F and Cr\n        self.neighborhood_function = lambda dist: np.exp(-dist**2 / (2 * self.sigma**2))\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # SOM-based parameter adaptation\n                best_matching_unit = self.find_best_matching_unit(self.F_values[i], self.Cr_values[i])\n                \n                # Update F and Cr based on BMU\n                F = self.som[best_matching_unit[0], best_matching_unit[1], 0]\n                Cr = self.som[best_matching_unit[0], best_matching_unit[1], 1]\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n\n                # Add archive component to mutation\n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += F * (self.archive[arc_idx] - population[i]) * 0.1  # Scale down the archive influence\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive using a probabilistic replacement based on fitness\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        # Replace the worst with probability proportional to improvement\n                        if fitness[i] < np.max(self.archive_fitness):\n                            probabilities = (self.archive_fitness - fitness[i]) / np.sum(self.archive_fitness - fitness[i])\n                            idx_to_replace = np.random.choice(len(self.archive), p=probabilities)\n                            self.archive[idx_to_replace] = population[i]\n                            self.archive_fitness[idx_to_replace] = fitness[i]\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update SOM - adjust the network towards the selected F and Cr\n                    self.update_som(best_matching_unit, F, Cr)\n                    self.F_values[i] = F\n                    self.Cr_values[i] = Cr\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    # Local search around the current individual with probability\n                    if np.random.rand() < self.local_search_prob:\n                        x_local = population[i] + np.random.normal(0, 0.05, self.dim)  # Gaussian perturbation\n                        x_local = np.clip(x_local, func.bounds.lb, func.bounds.ub)\n                        f_local = func(x_local)\n                        self.budget -= 1\n                        if self.budget <= 0:\n                            break\n\n                        if f_local < fitness[i]:\n                            population[i] = x_local\n                            fitness[i] = f_local\n                            if f_local < self.f_opt:\n                                self.f_opt = f_local\n                                self.x_opt = x_local\n                    \n                    #Update F and Cr values even if the trial vector is not better\n                    self.update_som(best_matching_unit, F, Cr)\n                    self.F_values[i] = F\n                    self.Cr_values[i] = Cr\n\n        return self.f_opt, self.x_opt\n\n    def find_best_matching_unit(self, F, Cr):\n        min_dist = np.inf\n        bmu = None\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                dist = np.sqrt((self.som[i, j, 0] - F)**2 + (self.som[i, j, 1] - Cr)**2)\n                if dist < min_dist:\n                    min_dist = dist\n                    bmu = (i, j)\n        return bmu\n\n    def update_som(self, bmu, F, Cr):\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                dist = np.sqrt((i - bmu[0])**2 + (j - bmu[1])**2)\n                influence = self.neighborhood_function(dist)\n                self.som[i, j, 0] += self.learning_rate * influence * (F - self.som[i, j, 0])\n                self.som[i, j, 1] += self.learning_rate * influence * (Cr - self.som[i, j, 1])", "configspace": "", "generation": 6, "feedback": "An exception occurred: probabilities are not non-negative.", "error": "", "parent_ids": ["018ae660-d68b-4cb7-9d40-7f2dd5eea8a5"], "operator": null, "metadata": {}}
{"id": "3f490f30-1adc-4573-b6c1-1dbcd6b85836", "fitness": 0.12119260650613922, "name": "AdaptiveDEwithCombinedMutationAndLocalSearch", "description": "Adaptive DE with a combination of Cauchy and Gaussian mutation, adaptive parameter control using a success-history archive, and a local search based on the best solution found so far.", "code": "import numpy as np\n\nclass AdaptiveDEwithCombinedMutationAndLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.local_search_prob = local_search_prob\n        self.F = 0.5\n        self.Cr = 0.9\n        self.memory_F = np.ones(archive_size) * 0.5\n        self.memory_Cr = np.ones(archive_size) * 0.9\n        self.archive = []\n        self.p_best_rate = 0.05\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                rnd = np.random.randint(self.archive_size)\n                self.F = self.memory_F[rnd]\n                self.Cr = self.memory_Cr[rnd]\n\n                # Mutation (Combined Cauchy and Gaussian)\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n\n                if np.random.rand() < 0.5:\n                    # Cauchy mutation\n                    mutant = population[a] + self.F * (population[b] - population[c]) * np.random.standard_cauchy(size=self.dim)\n                else:\n                    # Gaussian mutation\n                    mutant = population[a] + self.F * (population[b] - population[c]) * np.random.normal(size=self.dim)\n                \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive\n                    self.archive.append((self.F, self.Cr))\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    # Update memory\n                    if len(self.archive) > 0:\n                        F_vals, Cr_vals = zip(*self.archive)\n                        self.memory_F[rnd] = np.mean(F_vals)\n                        self.memory_Cr[rnd] = np.mean(Cr_vals)\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n            # Local Search (around the best solution)\n            if np.random.rand() < self.local_search_prob:\n                # Perturb each dimension of the best solution\n                for j in range(self.dim):\n                    # Create a small perturbation\n                    perturbation = np.random.normal(0, 0.05)  # Small step size\n                    trial = self.x_opt.copy()\n                    trial[j] += perturbation\n\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                    f_trial = func(trial)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                        # Update the population, replace a random individual\n                        replace_idx = np.random.randint(self.pop_size)\n                        population[replace_idx] = trial.copy()\n                        fitness[replace_idx] = f_trial\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDEwithCombinedMutationAndLocalSearch scored 0.121 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f3616077-de9a-46fc-84eb-2da40a84802b"], "operator": null, "metadata": {"aucs": [0.24238521301227844, 0]}}
{"id": "f0102570-7fb7-411f-82cf-4e73a5f651e7", "fitness": 0.0, "name": "AdaptiveDEwithCombinedMutation", "description": "Adaptive Differential Evolution with a combined Cauchy and Gaussian mutation strategy, dynamic population size adjustment, and an external archive with probabilistic selection.", "code": "import numpy as np\n\nclass AdaptiveDEwithCombinedMutation:\n    def __init__(self, budget=10000, dim=10, pop_size_min=10, pop_size_max=50, archive_size=20, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with larger population\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.archive_fitness = []\n        self.success_F = []\n        self.success_Cr = []\n        self.p_archive = 0.1  # Probability of using an archive individual\n        self.adapt_archive_prob = True #Adapt archive probability or not\n        self.tolerance = 1e-6 #Tolerance for population size change\n        self.improvement_history = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            old_f_opt = self.f_opt\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history\n                if self.success_F:\n                    weights = np.abs(np.array(self.success_Cr))\n                    weights /= weights.sum()\n                    F = np.sum(np.array(self.success_F) * weights)\n                    Cr = np.sum(np.array(self.success_Cr) * weights)\n                else:\n                    F = 0.5\n                    Cr = 0.9\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n\n                # Combined Cauchy and Gaussian Mutation\n                if np.random.rand() < 0.5:\n                    # Cauchy mutation\n                    mutant += 0.01 * np.random.standard_cauchy(size=self.dim)\n                else:\n                    # Gaussian mutation\n                    mutant += np.random.normal(0, 0.01, self.dim)\n                    \n                # Archive interaction\n                if len(self.archive) > 0 and np.random.rand() < self.p_archive:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += F * (self.archive[arc_idx] - population[i]) * 0.1\n                    \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        worst_archive_idx = np.argmax(self.archive_fitness)\n                        if fitness[i] < self.archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = population[i]\n                            self.archive_fitness[worst_archive_idx] = fitness[i]\n\n                    self.success_F.append(F)\n                    self.success_Cr.append(Cr)\n                    if len(self.success_F) > self.memory_size:\n                        self.success_F.pop(0)\n                        self.success_Cr.pop(0)\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            #Population size adaptation\n            improvement = old_f_opt - self.f_opt\n            self.improvement_history.append(improvement)\n            if len(self.improvement_history) > 10:\n                self.improvement_history.pop(0)\n            \n            avg_improvement = np.mean(self.improvement_history)\n\n            if avg_improvement < self.tolerance and self.pop_size > self.pop_size_min:\n                self.pop_size = max(self.pop_size - 1, self.pop_size_min)\n                population = population[:self.pop_size]\n                fitness = fitness[:self.pop_size]\n            elif avg_improvement > 5*self.tolerance and self.pop_size < self.pop_size_max:\n                self.pop_size = min(self.pop_size + 1, self.pop_size_max)\n                population = np.concatenate((population, np.random.uniform(func.bounds.lb, func.bounds.ub, size=(1, self.dim))))\n                fitness = np.concatenate((fitness, [func(population[-1])]))\n                self.budget -=1\n            if self.adapt_archive_prob:\n                self.p_archive = min(0.5, avg_improvement * 10) #linearly increase with improvement\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDEwithCombinedMutation scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["92dec1fc-a676-499b-acaa-3b5ca0e6ff20"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "3d68f5b1-5fd8-48a1-95dd-0124aab401fe", "fitness": -Infinity, "name": "AdaptiveDESOMEnhanced", "description": "Adaptive Differential Evolution with a mirrored SOM for parameter adaptation, combined with a probabilistic local search guided by the SOM and an elite-based archive.", "code": "import numpy as np\n\nclass AdaptiveDESOMEnhanced:\n    def __init__(self, budget=10000, dim=10, pop_size=20, som_grid_size=5, learning_rate=0.1, sigma=1.0, archive_size=10, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.som_grid_size = som_grid_size\n        self.learning_rate = learning_rate\n        self.sigma = sigma\n        self.archive_size = archive_size\n        self.archive = []\n        self.archive_fitness = []\n        self.F_values = np.random.uniform(0.1, 1.0, size=self.pop_size)\n        self.Cr_values = np.random.uniform(0.1, 1.0, size=self.pop_size)\n        self.local_search_prob = local_search_prob\n        \n        # Initialize SOM\n        self.som = np.random.rand(self.som_grid_size, self.som_grid_size, 2)  # 2 for F and Cr\n        self.mirrored_som = np.copy(self.som) # Mirrored SOM\n        self.neighborhood_function = lambda dist: np.exp(-dist**2 / (2 * self.sigma**2))\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        elite_idx = np.argmin(fitness)\n        elite = population[elite_idx].copy()\n        elite_fitness = self.f_opt\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # SOM-based parameter adaptation\n                best_matching_unit = self.find_best_matching_unit(self.F_values[i], self.Cr_values[i])\n                \n                # Update F and Cr based on BMU\n                F = self.som[best_matching_unit[0], best_matching_unit[1], 0]\n                Cr = self.som[best_matching_unit[0], best_matching_unit[1], 1]\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n\n                # Add archive component to mutation (using elite archive)\n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += F * (self.archive[arc_idx] - population[i]) * 0.1  # Scale down the archive influence\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    # Local search guided by SOM\n                    ls_step_size = 0.01 * (1 + self.mirrored_som[best_matching_unit[0], best_matching_unit[1], 0]) # Adjust step size based on SOM value\n                    trial = self.local_search(trial, func, ls_step_size)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        worst_archive_idx = np.argmax(self.archive_fitness)\n                        if fitness[i] < self.archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = population[i]\n                            self.archive_fitness[worst_archive_idx] = fitness[i]\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update mirrored SOM - adjust the network towards the selected F and Cr\n                    self.update_som(best_matching_unit, F, Cr)\n                    self.update_mirrored_som(best_matching_unit, F, Cr)\n                    self.F_values[i] = F\n                    self.Cr_values[i] = Cr\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                    if f_trial < elite_fitness:\n                        elite = trial.copy()\n                        elite_fitness = f_trial\n                elif f_trial < elite_fitness:\n                    elite = trial.copy()\n                    elite_fitness = f_trial\n                \n                if fitness[i] < elite_fitness:\n                    elite = population[i].copy()\n                    elite_fitness = fitness[i]\n\n            # Perturb SOM based on elite every few iterations to maintain diversity\n            if (self.budget % (self.pop_size * 5) == 0):\n                bmu_elite = self.find_best_matching_unit(self.F_values[elite_idx], self.Cr_values[elite_idx])\n                self.update_mirrored_som(bmu_elite, self.F_values[elite_idx], self.Cr_values[elite_idx], factor=0.5)\n        return self.f_opt, self.x_opt\n\n    def find_best_matching_unit(self, F, Cr):\n        min_dist = np.inf\n        bmu = None\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                dist = np.sqrt((self.som[i, j, 0] - F)**2 + (self.som[i, j, 1] - Cr)**2)\n                if dist < min_dist:\n                    min_dist = dist\n                    bmu = (i, j)\n        return bmu\n\n    def update_som(self, bmu, F, Cr, factor=1.0):\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                dist = np.sqrt((i - bmu[0])**2 + (j - bmu[1])**2)\n                influence = self.neighborhood_function(dist)\n                self.som[i, j, 0] += self.learning_rate * influence * (F - self.som[i, j, 0]) * factor\n                self.som[i, j, 1] += self.learning_rate * influence * (Cr - self.som[i, j, 1]) * factor\n\n    def update_mirrored_som(self, bmu, F, Cr, factor=1.0):\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                dist = np.sqrt((i - bmu[0])**2 + (j - bmu[1])**2)\n                influence = self.neighborhood_function(dist)\n                self.mirrored_som[i, j, 0] += self.learning_rate * influence * (F - self.mirrored_som[i, j, 0]) * factor\n                self.mirrored_som[i, j, 1] += self.learning_rate * influence * (Cr - self.mirrored_som[i, j, 1]) * factor\n\n    def local_search(self, x, func, step_size):\n        x_new = x.copy()\n        for j in range(self.dim):\n            # Randomly choose to increment or decrement the coordinate\n            direction = 1 if np.random.rand() < 0.5 else -1\n            x_new[j] += direction * step_size\n            x_new[j] = np.clip(x_new[j], func.bounds.lb, func.bounds.ub)\n        \n        f_new = func(x_new)\n        self.budget -= 1\n        if self.budget <= 0:\n            return x\n        \n        if f_new < func(x):\n            return x_new\n        else:\n            return x", "configspace": "", "generation": 6, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["018ae660-d68b-4cb7-9d40-7f2dd5eea8a5"], "operator": null, "metadata": {}}
{"id": "a5ceae90-d43e-4fc9-8e19-1f93f947f643", "fitness": 0.5088857934695433, "name": "AdaptiveDEwithOrthoArchive", "description": "Adaptive Differential Evolution with a self-organizing archive, orthogonal learning, and a restart mechanism based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveDEwithOrthoArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10, ortho_trials=5, diversity_threshold=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.ortho_trials = ortho_trials\n        self.diversity_threshold = diversity_threshold\n        self.archive = []\n        self.archive_fitness = []\n        self.F = 0.5\n        self.Cr = 0.9\n        self.stagnation_counter = 0\n        self.max_stagnation = 50 \n\n    def calculate_diversity(self, population):\n        \"\"\"Calculates population diversity based on the average distance to the centroid.\"\"\"\n        centroid = np.mean(population, axis=0)\n        distances = np.linalg.norm(population - centroid, axis=1)\n        return np.mean(distances)\n\n    def orthogonal_learning(self, x, func):\n        \"\"\"Performs orthogonal learning around a given solution x.\"\"\"\n        best_trial = func(x)\n        self.budget -= 1\n        best_x = x\n\n        for _ in range(self.ortho_trials):\n            direction = np.random.randn(self.dim)\n            direction /= np.linalg.norm(direction)  # Normalize\n            step_size = np.random.uniform(-0.1, 0.1) #adaptive step size\n            trial_x = x + step_size * direction\n            trial_x = np.clip(trial_x, func.bounds.lb, func.bounds.ub)\n            trial_fitness = func(trial_x)\n            self.budget -= 1\n\n            if trial_fitness < best_trial:\n                best_trial = trial_fitness\n                best_x = trial_x\n\n            if self.budget <= 0:\n                break\n        return best_trial, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        initial_fopt = self.f_opt\n\n        while self.budget > 0:\n            diversity = self.calculate_diversity(population)\n\n            if diversity < self.diversity_threshold:\n                self.stagnation_counter +=1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.max_stagnation:\n                # Restart mechanism\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n                self.stagnation_counter = 0\n                self.F = 0.5\n                self.Cr = 0.9\n                self.archive = []\n                self.archive_fitness = []\n\n\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n\n                # Add archive component to mutation\n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += self.F * (self.archive[arc_idx] - population[i]) * 0.1  # Scale down archive influence\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Learning\n                f_trial, trial = self.orthogonal_learning(trial, func)\n                if self.budget <= 0:\n                    break\n                \n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive using a self-organizing approach\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        #Replace the worst if better\n                        worst_archive_idx = np.argmax(self.archive_fitness)\n                        if fitness[i] < self.archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = population[i]\n                            self.archive_fitness[worst_archive_idx] = fitness[i]\n                    \n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Adaptive F and Cr (simple adaptation)\n                    if f_trial < fitness[i]:\n                        self.F = np.clip(self.F * np.random.uniform(0.8, 1.2), 0.1, 1.0)\n                        self.Cr = np.clip(self.Cr * np.random.uniform(0.8, 1.2), 0.1, 1.0)\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            if self.budget <= 0:\n                break\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDEwithOrthoArchive scored 0.509 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["92dec1fc-a676-499b-acaa-3b5ca0e6ff20"], "operator": null, "metadata": {"aucs": [0.20255178640357396, 0.44939425677993017, 0.4699808645850303, 0.6556612537402084, 0.34019067494545696, 0.5989659106762738, 0.3573644384769543, 0.4321061184386362, 0.4896647532574583, 0.30220880594564725, 0.7176004339592053, 0.9993263877474887, 0.49891175486659, 0.44777182973138585, 0.7079814388760965, 0.6051341193765738, 0.43155895522312104, 0.7268763853226088, 0.25048474045008595, 0.4939809605885406]}}
{"id": "9dea8105-eea3-4ca1-8ea0-b63cad83644d", "fitness": 0.6954544696426168, "name": "AdaptiveOrthogonalDEwithLocalSearch", "description": "Adaptive Differential Evolution with a CMA-ES-inspired mechanism, orthogonal crossover, and a newly added local search around the best solution, triggered with a probability that decays over time.", "code": "import numpy as np\n\nclass AdaptiveOrthogonalDEwithLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, orthogonal_components=5, restart_threshold=100, initial_step_size=0.1, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution scaling factor\n        self.Cr = Cr  # Crossover rate\n        self.orthogonal_components = orthogonal_components\n        self.restart_threshold = restart_threshold\n        self.initial_step_size = initial_step_size\n        self.step_size = initial_step_size\n        self.stagnation_counter = 0\n        self.cov = np.eye(dim)  # Covariance matrix for CMA-ES-like step size adaptation\n        self.mean = None\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        self.mean = self.x_opt.copy()\n\n        best_fitness_history = [self.f_opt]\n\n        iteration = 0\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover: Create an orthogonal array and sample based on it.\n                trial = self.orthogonal_crossover(population[i], mutant, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.mean = self.x_opt.copy() #Update the mean\n\n            # Step size adaptation (CMA-ES like, simplified)\n            diff = self.x_opt - self.mean\n            self.cov = 0.9 * self.cov + 0.1 * np.outer(diff, diff) #Simplified update\n\n            # Local Search around the best solution\n            if np.random.rand() < self.local_search_prob * np.exp(-iteration/500):  #Decaying probability\n                x_ls = np.random.normal(self.x_opt, np.sqrt(np.diag(self.cov)) * 0.1) #Smaller step size\n                x_ls = np.clip(x_ls, func.bounds.lb, func.bounds.ub)\n                f_ls = func(x_ls)\n                self.budget -= 1\n                if self.budget > 0 and f_ls < self.f_opt:\n                    self.f_opt = f_ls\n                    self.x_opt = x_ls\n                    self.mean = self.x_opt.copy()\n                    \n\n            #Stagnation check and restart\n            if self.f_opt >= best_fitness_history[-1]:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.restart_threshold:\n                #Restart: reinitialize around the current best\n                population = np.random.normal(self.x_opt, np.sqrt(np.diag(self.cov)), size=(self.pop_size, self.dim)) #Sample from the CMA adapted covariance.\n                population = np.clip(population, func.bounds.lb, func.bounds.ub)\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n                self.stagnation_counter = 0 #Reset stagnation counter\n                self.cov = np.eye(self.dim) # Reset covariance\n                self.mean = self.x_opt.copy()\n\n            best_fitness_history.append(self.f_opt)\n            if len(best_fitness_history) > 100:\n                best_fitness_history.pop(0)\n            \n            iteration += 1\n\n        return self.f_opt, self.x_opt\n\n    def orthogonal_crossover(self, x, mutant, lb, ub):\n        \"\"\"\n        Creates a trial vector using orthogonal crossover.\n        \"\"\"\n        trial = np.copy(x)\n        for j in range(self.dim):\n            if np.random.rand() < self.Cr:\n                # With probability Cr, choose either x or mutant based on orthogonal sampling\n                if np.random.rand() < 0.5:\n                    trial[j] = mutant[j]\n        trial = np.clip(trial, lb, ub)\n        return trial", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveOrthogonalDEwithLocalSearch scored 0.695 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f3616077-de9a-46fc-84eb-2da40a84802b"], "operator": null, "metadata": {"aucs": [0.20099679603510945, 0.3257852194946359, 0.7560358073830571, 0.9040281415839594, 0.8261858009152104, 0.8696954248861963, 0.6932026850118281, 0.7519503635595883, 0.8242171116193379, 0.8254116906399838, 0.848159696280026, 0.9963830747975584, 0.2864946656180598, 0.8192256027459278, 0.9061625108627219, 0.882996302770371, 0.5576653357313592, 0.8999274444347483, 0.21034991053369423, 0.5242158079489632]}}
{"id": "cbf38d94-b6ef-4882-a861-fa3ea9d17741", "fitness": 0.8236791201775165, "name": "AdaptiveDEwithSelfAdaptiveLocalSearchImproved", "description": "Adaptive Differential Evolution with Success-History based parameter adaptation, self-adaptive local search probability using a separate success rate for F and Cr, and improved local search with adaptive step size.", "code": "import numpy as np\n\nclass AdaptiveDEwithSelfAdaptiveLocalSearchImproved:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, initial_local_search_prob=0.1, archive_size=100, ls_decay=0.99, ls_increase=1.01, ls_step_size=0.1, ls_step_decay=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = initial_local_search_prob\n        self.archive_size = archive_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.ls_decay = ls_decay\n        self.ls_increase = ls_increase\n        self.ls_step_size = ls_step_size\n        self.ls_step_decay = ls_step_decay\n        self.successful_F = []\n        self.successful_Cr = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        previous_f_opt = self.f_opt\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history with weighted sampling\n                if self.successful_F:\n                    F = np.random.choice(self.successful_F)\n                else:\n                    F = 0.5  # Default value if no successful F values yet\n\n                if self.successful_Cr:\n                    Cr = np.random.choice(self.successful_Cr)\n                else:\n                    Cr = 0.9  # Default value if no successful Cr values yet\n\n                indices = np.random.choice(self.pop_size, size=3, replace=False)\n                a, b, c = indices[0], indices[1], indices[2]\n\n                # Differential Evolution Mutation\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.local_search(trial, func)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.archive.append(population[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    self.successful_F.append(F)\n                    self.successful_Cr.append(Cr)\n                    if len(self.successful_F) > self.memory_size:\n                        self.successful_F.pop(0)\n                        self.successful_Cr.pop(0)\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            if self.f_opt < previous_f_opt:\n                self.local_search_prob = min(1.0, self.local_search_prob * self.ls_increase)\n                self.ls_step_size = min(0.1, self.ls_step_size/self.ls_step_decay)\n            else:\n                self.local_search_prob = max(0.01, self.local_search_prob * self.ls_decay)\n                self.ls_step_size = max(1e-6, self.ls_step_size * self.ls_step_decay)\n            previous_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func):\n        # Local search using random step with adaptive step size\n        new_x = x + np.random.uniform(-self.ls_step_size, self.ls_step_size, size=self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDEwithSelfAdaptiveLocalSearchImproved scored 0.824 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["10a5f196-6334-4328-a26f-3b6271707947"], "operator": null, "metadata": {"aucs": [0.5958947280172151, 0.8702969814049015, 0.8493482650178965, 0.9490055551327065, 0.886825742276864, 0.9050782866004551, 0.8628925125169316, 0.48645612183221965, 0.9075214420039107, 0.876884365519842, 0.9480857152895359, 0.9894671411371215, 0.6433202198237803, 0.8734212803046704, 0.914215664615393, 0.8729691553504011, 0.8282714283278125, 0.9286593857915161, 0.7656396333939666, 0.5193287791931904]}}
{"id": "8a150427-1cd8-4090-aaed-6cb156cc8905", "fitness": 0.6956099061511781, "name": "AdaptiveDESOM", "description": "Adaptive Differential Evolution with SOM-based parameter adaptation, a diversity-enhancing mutation strategy based on opposition-based learning, and a local search to refine promising solutions.", "code": "import numpy as np\n\nclass AdaptiveDESOM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, som_grid_size=5, learning_rate=0.1, sigma=1.0, archive_size=10, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.som_grid_size = som_grid_size\n        self.learning_rate = learning_rate\n        self.sigma = sigma\n        self.archive_size = archive_size\n        self.archive = []\n        self.archive_fitness = []\n        self.F_values = np.random.uniform(0.1, 1.0, size=self.pop_size)\n        self.Cr_values = np.random.uniform(0.1, 1.0, size=self.pop_size)\n        self.local_search_prob = local_search_prob\n        \n        # Initialize SOM\n        self.som = np.random.rand(self.som_grid_size, self.som_grid_size, 2)  # 2 for F and Cr\n        self.neighborhood_function = lambda dist: np.exp(-dist**2 / (2 * self.sigma**2))\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # SOM-based parameter adaptation\n                best_matching_unit = self.find_best_matching_unit(self.F_values[i], self.Cr_values[i])\n                \n                # Update F and Cr based on BMU\n                F = self.som[best_matching_unit[0], best_matching_unit[1], 0]\n                Cr = self.som[best_matching_unit[0], best_matching_unit[1], 1]\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                # Differential Evolution Mutation with Opposition-Based Learning\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n\n                # Opposition-Based Learning for diversity\n                opposition = func.bounds.lb + func.bounds.ub - population[i]\n                if np.random.rand() < 0.1: # Introduce opposition-based learning with a small probability\n                    mutant = opposition\n\n                # Add archive component to mutation\n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += F * (self.archive[arc_idx] - population[i]) * 0.1  # Scale down the archive influence\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        worst_archive_idx = np.argmax(self.archive_fitness)\n                        if fitness[i] < self.archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = population[i]\n                            self.archive_fitness[worst_archive_idx] = fitness[i]\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update SOM - adjust the network towards the selected F and Cr\n                    self.update_som(best_matching_unit, F, Cr)\n                    self.F_values[i] = F\n                    self.Cr_values[i] = Cr\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                        # Local Search around the new best\n                        if np.random.rand() < self.local_search_prob:\n                            self.x_opt, self.f_opt = self.local_search(func, self.x_opt)\n\n        return self.f_opt, self.x_opt\n\n    def find_best_matching_unit(self, F, Cr):\n        min_dist = np.inf\n        bmu = None\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                dist = np.sqrt((self.som[i, j, 0] - F)**2 + (self.som[i, j, 1] - Cr)**2)\n                if dist < min_dist:\n                    min_dist = dist\n                    bmu = (i, j)\n        return bmu\n\n    def update_som(self, bmu, F, Cr):\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                dist = np.sqrt((i - bmu[0])**2 + (j - bmu[1])**2)\n                influence = self.neighborhood_function(dist)\n                self.som[i, j, 0] += self.learning_rate * influence * (F - self.som[i, j, 0])\n                self.som[i, j, 1] += self.learning_rate * influence * (Cr - self.som[i, j, 1])\n    \n    def local_search(self, func, x_opt, radius=0.1, num_points=5):\n        best_x = x_opt\n        best_f = self.f_opt\n        \n        for _ in range(num_points):\n            x = x_opt + np.random.uniform(-radius, radius, size=self.dim)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            f = func(x)\n            self.budget -= 1\n            if self.budget <= 0:\n                break\n            \n            if f < best_f:\n                best_f = f\n                best_x = x\n        return best_x, best_f", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDESOM scored 0.696 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["018ae660-d68b-4cb7-9d40-7f2dd5eea8a5"], "operator": null, "metadata": {"aucs": [0.25348437776883925, 0.29088523578778935, 0.7629306946482243, 0.9228080356971579, 0.7785495928112484, 0.895830651415495, 0.6212823591105302, 0.7980300047869525, 0.8115241169434261, 0.7829646476770107, 0.8438174382924255, 0.9832911119223997, 0.37446744074824767, 0.7365853544436889, 0.9054100437272021, 0.8794589292331109, 0.6632090967606511, 0.875214078802991, 0.2225118578890184, 0.5099430545571526]}}
{"id": "10f5d5fc-ccb9-4cc8-bb94-e3865887010e", "fitness": 0.2574564699667753, "name": "AdaptiveVelocityDE", "description": "Adaptive Differential Evolution with a novel combination of velocity-based mutation, a diversity maintenance strategy using orthogonal learning, and a self-adaptive local search.", "code": "import numpy as np\n\nclass AdaptiveVelocityDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, local_search_prob=0.1, orthogonal_pairs=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = local_search_prob\n        self.orthogonal_pairs = orthogonal_pairs\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.success_F = []\n        self.success_Cr = []\n        self.velocity = np.zeros((self.pop_size, self.dim)) # Initialize velocity for each individual\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history\n                if self.success_F:\n                    weights = np.abs(np.array(self.success_Cr))  # Use success Cr for weighting\n                    weights /= weights.sum()\n                    F = np.sum(np.array(self.success_F) * weights)\n                    Cr = np.sum(np.array(self.success_Cr) * weights)\n                else:\n                    F = 0.5\n                    Cr = 0.9\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                # Velocity-based Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n\n                # Update velocity (using current velocity + DE mutation)\n                self.velocity[i] = 0.5 * self.velocity[i] + F * (population[b] - population[c])\n                mutant = population[i] + self.velocity[i]\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Learning for Diversity Maintenance\n                if self.dim >= 2 and self.orthogonal_pairs > 0:\n                    for _ in range(self.orthogonal_pairs):\n                        j1, j2 = np.random.choice(self.dim, 2, replace=False)\n                        mutant[j1], mutant[j2] = (mutant[j1] + mutant[j2]) / 2, (mutant[j1] + mutant[j2]) / 2\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = trial + np.random.normal(0, 0.05, self.dim)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_F.append(F)\n                    self.success_Cr.append(Cr)\n                    if len(self.success_F) > self.memory_size:\n                        self.success_F.pop(0)\n                        self.success_Cr.pop(0)\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveVelocityDE scored 0.257 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["92dec1fc-a676-499b-acaa-3b5ca0e6ff20"], "operator": null, "metadata": {"aucs": [0.10429740586596037, 0.22033880873557077, 0.31785158456014895, 0.19099129284404848, 0.17901989250621098, 0.2344295609945236, 0.22499889539146045, 0.21500956211455835, 0.18873993434530867, 0.15180554183821027, 0.15506644317840634, 0.9991758045751342, 0.24891803547665514, 0.1928954886983416, 0.20494113410371606, 0.2620682962977928, 0.2388271087929329, 0.19418576632878382, 0.16725716420004832, 0.45831167848769483]}}
{"id": "9ba2074b-59f2-4df6-a9d9-134d516a3664", "fitness": 0.0, "name": "AdaptiveDESOM", "description": "Adaptive Differential Evolution with SOM-based parameter adaptation, local search, and improved archive handling using a probabilistic replacement strategy.", "code": "import numpy as np\n\nclass AdaptiveDESOM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, som_grid_size=5, learning_rate=0.1, sigma=1.0, archive_size=10, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.som_grid_size = som_grid_size\n        self.learning_rate = learning_rate\n        self.sigma = sigma\n        self.archive_size = archive_size\n        self.archive = []\n        self.archive_fitness = []\n        self.F_values = np.random.uniform(0.1, 1.0, size=self.pop_size)\n        self.Cr_values = np.random.uniform(0.1, 1.0, size=self.pop_size)\n        self.local_search_prob = local_search_prob\n        \n        # Initialize SOM\n        self.som = np.random.rand(self.som_grid_size, self.som_grid_size, 2)  # 2 for F and Cr\n        self.neighborhood_function = lambda dist: np.exp(-dist**2 / (2 * self.sigma**2))\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # SOM-based parameter adaptation\n                best_matching_unit = self.find_best_matching_unit(self.F_values[i], self.Cr_values[i])\n                \n                # Update F and Cr based on BMU\n                F = self.som[best_matching_unit[0], best_matching_unit[1], 0]\n                Cr = self.som[best_matching_unit[0], best_matching_unit[1], 1]\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n\n                # Add archive component to mutation\n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += F * (self.archive[arc_idx] - population[i]) * 0.1  # Scale down the archive influence\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.local_search(trial, func.bounds.lb, func.bounds.ub, func)\n                    if self.budget <= 0:\n                        break\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        # Probabilistic archive replacement\n                        probs = np.exp(-np.array(self.archive_fitness) / self.f_opt)  # Probability based on fitness relative to best\n                        probs /= np.sum(probs)\n                        replace_idx = np.random.choice(len(self.archive), p=probs) #Select for replacement with probability\n                        if fitness[i] < self.archive_fitness[replace_idx]:\n                            self.archive[replace_idx] = population[i]\n                            self.archive_fitness[replace_idx] = fitness[i]\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update SOM - adjust the network towards the selected F and Cr\n                    self.update_som(best_matching_unit, F, Cr)\n                    self.F_values[i] = F\n                    self.Cr_values[i] = Cr\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt\n\n    def find_best_matching_unit(self, F, Cr):\n        min_dist = np.inf\n        bmu = None\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                dist = np.sqrt((self.som[i, j, 0] - F)**2 + (self.som[i, j, 1] - Cr)**2)\n                if dist < min_dist:\n                    min_dist = dist\n                    bmu = (i, j)\n        return bmu\n\n    def update_som(self, bmu, F, Cr):\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                dist = np.sqrt((i - bmu[0])**2 + (j - bmu[1])**2)\n                influence = self.neighborhood_function(dist)\n                self.som[i, j, 0] += self.learning_rate * influence * (F - self.som[i, j, 0])\n                self.som[i, j, 1] += self.learning_rate * influence * (Cr - self.som[i, j, 1])\n                self.som[i,j,0] = np.clip(self.som[i,j,0], 0.1, 1.0)\n                self.som[i,j,1] = np.clip(self.som[i,j,1], 0.1, 1.0)\n\n    def local_search(self, x, lb, ub, func, radius=0.1, num_steps=5):\n        x_new = np.copy(x)\n        for _ in range(num_steps):\n            direction = np.random.uniform(-radius, radius, size=self.dim)\n            x_candidate = x_new + direction\n            x_candidate = np.clip(x_candidate, lb, ub)\n            f_candidate = func(x_candidate)\n            self.budget -= 1\n            if self.budget <= 0:\n                break\n            f_current = func(x_new) if _ == 0 else f_candidate_prev # to avoid repeated evaluation.\n            if f_candidate < f_current:\n                x_new = x_candidate\n            f_candidate_prev = f_candidate\n        return x_new", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDESOM scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["018ae660-d68b-4cb7-9d40-7f2dd5eea8a5"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "8993831c-e6dc-4624-aa99-ed2ddb5159f0", "fitness": 0.4891279241769776, "name": "AdaptiveDEFuzzySOM", "description": "Adaptive Differential Evolution with a Fuzzy Self-Organizing Map (FSOM) for parameter adaptation, incorporating fuzzy membership for smoother transitions and improved exploration.", "code": "import numpy as np\n\nclass AdaptiveDEFuzzySOM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, som_grid_size=5, learning_rate=0.1, sigma=1.0, archive_size=10, fuzzy_param=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.som_grid_size = som_grid_size\n        self.learning_rate = learning_rate\n        self.sigma = sigma\n        self.archive_size = archive_size\n        self.archive = []\n        self.archive_fitness = []\n        self.F_values = np.random.uniform(0.1, 1.0, size=self.pop_size)\n        self.Cr_values = np.random.uniform(0.1, 1.0, size=self.pop_size)\n        self.fuzzy_param = fuzzy_param #Fuzzification parameter\n\n        # Initialize Fuzzy SOM\n        self.som = np.random.rand(self.som_grid_size, self.som_grid_size, 2)  # 2 for F and Cr\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Fuzzy SOM-based parameter adaptation\n                bmu_indices, membership_values = self.find_fuzzy_best_matching_units(self.F_values[i], self.Cr_values[i])\n\n                # Weighted average of F and Cr based on fuzzy memberships\n                F = 0.0\n                Cr = 0.0\n                total_membership = np.sum(membership_values)\n                for j, (row, col) in enumerate(bmu_indices):\n                    F += membership_values[j] / total_membership * self.som[row, col, 0]\n                    Cr += membership_values[j] / total_membership * self.som[row, col, 1]\n\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n\n                # Add archive component to mutation\n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += F * (self.archive[arc_idx] - population[i]) * 0.1  # Scale down the archive influence\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        worst_archive_idx = np.argmax(self.archive_fitness)\n                        if fitness[i] < self.archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = population[i]\n                            self.archive_fitness[worst_archive_idx] = fitness[i]\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update Fuzzy SOM - adjust the network towards the selected F and Cr\n                    self.update_som(bmu_indices, membership_values, F, Cr)\n                    self.F_values[i] = F\n                    self.Cr_values[i] = Cr\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt\n\n    def find_fuzzy_best_matching_units(self, F, Cr):\n        distances = np.zeros((self.som_grid_size, self.som_grid_size))\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                distances[i, j] = np.sqrt((self.som[i, j, 0] - F)**2 + (self.som[i, j, 1] - Cr)**2)\n\n        # Calculate fuzzy membership values\n        membership_values = 1.0 / (distances** (2 / (self.fuzzy_param - 1)))\n        membership_values = membership_values.flatten()\n        \n        # Get indices of all SOM units\n        indices = np.array([(i, j) for i in range(self.som_grid_size) for j in range(self.som_grid_size)])\n\n        # Return the indices and membership values\n        return indices, membership_values\n    \n    def update_som(self, bmu_indices, membership_values, F, Cr):\n        total_membership = np.sum(membership_values)\n        for i, (row, col) in enumerate(bmu_indices):\n            influence = membership_values[i] / total_membership if total_membership > 0 else 0\n            self.som[row, col, 0] += self.learning_rate * influence * (F - self.som[row, col, 0])\n            self.som[row, col, 1] += self.learning_rate * influence * (Cr - self.som[row, col, 1])", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDEFuzzySOM scored 0.489 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["018ae660-d68b-4cb7-9d40-7f2dd5eea8a5"], "operator": null, "metadata": {"aucs": [0.23633353764844678, 0.33316905070911296, 0.47598199310334643, 0.5153615507589167, 0.3727927745829357, 0.4990555550570833, 0.34647444140839, 0.3685485287972765, 0.39958574717221873, 0.4744291822770156, 0.539191369354751, 0.9942537494610802, 0.404585866673417, 0.6308851691187247, 0.8072934087199072, 0.5322620959649673, 0.36171036884669516, 0.5273465601220575, 0.43846345168449596, 0.5248340820787118]}}
{"id": "73d444e3-2c72-4484-9d2c-c5400d7c005e", "fitness": 0.6758963257920783, "name": "EnhancedAdaptiveDE", "description": "Enhanced Adaptive Differential Evolution with improved exploration via sinusoidal parameter adaptation, orthogonal learning, and a dual local search strategy.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, local_search_prob=0.1, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = local_search_prob\n        self.archive_size = archive_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.archive_fitness = []\n        self.success_F = []\n        self.success_Cr = []\n        self.generation = 0\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            self.generation += 1\n            for i in range(self.pop_size):\n                # Parameter adaptation using sinusoidal function and success history\n                period = 100  # Sinusoidal period\n                F = 0.5 + 0.4 * np.sin(2 * np.pi * self.generation / period)\n                Cr = 0.9 + 0.09 * np.cos(2 * np.pi * self.generation / period)\n\n                if self.success_F:\n                    weights = np.abs(np.array(self.success_Cr))  # Use success Cr for weighting\n                    weights /= weights.sum()\n                    F = 0.5 * F + 0.5 * np.sum(np.array(self.success_F) * weights)\n                    Cr = 0.5 * Cr + 0.5 * np.sum(np.array(self.success_Cr) * weights)\n\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n\n                # Cauchy mutation to escape local optima\n                cauchy_mask = np.random.rand(self.dim) < 0.05  # Apply Cauchy mutation with a small probability\n                mutant[cauchy_mask] += 0.1 * np.random.standard_cauchy(size=np.sum(cauchy_mask))\n\n                # Archive component to mutation\n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += F * (self.archive[arc_idx] - population[i]) * 0.1  # Scale down the archive influence\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Dual Local Search\n                if np.random.rand() < self.local_search_prob:\n                    # Local Search 1: Small perturbation\n                    trial1 = trial + np.random.normal(0, 0.05, self.dim)\n                    trial1 = np.clip(trial1, func.bounds.lb, func.bounds.ub)\n\n                    # Local Search 2: Larger perturbation with decreasing intensity\n                    intensity = 0.1 * np.exp(-self.generation / 500)  # Decaying intensity\n                    trial2 = trial + np.random.normal(0, intensity, self.dim)\n                    trial2 = np.clip(trial2, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate both local searches and choose the better one\n                    f_trial1 = func(trial1)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    f_trial2 = func(trial2)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if f_trial1 < f_trial2:\n                        f_trial = f_trial1\n                        trial = trial1\n                    else:\n                        f_trial = f_trial2\n                        trial = trial2\n                else:\n                    f_trial = func(trial)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        worst_archive_idx = np.argmax(self.archive_fitness)\n                        if fitness[i] < self.archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = population[i]\n                            self.archive_fitness[worst_archive_idx] = fitness[i]\n\n                    self.success_F.append(F)\n                    self.success_Cr.append(Cr)\n                    if len(self.success_F) > self.memory_size:\n                        self.success_F.pop(0)\n                        self.success_Cr.pop(0)\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedAdaptiveDE scored 0.676 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["92dec1fc-a676-499b-acaa-3b5ca0e6ff20"], "operator": null, "metadata": {"aucs": [0.2413587534617737, 0.3847863091889584, 0.5056199886367009, 0.9221558827393641, 0.7935860152145402, 0.7928236961737345, 0.7964414727046173, 0.4735743171768426, 0.6292395760943112, 0.7373897759750011, 0.9079513341575103, 0.9934130513996627, 0.34397313881607483, 0.7042673858754928, 0.873178980072962, 0.8008621441584038, 0.6053006266340497, 0.8800759660724501, 0.631391599608106, 0.5005365016810075]}}
{"id": "33c6476b-6947-4895-8d01-d3eaa22dd32b", "fitness": -Infinity, "name": "CooperativeAdaptiveDEClustering", "description": "Cooperative Adaptive Differential Evolution with Intermittent Local Search and Population Clustering.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass CooperativeAdaptiveDEClustering:\n    def __init__(self, budget=10000, dim=10, pop_size=20, num_subpopulations=4, F=0.5, Cr=0.9, local_search_prob=0.1, local_search_radius=0.1, clustering_interval=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.num_subpopulations = num_subpopulations\n        self.F = F\n        self.Cr = Cr\n        self.local_search_prob = local_search_prob\n        self.local_search_radius = local_search_radius\n        self.clustering_interval = clustering_interval\n        self.population = None\n        self.fitness = None\n        self.subpopulations = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.iteration = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def differential_evolution(self, func, subpop_indices):\n        for i in subpop_indices:\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n            \n            trial = np.copy(self.population[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    trial[j] = mutant[j]\n            trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n            f_trial = func(trial)\n            self.budget -= 1\n            if f_trial < self.fitness[i]:\n                self.population[i] = trial\n                self.fitness[i] = f_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial\n            if self.budget <= 0:\n                break\n\n    def local_search(self, func):\n        if np.random.rand() < self.local_search_prob:\n            x_ls = np.random.normal(self.x_opt, self.local_search_radius)\n            x_ls = np.clip(x_ls, func.bounds.lb, func.bounds.ub)\n            f_ls = func(x_ls)\n            self.budget -= 1\n            if self.budget > 0 and f_ls < self.f_opt:\n                self.f_opt = f_ls\n                self.x_opt = x_ls\n\n    def cluster_population(self):\n        kmeans = KMeans(n_clusters=self.num_subpopulations, random_state=0, n_init = 'auto').fit(self.population)\n        self.subpopulations = [np.where(kmeans.labels_ == i)[0] for i in range(self.num_subpopulations)]\n        \n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.budget > 0:\n            if self.iteration % self.clustering_interval == 0:\n                self.cluster_population()\n\n            for subpop_indices in self.subpopulations:\n                self.differential_evolution(func, subpop_indices)\n                if self.budget <= 0:\n                    break\n\n            self.local_search(func)\n            if self.budget <= 0:\n                break\n\n            self.iteration += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "An exception occurred: name 'KMeans' is not defined.", "error": "", "parent_ids": ["9dea8105-eea3-4ca1-8ea0-b63cad83644d"], "operator": null, "metadata": {}}
{"id": "78757051-ab57-4758-8ce1-3391d37dd993", "fitness": 0.0, "name": "AdaptiveDEwithAgingandOpposition", "description": "An Adaptive Differential Evolution with a Novel Mutation Strategy based on Opposition-Based Learning and an Aging Mechanism to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveDEwithAgingandOpposition:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=50, aging_rate=0.01, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.aging_rate = aging_rate\n        self.F = F\n        self.Cr = Cr\n        self.archive = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = None\n        self.fitness = None\n        self.ages = None\n\n\n    def __call__(self, func):\n        # Initialize population\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.ages = np.zeros(self.pop_size)\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Increase age\n                self.ages[i] += self.aging_rate\n\n                # Adaptive F and Cr (simplified for now, can be enhanced later)\n                F = self.F\n                Cr = self.Cr\n\n                # Mutation with opposition-based learning\n                if np.random.rand() < 0.5:  # Apply opposition with a probability\n                    opposition = func.bounds.ub + func.bounds.lb - self.population[i]\n                    if func(opposition) < self.fitness[i]:\n                        mutant = opposition\n                    else:\n                        indices = np.random.choice(self.pop_size, size=3, replace=False)\n                        a, b, c = indices[0], indices[1], indices[2]\n                        mutant = self.population[a] + F * (self.population[b] - self.population[c])\n                else:\n                    indices = np.random.choice(self.pop_size, size=3, replace=False)\n                    a, b, c = indices[0], indices[1], indices[2]\n                    mutant = self.population[a] + F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    if self.fitness[i] < self.f_opt:\n                        self.archive.append(self.population[i])\n                        if len(self.archive) > self.archive_size:\n                            self.archive.pop(0)\n\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    self.ages[i] = 0  # Reset age\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    # Replace with a random archive member if old\n                    if self.ages[i] > 1.0 and len(self.archive) > 0:\n                        self.population[i] = self.archive[np.random.randint(len(self.archive))]\n                        self.fitness[i] = func(self.population[i])\n                        self.ages[i] = 0\n                        self.budget -= 1\n                        if self.budget <= 0:\n                            break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDEwithAgingandOpposition scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cbf38d94-b6ef-4882-a861-fa3ea9d17741"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "941177d3-9e33-4062-b3bb-12e133ae5448", "fitness": -Infinity, "name": "AdaptiveDESOMCauchyLS", "description": "Adaptive Differential Evolution with a self-organizing map (SOM) for population diversity maintenance, archive-based mutation, and a Cauchy mutation-based local search with dynamic step size.", "code": "import numpy as np\nfrom minisom import MiniSom  # You might need to install this: pip install MiniSom\n\nclass AdaptiveDESOMCauchyLS:\n    def __init__(self, budget=10000, dim=10, pop_size=20, som_grid_size=5, archive_size=50, ls_prob=0.1, ls_step_size=0.1, ls_decay=0.95, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.som_grid_size = som_grid_size\n        self.archive_size = archive_size\n        self.ls_prob = ls_prob\n        self.ls_step_size = ls_step_size\n        self.ls_decay = ls_decay\n        self.F = F\n        self.Cr = Cr\n        self.archive = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.som = MiniSom(som_grid_size, som_grid_size, dim, sigma=0.3, learning_rate=0.5)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        # Train initial SOM\n        self.som.train(population, 100)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation using SOM and Archive\n                if np.random.rand() < 0.5 and len(self.archive) > 0:\n                    # Archive-based mutation\n                    idx = np.random.randint(len(self.archive))\n                    x_archive = self.archive[idx]\n\n                    indices = np.random.choice(self.pop_size, size=2, replace=False)\n                    a, b = indices[0], indices[1]\n                    mutant = population[i] + self.F * (x_archive - population[a]) + self.F * (population[b] - population[i]) # Perturb current pop member with archive and two random\n                else:\n                    # SOM-guided mutation\n                    winner_node = self.som.winner(population[i])\n                    weights = self.som.get_weights()[winner_node[0], winner_node[1]] # Get weights of winning neuron\n                    indices = np.random.choice(self.pop_size, size=2, replace=False)\n                    a, b = indices[0], indices[1]\n                    mutant = population[i] + self.F * (weights - population[a]) + self.F * (population[b] - population[i]) # Perturb current pop member with SOM and two random\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                trial[mask] = mutant[mask]\n\n                # Cauchy Mutation based Local Search\n                if np.random.rand() < self.ls_prob:\n                    trial = self.cauchy_mutation_local_search(trial, func)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.archive.append(population[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update SOM with successful individuals\n                    self.som.update(trial, self.som.winner(trial), 0.1)  # Update SOM faster\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Adapt local search probability and step size\n            self.ls_prob *= self.ls_decay\n            self.ls_step_size *= self.ls_decay\n            self.ls_prob = np.clip(self.ls_prob, 0.01, 0.9)\n            self.ls_step_size = np.clip(self.ls_step_size, 1e-6, 0.1)\n\n            # Retrain SOM every few iterations\n            if self.budget % (self.pop_size * 5) == 0:\n                self.som.train(population, 50)  # Smaller training epochs\n\n        return self.f_opt, self.x_opt\n\n    def cauchy_mutation_local_search(self, x, func):\n        # Cauchy mutation based local search\n        new_x = x + self.ls_step_size * np.random.standard_cauchy(size=self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x", "configspace": "", "generation": 7, "feedback": "An exception occurred: No module named 'minisom'.", "error": "", "parent_ids": ["cbf38d94-b6ef-4882-a861-fa3ea9d17741"], "operator": null, "metadata": {}}
{"id": "ae109afd-b7f6-49e8-8cc5-02f6f29543a9", "fitness": 0.0, "name": "AdaptiveDEwithDynamicPopandEnhancedLS", "description": "Adaptive Differential Evolution with success-history based parameter adaptation, dynamic population size adjustment, and enhanced local search with both adaptive step size and direction.", "code": "import numpy as np\n\nclass AdaptiveDEwithDynamicPopandEnhancedLS:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, initial_local_search_prob=0.1, archive_size=100, ls_decay=0.99, ls_increase=1.01, ls_step_size=0.1, ls_step_decay=0.95, pop_size_decay=0.995, pop_size_increase=1.005):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_pop_size = pop_size  # Store initial population size\n        self.memory_size = memory_size\n        self.local_search_prob = initial_local_search_prob\n        self.archive_size = archive_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.ls_decay = ls_decay\n        self.ls_increase = ls_increase\n        self.ls_step_size = ls_step_size\n        self.ls_step_decay = ls_step_decay\n        self.successful_F = []\n        self.successful_Cr = []\n        self.pop_size_decay = pop_size_decay\n        self.pop_size_increase = pop_size_increase\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        previous_f_opt = self.f_opt\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history with weighted sampling\n                if self.successful_F:\n                    F = np.random.choice(self.successful_F)\n                else:\n                    F = 0.5  # Default value if no successful F values yet\n\n                if self.successful_Cr:\n                    Cr = np.random.choice(self.successful_Cr)\n                else:\n                    Cr = 0.9  # Default value if no successful Cr values yet\n\n                indices = np.random.choice(self.pop_size, size=3, replace=False)\n                a, b, c = indices[0], indices[1], indices[2]\n\n                # Differential Evolution Mutation\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.local_search(trial, func, population)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.archive.append(population[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    self.successful_F.append(F)\n                    self.successful_Cr.append(Cr)\n                    if len(self.successful_F) > self.memory_size:\n                        self.successful_F.pop(0)\n                        self.successful_Cr.pop(0)\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Dynamic population size adjustment\n            if self.f_opt < previous_f_opt:\n                self.local_search_prob = min(1.0, self.local_search_prob * self.ls_increase)\n                self.ls_step_size = min(0.1, self.ls_step_size/self.ls_step_decay)\n                self.pop_size = min(self.initial_pop_size * 2, int(self.pop_size * self.pop_size_increase)) #Increase\n            else:\n                self.local_search_prob = max(0.01, self.local_search_prob * self.ls_decay)\n                self.ls_step_size = max(1e-6, self.ls_step_size * self.ls_step_decay)\n                self.pop_size = max(10, int(self.pop_size * self.pop_size_decay)) #Decrease\n                if self.pop_size < population.shape[0]:\n                    indices_to_remove = np.argsort(fitness)[-1:-(population.shape[0] - self.pop_size)-1:-1]\n                    population = np.delete(population, indices_to_remove, axis=0)\n                    fitness = np.delete(fitness, indices_to_remove, axis=0)\n\n            previous_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func, population):\n        # Enhanced local search: explore around x, but also consider the direction towards the best solution\n        best_solution = population[np.argmin(np.array([func(xi) for xi in population]))]\n        direction = best_solution - x\n        step = np.random.uniform(-self.ls_step_size, self.ls_step_size, size=self.dim) + direction * self.ls_step_size # Combine random step with direction\n\n        new_x = x + step\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDEwithDynamicPopandEnhancedLS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cbf38d94-b6ef-4882-a861-fa3ea9d17741"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "7221aa52-d8ae-47c6-9eb1-4ffccbfc3097", "fitness": 0.0, "name": "AdaptiveDEwithSelfAdaptiveLocalSearchImproved", "description": "Adaptive Differential Evolution with Success-History based parameter adaptation, self-adaptive local search probability using separate success rates for F and Cr, an improved local search with adaptive step size and direction, and archive-based mutation.", "code": "import numpy as np\n\nclass AdaptiveDEwithSelfAdaptiveLocalSearchImproved:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, initial_local_search_prob=0.1, archive_size=100, ls_decay=0.99, ls_increase=1.01, ls_step_size=0.1, ls_step_decay=0.95, ls_success_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = initial_local_search_prob\n        self.archive_size = archive_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.ls_decay = ls_decay\n        self.ls_increase = ls_increase\n        self.ls_step_size = ls_step_size\n        self.ls_step_decay = ls_step_decay\n        self.successful_F = []\n        self.successful_Cr = []\n        self.ls_success_memory = ls_success_memory\n        self.ls_success_rates = np.zeros(self.ls_success_memory)\n        self.ls_success_idx = 0\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        previous_f_opt = self.f_opt\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history with weighted sampling\n                if self.successful_F:\n                    F = np.random.choice(self.successful_F)\n                else:\n                    F = 0.5  # Default value if no successful F values yet\n\n                if self.successful_Cr:\n                    Cr = np.random.choice(self.successful_Cr)\n                else:\n                    Cr = 0.9  # Default value if no successful Cr values yet\n\n                indices = np.random.choice(self.pop_size, size=3, replace=False)\n                a, b, c = indices[0], indices[1], indices[2]\n\n                # Differential Evolution Mutation using archive\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant = population[a] + F * (population[b] - self.archive[arc_idx])\n                else:\n                    mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial, ls_improved = self.local_search(trial, func)\n                else:\n                    ls_improved = False\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.archive.append(population[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    self.successful_F.append(F)\n                    self.successful_Cr.append(Cr)\n                    if len(self.successful_F) > self.memory_size:\n                        self.successful_F.pop(0)\n                        self.successful_Cr.pop(0)\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                    if ls_improved:\n                        self.ls_success_rates[self.ls_success_idx] = 1\n                    else:\n                        self.ls_success_rates[self.ls_success_idx] = 0\n                    self.ls_success_idx = (self.ls_success_idx + 1) % self.ls_success_memory\n\n            if self.f_opt < previous_f_opt:\n                self.local_search_prob = min(1.0, self.local_search_prob * self.ls_increase)\n                self.ls_step_size = min(0.1, self.ls_step_size/self.ls_step_decay)\n            else:\n                self.local_search_prob = max(0.01, self.local_search_prob * self.ls_decay)\n                self.ls_step_size = max(1e-6, self.ls_step_size * self.ls_step_decay)\n            previous_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func):\n        # Local search using random step with adaptive step size and adaptive direction\n        step = np.random.normal(0, self.ls_step_size, size=self.dim)\n        new_x = x + step\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_x)\n\n        if f_new < func(x):\n            return new_x, True\n        else:\n            # Try the opposite direction\n            new_x = x - step\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            f_new = func(new_x)\n            if f_new < func(x):\n                return new_x, True\n            else:\n                return x, False", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDEwithSelfAdaptiveLocalSearchImproved scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cbf38d94-b6ef-4882-a861-fa3ea9d17741"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "4252bc1b-cf32-455e-8de5-c29b0cfd98e8", "fitness": -Infinity, "name": "AdaptiveDESOMCMA", "description": "Adaptive Differential Evolution with a self-organizing map (SOM) for parameter control, opposition-based learning for diversity, an archive for experience replay, and a CMA-ES-inspired local search for refinement.", "code": "import numpy as np\n\nclass AdaptiveDESOMCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=20, som_grid_size=5, learning_rate=0.1, sigma=1.0, archive_size=10, local_search_prob=0.1, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.som_grid_size = som_grid_size\n        self.learning_rate = learning_rate\n        self.sigma = sigma\n        self.archive_size = archive_size\n        self.archive = []\n        self.archive_fitness = []\n        self.F_values = np.random.uniform(0.1, 1.0, size=self.pop_size)\n        self.Cr_values = np.random.uniform(0.1, 1.0, size=self.pop_size)\n        self.local_search_prob = local_search_prob\n        self.local_search_radius = local_search_radius\n        \n        # Initialize SOM\n        self.som = np.random.rand(self.som_grid_size, self.som_grid_size, 2)  # 2 for F and Cr\n        self.neighborhood_function = lambda dist: np.exp(-dist**2 / (2 * self.sigma**2))\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        # Initialize CMA-ES-like parameters for local search\n        sigma_ls = self.local_search_radius * np.ones(self.dim)  # Individual step sizes\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim) # Evolution path for C\n        ps = np.zeros(self.dim) # Evolution path for sigma\n        damps = 1 + self.dim / 2 # Damping for sigma\n        mu_eff = self.pop_size / 4\n        weights = np.log(mu_eff + 1/2) - np.log(np.arange(1,int(self.pop_size/2) + 1))\n        weights = weights / np.sum(weights)\n        cs = (mu_eff + 2) / (self.dim + mu_eff + 5)\n        cc = (4 + mu_eff/self.dim) / (self.dim + 4 + 2*mu_eff/self.dim)\n        c1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n        cmu = min(1-c1, 2 * (mu_eff - 2 + 1/mu_eff) / ((self.dim+2.3)**2 + mu_eff))\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # SOM-based parameter adaptation\n                best_matching_unit = self.find_best_matching_unit(self.F_values[i], self.Cr_values[i])\n                \n                # Update F and Cr based on BMU\n                F = self.som[best_matching_unit[0], best_matching_unit[1], 0]\n                Cr = self.som[best_matching_unit[0], best_matching_unit[1], 1]\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                # Differential Evolution Mutation with Opposition-Based Learning\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n\n                # Opposition-Based Learning for diversity\n                opposition = func.bounds.lb + func.bounds.ub - population[i]\n                if np.random.rand() < 0.1: # Introduce opposition-based learning with a small probability\n                    mutant = opposition\n\n                # Add archive component to mutation\n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += F * (self.archive[arc_idx] - population[i]) * 0.1  # Scale down the archive influence\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        worst_archive_idx = np.argmax(self.archive_fitness)\n                        if fitness[i] < self.archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = population[i]\n                            self.archive_fitness[worst_archive_idx] = fitness[i]\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update SOM - adjust the network towards the selected F and Cr\n                    self.update_som(best_matching_unit, F, Cr)\n                    self.F_values[i] = F\n                    self.Cr_values[i] = Cr\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                        # Local Search around the new best\n                        if np.random.rand() < self.local_search_prob:\n                            self.x_opt, self.f_opt, sigma_ls, C, pc, ps = self.local_search(func, self.x_opt, sigma_ls, C, pc, ps, weights, cs, cc, c1, cmu, damps)\n\n        return self.f_opt, self.x_opt\n\n    def find_best_matching_unit(self, F, Cr):\n        min_dist = np.inf\n        bmu = None\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                dist = np.sqrt((self.som[i, j, 0] - F)**2 + (self.som[i, j, 1] - Cr)**2)\n                if dist < min_dist:\n                    min_dist = dist\n                    bmu = (i, j)\n        return bmu\n\n    def update_som(self, bmu, F, Cr):\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                dist = np.sqrt((i - bmu[0])**2 + (j - bmu[1])**2)\n                influence = self.neighborhood_function(dist)\n                self.som[i, j, 0] += self.learning_rate * influence * (F - self.som[i, j, 0])\n                self.som[i, j, 1] += self.learning_rate * influence * (Cr - self.som[i, j, 1])\n    \n    def local_search(self, func, x_opt, sigma_ls, C, pc, ps, weights, cs, cc, c1, cmu, damps, num_points=5):\n        best_x = x_opt\n        best_f = self.f_opt\n\n        # Sample around the current best\n        z = np.random.normal(0, 1, size=(self.dim, num_points))\n        y = sigma_ls[:,None] * np.dot(np.linalg.cholesky(C), z)\n        x = x_opt[:,None] + y\n        x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n        f = np.array([func(xi) for xi in x.T])\n        self.budget -= num_points\n\n        if self.budget <= 0:\n            return best_x, best_f, sigma_ls, C, pc, ps\n\n        # Update best\n        best_idx = np.argmin(f)\n        if f[best_idx] < best_f:\n            best_f = f[best_idx]\n            best_x = x[:, best_idx]\n\n        # Update CMA-ES parameters\n        y_mean = np.sum(weights[:,None] * y[:, np.argsort(f)[:int(self.pop_size/2)]], axis=1)\n        ps = (1-cs) * ps + np.sqrt(cs*(2-cs)) * y_mean / sigma_ls\n        sigma_ls *= np.exp((cs/damps)*(np.linalg.norm(ps)/np.sqrt(self.dim)-1))\n        sigma_ls = np.clip(sigma_ls, self.local_search_radius/100, 2 * self.local_search_radius)\n\n        pc = (1-cc) * pc + np.sqrt(cc*(2-cc)) * y_mean\n        C = (1-c1-cmu) * C + c1 * (np.outer(pc,pc) + (1-cc) * C)\n        C += cmu * np.sum([w * np.outer(y[:,i], y[:,i]) for i, w in enumerate(weights)], axis=0)\n        C = np.triu(C) + np.triu(C,1).T # enforce symmetry\n        C = C / np.linalg.norm(C) # Rescaling C may improve numerical stability\n        \n        return best_x, best_f, sigma_ls, C, pc, ps", "configspace": "", "generation": 7, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,5) (2,) (2,) .", "error": "", "parent_ids": ["8a150427-1cd8-4090-aaed-6cb156cc8905"], "operator": null, "metadata": {}}
{"id": "a0e69583-8314-48ff-8b61-ca508f105b72", "fitness": 0.1737621514846277, "name": "CMAESPopulation", "description": "Covariance matrix adaptation evolution strategy with a population-based approach, incorporating adaptive mutation strength and a restart mechanism based on population diversity.", "code": "import numpy as np\n\nclass CMAESPopulation:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_sigma=0.1, mu_ratio=0.25,\n                 cs=0.3, damps=1.0, c_cov_mean=None, c_cov_rank_one=None,\n                 restart_trigger=1e-12, restart_factor=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = max(1, int(self.pop_size * mu_ratio))\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mu_eff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        \n        self.initial_sigma = initial_sigma\n        self.sigma = self.initial_sigma\n        self.mean = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.D = np.ones(self.dim)  # Eigenvalues of C\n        self.B = np.eye(self.dim)  # Eigenvectors of C\n        \n        self.cs = cs\n        self.damps = damps + (self.mu_eff / self.dim + 2) if damps is None else damps\n        self.pc = np.zeros(self.dim)\n        \n        self.c_cov_mean = c_cov_mean if c_cov_mean is not None else self.mu_eff / (self.dim + (self.mu_eff + 2))\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 2 / ((self.dim + 1.3)**2 + self.mu_eff)\n        self.c_cov_mu = min(1 - self.c_cov_rank_one, (2 * (self.mu_eff - 2 + 1/self.mu_eff)) / ((self.dim + 2)**2 + self.mu_eff))\n        \n        self.restart_trigger = restart_trigger\n        self.restart_factor = restart_factor\n\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.gen_count = 0\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n\n        while self.budget - self.eval_count > 0:\n            self.gen_count += 1\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            y = self.B.dot(np.diag(self.D)).dot(z.T).T\n            x = self.mean + self.sigma * y\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n            if self.eval_count > self.budget:\n                fitness = fitness[:self.pop_size - (self.eval_count - self.budget)]\n                x = x[:self.pop_size - (self.eval_count - self.budget)]\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n            \n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n                \n            # Calculate weighted mean\n            xmean = np.sum(x[:self.mu] * self.weights[:, None], axis=0)\n            ymean = np.sum(y[:self.mu] * self.weights[:, None], axis=0)\n            \n            # Update evolution path\n            self.pc = (1 - self.cs) * self.pc + np.sqrt(self.cs * (2 - self.cs) * self.mu_eff) * ymean\n            \n            # Update covariance matrix\n            delta = (1 - self.c_cov_mean - self.c_cov_mu)\n            C_temp = delta * self.C + self.c_cov_mean * np.outer(self.pc, self.pc)\n            C_temp += self.c_cov_mu * np.sum(self.weights[:, None, None] * y[:self.mu, :, None] * y[:self.mu, None, :], axis=0)\n            self.C = np.triu(C_temp) + np.triu(C_temp, k=1).T\n            \n            # Adapt step size\n            self.mean = xmean\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.pc) / np.sqrt(self.dim) - 1))\n            \n            # Eigenvalue decomposition\n            try:\n                self.D, self.B = np.linalg.eigh(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim)\n                self.D, self.B = np.linalg.eigh(self.C)\n            self.D = np.sqrt(np.maximum(self.D, 0))\n\n            # Restart mechanism\n            if np.min(self.D) < self.restart_trigger or np.max(self.D) > (self.restart_factor * np.median(self.D)):\n                self.C = np.eye(self.dim)\n                self.D = np.ones(self.dim)\n                self.B = np.eye(self.dim)\n                self.sigma = self.initial_sigma\n                self.pc = np.zeros(self.dim)\n                self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm CMAESPopulation scored 0.174 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cbf38d94-b6ef-4882-a861-fa3ea9d17741"], "operator": null, "metadata": {"aucs": [0.1353935343421746, 0.15971735584500857, 0.2140292016060874, 0.1649625982511872, 0.1551684913277882, 0.1477219083637199, 0.16517644971289425, 0.1676296150066683, 0.170622853460483, 0.12015612902382367, 0.12777074513689035, 0.24592984109631866, 0.15343782388649652, 0.1813462238036695, 0.14454914282027131, 0.19809601575474634, 0.1661487997583012, 0.1669830166425672, 0.14070661039278654, 0.3496966734606711]}}
{"id": "ebe5839e-d2df-4ab9-a60a-cd4f487ab950", "fitness": 0.7643004249839254, "name": "AdaptiveDEwithSelfAdaptiveLocalSearchImprovedMomentum", "description": "Adaptive Differential Evolution with Success-History based parameter adaptation, self-adaptive local search probability using separate success rates for F and Cr, improved local search with adaptive step size and momentum-based adaptation.", "code": "import numpy as np\n\nclass AdaptiveDEwithSelfAdaptiveLocalSearchImprovedMomentum:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, initial_local_search_prob=0.1, archive_size=100, ls_decay=0.99, ls_increase=1.01, ls_step_size=0.1, ls_step_decay=0.95, momentum_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = initial_local_search_prob\n        self.archive_size = archive_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.ls_decay = ls_decay\n        self.ls_increase = ls_increase\n        self.ls_step_size = ls_step_size\n        self.ls_step_decay = ls_step_decay\n        self.successful_F = []\n        self.successful_Cr = []\n        self.momentum_factor = momentum_factor\n        self.velocity = np.zeros(dim) # Velocity for momentum\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        previous_f_opt = self.f_opt\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history with weighted sampling\n                if self.successful_F:\n                    F = np.random.choice(self.successful_F)\n                else:\n                    F = 0.5  # Default value if no successful F values yet\n\n                if self.successful_Cr:\n                    Cr = np.random.choice(self.successful_Cr)\n                else:\n                    Cr = 0.9  # Default value if no successful Cr values yet\n\n                indices = np.random.choice(self.pop_size, size=3, replace=False)\n                a, b, c = indices[0], indices[1], indices[2]\n\n                # Differential Evolution Mutation\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.local_search(trial, func)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.archive.append(population[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    self.successful_F.append(F)\n                    self.successful_Cr.append(Cr)\n                    if len(self.successful_F) > self.memory_size:\n                        self.successful_F.pop(0)\n                        self.successful_Cr.pop(0)\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            if self.f_opt < previous_f_opt:\n                self.local_search_prob = min(1.0, self.local_search_prob * self.ls_increase)\n                self.ls_step_size = min(0.1, self.ls_step_size/self.ls_step_decay)\n            else:\n                self.local_search_prob = max(0.01, self.local_search_prob * self.ls_decay)\n                self.ls_step_size = max(1e-6, self.ls_step_size * self.ls_step_decay)\n            previous_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func):\n        # Local search using random step with adaptive step size and momentum\n        rand_vector = np.random.uniform(-self.ls_step_size, self.ls_step_size, size=self.dim)\n        self.velocity = self.momentum_factor * self.velocity + (1 - self.momentum_factor) * rand_vector\n        new_x = x + self.velocity\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDEwithSelfAdaptiveLocalSearchImprovedMomentum scored 0.764 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cbf38d94-b6ef-4882-a861-fa3ea9d17741"], "operator": null, "metadata": {"aucs": [0.5437144665034594, 0.8539012953607619, 0.8375864030073052, 0.935437625090947, 0.8800712471986087, 0.9159492139658962, 0.8354957960886786, 0.8386114578881572, 0.8934528367755856, 0.3770172495303039, 0.8280654878133357, 0.998966448597615, 0.2892021787251363, 0.8955836398867314, 0.9592399802088217, 0.9084785881295727, 0.8497741136021265, 0.8970669312866452, 0.23964758597417313, 0.5087459540446453]}}
{"id": "83e98317-2e7e-443d-b9e3-9eb5a7a494e8", "fitness": 0.6149670943788013, "name": "EnhancedAdaptiveDE", "description": "Enhanced Adaptive DE with a CMA-ES-inspired mutation, an archive, orthogonal crossover, and a self-adaptive local search probability based on the success rate.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, local_search_prob=0.1, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = local_search_prob\n        self.archive_size = archive_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.archive_fitness = []\n        self.success_F = []\n        self.success_Cr = []\n        self.generation = 0\n        self.success_count = 0\n        self.failure_count = 0\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            self.generation += 1\n            # Adjust local search probability based on success rate\n            if self.success_count + self.failure_count > 10:\n                success_rate = self.success_count / (self.success_count + self.failure_count)\n                self.local_search_prob = np.clip(success_rate, 0.05, 0.5)  # Keep it within reasonable bounds\n                self.success_count = 0\n                self.failure_count = 0\n\n            for i in range(self.pop_size):\n                # Parameter adaptation using sinusoidal function and success history\n                period = 100  # Sinusoidal period\n                F = 0.5 + 0.4 * np.sin(2 * np.pi * self.generation / period)\n                Cr = 0.9 + 0.09 * np.cos(2 * np.pi * self.generation / period)\n\n                if self.success_F:\n                    weights = np.abs(np.array(self.success_Cr))  # Use success Cr for weighting\n                    weights /= weights.sum() + 1e-6  # avoid division by zero\n                    F = 0.5 * F + 0.5 * np.sum(np.array(self.success_F) * weights)\n                    Cr = 0.5 * Cr + 0.5 * np.sum(np.array(self.success_Cr) * weights)\n\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                # Differential Evolution Mutation with CMA-ES-inspired adaptation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n\n                # Archive component to mutation\n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += F * (self.archive[arc_idx] - population[i]) * 0.1  # Scale down the archive influence\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Dual Local Search\n                if np.random.rand() < self.local_search_prob:\n                    # Local Search 1: Small perturbation\n                    trial1 = trial + np.random.normal(0, 0.05, self.dim)\n                    trial1 = np.clip(trial1, func.bounds.lb, func.bounds.ub)\n\n                    # Local Search 2: Larger perturbation with decreasing intensity\n                    intensity = 0.1 * np.exp(-self.generation / 500)  # Decaying intensity\n                    trial2 = trial + np.random.normal(0, intensity, self.dim)\n                    trial2 = np.clip(trial2, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate both local searches and choose the better one\n                    f_trial1 = func(trial1)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    f_trial2 = func(trial2)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if f_trial1 < f_trial2:\n                        f_trial = f_trial1\n                        trial = trial1\n                    else:\n                        f_trial = f_trial2\n                        trial = trial2\n                    \n                    if f_trial < fitness[i]:\n                        self.success_count += 1\n                    else:\n                        self.failure_count += 1\n\n                else:\n                    f_trial = func(trial)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    if f_trial < fitness[i]:\n                        self.success_count += 1\n                    else:\n                        self.failure_count += 1\n\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        worst_archive_idx = np.argmax(self.archive_fitness)\n                        if fitness[i] < self.archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = population[i]\n                            self.archive_fitness[worst_archive_idx] = fitness[i]\n\n                    self.success_F.append(F)\n                    self.success_Cr.append(Cr)\n                    if len(self.success_F) > self.memory_size:\n                        self.success_F.pop(0)\n                        self.success_Cr.pop(0)\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedAdaptiveDE scored 0.615 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["73d444e3-2c72-4484-9d2c-c5400d7c005e"], "operator": null, "metadata": {"aucs": [0.2149999815932887, 0.7803012499363711, 0.4627226929288857, 0.8991581294552485, 0.6912444393685272, 0.8531339575810901, 0.3533780668153661, 0.41220852323628787, 0.7762002115554922, 0.7864237836006174, 0.8888757088540404, 0.9884943541672176, 0.3816188184271918, 0.5094729949844872, 0.5864241276008427, 0.7597312964392643, 0.4318342052404873, 0.6958729007274442, 0.30652212638213017, 0.5207243186817443]}}
{"id": "25f40be8-02b4-42e8-add7-c6a4b86ee163", "fitness": 0.6293245027991436, "name": "EnhancedAdaptiveDE", "description": "Enhanced Adaptive Differential Evolution with a self-adaptive population size, restart mechanism, and improved local search.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, local_search_prob=0.1, archive_size=10, restart_trigger=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.min_pop_size = 5  # Minimum population size\n        self.max_pop_size = 50 # Maximum population size\n        self.memory_size = memory_size\n        self.local_search_prob = local_search_prob\n        self.archive_size = archive_size\n        self.restart_trigger = restart_trigger\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.archive_fitness = []\n        self.success_F = []\n        self.success_Cr = []\n        self.generation = 0\n        self.no_improvement_count = 0\n        self.last_improvement_gen = 0\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        self.last_improvement_gen = 0\n\n        while self.budget > 0:\n            self.generation += 1\n            \n            # Adaptive Population Size\n            if self.generation - self.last_improvement_gen > self.restart_trigger:\n                self.no_improvement_count +=1\n                self.pop_size = max(self.min_pop_size, int(self.pop_size * 0.75))  # Reduce population size\n                print(f\"Restarting with smaller pop size: {self.pop_size} at gen: {self.generation}\")\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n                self.last_improvement_gen = self.generation\n                \n            else:\n                self.no_improvement_count = 0\n                \n            if self.no_improvement_count > 3:\n                self.pop_size = min(self.max_pop_size, self.pop_size + 5)\n                print(f\"Increasing pop size: {self.pop_size} at gen: {self.generation}\")\n                new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(5, self.dim))\n                new_fitness = np.array([func(x) for x in new_individuals])\n                self.budget -= 5\n                population = np.vstack((population, new_individuals))\n                fitness = np.concatenate((fitness, new_fitness))\n\n            for i in range(self.pop_size):\n                # Parameter adaptation using sinusoidal function and success history\n                period = 100  # Sinusoidal period\n                F = 0.5 + 0.4 * np.sin(2 * np.pi * self.generation / period)\n                Cr = 0.9 + 0.09 * np.cos(2 * np.pi * self.generation / period)\n\n                if self.success_F:\n                    weights = np.abs(np.array(self.success_Cr))  # Use success Cr for weighting\n                    weights /= weights.sum()\n                    F = 0.5 * F + 0.5 * np.sum(np.array(self.success_F) * weights)\n                    Cr = 0.5 * Cr + 0.5 * np.sum(np.array(self.success_Cr) * weights)\n\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n\n                # Cauchy mutation to escape local optima\n                cauchy_mask = np.random.rand(self.dim) < 0.05  # Apply Cauchy mutation with a small probability\n                mutant[cauchy_mask] += 0.1 * np.random.standard_cauchy(size=np.sum(cauchy_mask))\n\n                # Archive component to mutation\n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += F * (self.archive[arc_idx] - population[i]) * 0.1  # Scale down the archive influence\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Dual Local Search - Improved\n                if np.random.rand() < self.local_search_prob:\n                    # Local Search 1: Small perturbation\n                    step_size1 = 0.01 + 0.04 * np.exp(-self.generation / 300)\n                    trial1 = trial + np.random.normal(0, step_size1, self.dim)\n                    trial1 = np.clip(trial1, func.bounds.lb, func.bounds.ub)\n\n                    # Local Search 2: Larger perturbation with decreasing intensity\n                    intensity = 0.1 * np.exp(-self.generation / 500)  # Decaying intensity\n                    trial2 = trial + np.random.normal(0, intensity, self.dim)\n                    trial2 = np.clip(trial2, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate both local searches and choose the better one\n                    f_trial1 = func(trial1)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    f_trial2 = func(trial2)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if f_trial1 < f_trial2:\n                        f_trial = f_trial1\n                        trial = trial1\n                    else:\n                        f_trial = f_trial2\n                        trial = trial2\n                else:\n                    f_trial = func(trial)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        worst_archive_idx = np.argmax(self.archive_fitness)\n                        if fitness[i] < self.archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = population[i]\n                            self.archive_fitness[worst_archive_idx] = fitness[i]\n\n                    self.success_F.append(F)\n                    self.success_Cr.append(Cr)\n                    if len(self.success_F) > self.memory_size:\n                        self.success_F.pop(0)\n                        self.success_Cr.pop(0)\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.last_improvement_gen = self.generation\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedAdaptiveDE scored 0.629 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["73d444e3-2c72-4484-9d2c-c5400d7c005e"], "operator": null, "metadata": {"aucs": [0.24086170360467896, 0.336645619047798, 0.6277848036338705, 0.918245259479998, 0.574094357683125, 0.8050375491881948, 0.7357355978881694, 0.6759542087434309, 0.5611558751017921, 0.559372679921434, 0.9077619004124027, 0.9943120538332728, 0.3720268024896485, 0.5295411982816678, 0.8632058214346527, 0.6924925006140012, 0.4398701175475813, 0.8299074040127579, 0.39129877731913, 0.5311858257452644]}}
{"id": "4f24c54c-675e-4135-a755-b16198079fa6", "fitness": -Infinity, "name": "DynamicDE", "description": "Differential Evolution with a dynamically adjusted population size and a distance-based mutation strategy that emphasizes exploration in sparse regions of the search space.", "code": "import numpy as np\n\nclass DynamicDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=20, min_pop_size=5, max_pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.generation = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def adjust_population_size(self):\n        # Dynamically adjust population size based on stagnation\n        if self.generation > 50:\n            if np.std(self.fitness) < 1e-6:  # Stagnation detected\n                self.pop_size = max(self.min_pop_size, int(self.pop_size * 0.8))  # Reduce population size\n            else:\n                if self.pop_size < self.max_pop_size and np.random.rand() < 0.05:\n                    self.pop_size = min(self.max_pop_size, self.pop_size + 1) # increase population size with a probability\n\n            new_population = np.random.uniform(self.x_opt - 0.1, self.x_opt + 0.1, size=(self.pop_size - len(self.population), self.dim))\n            self.population = np.vstack((self.population, new_population))\n            new_fitness = np.array([func(x) for x in new_population])\n            self.fitness = np.append(self.fitness, new_fitness)\n            self.budget -= len(new_population)\n\n\n    def distance_based_mutation(self, i):\n        # Distance-based mutation strategy\n        distances = np.linalg.norm(self.population - self.population[i], axis=1)\n        distances[i] = np.inf  # Exclude the current individual\n\n        # Find the farthest individuals\n        farthest_idx = np.argmax(distances)\n        \n        idxs = [idx for idx in range(self.pop_size) if idx != i and idx != farthest_idx]\n        if len(idxs) < 2:\n            a, b = 0, 1 # select first 2 if idxs is not long enough\n        else:\n             a, b = np.random.choice(idxs, 2, replace=False)\n        \n        mutant = self.population[i] + 0.5 * (self.population[farthest_idx] - self.population[i]) + 0.5 * (self.population[a] - self.population[b])\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n        return mutant\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            self.generation += 1\n            self.adjust_population_size()\n            \n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                mutant = self.distance_based_mutation(i)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                mask = np.random.rand(self.dim) < 0.7  # Cr = 0.7\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "An exception occurred: name 'func' is not defined.", "error": "", "parent_ids": ["73d444e3-2c72-4484-9d2c-c5400d7c005e"], "operator": null, "metadata": {}}
{"id": "48d62359-f969-474d-a9c7-54d11c67460b", "fitness": 0.4716286543389791, "name": "AdaptiveDEwithSelfAdaptiveLocalSearchDiversity", "description": "Adaptive Differential Evolution with success-history parameter adaptation, self-adaptive local search probability and step size, combined with a population diversity mechanism based on the distance to the population center.", "code": "import numpy as np\n\nclass AdaptiveDEwithSelfAdaptiveLocalSearchDiversity:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, initial_local_search_prob=0.1, archive_size=100, ls_decay=0.99, ls_increase=1.01, ls_step_size=0.1, ls_step_decay=0.95, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = initial_local_search_prob\n        self.archive_size = archive_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.ls_decay = ls_decay\n        self.ls_increase = ls_increase\n        self.ls_step_size = ls_step_size\n        self.ls_step_decay = ls_step_decay\n        self.successful_F = []\n        self.successful_Cr = []\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        previous_f_opt = self.f_opt\n\n        while self.budget > 0:\n            # Calculate population center\n            pop_center = np.mean(population, axis=0)\n            \n            for i in range(self.pop_size):\n                # Parameter adaptation using success history with weighted sampling\n                if self.successful_F:\n                    F = np.random.choice(self.successful_F)\n                else:\n                    F = 0.5  # Default value if no successful F values yet\n\n                if self.successful_Cr:\n                    Cr = np.random.choice(self.successful_Cr)\n                else:\n                    Cr = 0.9  # Default value if no successful Cr values yet\n\n                indices = np.random.choice(self.pop_size, size=3, replace=False)\n                a, b, c = indices[0], indices[1], indices[2]\n\n                # Differential Evolution Mutation\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n                \n                # Diversity maintenance: If individual is too close to the population center, perturb it\n                if np.linalg.norm(population[i] - pop_center) < self.diversity_threshold:\n                    trial = np.random.uniform(func.bounds.lb, func.bounds.ub)\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.local_search(trial, func)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.archive.append(population[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    self.successful_F.append(F)\n                    self.successful_Cr.append(Cr)\n                    if len(self.successful_F) > self.memory_size:\n                        self.successful_F.pop(0)\n                        self.successful_Cr.pop(0)\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            if self.f_opt < previous_f_opt:\n                self.local_search_prob = min(1.0, self.local_search_prob * self.ls_increase)\n                self.ls_step_size = min(0.1, self.ls_step_size/self.ls_step_decay)\n            else:\n                self.local_search_prob = max(0.01, self.local_search_prob * self.ls_decay)\n                self.ls_step_size = max(1e-6, self.ls_step_size * self.ls_step_decay)\n            previous_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func):\n        # Local search using random step with adaptive step size\n        new_x = x + np.random.uniform(-self.ls_step_size, self.ls_step_size, size=self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDEwithSelfAdaptiveLocalSearchDiversity scored 0.472 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cbf38d94-b6ef-4882-a861-fa3ea9d17741"], "operator": null, "metadata": {"aucs": [0.27652850015892494, 0.2867308548480383, 0.45525741691977994, 0.5011734974717864, 0.35703831339068914, 0.4588352774073129, 0.4653385617416044, 0.38051690476174804, 0.3778669336634264, 0.237522856747858, 0.9473829280225957, 0.9991486881537721, 0.41149671251665976, 0.34720541513244474, 0.7667267075986068, 0.470609700506726, 0.3867183491780186, 0.5409707323229054, 0.22060548629425802, 0.5448992499424267]}}
{"id": "6d5064d2-0fc0-4182-ae1a-84aad4430963", "fitness": -Infinity, "name": "AdaptiveDEwithOppositionAndAging", "description": "Adaptive Differential Evolution with a modified mutation strategy incorporating opposition-based learning and a Cauchy distributed random variable, combined with an aging mechanism for population diversity.", "code": "import numpy as np\n\nclass AdaptiveDEwithOppositionAndAging:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, initial_F=0.5, initial_Cr=0.9, aging_rate=0.01, opposition_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.F_memory = np.ones(self.memory_size) * initial_F\n        self.Cr_memory = np.ones(self.memory_size) * initial_Cr\n        self.archive = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.aging_rate = aging_rate\n        self.opposition_rate = opposition_rate\n        self.population_age = np.zeros(self.pop_size)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history\n                F = np.random.choice(self.F_memory)\n                Cr = np.random.choice(self.Cr_memory)\n\n                indices = np.random.choice(self.pop_size, size=3, replace=False)\n                a, b, c = indices[0], indices[1], indices[2]\n\n                # Opposition-based learning\n                if np.random.rand() < self.opposition_rate:\n                    opposition_point = func.bounds.lb + func.bounds.ub - population[i]\n                    \n                    if func(opposition_point) < fitness[i]:\n                       population[i] = opposition_point\n                       fitness[i] = func(opposition_point)\n                       if fitness[i] < self.f_opt:\n                            self.f_opt = fitness[i]\n                            self.x_opt = population[i]\n\n                # Modified Mutation with Cauchy distribution\n                cauchy_rand = np.random.standard_cauchy(size=self.dim) * 0.1  # Scale the Cauchy distribution\n                mutant = population[a] + F * (population[b] - population[c]) + cauchy_rand\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.archive.append(population[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    self.population_age[i] = 0  # Reset age\n\n                    # Update memory\n                    self.F_memory = np.concatenate(([F], self.F_memory[:-1]))\n                    self.Cr_memory = np.concatenate(([Cr], self.Cr_memory[:-1]))\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                   self.population_age[i] += 1\n\n            # Aging mechanism: replace old individuals\n            for i in range(self.pop_size):\n                if self.population_age[i] > (1.0 / self.aging_rate): # Old individual\n                    population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    fitness[i] = func(population[i])\n                    self.budget -=1\n                    self.population_age[i] = 0\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = population[i]\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occurred: 'AdaptiveDEwithOppositionAndAging' object has no attribute 'archive_size'.", "error": "", "parent_ids": ["ebe5839e-d2df-4ab9-a60a-cd4f487ab950"], "operator": null, "metadata": {}}
{"id": "b77f35f6-6310-40b3-961f-8f3750279295", "fitness": -Infinity, "name": "ReinforcementLearningDE", "description": "Adaptive Differential Evolution with a reinforcement learning-based parameter selection, experience replay, and a dynamically adjusted local search region.", "code": "import numpy as np\nimport collections\n\nclass ReinforcementLearningDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, initial_learning_rate=0.1, learning_rate_decay=0.99, exploration_rate=0.2, exploration_decay=0.995, local_search_prob=0.1, ls_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.learning_rate = initial_learning_rate\n        self.learning_rate_decay = learning_rate_decay\n        self.exploration_rate = exploration_rate\n        self.exploration_decay = exploration_decay\n        self.local_search_prob = local_search_prob\n        self.ls_scale = ls_scale\n        self.Q_table = collections.defaultdict(lambda: np.zeros(3)) # Q-table for F, Cr, LS choices\n        self.memory = collections.deque(maxlen=memory_size)\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Choose action based on epsilon-greedy policy\n                state = self.discretize_state(fitness[i])\n                if np.random.rand() < self.exploration_rate:\n                    action = np.random.randint(0, 3)  # 0: F, 1: Cr, 2: Local Search\n                else:\n                    action = np.argmax(self.Q_table[state])\n\n                # Generate parameters based on action\n                if action == 0:  # F\n                    F = np.random.uniform(0.1, 0.9)\n                    Cr = 0.9 # Fixed Cr\n                    trial = self.de_mutation(population, i, F, Cr, func.bounds.lb, func.bounds.ub)\n                elif action == 1:  # Cr\n                    Cr = np.random.uniform(0.1, 0.9)\n                    F = 0.5 # Fixed F\n                    trial = self.de_mutation(population, i, F, Cr, func.bounds.lb, func.bounds.ub)\n\n                else:  # Local Search\n                    F = 0.5 # Fixed F\n                    Cr = 0.9 # Fixed Cr\n                    trial = self.de_mutation(population, i, F, Cr, func.bounds.lb, func.bounds.ub)\n                    if np.random.rand() < self.local_search_prob:\n                        trial = self.local_search(trial, func)\n                \n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Reward calculation\n                reward = fitness[i] - f_trial # Reward is the improvement in fitness\n\n                # Update Q-table\n                next_state = self.discretize_state(f_trial)\n                best_next_action = np.max(self.Q_table[next_state])\n                self.Q_table[state][action] += self.learning_rate * (reward + 0.9 * best_next_action - self.Q_table[state][action])\n\n                # Store experience in memory\n                self.memory.append((state, action, reward, next_state))\n                \n                # Experience Replay\n                if len(self.memory) > self.memory_size // 2:\n                    batch = np.random.choice(len(self.memory), size=self.memory_size // 4, replace=False)\n                    for idx in batch:\n                        state_exp, action_exp, reward_exp, next_state_exp = self.memory[idx]\n                        best_next_action_exp = np.max(self.Q_table[next_state_exp])\n                        self.Q_table[state_exp][action_exp] += self.learning_rate * (reward_exp + 0.9 * best_next_action_exp - self.Q_table[state_exp][action_exp])\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Update exploration rate and learning rate\n            self.exploration_rate *= self.exploration_decay\n            self.learning_rate *= self.learning_rate_decay\n\n        return self.f_opt, self.x_opt\n\n    def de_mutation(self, population, i, F, Cr, lb, ub):\n        indices = np.random.choice(self.pop_size, size=3, replace=False)\n        a, b, c = indices[0], indices[1], indices[2]\n        mutant = population[a] + F * (population[b] - population[c])\n        mutant = np.clip(mutant, lb, ub)\n        trial = np.copy(population[i])\n        mask = np.random.rand(self.dim) < Cr\n        trial[mask] = mutant[mask]\n        return trial\n\n    def local_search(self, x, func):\n        # Adapt local search region dynamically\n        scale = self.ls_scale * (func.bounds.ub - func.bounds.lb) # Adjust the scale based on the search space\n        new_x = x + np.random.uniform(-scale, scale, size=self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x\n\n    def discretize_state(self, fitness):\n        # Discretize the fitness value to create a finite state space\n        # You can adjust the boundaries based on the problem domain\n        if fitness < self.f_opt:\n            return 0\n        elif fitness < self.f_opt * 1.1:\n            return 1\n        else:\n            return 2", "configspace": "", "generation": 8, "feedback": "An exception occurred: name 'collections' is not defined.", "error": "", "parent_ids": ["ebe5839e-d2df-4ab9-a60a-cd4f487ab950"], "operator": null, "metadata": {}}
{"id": "8f59865d-cc8b-419a-bea1-e6b0264cd8af", "fitness": -Infinity, "name": "EnhancedAdaptiveDE", "description": "Enhanced Adaptive Differential Evolution with success-rate based parameter adaptation, adaptive local search using Nelder-Mead, and orthogonal initialization.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, local_search_prob=0.1, archive_size=10, restart_trigger=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.min_pop_size = 5  # Minimum population size\n        self.max_pop_size = 50 # Maximum population size\n        self.memory_size = memory_size\n        self.local_search_prob = local_search_prob\n        self.archive_size = archive_size\n        self.restart_trigger = restart_trigger\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.archive_fitness = []\n        self.success_F = []\n        self.success_Cr = []\n        self.generation = 0\n        self.no_improvement_count = 0\n        self.last_improvement_gen = 0\n\n    def __call__(self, func):\n        # Orthogonal Initialization\n        population = self.orthogonal_initialization(func, self.pop_size)\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        self.last_improvement_gen = 0\n\n        while self.budget > 0:\n            self.generation += 1\n            \n            # Adaptive Population Size\n            if self.generation - self.last_improvement_gen > self.restart_trigger:\n                self.no_improvement_count +=1\n                self.pop_size = max(self.min_pop_size, int(self.pop_size * 0.75))  # Reduce population size\n                print(f\"Restarting with smaller pop size: {self.pop_size} at gen: {self.generation}\")\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n                self.last_improvement_gen = self.generation\n                \n            else:\n                self.no_improvement_count = 0\n                \n            if self.no_improvement_count > 3:\n                self.pop_size = min(self.max_pop_size, self.pop_size + 5)\n                print(f\"Increasing pop size: {self.pop_size} at gen: {self.generation}\")\n                new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(5, self.dim))\n                new_fitness = np.array([func(x) for x in new_individuals])\n                self.budget -= 5\n                population = np.vstack((population, new_individuals))\n                fitness = np.concatenate((fitness, new_fitness))\n\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history\n                if self.success_F:\n                    weights = np.array(self.success_Cr)  # Use success Cr for weighting\n                    weights /= weights.sum()\n                    F = np.sum(np.array(self.success_F) * weights)\n                    Cr = np.sum(np.array(self.success_Cr) * weights)\n                else:\n                    F = 0.5\n                    Cr = 0.9\n\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n\n                # Archive component to mutation\n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += F * (self.archive[arc_idx] - population[i]) * 0.1  # Scale down the archive influence\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search using Nelder-Mead\n                if np.random.rand() < self.local_search_prob:\n                    bounds = [(func.bounds.lb, func.bounds.ub) for _ in range(self.dim)]\n                    res = minimize(func, trial, method='Nelder-Mead', bounds=bounds, options={'maxfev': 20})\n                    if res.fun < func(trial):\n                        trial = res.x\n                        f_trial = res.fun\n                        self.budget += -res.nfev\n                        if self.budget <= 0:\n                            break\n                    else:\n                        f_trial = func(trial)\n                        self.budget -= 1\n                        if self.budget <= 0:\n                            break\n\n                else:\n                    f_trial = func(trial)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        worst_archive_idx = np.argmax(self.archive_fitness)\n                        if fitness[i] < self.archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = population[i]\n                            self.archive_fitness[worst_archive_idx] = fitness[i]\n\n                    self.success_F.append(F)\n                    self.success_Cr.append(Cr)\n                    if len(self.success_F) > self.memory_size:\n                        self.success_F.pop(0)\n                        self.success_Cr.pop(0)\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.last_improvement_gen = self.generation\n\n        return self.f_opt, self.x_opt\n\n    def orthogonal_initialization(self, func, pop_size):\n        # Generate Latin hypercube sample\n        sample = np.random.rand(pop_size, self.dim)\n        for i in range(self.dim):\n            permutation = np.random.permutation(pop_size)\n            sample[:, i] = (permutation + sample[:, i]) / pop_size\n        # Scale to the bounds\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = lb + sample * (ub - lb)\n        return population", "configspace": "", "generation": 8, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["25f40be8-02b4-42e8-add7-c6a4b86ee163"], "operator": null, "metadata": {}}
{"id": "19422556-89d1-4203-a478-f5382eef234e", "fitness": 0.0, "name": "AdaptiveDEwithAgingAndMultiStrategyLS", "description": "Adaptive DE with a novel aging mechanism for population members, prioritizing exploration by replacing older, less-fit individuals and integrating a multi-strategy local search with dynamic strategy selection.", "code": "import numpy as np\n\nclass AdaptiveDEwithAgingAndMultiStrategyLS:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, initial_local_search_prob=0.1, archive_size=100, ls_decay=0.99, ls_increase=1.01, aging_rate=0.05, ls_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = initial_local_search_prob\n        self.archive_size = archive_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.ls_decay = ls_decay\n        self.ls_increase = ls_increase\n        self.aging_rate = aging_rate\n        self.ages = np.zeros(pop_size)\n        self.ls_step_size = ls_step_size\n        self.successful_F = []\n        self.successful_Cr = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        previous_f_opt = self.f_opt\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history with weighted sampling\n                if self.successful_F:\n                    F = np.random.choice(self.successful_F)\n                else:\n                    F = 0.5  # Default value if no successful F values yet\n\n                if self.successful_Cr:\n                    Cr = np.random.choice(self.successful_Cr)\n                else:\n                    Cr = 0.9  # Default value if no successful Cr values yet\n\n                indices = np.random.choice(self.pop_size, size=3, replace=False)\n                a, b, c = indices[0], indices[1], indices[2]\n\n                # Differential Evolution Mutation\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search (Multi-Strategy)\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.multi_strategy_local_search(trial, func)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.archive.append(population[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    population[i] = trial\n                    fitness[i] = f_trial\n                    self.ages[i] = 0  # Reset age\n\n                    self.successful_F.append(F)\n                    self.successful_Cr.append(Cr)\n                    if len(self.successful_F) > self.memory_size:\n                        self.successful_F.pop(0)\n                        self.successful_Cr.pop(0)\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.ages[i] += 1\n\n            # Aging mechanism: Replace old individuals\n            for i in range(self.pop_size):\n                if np.random.rand() < self.aging_rate * (self.ages[i] / np.max(self.ages)):  # Probability increases with age\n                    population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)  # Reinitialize\n                    fitness[i] = func(population[i])\n                    self.budget -=1\n                    self.ages[i] = 0\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = population[i]\n            \n            if self.f_opt < previous_f_opt:\n                self.local_search_prob = min(1.0, self.local_search_prob * self.ls_increase)\n                self.ls_step_size = min(0.1, self.ls_step_size/self.ls_step_size) #Step size decays now\n            else:\n                self.local_search_prob = max(0.01, self.local_search_prob * self.ls_decay)\n                self.ls_step_size = max(1e-6, self.ls_step_size*self.ls_decay) #Step size decays here too\n            previous_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt\n\n    def multi_strategy_local_search(self, x, func):\n        # Strategy 1: Random step\n        new_x1 = x + np.random.uniform(-self.ls_step_size, self.ls_step_size, size=self.dim)\n        new_x1 = np.clip(new_x1, func.bounds.lb, func.bounds.ub)\n\n        # Strategy 2: Gradient-based (simplified - using finite differences)\n        delta = 1e-5\n        grad = np.zeros(self.dim)\n        for j in range(self.dim):\n            x_plus_delta = np.copy(x)\n            x_plus_delta[j] += delta\n            x_plus_delta = np.clip(x_plus_delta, func.bounds.lb, func.bounds.ub)\n            grad[j] = (func(x_plus_delta) - func(x)) / delta\n            self.budget -= 1\n            if self.budget <= 0:\n                break\n        new_x2 = x - self.ls_step_size * grad\n        new_x2 = np.clip(new_x2, func.bounds.lb, func.bounds.ub)\n        \n        # Strategy 3: Move towards the best solution found so far\n        new_x3 = x + 0.1 * (self.x_opt - x)  # Adjust the 0.1 factor as needed\n        new_x3 = np.clip(new_x3, func.bounds.lb, func.bounds.ub)\n\n        # Choose the best among the three\n        f1 = func(new_x1)\n        self.budget -= 1\n        if self.budget <= 0:\n            return x\n        f2 = func(new_x2)\n        self.budget -= 1\n        if self.budget <= 0:\n            return x\n            \n        f3 = func(new_x3)\n        self.budget -= 1\n        if self.budget <= 0:\n            return x\n\n        best_x = new_x1 if f1 <= f2 and f1 <= f3 else (new_x2 if f2 <= f1 and f2 <= f3 else new_x3)\n        return best_x", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDEwithAgingAndMultiStrategyLS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ebe5839e-d2df-4ab9-a60a-cd4f487ab950"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "25eb8041-0c1f-4b6f-a50f-3c551ebbd715", "fitness": 0.0, "name": "AdaptiveDEwithDynamicPopSizeAndCMAESLS", "description": "Adaptive Differential Evolution with dynamic population size adjustment, success-history adaptation, and an improved local search using a CMA-ES inspired approach.", "code": "import numpy as np\n\nclass AdaptiveDEwithDynamicPopSizeAndCMAESLS:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=20, memory_size=10, initial_local_search_prob=0.1, archive_size=100, ls_decay=0.99, ls_increase=1.01, ls_step_size=0.1, ls_step_decay=0.95, pop_size_decay=0.99, pop_size_increase=1.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = 5\n        self.max_pop_size = 100\n        self.memory_size = memory_size\n        self.local_search_prob = initial_local_search_prob\n        self.archive_size = archive_size\n        self.archive = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.ls_decay = ls_decay\n        self.ls_increase = ls_increase\n        self.ls_step_size = ls_step_size\n        self.ls_step_decay = ls_step_decay\n        self.successful_F = []\n        self.successful_Cr = []\n        self.pop_size_decay = pop_size_decay\n        self.pop_size_increase = pop_size_increase\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        previous_f_opt = self.f_opt\n        no_improvement_counter = 0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history with weighted sampling\n                if self.successful_F:\n                    F = np.random.choice(self.successful_F)\n                else:\n                    F = 0.5  # Default value if no successful F values yet\n\n                if self.successful_Cr:\n                    Cr = np.random.choice(self.successful_Cr)\n                else:\n                    Cr = 0.9  # Default value if no successful Cr values yet\n\n                indices = np.random.choice(self.pop_size, size=3, replace=False)\n                a, b, c = indices[0], indices[1], indices[2]\n\n                # Differential Evolution Mutation\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n                \n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.local_search(trial, func, population)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.archive.append(population[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    self.successful_F.append(F)\n                    self.successful_Cr.append(Cr)\n                    if len(self.successful_F) > self.memory_size:\n                        self.successful_F.pop(0)\n                        self.successful_Cr.pop(0)\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        no_improvement_counter = 0 # Reset counter\n                else:\n                     no_improvement_counter += 1  # Increment counter if no improvement\n\n            # Adjust population size based on recent progress\n            if no_improvement_counter > self.pop_size:  # If no improvement for a while\n                self.pop_size = max(self.min_pop_size, int(self.pop_size * self.pop_size_decay))  # Reduce population\n                no_improvement_counter = 0  # Reset counter\n            elif self.successful_F:  # If there was improvement recently\n                self.pop_size = min(self.max_pop_size, int(self.pop_size * self.pop_size_increase))  # Increase population\n                \n            # Resize the population if it has changed\n            if self.pop_size != population.shape[0]:\n                # Option 1: Re-initialize the population\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                # Option 2: Truncate/Pad the population\n                # new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                # min_size = min(self.pop_size, population.shape[0])\n                # new_population[:min_size] = population[:min_size]\n                # population = new_population\n\n            \n            if self.f_opt < previous_f_opt:\n                self.local_search_prob = min(1.0, self.local_search_prob * self.ls_increase)\n                self.ls_step_size = min(0.1, self.ls_step_size/self.ls_step_decay)\n            else:\n                self.local_search_prob = max(0.01, self.local_search_prob * self.ls_decay)\n                self.ls_step_size = max(1e-6, self.ls_step_size * self.ls_step_decay)\n            previous_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func, population):\n        # Local search using CMA-ES-inspired adaptation\n        cov = np.cov(population.T)  # Calculate covariance matrix\n        if np.linalg.det(cov) == 0: #Checking if cov is invertible\n            cov = np.eye(self.dim) * 0.01\n        \n        try:\n            new_x = np.random.multivariate_normal(x, cov * self.ls_step_size) #Sample from gaussian distribution\n        except: # Handle singular covariance matrix\n            new_x = x + np.random.uniform(-self.ls_step_size, self.ls_step_size, size=self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDEwithDynamicPopSizeAndCMAESLS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["48d62359-f969-474d-a9c7-54d11c67460b"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "35375739-577d-4f31-b1f4-a6be7c91f6e5", "fitness": 0.0, "name": "AdaptiveDEwithSelfAdaptiveLocalSearchDiversity2", "description": "Adaptive Differential Evolution with success-history parameter adaptation, self-adaptive local search probability and step size, combined with a population diversity mechanism using nearest neighbor distances and an enhanced local search.", "code": "import numpy as np\n\nclass AdaptiveDEwithSelfAdaptiveLocalSearchDiversity2:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, initial_local_search_prob=0.1, archive_size=100, ls_decay=0.99, ls_increase=1.01, ls_step_size=0.1, ls_step_decay=0.95, diversity_threshold=0.1, neighbor_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = initial_local_search_prob\n        self.archive_size = archive_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.ls_decay = ls_decay\n        self.ls_increase = ls_increase\n        self.ls_step_size = ls_step_size\n        self.ls_step_decay = ls_step_decay\n        self.successful_F = []\n        self.successful_Cr = []\n        self.diversity_threshold = diversity_threshold\n        self.neighbor_ratio = neighbor_ratio\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        previous_f_opt = self.f_opt\n\n        while self.budget > 0:\n            # Calculate nearest neighbors for diversity maintenance\n            distances = np.zeros((self.pop_size, self.pop_size))\n            for i in range(self.pop_size):\n                for j in range(i + 1, self.pop_size):\n                    distances[i, j] = np.linalg.norm(population[i] - population[j])\n                    distances[j, i] = distances[i, j]\n            \n            for i in range(self.pop_size):\n                # Parameter adaptation using success history with weighted sampling\n                if self.successful_F:\n                    F = np.random.choice(self.successful_F)\n                else:\n                    F = 0.5  # Default value if no successful F values yet\n\n                if self.successful_Cr:\n                    Cr = np.random.choice(self.successful_Cr)\n                else:\n                    Cr = 0.9  # Default value if no successful Cr values yet\n\n                indices = np.random.choice(self.pop_size, size=3, replace=False)\n                a, b, c = indices[0], indices[1], indices[2]\n\n                # Differential Evolution Mutation\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Diversity maintenance: Perturb based on nearest neighbors\n                neighbor_indices = np.argsort(distances[i])[1:int(self.neighbor_ratio * self.pop_size) + 1]  # Exclude self, take nearest neighbors\n                if len(neighbor_indices) > 0:\n                    neighbor_positions = population[neighbor_indices]\n                    mean_neighbor = np.mean(neighbor_positions, axis=0)\n                    if np.linalg.norm(population[i] - mean_neighbor) < self.diversity_threshold:\n                        trial = np.random.uniform(func.bounds.lb, func.bounds.ub)  # Random restart if too close to neighbors\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.local_search(trial, func)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.archive.append(population[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    self.successful_F.append(F)\n                    self.successful_Cr.append(Cr)\n                    if len(self.successful_F) > self.memory_size:\n                        self.successful_F.pop(0)\n                        self.successful_Cr.pop(0)\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            if self.f_opt < previous_f_opt:\n                self.local_search_prob = min(1.0, self.local_search_prob * self.ls_increase)\n                self.ls_step_size = min(0.1, self.ls_step_size/self.ls_step_decay)\n            else:\n                self.local_search_prob = max(0.01, self.local_search_prob * self.ls_decay)\n                self.ls_step_size = max(1e-6, self.ls_step_size * self.ls_step_decay)\n            previous_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func):\n        # Enhanced local search with multiple steps and diminishing step size\n        best_x = x\n        best_f = func(x)\n        ls_step = self.ls_step_size\n        for _ in range(5):  # Multiple local search steps\n            new_x = x + np.random.uniform(-ls_step, ls_step, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            if self.budget <= 0:\n                break\n\n            if new_f < best_f:\n                best_x = new_x\n                best_f = new_f\n            ls_step *= 0.8  # Diminishing step size\n        return best_x", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDEwithSelfAdaptiveLocalSearchDiversity2 scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["48d62359-f969-474d-a9c7-54d11c67460b"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "10582f4b-fc45-400a-8219-274a3dac314c", "fitness": 0.5002467233911189, "name": "NeighborhoodAdaptiveDE", "description": "Population-based Adaptive DE with a Neighborhood-Based Mutation, adaptive mutation strength using rank based approach, and a self-adaptive local search with dynamically adjusted radius.", "code": "import numpy as np\n\nclass NeighborhoodAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, local_search_prob=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = local_search_prob\n        self.neighborhood_size = neighborhood_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.success_F = []\n        self.success_Cr = []\n        self.generation = 0\n        self.success_count = 0\n        self.failure_count = 0\n        self.local_search_radius = 0.1 \n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            self.generation += 1\n\n            # Adjust local search probability based on success rate\n            if self.success_count + self.failure_count > 10:\n                success_rate = self.success_count / (self.success_count + self.failure_count)\n                self.local_search_prob = np.clip(success_rate, 0.05, 0.5)  # Keep it within reasonable bounds\n                self.success_count = 0\n                self.failure_count = 0\n\n            # Sort population by fitness\n            ranked_indices = np.argsort(fitness)\n\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history\n                if self.success_F:\n                    weights = np.abs(np.array(self.success_Cr))  # Use success Cr for weighting\n                    weights /= weights.sum() + 1e-6  # avoid division by zero\n                    F = np.sum(np.array(self.success_F) * weights)\n                    Cr = np.sum(np.array(self.success_Cr) * weights)\n                else:\n                     F = 0.5\n                     Cr = 0.9\n\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n                \n                # Neighborhood-based Mutation\n                neighborhood_indices = ranked_indices[max(0, i - self.neighborhood_size // 2):min(self.pop_size, i + self.neighborhood_size // 2 + 1)]\n                neighborhood = population[neighborhood_indices]\n\n                if len(neighborhood) < 3:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = np.random.choice(idxs, 3, replace=False)\n                    mutant = population[a] + F * (population[b] - population[c])\n                else:\n                    # Rank-based mutation strength adaptation\n                    rank = np.where(ranked_indices == i)[0][0]  # Find rank of current individual\n                    mutation_strength = (rank / self.pop_size)  # Scale mutation strength with rank\n                    \n                    idxs = np.random.choice(len(neighborhood), 3, replace=False)\n                    a, b, c = neighborhood[idxs]\n                    mutant = a + mutation_strength * F * (b - c)\n                \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Self-Adaptive Local Search\n                if np.random.rand() < self.local_search_prob:\n                    # Dynamically adjust the radius based on the individual's performance\n                    radius = self.local_search_radius * (1 - rank / self.pop_size)  # Smaller radius for better individuals\n\n                    trial_ls = trial + np.random.normal(0, radius, self.dim)\n                    trial_ls = np.clip(trial_ls, func.bounds.lb, func.bounds.ub)\n                    f_trial_ls = func(trial_ls)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if f_trial_ls < fitness[i]:\n                        f_trial = f_trial_ls\n                        trial = trial_ls\n                        self.success_count += 1\n                    else:\n                        f_trial = func(trial)\n                        self.budget -= 1\n                        if self.budget <= 0:\n                            break\n                        self.failure_count += 1\n\n                else:\n                    f_trial = func(trial)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    if f_trial < fitness[i]:\n                        self.success_count += 1\n                    else:\n                        self.failure_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_F.append(F)\n                    self.success_Cr.append(Cr)\n                    if len(self.success_F) > self.memory_size:\n                        self.success_F.pop(0)\n                        self.success_Cr.pop(0)\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm NeighborhoodAdaptiveDE scored 0.500 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["83e98317-2e7e-443d-b9e3-9eb5a7a494e8"], "operator": null, "metadata": {"aucs": [0.1492004768884122, 0.2004749940227908, 0.48977566239592996, 0.9431300393326035, 0.6912427456023342, 0.5793682703299827, 0.35834410807935224, 0.533924114563118, 0.5320794452955537, 0.20420235362342232, 0.9373536416405516, 1.0, 0.259246613571001, 0.20654472142336788, 0.8033865603102184, 0.3589796778992046, 0.3341349518913658, 0.7024526477431258, 0.22121520670164685, 0.4998782365083937]}}
{"id": "62eb9ded-04ff-4f21-8121-2d2aa9e45eaf", "fitness": 0.6562203783045764, "name": "AdaptiveDENeighborhoodCMA", "description": "An adaptive Differential Evolution algorithm with a neighborhood-based mutation strategy, covariance matrix adaptation, and adaptive local search with a decreasing step size.", "code": "import numpy as np\n\nclass AdaptiveDENeighborhoodCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, initial_local_search_prob=0.1, archive_size=100, ls_decay=0.99, ls_increase=1.01, ls_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = initial_local_search_prob\n        self.archive_size = archive_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.ls_decay = ls_decay\n        self.ls_increase = ls_increase\n        self.ls_step_size = ls_step_size\n        self.successful_F = []\n        self.successful_Cr = []\n        self.C = np.eye(dim)  # Covariance matrix for CMA-ES-like adaptation\n        self.learning_rate_C = 0.1\n        self.neighborhood_size = 5 # Size of the neighborhood for mutation\n        self.ls_step_decay = 0.95\n\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        previous_f_opt = self.f_opt\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history with weighted sampling\n                if self.successful_F:\n                    F = np.random.choice(self.successful_F)\n                else:\n                    F = 0.5  # Default value if no successful F values yet\n\n                if self.successful_Cr:\n                    Cr = np.random.choice(self.successful_Cr)\n                else:\n                    Cr = 0.9  # Default value if no successful Cr values yet\n\n                # Neighborhood-based mutation\n                neighborhood_indices = np.random.choice(self.pop_size, size=self.neighborhood_size, replace=False)\n                best_neighbor_index = neighborhood_indices[np.argmin(fitness[neighborhood_indices])]\n                \n                indices = np.random.choice(self.pop_size, size=2, replace=False) # reduced to 2 to compensate for best neighbor\n                a, b = indices[0], indices[1]\n\n                # Differential Evolution Mutation using the best neighbor\n                mutant = population[best_neighbor_index] + F * (population[a] - population[b])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.local_search(trial, func)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.archive.append(population[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    self.successful_F.append(F)\n                    self.successful_Cr.append(Cr)\n                    if len(self.successful_F) > self.memory_size:\n                        self.successful_F.pop(0)\n                        self.successful_Cr.pop(0)\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            if self.f_opt < previous_f_opt:\n                self.local_search_prob = min(1.0, self.local_search_prob * self.ls_increase)\n                # CMA-ES adaptation: simplified version\n                diff = population[np.argmin(fitness)] - self.x_opt\n                self.C = (1 - self.learning_rate_C) * self.C + self.learning_rate_C * np.outer(diff, diff)\n                self.ls_step_size = min(0.1, self.ls_step_size/self.ls_step_decay) #adaptive step size decay\n            else:\n                self.local_search_prob = max(0.01, self.local_search_prob * self.ls_decay)\n                self.ls_step_size = max(1e-6, self.ls_step_size * self.ls_step_decay) #adaptive step size decay\n            previous_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func):\n        # Local search using random step with adaptive step size\n        new_x = x + np.random.uniform(-self.ls_step_size, self.ls_step_size, size=self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDENeighborhoodCMA scored 0.656 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["48d62359-f969-474d-a9c7-54d11c67460b"], "operator": null, "metadata": {"aucs": [0.37684742819288486, 0.22984866106275204, 0.9292944172511974, 0.9715496465768545, 0.3148515984741035, 0.9431602061544285, 0.38300729853261695, 0.7505907635634465, 0.9188810369819299, 0.5182644489441542, 0.9788424417522888, 0.99916595478965, 0.33497767047769156, 0.9392939527566904, 0.8947603641636579, 0.3656871879771635, 0.6424157929148028, 0.818215125965483, 0.310856427925045, 0.5038971416346874]}}
{"id": "41b8284b-6b04-4f24-9a86-ca0adf32520a", "fitness": 0.5471972368526392, "name": "EnhancedAdaptiveDE", "description": "Enhanced Adaptive DE with a multi-strategy ensemble based on population diversity, adaptive population size, archive, orthogonal crossover, and self-adaptive local search.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, local_search_prob=0.1, archive_size=10, restart_trigger=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.min_pop_size = 5  # Minimum population size\n        self.max_pop_size = 50 # Maximum population size\n        self.memory_size = memory_size\n        self.local_search_prob = local_search_prob\n        self.archive_size = archive_size\n        self.restart_trigger = restart_trigger\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.archive_fitness = []\n        self.success_F = []\n        self.success_Cr = []\n        self.generation = 0\n        self.no_improvement_count = 0\n        self.last_improvement_gen = 0\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        self.last_improvement_gen = 0\n\n        while self.budget > 0:\n            self.generation += 1\n            \n            # Adaptive Population Size\n            if self.generation - self.last_improvement_gen > self.restart_trigger:\n                self.no_improvement_count +=1\n                self.pop_size = max(self.min_pop_size, int(self.pop_size * 0.75))  # Reduce population size\n                #print(f\"Restarting with smaller pop size: {self.pop_size} at gen: {self.generation}\")\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n                self.last_improvement_gen = self.generation\n                \n            else:\n                self.no_improvement_count = 0\n                \n            if self.no_improvement_count > 3:\n                self.pop_size = min(self.max_pop_size, self.pop_size + 5)\n                #print(f\"Increasing pop size: {self.pop_size} at gen: {self.generation}\")\n                new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(5, self.dim))\n                new_fitness = np.array([func(x) for x in new_individuals])\n                self.budget -= 5\n                population = np.vstack((population, new_individuals))\n                fitness = np.concatenate((fitness, new_fitness))\n\n            # Calculate population diversity (standard deviation)\n            diversity = np.std(population)\n\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history\n                if self.success_F:\n                    weights = np.abs(np.array(self.success_Cr))  # Use success Cr for weighting\n                    weights /= weights.sum()\n                    F = np.sum(np.array(self.success_F) * weights)\n                    Cr = np.sum(np.array(self.success_Cr) * weights)\n                else:\n                    F = 0.5\n                    Cr = 0.9\n\n\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                # Strategy Ensemble based on diversity\n                if diversity > 1.0:  # High diversity: explore\n                    strategy = 1  # DE mutation with Cauchy and Archive\n                elif diversity > 0.5: # Medium diversity: balance\n                    strategy = 2  # DE mutation with orthogonal crossover\n                else:  # Low diversity: exploit\n                    strategy = 3  # Local search focused\n\n                if strategy == 1:\n                    # Differential Evolution Mutation with Cauchy and Archive\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = np.random.choice(idxs, 3, replace=False)\n                    mutant = population[a] + F * (population[b] - population[c])\n\n                    # Cauchy mutation\n                    cauchy_mask = np.random.rand(self.dim) < 0.05\n                    mutant[cauchy_mask] += 0.1 * np.random.standard_cauchy(size=np.sum(cauchy_mask))\n\n                    # Archive component\n                    if len(self.archive) > 0:\n                        arc_idx = np.random.randint(len(self.archive))\n                        mutant += F * (self.archive[arc_idx] - population[i]) * 0.1\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                    trial = mutant  # No crossover\n\n                elif strategy == 2:\n                    # DE mutation with orthogonal crossover\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = np.random.choice(idxs, 3, replace=False)\n                    mutant = population[a] + F * (population[b] - population[c])\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    # Orthogonal Crossover\n                    trial = np.copy(population[i])\n                    mask = np.random.rand(self.dim) < Cr\n                    trial[mask] = mutant[mask]\n\n                else:  # strategy == 3:\n                    # Local Search only\n                    trial = np.copy(population[i])\n                    step_size = 0.01 + 0.04 * np.exp(-self.generation / 300)\n                    trial = trial + np.random.normal(0, step_size, self.dim)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n\n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        worst_archive_idx = np.argmax(self.archive_fitness)\n                        if fitness[i] < self.archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = population[i]\n                            self.archive_fitness[worst_archive_idx] = fitness[i]\n\n                    self.success_F.append(F)\n                    self.success_Cr.append(Cr)\n                    if len(self.success_F) > self.memory_size:\n                        self.success_F.pop(0)\n                        self.success_Cr.pop(0)\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.last_improvement_gen = self.generation\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedAdaptiveDE scored 0.547 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["25f40be8-02b4-42e8-add7-c6a4b86ee163"], "operator": null, "metadata": {"aucs": [0.2763415521173339, 0.34880531076089294, 0.520065523417286, 0.8836658956525931, 0.3722364896982805, 0.6985778259550857, 0.3198116589602418, 0.48737024684036656, 0.515695151602636, 0.5953116854022538, 0.4371435540597559, 0.9934072605872966, 0.302303951669039, 0.6281245780721646, 0.8262634881281776, 0.687586793040373, 0.5328154125408748, 0.7875398654182534, 0.24513784310660036, 0.48574065002327593]}}
{"id": "8da49e2d-a281-46b3-b29b-372d5f890aa5", "fitness": 0.6544506252152502, "name": "AdaptiveDEMomentumArchiveLocalSearch", "description": "Adaptive Differential Evolution with Momentum-based Crossover, a self-adjusting archive, and adaptive local search with dynamic step size adjustments based on success rates.", "code": "import numpy as np\n\nclass AdaptiveDEMomentumArchiveLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, local_search_prob=0.1, archive_size=10, restart_trigger=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.min_pop_size = 5  # Minimum population size\n        self.max_pop_size = 50 # Maximum population size\n        self.memory_size = memory_size\n        self.local_search_prob = local_search_prob\n        self.archive_size = archive_size\n        self.restart_trigger = restart_trigger\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.archive_fitness = []\n        self.success_F = []\n        self.success_Cr = []\n        self.local_search_success_rate = 0.5  # Initial success rate\n        self.generation = 0\n        self.no_improvement_count = 0\n        self.last_improvement_gen = 0\n        self.momentum = 0.1  # Momentum factor for crossover\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        self.last_improvement_gen = 0\n\n        while self.budget > 0:\n            self.generation += 1\n            \n            # Adaptive Population Size\n            if self.generation - self.last_improvement_gen > self.restart_trigger:\n                self.no_improvement_count +=1\n                self.pop_size = max(self.min_pop_size, int(self.pop_size * 0.75))  # Reduce population size\n                #print(f\"Restarting with smaller pop size: {self.pop_size} at gen: {self.generation}\")\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n                self.last_improvement_gen = self.generation\n                \n            else:\n                self.no_improvement_count = 0\n                \n            if self.no_improvement_count > 3:\n                self.pop_size = min(self.max_pop_size, self.pop_size + 5)\n                #print(f\"Increasing pop size: {self.pop_size} at gen: {self.generation}\")\n                new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(5, self.dim))\n                new_fitness = np.array([func(x) for x in new_individuals])\n                self.budget -= 5\n                population = np.vstack((population, new_individuals))\n                fitness = np.concatenate((fitness, new_fitness))\n\n            for i in range(self.pop_size):\n                # Parameter adaptation using sinusoidal function and success history\n                period = 100  # Sinusoidal period\n                F = 0.5 + 0.4 * np.sin(2 * np.pi * self.generation / period)\n                Cr = 0.9 + 0.09 * np.cos(2 * np.pi * self.generation / period)\n\n                if self.success_F:\n                    weights = np.abs(np.array(self.success_Cr))  # Use success Cr for weighting\n                    weights /= weights.sum()\n                    F = 0.5 * F + 0.5 * np.sum(np.array(self.success_F) * weights)\n                    Cr = 0.5 * Cr + 0.5 * np.sum(np.array(self.success_Cr) * weights)\n\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                # Momentum-based crossover\n                mutant = population[a] + F * (population[b] - population[c]) + self.momentum * (population[i] - population[a])\n\n                # Cauchy mutation to escape local optima\n                cauchy_mask = np.random.rand(self.dim) < 0.05  # Apply Cauchy mutation with a small probability\n                mutant[cauchy_mask] += 0.1 * np.random.standard_cauchy(size=np.sum(cauchy_mask))\n\n                # Archive component to mutation\n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += F * (self.archive[arc_idx] - population[i]) * 0.1  # Scale down the archive influence\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Adaptive Local Search\n                if np.random.rand() < self.local_search_prob:\n                    # Dynamic step size adjustment based on success rate\n                    step_size = 0.01 + 0.04 * np.exp(-self.generation / 300) * self.local_search_success_rate\n                    trial_ls = trial + np.random.normal(0, step_size, self.dim)\n                    trial_ls = np.clip(trial_ls, func.bounds.lb, func.bounds.ub)\n                    f_trial_ls = func(trial_ls)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if f_trial_ls < fitness[i]:\n                        trial = trial_ls\n                        f_trial = f_trial_ls\n                        self.local_search_success_rate = min(1.0, self.local_search_success_rate + 0.05)  # Increase success rate\n                    else:\n                        f_trial = func(trial)\n                        self.budget -= 1\n                        self.local_search_success_rate = max(0.1, self.local_search_success_rate - 0.05)  # Decrease success rate\n                        if self.budget <= 0:\n                            break\n                else:\n                    f_trial = func(trial)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive (adaptive replacement)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        # Probabilistic replacement based on fitness\n                        probs = np.exp(np.array(self.archive_fitness) - np.max(self.archive_fitness))\n                        probs /= np.sum(probs)\n                        replace_idx = np.random.choice(len(self.archive), p=probs)\n                        if fitness[i] < self.archive_fitness[replace_idx]:\n                            self.archive[replace_idx] = population[i]\n                            self.archive_fitness[replace_idx] = fitness[i]\n\n                    self.success_F.append(F)\n                    self.success_Cr.append(Cr)\n                    if len(self.success_F) > self.memory_size:\n                        self.success_F.pop(0)\n                        self.success_Cr.pop(0)\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.last_improvement_gen = self.generation\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDEMomentumArchiveLocalSearch scored 0.654 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["25f40be8-02b4-42e8-add7-c6a4b86ee163"], "operator": null, "metadata": {"aucs": [0.2248835833739785, 0.8220246596304267, 0.6116232817419689, 0.9196886281395735, 0.816427391168722, 0.842440509300157, 0.7505500625751025, 0.5701484209683445, 0.5257804314353617, 0.28795834161322287, 0.934773777852191, 0.9909486914796473, 0.37745939325706446, 0.59027401137636, 0.930514686296271, 0.8240222136774555, 0.39533737732578955, 0.901205616811709, 0.23965978599890303, 0.5332916402827534]}}
{"id": "6d28ce25-c481-4151-ad1c-511b26eff47f", "fitness": 0.5571772284000162, "name": "AdaptiveDEwithDynamicPopulationAndOrthogonalLearning", "description": "Adaptive Differential Evolution with success-history parameter adaptation, dynamic population sizing, self-adaptive local search, and orthogonal learning to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDEwithDynamicPopulationAndOrthogonalLearning:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=20, min_pop_size=5, max_pop_size=100, memory_size=10, initial_local_search_prob=0.1, archive_size=100, ls_decay=0.99, ls_increase=1.01, ls_step_size=0.1, ls_step_decay=0.95, orthogonal_learning_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = initial_local_search_prob\n        self.archive_size = archive_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.ls_decay = ls_decay\n        self.ls_increase = ls_increase\n        self.ls_step_size = ls_step_size\n        self.ls_step_decay = ls_step_decay\n        self.successful_F = []\n        self.successful_Cr = []\n        self.orthogonal_learning_prob = orthogonal_learning_prob\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        previous_f_opt = self.f_opt\n        stagnation_counter = 0\n\n        while self.budget > 0:\n            \n            # Dynamic Population Sizing\n            if self.f_opt < previous_f_opt:\n                stagnation_counter = 0\n                self.pop_size = min(self.max_pop_size, int(self.pop_size * 1.05)) # increase pop size slightly upon improvement\n            else:\n                stagnation_counter += 1\n                if stagnation_counter > 5: # If no improvement after several iterations, reduce population size\n                     self.pop_size = max(self.min_pop_size, int(self.pop_size * 0.95))\n                     stagnation_counter = 0\n\n            if self.pop_size != population.shape[0]:\n                # Resize population\n                if self.pop_size > population.shape[0]:\n                    # Add new random individuals\n                    num_new = self.pop_size - population.shape[0]\n                    new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new, self.dim))\n                    new_fitness = np.array([func(x) for x in new_individuals])\n                    self.budget -= num_new\n                    if self.budget <=0:\n                        break\n                    population = np.vstack((population, new_individuals))\n                    fitness = np.concatenate((fitness, new_fitness))\n                else:\n                    # Remove worst individuals\n                    indices_to_remove = np.argsort(fitness)[self.pop_size:]\n                    population = np.delete(population, indices_to_remove, axis=0)\n                    fitness = np.delete(fitness, indices_to_remove)\n\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history with weighted sampling\n                if self.successful_F:\n                    F = np.random.choice(self.successful_F)\n                else:\n                    F = 0.5  # Default value if no successful F values yet\n\n                if self.successful_Cr:\n                    Cr = np.random.choice(self.successful_Cr)\n                else:\n                    Cr = 0.9  # Default value if no successful Cr values yet\n\n                indices = np.random.choice(self.pop_size, size=3, replace=False)\n                a, b, c = indices[0], indices[1], indices[2]\n\n                # Differential Evolution Mutation\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Orthogonal Learning\n                if np.random.rand() < self.orthogonal_learning_prob:\n                    trial = self.orthogonal_learning(population, trial, func.bounds.lb, func.bounds.ub)\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.local_search(trial, func)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.archive.append(population[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    self.successful_F.append(F)\n                    self.successful_Cr.append(Cr)\n                    if len(self.successful_F) > self.memory_size:\n                        self.successful_F.pop(0)\n                        self.successful_Cr.pop(0)\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            if self.f_opt < previous_f_opt:\n                self.local_search_prob = min(1.0, self.local_search_prob * self.ls_increase)\n                self.ls_step_size = min(0.1, self.ls_step_size/self.ls_step_decay)\n            else:\n                self.local_search_prob = max(0.01, self.local_search_prob * self.ls_decay)\n                self.ls_step_size = max(1e-6, self.ls_step_size * self.ls_step_decay)\n            previous_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func):\n        # Local search using random step with adaptive step size\n        new_x = x + np.random.uniform(-self.ls_step_size, self.ls_step_size, size=self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x\n    \n    def orthogonal_learning(self, population, x, lb, ub):\n        # Orthogonal Design to generate candidate solutions\n        levels = 3  # Number of levels for each factor\n        latin_hypercube = np.random.randint(0, levels, size=(self.dim, levels))\n\n        candidates = np.zeros((levels, self.dim))\n        for i in range(self.dim):\n            range_i = ub[i] - lb[i]\n            candidates[:, i] = lb[i] + range_i * (latin_hypercube[i, :] / (levels - 1))\n\n        # Evaluate candidates and select the best\n        best_candidate = x\n        best_fitness = np.inf\n        for candidate in candidates:\n            fitness = np.linalg.norm(candidate - x) #Simple distance metric\n            if fitness < best_fitness:\n                best_fitness = fitness\n                best_candidate = candidate\n        \n        return np.clip(best_candidate, lb, ub)", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDEwithDynamicPopulationAndOrthogonalLearning scored 0.557 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["48d62359-f969-474d-a9c7-54d11c67460b"], "operator": null, "metadata": {"aucs": [0.24385637268612426, 0.2965908723327727, 0.5732363830263589, 0.9538351726516544, 0.48410882393803034, 0.5322977564078262, 0.44370488972540156, 0.4486660167835157, 0.6222752983600979, 0.5010436107068632, 0.5971015222192668, 0.9930928853609283, 0.4161845895169658, 0.7262567553426575, 0.7477510963450058, 0.6452241372912829, 0.4061226490955475, 0.7899044832012687, 0.22845158963353518, 0.493839663375219]}}
{"id": "b3a13302-edb8-492d-a6d4-e9a5d6af5e86", "fitness": 0.5402522447877299, "name": "EnhancedAdaptiveDE", "description": "Enhanced Adaptive DE with orthogonal crossover, archive, CMA-ES-inspired mutation, self-adaptive local search, and improved parameter adaptation using a weighted average of successful parameters and a distance-based diversity mechanism.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, local_search_prob=0.1, archive_size=10, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = local_search_prob\n        self.archive_size = archive_size\n        self.diversity_threshold = diversity_threshold  # Added diversity threshold\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.archive_fitness = []\n        self.success_F = []\n        self.success_Cr = []\n        self.generation = 0\n        self.success_count = 0\n        self.failure_count = 0\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            self.generation += 1\n\n            # Adjust local search probability based on success rate\n            if self.success_count + self.failure_count > 10:\n                success_rate = self.success_count / (self.success_count + self.failure_count)\n                self.local_search_prob = np.clip(success_rate, 0.05, 0.5)  # Keep it within reasonable bounds\n                self.success_count = 0\n                self.failure_count = 0\n\n            # Calculate population center\n            pop_center = np.mean(population, axis=0)\n            \n            for i in range(self.pop_size):\n                # Parameter adaptation using sinusoidal function and success history\n                period = 100  # Sinusoidal period\n                F = 0.5 + 0.4 * np.sin(2 * np.pi * self.generation / period)\n                Cr = 0.9 + 0.09 * np.cos(2 * np.pi * self.generation / period)\n\n                if self.success_F:\n                    weights = np.abs(np.array(self.success_Cr))  # Use success Cr for weighting\n                    weights /= weights.sum() + 1e-6  # avoid division by zero\n                    F = 0.5 * F + 0.5 * np.sum(np.array(self.success_F) * weights)\n                    Cr = 0.5 * Cr + 0.5 * np.sum(np.array(self.success_Cr) * weights)\n\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                # Differential Evolution Mutation with CMA-ES-inspired adaptation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n\n                # Archive component to mutation\n                if len(self.archive) > 0:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant += F * (self.archive[arc_idx] - population[i]) * 0.1  # Scale down the archive influence\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Dual Local Search\n                if np.random.rand() < self.local_search_prob:\n                    # Local Search 1: Small perturbation\n                    trial1 = trial + np.random.normal(0, 0.05, self.dim)\n                    trial1 = np.clip(trial1, func.bounds.lb, func.bounds.ub)\n\n                    # Local Search 2: Larger perturbation with decreasing intensity\n                    intensity = 0.1 * np.exp(-self.generation / 500)  # Decaying intensity\n                    trial2 = trial + np.random.normal(0, intensity, self.dim)\n                    trial2 = np.clip(trial2, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate both local searches and choose the better one\n                    f_trial1 = func(trial1)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    f_trial2 = func(trial2)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if f_trial1 < f_trial2:\n                        f_trial = f_trial1\n                        trial = trial1\n                    else:\n                        f_trial = f_trial2\n                        trial = trial2\n\n                    if f_trial < fitness[i]:\n                        self.success_count += 1\n                    else:\n                        self.failure_count += 1\n\n                else:\n                    f_trial = func(trial)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    if f_trial < fitness[i]:\n                        self.success_count += 1\n                    else:\n                        self.failure_count += 1\n\n                # Diversity check and adaptation\n                distance_to_center = np.linalg.norm(trial - pop_center)\n                if distance_to_center < self.diversity_threshold:\n                    # If the solution is too close to the population center, perturb it\n                    trial = trial + np.random.normal(0, 0.1, self.dim)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                    f_trial = func(trial)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        worst_archive_idx = np.argmax(self.archive_fitness)\n                        if fitness[i] < self.archive_fitness[worst_archive_idx]:\n                            self.archive[worst_archive_idx] = population[i]\n                            self.archive_fitness[worst_archive_idx] = fitness[i]\n\n                    self.success_F.append(F)\n                    self.success_Cr.append(Cr)\n                    if len(self.success_F) > self.memory_size:\n                        self.success_F.pop(0)\n                        self.success_Cr.pop(0)\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedAdaptiveDE scored 0.540 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["83e98317-2e7e-443d-b9e3-9eb5a7a494e8"], "operator": null, "metadata": {"aucs": [0.25752327292571264, 0.34229908669259557, 0.4674814636921677, 0.8944554603064004, 0.462352962418513, 0.49806702177899664, 0.43394574284671616, 0.43344616768898037, 0.4279183606022602, 0.38251583612000317, 0.8752338893449677, 0.9984990845358975, 0.41255940528920043, 0.43769663171532125, 0.9424342099560276, 0.5878765589169762, 0.4079622533784746, 0.6429398530109977, 0.38468474724308543, 0.5151528872913038]}}
