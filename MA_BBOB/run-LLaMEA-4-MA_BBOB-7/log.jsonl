{"id": "e14427fa-5eec-4421-bc12-551f4721e8bf", "fitness": -Infinity, "name": "CMAES_OAS", "description": "Covariance matrix adaptation evolution strategy with orthogonal sampling and budget-aware adaptation.", "code": "import numpy as np\nfrom numpy.linalg import norm\nfrom scipy.linalg import sqrtm\n\nclass CMAES_OAS:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=1, ccov1=0.01, ccovmu=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.cs = cs\n        self.damps = damps\n        self.ccov1 = ccov1\n        self.ccovmu = ccovmu\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (100 * self.dim**2)))\n        self.eval_count = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            R = np.linalg.qr(z)[0] # Orthogonal sampling\n            x = self.m + self.sigma * np.dot(sqrtm(self.C), R).T  # Apply covariance matrix and step-size\n            \n            # Evaluate population, handling budget constraints\n            f = np.array([func(xi) if self.eval_count < self.budget else np.inf for xi in x])\n            self.eval_count += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n            \n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(x[:self.mu].T * self.weights, axis=1)\n            \n            # Update evolution path\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mu) * (self.m - m_old) / self.sigma / np.sqrt(np.diag(self.C))\n            hsig = (norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.eval_count / self.popsize)) / self.chiN) < (1.4 + 2 / (self.dim + 1))\n            self.pc = (1 - self.ccov1) * self.pc + hsig * np.sqrt(self.ccov1 * (2 - self.ccov1) * self.mu) * (self.m - m_old) / self.sigma\n            \n            # Update covariance matrix\n            dC = (self.ccov1 * np.outer(self.pc, self.pc) + self.ccovmu * np.sum(self.weights[:, None, None] * [(x[:self.mu][i] - m_old)[:, None] @ (x[:self.mu][i] - m_old)[None, :] for i in range(self.mu)], axis=0)) / self.sigma**2\n            self.C = (1 - self.ccov1 - self.ccovmu) * self.C + dC\n            \n            # Ensure covariance matrix is positive definite\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)  # Reset if not positive definite\n\n            # Adapt step size\n            self.sigma *= np.exp((self.cs / self.damps) * (norm(self.ps) / self.chiN - 1))\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occurred: name 'sqrtm' is not defined.", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "89b3cf9a-f830-494c-a1e2-39a9023e3e01", "fitness": 0.3314369884146578, "name": "HybridPSO_DE", "description": "A population-based algorithm that combines particle swarm optimization with differential evolution mutation, using a self-adaptive strategy to control exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate for DE\n        self.f = f  # Mutation factor for DE\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.Inf\n        self.best_position = None\n        self.pbest_fitness = None\n        self.pbest_position = None\n        self.eval_count = 0\n\n    def initialize(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        self.pbest_fitness = np.copy(self.fitness)\n        self.pbest_position = np.copy(self.pop)\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n\n    def update_best(self):\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.pbest_fitness[i]:\n                self.pbest_fitness[i] = self.fitness[i]\n                self.pbest_position[i] = self.pop[i].copy()\n\n        if np.min(self.pbest_fitness) < self.best_fitness:\n            self.best_fitness = np.min(self.pbest_fitness)\n            self.best_position = self.pbest_position[np.argmin(self.pbest_fitness)].copy()\n            \n    def de_mutation(self):\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.pop[idxs]\n            v = x1 + self.f * (x2 - x3)\n            \n            #Ensure bounds\n            v = np.clip(v, -5.0, 5.0)\n            \n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.cr or j == j_rand:\n                    self.pop[i, j] = v[j]\n\n    def pso_update(self):\n        velocity = (self.w * np.random.rand(self.pop_size, self.dim) * (self.pbest_position - self.pop) +\n                    self.c1 * np.random.rand(self.pop_size, self.dim) * (self.pbest_position - self.pop) +\n                    self.c2 * np.random.rand(self.pop_size, self.dim) * (self.best_position - self.pop))\n        \n        self.pop += velocity\n        \n        #Ensure bounds\n        self.pop = np.clip(self.pop, -5.0, 5.0)\n                    \n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            # Apply DE mutation\n            self.de_mutation()\n            \n            # Apply PSO update\n            self.pso_update()\n            \n            # Evaluate new solutions\n            new_fitness = np.array([func(x) for x in self.pop])\n            self.eval_count += self.pop_size\n            self.fitness = new_fitness\n            \n            #Update personal best and global best\n            self.update_best()\n            \n            # Adaptive adjustment of parameters (optional)\n            self.w = 0.9 - (0.5 / self.budget) * self.eval_count\n            self.cr = 0.5 + (0.4 / self.budget) * self.eval_count\n        \n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE scored 0.331 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1316325360950692, 0.2301461547747704, 0.3020892925447387, 0.289724355029372, 0.2473937231478026, 0.3116411091049358, 0.27254367533594315, 0.27375169302477187, 0.2404871635176714, 0.1959577188122128, 0.2848230501783071, 0.9994912747946998, 0.2638732142537472, 0.3081446982174174, 0.6283963462512776, 0.3441847604394639, 0.26053062779416847, 0.36867652817891017, 0.19373515636651473, 0.4815166904313618]}}
{"id": "258be5e9-1d3d-4dbb-9ee0-7b3cf7d33b38", "fitness": 0.7000238898949541, "name": "ADE", "description": "Adaptive Differential Evolution with a population-based archive for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass ADE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=100, F=0.5, Cr=0.9):\n        \"\"\"\n        Adaptive Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            archive_size (int): The size of the archive.\n            F (float): The initial scaling factor for differential variation.\n            Cr (float): The initial crossover rate.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.archive = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))  # Initialize archive\n\n        fevals = self.pop_size # Initial population evaluation\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[indices]\n\n                # Add archive member to the selection pool with small probability\n                if np.random.rand() < 0.1:\n                    arch_ind = np.random.choice(self.archive_size, 1)[0]\n                    x_r3 = self.archive[arch_ind]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    # Update archive (replace a random archive member)\n                    arch_ind = np.random.randint(self.archive_size)\n                    self.archive[arch_ind] = x_trial\n                \n                if f_trial < self.f_opt:\n                  self.f_opt = f_trial\n                  self.x_opt = x_trial\n\n                if fevals >= self.budget:\n                    break\n\n            # Adaptive F and Cr (optional, but can improve performance)\n            self.F = 0.5 * (1 + np.random.normal(0, 0.1)) # Sample from a normal distribution around 0.5\n            self.Cr = np.clip(np.random.normal(0.9, 0.1), 0, 1) # Sample from a normal distribution around 0.9 and clip\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ADE scored 0.700 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.2918408294311021, 0.6877034514982823, 0.6633102545793014, 0.876417792878327, 0.7420734444172021, 0.7722013727240138, 0.6331798405723499, 0.6541234626107277, 0.7205727814904853, 0.605681907022348, 0.8474816861996811, 0.9959892613423652, 0.6923724429031359, 0.7373635015610158, 0.9345591444537975, 0.7776751463892309, 0.6254421145057836, 0.8262843246891729, 0.4169210387058111, 0.499283999924949]}}
{"id": "81708838-5453-4ad4-8424-08755069aca7", "fitness": 0.7091507663072949, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Archive and Stochastic Ranking.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.pop[i].copy()\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n\n                # Handle archive\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant = self.pop[a] + self.F * (self.pop[b] - self.archive[arc_idx])\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_to_replace] = self.pop[i].copy()\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i].copy()\n                \n                # Adaptive F and CR (simplified)\n                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.9, 0.2), 0.1, 1.0)\n                \n                if self.budget <= 0:\n                    break\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.709 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.38055990421051633, 0.7447536385306903, 0.6790560917193178, 0.8776155298106668, 0.7412492636094228, 0.79896499537492, 0.6633976313232397, 0.6596278413243599, 0.755970151611461, 0.6834049244151235, 0.8551266509196607, 0.9990273155417893, 0.6749024147832345, 0.7053370507171773, 0.9177900204847981, 0.7763072580884969, 0.6237293755124602, 0.8358399070160485, 0.3005894516476614, 0.5097659095048557]}}
{"id": "70d4cd8b-1ca6-4f30-81bd-cbdb0f870364", "fitness": -Infinity, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with orthogonal design for parameter adaptation and a dynamically updated archive.", "code": "import numpy as np\nfrom scipy.stats import norm\nfrom scipy.linalg import hadamard\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, orthogonal_levels=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n        self.orthogonal_levels = orthogonal_levels # Levels for orthogonal design\n        self.orthogonal_matrix = self._create_orthogonal_array(orthogonal_levels)\n        self.num_orthogonal_samples = self.orthogonal_matrix.shape[0]\n        self.current_orthogonal_sample = 0\n        self.success_F = []\n        self.success_CR = []\n\n    def _create_orthogonal_array(self, levels):\n        \"\"\"Creates an orthogonal array using Hadamard matrix.\"\"\"\n        # Find the smallest Hadamard matrix size >= levels\n        n = 1\n        while True:\n            try:\n                H = hadamard(n)\n                if n >= levels:\n                    break\n            except ValueError:\n                n *= 2\n            else:\n                n *= 2\n\n        # Use the first 'levels' rows and convert to an orthogonal array scaled from 0 to levels - 1.\n        orthogonal_matrix = H[:levels, :levels]\n        orthogonal_matrix = (orthogonal_matrix + 1) / 2 * (levels -1)\n        return orthogonal_matrix.astype(int)\n\n    def _sample_F_CR(self):\n        \"\"\"Samples F and CR using orthogonal design.\"\"\"\n        sample_index = self.current_orthogonal_sample % self.num_orthogonal_samples\n        level_index_F = self.orthogonal_matrix[sample_index, 0]\n        level_index_CR = self.orthogonal_matrix[sample_index, 1]\n        \n        F = 0.1 + (0.9 / (self.orthogonal_levels - 1)) * level_index_F\n        CR = (0.1 + (0.9 / (self.orthogonal_levels - 1)) * level_index_CR)\n        \n        self.current_orthogonal_sample += 1\n        return F, CR\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.pop[i].copy()\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using orthogonal design\n                self.F, self.CR = self._sample_F_CR()\n                \n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n\n                # Handle archive\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant = self.pop[a] + self.F * (self.pop[b] - self.archive[arc_idx])\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update archive using stochastic replacement\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        if np.random.rand() < 0.5:\n                            idx_to_replace = np.random.randint(self.archive_size)\n                            self.archive[idx_to_replace] = self.pop[i].copy()\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i].copy()\n                \n                if self.budget <= 0:\n                    break\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: name 'hadamard' is not defined.", "error": "", "parent_ids": ["81708838-5453-4ad4-8424-08755069aca7"], "operator": null, "metadata": {}}
{"id": "f9dd8dff-f038-4a81-932c-d12713164158", "fitness": -Infinity, "name": "AdaptiveCMAES", "description": "A modified CMA-ES that uses eigenvalue decomposition for covariance matrix adaptation and incorporates a restart strategy when stagnation is detected.", "code": "import numpy as np\nfrom numpy.linalg import norm, eig\nfrom scipy.linalg import sqrtm\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=1, ccov1=0.01, ccovmu=0.1, restart_trigger=1e-12):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.cs = cs\n        self.damps = damps\n        self.ccov1 = ccov1\n        self.ccovmu = ccovmu\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (100 * self.dim**2)))\n        self.eval_count = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.restart_trigger = restart_trigger # Threshold for restarting CMA-ES\n        self.eigenvalues = None\n        self.eigenvectors = None\n        self.last_change = np.inf\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            \n            # Use eigenvalue decomposition instead of sqrtm\n            if self.eigenvalues is None:\n                self.eigenvalues, self.eigenvectors = eig(self.C)\n                self.eigenvalues = np.real(self.eigenvalues)\n                self.eigenvectors = np.real(self.eigenvectors)\n\n                # Handle potential negative eigenvalues\n                self.eigenvalues[self.eigenvalues < 0] = 1e-8\n\n            C_sqrt = self.eigenvectors @ np.diag(np.sqrt(self.eigenvalues)) @ self.eigenvectors.T\n            x = self.m + self.sigma * np.dot(C_sqrt, z).T  # Apply covariance matrix and step-size\n\n            # Evaluate population, handling budget constraints\n            f = np.array([func(xi) if self.eval_count < self.budget else np.inf for xi in x])\n            self.eval_count += self.popsize\n\n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(x[:self.mu].T * self.weights, axis=1)\n\n            # Update evolution path\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mu) * (self.m - m_old) / self.sigma / np.sqrt(np.diag(self.C))\n            hsig = (norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.eval_count / self.popsize)) / self.chiN) < (1.4 + 2 / (self.dim + 1))\n            self.pc = (1 - self.ccov1) * self.pc + hsig * np.sqrt(self.ccov1 * (2 - self.ccov1) * self.mu) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            dC = (self.ccov1 * np.outer(self.pc, self.pc) + self.ccovmu * np.sum(self.weights[:, None, None] * [(x[:self.mu][i] - m_old)[:, None] @ (x[:self.mu][i] - m_old)[None, :] for i in range(self.mu)], axis=0)) / self.sigma**2\n            self.C = (1 - self.ccov1 - self.ccovmu) * self.C + dC\n\n            # Ensure covariance matrix is positive definite and update eigenvalues/eigenvectors\n            try:\n                self.eigenvalues, self.eigenvectors = eig(self.C)\n                self.eigenvalues = np.real(self.eigenvalues)\n                self.eigenvectors = np.real(self.eigenvectors)\n                self.eigenvalues[self.eigenvalues < 0] = 1e-8 # Handle negative eigenvalues\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n                self.eigenvalues = None\n                self.eigenvectors = None\n\n\n            # Adapt step size\n            self.sigma *= np.exp((self.cs / self.damps) * (norm(self.ps) / self.chiN - 1))\n\n            # Restart strategy: detect stagnation and restart\n            if abs(self.f_opt - self.last_change) < self.restart_trigger:\n                # Restart CMA-ES\n                self.m = np.zeros(self.dim)\n                self.sigma = 0.5\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.eigenvalues = None\n                self.eigenvectors = None\n            \n            self.last_change = self.f_opt\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: name 'eig' is not defined.", "error": "", "parent_ids": ["e14427fa-5eec-4421-bc12-551f4721e8bf"], "operator": null, "metadata": {}}
{"id": "396540da-a5b1-48f3-bd46-057f84aee5a6", "fitness": -Infinity, "name": "CMAES_OAS", "description": "Covariance matrix adaptation evolution strategy with orthogonal sampling and budget-aware adaptation, using a numerically stable eigenvalue decomposition for covariance matrix adaptation.", "code": "import numpy as np\nfrom numpy.linalg import norm, eigvalsh\nfrom scipy.linalg import sqrtm\n\nclass CMAES_OAS:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=1, ccov1=0.01, ccovmu=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.cs = cs\n        self.damps = damps\n        self.ccov1 = ccov1\n        self.ccovmu = ccovmu\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (100 * self.dim**2)))\n        self.eval_count = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            R = np.linalg.qr(z)[0] # Orthogonal sampling\n\n            # Eigen decomposition for numerical stability\n            try:\n                D, B = np.linalg.eigh(self.C)\n                D = np.diag(np.sqrt(np.maximum(D, 1e-16)))  # Ensure positive definiteness\n                C_sqrt = B @ D @ B.T\n            except np.linalg.LinAlgError:\n                C_sqrt = np.eye(self.dim)\n                self.C = np.eye(self.dim)\n\n            x = self.m + self.sigma * np.dot(C_sqrt, R).T  # Apply covariance matrix and step-size\n            \n            # Evaluate population, handling budget constraints\n            f = np.array([func(xi) if self.eval_count < self.budget else np.inf for xi in x])\n            self.eval_count += self.popsize\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n            \n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(x[:self.mu].T * self.weights, axis=1)\n            \n            # Update evolution path\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mu) * (self.m - m_old) / self.sigma / np.sqrt(np.diag(self.C) + 1e-8)\n            hsig = (norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.eval_count / self.popsize)) / self.chiN) < (1.4 + 2 / (self.dim + 1))\n            self.pc = (1 - self.ccov1) * self.pc + hsig * np.sqrt(self.ccov1 * (2 - self.ccov1) * self.mu) * (self.m - m_old) / self.sigma\n            \n            # Update covariance matrix\n            dC = (self.ccov1 * np.outer(self.pc, self.pc) + self.ccovmu * np.sum(self.weights[:, None, None] * [(x[:self.mu][i] - m_old)[:, None] @ (x[:self.mu][i] - m_old)[None, :] for i in range(self.mu)], axis=0)) / self.sigma**2\n            self.C = (1 - self.ccov1 - self.ccovmu) * self.C + dC\n            \n            # Ensure covariance matrix is positive definite\n            try:\n                eigval = eigvalsh(self.C)\n                min_eigval = np.min(eigval)\n                if min_eigval < 1e-12:\n                    self.C += np.eye(self.dim) * (1e-12 - min_eigval)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)  # Reset if not positive definite\n\n            # Adapt step size\n            self.sigma *= np.exp((self.cs / self.damps) * (norm(self.ps) / self.chiN - 1))\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,2) (3,) .", "error": "", "parent_ids": ["e14427fa-5eec-4421-bc12-551f4721e8bf"], "operator": null, "metadata": {}}
{"id": "fb39231b-37e4-46f0-8a71-138596c67840", "fitness": 0.0, "name": "AdaptiveDERestart", "description": "Adaptive Differential Evolution with a dynamically adjusted population size and a restart mechanism based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveDERestart:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, archive_size=10, stagnation_iter=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_init = pop_size_init\n        self.pop_size = pop_size_init\n        self.archive_size = archive_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.stagnation_iter = stagnation_iter\n        self.stagnation_counter = 0\n        self.f_opt_last = np.Inf\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.pop[i].copy()\n\n        self.f_opt_last = self.f_opt  # Initialize f_opt_last\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n\n                # Handle archive\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant = self.pop[a] + self.F * (self.pop[b] - self.archive[arc_idx])\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_to_replace] = self.pop[i].copy()\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i].copy()\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    self.stagnation_counter += 1\n\n                # Adaptive F and CR (simplified)\n                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.9, 0.2), 0.1, 1.0)\n\n                if self.budget <= 0:\n                    break\n\n            # Stagnation check and restart\n            if self.stagnation_counter > self.stagnation_iter:\n                # Dynamically adjust population size\n                self.pop_size = int(self.pop_size * 0.8)  # Reduce population size\n                if self.pop_size < 10:\n                    self.pop_size = self.pop_size_init # Reset to initial pop size if too small\n\n                # Restart with new population\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.budget -= self.pop_size\n\n                for i in range(self.pop_size):\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.pop[i].copy()\n\n                self.stagnation_counter = 0  # Reset stagnation counter\n                print(\"Restarting with new population, pop size:\", self.pop_size)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDERestart scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["81708838-5453-4ad4-8424-08755069aca7"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "0d7a40cc-641b-473b-abaa-5621b259ae46", "fitness": 0.0, "name": "HybridPSO_DE_Restart", "description": "Combines PSO and DE, using a restart mechanism based on population diversity and adaptive parameter control, further integrating a local search operator to refine promising solutions.", "code": "import numpy as np\n\nclass HybridPSO_DE_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.Inf\n        self.best_position = None\n        self.pbest_fitness = None\n        self.pbest_position = None\n        self.eval_count = 0\n        self.local_search_prob = local_search_prob\n\n    def initialize(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        self.pbest_fitness = np.copy(self.fitness)\n        self.pbest_position = np.copy(self.pop)\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.initial_best_fitness = self.best_fitness  # Store initial best fitness\n\n    def update_best(self):\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.pbest_fitness[i]:\n                self.pbest_fitness[i] = self.fitness[i]\n                self.pbest_position[i] = self.pop[i].copy()\n\n        if np.min(self.pbest_fitness) < self.best_fitness:\n            self.best_fitness = np.min(self.pbest_fitness)\n            self.best_position = self.pbest_position[np.argmin(self.pbest_fitness)].copy()\n            \n\n    def de_mutation(self):\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.pop[idxs]\n            v = x1 + self.f * (x2 - x3)\n            \n            v = np.clip(v, -5.0, 5.0)\n            \n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.cr or j == j_rand:\n                    self.pop[i, j] = v[j]\n\n    def pso_update(self):\n        velocity = (self.w * np.random.rand(self.pop_size, self.dim) * (self.pbest_position - self.pop) +\n                    self.c1 * np.random.rand(self.pop_size, self.dim) * (self.pbest_position - self.pop) +\n                    self.c2 * np.random.rand(self.pop_size, self.dim) * (self.best_position - self.pop))\n        \n        self.pop += velocity\n        \n        self.pop = np.clip(self.pop, -5.0, 5.0)\n\n    def local_search(self, func, x):\n        # Simple Gaussian mutation for local search\n        x_new = x + np.random.normal(0, 0.1, size=self.dim)\n        x_new = np.clip(x_new, -5.0, 5.0)\n        f_new = func(x_new)\n        self.eval_count += 1\n        if f_new < func(x):\n            return x_new, f_new\n        else:\n            return x, func(x)\n    \n    def should_restart(self):\n        # Restart if population diversity is low, or stagnation is detected\n        diversity = np.std(self.fitness)\n        stagnation = (self.best_fitness - self.initial_best_fitness) < 1e-6  #Stagnation if little improvement\n        return diversity < 1e-6 or stagnation\n    \n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            # Apply DE mutation\n            self.de_mutation()\n            \n            # Apply PSO update\n            self.pso_update()\n            \n            # Evaluate new solutions\n            new_fitness = np.array([func(x) for x in self.pop])\n            self.eval_count += self.pop_size\n            self.fitness = new_fitness\n            \n            #Update personal best and global best\n            self.update_best()\n\n            # Local search\n            if np.random.rand() < self.local_search_prob:\n                idx = np.random.randint(self.pop_size)\n                self.pop[idx], self.fitness[idx] = self.local_search(func, self.pop[idx])\n                self.update_best()\n            \n            # Adaptive adjustment of parameters (optional)\n            self.w = 0.9 - (0.5 / self.budget) * self.eval_count\n            self.cr = 0.5 + (0.4 / self.budget) * self.eval_count\n\n            # Restart mechanism\n            if self.should_restart():\n                self.initialize(func)  # Reinitialize the population\n                \n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DE_Restart scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["89b3cf9a-f830-494c-a1e2-39a9023e3e01"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "9c063f00-fdd1-4fb1-9c72-d434164de447", "fitness": 0.0, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with orthogonal design for parameter adaptation and a dynamically sized archive to balance exploration and exploitation.", "code": "import numpy as np\nfrom scipy.stats import norm\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size_factor=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = int(pop_size * archive_size_factor)\n        self.archive = []\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n        self.F_memory = []\n        self.CR_memory = []\n        self.sf_prob = 0.1\n        self.scr_prob = 0.1\n        self.p_selection = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.pop[i].copy()\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter Adaptation (Orthogonal Design)\n                if len(self.F_memory) > 5:\n                    self.F = self.sample_parameter(self.F_memory, 0.5, 0.3, self.sf_prob)\n                else:\n                    self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                if len(self.CR_memory) > 5:\n                     self.CR = self.sample_parameter(self.CR_memory, 0.9, 0.2, self.scr_prob)\n                else:\n                    self.CR = np.clip(np.random.normal(0.9, 0.2), 0.1, 1.0)\n                \n\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n\n                # Archive utilization\n                if len(self.archive) > 0 and np.random.rand() < self.p_selection:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant = self.pop[a] + self.F * (self.pop[b] - self.archive[arc_idx])\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.F_memory.append(self.F)\n                    self.CR_memory.append(self.CR)\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update archive (dynamic size adjustment)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        # Tournament selection for replacement\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        if f_trial < func(self.archive[idx_to_replace]): #Direct comparison\n                            self.archive[idx_to_replace] = self.pop[i].copy()\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i].copy()\n                \n                # Adapt archive size dynamically based on performance\n                if self.budget % (self.pop_size * 5) == 0:  # Check every few generations\n                    improvement_ratio = np.sum(self.fitness < np.mean(self.fitness)) / self.pop_size\n                    if improvement_ratio > 0.5: # High performing population, increase archive\n                        self.archive_size = min(self.pop_size, self.archive_size + 1)\n                    elif improvement_ratio < 0.2: #Stagnating, decrease archive to promote exploration\n                        self.archive_size = max(1, self.archive_size - 1)\n                    self.archive = self.archive[:self.archive_size]\n\n                if self.budget <= 0:\n                    break\n                    \n        return self.f_opt, self.x_opt\n\n    def sample_parameter(self, memory, mean, std, prob):\n        if np.random.rand() < prob:\n            # Sample from memory\n            idx = np.random.randint(len(memory))\n            return memory[idx]\n        else:\n            # Sample from normal distribution\n            return np.clip(np.random.normal(mean, std), 0.1, 1.0)", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["81708838-5453-4ad4-8424-08755069aca7"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "779d72fb-2a9c-4337-873b-4a752492bd4e", "fitness": 0.0, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with orthogonal design for parameter tuning, archive, and stochastic ranking.", "code": "import numpy as np\nfrom scipy.stats import norm\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, ortho_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.ortho_trials = ortho_trials  # Number of orthogonal design trials for F/CR\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n        self.F_memory = []\n        self.CR_memory = []\n\n    def generate_orthogonal_array(self, n_factors, n_levels):\n        \"\"\"Generates an orthogonal array using Plackett-Burman design.\"\"\"\n        # This is a simplified example.  For larger factorials, consider using pyDOE\n        if n_factors == 2 and n_levels == 2:\n            return np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        else:\n            # Fallback: Return a full factorial design (not truly orthogonal for n_factors > 2)\n            arrays = [np.array(list(np.binary_repr(i, width=n_factors))).astype(int) for i in range(n_levels**n_factors)]\n            return np.array(arrays)\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.pop[i].copy()\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Orthogonal design for F/CR tuning\n                best_trial_fitness = np.inf\n                best_mutant = None\n\n                orthogonal_array = self.generate_orthogonal_array(2, 2) # F and CR are two factors, each with two levels around the current value.\n\n                for trial in range(min(self.ortho_trials, orthogonal_array.shape[0])): # Limit trials to prevent excessive budget consumption\n                    F_trial = np.clip(self.F + 0.2 * (orthogonal_array[trial][0] * 2 - 1), 0.1, 1.0) # perturb F\n                    CR_trial = np.clip(self.CR + 0.2 * (orthogonal_array[trial][1] * 2 - 1), 0.1, 1.0) # perturb CR\n\n\n                    # Mutation\n                    indices = [j for j in range(self.pop_size) if j != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = self.pop[a] + F_trial * (self.pop[b] - self.pop[c])\n\n                    # Handle archive\n                    if len(self.archive) > 0 and np.random.rand() < 0.1:\n                        arc_idx = np.random.randint(len(self.archive))\n                        mutant = self.pop[a] + F_trial * (self.pop[b] - self.archive[arc_idx])\n\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    cross_points = np.random.rand(self.dim) < CR_trial\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial_vector = np.where(cross_points, mutant, self.pop[i])\n\n                    # Selection\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < best_trial_fitness:\n                      best_trial_fitness = f_trial\n                      best_mutant = trial_vector\n                      best_F = F_trial\n                      best_CR = CR_trial\n\n\n                # After orthogonal trials, compare the best trial with the current pop member.\n                if best_trial_fitness < self.fitness[i]:\n                    self.pop[i] = best_mutant\n                    self.fitness[i] = best_trial_fitness\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_to_replace] = self.pop[i].copy()\n\n                    if best_trial_fitness < self.f_opt:\n                        self.f_opt = best_trial_fitness\n                        self.x_opt = self.pop[i].copy()\n\n                    # Update F and CR based on success (using memory)\n                    self.F_memory.append(best_F)\n                    self.CR_memory.append(best_CR)\n\n                if len(self.F_memory) > 10:\n                    self.F = np.mean(self.F_memory[-10:])\n                    self.CR = np.mean(self.CR_memory[-10:])\n                else:\n                    self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                    self.CR = np.clip(np.random.normal(0.9, 0.2), 0.1, 1.0)\n                \n                if self.budget <= 0:\n                    break\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["81708838-5453-4ad4-8424-08755069aca7"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "cf82703d-14a8-46dc-8369-172bca615320", "fitness": 0.27730118837956164, "name": "HybridPSODE_Restart", "description": "Combines PSO and DE with a restart mechanism triggered by stagnation detection and adjusts exploration/exploitation balance using a diversity measure.", "code": "import numpy as np\n\nclass HybridPSODE_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, c1=2.0, c2=2.0, cr=0.7, f=0.8, stagnation_limit=50, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.stagnation_limit = stagnation_limit\n        self.diversity_threshold = diversity_threshold\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.Inf\n        self.best_position = None\n        self.pbest_fitness = None\n        self.pbest_position = None\n        self.velocity = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n    \n    def initialize(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        self.pbest_fitness = np.copy(self.fitness)\n        self.pbest_position = np.copy(self.pop)\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.velocity = np.zeros_like(self.pop)\n        \n    def update_best(self):\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.pbest_fitness[i]:\n                self.pbest_fitness[i] = self.fitness[i]\n                self.pbest_position[i] = self.pop[i].copy()\n\n        if np.min(self.pbest_fitness) < self.best_fitness:\n            self.best_fitness = np.min(self.pbest_fitness)\n            self.best_position = self.pbest_position[np.argmin(self.pbest_fitness)].copy()\n            self.stagnation_counter = 0 # Reset stagnation counter\n        else:\n            self.stagnation_counter +=1\n            \n    def de_mutation(self):\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.pop[idxs]\n            v = x1 + self.f * (x2 - x3)\n            \n            #Ensure bounds\n            v = np.clip(v, -5.0, 5.0)\n            \n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.cr or j == j_rand:\n                    self.pop[i, j] = v[j]\n\n    def pso_update(self, w):\n        self.velocity = (w * self.velocity +\n                    self.c1 * np.random.rand(self.pop_size, self.dim) * (self.pbest_position - self.pop) +\n                    self.c2 * np.random.rand(self.pop_size, self.dim) * (self.best_position - self.pop))\n        \n        self.pop += self.velocity\n        \n        #Ensure bounds\n        self.pop = np.clip(self.pop, -5.0, 5.0)\n\n    def calculate_diversity(self):\n        centroid = np.mean(self.pop, axis=0)\n        distances = np.linalg.norm(self.pop - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def restart_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        self.pbest_fitness = np.copy(self.fitness)\n        self.pbest_position = np.copy(self.pop)\n\n        # Do not change best fitness/position\n\n    def __call__(self, func):\n        self.initialize(func)\n        \n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n            \n            # Apply DE mutation\n            self.de_mutation()\n            \n            # Apply PSO update\n            self.pso_update(w)\n            \n            # Evaluate new solutions\n            new_fitness = np.array([func(x) for x in self.pop])\n            self.eval_count += self.pop_size\n            self.fitness = new_fitness\n            \n            #Update personal best and global best\n            self.update_best()\n            \n            # Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_limit:\n                diversity = self.calculate_diversity()\n                if diversity < self.diversity_threshold:\n                    self.restart_population(func)\n                    self.stagnation_counter = 0  # Reset counter after restart\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSODE_Restart scored 0.277 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["89b3cf9a-f830-494c-a1e2-39a9023e3e01"], "operator": null, "metadata": {"aucs": [0.09751638226406745, 0.15810914913106155, 0.24234459843780398, 0.19371410962908597, 0.20615055422280726, 0.22021696193819718, 0.22273029899712304, 0.19654054299046853, 0.18083466902739542, 0.17695686585275017, 0.21592312302251715, 0.9969101401375006, 0.2280101427582778, 0.23270990584056261, 0.6065576664619039, 0.2870997150911341, 0.20608718831867157, 0.28842585052237324, 0.14797093999866884, 0.4412149629488603]}}
{"id": "7ea90aea-883c-425d-9400-666a45683148", "fitness": 0.6959998584588216, "name": "ADE", "description": "Adaptive Differential Evolution with improved parameter adaptation and archive handling using a ranking-based replacement strategy.", "code": "import numpy as np\n\nclass ADE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=100, F=0.5, Cr=0.9, adapt_freq=10):\n        \"\"\"\n        Adaptive Differential Evolution algorithm with improved parameter adaptation and archive handling.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            archive_size (int): The size of the archive.\n            F (float): The initial scaling factor for differential variation.\n            Cr (float): The initial crossover rate.\n            adapt_freq (int): How often to adapt F and Cr parameters.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.archive = None\n        self.adapt_freq = adapt_freq\n        self.fevals = 0\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))  # Initialize archive\n        self.archive_fitness = np.array([np.inf] * self.archive_size) #Archive fitness values\n        self.fevals = self.pop_size # Initial population evaluation\n\n        while self.fevals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[indices]\n\n                # Add archive member to the selection pool with small probability\n                if np.random.rand() < 0.1:\n                    arch_ind = np.random.choice(self.archive_size, 1)[0]\n                    x_r3 = self.archive[arch_ind]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    # Update population\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    # Update archive using ranking\n                    if f_trial < np.max(self.archive_fitness):\n                        worst_index = np.argmax(self.archive_fitness)\n                        self.archive[worst_index] = x_trial\n                        self.archive_fitness[worst_index] = f_trial\n                \n                if f_trial < self.f_opt:\n                  self.f_opt = f_trial\n                  self.x_opt = x_trial\n\n                if self.fevals >= self.budget:\n                    break\n\n            # Adaptive F and Cr\n            if self.fevals % self.adapt_freq == 0:\n                self.F = np.random.normal(0.5, 0.3)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.Cr = np.random.normal(0.9, 0.2)\n                self.Cr = np.clip(self.Cr, 0.1, 1.0)\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm ADE scored 0.696 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["258be5e9-1d3d-4dbb-9ee0-7b3cf7d33b38"], "operator": null, "metadata": {"aucs": [0.3567896050226623, 0.7055294970193864, 0.6962260735337797, 0.8459175347475609, 0.7362149229609328, 0.7811929558900135, 0.6896674952147823, 0.6411567324947055, 0.7215730718002127, 0.6635314373562994, 0.8662519987201147, 0.9934074197600014, 0.4309682885314614, 0.7421397273294281, 0.8895800634821656, 0.7968642904367411, 0.6296012780812863, 0.8568958437459766, 0.35013812897002616, 0.5263508040788976]}}
{"id": "1eb4f868-b4ac-4344-a17f-224f7de28732", "fitness": 0.713222627641432, "name": "DiversityAdaptiveDE", "description": "Differential Evolution with self-adaptive parameters and a diversity-preserving mechanism that replaces the worst individual in the population with a randomly generated one if the population stagnates.", "code": "import numpy as np\n\nclass DiversityAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, stagnation_threshold=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.previous_best_fitness = np.Inf\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.pop[i].copy()\n        \n        while self.budget > 0:\n            best_fitness_current_iter = np.min(self.fitness)\n            if best_fitness_current_iter >= self.previous_best_fitness:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n            self.previous_best_fitness = best_fitness_current_iter\n            \n            if self.stagnation_counter > self.stagnation_threshold:\n                # Replace worst individual with a random one\n                worst_index = np.argmax(self.fitness)\n                self.pop[worst_index] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                self.fitness[worst_index] = func(self.pop[worst_index])\n                self.budget -= 1\n                self.stagnation_counter = 0  # Reset counter\n\n                if self.fitness[worst_index] < self.f_opt:\n                    self.f_opt = self.fitness[worst_index]\n                    self.x_opt = self.pop[worst_index].copy()\n\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n\n                # Handle archive\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant = self.pop[a] + self.F * (self.pop[b] - self.archive[arc_idx])\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_to_replace] = self.pop[i].copy()\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i].copy()\n                \n                # Adaptive F and CR (simplified)\n                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.9, 0.2), 0.1, 1.0)\n                \n                if self.budget <= 0:\n                    break\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm DiversityAdaptiveDE scored 0.713 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["81708838-5453-4ad4-8424-08755069aca7"], "operator": null, "metadata": {"aucs": [0.35059642786505674, 0.6318823870558443, 0.6530359703047599, 0.8965668482521885, 0.7445144601666984, 0.7816152867934749, 0.6487943387453026, 0.6470231026715494, 0.7614314796261226, 0.7067202733550846, 0.890621665184613, 0.9944284033214393, 0.6478262136046888, 0.7459435812988403, 0.9177381444248744, 0.8031956466639972, 0.6411529197642016, 0.8264378482498133, 0.44614655823763183, 0.5287809972424558]}}
{"id": "72ab638c-a3e4-4fb5-af1d-1f65d42210f7", "fitness": 0.0, "name": "AdaptiveDE_LS", "description": "Adaptive Differential Evolution with a self-adaptive population size and a local search operator triggered probabilistically.", "code": "import numpy as np\n\nclass AdaptiveDE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size_min=10, pop_size_max=100, archive_size=10, ls_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with a larger population\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n        self.ls_prob = ls_prob #Probability of local search\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.pop[i].copy()\n        \n        while self.budget > 0:\n            # Adjust population size based on progress (simplified - can be improved with more sophisticated metrics)\n            if np.std(self.fitness) < 0.01 and self.pop_size > self.pop_size_min:\n                self.pop_size = max(self.pop_size_min, int(self.pop_size * 0.9)) #Reduce pop size if converged\n                self.pop = self.pop[:self.pop_size]\n                self.fitness = self.fitness[:self.pop_size]\n\n            elif np.std(self.fitness) > 1 and self.pop_size < self.pop_size_max:\n                 self.pop_size = min(self.pop_size_max, int(self.pop_size * 1.1)) #Increase pop size if diverse\n                 new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - len(self.pop), self.dim))\n                 self.pop = np.vstack((self.pop, new_individuals))\n                 self.fitness = np.concatenate((self.fitness, np.array([func(x) for x in new_individuals])))\n                 self.budget -= (self.pop_size - len(self.pop))\n\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n\n                # Handle archive\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant = self.pop[a] + self.F * (self.pop[b] - self.archive[arc_idx])\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_to_replace] = self.pop[i].copy()\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i].copy()\n                \n                # Adaptive F and CR (simplified)\n                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.9, 0.2), 0.1, 1.0)\n                \n                # Local Search\n                if np.random.rand() < self.ls_prob:\n                    trial_ls = self.local_search(func, self.pop[i], func.bounds.lb, func.bounds.ub)\n                    f_trial_ls = func(trial_ls)\n                    self.budget -= 1\n\n                    if f_trial_ls < self.fitness[i]:\n                        self.pop[i] = trial_ls\n                        self.fitness[i] = f_trial_ls\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.pop[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(self.archive_size)\n                            self.archive[idx_to_replace] = self.pop[i].copy()\n\n                        if f_trial_ls < self.f_opt:\n                            self.f_opt = f_trial_ls\n                            self.x_opt = self.pop[i].copy()\n\n\n                if self.budget <= 0:\n                    break\n                    \n        return self.f_opt, self.x_opt\n    \n    def local_search(self, func, x, lb, ub, step_size=0.1, iterations=5):\n        \"\"\"Simple local search around x.\"\"\"\n        x_current = x.copy()\n        f_current = func(x_current)\n        \n        for _ in range(iterations):\n            x_new = x_current + np.random.uniform(-step_size, step_size, size=self.dim)\n            x_new = np.clip(x_new, lb, ub)\n            f_new = func(x_new)\n            self.budget -= 1\n\n            if f_new < f_current:\n                f_current = f_new\n                x_current = x_new\n        return x_current", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE_LS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["81708838-5453-4ad4-8424-08755069aca7"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "8d322458-b77a-4531-85a5-aa8935bb188e", "fitness": 0.6750443693322048, "name": "SelfAdaptiveDE", "description": "Self-adaptive Differential Evolution with a Cauchy mutation operator and a learning mechanism for F and Cr.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=100, F_init=0.5, Cr_init=0.9):\n        \"\"\"\n        Self-Adaptive Differential Evolution algorithm with Cauchy mutation and F/Cr learning.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            archive_size (int): The size of the archive.\n            F_init (float): The initial scaling factor for differential variation.\n            Cr_init (float): The initial crossover rate.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F_init = F_init\n        self.Cr_init = Cr_init\n        self.pop = None\n        self.fitness = None\n        self.archive = None\n        self.F = None # individual F values\n        self.Cr = None # individual Cr values\n        self.sf_memory = [] # successful F memory\n        self.scr_memory = [] # successful Cr memory\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Self-Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))  # Initialize archive\n        self.F = np.full(self.pop_size, self.F_init) # Initialize F for each individual\n        self.Cr = np.full(self.pop_size, self.Cr_init) # Initialize Cr for each individual\n        self.sf_memory = []\n        self.scr_memory = []\n\n        fevals = self.pop_size # Initial population evaluation\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[indices]\n\n                # Add archive member to the selection pool with small probability\n                if np.random.rand() < 0.1:\n                    arch_ind = np.random.choice(self.archive_size, 1)[0]\n                    x_r3 = self.archive[arch_ind]\n\n                # Cauchy mutation\n                F_i = self.F[i]\n                x_mutated = x_r1 + F_i * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr[i] or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    # Store successful F and Cr values\n                    self.sf_memory.append(self.F[i])\n                    self.scr_memory.append(self.Cr[i])\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    # Update archive (replace a random archive member)\n                    arch_ind = np.random.randint(self.archive_size)\n                    self.archive[arch_ind] = x_trial\n                \n                if f_trial < self.f_opt:\n                  self.f_opt = f_trial\n                  self.x_opt = x_trial\n\n                if fevals >= self.budget:\n                    break\n\n            # Adaptive F and Cr (using a learning mechanism based on successful values)\n            if self.sf_memory:\n                sf_mean = np.mean(self.sf_memory)\n                self.F = np.clip(np.random.normal(sf_mean, 0.1, self.pop_size), 0.1, 1.0)\n                self.sf_memory = [] # Reset memory\n\n            if self.scr_memory:\n                scr_mean = np.mean(self.scr_memory)\n                self.Cr = np.clip(np.random.normal(scr_mean, 0.1, self.pop_size), 0.0, 1.0)\n                self.scr_memory = [] # Reset memory\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm SelfAdaptiveDE scored 0.675 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["258be5e9-1d3d-4dbb-9ee0-7b3cf7d33b38"], "operator": null, "metadata": {"aucs": [0.237185538757114, 0.8042931360754935, 0.38338233820802614, 0.8728483822675734, 0.7766901535815276, 0.8320600685158461, 0.6883290874917476, 0.6914472046089366, 0.752270540687314, 0.735374348145348, 0.8879643266738528, 0.9979858516929403, 0.36268792570623587, 0.8030074714238074, 0.7434904932772081, 0.8214632542915645, 0.47781026700620355, 0.8678924620568387, 0.23875576012648492, 0.5259487760500318]}}
{"id": "e3fb715a-d651-4c22-a703-0b2baadf1698", "fitness": -Infinity, "name": "LevyOrthogonalDE", "description": "Differential Evolution with a novel jumping strategy based on Lvy flights and orthogonal learning to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass LevyOrthogonalDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, levy_exponent=1.5, orthogonal_components=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.levy_exponent = levy_exponent\n        self.orthogonal_components = orthogonal_components\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) / \\\n                 (np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * (2 ** ((self.levy_exponent - 1) / 2)))) ** (1 / self.levy_exponent)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / abs(v)**(1/self.levy_exponent)\n        return step\n\n    def orthogonal_design(self, x):\n        orthogonal_matrix = np.random.randn(self.dim, self.orthogonal_components)\n        orthogonal_matrix = orthogonal_matrix / np.linalg.norm(orthogonal_matrix, axis=0)\n        new_points = x + np.random.uniform(-0.1, 0.1) * orthogonal_matrix\n        return new_points\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.pop[i].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation with Levy Flight\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                levy_steps = self.levy_flight(self.dim)\n                mutant = self.pop[a] + levy_steps * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                orthogonal_points = self.orthogonal_design(self.pop[i])\n                orthogonal_fitness = np.array([func(point) if self.budget > 0 else np.inf for point in orthogonal_points.T])\n                self.budget -= np.sum(self.budget > 0) and orthogonal_points.shape[1]\n                \n                best_orthogonal_index = np.argmin(orthogonal_fitness) if len(orthogonal_fitness) > 0 else None\n                \n                if best_orthogonal_index is not None and orthogonal_fitness[best_orthogonal_index] < self.fitness[i]:\n                        trial = orthogonal_points[:, best_orthogonal_index]\n                else:\n                        trial = mutant\n\n                # Selection\n                f_trial = func(trial) if self.budget > 0 else np.inf\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i].copy()\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,) (2,5) .", "error": "", "parent_ids": ["1eb4f868-b4ac-4344-a17f-224f7de28732"], "operator": null, "metadata": {}}
{"id": "266b45fb-c62b-492b-ba4e-9d5b97a01bc3", "fitness": -Infinity, "name": "DynamicDE_LocalSearch", "description": "Differential Evolution with a dynamically adjusted population size based on stagnation detection and a Gaussian local search applied to the best individuals.", "code": "import numpy as np\n\nclass DynamicDE_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, archive_size=50, F=0.5, Cr=0.9, stagnation_threshold=1000, local_search_probability=0.1):\n        \"\"\"\n        Differential Evolution with dynamic population size and Gaussian local search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size_init (int): Initial population size.\n            archive_size (int): The size of the archive.\n            F (float): Scaling factor for differential variation.\n            Cr (float): Crossover rate.\n            stagnation_threshold (int): Number of iterations without improvement before reducing population.\n            local_search_probability (float): Probability of applying local search to the best individual.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_init = pop_size_init\n        self.pop_size = pop_size_init\n        self.archive_size = archive_size\n        self.F = F\n        self.Cr = Cr\n        self.stagnation_threshold = stagnation_threshold\n        self.local_search_probability = local_search_probability\n        self.pop = None\n        self.fitness = None\n        self.archive = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with dynamic population size and Gaussian local search.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n\n        self.archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))  # Initialize archive\n        archive_fitness = np.array([func(x) for x in self.archive])\n        self.f_opt = np.min(np.min(self.fitness), np.min(archive_fitness))\n        self.x_opt = self.pop[np.argmin(self.fitness)] if np.min(self.fitness) < np.min(archive_fitness) else self.archive[np.argmin(archive_fitness)]\n\n\n        fevals = self.pop_size + self.archive_size # Initial population evaluation\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[indices]\n\n                # Add archive member to the selection pool with a small probability\n                if np.random.rand() < 0.1:\n                    arch_ind = np.random.choice(self.archive_size, 1)[0]\n                    x_r3 = self.archive[arch_ind]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    # Update archive (replace a random archive member)\n                    arch_ind = np.random.randint(self.archive_size)\n                    self.archive[arch_ind] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.stagnation_counter = 0 # Reset stagnation counter\n                else:\n                    self.stagnation_counter += 1\n\n                if fevals >= self.budget:\n                    break\n            \n            # Local search around the best solution\n            if np.random.rand() < self.local_search_probability:\n                x_local_search = np.clip(self.x_opt + np.random.normal(0, 0.05, self.dim), func.bounds.lb, func.bounds.ub)\n                f_local_search = func(x_local_search)\n                fevals += 1\n                \n                if f_local_search < self.f_opt:\n                    self.f_opt = f_local_search\n                    self.x_opt = x_local_search\n                    self.stagnation_counter = 0 # Reset stagnation counter\n\n\n            # Dynamic population size adjustment based on stagnation\n            if self.stagnation_counter > self.stagnation_threshold and self.pop_size > 10:\n                self.pop_size = max(10, int(self.pop_size * 0.8))  # Reduce population size by 20%\n                self.pop = self.pop[:self.pop_size]  # Truncate the population\n                self.fitness = self.fitness[:self.pop_size]\n                self.stagnation_counter = 0\n                print(f\"Population size reduced to {self.pop_size}\")\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: 'numpy.float64' object cannot be interpreted as an integer.", "error": "", "parent_ids": ["8d322458-b77a-4531-85a5-aa8935bb188e"], "operator": null, "metadata": {}}
{"id": "1bea3931-549d-46ad-8c4b-b7ade3d0af11", "fitness": -Infinity, "name": "EnhancedSelfAdaptiveDE", "description": "An enhanced self-adaptive Differential Evolution with a modified mutation strategy using a combination of current-to-best and current-to-rand mutation, incorporating orthogonal learning to improve exploration.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=100, F_init=0.5, Cr_init=0.9):\n        \"\"\"\n        Enhanced Self-Adaptive Differential Evolution algorithm with a combined mutation strategy\n        (current-to-best and current-to-rand) and orthogonal learning.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            archive_size (int): The size of the archive.\n            F_init (float): The initial scaling factor for differential variation.\n            Cr_init (float): The initial crossover rate.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F_init = F_init\n        self.Cr_init = Cr_init\n        self.pop = None\n        self.fitness = None\n        self.archive = None\n        self.F = None\n        self.Cr = None\n        self.sf_memory = []\n        self.scr_memory = []\n        self.best_index = None\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Enhanced Self-Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))\n        self.F = np.full(self.pop_size, self.F_init)\n        self.Cr = np.full(self.pop_size, self.Cr_init)\n        self.sf_memory = []\n        self.scr_memory = []\n        self.best_index = np.argmin(self.fitness)\n        fevals = self.pop_size\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation (Combined current-to-best and current-to-rand)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[indices]\n                x_best = self.pop[self.best_index]\n\n                # Adaptive probability for choosing mutation strategy\n                p = np.random.rand()\n                if p < 0.5: # Current-to-best\n                    x_mutated = self.pop[i] + self.F[i] * (x_best - self.pop[i]) + self.F[i] * (x_r1 - x_r2)\n                else: # Current-to-rand\n                    x_mutated = x_r1 + self.F[i] * (x_r2 - x_r3)\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr[i] or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Orthogonal Learning (select a random dimension and optimize it around x_trial)\n                j_orth = np.random.randint(self.dim)\n                x_trial_orth = np.copy(x_trial)\n                delta = np.random.uniform(-0.1, 0.1) * (func.bounds.ub - func.bounds.lb) # small perturbation\n                x_trial_orth[j_orth] += delta\n                x_trial_orth = np.clip(x_trial_orth, func.bounds.lb, func.bounds.ub)\n                \n                # Selection\n                f_trial = func(x_trial)\n                f_trial_orth = func(x_trial_orth)\n                fevals += 2  # Two function evaluations here\n\n                if f_trial_orth < f_trial:\n                    f_trial = f_trial_orth\n                    x_trial = x_trial_orth\n\n                if f_trial < self.fitness[i]:\n                    # Store successful F and Cr values\n                    self.sf_memory.append(self.F[i])\n                    self.scr_memory.append(self.Cr[i])\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n                    \n                    #Update best index\n                    if f_trial < self.fitness[self.best_index]:\n                        self.best_index = i\n\n                    # Update archive (replace a random archive member)\n                    arch_ind = np.random.randint(self.archive_size)\n                    self.archive[arch_ind] = x_trial\n                \n                if f_trial < self.f_opt:\n                  self.f_opt = f_trial\n                  self.x_opt = x_trial\n\n                if fevals >= self.budget:\n                    break\n\n            # Adaptive F and Cr\n            if self.sf_memory:\n                sf_mean = np.mean(self.sf_memory)\n                self.F = np.clip(np.random.normal(sf_mean, 0.1, self.pop_size), 0.1, 1.0)\n                self.sf_memory = []\n\n            if self.scr_memory:\n                scr_mean = np.mean(self.scr_memory)\n                self.Cr = np.clip(np.random.normal(scr_mean, 0.1, self.pop_size), 0.0, 1.0)\n                self.scr_memory = []\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["8d322458-b77a-4531-85a5-aa8935bb188e"], "operator": null, "metadata": {}}
{"id": "89b264fd-dbf6-4f31-9e65-d151997c4e8e", "fitness": 0.0, "name": "ImprovedSelfAdaptiveDE", "description": "Improved Self-Adaptive Differential Evolution with enhanced parameter adaptation, archive update, and stagnation handling using a modified Cauchy mutation.", "code": "import numpy as np\n\nclass ImprovedSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=100, F_init=0.5, Cr_init=0.9, stagnation_threshold=50):\n        \"\"\"\n        Improved Self-Adaptive Differential Evolution algorithm with Cauchy mutation, F/Cr learning,\n        archive update, and stagnation handling.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            archive_size (int): The size of the archive.\n            F_init (float): The initial scaling factor for differential variation.\n            Cr_init (float): The initial crossover rate.\n            stagnation_threshold (int): Number of iterations without improvement to trigger restart.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F_init = F_init\n        self.Cr_init = Cr_init\n        self.pop = None\n        self.fitness = None\n        self.archive = None\n        self.F = None # individual F values\n        self.Cr = None # individual Cr values\n        self.sf_memory = [] # successful F memory\n        self.scr_memory = [] # successful Cr memory\n        self.stagnation_counter = 0\n        self.stagnation_threshold = stagnation_threshold\n        self.best_fitness_history = []\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Improved Self-Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))  # Initialize archive\n        self.F = np.full(self.pop_size, self.F_init) # Initialize F for each individual\n        self.Cr = np.full(self.pop_size, self.Cr_init) # Initialize Cr for each individual\n        self.sf_memory = []\n        self.scr_memory = []\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n\n        fevals = self.pop_size # Initial population evaluation\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[indices]\n\n                # Add archive member to the selection pool with small probability\n                if np.random.rand() < 0.1:\n                    arch_ind = np.random.choice(self.archive_size, 1)[0]\n                    x_r3 = self.archive[arch_ind]\n\n                # Cauchy mutation with a small probability of using current best\n                if np.random.rand() < 0.05:\n                    x_r1 = self.x_opt if self.x_opt is not None else x_r1  # Use best if available\n\n\n                F_i = self.F[i]\n                cauchy_rand = np.random.standard_cauchy(size=self.dim)\n                x_mutated = x_r1 + F_i * cauchy_rand * (x_r2 - x_r3) # Cauchy Mutation\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr[i] or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    # Store successful F and Cr values\n                    self.sf_memory.append(self.F[i])\n                    self.scr_memory.append(self.Cr[i])\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    # Update archive (replace a random archive member, biased towards worse solutions)\n                    fitness_values = np.array([func(x) for x in self.archive])\n                    probabilities = np.exp(fitness_values / np.mean(fitness_values))  # Boltzmann distribution\n                    probabilities /= np.sum(probabilities)\n                    arch_ind = np.random.choice(self.archive_size, p=probabilities)\n                    self.archive[arch_ind] = x_trial\n                \n                if f_trial < self.f_opt:\n                  self.f_opt = f_trial\n                  self.x_opt = x_trial\n\n                if fevals >= self.budget:\n                    break\n            \n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                if self.best_fitness_history[-1] >= np.min(self.best_fitness_history[-self.stagnation_threshold:]): #No improvement\n                    self.stagnation_counter += 1\n                else:\n                    self.stagnation_counter = 0\n\n            if self.stagnation_counter >= self.stagnation_threshold:\n                # Reset population if stagnating\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.F = np.full(self.pop_size, self.F_init)\n                self.Cr = np.full(self.pop_size, self.Cr_init)\n                self.sf_memory = []\n                self.scr_memory = []\n                self.stagnation_counter = 0\n                \n\n            # Adaptive F and Cr (using a learning mechanism based on successful values)\n            if self.sf_memory:\n                sf_mean = np.mean(self.sf_memory)\n                self.F = np.clip(np.random.normal(sf_mean, 0.1, self.pop_size), 0.1, 1.0)\n                self.sf_memory = [] # Reset memory\n\n            if self.scr_memory:\n                scr_mean = np.mean(self.scr_memory)\n                self.Cr = np.clip(np.random.normal(scr_mean, 0.1, self.pop_size), 0.0, 1.0)\n                self.scr_memory = [] # Reset memory\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm ImprovedSelfAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8d322458-b77a-4531-85a5-aa8935bb188e"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "7ab01f72-7cf0-4508-89b2-d4a2d8b19b14", "fitness": -Infinity, "name": "AdaptivePopulationDE", "description": "An Adaptive Population DE algorithm that adjusts population size based on the function evaluations and uses a pool of mutation strategies with probabilities dynamically adapted based on their success.", "code": "import numpy as np\n\nclass AdaptivePopulationDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, mutation_pool_size=4):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.pop_size = initial_pop_size  # Start with initial population size\n        self.mutation_pool_size = mutation_pool_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.mutation_strategies = [\n            self._mutation_rand1,\n            self._mutation_current_to_best1,\n            self._mutation_best2,\n            self._mutation_rand2\n        ]\n        self.mutation_probabilities = np.ones(self.mutation_pool_size) / self.mutation_pool_size\n        self.success_counts = np.zeros(self.mutation_pool_size)\n        self.epsilon = 1e-6  # small value to avoid division by zero\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n\n        if self.fitness[self.best_index] < self.f_opt:\n            self.f_opt = self.fitness[self.best_index]\n            self.x_opt = self.pop[self.best_index].copy()\n        \n        while self.budget > 0:\n            # Adjust population size based on remaining budget (simple heuristic)\n            self.pop_size = max(self.min_pop_size, min(self.max_pop_size, int(self.initial_pop_size * (self.budget / 10000.0) + self.min_pop_size)))\n            \n            if self.pop_size != self.pop.shape[0]:\n                # Resize population\n                if self.pop_size > self.pop.shape[0]:\n                    # Add new random individuals\n                    num_new = self.pop_size - self.pop.shape[0]\n                    new_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new, self.dim))\n                    new_fitness = np.array([func(x) for x in new_pop])\n                    self.budget -= num_new\n                    self.pop = np.vstack((self.pop, new_pop))\n                    self.fitness = np.concatenate((self.fitness, new_fitness))\n                else:\n                    # Remove worst individuals\n                    num_remove = self.pop.shape[0] - self.pop_size\n                    remove_indices = np.argsort(self.fitness)[-num_remove:]\n                    self.pop = np.delete(self.pop, remove_indices, axis=0)\n                    self.fitness = np.delete(self.fitness, remove_indices)\n\n            for i in range(self.pop.shape[0]):\n                # Choose mutation strategy based on probabilities\n                mutation_index = np.random.choice(self.mutation_pool_size, p=self.mutation_probabilities)\n                mutant = self.mutation_strategies[mutation_index](i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    # Mutation strategy successful\n                    self.success_counts[mutation_index] += 1\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i].copy()\n                \n                if self.budget <= 0:\n                    break\n            \n            # Update mutation probabilities based on success counts\n            self.mutation_probabilities = (1 - 0.1) * self.mutation_probabilities + 0.1 * (self.success_counts / (np.sum(self.success_counts) + self.epsilon))\n            self.mutation_probabilities /= np.sum(self.mutation_probabilities)\n            self.success_counts[:] = 0 # Reset success counts after each generation\n\n            self.best_index = np.argmin(self.fitness)\n            if self.fitness[self.best_index] < self.f_opt:\n                self.f_opt = self.fitness[self.best_index]\n                self.x_opt = self.pop[self.best_index].copy()\n                \n        return self.f_opt, self.x_opt\n\n    def _mutation_rand1(self, i):\n        indices = [j for j in range(self.pop.shape[0]) if j != i]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        return self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n\n    def _mutation_current_to_best1(self, i):\n        indices = [j for j in range(self.pop.shape[0]) if j != i]\n        a, b = np.random.choice(indices, 2, replace=False)\n        return self.pop[i] + self.F * (self.pop[self.best_index] - self.pop[i]) + self.F * (self.pop[a] - self.pop[b])\n\n    def _mutation_best2(self, i):\n         indices = [j for j in range(self.pop.shape[0]) if j != i]\n         a, b, c, d = np.random.choice(indices, 4, replace=False)\n         return self.pop[self.best_index] + self.F * (self.pop[a] - self.pop[b]) + self.F * (self.pop[c] - self.pop[d])\n\n    def _mutation_rand2(self, i):\n        indices = [j for j in range(self.pop.shape[0]) if j != i]\n        a, b, c, d, e = np.random.choice(indices, 5, replace=False)\n        return self.pop[a] + self.F * (self.pop[b] - self.pop[c]) + self.F * (self.pop[d] - self.pop[e])", "configspace": "", "generation": 2, "feedback": "An exception occurred: index 21 is out of bounds for axis 0 with size 21.", "error": "", "parent_ids": ["1eb4f868-b4ac-4344-a17f-224f7de28732"], "operator": null, "metadata": {}}
{"id": "51aa95f5-3d6a-4292-a6e0-bc4a78089b59", "fitness": 0.0, "name": "DiversityAdaptiveDE", "description": "Diversity Adaptive DE with improved stagnation detection using fitness variance, adaptive population size, and a more robust archive update strategy.", "code": "import numpy as np\n\nclass DiversityAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, stagnation_threshold=10, pop_size_adapt_freq=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.previous_best_fitness = np.Inf\n        self.fitness_history = []\n        self.pop_size_adapt_freq = pop_size_adapt_freq  # Frequency to adapt population size\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n        self.fitness_history.append(np.mean(self.fitness))\n\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.pop[i].copy()\n        \n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n\n            best_fitness_current_iter = np.min(self.fitness)\n            if best_fitness_current_iter >= self.previous_best_fitness:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n            self.previous_best_fitness = best_fitness_current_iter\n            \n            # Stagnation Detection based on fitness variance\n            fitness_variance = np.var(self.fitness)\n            if fitness_variance < 1e-6:  # Adjust threshold as needed\n                self.stagnation_counter += 1\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Replace worst individual(s) with random ones\n                num_to_replace = max(1, int(0.1 * self.pop_size))  # Replace 10% or at least 1\n                worst_indices = np.argsort(self.fitness)[-num_to_replace:]\n                for worst_index in worst_indices:\n                    self.pop[worst_index] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    self.fitness[worst_index] = func(self.pop[worst_index])\n                    self.budget -= 1\n\n                    if self.fitness[worst_index] < self.f_opt:\n                        self.f_opt = self.fitness[worst_index]\n                        self.x_opt = self.pop[worst_index].copy()\n                self.stagnation_counter = 0  # Reset counter\n            \n            if iteration % self.pop_size_adapt_freq == 0:\n                # Adapt population size based on improvement\n                improvement = self.fitness_history[-1] - best_fitness_current_iter if len(self.fitness_history) > 0 else 0\n                if improvement > 1e-3:  # Significant improvement\n                    self.pop_size = min(100, int(self.pop_size * 1.1))  # Increase pop size\n                else:\n                    self.pop_size = max(10, int(self.pop_size * 0.9))  # Decrease pop size\n                \n                # Regenerate population with new size\n                old_pop = self.pop.copy()\n                old_fitness = self.fitness.copy()\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.budget -= self.pop_size\n\n                # Keep the best individuals from the previous population\n                num_to_keep = min(self.pop_size, len(old_pop))\n                best_indices = np.argsort(old_fitness)[:num_to_keep]\n                self.pop[:num_to_keep] = old_pop[best_indices]\n                self.fitness[:num_to_keep] = old_fitness[best_indices]\n\n                for i in range(self.pop_size):\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.pop[i].copy()\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n\n                # Handle archive with higher probability\n                if len(self.archive) > 0 and np.random.rand() < 0.2:  # Increased archive usage\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant = self.pop[a] + self.F * (self.pop[b] - self.archive[arc_idx])\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update archive: Replace the worst element in archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        archive_fitness = np.array([func(x) for x in self.archive])\n                        idx_to_replace = np.argmax(archive_fitness)  # Replace worst in archive\n                        self.archive[idx_to_replace] = self.pop[i].copy()\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i].copy()\n                \n                # Adaptive F and CR (simplified)\n                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.9, 0.2), 0.1, 1.0)\n                \n                if self.budget <= 0:\n                    break\n\n            self.fitness_history.append(np.mean(self.fitness))\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm DiversityAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1eb4f868-b4ac-4344-a17f-224f7de28732"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "f7c808d2-ce58-44af-9108-a70897cf9eac", "fitness": 0.7137881531638037, "name": "DynamicPopulationDE", "description": "A Differential Evolution strategy with a dynamically adjusted population size based on the success rate of the individuals and a mutation strategy employing both current-to-best and random components.", "code": "import numpy as np\n\nclass DynamicPopulationDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, F=0.5, Cr=0.9):\n        \"\"\"\n        Differential Evolution algorithm with dynamic population size and a hybrid mutation strategy.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            initial_pop_size (int): The initial population size.\n            min_pop_size (int): The minimum population size.\n            max_pop_size (int): The maximum population size.\n            F (float): The scaling factor for differential variation.\n            Cr (float): The crossover rate.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.pop_size = initial_pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with dynamic population size.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n\n        success_counter = 0\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation: current-to-best/1 and rand/1\n                if np.random.rand() < 0.5: # Choose mutation strategy\n                    # Current-to-best/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F * (self.pop[self.best_idx] - self.pop[i]) + self.F * (x_r1 - x_r2)\n                else:\n                    # Rand/1\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[indices]\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n                    success_counter += 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n                \n                if fevals >= self.budget:\n                    break\n\n            # Adjust population size based on success rate\n            success_rate = success_counter / self.pop_size\n            success_counter = 0 # Reset counter\n            \n            if success_rate > 0.2 and self.pop_size < self.max_pop_size:\n                self.pop_size = min(self.pop_size + 1, self.max_pop_size)\n                self.pop = np.vstack((self.pop, np.random.uniform(func.bounds.lb, func.bounds.ub, size=(1, self.dim))))\n                self.fitness = np.append(self.fitness, func(self.pop[-1]))\n                fevals += 1\n                if self.fitness[-1] < self.f_opt:\n                    self.f_opt = self.fitness[-1]\n                    self.x_opt = self.pop[-1]\n                    self.best_idx = self.pop_size - 1\n\n\n            elif success_rate < 0.05 and self.pop_size > self.min_pop_size:\n                # Remove the worst individual\n                worst_idx = np.argmax(self.fitness)\n                self.pop = np.delete(self.pop, worst_idx, axis=0)\n                self.fitness = np.delete(self.fitness, worst_idx)\n                self.pop_size -= 1\n                self.best_idx = np.argmin(self.fitness) #Update best index\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm DynamicPopulationDE scored 0.714 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8d322458-b77a-4531-85a5-aa8935bb188e"], "operator": null, "metadata": {"aucs": [0.3397566874157304, 0.672668857923492, 0.7116393171530282, 0.913450044566039, 0.7522575689136394, 0.7897141592786174, 0.551188596857114, 0.6691720273061712, 0.7538256390838467, 0.6322902917306115, 0.8921885666434729, 0.9937295926609574, 0.6715026814532488, 0.7460000215677915, 0.935718546745348, 0.789583150783776, 0.6209769593386274, 0.8840257998869817, 0.3420824672581625, 0.6139920867094193]}}
{"id": "ad7a0ab9-1830-4670-9557-8c4399f3fcdb", "fitness": 0.28083833378414547, "name": "HybridPSODE_Restart_Enhanced", "description": "Combines PSO and DE with adaptive parameter control, a stagnation detection mechanism using both fitness and diversity, and a local search strategy upon stagnation.", "code": "import numpy as np\n\nclass HybridPSODE_Restart_Enhanced:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, c1=2.0, c2=2.0, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, stagnation_limit=50, diversity_threshold=0.1, local_search_probability=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr_init = cr_init\n        self.cr_end = cr_end\n        self.f_init = f_init\n        self.f_end = f_end\n        self.stagnation_limit = stagnation_limit\n        self.diversity_threshold = diversity_threshold\n        self.local_search_probability = local_search_probability\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.Inf\n        self.best_position = None\n        self.pbest_fitness = None\n        self.pbest_position = None\n        self.velocity = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.last_best_fitness = np.Inf\n        self.stagnation_fitness_limit = 20  # How many iterations of same best fitness before stagnation\n\n    def initialize(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        self.pbest_fitness = np.copy(self.fitness)\n        self.pbest_position = np.copy(self.pop)\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.velocity = np.zeros_like(self.pop)\n        self.last_best_fitness = self.best_fitness\n\n    def update_best(self):\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.pbest_fitness[i]:\n                self.pbest_fitness[i] = self.fitness[i]\n                self.pbest_position[i] = self.pop[i].copy()\n\n        if np.min(self.pbest_fitness) < self.best_fitness:\n            self.best_fitness = np.min(self.pbest_fitness)\n            self.best_position = self.pbest_position[np.argmin(self.pbest_fitness)].copy()\n            self.stagnation_counter = 0  # Reset stagnation counter\n        else:\n            self.stagnation_counter += 1\n\n    def de_mutation(self, cr, f):\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.pop[idxs]\n            v = x1 + f * (x2 - x3)\n\n            #Ensure bounds\n            v = np.clip(v, -5.0, 5.0)\n\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < cr or j == j_rand:\n                    self.pop[i, j] = v[j]\n\n    def pso_update(self, w):\n        self.velocity = (w * self.velocity +\n                    self.c1 * np.random.rand(self.pop_size, self.dim) * (self.pbest_position - self.pop) +\n                    self.c2 * np.random.rand(self.pop_size, self.dim) * (self.best_position - self.pop))\n\n        self.pop += self.velocity\n\n        #Ensure bounds\n        self.pop = np.clip(self.pop, -5.0, 5.0)\n\n    def calculate_diversity(self):\n        centroid = np.mean(self.pop, axis=0)\n        distances = np.linalg.norm(self.pop - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def restart_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        self.pbest_fitness = np.copy(self.fitness)\n        self.pbest_position = np.copy(self.pop)\n\n    def local_search(self, func):\n        # Apply local search around the best solution\n        for i in range(self.pop_size):\n            if np.random.rand() < self.local_search_probability:\n                # Create a small perturbation\n                perturbation = np.random.normal(0, 0.1, size=self.dim)\n                new_position = self.best_position + perturbation\n\n                # Ensure bounds\n                new_position = np.clip(new_position, -5.0, 5.0)\n\n                new_fitness = func(new_position)\n                self.eval_count += 1\n\n                if new_fitness < self.best_fitness:\n                    self.best_fitness = new_fitness\n                    self.best_position = new_position.copy()\n                \n                if new_fitness < self.pbest_fitness[i]:\n                    self.pbest_fitness[i] = new_fitness\n                    self.pbest_position[i] = new_position.copy()\n\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n            # Adaptive Cr and F\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (self.eval_count / self.budget)\n            f = self.f_init - (self.f_init - self.f_end) * (self.eval_count / self.budget)\n\n            # Apply DE mutation\n            self.de_mutation(cr, f)\n\n            # Apply PSO update\n            self.pso_update(w)\n\n            # Evaluate new solutions\n            new_fitness = np.array([func(x) for x in self.pop])\n            self.eval_count += self.pop_size\n            self.fitness = new_fitness\n\n            #Update personal best and global best\n            self.update_best()\n\n            # Stagnation Check\n            if self.best_fitness == self.last_best_fitness:\n                self.stagnation_fitness_limit += 1\n            else:\n                self.stagnation_fitness_limit = 0\n            self.last_best_fitness = self.best_fitness\n\n            if self.stagnation_counter > self.stagnation_limit or self.stagnation_fitness_limit > self.stagnation_limit :\n                diversity = self.calculate_diversity()\n                if diversity < self.diversity_threshold:\n                    self.local_search(func)\n                    self.restart_population(func)\n                    self.stagnation_counter = 0\n                    self.stagnation_fitness_limit = 0\n\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSODE_Restart_Enhanced scored 0.281 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cf82703d-14a8-46dc-8369-172bca615320"], "operator": null, "metadata": {"aucs": [0.1073767191997771, 0.1653765704837118, 0.2550154408685773, 0.21486484090621782, 0.21766611786418766, 0.2325064032606845, 0.21720173066793824, 0.18161784873329256, 0.1955712029749459, 0.16493137308226125, 0.223058565729645, 0.9988234978343801, 0.2332359740475295, 0.23190421945513828, 0.6005640380207955, 0.2803595304974382, 0.21568526844572922, 0.2677098637522055, 0.1660357123628472, 0.4472617574956055]}}
{"id": "f7583544-1f94-449c-b947-d6bfea07e377", "fitness": 0.6762689727713247, "name": "ADE", "description": "Adaptive Differential Evolution with improved parameter adaptation using a success-history based adaptation and a better archive update strategy.", "code": "import numpy as np\n\nclass ADE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=100, F=0.5, Cr=0.9, adapt_freq=10, memory_size=10):\n        \"\"\"\n        Adaptive Differential Evolution algorithm with improved parameter adaptation and archive handling.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            archive_size (int): The size of the archive.\n            F (float): The initial scaling factor for differential variation.\n            Cr (float): The initial crossover rate.\n            adapt_freq (int): How often to adapt F and Cr parameters.\n            memory_size (int): The size of the memory for successful F and Cr values.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.archive = None\n        self.adapt_freq = adapt_freq\n        self.fevals = 0\n        self.memory_size = memory_size\n        self.F_memory = np.ones(memory_size) * F\n        self.Cr_memory = np.ones(memory_size) * Cr\n        self.memory_index = 0\n        self.success_F = []\n        self.success_Cr = []\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))  # Initialize archive\n        self.archive_fitness = np.array([np.inf] * self.archive_size) #Archive fitness values\n        self.fevals = self.pop_size # Initial population evaluation\n\n        while self.fevals < self.budget:\n            for i in range(self.pop_size):\n                # Adaptation of F and Cr using memory\n                self.F = np.random.choice(self.F_memory)\n                self.Cr = np.random.choice(self.Cr_memory)\n\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[indices]\n\n                # Add archive member to the selection pool with small probability\n                if np.random.rand() < 0.1:\n                    arch_ind = np.random.choice(self.archive_size, 1)[0]\n                    x_r3 = self.archive[arch_ind]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    # Store successful F and Cr values\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n\n                    # Update population\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    #Update archive: replace the worst archive member only if the trial vector is better than the worst in the archive AND better than the current individual\n                    if f_trial < np.max(self.archive_fitness) and f_trial < self.fitness[i]:\n                        worst_index = np.argmax(self.archive_fitness)\n                        self.archive[worst_index] = x_trial\n                        self.archive_fitness[worst_index] = f_trial\n                \n                if f_trial < self.f_opt:\n                  self.f_opt = f_trial\n                  self.x_opt = x_trial\n\n                if self.fevals >= self.budget:\n                    break\n\n            # Update F and Cr memory\n            if self.success_F:\n                self.F_memory[self.memory_index] = np.mean(self.success_F)\n                self.Cr_memory[self.memory_index] = np.mean(self.success_Cr)\n                self.memory_index = (self.memory_index + 1) % self.memory_size\n                self.success_F = []\n                self.success_Cr = []\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm ADE scored 0.676 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7ea90aea-883c-425d-9400-666a45683148"], "operator": null, "metadata": {"aucs": [0.28841429353353965, 0.597969339938522, 0.6334278714128854, 0.8670987813447268, 0.7154101172259769, 0.7705796901269284, 0.620842992959814, 0.6223748375197167, 0.6870400054546373, 0.6032528286128964, 0.867527844099957, 0.9974180415256898, 0.6233650493525953, 0.7001530708204369, 0.9297224811826028, 0.7587530670069756, 0.5761894198298229, 0.8192617804479148, 0.3482412267067786, 0.49833671632407417]}}
{"id": "19aecb8f-306f-4844-84c3-4f2928ae91ae", "fitness": 0.7008822361764058, "name": "DiversityAdaptiveDE", "description": "Diversity Adaptive DE with improved stagnation detection using fitness variance and a dynamically adjusted archive update probability.", "code": "import numpy as np\n\nclass DiversityAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, stagnation_threshold=10, stagnation_fitness_threshold=1e-6):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.stagnation_fitness_threshold = stagnation_fitness_threshold\n        self.previous_best_fitness = np.Inf\n        self.archive_update_prob = 0.1  # Initial archive update probability\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.pop[i].copy()\n        \n        while self.budget > 0:\n            fitness_variance = np.var(self.fitness)\n            best_fitness_current_iter = np.min(self.fitness)\n            \n            if best_fitness_current_iter >= self.previous_best_fitness and fitness_variance < self.stagnation_fitness_threshold:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n            self.previous_best_fitness = best_fitness_current_iter\n            \n            if self.stagnation_counter > self.stagnation_threshold:\n                # Replace worst individual with a random one\n                worst_index = np.argmax(self.fitness)\n                self.pop[worst_index] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                self.fitness[worst_index] = func(self.pop[worst_index])\n                self.budget -= 1\n                self.stagnation_counter = 0  # Reset counter\n\n                if self.fitness[worst_index] < self.f_opt:\n                    self.f_opt = self.fitness[worst_index]\n                    self.x_opt = self.pop[worst_index].copy()\n\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n\n                # Handle archive\n                if len(self.archive) > 0 and np.random.rand() < self.archive_update_prob:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant = self.pop[a] + self.F * (self.pop[b] - self.archive[arc_idx])\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_to_replace] = self.pop[i].copy()\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i].copy()\n                \n                # Adaptive F and CR (simplified)\n                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.9, 0.2), 0.1, 1.0)\n\n                # Dynamically adjust archive update probability\n                if fitness_variance < self.stagnation_fitness_threshold:\n                    self.archive_update_prob = min(self.archive_update_prob + 0.01, 0.5)  # Increase probability when stagnating\n                else:\n                    self.archive_update_prob = max(self.archive_update_prob - 0.01, 0.01) # Decrease otherwise\n                \n                if self.budget <= 0:\n                    break\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm DiversityAdaptiveDE scored 0.701 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1eb4f868-b4ac-4344-a17f-224f7de28732"], "operator": null, "metadata": {"aucs": [0.3012904833986315, 0.6754609269700034, 0.6952236019438967, 0.8507395895087317, 0.7423198647614448, 0.7922581048301324, 0.6268794796798189, 0.6813387755317907, 0.7418674295024662, 0.7260583898614594, 0.8520117678857942, 0.9924615069664117, 0.6294791216424604, 0.721064541202113, 0.8900347261142486, 0.7803987203426981, 0.6340524644753536, 0.8391650489291397, 0.31521859895863724, 0.5303215810228844]}}
{"id": "e7ae8100-0dda-4129-8d99-fcdc67b5617f", "fitness": -Infinity, "name": "AdaptiveHybridPSODE", "description": "Adaptive Hybrid PSO-DE with dynamic parameter adjustment based on success history and enhanced restart mechanism using opposition-based learning.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, c1_init=2.0, c1_end=1.0, c2_init=1.0, c2_end=2.0, cr_init=0.7, cr_end=0.9, f_init=0.8, f_end=0.6, stagnation_limit=50, diversity_threshold=0.1, success_rate_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1_init = c1_init\n        self.c1_end = c1_end\n        self.c2_init = c2_init\n        self.c2_end = c2_end\n        self.cr_init = cr_init\n        self.cr_end = cr_end\n        self.f_init = f_init\n        self.f_end = f_end\n        self.stagnation_limit = stagnation_limit\n        self.diversity_threshold = diversity_threshold\n        self.success_rate_memory = success_rate_memory\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.Inf\n        self.best_position = None\n        self.pbest_fitness = None\n        self.pbest_position = None\n        self.velocity = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.success_history_cr = []\n        self.success_history_f = []\n    \n    def initialize(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        self.pbest_fitness = np.copy(self.fitness)\n        self.pbest_position = np.copy(self.pop)\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.velocity = np.zeros_like(self.pop)\n        \n    def update_best(self):\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.pbest_fitness[i]:\n                self.pbest_fitness[i] = self.fitness[i]\n                self.pbest_position[i] = self.pop[i].copy()\n\n        if np.min(self.pbest_fitness) < self.best_fitness:\n            self.best_fitness = np.min(self.pbest_fitness)\n            self.best_position = self.pbest_position[np.argmin(self.pbest_fitness)].copy()\n            self.stagnation_counter = 0 # Reset stagnation counter\n        else:\n            self.stagnation_counter +=1\n            \n    def de_mutation(self):\n        cr = self.cr_init - (self.cr_init - self.cr_end) * (self.eval_count / self.budget)\n        f = self.f_init - (self.f_init - self.f_end) * (self.eval_count / self.budget)\n\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.pop[idxs]\n            v = x1 + f * (x2 - x3)\n            \n            #Ensure bounds\n            v = np.clip(v, -5.0, 5.0)\n            \n            j_rand = np.random.randint(self.dim)\n            trial_vector = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < cr or j == j_rand:\n                    trial_vector[j] = v[j]\n                    \n            trial_fitness = func(trial_vector)\n            self.eval_count += 1\n            \n            if trial_fitness < self.fitness[i]:\n                self.pop[i] = trial_vector\n                self.fitness[i] = trial_fitness\n                self.success_history_cr.append(cr)\n                self.success_history_f.append(f)\n                if len(self.success_history_cr) > self.success_rate_memory:\n                    self.success_history_cr.pop(0)\n                    self.success_history_f.pop(0)\n\n    def pso_update(self, w, c1, c2):\n        self.velocity = (w * self.velocity +\n                    c1 * np.random.rand(self.pop_size, self.dim) * (self.pbest_position - self.pop) +\n                    c2 * np.random.rand(self.pop_size, self.dim) * (self.best_position - self.pop))\n        \n        self.pop += self.velocity\n        \n        #Ensure bounds\n        self.pop = np.clip(self.pop, -5.0, 5.0)\n\n    def calculate_diversity(self):\n        centroid = np.mean(self.pop, axis=0)\n        distances = np.linalg.norm(self.pop - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def restart_population(self, func):\n        # Opposition-based learning for restart\n        new_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        opposite_pop = func.bounds.lb + func.bounds.ub - self.pop\n        \n        # Evaluate opposite population\n        opposite_fitness = np.array([func(x) for x in opposite_pop])\n        self.eval_count += self.pop_size\n\n        # Combine original and opposite populations, selecting the best\n        combined_pop = np.vstack((self.pop, opposite_pop))\n        combined_fitness = np.hstack((self.fitness, opposite_fitness))\n        \n        #Select best individuals for the new population\n        idx = np.argsort(combined_fitness)[:self.pop_size]\n        self.pop = combined_pop[idx]\n        self.fitness = combined_fitness[idx]\n\n        self.pbest_fitness = np.copy(self.fitness)\n        self.pbest_position = np.copy(self.pop)\n\n        # Do not change best fitness/position\n        \n    def __call__(self, func):\n        self.initialize(func)\n        \n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n            c1 = self.c1_init - (self.c1_init - self.c1_end) * (self.eval_count / self.budget)\n            c2 = self.c2_init - (self.c2_init - self.c2_end) * (self.eval_count / self.budget)\n            \n            # Apply DE mutation\n            self.de_mutation()\n            \n            # Apply PSO update\n            self.pso_update(w, c1, c2)\n            \n            # Evaluate new solutions (already done inside de_mutation when trial_vector is better)\n            #new_fitness = np.array([func(x) for x in self.pop])\n            #self.eval_count += self.pop_size\n            #self.fitness = new_fitness\n            \n            #Update personal best and global best\n            self.update_best()\n            \n            # Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_limit:\n                diversity = self.calculate_diversity()\n                if diversity < self.diversity_threshold:\n                    self.restart_population(func)\n                    self.stagnation_counter = 0  # Reset counter after restart\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 2, "feedback": "An exception occurred: name 'func' is not defined.", "error": "", "parent_ids": ["cf82703d-14a8-46dc-8369-172bca615320"], "operator": null, "metadata": {}}
{"id": "0222700c-a2f7-4ec2-8d35-bee38849cbe6", "fitness": 0.4786702065999295, "name": "AdaptivePopulationBasedSA", "description": "Adaptive Population-Based Simulated Annealing (APBSA) that adjusts temperature based on population diversity and uses a mutation operator inspired by Differential Evolution.", "code": "import numpy as np\n\nclass AdaptivePopulationBasedSA:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_temp=1.0, cooling_rate=0.9, temp_adaptive=True, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp_adaptive = temp_adaptive\n        self.diversity_threshold = diversity_threshold\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.Inf\n        self.best_position = None\n        self.eval_count = 0\n        self.temp = initial_temp\n\n    def initialize(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n\n    def de_mutation(self, pop, f=0.8):\n        new_pop = np.copy(pop)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = pop[idxs]\n            v = x1 + f * (x2 - x3)\n            \n            #Ensure bounds\n            v = np.clip(v, -5.0, 5.0)\n\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < 0.7 or j == j_rand:\n                    new_pop[i, j] = v[j]\n        return new_pop\n\n    def calculate_diversity(self):\n        centroid = np.mean(self.pop, axis=0)\n        distances = np.linalg.norm(self.pop - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            # Generate mutated population using DE\n            mutated_pop = self.de_mutation(self.pop)\n            mutated_fitness = np.array([func(x) for x in mutated_pop])\n            self.eval_count += self.pop_size\n\n            # Simulated Annealing acceptance criterion\n            delta_e = mutated_fitness - self.fitness\n            acceptance_prob = np.exp(-delta_e / self.temp)\n            \n            #Accept if better or based on acceptance probability\n            accept = (delta_e < 0) | (np.random.rand(self.pop_size) < acceptance_prob)\n            \n            self.pop[accept] = mutated_pop[accept]\n            self.fitness[accept] = mutated_fitness[accept]\n\n            # Update best solution\n            if np.min(self.fitness) < self.best_fitness:\n                self.best_fitness = np.min(self.fitness)\n                self.best_position = self.pop[np.argmin(self.fitness)].copy()\n\n            # Adaptive temperature adjustment\n            if self.temp_adaptive:\n                diversity = self.calculate_diversity()\n                if diversity < self.diversity_threshold:\n                    self.temp = self.initial_temp  # Reheat if diversity is low\n                else:\n                    self.temp *= self.cooling_rate #Cool normally\n            else:\n                self.temp *= self.cooling_rate\n            \n            self.temp = max(self.temp, 0.0001) #Ensure temp doesn't go to zero\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptivePopulationBasedSA scored 0.479 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cf82703d-14a8-46dc-8369-172bca615320"], "operator": null, "metadata": {"aucs": [0.20232972012928763, 0.3514559497951051, 0.42728410768095715, 0.8125132650792671, 0.37616946075645274, 0.4496542158763708, 0.3792208326412375, 0.3771376516125816, 0.37525595600584105, 0.33798699921894115, 0.7445666678725977, 0.9934385909447183, 0.3799148796780287, 0.3875494621688115, 0.6934287090545679, 0.5359780186497205, 0.41577593197801144, 0.585081191018942, 0.23895651238492732, 0.5097060094522237]}}
{"id": "21c1ca34-a919-46fb-ad04-1fab7b938da8", "fitness": 0.0, "name": "SelfAdaptiveRestartDE", "description": "Differential Evolution with self-adaptive parameters and a restart mechanism based on population stagnation.", "code": "import numpy as np\n\nclass SelfAdaptiveRestartDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_mu=0.5, F_std=0.3, Cr_mu=0.5, Cr_std=0.3, stagnation_threshold=10):\n        \"\"\"\n        Differential Evolution with self-adaptive parameters and restart mechanism.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            F_mu (float): Mean for the normal distribution of the scaling factor F.\n            F_std (float): Standard deviation for the normal distribution of the scaling factor F.\n            Cr_mu (float): Mean for the normal distribution of the crossover rate Cr.\n            Cr_std (float): Standard deviation for the normal distribution of the crossover rate Cr.\n            stagnation_threshold (int): Number of iterations without improvement before restart.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_mu = F_mu\n        self.F_std = F_std\n        self.Cr_mu = Cr_mu\n        self.Cr_std = Cr_std\n        self.stagnation_threshold = stagnation_threshold\n        self.pop = None\n        self.fitness = None\n        self.F = None\n        self.Cr = None\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.stagnation_counter = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.F = np.random.normal(self.F_mu, self.F_std, size=self.pop_size)\n        self.F = np.clip(self.F, 0.1, 1.0)\n        self.Cr = np.random.normal(self.Cr_mu, self.Cr_std, size=self.pop_size)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n        best_idx = np.argmin(self.fitness)\n        self.best_fitness = self.fitness[best_idx]\n        self.best_solution = self.pop[best_idx]\n        return self.pop_size\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with self-adaptive parameters and restart.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        fevals = self.initialize_population(func)\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[indices]\n                x_mutated = x_r1 + self.F[i] * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr[i] or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n                    self.F[i] = np.random.normal(self.F_mu, self.F_std)\n                    self.F[i] = np.clip(self.F[i], 0.1, 1.0)\n                    self.Cr[i] = np.random.normal(self.Cr_mu, self.Cr_std)\n                    self.Cr[i] = np.clip(self.Cr[i], 0.1, 1.0)\n\n                    if f_trial < self.best_fitness:\n                        self.best_fitness = f_trial\n                        self.best_solution = x_trial\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                if fevals >= self.budget:\n                    break\n\n            # Restart if stagnating\n            if self.stagnation_counter > self.stagnation_threshold:\n                fevals += self.initialize_population(func)\n                self.stagnation_counter = 0\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 3, "feedback": "The algorithm SelfAdaptiveRestartDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f7c808d2-ce58-44af-9108-a70897cf9eac"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "25592512-0a1c-4288-a73b-96e7319e5776", "fitness": 0.0, "name": "APSA_PSO", "description": "An adaptive metaheuristic combining aspects of Simulated Annealing and Particle Swarm Optimization with dynamic parameter adjustments based on population fitness improvements and stagnation detection.", "code": "import numpy as np\n\nclass APSA_PSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_temp=1.0, cooling_rate=0.9,\n                 inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, stagnation_threshold=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.stagnation_threshold = stagnation_threshold\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_fitness = np.Inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.temp = initial_temp\n        self.stagnation_counter = 0\n        self.previous_best_fitness = np.Inf\n\n    def initialize(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) #Initialize velocities\n        self.eval_count += self.pop_size\n        self.personal_best_positions = self.pop.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.previous_best_fitness = self.global_best_fitness\n        self.stagnation_counter = 0\n\n    def update_velocities(self):\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions - self.pop)\n        social_component = self.social_coeff * r2 * (self.global_best_position - self.pop)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_component + social_component\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            # Update velocities based on PSO\n            self.update_velocities()\n\n            # Move particles\n            new_pop = self.pop + self.velocities\n            new_pop = np.clip(new_pop, -5.0, 5.0)  # Ensure bounds\n\n            new_fitness = np.array([func(x) for x in new_pop])\n            self.eval_count += self.pop_size\n            \n            delta_e = new_fitness - self.fitness\n            acceptance_prob = np.exp(-delta_e / self.temp)\n            accept = (delta_e < 0) | (np.random.rand(self.pop_size) < acceptance_prob)\n\n            # Simulated Annealing acceptance\n            self.pop[accept] = new_pop[accept]\n            self.fitness[accept] = new_fitness[accept]\n\n            # Update personal best\n            improved = self.fitness < self.personal_best_fitness\n            self.personal_best_positions[improved] = self.pop[improved].copy()\n            self.personal_best_fitness[improved] = self.fitness[improved].copy()\n\n            # Update global best\n            if np.min(self.fitness) < self.global_best_fitness:\n                self.global_best_fitness = np.min(self.fitness)\n                self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n                self.stagnation_counter = 0 #Reset stagnation counter\n            else:\n                self.stagnation_counter += 1\n            \n            #Stagnation detection and adaptation\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Re-initialize a fraction of the population\n                num_reinit = int(0.2 * self.pop_size)\n                indices_to_reinit = np.random.choice(self.pop_size, num_reinit, replace=False)\n                self.pop[indices_to_reinit] = np.random.uniform(-5.0, 5.0, size=(num_reinit, self.dim))\n                self.fitness[indices_to_reinit] = np.array([func(x) for x in self.pop[indices_to_reinit]])\n                self.eval_count += num_reinit  #Correct the evaluation count.\n                \n                #Adjust parameters to encourage exploration\n                self.inertia_weight = min(0.9, self.inertia_weight + 0.05)\n                self.cognitive_coeff = max(1.0, self.cognitive_coeff - 0.1)\n                self.social_coeff = max(1.0, self.social_coeff - 0.1)\n                self.stagnation_counter = 0  # Reset counter\n            else:\n                # Gradual parameter adaptation\n                self.inertia_weight = max(0.4, self.inertia_weight - 0.001) #Slow decrease\n                self.cognitive_coeff = min(2.0, self.cognitive_coeff + 0.0005)\n                self.social_coeff = min(2.0, self.social_coeff + 0.0005)\n\n            #Cooling schedule\n            self.temp *= self.cooling_rate\n            self.temp = max(self.temp, 0.0001)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm APSA_PSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0222700c-a2f7-4ec2-8d35-bee38849cbe6"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "d90bb5ae-56fa-4e74-ab72-feb2c6621e71", "fitness": 0.0, "name": "DynamicPopulationDE_with_LocalSearch", "description": "Dynamically adjusts population size and mutation strategy weights based on success, incorporating a local search around the best solution.", "code": "import numpy as np\n\nclass DynamicPopulationDE_with_LocalSearch:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, F=0.5, Cr=0.9, local_search_prob=0.1):\n        \"\"\"\n        Differential Evolution algorithm with dynamic population size, a hybrid mutation strategy, and local search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            initial_pop_size (int): The initial population size.\n            min_pop_size (int): The minimum population size.\n            max_pop_size (int): The maximum population size.\n            F (float): The scaling factor for differential variation.\n            Cr (float): The crossover rate.\n            local_search_prob (float): Probability of performing local search around the best solution.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.pop_size = initial_pop_size\n        self.F = F\n        self.Cr = Cr\n        self.local_search_prob = local_search_prob\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.mutation_strategy_weights = [0.5, 0.5]  # Initial weights for current-to-best and rand/1\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with dynamic population size and local search.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n\n        success_counter = 0\n        mutation_success = [0, 0] # Counters for successful mutation strategies\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation: current-to-best/1 and rand/1, weighted selection\n                if np.random.rand() < self.mutation_strategy_weights[0]: # Choose mutation strategy\n                    # Current-to-best/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F * (self.pop[self.best_idx] - self.pop[i]) + self.F * (x_r1 - x_r2)\n                    mutation_type = 0\n                else:\n                    # Rand/1\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[indices]\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                    mutation_type = 1\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n                    success_counter += 1\n                    mutation_success[mutation_type] += 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n                \n                if fevals >= self.budget:\n                    break\n\n            # Adjust population size based on success rate\n            success_rate = success_counter / self.pop_size\n            success_counter = 0 # Reset counter\n            \n            if success_rate > 0.2 and self.pop_size < self.max_pop_size:\n                self.pop_size = min(self.pop_size + 1, self.max_pop_size)\n                self.pop = np.vstack((self.pop, np.random.uniform(func.bounds.lb, func.bounds.ub, size=(1, self.dim))))\n                self.fitness = np.append(self.fitness, func(self.pop[-1]))\n                fevals += 1\n                if self.fitness[-1] < self.f_opt:\n                    self.f_opt = self.fitness[-1]\n                    self.x_opt = self.pop[-1]\n                    self.best_idx = self.pop_size - 1\n\n\n            elif success_rate < 0.05 and self.pop_size > self.min_pop_size:\n                # Remove the worst individual\n                worst_idx = np.argmax(self.fitness)\n                self.pop = np.delete(self.pop, worst_idx, axis=0)\n                self.fitness = np.delete(self.fitness, worst_idx)\n                self.pop_size -= 1\n                self.best_idx = np.argmin(self.fitness) #Update best index\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n\n            # Adjust mutation strategy weights based on success\n            total_success = sum(mutation_success)\n            if total_success > 0:\n                self.mutation_strategy_weights[0] = mutation_success[0] / total_success\n                self.mutation_strategy_weights[1] = mutation_success[1] / total_success\n            mutation_success = [0, 0] # Reset mutation success counters\n\n            # Local search around the best solution\n            if np.random.rand() < self.local_search_prob:\n                x_local_search = self.x_opt + np.random.normal(0, 0.05, size=self.dim)  # Adjust step size as needed\n                x_local_search = np.clip(x_local_search, func.bounds.lb, func.bounds.ub)\n                f_local_search = func(x_local_search)\n                fevals += 1\n\n                if f_local_search < self.f_opt:\n                    self.f_opt = f_local_search\n                    self.x_opt = x_local_search\n                    self.fitness[self.best_idx] = f_local_search  # Update fitness of the best individual\n                    self.pop[self.best_idx] = x_local_search\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm DynamicPopulationDE_with_LocalSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f7c808d2-ce58-44af-9108-a70897cf9eac"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "9839b8e6-3cfb-4d63-9ee7-f3f1631585ed", "fitness": 0.0, "name": "EnhancedADE", "description": "Enhanced Adaptive Differential Evolution with periodic population rejuvenation and covariance matrix adaptation for mutation scaling.", "code": "import numpy as np\n\nclass EnhancedADE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=100, F=0.5, Cr=0.9, adapt_freq=10, memory_size=10, rejuvenation_rate=0.05, cma_learning_rate=0.1):\n        \"\"\"\n        Enhanced Adaptive Differential Evolution algorithm with improved parameter adaptation, archive handling,\n        periodic population rejuvenation and covariance matrix adaptation for mutation scaling.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            archive_size (int): The size of the archive.\n            F (float): The initial scaling factor for differential variation.\n            Cr (float): The initial crossover rate.\n            adapt_freq (int): How often to adapt F and Cr parameters.\n            memory_size (int): The size of the memory for successful F and Cr values.\n            rejuvenation_rate (float): The rate at which to rejuvenate the population (percentage of individuals to re-initialize).\n            cma_learning_rate (float): Learning rate for covariance matrix adaptation\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.archive = None\n        self.adapt_freq = adapt_freq\n        self.fevals = 0\n        self.memory_size = memory_size\n        self.F_memory = np.ones(memory_size) * F\n        self.Cr_memory = np.ones(memory_size) * Cr\n        self.memory_index = 0\n        self.success_F = []\n        self.success_Cr = []\n        self.rejuvenation_rate = rejuvenation_rate\n        self.cma_learning_rate = cma_learning_rate\n        self.C = np.eye(dim)  # Covariance matrix for CMA\n        self.mean = None\n        self.eigen_value = None\n        self.eigen_vector = None\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Enhanced Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = np.random.uniform(lb, ub, size=(self.archive_size, self.dim))  # Initialize archive\n        self.archive_fitness = np.array([np.inf] * self.archive_size) #Archive fitness values\n        self.fevals = self.pop_size # Initial population evaluation\n\n        self.mean = np.mean(self.pop, axis=0)\n        \n        def update_covariance_matrix(success_vector):\n            delta = success_vector - self.mean\n            self.C = (1 - self.cma_learning_rate) * self.C + self.cma_learning_rate * np.outer(delta, delta)\n            self.mean = success_vector\n            \n        def sample_from_covariance():\n            eigen_value, eigen_vector = np.linalg.eigh(self.C)\n            return self.mean + np.dot(eigen_vector, np.sqrt(eigen_value) * np.random.randn(self.dim))\n\n        while self.fevals < self.budget:\n            for i in range(self.pop_size):\n                # Adaptation of F and Cr using memory\n                self.F = np.random.choice(self.F_memory)\n                self.Cr = np.random.choice(self.Cr_memory)\n\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[indices]\n\n                # Add archive member to the selection pool with small probability\n                if np.random.rand() < 0.1:\n                    arch_ind = np.random.choice(self.archive_size, 1)[0]\n                    x_r3 = self.archive[arch_ind]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n\n                #CMA-ES Mutation\n                #x_mutated = sample_from_covariance()\n\n                x_mutated = np.clip(x_mutated, lb, ub)  # Keep within bounds\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                x_trial = np.clip(x_trial, lb, ub)\n                f_trial = func(x_trial)\n                self.fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    # Store successful F and Cr values\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n\n                    # Update population\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    #Update archive: replace the worst archive member only if the trial vector is better than the worst in the archive AND better than the current individual\n                    if f_trial < np.max(self.archive_fitness) and f_trial < self.fitness[i]:\n                        worst_index = np.argmax(self.archive_fitness)\n                        self.archive[worst_index] = x_trial\n                        self.archive_fitness[worst_index] = f_trial\n                        \n                    update_covariance_matrix(x_trial)\n                \n                if f_trial < self.f_opt:\n                  self.f_opt = f_trial\n                  self.x_opt = x_trial\n\n                if self.fevals >= self.budget:\n                    break\n\n            # Update F and Cr memory\n            if self.success_F:\n                self.F_memory[self.memory_index] = np.mean(self.success_F)\n                self.Cr_memory[self.memory_index] = np.mean(self.success_Cr)\n                self.memory_index = (self.memory_index + 1) % self.memory_size\n                self.success_F = []\n                self.success_Cr = []\n                \n            # Population Rejuvenation\n            num_rejuvenate = int(self.rejuvenation_rate * self.pop_size)\n            indices_to_rejuvenate = np.random.choice(self.pop_size, num_rejuvenate, replace=False)\n            self.pop[indices_to_rejuvenate] = np.random.uniform(lb, ub, size=(num_rejuvenate, self.dim))\n            self.fitness[indices_to_rejuvenate] = [func(x) for x in self.pop[indices_to_rejuvenate]]\n            self.fevals += num_rejuvenate\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedADE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f7583544-1f94-449c-b947-d6bfea07e377"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "05e82c6b-d6df-4991-aa50-e6a32c139c40", "fitness": 0.3708229166027127, "name": "HybridDE_NM", "description": "Hybridizes Differential Evolution with a Nelder-Mead simplex search, adaptively switching between global exploration and local refinement based on stagnation detection.", "code": "import numpy as np\n\nclass HybridDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_mutation_factor=0.8, de_crossover_rate=0.7, nm_alpha=1.0, nm_beta=0.5, nm_gamma=2.0, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.nm_alpha = nm_alpha  # Reflection coefficient\n        self.nm_beta = nm_beta    # Contraction coefficient\n        self.nm_gamma = nm_gamma  # Expansion coefficient\n        self.stagnation_threshold = stagnation_threshold\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.Inf\n        self.best_position = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.de_active = True  # Start with DE\n\n    def initialize(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n\n    def de_mutation(self, pop):\n        new_pop = np.copy(pop)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = pop[idxs]\n            v = x1 + self.de_mutation_factor * (x2 - x3)\n\n            # Ensure bounds\n            v = np.clip(v, -5.0, 5.0)\n\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.de_crossover_rate or j == j_rand:\n                    new_pop[i, j] = v[j]\n        return new_pop\n\n    def nelder_mead_step(self, vertices, func):\n        # Order vertices by fitness\n        fitness_values = np.array([func(v) for v in vertices])\n        self.eval_count += len(vertices)\n        sorted_indices = np.argsort(fitness_values)\n        vertices = vertices[sorted_indices]\n        fitness_values = fitness_values[sorted_indices]\n        \n        best, worst = vertices[0], vertices[-1]\n        f_best, f_worst = fitness_values[0], fitness_values[-1]\n        \n        centroid = np.mean(vertices[:-1], axis=0)\n\n        # Reflection\n        reflected_point = centroid + self.nm_alpha * (centroid - worst)\n        reflected_point = np.clip(reflected_point, -5.0, 5.0) #bounds\n        f_reflected = func(reflected_point)\n        self.eval_count += 1\n\n        if f_best <= f_reflected < fitness_values[-2]:\n            vertices[-1] = reflected_point\n            return vertices\n        elif f_reflected < f_best:\n            # Expansion\n            expanded_point = centroid + self.nm_gamma * (reflected_point - centroid)\n            expanded_point = np.clip(expanded_point, -5.0, 5.0) #bounds\n            f_expanded = func(expanded_point)\n            self.eval_count += 1\n\n            if f_expanded < f_reflected:\n                vertices[-1] = expanded_point\n            else:\n                vertices[-1] = reflected_point\n            return vertices\n        else:\n            # Contraction\n            contracted_point = centroid + self.nm_beta * (worst - centroid)\n            contracted_point = np.clip(contracted_point, -5.0, 5.0) #bounds\n            f_contracted = func(contracted_point)\n            self.eval_count += 1\n            if f_contracted < f_worst:\n                vertices[-1] = contracted_point\n                return vertices\n            else:\n                # Shrink\n                for i in range(1, len(vertices)):\n                    vertices[i] = best + self.nm_beta * (vertices[i] - best)\n                    vertices[i] = np.clip(vertices[i], -5.0, 5.0) #bounds\n\n                return vertices\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            if self.de_active:\n                # Differential Evolution\n                mutated_pop = self.de_mutation(self.pop)\n                mutated_fitness = np.array([func(x) for x in mutated_pop])\n                self.eval_count += self.pop_size\n\n                # Selection\n                improved = mutated_fitness < self.fitness\n                self.pop[improved] = mutated_pop[improved]\n                self.fitness[improved] = mutated_fitness[improved]\n            else:\n                # Nelder-Mead on the best solution\n                vertices = self.pop[np.argsort(self.fitness)[:self.dim+1]].copy() #take best dim+1 individuals\n                vertices = self.nelder_mead_step(vertices, func)\n                \n                fitness_values = np.array([func(x) for x in vertices])\n                self.eval_count += len(vertices)\n                \n                best_index = np.argmin(fitness_values)\n\n                #replace the worst individuals in pop with vertices\n                worst_indices = np.argsort(self.fitness)[-len(vertices):]\n                self.pop[worst_indices] = vertices\n                self.fitness[worst_indices] = fitness_values\n\n\n            # Update best solution\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.best_fitness:\n                self.best_fitness = current_best_fitness\n                self.best_position = self.pop[np.argmin(self.fitness)].copy()\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n\n            # Adaptive switching between DE and NM\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.de_active = not self.de_active\n                self.stagnation_counter = 0 #reset\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 3, "feedback": "The algorithm HybridDE_NM scored 0.371 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0222700c-a2f7-4ec2-8d35-bee38849cbe6"], "operator": null, "metadata": {"aucs": [0.20386122955269226, 0.5775159243539771, 0.7019145125041815, 0]}}
{"id": "936517df-4bb7-47a3-8800-61b09173f91e", "fitness": 0.6015085130506715, "name": "DynamicPopulationDE", "description": "Dynamic Population DE with aging mechanism to remove stagnant individuals and adaptive F and Cr parameters based on success history.", "code": "import numpy as np\n\nclass DynamicPopulationDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, F_initial=0.5, Cr_initial=0.9, archive_size=10):\n        \"\"\"\n        Differential Evolution algorithm with dynamic population size, aging mechanism and adaptive F and Cr.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            initial_pop_size (int): The initial population size.\n            min_pop_size (int): The minimum population size.\n            max_pop_size (int): The maximum population size.\n            F_initial (float): The initial scaling factor for differential variation.\n            Cr_initial (float): The initial crossover rate.\n            archive_size (int): Size of the archive for storing successful F and Cr values.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.pop_size = initial_pop_size\n        self.F = F_initial\n        self.Cr = Cr_initial\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.archive_F = []\n        self.archive_Cr = []\n        self.archive_size = archive_size\n        self.age = np.zeros(initial_pop_size) # Individual age, reset when improves\n        self.max_age = 5 #Max age before removal\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with dynamic population size, aging and adaptive F/Cr.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n\n        success_counter = 0\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Adaptation of F and Cr\n                if len(self.archive_F) > 0:\n                    self.F = np.random.choice(self.archive_F)\n                else:\n                    self.F = 0.5 # Default F\n                if len(self.archive_Cr) > 0:\n                    self.Cr = np.random.choice(self.archive_Cr)\n                else:\n                    self.Cr = 0.9 # Default Cr\n\n                # Mutation: current-to-best/1 and rand/1\n                if np.random.rand() < 0.5: # Choose mutation strategy\n                    # Current-to-best/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F * (self.pop[self.best_idx] - self.pop[i]) + self.F * (x_r1 - x_r2)\n                else:\n                    # Rand/1\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[indices]\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n                    success_counter += 1\n                    self.age[i] = 0 #Reset age\n                    # Archive successful F and Cr\n                    self.archive_F.append(self.F)\n                    self.archive_Cr.append(self.Cr)\n                    if len(self.archive_F) > self.archive_size:\n                        self.archive_F.pop(0)\n                        self.archive_Cr.pop(0)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n                else:\n                    self.age[i] += 1 #Increase age if no improvement\n\n                if fevals >= self.budget:\n                    break\n\n            # Adjust population size based on success rate\n            success_rate = success_counter / self.pop_size\n            success_counter = 0 # Reset counter\n            \n            if success_rate > 0.2 and self.pop_size < self.max_pop_size:\n                self.pop_size = min(self.pop_size + 1, self.max_pop_size)\n                self.pop = np.vstack((self.pop, np.random.uniform(func.bounds.lb, func.bounds.ub, size=(1, self.dim))))\n                self.fitness = np.append(self.fitness, func(self.pop[-1]))\n                self.age = np.append(self.age, 0) #New individual is young\n\n                fevals += 1\n                if self.fitness[-1] < self.f_opt:\n                    self.f_opt = self.fitness[-1]\n                    self.x_opt = self.pop[-1]\n                    self.best_idx = self.pop_size - 1\n\n\n            elif success_rate < 0.05 and self.pop_size > self.min_pop_size:\n                # Remove the worst individual\n                worst_idx = np.argmax(self.fitness) #Removes worst individual, irrespective of age\n                self.pop = np.delete(self.pop, worst_idx, axis=0)\n                self.fitness = np.delete(self.fitness, worst_idx)\n                self.age = np.delete(self.age, worst_idx) #remove age also\n                self.pop_size -= 1\n                self.best_idx = np.argmin(self.fitness) #Update best index\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n            \n            #Aging mechanism: remove old individuals\n            old_indices = np.where(self.age >= self.max_age)[0]\n            if len(old_indices) > 0 and self.pop_size > self.min_pop_size:\n                #remove oldest individual\n                oldest_idx = old_indices[np.argmax(self.age[old_indices])]\n                self.pop = np.delete(self.pop, oldest_idx, axis=0)\n                self.fitness = np.delete(self.fitness, oldest_idx)\n                self.age = np.delete(self.age, oldest_idx)\n                self.pop_size -= 1\n                self.best_idx = np.argmin(self.fitness) #Update best index\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm DynamicPopulationDE scored 0.602 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f7c808d2-ce58-44af-9108-a70897cf9eac"], "operator": null, "metadata": {"aucs": [0.555925646958532, 0.7765649231622965, 0.778775003615033, 0.8962769915174966, 0]}}
{"id": "20f4de27-b6f7-4e23-81c5-b6d635e0c1ce", "fitness": 0.43682047416704395, "name": "AdaptivePopulationBasedSA", "description": "Improved Adaptive Population-Based Simulated Annealing with adaptive mutation scaling and temperature adjustment based on fitness improvement rate.", "code": "import numpy as np\n\nclass AdaptivePopulationBasedSA:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_temp=1.0, cooling_rate=0.9, temp_adaptive=True, diversity_threshold=0.1, mutation_scaling=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp_adaptive = temp_adaptive\n        self.diversity_threshold = diversity_threshold\n        self.mutation_scaling = mutation_scaling\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.Inf\n        self.best_position = None\n        self.eval_count = 0\n        self.temp = initial_temp\n        self.fitness_history = [] #For adaptive temperature adjustment\n\n    def initialize(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.fitness_history.append(self.best_fitness)\n\n    def de_mutation(self, pop, f=0.8):\n        new_pop = np.copy(pop)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = pop[idxs]\n            v = x1 + f * (x2 - x3) * self.mutation_scaling  # Scale the mutation\n            \n            #Ensure bounds\n            v = np.clip(v, -5.0, 5.0)\n\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < 0.7 or j == j_rand:\n                    new_pop[i, j] = v[j]\n        return new_pop\n\n    def calculate_diversity(self):\n        centroid = np.mean(self.pop, axis=0)\n        distances = np.linalg.norm(self.pop - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            # Generate mutated population using DE\n            mutated_pop = self.de_mutation(self.pop)\n            mutated_fitness = np.array([func(x) for x in mutated_pop])\n            self.eval_count += self.pop_size\n\n            # Simulated Annealing acceptance criterion\n            delta_e = mutated_fitness - self.fitness\n            acceptance_prob = np.exp(-delta_e / self.temp)\n            \n            #Accept if better or based on acceptance probability\n            accept = (delta_e < 0) | (np.random.rand(self.pop_size) < acceptance_prob)\n            \n            self.pop[accept] = mutated_pop[accept]\n            self.fitness[accept] = mutated_fitness[accept]\n\n            # Update best solution\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.best_fitness:\n                self.best_fitness = current_best_fitness\n                self.best_position = self.pop[np.argmin(self.fitness)].copy()\n\n            # Adaptive temperature adjustment based on fitness improvement\n            if self.temp_adaptive:\n                #Calculate improvement ratio over a window\n                improvement = 0\n                if len(self.fitness_history) > 5:\n                    improvement = (self.fitness_history[-5] - self.best_fitness) / self.fitness_history[-5]\n\n                if improvement > 0.01:  #Significant improvement, reduce temp\n                    self.temp *= self.cooling_rate\n                elif self.calculate_diversity() < self.diversity_threshold:\n                     self.temp = self.initial_temp #Reheat on low diversity\n                else:\n                    self.temp = min(self.temp * (1/self.cooling_rate), self.initial_temp) #Slightly increase temp if no improvement\n\n            else:\n                self.temp *= self.cooling_rate\n            \n            self.temp = max(self.temp, 0.0001) #Ensure temp doesn't go to zero\n            self.fitness_history.append(self.best_fitness) #Track fitness history\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptivePopulationBasedSA scored 0.437 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0222700c-a2f7-4ec2-8d35-bee38849cbe6"], "operator": null, "metadata": {"aucs": [0.2719915109948432, 0.4889631905175731, 0.30597333178930375, 0.43501627991969216, 0.3657457205878665, 0.4899106738557367, 0.42487716454109403, 0.4069646904987547, 0.36363766619973326, 0.5120641541998361, 0.38654319425597294, 0.9964874673185523, 0.37321124205212786, 0.4257026923598053, 0.6462328030669406, 0.3384451500809347, 0.386275425069341, 0.4312434419704523, 0.22869678517585545, 0.4584268988864628]}}
{"id": "ea262787-54c8-4ef2-94dc-219976453f8c", "fitness": 0.5110703383735822, "name": "EnhancedAdaptivePopulationBasedSA", "description": "Enhanced Adaptive Population-Based Simulated Annealing with adaptive mutation scaling and temperature adjustment based on fitness improvement rate.", "code": "import numpy as np\n\nclass EnhancedAdaptivePopulationBasedSA:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_temp=1.0, cooling_rate=0.9, temp_adaptive=True, diversity_threshold=0.1, mutation_scaling=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp_adaptive = temp_adaptive\n        self.diversity_threshold = diversity_threshold\n        self.mutation_scaling = mutation_scaling\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.Inf\n        self.best_position = None\n        self.eval_count = 0\n        self.temp = initial_temp\n        self.fitness_history = []\n        self.improvement_rate = 0.0\n\n    def initialize(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.fitness_history.append(self.best_fitness)\n\n    def de_mutation(self, pop, f=0.8):\n        new_pop = np.copy(pop)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = pop[idxs]\n            v = x1 + f * self.mutation_scaling * (x2 - x3)  # Apply mutation scaling\n            \n            #Ensure bounds\n            v = np.clip(v, -5.0, 5.0)\n\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < 0.7 or j == j_rand:\n                    new_pop[i, j] = v[j]\n        return new_pop\n\n    def calculate_diversity(self):\n        centroid = np.mean(self.pop, axis=0)\n        distances = np.linalg.norm(self.pop - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def calculate_improvement_rate(self):\n        if len(self.fitness_history) > 1:\n            improvement = self.fitness_history[-2] - self.fitness_history[-1]\n            self.improvement_rate = improvement / abs(self.fitness_history[-2]) if self.fitness_history[-2] != 0 else 0\n        else:\n            self.improvement_rate = 0.0\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            # Generate mutated population using DE\n            mutated_pop = self.de_mutation(self.pop)\n            mutated_fitness = np.array([func(x) for x in mutated_pop])\n            self.eval_count += self.pop_size\n\n            # Simulated Annealing acceptance criterion\n            delta_e = mutated_fitness - self.fitness\n            acceptance_prob = np.exp(-delta_e / self.temp)\n            \n            #Accept if better or based on acceptance probability\n            accept = (delta_e < 0) | (np.random.rand(self.pop_size) < acceptance_prob)\n            \n            self.pop[accept] = mutated_pop[accept]\n            self.fitness[accept] = mutated_fitness[accept]\n\n            # Update best solution\n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.best_fitness:\n                self.best_fitness = current_best_fitness\n                self.best_position = self.pop[np.argmin(self.fitness)].copy()\n            \n            self.fitness_history.append(self.best_fitness)\n            self.calculate_improvement_rate()\n\n            # Adaptive mutation scaling adjustment\n            if self.improvement_rate > 0.01:  # Significant improvement\n                self.mutation_scaling *= 1.05  # Increase mutation\n            elif self.improvement_rate < 0.001:  # Stagnation\n                self.mutation_scaling *= 0.95  # Decrease mutation\n            self.mutation_scaling = np.clip(self.mutation_scaling, 0.5, 1.2)\n                \n            # Adaptive temperature adjustment\n            if self.temp_adaptive:\n                diversity = self.calculate_diversity()\n                if diversity < self.diversity_threshold:\n                    self.temp = self.initial_temp  # Reheat if diversity is low\n                else:\n                    self.temp *= self.cooling_rate #Cool normally\n            else:\n                self.temp *= self.cooling_rate\n            \n            self.temp = max(self.temp, 0.0001) #Ensure temp doesn't go to zero\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedAdaptivePopulationBasedSA scored 0.511 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0222700c-a2f7-4ec2-8d35-bee38849cbe6"], "operator": null, "metadata": {"aucs": [0.2565035147441773, 0.4796402785484847, 0.434079855906256, 0.9320627626900536, 0.4581221102884161, 0.4904874628213415, 0.4175423367616551, 0.38469864316507785, 0.40847119054845293, 0.3703424863100816, 0.7599040887760395, 0.9961159480169776, 0.3635853213639598, 0.40888674743051057, 0.7024125710406486, 0.5292303601712971, 0.42308410740034885, 0.58951798031938, 0.3180822981269553, 0.49863670304152996]}}
{"id": "7f90e646-64d3-4448-af87-b7f3781f43d7", "fitness": 0.7113701151833561, "name": "DynamicPopulationDE", "description": "Dynamically adjusts population size and DE parameters (F and Cr) based on success history, using a weighted average for parameter updates and a rank-based selection for population reduction.", "code": "import numpy as np\n\nclass DynamicPopulationDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, F=0.5, Cr=0.9, archive_size=10):\n        \"\"\"\n        Differential Evolution algorithm with dynamic population size and parameter adaptation based on success history.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            initial_pop_size (int): The initial population size.\n            min_pop_size (int): The minimum population size.\n            max_pop_size (int): The maximum population size.\n            F (float): The initial scaling factor for differential variation.\n            Cr (float): The initial crossover rate.\n            archive_size (int): The size of the archive for storing successful F and Cr values.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.pop_size = initial_pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.archive_F = np.full(archive_size, F)\n        self.archive_Cr = np.full(archive_size, Cr)\n        self.archive_idx = 0\n        self.archive_size = archive_size\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with dynamic population size and parameter adaptation.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n\n        success_F = []\n        success_Cr = []\n        success_count = 0\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Parameter Adaptation\n                F = np.random.choice(self.archive_F)\n                Cr = np.random.choice(self.archive_Cr)\n                \n                # Mutation: current-to-best/1\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.pop[indices]\n                x_mutated = self.pop[i] + F * (self.pop[self.best_idx] - self.pop[i]) + F * (x_r1 - x_r2)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    success_F.append(F)\n                    success_Cr.append(Cr)\n                    success_count += 1\n                    \n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n\n                if fevals >= self.budget:\n                    break\n            \n            # Update archive with successful F and Cr values using a weighted average\n            if success_F:\n                self.archive_F[self.archive_idx] = np.mean(success_F) * 0.5 + self.archive_F[self.archive_idx] * 0.5\n                self.archive_Cr[self.archive_idx] = np.mean(success_Cr) * 0.5 + self.archive_Cr[self.archive_idx] * 0.5\n                self.archive_idx = (self.archive_idx + 1) % self.archive_size\n                success_F = []\n                success_Cr = []\n            \n            # Adjust population size based on success rate\n            success_rate = success_count / self.pop_size\n            success_count = 0 # Reset counter\n\n            if success_rate > 0.2 and self.pop_size < self.max_pop_size:\n                self.pop_size = min(self.pop_size + 1, self.max_pop_size)\n                self.pop = np.vstack((self.pop, np.random.uniform(func.bounds.lb, func.bounds.ub, size=(1, self.dim))))\n                self.fitness = np.append(self.fitness, func(self.pop[-1]))\n                fevals += 1\n                if self.fitness[-1] < self.f_opt:\n                    self.f_opt = self.fitness[-1]\n                    self.x_opt = self.pop[-1]\n                    self.best_idx = self.pop_size - 1\n\n            elif success_rate < 0.05 and self.pop_size > self.min_pop_size:\n                # Rank-based population reduction\n                ranked_indices = np.argsort(self.fitness)[::-1]  # Sort in descending order (worst to best)\n                num_to_remove = min(int(0.1 * self.pop_size), self.pop_size - self.min_pop_size)  # Remove 10% or until min_pop_size\n                indices_to_remove = ranked_indices[:num_to_remove]\n                \n                self.pop = np.delete(self.pop, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size -= num_to_remove\n                self.best_idx = np.argmin(self.fitness)  # Update best index\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm DynamicPopulationDE scored 0.711 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f7c808d2-ce58-44af-9108-a70897cf9eac"], "operator": null, "metadata": {"aucs": [0.369967549842375, 0.7293805549149772, 0.7693224951478653, 0.9246511751119559, 0.7839082786777499, 0.8278962978602756, 0.33228514547811727, 0.708490549089995, 0.8074198710981276, 0.6016523150616034, 0.9078158060399939, 0.9972514871703015, 0.6842524582220573, 0.7497777243754988, 0.941442880815322, 0.7839981599231282, 0.6832639674321297, 0.8814123002527593, 0.23868043610242384, 0.5045328510504667]}}
{"id": "8822a15f-e73a-4fc1-a76b-30d8bb54da71", "fitness": 0.6434422441491525, "name": "ImprovedADE", "description": "Improved Adaptive Differential Evolution with self-adaptive population size, enhanced archive usage, and parameter control.", "code": "import numpy as np\n\nclass ImprovedADE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, archive_size=100, F=0.5, Cr=0.9, adapt_freq=10, memory_size=10, pop_size_adapt_freq=50):\n        \"\"\"\n        Improved Adaptive Differential Evolution algorithm with self-adaptive population size and improved parameter adaptation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size_init (int): The initial population size.\n            archive_size (int): The size of the archive.\n            F (float): The initial scaling factor for differential variation.\n            Cr (float): The initial crossover rate.\n            adapt_freq (int): How often to adapt F and Cr parameters.\n            memory_size (int): The size of the memory for successful F and Cr values.\n            pop_size_adapt_freq (int): How often to adapt the population size.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.archive_size = archive_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.archive = None\n        self.adapt_freq = adapt_freq\n        self.fevals = 0\n        self.memory_size = memory_size\n        self.F_memory = np.ones(memory_size) * F\n        self.Cr_memory = np.ones(memory_size) * Cr\n        self.memory_index = 0\n        self.success_F = []\n        self.success_Cr = []\n        self.pop_size_adapt_freq = pop_size_adapt_freq\n        self.success_rate = 0.0\n        self.success_history = []\n        self.min_pop_size = 10\n        self.max_pop_size = 100\n        self.archive_selection_rate = 0.1\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Improved Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))  # Initialize archive\n        self.archive_fitness = np.array([np.inf] * self.archive_size) #Archive fitness values\n        self.fevals = self.pop_size # Initial population evaluation\n        self.success_count = 0\n\n        while self.fevals < self.budget:\n            for i in range(self.pop_size):\n                # Adaptation of F and Cr using memory\n                self.F = np.random.choice(self.F_memory)\n                self.Cr = np.random.choice(self.Cr_memory)\n\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[indices]\n\n                # Add archive member to the selection pool with a probability\n                if np.random.rand() < self.archive_selection_rate:\n                    arch_ind = np.random.choice(self.archive_size, 1)[0]\n                    x_r3 = self.archive[arch_ind]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    # Store successful F and Cr values\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n                    self.success_count += 1\n\n                    # Update population\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    #Update archive: replace the worst archive member only if the trial vector is better than the worst in the archive\n                    if f_trial < np.max(self.archive_fitness):\n                        worst_index = np.argmax(self.archive_fitness)\n                        self.archive[worst_index] = x_trial\n                        self.archive_fitness[worst_index] = f_trial\n                \n                if f_trial < self.f_opt:\n                  self.f_opt = f_trial\n                  self.x_opt = x_trial\n\n                if self.fevals >= self.budget:\n                    break\n\n            # Update F and Cr memory\n            if self.success_F:\n                self.F_memory[self.memory_index] = np.mean(self.success_F)\n                self.Cr_memory[self.memory_index] = np.mean(self.success_Cr)\n                self.memory_index = (self.memory_index + 1) % self.memory_size\n                self.success_F = []\n                self.success_Cr = []\n                \n            #Adapt population size\n            if self.fevals // self.pop_size_adapt_freq > (self.fevals - self.pop_size) // self.pop_size_adapt_freq:\n                self.success_rate = self.success_count / self.pop_size\n                self.success_history.append(self.success_rate)\n                self.success_count = 0\n                \n                if len(self.success_history) > 5:\n                    window_size = 5\n                    recent_success = np.mean(self.success_history[-window_size:])\n\n                    if recent_success > 0.4:\n                        self.pop_size = min(self.pop_size + 5, self.max_pop_size)\n                        self.pop = np.vstack((self.pop, np.random.uniform(func.bounds.lb, func.bounds.ub, size=(5, self.dim))))\n                        self.fitness = np.concatenate((self.fitness, np.array([func(x) for x in self.pop[-5:]])))\n                        self.fevals += 5\n\n                    elif recent_success < 0.1 and self.pop_size > self.min_pop_size:\n                        num_reduce = min(5, self.pop_size - self.min_pop_size)\n                        indices_to_remove = np.argsort(self.fitness)[-num_reduce:]\n                        self.pop = np.delete(self.pop, indices_to_remove, axis=0)\n                        self.fitness = np.delete(self.fitness, indices_to_remove)\n                        self.pop_size -= num_reduce\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm ImprovedADE scored 0.643 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f7583544-1f94-449c-b947-d6bfea07e377"], "operator": null, "metadata": {"aucs": [0.3146953334811561, 0.6363217089906061, 0.6232195996524792, 0.8781448550505894, 0.6775642727266794, 0.6412573146555631, 0.5131086942661163, 0.5029570513607229, 0.5815218979149309, 0.683116712221711, 0.8518236786179629, 0.9986063949173579, 0.6506644449138259, 0.49342025929729283, 0.8650022478115732, 0.6761760162665039, 0.6305836437307104, 0.7750413894667249, 0.3477710808527905, 0.527848286787751]}}
{"id": "e1ae864e-db9b-4a43-adfb-73571b992dfa", "fitness": -Infinity, "name": "GaussianMixtureOptimizer", "description": "A self-organizing optimization algorithm that adjusts its search behavior based on the distribution of successful solutions, using a Gaussian Mixture Model to sample new candidate solutions.", "code": "import numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nclass GaussianMixtureOptimizer:\n    def __init__(self, budget=10000, dim=10, n_components=5, initial_samples=50, learning_rate=0.1):\n        \"\"\"\n        Gaussian Mixture Model based Optimization Algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            n_components (int): The number of components in the Gaussian Mixture Model.\n            initial_samples (int): Number of initial random samples.\n            learning_rate (float): Learning rate for updating GMM weights based on success.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.n_components = n_components\n        self.initial_samples = initial_samples\n        self.learning_rate = learning_rate\n        self.gmm = None\n        self.samples = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using a Gaussian Mixture Model.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n\n        # 1. Initial sampling\n        self.samples = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.initial_samples, self.dim))\n        self.fitness = np.array([func(x) for x in self.samples])\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.samples[np.argmin(self.fitness)]\n\n        fevals = self.initial_samples\n\n        # 2. Optimization loop\n        while fevals < self.budget:\n            # 3. Fit Gaussian Mixture Model to the best samples\n            num_good_samples = min(self.initial_samples // 2, len(self.samples))\n            idx = np.argsort(self.fitness)[:num_good_samples]  # Indices of best samples\n            good_samples = self.samples[idx]\n\n            try:\n                self.gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=100, random_state=0)\n                self.gmm.fit(good_samples)\n            except ValueError as e:\n                # Handle potential errors during GMM fitting (e.g., singular covariance)\n                # If fitting fails, sample randomly from the bounds.\n                new_samples = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.initial_samples, self.dim))\n                new_fitness = np.array([func(x) for x in new_samples])\n                fevals += self.initial_samples\n                \n                # Update the best solution if a better one is found.\n                for i in range(self.initial_samples):\n                    if new_fitness[i] < self.f_opt:\n                        self.f_opt = new_fitness[i]\n                        self.x_opt = new_samples[i]\n                \n                # Concatenate with old samples and fitnesses\n                self.samples = np.concatenate((self.samples, new_samples), axis=0)\n                self.fitness = np.concatenate((self.fitness, new_fitness))\n                continue\n\n\n            # 4. Sample new candidate solutions from the GMM\n            new_samples = self.gmm.sample(self.initial_samples)[0]\n            new_samples = np.clip(new_samples, func.bounds.lb, func.bounds.ub) # Clip to bounds\n            new_fitness = np.array([func(x) for x in new_samples])\n            fevals += self.initial_samples\n\n            # 5. Update the best solution if a better one is found.\n            for i in range(self.initial_samples):\n                if new_fitness[i] < self.f_opt:\n                    self.f_opt = new_fitness[i]\n                    self.x_opt = new_samples[i]\n\n            # 6. Update the sample set by replacing the worst samples with the new ones.\n            worst_indices = np.argsort(self.fitness)[-self.initial_samples:]\n            self.samples[worst_indices] = new_samples\n            self.fitness[worst_indices] = new_fitness\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occurred: name 'GaussianMixture' is not defined.", "error": "", "parent_ids": ["f7c808d2-ce58-44af-9108-a70897cf9eac"], "operator": null, "metadata": {}}
{"id": "1d56175f-03e6-4cf0-be31-0c76c93ff3ee", "fitness": 0.6017687214694823, "name": "DiversityAdaptiveDE", "description": "Diversity Adaptive DE with momentum-based adaptation of F and CR, and a more aggressive stagnation handling using both random restarts and population perturbation.", "code": "import numpy as np\n\nclass DiversityAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, stagnation_threshold=10, stagnation_fitness_threshold=1e-6, F=0.5, CR=0.9, archive_update_prob=0.1, f_momentum=0.9, cr_momentum=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = F  # Initial scaling factor\n        self.CR = CR  # Initial crossover rate\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.stagnation_fitness_threshold = stagnation_fitness_threshold\n        self.previous_best_fitness = np.Inf\n        self.archive_update_prob = archive_update_prob  # Initial archive update probability\n        self.f_momentum = f_momentum\n        self.cr_momentum = cr_momentum\n        self.f_memory = []\n        self.cr_memory = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.pop[i].copy()\n        \n        while self.budget > 0:\n            fitness_variance = np.var(self.fitness)\n            best_fitness_current_iter = np.min(self.fitness)\n            \n            if best_fitness_current_iter >= self.previous_best_fitness and fitness_variance < self.stagnation_fitness_threshold:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n            self.previous_best_fitness = best_fitness_current_iter\n            \n            if self.stagnation_counter > self.stagnation_threshold:\n                # Stagnation handling: restart or perturb\n                if np.random.rand() < 0.5:\n                    # Replace a portion of the population with random individuals\n                    num_to_replace = int(0.2 * self.pop_size)\n                    indices_to_replace = np.random.choice(self.pop_size, num_to_replace, replace=False)\n                    self.pop[indices_to_replace] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_replace, self.dim))\n                    self.fitness[indices_to_replace] = [func(x) for x in self.pop[indices_to_replace]]\n                    self.budget -= num_to_replace\n\n                    for i in indices_to_replace:\n                        if self.fitness[i] < self.f_opt:\n                            self.f_opt = self.fitness[i]\n                            self.x_opt = self.pop[i].copy()\n                else:\n                    # Perturb the population\n                    perturbation_scale = 0.05 * (func.bounds.ub - func.bounds.lb)\n                    self.pop += np.random.uniform(-perturbation_scale, perturbation_scale, size=self.pop.shape)\n                    self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n                    self.fitness = np.array([func(x) for x in self.pop])\n                    self.budget -= self.pop_size\n\n                    for i in range(self.pop_size):\n                        if self.fitness[i] < self.f_opt:\n                            self.f_opt = self.fitness[i]\n                            self.x_opt = self.pop[i].copy()\n                \n                self.stagnation_counter = 0  # Reset counter\n\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n\n                # Handle archive\n                if len(self.archive) > 0 and np.random.rand() < self.archive_update_prob:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant = self.pop[a] + self.F * (self.pop[b] - self.archive[arc_idx])\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_to_replace] = self.pop[i].copy()\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i].copy()\n\n                    # Adaptive F and CR using success history and momentum\n                    self.f_memory.append(self.F)\n                    self.cr_memory.append(self.CR)\n\n                    # Update F and CR based on success history\n                    success_F = np.mean(self.f_memory[-10:]) if len(self.f_memory) >= 10 else self.F\n                    success_CR = np.mean(self.cr_memory[-10:]) if len(self.cr_memory) >= 10 else self.CR\n                    \n                    self.F = self.f_momentum * self.F + (1 - self.f_momentum) * success_F\n                    self.CR = self.cr_momentum * self.CR + (1 - self.cr_momentum) * success_CR\n\n                \n                # Adaptive F and CR (simplified)\n                self.F = np.clip(np.random.normal(self.F, 0.3), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(self.CR, 0.2), 0.1, 1.0)\n\n                # Dynamically adjust archive update probability\n                if fitness_variance < self.stagnation_fitness_threshold:\n                    self.archive_update_prob = min(self.archive_update_prob + 0.01, 0.5)  # Increase probability when stagnating\n                else:\n                    self.archive_update_prob = max(self.archive_update_prob - 0.01, 0.01) # Decrease otherwise\n                \n                if self.budget <= 0:\n                    break\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm DiversityAdaptiveDE scored 0.602 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["19aecb8f-306f-4844-84c3-4f2928ae91ae"], "operator": null, "metadata": {"aucs": [0.21100991052853846, 0.40764238169904854, 0.5301993972442173, 0.7735795794379963, 0.6674698023137462, 0.6879687935241365, 0.6197174979473852, 0.562333916111023, 0.6520389355445331, 0.5234891252172147, 0.7916631706257818, 0.9984742392763122, 0.3926585972973018, 0.5889194614292228, 0.8769133701430235, 0.7297437790929657, 0.4363410513212945, 0.7975527146917858, 0.2843731458965938, 0.5032855600475244]}}
{"id": "71fe87bf-20e3-4eb5-9683-9619f206cfa4", "fitness": -Infinity, "name": "ImprovedADE", "description": "Improved Adaptive DE with orthogonal design for enhanced sampling, a better archive update strategy, and dynamic population size adjustment based on success rate.", "code": "import numpy as np\nfrom scipy.stats import norm\n\nclass ImprovedADE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, archive_size=100, F=0.5, Cr=0.9, adapt_freq=10, memory_size=10, pop_size_adapt_freq=50, archive_selection_rate=0.1):\n        \"\"\"\n        Improved Adaptive Differential Evolution algorithm with self-adaptive population size and improved parameter adaptation, orthogonal design and better archive update.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size_init (int): The initial population size.\n            archive_size (int): The size of the archive.\n            F (float): The initial scaling factor for differential variation.\n            Cr (float): The initial crossover rate.\n            adapt_freq (int): How often to adapt F and Cr parameters.\n            memory_size (int): The size of the memory for successful F and Cr values.\n            pop_size_adapt_freq (int): How often to adapt the population size.\n            archive_selection_rate (float): Probability of selecting an archive member for mutation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.archive_size = archive_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.archive = None\n        self.adapt_freq = adapt_freq\n        self.fevals = 0\n        self.memory_size = memory_size\n        self.F_memory = np.ones(memory_size) * F\n        self.Cr_memory = np.ones(memory_size) * Cr\n        self.memory_index = 0\n        self.success_F = []\n        self.success_Cr = []\n        self.pop_size_adapt_freq = pop_size_adapt_freq\n        self.success_rate = 0.0\n        self.success_history = []\n        self.min_pop_size = 10\n        self.max_pop_size = 100\n        self.archive_selection_rate = archive_selection_rate\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Improved Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))  # Initialize archive\n        self.archive_fitness = np.array([np.inf] * self.archive_size) #Archive fitness values\n        self.fevals = self.pop_size # Initial population evaluation\n        self.success_count = 0\n\n        while self.fevals < self.budget:\n            for i in range(self.pop_size):\n                # Adaptation of F and Cr using memory\n                self.F = np.random.choice(self.F_memory)\n                self.Cr = np.random.choice(self.Cr_memory)\n\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[indices]\n\n                # Add archive member to the selection pool with a probability\n                if np.random.rand() < self.archive_selection_rate:\n                    arch_ind = np.random.choice(self.archive_size, 1)[0]\n                    x_r3 = self.archive[arch_ind]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Orthogonal design-based sampling around the trial vector\n                x_trial_orth = np.copy(x_trial)\n                for j in range(self.dim):\n                    delta = 0.05 * (func.bounds.ub - func.bounds.lb)  # Small perturbation\n                    x_trial_orth[j] = np.clip(x_trial[j] + np.random.normal(0, delta), func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(x_trial)\n                f_trial_orth = func(x_trial_orth)\n                self.fevals += 2\n\n                if f_trial_orth < f_trial:\n                    f_trial = f_trial_orth\n                    x_trial = x_trial_orth\n\n                if f_trial < self.fitness[i]:\n                    # Store successful F and Cr values\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n                    self.success_count += 1\n\n                    # Update population\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    #Update archive: replace a random archive member if the trial vector is better than the worst AND better than a randomly chosen member\n                    random_index = np.random.randint(self.archive_size)\n                    if f_trial < np.max(self.archive_fitness) and f_trial < self.archive_fitness[random_index]:\n                        worst_index = np.argmax(self.archive_fitness)\n                        if np.random.rand() < 0.5: #Replace either the worst or the random index\n                            self.archive[worst_index] = x_trial\n                            self.archive_fitness[worst_index] = f_trial\n                        else:\n                            self.archive[random_index] = x_trial\n                            self.archive_fitness[random_index] = f_trial\n                \n                if f_trial < self.f_opt:\n                  self.f_opt = f_trial\n                  self.x_opt = x_trial\n\n                if self.fevals >= self.budget:\n                    break\n\n            # Update F and Cr memory\n            if self.success_F:\n                self.F_memory[self.memory_index] = np.mean(self.success_F)\n                self.Cr_memory[self.memory_index] = np.mean(self.success_Cr)\n                self.memory_index = (self.memory_index + 1) % self.memory_size\n                self.success_F = []\n                self.success_Cr = []\n                \n            #Adapt population size\n            if self.fevals // self.pop_size_adapt_freq > (self.fevals - self.pop_size) // self.pop_size_adapt_freq:\n                self.success_rate = self.success_count / self.pop_size\n                self.success_history.append(self.success_rate)\n                self.success_count = 0\n                \n                if len(self.success_history) > 5:\n                    window_size = 5\n                    recent_success = np.mean(self.success_history[-window_size:])\n\n                    if recent_success > 0.4:\n                        self.pop_size = min(self.pop_size + 5, self.max_pop_size)\n                        self.pop = np.vstack((self.pop, np.random.uniform(func.bounds.lb, func.bounds.ub, size=(5, self.dim))))\n                        self.fitness = np.concatenate((self.fitness, np.array([func(x) for x in self.pop[-5:]])))\n                        self.fevals += 5\n\n                    elif recent_success < 0.1 and self.pop_size > self.min_pop_size:\n                        num_reduce = min(5, self.pop_size - self.min_pop_size)\n                        indices_to_remove = np.argsort(self.fitness)[-num_reduce:]\n                        self.pop = np.delete(self.pop, indices_to_remove, axis=0)\n                        self.fitness = np.delete(self.fitness, indices_to_remove)\n                        self.pop_size -= num_reduce\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["8822a15f-e73a-4fc1-a76b-30d8bb54da71"], "operator": null, "metadata": {}}
{"id": "895b199c-0801-4b84-a6a1-8700486d84e5", "fitness": -Infinity, "name": "EnhancedImprovedADE", "description": "Enhanced Improved ADE with adaptive archive selection, aging-based population diversity, and self-adaptive F/Cr with a forgetting mechanism.", "code": "import numpy as np\n\nclass EnhancedImprovedADE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, archive_size=100, F=0.5, Cr=0.9, adapt_freq=10, memory_size=10, pop_size_adapt_freq=50, archive_selection_rate=0.1, aging_rate=0.02):\n        \"\"\"\n        Enhanced Improved Adaptive Differential Evolution algorithm with self-adaptive population size,\n        improved parameter adaptation, adaptive archive selection, and aging-based population diversity.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size_init (int): The initial population size.\n            archive_size (int): The size of the archive.\n            F (float): The initial scaling factor for differential variation.\n            Cr (float): The initial crossover rate.\n            adapt_freq (int): How often to adapt F and Cr parameters.\n            memory_size (int): The size of the memory for successful F and Cr values.\n            pop_size_adapt_freq (int): How often to adapt the population size.\n            archive_selection_rate (float): Probability of selecting an archive member.\n            aging_rate (float): Rate at which age increases for population members.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.archive_size = archive_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.archive = None\n        self.adapt_freq = adapt_freq\n        self.fevals = 0\n        self.memory_size = memory_size\n        self.F_memory = np.ones(memory_size) * F\n        self.Cr_memory = np.ones(memory_size) * Cr\n        self.memory_index = 0\n        self.success_F = []\n        self.success_Cr = []\n        self.pop_size_adapt_freq = pop_size_adapt_freq\n        self.success_rate = 0.0\n        self.success_history = []\n        self.min_pop_size = 10\n        self.max_pop_size = 100\n        self.archive_selection_rate = archive_selection_rate\n        self.success_count = 0\n        self.age = None\n        self.aging_rate = aging_rate\n        self.archive_age = np.zeros(archive_size)\n        self.archive_fitness = np.array([np.inf] * self.archive_size) #Archive fitness values\n        self.archive_selection_prob = np.ones(archive_size) / archive_size  # Initial uniform probabilities\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Enhanced Improved Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))  # Initialize archive\n        self.age = np.zeros(self.pop_size) # Initialize age of individuals\n        self.fevals = self.pop_size # Initial population evaluation\n        \n        # Evaluate initial archive\n        for i in range(self.archive_size):\n            self.archive_fitness[i] = func(self.archive[i])\n            self.fevals += 1\n\n        while self.fevals < self.budget:\n            for i in range(self.pop_size):\n                # Adaptation of F and Cr using memory\n                self.F = np.random.choice(self.F_memory)\n                self.Cr = np.random.choice(self.Cr_memory)\n\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[indices]\n\n                # Add archive member to the selection pool with a probability\n                if np.random.rand() < self.archive_selection_rate:\n                    arch_ind = np.random.choice(self.archive_size, p=self.archive_selection_prob)\n                    x_r3 = self.archive[arch_ind]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    # Store successful F and Cr values\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n                    self.success_count += 1\n\n                    # Update population\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n                    self.age[i] = 0 #Reset age\n\n                    #Update archive: replace the worst archive member only if the trial vector is better than the worst in the archive\n                    if f_trial < np.max(self.archive_fitness):\n                        worst_index = np.argmax(self.archive_fitness)\n                        self.archive[worst_index] = x_trial\n                        self.archive_fitness[worst_index] = f_trial\n                        self.archive_age[worst_index] = 0 #Reset age of archive member\n\n                        # Update archive selection probabilities (favoring newer and better solutions)\n                        self.archive_selection_prob = np.exp(-self.archive_age / np.mean(self.archive_age)) * (1 / (1 + np.argsort(np.argsort(self.archive_fitness))))\n                        self.archive_selection_prob /= np.sum(self.archive_selection_prob)  # Normalize probabilities\n\n                else:\n                    self.age[i] += self.aging_rate # Increase age if not improving\n\n                if f_trial < self.f_opt:\n                  self.f_opt = f_trial\n                  self.x_opt = x_trial\n\n                if self.fevals >= self.budget:\n                    break\n\n            # Update F and Cr memory with forgetting mechanism\n            if self.success_F:\n                avg_F = np.mean(self.success_F)\n                avg_Cr = np.mean(self.success_Cr)\n\n                # Implement forgetting by linearly interpolating with the old value\n                self.F_memory[self.memory_index] = 0.8 * self.F_memory[self.memory_index] + 0.2 * avg_F\n                self.Cr_memory[self.memory_index] = 0.8 * self.Cr_memory[self.memory_index] + 0.2 * avg_Cr\n\n                self.memory_index = (self.memory_index + 1) % self.memory_size\n                self.success_F = []\n                self.success_Cr = []\n            \n            #Adapt population size\n            if self.fevals // self.pop_size_adapt_freq > (self.fevals - self.pop_size) // self.pop_size_adapt_freq:\n                self.success_rate = self.success_count / self.pop_size\n                self.success_history.append(self.success_rate)\n                self.success_count = 0\n                \n                if len(self.success_history) > 5:\n                    window_size = 5\n                    recent_success = np.mean(self.success_history[-window_size:])\n\n                    if recent_success > 0.4:\n                        self.pop_size = min(self.pop_size + 5, self.max_pop_size)\n                        self.pop = np.vstack((self.pop, np.random.uniform(func.bounds.lb, func.bounds.ub, size=(5, self.dim))))\n                        self.fitness = np.concatenate((self.fitness, np.array([func(x) for x in self.pop[-5:]])))\n                        self.age = np.concatenate((self.age, np.zeros(5)))  # Initialize age for new individuals\n                        self.fevals += 5\n\n                    elif recent_success < 0.1 and self.pop_size > self.min_pop_size:\n                        num_reduce = min(5, self.pop_size - self.min_pop_size)\n                        # Remove oldest individuals\n                        indices_to_remove = np.argsort(self.age)[-num_reduce:]\n                        self.pop = np.delete(self.pop, indices_to_remove, axis=0)\n                        self.fitness = np.delete(self.fitness, indices_to_remove)\n                        self.age = np.delete(self.age, indices_to_remove)\n                        self.pop_size -= num_reduce\n\n            #Increase archive age\n            self.archive_age += 1\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occurred: probabilities contain NaN.", "error": "", "parent_ids": ["8822a15f-e73a-4fc1-a76b-30d8bb54da71"], "operator": null, "metadata": {}}
{"id": "075a1cbc-f4b9-478f-bb70-389cafdaa308", "fitness": 0.0, "name": "EnhancedDiversityAdaptiveDE", "description": "Enhanced Diversity Adaptive DE with adaptive population size based on fitness variance, improved stagnation handling using Nelder-Mead, and dynamic F/CR adaptation using weighted historical memory.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedDiversityAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, stagnation_threshold=10, stagnation_fitness_threshold=1e-6, F=0.5, CR=0.9, archive_update_prob=0.1, f_momentum=0.9, cr_momentum=0.9, pop_size_adapt_freq=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = F  # Initial scaling factor\n        self.CR = CR  # Initial crossover rate\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.stagnation_fitness_threshold = stagnation_fitness_threshold\n        self.previous_best_fitness = np.Inf\n        self.archive_update_prob = archive_update_prob  # Initial archive update probability\n        self.f_momentum = f_momentum\n        self.cr_momentum = cr_momentum\n        self.f_memory = []\n        self.cr_memory = []\n        self.pop_size_adapt_freq = pop_size_adapt_freq\n        self.success_f = []\n        self.success_cr = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.pop[i].copy()\n        \n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            fitness_variance = np.var(self.fitness)\n            best_fitness_current_iter = np.min(self.fitness)\n            \n            if best_fitness_current_iter >= self.previous_best_fitness and fitness_variance < self.stagnation_fitness_threshold:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n            self.previous_best_fitness = best_fitness_current_iter\n            \n            if self.stagnation_counter > self.stagnation_threshold:\n                # Stagnation handling: Nelder-Mead on best solution\n                res = minimize(func, self.x_opt, method='Nelder-Mead', bounds=func.bounds, options={'maxfev': min(500, self.budget // 2)})\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n                self.budget -= res.nfev\n                self.stagnation_counter = 0  # Reset counter\n            \n            # Population size adaptation\n            if generation % self.pop_size_adapt_freq == 0:\n                if fitness_variance > 1e-4:  # Dynamic adjustment based on variance\n                    self.pop_size = min(int(self.pop_size * 1.1), 100)  # Increase if high diversity\n                else:\n                    self.pop_size = max(int(self.pop_size * 0.9), 10)   # Decrease if low diversity\n                \n                # Resize population (naive - replace worst individuals)\n                if self.pop.shape[0] < self.pop_size:\n                    num_to_add = self.pop_size - self.pop.shape[0]\n                    new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_add, self.dim))\n                    new_fitness = [func(x) for x in new_individuals]\n                    self.budget -= num_to_add\n                    self.pop = np.vstack((self.pop, new_individuals))\n                    self.fitness = np.concatenate((self.fitness, new_fitness))\n\n                    for i in range(num_to_add):\n                        if self.fitness[-i-1] < self.f_opt:\n                            self.f_opt = self.fitness[-i-1]\n                            self.x_opt = self.pop[-i-1].copy()\n\n                elif self.pop.shape[0] > self.pop_size:\n                    num_to_remove = self.pop.shape[0] - self.pop_size\n                    worst_indices = np.argsort(self.fitness)[-num_to_remove:]\n                    mask = np.ones(len(self.fitness), dtype=bool)\n                    mask[worst_indices] = False\n                    self.pop = self.pop[mask]\n                    self.fitness = self.fitness[mask]\n\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n\n                # Handle archive\n                if len(self.archive) > 0 and np.random.rand() < self.archive_update_prob:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant = self.pop[a] + self.F * (self.pop[b] - self.archive[arc_idx])\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_to_replace] = self.pop[i].copy()\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i].copy()\n\n                    # Adaptive F and CR using success history and momentum\n                    self.success_f.append(self.F)\n                    self.success_cr.append(self.CR)\n\n            if self.success_f:\n                weights = np.arange(1, len(self.success_f) + 1)  # Linear weighting\n                weighted_avg_f = np.average(self.success_f, weights=weights / weights.sum())\n                weighted_avg_cr = np.average(self.success_cr, weights=weights / weights.sum())\n            else:\n                weighted_avg_f = self.F\n                weighted_avg_cr = self.CR\n                            \n            # Update F and CR based on weighted success history\n            self.F = self.f_momentum * self.F + (1 - self.f_momentum) * weighted_avg_f\n            self.CR = self.cr_momentum * self.CR + (1 - self.cr_momentum) * weighted_avg_cr\n            \n            # Adaptive F and CR (simplified)\n            self.F = np.clip(np.random.normal(self.F, 0.3), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(self.CR, 0.2), 0.1, 1.0)\n\n            # Dynamically adjust archive update probability\n            if fitness_variance < self.stagnation_fitness_threshold:\n                self.archive_update_prob = min(self.archive_update_prob + 0.01, 0.5)  # Increase probability when stagnating\n            else:\n                self.archive_update_prob = max(self.archive_update_prob - 0.01, 0.01) # Decrease otherwise\n            \n            if self.budget <= 0:\n                break\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedDiversityAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1d56175f-03e6-4cf0-be31-0c76c93ff3ee"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "ca960072-0faf-4906-89b5-2effacd70d6a", "fitness": 0.0, "name": "EnhancedDynamicPopulationDE", "description": "Enhanced Dynamic Population DE with orthogonal learning and a more robust population size adaptation strategy using moving averages of success rates.", "code": "import numpy as np\n\nclass EnhancedDynamicPopulationDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, F=0.5, Cr=0.9, archive_size=10, lr_F=0.1, lr_Cr=0.1, pop_adapt_rate=0.1):\n        \"\"\"\n        Differential Evolution algorithm with dynamic population size and parameter adaptation based on success history, orthogonal learning, and moving averages for population control.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            initial_pop_size (int): The initial population size.\n            min_pop_size (int): The minimum population size.\n            max_pop_size (int): The maximum population size.\n            F (float): The initial scaling factor for differential variation.\n            Cr (float): The initial crossover rate.\n            archive_size (int): The size of the archive for storing successful F and Cr values.\n            lr_F (float): Learning rate for F adaptation.\n            lr_Cr (float): Learning rate for Cr adaptation.\n            pop_adapt_rate (float): Rate for adapting the population size (moving average).\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.pop_size = initial_pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.archive_F = np.full(archive_size, F)\n        self.archive_Cr = np.full(archive_size, Cr)\n        self.archive_idx = 0\n        self.archive_size = archive_size\n        self.lr_F = lr_F\n        self.lr_Cr = lr_Cr\n        self.pop_adapt_rate = pop_adapt_rate\n        self.success_rate_history = []\n\n    def orthogonal_learning(self, x_current, func, bounds):\n        \"\"\"\n        Performs orthogonal learning to generate a potentially better solution.\n        \"\"\"\n        levels = 3  # Number of levels for each dimension\n        orthogonal_matrix = self.generate_orthogonal_matrix(self.dim, levels)\n        \n        best_f = np.inf\n        best_x = None\n\n        for i in range(levels):\n            x_trial = np.copy(x_current)\n            for j in range(self.dim):\n                level_index = orthogonal_matrix[i, j]\n                x_trial[j] = bounds.lb[j] + (bounds.ub[j] - bounds.lb[j]) * (level_index / (levels - 1))\n            \n            f_trial = func(x_trial)\n            if f_trial < best_f:\n                best_f = f_trial\n                best_x = x_trial\n        \n        return best_x, best_f\n\n    def generate_orthogonal_matrix(self, dim, levels):\n        \"\"\"\n        Generates an orthogonal matrix using a simple approach. For higher dimensions and levels, \n        more sophisticated methods may be needed. This is a simplified example.\n        \"\"\"\n        matrix = np.zeros((levels, dim), dtype=int)\n        for i in range(levels):\n            for j in range(dim):\n                matrix[i, j] = i % levels\n        return matrix\n        \n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with dynamic population size, parameter adaptation, and orthogonal learning.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        bounds = func.bounds\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(bounds.lb, bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n\n        success_F = []\n        success_Cr = []\n        success_count = 0\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Parameter Adaptation\n                F = np.random.choice(self.archive_F)\n                Cr = np.random.choice(self.archive_Cr)\n                \n                # Mutation: current-to-best/1\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.pop[indices]\n                x_mutated = self.pop[i] + F * (self.pop[self.best_idx] - self.pop[i]) + F * (x_r1 - x_r2)\n                x_mutated = np.clip(x_mutated, bounds.lb, bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Orthogonal learning\n                x_ortho, f_ortho = self.orthogonal_learning(x_trial, func, bounds)\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                if f_ortho < f_trial and f_ortho < self.fitness[i]:\n                    x_trial = x_ortho\n                    f_trial = f_ortho\n\n                if f_trial < self.fitness[i]:\n                    success_F.append(F)\n                    success_Cr.append(Cr)\n                    success_count += 1\n                    \n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n\n                if fevals >= self.budget:\n                    break\n            \n            # Update archive with successful F and Cr values using a moving average\n            if success_F:\n                mean_F = np.mean(success_F)\n                mean_Cr = np.mean(success_Cr)\n                self.archive_F[self.archive_idx] = (1 - self.lr_F) * self.archive_F[self.archive_idx] + self.lr_F * mean_F\n                self.archive_Cr[self.archive_idx] = (1 - self.lr_Cr) * self.archive_Cr[self.archive_idx] + self.lr_Cr * mean_Cr\n                self.archive_idx = (self.archive_idx + 1) % self.archive_size\n                success_F = []\n                success_Cr = []\n            \n            # Adjust population size based on success rate using moving average\n            success_rate = success_count / self.pop_size\n            self.success_rate_history.append(success_rate)\n            if len(self.success_rate_history) > 10:\n                self.success_rate_history.pop(0)  # Keep only the last 10 success rates\n            \n            avg_success_rate = np.mean(self.success_rate_history) if self.success_rate_history else success_rate # Use current if history is empty\n            success_count = 0 # Reset counter\n\n            if avg_success_rate > 0.2 and self.pop_size < self.max_pop_size:\n                new_pop_size = min(self.pop_size + 1, self.max_pop_size)\n                num_new_individuals = new_pop_size - self.pop_size\n                new_individuals = np.random.uniform(bounds.lb, bounds.ub, size=(num_new_individuals, self.dim))\n                new_fitness = [func(x) for x in new_individuals]\n                fevals += num_new_individuals\n                \n                self.pop = np.vstack((self.pop, new_individuals))\n                self.fitness = np.append(self.fitness, new_fitness)\n                self.pop_size = new_pop_size\n\n                for i, f in enumerate(new_fitness):\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_individuals[i]\n                        self.best_idx = self.pop_size - num_new_individuals + i\n\n            elif avg_success_rate < 0.05 and self.pop_size > self.min_pop_size:\n                # Rank-based population reduction\n                ranked_indices = np.argsort(self.fitness)[::-1]  # Sort in descending order (worst to best)\n                num_to_remove = min(int(0.1 * self.pop_size), self.pop_size - self.min_pop_size)  # Remove 10% or until min_pop_size\n                indices_to_remove = ranked_indices[:num_to_remove]\n                \n                self.pop = np.delete(self.pop, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size -= num_to_remove\n                self.best_idx = np.argmin(self.fitness)  # Update best index\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedDynamicPopulationDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7f90e646-64d3-4448-af87-b7f3781f43d7"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "d5a067cf-f083-4582-a445-a70d6eea1efc", "fitness": 0.0, "name": "EnhancedDynamicPopulationDE", "description": "Enhanced Dynamic Population DE with adaptive F and Cr based on individual success, a roulette wheel selection for population reduction, and an archive with forgetting mechanism.", "code": "import numpy as np\n\nclass EnhancedDynamicPopulationDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, F_initial=0.5, Cr_initial=0.9, archive_size=10, archive_decay_rate=0.95):\n        \"\"\"\n        Differential Evolution algorithm with dynamic population size, aging mechanism and adaptive F and Cr.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            initial_pop_size (int): The initial population size.\n            min_pop_size (int): The minimum population size.\n            max_pop_size (int): The maximum population size.\n            F_initial (float): The initial scaling factor for differential variation.\n            Cr_initial (float): The initial crossover rate.\n            archive_size (int): Size of the archive for storing successful F and Cr values.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.pop_size = initial_pop_size\n        self.F = np.full(initial_pop_size, F_initial)  # Individual F\n        self.Cr = np.full(initial_pop_size, Cr_initial) # Individual Cr\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.archive_F = []\n        self.archive_Cr = []\n        self.archive_size = archive_size\n        self.archive_decay_rate = archive_decay_rate\n        self.age = np.zeros(initial_pop_size) # Individual age, reset when improves\n        self.max_age = 5 #Max age before removal\n        self.individual_success = np.zeros(initial_pop_size)\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with dynamic population size, aging and adaptive F/Cr.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n\n        success_counter = 0\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Adaptation of F and Cr based on individual success\n                if len(self.archive_F) > 0:\n                    self.F[i] = np.random.choice(self.archive_F) # Sample from archive\n                else:\n                    self.F[i] = 0.5 # Default F\n                if len(self.archive_Cr) > 0:\n                    self.Cr[i] = np.random.choice(self.archive_Cr) # Sample from archive\n                else:\n                    self.Cr[i] = 0.9 # Default Cr\n\n                # Mutation: current-to-best/1 and rand/1\n                if np.random.rand() < 0.5: # Choose mutation strategy\n                    # Current-to-best/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F[i] * (self.pop[self.best_idx] - self.pop[i]) + self.F[i] * (x_r1 - x_r2)\n                else:\n                    # Rand/1\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[indices]\n                    x_mutated = x_r1 + self.F[i] * (x_r2 - x_r3)\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr[i] or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n                    success_counter += 1\n                    self.age[i] = 0 #Reset age\n                    self.individual_success[i] += 1\n                    # Archive successful F and Cr\n                    self.archive_F.append(self.F[i])\n                    self.archive_Cr.append(self.Cr[i])\n                    if len(self.archive_F) > self.archive_size:\n                        self.archive_F.pop(0)\n                        self.archive_Cr.pop(0)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n                else:\n                    self.age[i] += 1 #Increase age if no improvement\n                    self.individual_success[i] = max(0, self.individual_success[i]-0.1)\n\n                if fevals >= self.budget:\n                    break\n\n            # Adjust population size based on success rate\n            success_rate = success_counter / self.pop_size\n            success_counter = 0 # Reset counter\n            \n            if success_rate > 0.2 and self.pop_size < self.max_pop_size:\n                self.pop_size = min(self.pop_size + 1, self.max_pop_size)\n                self.pop = np.vstack((self.pop, np.random.uniform(func.bounds.lb, func.bounds.ub, size=(1, self.dim))))\n                self.fitness = np.append(self.fitness, func(self.pop[-1]))\n                self.age = np.append(self.age, 0) #New individual is young\n                self.F = np.append(self.F, np.random.rand()) #Random F\n                self.Cr = np.append(self.Cr, np.random.rand()) # Random Cr\n                self.individual_success = np.append(self.individual_success, 0)\n\n                fevals += 1\n                if self.fitness[-1] < self.f_opt:\n                    self.f_opt = self.fitness[-1]\n                    self.x_opt = self.pop[-1]\n                    self.best_idx = self.pop_size - 1\n\n\n            elif success_rate < 0.05 and self.pop_size > self.min_pop_size:\n                # Remove the worst individual based on roulette wheel selection using inverse of individual success\n                probabilities = 1.0 / (self.individual_success + 0.0001)  # Avoid division by zero\n                probabilities /= np.sum(probabilities)\n                worst_idx = np.random.choice(self.pop_size, p=probabilities)\n                self.pop = np.delete(self.pop, worst_idx, axis=0)\n                self.fitness = np.delete(self.fitness, worst_idx)\n                self.age = np.delete(self.age, worst_idx)\n                self.F = np.delete(self.F, worst_idx)\n                self.Cr = np.delete(self.Cr, worst_idx)\n                self.individual_success = np.delete(self.individual_success, worst_idx)\n                self.pop_size -= 1\n                self.best_idx = np.argmin(self.fitness) #Update best index\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n            \n            #Aging mechanism: remove old individuals\n            old_indices = np.where(self.age >= self.max_age)[0]\n            if len(old_indices) > 0 and self.pop_size > self.min_pop_size:\n                #remove oldest individual\n                oldest_idx = old_indices[np.argmax(self.age[old_indices])]\n                self.pop = np.delete(self.pop, oldest_idx, axis=0)\n                self.fitness = np.delete(self.fitness, oldest_idx)\n                self.age = np.delete(self.age, oldest_idx)\n                self.F = np.delete(self.F, oldest_idx)\n                self.Cr = np.delete(self.Cr, oldest_idx)\n                self.individual_success = np.delete(self.individual_success, oldest_idx)\n\n                self.pop_size -= 1\n                self.best_idx = np.argmin(self.fitness) #Update best index\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n\n            # Decay archive to encourage exploration\n            self.archive_F = [f * self.archive_decay_rate for f in self.archive_F]\n            self.archive_Cr = [cr * self.archive_decay_rate for cr in self.archive_Cr]\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedDynamicPopulationDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["936517df-4bb7-47a3-8800-61b09173f91e"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "43b89f21-9865-4626-a4dd-51008e4af3a5", "fitness": 0.29985083361339565, "name": "SOMA", "description": "Self-Organizing Migrating Algorithm (SOMA) with dynamic step size adaptation based on individual success and a memory of past best solutions to guide the search.", "code": "import numpy as np\n\nclass SOMA:\n    def __init__(self, budget=10000, dim=10, pop_size=40, step_size=0.1, path_length=2.0, min_div=0.001, archive_size=10):\n        \"\"\"\n        Self-Organizing Migrating Algorithm (SOMA) with dynamic step size adaptation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            step_size (float): The initial step size.\n            path_length (float): The maximum length of the path traveled by each individual.\n            min_div (float): Minimum accepted diversity\n            archive_size (int): The size of the archive for storing past best solutions.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.path_length = path_length\n        self.min_div = min_div\n        self.pop = None\n        self.fitness = None\n        self.leader_idx = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = archive_size\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using SOMA with dynamic step size adaptation.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.leader_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.leader_idx]\n        self.x_opt = self.pop[self.leader_idx]\n        fevals = self.pop_size\n\n        while fevals < self.budget:\n            # Migration loop\n            for i in range(self.pop_size):\n                if fevals >= self.budget:\n                    break\n                \n                # Calculate direction vector towards the leader\n                direction_vector = self.pop[self.leader_idx] - self.pop[i]\n                \n                # Migrate along the path\n                for j in np.arange(self.step_size, self.path_length + self.step_size, self.step_size):\n                    if fevals >= self.budget:\n                        break\n                    \n                    new_position = self.pop[i] + j * direction_vector\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                    \n                    f_new = func(new_position)\n                    fevals += 1\n                    \n                    if f_new < self.fitness[i]:\n                        self.fitness[i] = f_new\n                        self.pop[i] = new_position\n                        \n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = new_position\n                            self.leader_idx = i\n            \n            # Diversity check and possible restart\n            diversity = np.std(self.pop)\n            if diversity < self.min_div:\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                fevals += self.pop_size\n                self.leader_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[self.leader_idx]\n                self.x_opt = self.pop[self.leader_idx]\n                \n            # Step size adaptation\n            if len(self.archive) > 0:\n                 distances = np.linalg.norm(self.pop - np.mean(self.archive, axis=0), axis=1)\n                 self.step_size = 0.1 + 0.4 * np.mean(distances) / np.linalg.norm(func.bounds.ub - func.bounds.lb) # adapt depending on average distance to best solutions\n\n            # Archive the best solution\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.x_opt)\n            else:\n                self.archive.pop(0)\n                self.archive.append(self.x_opt)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm SOMA scored 0.300 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7f90e646-64d3-4448-af87-b7f3781f43d7"], "operator": null, "metadata": {"aucs": [0.12505963926796904, 0.2279799877142683, 0.3107965184594286, 0.2002070909124294, 0.26403928220126915, 0.2714562927929943, 0.29099598541039595, 0.22658543479521653, 0.23205460765879782, 0.1631521385498561, 0.2611661448915418, 0.9948757032594785, 0.21005569508451805, 0.23386550014649654, 0.5646915941602422, 0.2544294691656671, 0.24269300677476502, 0.2856717883903853, 0.19152148352406673, 0.44571930910812596]}}
{"id": "18dbcc78-3c3d-4905-b420-a9bcb8c076ae", "fitness": 0.680270576533215, "name": "AdaptiveResourceDE", "description": "Adaptive Differential Evolution with dynamic population size, success-history based parameter adaptation using a more robust weighting scheme, and a resource allocation strategy favoring promising individuals.", "code": "import numpy as np\n\nclass AdaptiveResourceDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, F=0.5, Cr=0.9, archive_size=10, success_memory=10):\n        \"\"\"\n        Adaptive Differential Evolution with dynamic population size, success-history based parameter adaptation,\n        and a resource allocation strategy favoring promising individuals.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            initial_pop_size (int): The initial population size.\n            min_pop_size (int): The minimum population size.\n            max_pop_size (int): The maximum population size.\n            F (float): The initial scaling factor for differential variation.\n            Cr (float): The initial crossover rate.\n            archive_size (int): The size of the archive for storing successful F and Cr values.\n            success_memory (int): Size of memory for storing successful F and Cr values for adaptation\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.pop_size = initial_pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.archive_F = np.full(archive_size, F)\n        self.archive_Cr = np.full(archive_size, Cr)\n        self.archive_idx = 0\n        self.archive_size = archive_size\n        self.success_F_memory = []\n        self.success_Cr_memory = []\n        self.success_memory = success_memory\n        self.fevals_per_individual = np.ones(initial_pop_size, dtype=int) * (budget // initial_pop_size)\n        self.min_fevals_per_individual = 1\n        self.resource_allocation_frequency = 10  # Adjust resource allocation every this many iterations\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with dynamic population size, parameter adaptation, and resource allocation.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n\n        success_count = 0\n        iteration = 0\n\n        while fevals < self.budget:\n            iteration += 1\n            for i in range(self.pop_size):\n                if self.fevals_per_individual[i] <= 0:\n                    continue\n                # Parameter Adaptation\n                F = np.random.choice(self.archive_F)\n                Cr = np.random.choice(self.archive_Cr)\n                \n                # Mutation: current-to-best/1\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.pop[indices]\n                x_mutated = self.pop[i] + F * (self.pop[self.best_idx] - self.pop[i]) + F * (x_r1 - x_r2)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n                self.fevals_per_individual[i] -=1 \n\n                if f_trial < self.fitness[i]:\n                    self.success_F_memory.append(F)\n                    self.success_Cr_memory.append(Cr)\n\n                    if len(self.success_F_memory) > self.success_memory:\n                        self.success_F_memory.pop(0)\n                        self.success_Cr_memory.pop(0)\n\n                    success_count += 1\n                    \n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n\n                if fevals >= self.budget:\n                    break\n            \n            # Update archive with successful F and Cr values using a weighted average\n            if self.success_F_memory:\n                weights = np.linspace(0.1, 1.0, len(self.success_F_memory))\n                weights /= weights.sum()  # Normalize weights\n\n                weighted_avg_F = np.average(self.success_F_memory, weights=weights)\n                weighted_avg_Cr = np.average(self.success_Cr_memory, weights=weights)\n                \n                self.archive_F[self.archive_idx] = weighted_avg_F * 0.5 + self.archive_F[self.archive_idx] * 0.5\n                self.archive_Cr[self.archive_idx] = weighted_avg_Cr * 0.5 + self.archive_Cr[self.archive_idx] * 0.5\n                self.archive_idx = (self.archive_idx + 1) % self.archive_size\n\n            \n            # Adjust population size based on success rate\n            success_rate = success_count / self.pop_size\n            success_count = 0 # Reset counter\n\n            if success_rate > 0.2 and self.pop_size < self.max_pop_size:\n                self.pop_size = min(self.pop_size + 1, self.max_pop_size)\n                new_individual = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(1, self.dim))\n                self.pop = np.vstack((self.pop, new_individual))\n                self.fitness = np.append(self.fitness, func(new_individual[0]))\n                self.fevals_per_individual = np.append(self.fevals_per_individual, self.budget // self.pop_size)\n                fevals += 1\n                if self.fitness[-1] < self.f_opt:\n                    self.f_opt = self.fitness[-1]\n                    self.x_opt = self.pop[-1]\n                    self.best_idx = self.pop_size - 1\n\n            elif success_rate < 0.05 and self.pop_size > self.min_pop_size:\n                # Rank-based population reduction\n                ranked_indices = np.argsort(self.fitness)[::-1]  # Sort in descending order (worst to best)\n                num_to_remove = min(int(0.1 * self.pop_size), self.pop_size - self.min_pop_size)  # Remove 10% or until min_pop_size\n                indices_to_remove = ranked_indices[:num_to_remove]\n                \n                self.pop = np.delete(self.pop, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size -= num_to_remove\n                self.fevals_per_individual = np.delete(self.fevals_per_individual, indices_to_remove)\n                self.best_idx = np.argmin(self.fitness)  # Update best index\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n\n            # Resource allocation\n            if iteration % self.resource_allocation_frequency == 0:\n                # Distribute remaining budget based on fitness rank\n                remaining_fevals = self.budget - fevals\n                if remaining_fevals > 0:\n                    ranked_indices = np.argsort(self.fitness) # Ascending order (best to worst)\n                    weights = np.linspace(1.0, 0.1, self.pop_size) # Assign weights from best to worst\n                    weights /= weights.sum() # Normalize weights\n                    \n                    # Allocate fevals, ensuring minimum allocation\n                    new_fevals_per_individual = (weights * remaining_fevals).astype(int) + self.min_fevals_per_individual\n                    \n                    # Ensure that the total fevals do not exceed remaining budget\n                    if np.sum(new_fevals_per_individual) > remaining_fevals:\n                        diff = np.sum(new_fevals_per_individual) - remaining_fevals\n                        new_fevals_per_individual[ranked_indices[-diff:]] -= 1\n\n                    self.fevals_per_individual = new_fevals_per_individual\n                    \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveResourceDE scored 0.680 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7f90e646-64d3-4448-af87-b7f3781f43d7"], "operator": null, "metadata": {"aucs": [0.3570850528826027, 0.7666659223895999, 0.7492106390794708, 0.9179314399269143, 0.7926324648818793, 0.8247910643633884, 0.34644287593541667, 0.7080922775186792, 0.7917970029203434, 0.365214237723832, 0.9242323396116421, 0.9962325927623394, 0.6587699584084827, 0.317663120165973, 0.9548368820560328, 0.7780430694663683, 0.6933861606949089, 0.896552270981524, 0.2634402283034204, 0.5023919305914837]}}
{"id": "39514fee-7312-4d41-a54d-8da791c4c73e", "fitness": 0.6892536860048212, "name": "SelfAdaptiveDE", "description": "Differential Evolution with a self-adaptive strategy selection based on past success, incorporating a diversity maintenance scheme and a restart mechanism if stagnation is detected.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_initial=0.5, Cr_initial=0.9, archive_size=10, stagnation_limit=500):\n        \"\"\"\n        Differential Evolution with self-adaptive strategy selection, diversity maintenance, and stagnation handling.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            F_initial (float): The initial scaling factor for differential variation.\n            Cr_initial (float): The initial crossover rate.\n            archive_size (int): Size of the archive for storing successful F and Cr values.\n            stagnation_limit (int): Number of iterations without improvement before triggering a restart.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_initial\n        self.Cr = Cr_initial\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.archive_F = []\n        self.archive_Cr = []\n        self.archive_size = archive_size\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.strategy_success = np.zeros(3)  # Success count for each strategy\n        self.strategy_selection_prob = np.array([1/3, 1/3, 1/3]) # Initial probabilities\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with self-adaptive strategy selection, diversity maintenance, and stagnation handling.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n        last_improvement = 0\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Strategy selection based on success probabilities\n                strategy_idx = np.random.choice(3, p=self.strategy_selection_prob)\n\n                # Adaptation of F and Cr (using archive or default values)\n                if len(self.archive_F) > 0:\n                    self.F = np.random.choice(self.archive_F)\n                else:\n                    self.F = 0.5  # Default F\n                if len(self.archive_Cr) > 0:\n                    self.Cr = np.random.choice(self.archive_Cr)\n                else:\n                    self.Cr = 0.9  # Default Cr\n\n                # Mutation Strategies\n                if strategy_idx == 0:\n                    # Current-to-best/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F * (self.pop[self.best_idx] - self.pop[i]) + self.F * (x_r1 - x_r2)\n                elif strategy_idx == 1:\n                    # Rand/1\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[indices]\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                else:\n                    # Current/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F * (x_r1 - x_r2)\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    # Improvement\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n                    self.strategy_success[strategy_idx] += 1 #Increase strategy success count\n\n                    # Archive successful F and Cr\n                    self.archive_F.append(self.F)\n                    self.archive_Cr.append(self.Cr)\n                    if len(self.archive_F) > self.archive_size:\n                        self.archive_F.pop(0)\n                        self.archive_Cr.pop(0)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n                        last_improvement = fevals\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increase stagnation counter\n\n\n                if fevals >= self.budget:\n                    break\n\n            # Update strategy selection probabilities based on success\n            total_success = np.sum(self.strategy_success)\n            if total_success > 0:\n                self.strategy_selection_prob = self.strategy_success / total_success\n            else:\n                self.strategy_selection_prob = np.array([1/3, 1/3, 1/3]) # Reset if no success\n\n            self.strategy_success[:] = 0 #Reset success counters\n\n            # Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_limit:\n                # Option 1: Restart with new random population\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n                fevals += self.pop_size\n                self.stagnation_counter = 0\n                # Resetting success history might also be a good idea here.\n                # Option 2: Perturb the current population. Can be combined with option 1.\n                # self.pop += 0.05 * np.random.normal(size=self.pop.shape)  # Small perturbation\n                # self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n                # self.fitness = np.array([func(x) for x in self.pop]) #Recalculate fitness\n                # self.best_idx = np.argmin(self.fitness)\n                # self.f_opt = self.fitness[self.best_idx]\n                # self.x_opt = self.pop[self.best_idx]\n                # fevals += self.pop_size\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm SelfAdaptiveDE scored 0.689 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["936517df-4bb7-47a3-8800-61b09173f91e"], "operator": null, "metadata": {"aucs": [0.36272500406939856, 0.23595146488157548, 0.6565626956382677, 0.924364705808743, 0.8775099852177332, 0.8959224363856574, 0.41915286236243054, 0.8236353900599839, 0.8762685551941525, 0.4533171749685817, 0.9438727710029517, 0.9963445528876872, 0.4953311481316166, 0.8482897953926005, 0.9582865945406045, 0.8875421273645996, 0.4147534175055515, 0.9173722017531056, 0.28879672819004854, 0.509074108741135]}}
{"id": "653423e0-cf06-4361-83b8-fb783dd51170", "fitness": 0.6271439431765756, "name": "ImprovedADE", "description": "Adaptive DE with improved archive management using a hybrid approach of fitness and diversity metrics, and a refined population size adaptation strategy based on the performance trend.", "code": "import numpy as np\n\nclass ImprovedADE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, archive_size=100, F=0.5, Cr=0.9, adapt_freq=10, memory_size=10, pop_size_adapt_freq=50, archive_selection_rate=0.1):\n        \"\"\"\n        Improved Adaptive Differential Evolution algorithm with self-adaptive population size and improved parameter adaptation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size_init (int): The initial population size.\n            archive_size (int): The size of the archive.\n            F (float): The initial scaling factor for differential variation.\n            Cr (float): The initial crossover rate.\n            adapt_freq (int): How often to adapt F and Cr parameters.\n            memory_size (int): The size of the memory for successful F and Cr values.\n            pop_size_adapt_freq (int): How often to adapt the population size.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.archive_size = archive_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.archive = None\n        self.adapt_freq = adapt_freq\n        self.fevals = 0\n        self.memory_size = memory_size\n        self.F_memory = np.ones(memory_size) * F\n        self.Cr_memory = np.ones(memory_size) * Cr\n        self.memory_index = 0\n        self.success_F = []\n        self.success_Cr = []\n        self.pop_size_adapt_freq = pop_size_adapt_freq\n        self.success_rate = 0.0\n        self.success_history = []\n        self.min_pop_size = 10\n        self.max_pop_size = 100\n        self.archive_selection_rate = archive_selection_rate\n        self.archive_age = np.zeros(archive_size) # Track the age of each archive member\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Improved Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))  # Initialize archive\n        self.archive_fitness = np.array([np.inf] * self.archive_size) #Archive fitness values\n        self.fevals = self.pop_size # Initial population evaluation\n        self.success_count = 0\n\n        while self.fevals < self.budget:\n            for i in range(self.pop_size):\n                # Adaptation of F and Cr using memory\n                self.F = np.random.choice(self.F_memory)\n                self.Cr = np.random.choice(self.Cr_memory)\n\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[indices]\n\n                # Add archive member to the selection pool with a probability\n                if np.random.rand() < self.archive_selection_rate:\n                    arch_ind = np.random.choice(self.archive_size, 1)[0]\n                    x_r3 = self.archive[arch_ind]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    # Store successful F and Cr values\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n                    self.success_count += 1\n\n                    # Update population\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    #Update archive: hybrid replacement strategy\n                    if f_trial < np.max(self.archive_fitness):\n                        # Diversity metric: distance to nearest neighbor in archive\n                        distances = np.linalg.norm(self.archive - x_trial, axis=1)\n                        min_distance_index = np.argmin(distances)\n                        \n                        #Replace the archive member with the worst fitness or the one closest to the trial vector, based on random choice\n                        if np.random.rand() < 0.5:\n                            worst_index = np.argmax(self.archive_fitness)\n                            self.archive[worst_index] = x_trial\n                            self.archive_fitness[worst_index] = f_trial\n                            self.archive_age[worst_index] = 0 #reset age\n                        else:\n                            self.archive[min_distance_index] = x_trial\n                            self.archive_fitness[min_distance_index] = f_trial\n                            self.archive_age[min_distance_index] = 0\n\n                #Increment age of archive members\n                self.archive_age += 1\n\n                if f_trial < self.f_opt:\n                  self.f_opt = f_trial\n                  self.x_opt = x_trial\n\n                if self.fevals >= self.budget:\n                    break\n\n            # Update F and Cr memory\n            if self.success_F:\n                self.F_memory[self.memory_index] = np.mean(self.success_F)\n                self.Cr_memory[self.memory_index] = np.mean(self.success_Cr)\n                self.memory_index = (self.memory_index + 1) % self.memory_size\n                self.success_F = []\n                self.success_Cr = []\n                \n            #Adapt population size - improved adaptation rule\n            if self.fevals // self.pop_size_adapt_freq > (self.fevals - self.pop_size) // self.pop_size_adapt_freq:\n                self.success_rate = self.success_count / self.pop_size\n                self.success_history.append(self.success_rate)\n                self.success_count = 0\n                \n                if len(self.success_history) > 5:\n                    window_size = 5\n                    recent_success = np.mean(self.success_history[-window_size:])\n                    \n                    # More aggressive increase/decrease\n                    if recent_success > 0.4:\n                        increase_amount = int(0.1 * self.pop_size)  # Increase by 10%\n                        new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(increase_amount, self.dim))\n                        self.pop = np.vstack((self.pop, new_individuals))\n                        self.fitness = np.concatenate((self.fitness, np.array([func(x) for x in new_individuals])))\n                        self.pop_size += increase_amount\n                        self.pop_size = min(self.pop_size, self.max_pop_size)\n                        self.fevals += increase_amount\n\n                    elif recent_success < 0.1 and self.pop_size > self.min_pop_size:\n                        decrease_amount = int(0.1 * self.pop_size)  # Decrease by 10%\n                        decrease_amount = max(1, decrease_amount) #Ensure at least one individual is removed\n                        indices_to_remove = np.argsort(self.fitness)[-decrease_amount:]\n                        self.pop = np.delete(self.pop, indices_to_remove, axis=0)\n                        self.fitness = np.delete(self.fitness, indices_to_remove)\n                        self.pop_size -= decrease_amount\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm ImprovedADE scored 0.627 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8822a15f-e73a-4fc1-a76b-30d8bb54da71"], "operator": null, "metadata": {"aucs": [0.3773935210132561, 0.6468129490592793, 0.6592095733609691, 0.8512071410804367, 0.5069213873521119, 0.6060779536908902, 0.5479283884992421, 0.4879630326308898, 0.658157786805286, 0.6514558438194828, 0.8688695780924662, 0.9937979135057835, 0.6418266734557797, 0.5306580700763426, 0.8921034006765921, 0.6824446871922155, 0.4610849193556389, 0.7350333404134752, 0.21777448975849223, 0.5261582136928842]}}
{"id": "d09bde57-b7dd-47c9-ae70-df532a70b78a", "fitness": -Infinity, "name": "EnhancedDiversityAdaptiveDE", "description": "Enhanced Diversity Adaptive DE with adaptive population size and mutation strategies based on fitness landscape features.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, archive_size=10, stagnation_threshold=10, stagnation_fitness_threshold=1e-6, F=0.5, CR=0.9, archive_update_prob=0.1, f_momentum=0.9, cr_momentum=0.9, pop_adapt_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with max pop size and adapt\n        self.archive_size = archive_size\n        self.F = F  # Initial scaling factor\n        self.CR = CR  # Initial crossover rate\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.stagnation_fitness_threshold = stagnation_fitness_threshold\n        self.previous_best_fitness = np.Inf\n        self.archive_update_prob = archive_update_prob  # Initial archive update probability\n        self.f_momentum = f_momentum\n        self.cr_momentum = cr_momentum\n        self.f_memory = []\n        self.cr_memory = []\n        self.pop_adapt_rate = pop_adapt_rate\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.pop[i].copy()\n        \n        while self.budget > 0:\n            fitness_variance = np.var(self.fitness)\n            best_fitness_current_iter = np.min(self.fitness)\n            \n            if best_fitness_current_iter >= self.previous_best_fitness and fitness_variance < self.stagnation_fitness_threshold:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n            self.previous_best_fitness = best_fitness_current_iter\n            \n            # Adjust population size based on fitness variance\n            if fitness_variance > 0.01:  # Higher variance, increase population\n                self.pop_size = min(self.pop_size + int(self.pop_adapt_rate * (self.pop_size_max - self.pop_size)), self.pop_size_max)\n            else:  # Lower variance, decrease population\n                self.pop_size = max(self.pop_size - int(self.pop_adapt_rate * (self.pop_size - self.pop_size_min)), self.pop_size_min)\n\n            # Resize population if necessary\n            if self.pop.shape[0] != self.pop_size:\n                if self.pop.shape[0] < self.pop_size:\n                    num_to_add = self.pop_size - self.pop.shape[0]\n                    new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_add, self.dim))\n                    self.pop = np.vstack((self.pop, new_individuals))\n                    new_fitness = np.array([func(x) for x in new_individuals])\n                    self.fitness = np.concatenate((self.fitness, new_fitness))\n                    self.budget -= num_to_add\n\n                    for i in range(self.pop.shape[0] - num_to_add, self.pop.shape[0]):\n                        if self.fitness[i] < self.f_opt:\n                            self.f_opt = self.fitness[i]\n                            self.x_opt = self.pop[i].copy()\n\n                else:\n                    indices_to_remove = np.argsort(self.fitness)[- (self.pop.shape[0] - self.pop_size):]\n                    self.pop = np.delete(self.pop, indices_to_remove, axis=0)\n                    self.fitness = np.delete(self.fitness, indices_to_remove)\n            \n            if self.stagnation_counter > self.stagnation_threshold:\n                # Stagnation handling: restart or perturb\n                if np.random.rand() < 0.5:\n                    # Replace a portion of the population with random individuals\n                    num_to_replace = int(0.2 * self.pop_size)\n                    indices_to_replace = np.random.choice(self.pop_size, num_to_replace, replace=False)\n                    self.pop[indices_to_replace] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_replace, self.dim))\n                    self.fitness[indices_to_replace] = [func(x) for x in self.pop[indices_to_replace]]\n                    self.budget -= num_to_replace\n\n                    for i in indices_to_replace:\n                        if self.fitness[i] < self.f_opt:\n                            self.f_opt = self.fitness[i]\n                            self.x_opt = self.pop[i].copy()\n                else:\n                    # Perturb the population\n                    perturbation_scale = 0.05 * (func.bounds.ub - func.bounds.lb)\n                    self.pop += np.random.uniform(-perturbation_scale, perturbation_scale, size=self.pop.shape)\n                    self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n                    self.fitness = np.array([func(x) for x in self.pop])\n                    self.budget -= self.pop_size\n\n                    for i in range(self.pop_size):\n                        if self.fitness[i] < self.f_opt:\n                            self.f_opt = self.fitness[i]\n                            self.x_opt = self.pop[i].copy()\n                \n                self.stagnation_counter = 0  # Reset counter\n\n\n            for i in range(self.pop_size):\n                # Mutation Strategy Selection\n                if fitness_variance > 0.01:  # High variance: explore more\n                    mutation_strategy = 1 # DE/rand/1\n                    indices = np.random.choice(self.pop_size, 5, replace=False)\n                    a, b, c, d, e = self.pop[indices[0]], self.pop[indices[1]], self.pop[indices[2]], self.pop[indices[3]], self.pop[indices[4]]\n                    mutant = a + self.F * (b - c) + self.F * (d - e)\n                else:  # Low variance: exploit more\n                    mutation_strategy = 0 # DE/current-to-best/1\n                    best_idx = np.argmin(self.fitness)\n                    indices = [j for j in range(self.pop_size) if j != i and j != best_idx]\n                    a, b = np.random.choice(indices, 2, replace=False)\n                    mutant = self.pop[i] + self.F * (self.pop[best_idx] - self.pop[i]) + self.F * (self.pop[a] - self.pop[b])\n\n                # Handle archive\n                if len(self.archive) > 0 and np.random.rand() < self.archive_update_prob:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant = self.pop[a] + self.F * (self.pop[b] - self.archive[arc_idx])\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_to_replace] = self.pop[i].copy()\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i].copy()\n\n                    # Adaptive F and CR using success history and momentum\n                    self.f_memory.append(self.F)\n                    self.cr_memory.append(self.CR)\n\n                    # Update F and CR based on success history\n                    success_F = np.mean(self.f_memory[-10:]) if len(self.f_memory) >= 10 else self.F\n                    success_CR = np.mean(self.cr_memory[-10:]) if len(self.cr_memory) >= 10 else self.CR\n                    \n                    self.F = self.f_momentum * self.F + (1 - self.f_momentum) * success_F\n                    self.CR = self.cr_momentum * self.CR + (1 - self.cr_momentum) * success_CR\n\n                \n                # Adaptive F and CR (simplified)\n                self.F = np.clip(np.random.normal(self.F, 0.3), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(self.CR, 0.2), 0.1, 1.0)\n\n                # Dynamically adjust archive update probability\n                if fitness_variance < self.stagnation_fitness_threshold:\n                    self.archive_update_prob = min(self.archive_update_prob + 0.01, 0.5)  # Increase probability when stagnating\n                else:\n                    self.archive_update_prob = max(self.archive_update_prob - 0.01, 0.01) # Decrease otherwise\n                \n                if self.budget <= 0:\n                    break\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occurred: arrays used as indices must be of integer (or boolean) type.", "error": "", "parent_ids": ["1d56175f-03e6-4cf0-be31-0c76c93ff3ee"], "operator": null, "metadata": {}}
{"id": "620de4a7-62f3-405c-a207-fda170d8d5b1", "fitness": -Infinity, "name": "EnhancedDiversityAdaptiveDE", "description": "Enhanced Diversity Adaptive DE with orthogonal learning, population diversity maintenance, and adaptive parameter control based on success rate and fitness landscape.", "code": "import numpy as np\n\nclass EnhancedDiversityAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, stagnation_threshold=10, stagnation_fitness_threshold=1e-6, F=0.5, CR=0.9, archive_update_prob=0.1, f_momentum=0.9, cr_momentum=0.9, orthogonal_learning_rate=0.1, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = F\n        self.CR = CR\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.stagnation_fitness_threshold = stagnation_fitness_threshold\n        self.previous_best_fitness = np.Inf\n        self.archive_update_prob = archive_update_prob\n        self.f_momentum = f_momentum\n        self.cr_momentum = cr_momentum\n        self.f_memory = []\n        self.cr_memory = []\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n        self.diversity_threshold = diversity_threshold\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.pop[i].copy()\n\n        while self.budget > 0:\n            fitness_variance = np.var(self.fitness)\n            best_fitness_current_iter = np.min(self.fitness)\n\n            if best_fitness_current_iter >= self.previous_best_fitness and fitness_variance < self.stagnation_fitness_threshold:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n            self.previous_best_fitness = best_fitness_current_iter\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Stagnation handling: restart or orthogonal learning\n                if np.random.rand() < 0.5:\n                    # Orthogonal Learning\n                    for i in range(self.pop_size):\n                        basis_vector = np.random.normal(0, 1, self.dim)\n                        basis_vector /= np.linalg.norm(basis_vector)\n                        step_size = np.random.uniform(-self.orthogonal_learning_rate, self.orthogonal_learning_rate) * (func.bounds.ub - func.bounds.lb)\n                        new_x = self.pop[i] + step_size * basis_vector\n                        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                        f_new = func(new_x)\n                        self.budget -=1\n                        if f_new < self.fitness[i]:\n                            self.pop[i] = new_x\n                            self.fitness[i] = f_new\n                            if f_new < self.f_opt:\n                                self.f_opt = f_new\n                                self.x_opt = self.pop[i].copy()\n                else:\n                    # Replace a portion of the population with random individuals\n                    num_to_replace = int(0.2 * self.pop_size)\n                    indices_to_replace = np.random.choice(self.pop_size, num_to_replace, replace=False)\n                    self.pop[indices_to_replace] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_replace, self.dim))\n                    self.fitness[indices_to_replace] = [func(x) for x in self.pop[indices_to_replace]]\n                    self.budget -= num_to_replace\n\n                    for i in indices_to_replace:\n                        if self.fitness[i] < self.f_opt:\n                            self.f_opt = self.fitness[i]\n                            self.x_opt = self.pop[i].copy()\n\n                self.stagnation_counter = 0  # Reset counter\n\n            # Diversity maintenance\n            distances = np.zeros((self.pop_size, self.pop_size))\n            for i in range(self.pop_size):\n                for j in range(i + 1, self.pop_size):\n                    distances[i, j] = np.linalg.norm(self.pop[i] - self.pop[j])\n                    distances[j, i] = distances[i, j]\n            \n            if np.mean(distances) < self.diversity_threshold * (func.bounds.ub - func.bounds.lb):\n                # Perturb the population to increase diversity\n                perturbation_scale = 0.1 * (func.bounds.ub - func.bounds.lb)\n                self.pop += np.random.uniform(-perturbation_scale, perturbation_scale, size=self.pop.shape)\n                self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.budget -= self.pop_size\n\n                for i in range(self.pop_size):\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.pop[i].copy()\n            \n            \n            success_count = 0\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n\n                # Handle archive\n                if len(self.archive) > 0 and np.random.rand() < self.archive_update_prob:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant = self.pop[a] + self.F * (self.pop[b] - self.archive[arc_idx])\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    success_count+=1\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_to_replace] = self.pop[i].copy()\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i].copy()\n\n                    # Adaptive F and CR using success history and momentum\n                    self.f_memory.append(self.F)\n                    self.cr_memory.append(self.CR)\n\n                    # Update F and CR based on success history\n                    success_F = np.mean(self.f_memory[-10:]) if len(self.f_memory) >= 10 else self.F\n                    success_CR = np.mean(self.cr_memory[-10:]) if len(self.cr_memory) >= 10 else self.CR\n                    \n                    self.F = self.f_momentum * self.F + (1 - self.f_momentum) * success_F\n                    self.CR = self.cr_momentum * self.CR + (1 - self.cr_momentum) * success_CR\n                    \n            # Adjust parameters based on success rate\n            success_rate = success_count / self.pop_size\n            if success_rate > 0.2:\n                self.F = min(self.F * 1.1, 1.0)\n                self.CR = min(self.CR * 1.1, 1.0)\n            else:\n                self.F = max(self.F * 0.9, 0.1)\n                self.CR = max(self.CR * 0.9, 0.1)\n\n            # Adaptive F and CR (simplified)\n            self.F = np.clip(np.random.normal(self.F, 0.3), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(self.CR, 0.2), 0.1, 1.0)\n\n            # Dynamically adjust archive update probability\n            if fitness_variance < self.stagnation_fitness_threshold:\n                self.archive_update_prob = min(self.archive_update_prob + 0.01, 0.5)  # Increase probability when stagnating\n            else:\n                self.archive_update_prob = max(self.archive_update_prob - 0.01, 0.01) # Decrease otherwise\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["1d56175f-03e6-4cf0-be31-0c76c93ff3ee"], "operator": null, "metadata": {}}
{"id": "55c8356f-d191-4dce-addd-b407a4c3f4b9", "fitness": -Infinity, "name": "SOMGuidedDE", "description": "A Differential Evolution strategy with a self-organizing map (SOM) to guide mutation and crossover, dynamically adapting parameters and population based on SOM-clustered performance.", "code": "import numpy as np\n\nclass SOMGuidedDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, F=0.5, Cr=0.9, som_grid_size=10, learning_rate=0.1, sigma=1.0):\n        \"\"\"\n        Differential Evolution algorithm guided by a Self-Organizing Map (SOM) for enhanced exploration and exploitation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            initial_pop_size (int): The initial population size.\n            min_pop_size (int): The minimum population size.\n            max_pop_size (int): The maximum population size.\n            F (float): The initial scaling factor for differential variation.\n            Cr (float): The initial crossover rate.\n            som_grid_size (int): The size of the SOM grid (som_grid_size x som_grid_size).\n            learning_rate (float): The learning rate for the SOM.\n            sigma (float): The initial radius of influence for the SOM.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.pop_size = initial_pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.som_grid_size = som_grid_size\n        self.learning_rate = learning_rate\n        self.sigma = sigma\n        self.som = np.random.rand(som_grid_size, som_grid_size, dim)  # Initialize SOM weights\n        self.node_counts = np.zeros((som_grid_size, som_grid_size)) # Track how many individuals are mapped to each SOM node\n\n    def find_best_matching_unit(self, x):\n        \"\"\"\n        Finds the best matching unit (BMU) in the SOM for a given individual.\n\n        Args:\n            x (numpy.ndarray): The individual.\n\n        Returns:\n            tuple: The coordinates (row, column) of the BMU in the SOM.\n        \"\"\"\n        distances = np.sum((self.som - x)**2, axis=2)\n        return np.unravel_index(np.argmin(distances), distances.shape)\n\n    def update_som(self, x, bmu_row, bmu_col, iteration, total_iterations):\n        \"\"\"\n        Updates the SOM based on the given individual and BMU.\n\n        Args:\n            x (numpy.ndarray): The individual.\n            bmu_row (int): The row index of the BMU.\n            bmu_col (int): The column index of the BMU.\n            iteration (int): The current iteration number.\n            total_iterations (int): The total number of iterations.\n        \"\"\"\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                distance = np.sqrt((i - bmu_row)**2 + (j - bmu_col)**2)\n                influence = np.exp(-distance**2 / (2 * self.sigma**2))\n                self.som[i, j] += self.learning_rate * influence * (x - self.som[i, j])\n        \n        # Decay learning rate and sigma\n        self.learning_rate = 0.1 * (1 - iteration / total_iterations)\n        self.sigma = 1.0 * np.exp(-iteration / total_iterations)\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution guided by a Self-Organizing Map.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n        iteration = 0\n        total_iterations = self.budget // self.pop_size  # Approximate total iterations\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Find BMU in SOM\n                bmu_row, bmu_col = self.find_best_matching_unit(self.pop[i])\n                self.node_counts[bmu_row, bmu_col] +=1\n\n                # Mutation: SOM-guided\n                neighbor_row = np.random.randint(max(0, bmu_row - 1), min(self.som_grid_size, bmu_row + 2)) # Sample from neighbors\n                neighbor_col = np.random.randint(max(0, bmu_col - 1), min(self.som_grid_size, bmu_col + 2))\n                \n                x_som_guide = self.som[neighbor_row, neighbor_col] # Guide mutation based on SOM neighbor\n                \n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.pop[indices]\n\n                x_mutated = self.pop[i] + self.F * (x_som_guide - self.pop[i]) + self.F * (x_r1 - x_r2)  # SOM guided mutation\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n\n                # Update SOM\n                self.update_som(self.pop[i], bmu_row, bmu_col, iteration, total_iterations)\n                \n                if fevals >= self.budget:\n                    break\n\n            # Population size adjustment based on SOM node density\n            node_density = self.node_counts / np.sum(self.node_counts) # Normalize the counts\n            if np.any(node_density > (1.5 / self.som_grid_size**2)) and self.pop_size < self.max_pop_size: # If any node is overcrowded\n                self.pop_size = min(self.pop_size + 1, self.max_pop_size)\n                self.pop = np.vstack((self.pop, np.random.uniform(func.bounds.lb, func.bounds.ub, size=(1, self.dim))))\n                self.fitness = np.append(self.fitness, func(self.pop[-1]))\n                fevals += 1\n                if self.fitness[-1] < self.f_opt:\n                    self.f_opt = self.fitness[-1]\n                    self.x_opt = self.pop[-1]\n                    self.best_idx = self.pop_size - 1\n\n            elif np.all(node_density < (0.5 / self.som_grid_size**2)) and self.pop_size > self.min_pop_size:  # If all nodes are sparse\n                ranked_indices = np.argsort(self.fitness)[::-1]  # Sort in descending order (worst to best)\n                num_to_remove = min(int(0.1 * self.pop_size), self.pop_size - self.min_pop_size)\n                indices_to_remove = ranked_indices[:num_to_remove]\n\n                self.pop = np.delete(self.pop, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size -= num_to_remove\n                self.best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n\n            self.node_counts[:] = 0 # Reset for next iteration\n            iteration +=1\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occurred: Evaluation timed out after 60 seconds..", "error": "", "parent_ids": ["7f90e646-64d3-4448-af87-b7f3781f43d7"], "operator": null, "metadata": {}}
{"id": "fb29c93d-274e-4b06-beb9-e5baa74ef722", "fitness": -Infinity, "name": "CooperativeDE", "description": "Cooperative Differential Evolution with dynamic subpopulation allocation based on landscape exploration and exploitation, using a shared archive and periodic information exchange.", "code": "import numpy as np\n\nclass CooperativeDE:\n    def __init__(self, budget=10000, dim=10, num_subpops=5, pop_size=20, archive_size=50, F=0.5, Cr=0.9, exploration_prob=0.3, exchange_interval=50):\n        \"\"\"\n        Cooperative Differential Evolution with subpopulation-based exploration and exploitation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            num_subpops (int): The number of subpopulations.\n            pop_size (int): The size of each subpopulation.\n            archive_size (int): The size of the shared archive.\n            F (float): The scaling factor for differential variation.\n            Cr (float): The crossover rate.\n            exploration_prob (float): Probability of exploration-focused parameter settings.\n            exchange_interval (int): Number of iterations between information exchange.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.num_subpops = num_subpops\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = F\n        self.Cr = Cr\n        self.exploration_prob = exploration_prob\n        self.exchange_interval = exchange_interval\n        self.subpops = []\n        self.fitnesses = []\n        self.archive = None\n        self.archive_fitness = None\n        self.fevals = 0\n        self.best_fitness = np.inf\n        self.best_solution = None\n\n    def initialize_subpopulations(self, func):\n        \"\"\"Initializes subpopulations with random positions and assigns exploration/exploitation roles.\"\"\"\n        for _ in range(self.num_subpops):\n            pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            fitness = np.array([func(x) for x in pop])\n            self.subpops.append(pop)\n            self.fitnesses.append(fitness)\n            self.fevals += self.pop_size\n\n    def initialize_archive(self, func):\n        \"\"\"Initializes a shared archive with diverse solutions.\"\"\"\n        self.archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))\n        self.archive_fitness = np.array([func(x) for x in self.archive])\n        self.fevals += self.archive_size\n\n    def select_mutation_strategy(self):\n        \"\"\"Selects mutation strategy based on exploration/exploitation balance.\"\"\"\n        if np.random.rand() < self.exploration_prob:\n            # Exploration: Larger F, lower Cr\n            F = np.random.uniform(0.5, 1.0)\n            Cr = np.random.uniform(0.0, 0.3)\n        else:\n            # Exploitation: Smaller F, higher Cr\n            F = np.random.uniform(0.0, 0.5)\n            Cr = np.random.uniform(0.7, 1.0)\n        return F, Cr\n\n    def mutate_and_cross(self, pop, F, Cr, func):\n        \"\"\"Performs mutation and crossover operations.\"\"\"\n        new_pop = np.copy(pop)\n        for i in range(self.pop_size):\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = pop[indices]\n\n            #Use archive information: choose one individual from the archive with probability 0.1\n            if np.random.rand() < 0.1 and self.archive is not None and len(self.archive) > 0:\n                arch_idx = np.random.choice(len(self.archive), 1)[0]\n                x_r3 = self.archive[arch_idx]\n\n            x_mutated = x_r1 + F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            x_trial = np.copy(pop[i])\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n            new_pop[i] = x_trial\n        return new_pop\n\n    def select(self, pop, fitness, new_pop, new_fitness):\n        \"\"\"Performs selection based on fitness.\"\"\"\n        for i in range(self.pop_size):\n            if new_fitness[i] < fitness[i]:\n                pop[i] = new_pop[i]\n                fitness[i] = new_fitness[i]\n        return pop, fitness\n\n    def update_archive(self, func):\n        \"\"\"Updates the shared archive with diverse and promising solutions.\"\"\"\n        all_solutions = np.concatenate(self.subpops)\n        all_fitnesses = np.concatenate(self.fitnesses)\n        \n        # Combine current archive and all solutions, keeping the best.\n        combined_solutions = np.vstack((self.archive, all_solutions))\n        combined_fitnesses = np.concatenate((self.archive_fitness, all_fitnesses))\n\n        # Sort by fitness and select the best archive_size solutions\n        sorted_indices = np.argsort(combined_fitnesses)[:self.archive_size]\n        self.archive = combined_solutions[sorted_indices]\n        self.archive_fitness = combined_fitnesses[sorted_indices]\n\n    def exchange_information(self):\n        \"\"\"Exchanges information between subpopulations by swapping individuals.\"\"\"\n        for i in range(self.num_subpops):\n            # Select another subpopulation to exchange with\n            j = (i + 1) % self.num_subpops\n            \n            # Select a random individual from each subpopulation\n            idx_i = np.random.randint(self.pop_size)\n            idx_j = np.random.randint(self.pop_size)\n            \n            # Swap the individuals\n            self.subpops[i][idx_i], self.subpops[j][idx_j] = self.subpops[j][idx_j], self.subpops[i][idx_i]\n            self.fitnesses[i][idx_i], self.fitnesses[j][idx_j] = self.fitnesses[j][idx_j], self.fitnesses[i][idx_i]\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function using Cooperative Differential Evolution.\"\"\"\n        self.initialize_subpopulations(func)\n        self.initialize_archive(func)\n\n        while self.fevals < self.budget:\n            for i in range(self.num_subpops):\n                # Select mutation strategy based on exploration/exploitation\n                F, Cr = self.select_mutation_strategy()\n\n                # Mutate and crossover\n                new_pop = self.mutate_and_cross(self.subpops[i], F, Cr, func)\n                new_fitness = np.array([func(x) for x in new_pop])\n                self.fevals += self.pop_size\n\n                # Select\n                self.subpops[i], self.fitnesses[i] = self.select(self.subpops[i], self.fitnesses[i], new_pop, new_fitness)\n\n                # Update best solution\n                best_idx = np.argmin(self.fitnesses[i])\n                if self.fitnesses[i][best_idx] < self.best_fitness:\n                    self.best_fitness = self.fitnesses[i][best_idx]\n                    self.best_solution = self.subpops[i][best_idx]\n                    \n                if self.fevals >= self.budget:\n                    break\n\n            # Update the shared archive\n            self.update_archive(func)\n\n            # Exchange information between subpopulations\n            if (self.fevals // (self.pop_size * self.num_subpops)) % (self.exchange_interval // (self.pop_size * self.num_subpops)) == 0:\n                self.exchange_information()\n            \n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 5, "feedback": "An exception occurred: integer division or modulo by zero.", "error": "", "parent_ids": ["653423e0-cf06-4361-83b8-fb783dd51170"], "operator": null, "metadata": {}}
{"id": "cce188c5-fa14-4768-80c4-970a872d1634", "fitness": 0.0, "name": "SelfAdaptiveDENiche", "description": "Differential Evolution with self-adaptive parameters, a niching strategy to promote diversity, and a combined stagnation handling mechanism with both restart and perturbation.", "code": "import numpy as np\n\nclass SelfAdaptiveDENiche:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_initial=0.5, Cr_initial=0.9, archive_size=10, stagnation_limit=500, niche_radius=0.5):\n        \"\"\"\n        Differential Evolution with self-adaptive strategy selection, diversity maintenance using niching, and stagnation handling.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            F_initial (float): The initial scaling factor for differential variation.\n            Cr_initial (float): The initial crossover rate.\n            archive_size (int): Size of the archive for storing successful F and Cr values.\n            stagnation_limit (int): Number of iterations without improvement before triggering a restart.\n            niche_radius (float): Radius for niching to maintain diversity.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_initial\n        self.Cr = Cr_initial\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.archive_F = []\n        self.archive_Cr = []\n        self.archive_size = archive_size\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.strategy_success = np.zeros(3)  # Success count for each strategy\n        self.strategy_selection_prob = np.array([1/3, 1/3, 1/3]) # Initial probabilities\n        self.niche_radius = niche_radius\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with self-adaptive strategy selection, diversity maintenance using niching, and stagnation handling.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n        last_improvement = 0\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Strategy selection based on success probabilities\n                strategy_idx = np.random.choice(3, p=self.strategy_selection_prob)\n\n                # Adaptation of F and Cr (using archive or default values)\n                if len(self.archive_F) > 0:\n                    self.F = np.random.choice(self.archive_F)\n                else:\n                    self.F = 0.5  # Default F\n                if len(self.archive_Cr) > 0:\n                    self.Cr = np.random.choice(self.archive_Cr)\n                else:\n                    self.Cr = 0.9  # Default Cr\n\n                # Mutation Strategies\n                if strategy_idx == 0:\n                    # Current-to-best/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F * (self.pop[self.best_idx] - self.pop[i]) + self.F * (x_r1 - x_r2)\n                elif strategy_idx == 1:\n                    # Rand/1\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[indices]\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                else:\n                    # Current/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F * (x_r1 - x_r2)\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection with Niching\n                f_trial = func(x_trial)\n                fevals += 1\n\n                # Niching: Check if the trial vector is within the niche radius of another individual\n                is_in_niche = False\n                for j in range(self.pop_size):\n                    if i != j and np.linalg.norm(x_trial - self.pop[j]) < self.niche_radius:\n                        is_in_niche = True\n                        break\n\n                if f_trial < self.fitness[i]: #Improvement and/or not in niche.\n                    # Improvement\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n                    self.strategy_success[strategy_idx] += 1 #Increase strategy success count\n\n                    # Archive successful F and Cr\n                    self.archive_F.append(self.F)\n                    self.archive_Cr.append(self.Cr)\n                    if len(self.archive_F) > self.archive_size:\n                        self.archive_F.pop(0)\n                        self.archive_Cr.pop(0)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n                        last_improvement = fevals\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increase stagnation counter\n\n\n                if fevals >= self.budget:\n                    break\n\n            # Update strategy selection probabilities based on success\n            total_success = np.sum(self.strategy_success)\n            if total_success > 0:\n                self.strategy_selection_prob = self.strategy_success / total_success\n            else:\n                self.strategy_selection_prob = np.array([1/3, 1/3, 1/3]) # Reset if no success\n\n            self.strategy_success[:] = 0 #Reset success counters\n\n            # Stagnation Check and Combined Restart/Perturbation\n            if self.stagnation_counter > self.stagnation_limit:\n                if np.random.rand() < 0.5:\n                    # Option 1: Restart with new random population\n                    self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    self.fitness = np.array([func(x) for x in self.pop])\n                    self.best_idx = np.argmin(self.fitness)\n                    self.f_opt = self.fitness[self.best_idx]\n                    self.x_opt = self.pop[self.best_idx]\n                    fevals += self.pop_size\n                    self.stagnation_counter = 0\n                else:\n                    # Option 2: Perturb the current population.\n                    self.pop += 0.05 * np.random.normal(size=self.pop.shape)  # Small perturbation\n                    self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n                    self.fitness = np.array([func(x) for x in self.pop]) #Recalculate fitness\n                    self.best_idx = np.argmin(self.fitness)\n                    self.f_opt = self.fitness[self.best_idx]\n                    self.x_opt = self.pop[self.best_idx]\n                    fevals += self.pop_size//2 #Saves some function evaluations because it only perturbs.  Not a full restart.\n                    self.stagnation_counter = 0\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm SelfAdaptiveDENiche scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["39514fee-7312-4d41-a54d-8da791c4c73e"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "67a11032-ff3f-4ffd-9392-f90f8e150c60", "fitness": -Infinity, "name": "EnhancedAdaptiveDE", "description": "Enhanced Adaptive DE with age-based archive replacement and dynamic F/Cr adaptation using a cumulative distribution to bias towards successful parameters.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, archive_size=10, success_memory=10, age_limit=50):\n        \"\"\"\n        Enhanced Adaptive Differential Evolution with dynamic population size, success-history based parameter adaptation using cumulative distribution,\n        age-based archive replacement, and a resource allocation strategy favoring promising individuals.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            initial_pop_size (int): The initial population size.\n            min_pop_size (int): The minimum population size.\n            max_pop_size (int): The maximum population size.\n            archive_size (int): The size of the archive for storing successful F and Cr values.\n            success_memory (int): Size of memory for storing successful F and Cr values for adaptation\n            age_limit (int): Number of iterations before an archive entry is considered for replacement.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.pop_size = initial_pop_size\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.archive_F = np.full(archive_size, 0.5)  # Initialize F to 0.5\n        self.archive_Cr = np.full(archive_size, 0.9) # Initialize Cr to 0.9\n        self.archive_age = np.zeros(archive_size, dtype=int)\n        self.archive_size = archive_size\n        self.success_F_memory = []\n        self.success_Cr_memory = []\n        self.success_memory = success_memory\n        self.fevals_per_individual = np.ones(initial_pop_size, dtype=int) * (budget // initial_pop_size)\n        self.min_fevals_per_individual = 1\n        self.resource_allocation_frequency = 10  # Adjust resource allocation every this many iterations\n        self.age_limit = age_limit # Define age limit for archive entries\n        self.archive_idx = 0\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with dynamic population size, parameter adaptation, and resource allocation.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n\n        success_count = 0\n        iteration = 0\n\n        while fevals < self.budget:\n            iteration += 1\n            for i in range(self.pop_size):\n                if self.fevals_per_individual[i] <= 0:\n                    continue\n                # Parameter Adaptation\n                if self.success_F_memory:\n                    # Create CDF from successful F values\n                    F_values = np.array(self.success_F_memory)\n                    F_counts, _ = np.histogram(F_values, bins=10, range=(0, 1))\n                    F_cdf = np.cumsum(F_counts / np.sum(F_counts))\n                    rand = np.random.rand()\n                    F = np.min(F_values[F_cdf >= rand]) if any(F_cdf >= rand) else np.random.uniform(0.0, 1.0)\n                else:\n                    F = np.random.uniform(0.0, 1.0)\n\n                if self.success_Cr_memory:\n                    # Create CDF from successful Cr values\n                    Cr_values = np.array(self.success_Cr_memory)\n                    Cr_counts, _ = np.histogram(Cr_values, bins=10, range=(0, 1))\n                    Cr_cdf = np.cumsum(Cr_counts / np.sum(Cr_counts))\n                    rand = np.random.rand()\n                    Cr = np.min(Cr_values[Cr_cdf >= rand]) if any(Cr_cdf >= rand) else np.random.uniform(0.0, 1.0)\n                else:\n                    Cr = np.random.uniform(0.0, 1.0)\n                \n                # Mutation: current-to-best/1\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.pop[indices]\n                x_mutated = self.pop[i] + F * (self.pop[self.best_idx] - self.pop[i]) + F * (x_r1 - x_r2)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n                self.fevals_per_individual[i] -=1 \n\n                if f_trial < self.fitness[i]:\n                    self.success_F_memory.append(F)\n                    self.success_Cr_memory.append(Cr)\n\n                    if len(self.success_F_memory) > self.success_memory:\n                        self.success_F_memory.pop(0)\n                        self.success_Cr_memory.pop(0)\n\n                    success_count += 1\n                    \n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n\n                if fevals >= self.budget:\n                    break\n            \n            # Age-based archive replacement with probability\n            for idx in range(self.archive_size):\n                self.archive_age[idx] += 1\n                if self.archive_age[idx] > self.age_limit and np.random.rand() < 0.2: #Consider for replacement with 20% chance\n                    if self.success_F_memory:\n                        F = np.random.choice(self.success_F_memory)\n                    else:\n                        F = np.random.uniform(0.0, 1.0)\n\n                    if self.success_Cr_memory:\n                        Cr = np.random.choice(self.success_Cr_memory)\n                    else:\n                        Cr = np.random.uniform(0.0, 1.0)\n                    self.archive_F[idx] = F\n                    self.archive_Cr[idx] = Cr\n                    self.archive_age[idx] = 0\n            \n            # Adjust population size based on success rate\n            success_rate = success_count / self.pop_size\n            success_count = 0 # Reset counter\n\n            if success_rate > 0.2 and self.pop_size < self.max_pop_size:\n                self.pop_size = min(self.pop_size + 1, self.max_pop_size)\n                new_individual = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(1, self.dim))\n                self.pop = np.vstack((self.pop, new_individual))\n                self.fitness = np.append(self.fitness, func(new_individual[0]))\n                self.fevals_per_individual = np.append(self.fevals_per_individual, self.budget // self.pop_size)\n                fevals += 1\n                if self.fitness[-1] < self.f_opt:\n                    self.f_opt = self.fitness[-1]\n                    self.x_opt = self.pop[-1]\n                    self.best_idx = self.pop_size - 1\n\n            elif success_rate < 0.05 and self.pop_size > self.min_pop_size:\n                # Rank-based population reduction\n                ranked_indices = np.argsort(self.fitness)[::-1]  # Sort in descending order (worst to best)\n                num_to_remove = min(int(0.1 * self.pop_size), self.pop_size - self.min_pop_size)  # Remove 10% or until min_pop_size\n                indices_to_remove = ranked_indices[:num_to_remove]\n                \n                self.pop = np.delete(self.pop, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size -= num_to_remove\n                self.fevals_per_individual = np.delete(self.fevals_per_individual, indices_to_remove)\n                self.best_idx = np.argmin(self.fitness)  # Update best index\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n\n            # Resource allocation\n            if iteration % self.resource_allocation_frequency == 0:\n                # Distribute remaining budget based on fitness rank\n                remaining_fevals = self.budget - fevals\n                if remaining_fevals > 0:\n                    ranked_indices = np.argsort(self.fitness) # Ascending order (best to worst)\n                    weights = np.linspace(1.0, 0.1, self.pop_size) # Assign weights from best to worst\n                    weights /= weights.sum() # Normalize weights\n                    \n                    # Allocate fevals, ensuring minimum allocation\n                    new_fevals_per_individual = (weights * remaining_fevals).astype(int) + self.min_fevals_per_individual\n                    \n                    # Ensure that the total fevals do not exceed remaining budget\n                    if np.sum(new_fevals_per_individual) > remaining_fevals:\n                        diff = np.sum(new_fevals_per_individual) - remaining_fevals\n                        new_fevals_per_individual[ranked_indices[-diff:]] -= 1\n\n                    self.fevals_per_individual = new_fevals_per_individual\n                    \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occurred: boolean index did not match indexed array along dimension 0; dimension is 1 but corresponding boolean dimension is 10.", "error": "", "parent_ids": ["18dbcc78-3c3d-4905-b420-a9bcb8c076ae"], "operator": null, "metadata": {}}
{"id": "fb923e64-8fb8-4860-b928-6dfcc967a556", "fitness": 0.2353643933022172, "name": "SOMA", "description": "SOMA with adaptive step size and path length based on population diversity and success rate, incorporating a ring topology and stochastic perturbation of the leader.", "code": "import numpy as np\n\nclass SOMA:\n    def __init__(self, budget=10000, dim=10, pop_size=40, initial_step_size=0.1, initial_path_length=2.0, min_div=0.001, archive_size=10, perturbation_rate=0.1):\n        \"\"\"\n        Self-Organizing Migrating Algorithm (SOMA) with adaptive step size and path length.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            initial_step_size (float): The initial step size.\n            initial_path_length (float): The initial path length.\n            min_div (float): Minimum accepted diversity\n            archive_size (int): The size of the archive for storing past best solutions.\n            perturbation_rate (float): Probability of perturbing the leader.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = initial_step_size\n        self.path_length = initial_path_length\n        self.initial_step_size = initial_step_size\n        self.initial_path_length = initial_path_length\n        self.min_div = min_div\n        self.pop = None\n        self.fitness = None\n        self.leader_idx = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = archive_size\n        self.perturbation_rate = perturbation_rate\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using SOMA with adaptive step size and path length.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.leader_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.leader_idx]\n        self.x_opt = self.pop[self.leader_idx].copy()\n        fevals = self.pop_size\n\n        while fevals < self.budget:\n            # Migration loop\n            for i in range(self.pop_size):\n                if fevals >= self.budget:\n                    break\n                \n                # Select a leader using ring topology\n                leader_idx = (self.leader_idx + 1) % self.pop_size\n                leader = self.pop[leader_idx]\n\n                # Perturb the leader with a small probability\n                if np.random.rand() < self.perturbation_rate:\n                    leader = leader + np.random.normal(0, 0.05, size=self.dim)  # Small perturbation\n                    leader = np.clip(leader, func.bounds.lb, func.bounds.ub)\n\n                # Calculate direction vector towards the leader\n                direction_vector = leader - self.pop[i]\n                \n                # Migrate along the path\n                for j in np.arange(self.step_size, self.path_length + self.step_size, self.step_size):\n                    if fevals >= self.budget:\n                        break\n                    \n                    new_position = self.pop[i] + j * direction_vector\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                    \n                    f_new = func(new_position)\n                    fevals += 1\n                    \n                    if f_new < self.fitness[i]:\n                        self.fitness[i] = f_new\n                        self.pop[i] = new_position\n                        \n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = new_position.copy()\n                            self.leader_idx = i\n            \n            # Diversity check and possible restart\n            diversity = np.std(self.pop)\n            if diversity < self.min_div:\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                fevals += self.pop_size\n                self.leader_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[self.leader_idx]\n                self.x_opt = self.pop[self.leader_idx].copy()\n                self.step_size = self.initial_step_size\n                self.path_length = self.initial_path_length\n                \n            # Step size and path length adaptation based on success rate\n            success_rate = np.sum(self.fitness < np.mean(self.fitness)) / self.pop_size\n            self.step_size = max(0.01, self.step_size * (1 + 0.2 * (success_rate - 0.5)))\n            self.path_length = max(0.1, self.path_length * (1 + 0.1 * (success_rate - 0.5)))\n            self.step_size = min(1.0, self.step_size)\n            self.path_length = min(5.0, self.path_length)\n\n\n            # Archive the best solution\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.x_opt)\n            else:\n                self.archive.pop(0)\n                self.archive.append(self.x_opt)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm SOMA scored 0.235 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["43b89f21-9865-4626-a4dd-51008e4af3a5"], "operator": null, "metadata": {"aucs": [0.0845509400308121, 0.1954870385535069, 0.2592598694182927, 0.1448199920301142, 0.19137838767210658, 0.16960283594238812, 0.21256997156795798, 0.15786867204522825, 0.1833218369036248, 0.15996763080987098, 0.14904474072393403, 0.9979348188934839, 0.24677045763978445, 0.11509772390723305, 0.19723558962409027, 0.23268021888419244, 0.20344238618210753, 0.19114782879024583, 0.18078515382397453, 0.43432177260139493]}}
{"id": "2ad1d82e-6426-4804-9c8f-88a127cf94ed", "fitness": 0.41822676502858663, "name": "CooperativeSwarm", "description": "Cooperative Swarm Optimization with dynamic sub-swarm allocation and inter-swarm learning for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass CooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=10, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, exploration_pressure=0.1):\n        \"\"\"\n        Cooperative Swarm Optimization algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            num_swarms (int): The number of sub-swarms.\n            swarm_size (int): The size of each sub-swarm.\n            inertia (float): Inertia weight for particle velocity update.\n            cognitive_coeff (float): Cognitive coefficient for personal best influence.\n            social_coeff (float): Social coefficient for global best influence.\n            exploration_pressure (float): Probability of exploring a new region instead of exploiting.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_pressure = exploration_pressure\n        self.swarms = []\n        self.personal_best_positions = []\n        self.personal_best_fitness = []\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n\n    def initialize_swarm(self, func):\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.fevals += self.swarm_size\n        return swarm, fitness\n\n    def update_personal_best(self, swarm, fitness):\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n        return personal_best_positions, personal_best_fitness\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Cooperative Swarm Optimization.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        # Initialize swarms\n        for _ in range(self.num_swarms):\n            swarm, fitness = self.initialize_swarm(func)\n            self.swarms.append(swarm)\n            personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n            self.personal_best_positions.append(personal_best_positions)\n            self.personal_best_fitness.append(personal_best_fitness)\n\n            # Update global best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.global_best_fitness:\n                self.global_best_fitness = fitness[best_idx]\n                self.global_best_position = swarm[best_idx].copy()\n\n        velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n\n        while self.fevals < self.budget:\n            for i in range(self.num_swarms):\n                swarm = self.swarms[i]\n                personal_best_positions = self.personal_best_positions[i]\n                personal_best_fitness = self.personal_best_fitness[i]\n                velocity = velocities[i]\n\n                # Update velocities and positions\n                r1 = np.random.rand(self.swarm_size, self.dim)\n                r2 = np.random.rand(self.swarm_size, self.dim)\n\n                # Cooperative component: Influence from other swarms' best\n                cooperative_influence = np.zeros((self.swarm_size, self.dim))\n                for j in range(self.num_swarms):\n                    if i != j:\n                        best_idx_other = np.argmin(self.personal_best_fitness[j])\n                        cooperative_influence += (self.personal_best_positions[j][best_idx_other] - swarm)\n                cooperative_influence /= (self.num_swarms - 1) # Average influence\n\n                velocity = (self.inertia * velocity\n                            + self.cognitive_coeff * r1 * (personal_best_positions - swarm)\n                            + self.social_coeff * r2 * (self.global_best_position - swarm)\n                            + 0.1 * cooperative_influence) # Add cooperative influence with a small weight\n\n                new_swarm = swarm + velocity\n\n                # Exploration: Introduce random search with probability exploration_pressure\n                for k in range(self.swarm_size):\n                    if np.random.rand() < self.exploration_pressure:\n                        new_swarm[k] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Explore\n\n                new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n                new_fitness = np.array([func(x) for x in new_swarm])\n                self.fevals += self.swarm_size\n\n                # Update personal best\n                improvement = new_fitness < personal_best_fitness\n                personal_best_positions[improvement] = new_swarm[improvement].copy()\n                personal_best_fitness[improvement] = new_fitness[improvement].copy()\n\n                self.swarms[i] = new_swarm\n                self.personal_best_positions[i] = personal_best_positions\n                self.personal_best_fitness[i] = personal_best_fitness\n                velocities[i] = velocity\n\n                # Update global best\n                best_idx = np.argmin(personal_best_fitness)\n                if personal_best_fitness[best_idx] < self.global_best_fitness:\n                    self.global_best_fitness = personal_best_fitness[best_idx]\n                    self.global_best_position = personal_best_positions[best_idx].copy()\n                \n                if self.fevals >= self.budget:\n                    break\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm CooperativeSwarm scored 0.418 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["39514fee-7312-4d41-a54d-8da791c4c73e"], "operator": null, "metadata": {"aucs": [0.1559184117337472, 0.3388542336824363, 0.41602039926175116, 0.779429878136881, 0.26905036848890584, 0.5097191459081803, 0.29654695034552925, 0.40730046213024973, 0.4577109062106589, 0.22256657927480816, 0.5025114538232415, 0.9979555969030264, 0.2248111838544874, 0.27046988019528884, 0.6489423155101978, 0.4001290938301595, 0.37457409667730557, 0.3751653038144489, 0.2104976295181793, 0.5063614112722497]}}
{"id": "f89afa37-1acb-49f3-bb1c-3b371699ef1e", "fitness": 0.309176943083408, "name": "SOMA", "description": "Self-Organizing Migrating Algorithm (SOMA) with dynamic step size and path length adaptation based on success, incorporating an aging mechanism and a more robust diversity maintenance strategy using the median.", "code": "import numpy as np\n\nclass SOMA:\n    def __init__(self, budget=10000, dim=10, pop_size=40, step_size=0.1, path_length=2.0, min_div=0.001, archive_size=10, age_limit=5):\n        \"\"\"\n        Self-Organizing Migrating Algorithm (SOMA) with dynamic step size adaptation and aging.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            step_size (float): The initial step size.\n            path_length (float): The maximum length of the path traveled by each individual.\n            min_div (float): Minimum accepted diversity\n            archive_size (int): The size of the archive for storing past best solutions.\n            age_limit (int): The number of iterations an individual can stay without improvement before aging.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.path_length = path_length\n        self.min_div = min_div\n        self.pop = None\n        self.fitness = None\n        self.leader_idx = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = archive_size\n        self.age = np.zeros(pop_size)\n        self.age_limit = age_limit\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using SOMA with dynamic step size adaptation and aging.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.leader_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.leader_idx]\n        self.x_opt = self.pop[self.leader_idx]\n        fevals = self.pop_size\n\n        while fevals < self.budget:\n            # Migration loop\n            for i in range(self.pop_size):\n                if fevals >= self.budget:\n                    break\n                \n                # Calculate direction vector towards the leader\n                direction_vector = self.pop[self.leader_idx] - self.pop[i]\n                \n                # Migrate along the path\n                improved = False\n                for j in np.arange(self.step_size, self.path_length + self.step_size, self.step_size):\n                    if fevals >= self.budget:\n                        break\n                    \n                    new_position = self.pop[i] + j * direction_vector\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                    \n                    f_new = func(new_position)\n                    fevals += 1\n                    \n                    if f_new < self.fitness[i]:\n                        self.fitness[i] = f_new\n                        self.pop[i] = new_position\n                        improved = True\n                        \n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = new_position\n                            self.leader_idx = i\n                \n                # Aging mechanism\n                if not improved:\n                    self.age[i] += 1\n                    if self.age[i] > self.age_limit:\n                        self.pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                        self.fitness[i] = func(self.pop[i])\n                        fevals += 1\n                        self.age[i] = 0  # Reset age\n\n                        if self.fitness[i] < self.f_opt:\n                            self.f_opt = self.fitness[i]\n                            self.x_opt = self.pop[i]\n                            self.leader_idx = i\n                else:\n                    self.age[i] = 0 #reset age\n\n            # Diversity check and possible restart, using the median.\n            diversity = np.median(np.std(self.pop, axis=0))\n            if diversity < self.min_div:\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                fevals += self.pop_size\n                self.leader_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[self.leader_idx]\n                self.x_opt = self.pop[self.leader_idx]\n                self.age = np.zeros(self.pop_size) # reset age\n\n            # Step size adaptation\n            if len(self.archive) > 0:\n                distances = np.linalg.norm(self.pop - np.mean(self.archive, axis=0), axis=1)\n                self.step_size = 0.05 + 0.3 * np.mean(distances) / np.linalg.norm(func.bounds.ub - func.bounds.lb)\n                self.path_length = 1.5 + 0.5 * np.mean(distances) / np.linalg.norm(func.bounds.ub - func.bounds.lb)\n\n            # Archive the best solution\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.x_opt)\n            else:\n                self.archive.pop(0)\n                self.archive.append(self.x_opt)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm SOMA scored 0.309 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["43b89f21-9865-4626-a4dd-51008e4af3a5"], "operator": null, "metadata": {"aucs": [0.1713516385646804, 0.18952994052297711, 0.32465321948054093, 0.22422937302851464, 0.28278999853718434, 0.24981170654054596, 0.27392027574248456, 0.23070186007783455, 0.2480446676346134, 0.19107675098227128, 0.27918928807839705, 0.9738473754467544, 0.2845262258065785, 0.21518817030170034, 0.5906679034531361, 0.28395380729920194, 0.2059430029232514, 0.3413442020136055, 0.15882061165904449, 0.46394884357484234]}}
{"id": "02bf4171-b00d-4759-8a48-c3249f323689", "fitness": 0.2879617021825459, "name": "SOMA", "description": "Self-Organizing Migrating Algorithm (SOMA) with adaptive step size and path length, combined with a niching strategy to maintain diversity and prevent premature convergence.", "code": "import numpy as np\n\nclass SOMA:\n    def __init__(self, budget=10000, dim=10, pop_size=40, step_size=0.1, path_length=2.0, min_div=0.001, archive_size=10, num_niches=5):\n        \"\"\"\n        Self-Organizing Migrating Algorithm (SOMA) with dynamic step size adaptation and niching.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            step_size (float): The initial step size.\n            path_length (float): The maximum length of the path traveled by each individual.\n            min_div (float): Minimum accepted diversity\n            archive_size (int): The size of the archive for storing past best solutions.\n            num_niches (int): The number of niches to maintain.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.path_length = path_length\n        self.min_div = min_div\n        self.pop = None\n        self.fitness = None\n        self.leader_idx = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = archive_size\n        self.num_niches = num_niches\n        self.niches = None\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using SOMA with dynamic step size adaptation and niching.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.leader_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.leader_idx]\n        self.x_opt = self.pop[self.leader_idx]\n        fevals = self.pop_size\n\n        # Initialize niches\n        self.niches = self.pop[np.random.choice(self.pop_size, size=self.num_niches, replace=False)]\n\n        while fevals < self.budget:\n            # Migration loop\n            for i in range(self.pop_size):\n                if fevals >= self.budget:\n                    break\n\n                # Select leader from nearest niche\n                distances = np.linalg.norm(self.niches - self.pop[i], axis=1)\n                nearest_niche_idx = np.argmin(distances)\n                leader = self.niches[nearest_niche_idx]\n\n                # Calculate direction vector towards the leader\n                direction_vector = leader - self.pop[i]\n                \n                # Adaptive path length\n                adaptive_path_length = self.path_length * (1.0 - fevals / self.budget)\n\n                # Migrate along the path\n                for j in np.arange(self.step_size, adaptive_path_length + self.step_size, self.step_size):\n                    if fevals >= self.budget:\n                        break\n                    \n                    new_position = self.pop[i] + j * direction_vector\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                    \n                    f_new = func(new_position)\n                    fevals += 1\n                    \n                    if f_new < self.fitness[i]:\n                        self.fitness[i] = f_new\n                        self.pop[i] = new_position\n                        \n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = new_position\n                            \n            # Update niches\n            for k in range(self.num_niches):\n                niche_members = np.argsort(np.linalg.norm(self.pop - self.niches[k], axis=1))[:self.pop_size // self.num_niches]\n                best_member_idx = niche_members[np.argmin(self.fitness[niche_members])]\n                self.niches[k] = self.pop[best_member_idx]\n                            \n            # Diversity check and possible restart\n            diversity = np.std(self.pop)\n            if diversity < self.min_div:\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                fevals += self.pop_size\n                # Re-initialize niches\n                self.niches = self.pop[np.random.choice(self.pop_size, size=self.num_niches, replace=False)]\n\n            # Step size adaptation\n            if len(self.archive) > 0:\n                 distances = np.linalg.norm(self.pop - np.mean(self.archive, axis=0), axis=1)\n                 self.step_size = 0.05 + 0.25 * np.mean(distances) / np.linalg.norm(func.bounds.ub - func.bounds.lb) # adapt depending on average distance to best solutions\n\n            # Archive the best solution\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.x_opt)\n            else:\n                self.archive.pop(0)\n                self.archive.append(self.x_opt)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm SOMA scored 0.288 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["43b89f21-9865-4626-a4dd-51008e4af3a5"], "operator": null, "metadata": {"aucs": [0.11912812892815294, 0.1648873103073294, 0.2631741803175912, 0.3117397073295185, 0.22261528043456602, 0.26041232859373, 0.25195946718901274, 0.18568598837617523, 0.197721624562456, 0.1771525226144024, 0.21905831027615752, 0.9966740286275703, 0.240087990000051, 0.24616404761387944, 0.5227438021667233, 0.2545740339348257, 0.22521986777198377, 0.27528763838427905, 0.15756054944381936, 0.4673872367786941]}}
{"id": "b73699bf-7744-48de-a28b-ad8ed2bb5cd3", "fitness": 0.579600750363618, "name": "CooperativeSwarm", "description": "Cooperative Swarm Optimization with adaptive velocity clamping and neighborhood-based learning guided by fitness and distance.", "code": "import numpy as np\n\nclass CooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, velocity_clamp_factor=0.2, neighborhood_size=5):\n        \"\"\"\n        Cooperative Swarm Optimization with adaptive velocity clamping and neighborhood-based learning.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            swarm_size (int): The number of particles in the swarm.\n            inertia (float): Inertia weight for the particle's previous velocity.\n            cognitive_coeff (float): Cognitive acceleration coefficient.\n            social_coeff (float): Social acceleration coefficient.\n            velocity_clamp_factor (float): Factor for adaptive velocity clamping based on search space.\n            neighborhood_size (int): Size of the neighborhood for social learning.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp_factor = velocity_clamp_factor\n        self.neighborhood_size = neighborhood_size\n        self.swarm = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Cooperative Swarm Optimization.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.swarm_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.swarm])\n        self.personal_best_positions = np.copy(self.swarm)\n        self.personal_best_fitness = np.copy(self.fitness)\n        self.global_best_position = self.swarm[np.argmin(self.fitness)]\n        self.global_best_fitness = np.min(self.fitness)\n\n        fevals = self.swarm_size\n\n        while fevals < self.budget:\n            for i in range(self.swarm_size):\n                # Adaptive velocity clamping\n                v_max = self.velocity_clamp_factor * (func.bounds.ub - func.bounds.lb)\n                self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n                # Neighborhood selection (k-nearest neighbors based on Euclidean distance)\n                distances = np.linalg.norm(self.swarm - self.swarm[i], axis=1)\n                neighborhood_indices = np.argsort(distances)[:self.neighborhood_size]\n\n                # Cooperative Learning: Find best neighbor based on fitness and distance.\n                best_neighbor_idx = neighborhood_indices[0]\n                best_neighbor_fitness = self.personal_best_fitness[neighborhood_indices[0]]\n                for idx in neighborhood_indices[1:]:\n                    if self.personal_best_fitness[idx] < best_neighbor_fitness:\n                        best_neighbor_fitness = self.personal_best_fitness[idx]\n                        best_neighbor_idx = idx\n                    elif self.personal_best_fitness[idx] == best_neighbor_fitness and distances[idx] < distances[best_neighbor_idx]:\n                        # Break ties by preferring closer particles\n                        best_neighbor_idx = idx\n\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = (self.inertia * self.velocities[i]\n                                     + self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.swarm[i])\n                                     + self.social_coeff * r2 * (self.personal_best_positions[best_neighbor_idx] - self.swarm[i]))\n\n                # Update position\n                new_position = self.swarm[i] + self.velocities[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                new_fitness = func(new_position)\n                fevals += 1\n\n                # Update personal best\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position\n\n                # Update global best\n                if new_fitness < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness\n                    self.global_best_position = new_position\n\n                self.swarm[i] = new_position #Update swarm\n\n                if fevals >= self.budget:\n                    break\n            \n            #Potentially add diversity maintenance here, such as random restarts of particles far from the global best.\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm CooperativeSwarm scored 0.580 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["39514fee-7312-4d41-a54d-8da791c4c73e"], "operator": null, "metadata": {"aucs": [0.22197913979915151, 0.22645461539775513, 0.6734526303245711, 0.888718264944706, 0.7758878658404981, 0.7872543489889615, 0.32538690781556856, 0.6716644011211563, 0.7646471207023445, 0.21478006072168487, 0.8700494899853352, 0.9917849602018739, 0.26481099668755925, 0.5766310182870655, 0.7198325892027957, 0.634847716349253, 0.5490899874467737, 0.7222543715501304, 0.20206764931176768, 0.510420872593408]}}
{"id": "161ec2fc-6418-4deb-8186-119ae89e5ad1", "fitness": 0.6925449702981009, "name": "AdaptiveResourceDE", "description": "Adaptive Differential Evolution with population diversity control, dynamic F/Cr adaptation using a trend-aware mechanism, and a budget-aware resource allocation strategy.", "code": "import numpy as np\n\nclass AdaptiveResourceDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, F=0.5, Cr=0.9, archive_size=10, success_memory=10, diversity_threshold=0.1):\n        \"\"\"\n        Adaptive Differential Evolution with dynamic population size, success-history based parameter adaptation,\n        and a resource allocation strategy favoring promising individuals.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            initial_pop_size (int): The initial population size.\n            min_pop_size (int): The minimum population size.\n            max_pop_size (int): The maximum population size.\n            F (float): The initial scaling factor for differential variation.\n            Cr (float): The initial crossover rate.\n            archive_size (int): The size of the archive for storing successful F and Cr values.\n            success_memory (int): Size of memory for storing successful F and Cr values for adaptation\n            diversity_threshold (float): Threshold for population diversity check\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.pop_size = initial_pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.archive_F = np.full(archive_size, F)\n        self.archive_Cr = np.full(archive_size, Cr)\n        self.archive_idx = 0\n        self.archive_size = archive_size\n        self.success_F_memory = []\n        self.success_Cr_memory = []\n        self.success_memory = success_memory\n        self.fevals_per_individual = np.ones(initial_pop_size, dtype=int) * (budget // initial_pop_size)\n        self.min_fevals_per_individual = 1\n        self.resource_allocation_frequency = 10  # Adjust resource allocation every this many iterations\n        self.diversity_threshold = diversity_threshold\n        self.f_trend = []\n        self.trend_window = 5\n        self.stagnation_tolerance = 50\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with dynamic population size, parameter adaptation, and resource allocation.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n        success_count = 0\n        iteration = 0\n        stagnation_counter = 0\n\n        while fevals < self.budget:\n            iteration += 1\n            old_f_opt = self.f_opt\n\n            for i in range(self.pop_size):\n                if self.fevals_per_individual[i] <= 0:\n                    continue\n\n                # Parameter Adaptation\n                F = np.random.choice(self.archive_F)\n                Cr = np.random.choice(self.archive_Cr)\n\n                # Mutation: current-to-best/1\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.pop[indices]\n                x_mutated = self.pop[i] + F * (self.pop[self.best_idx] - self.pop[i]) + F * (x_r1 - x_r2)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n                self.fevals_per_individual[i] -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.success_F_memory.append(F)\n                    self.success_Cr_memory.append(Cr)\n\n                    if len(self.success_F_memory) > self.success_memory:\n                        self.success_F_memory.pop(0)\n                        self.success_Cr_memory.pop(0)\n\n                    success_count += 1\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n\n                if fevals >= self.budget:\n                    break\n\n            # Track fitness trend\n            self.f_trend.append(self.f_opt)\n            if len(self.f_trend) > self.trend_window:\n                self.f_trend.pop(0)\n            \n            # Stagnation Detection\n            if self.f_opt >= old_f_opt:\n                stagnation_counter += 1\n            else:\n                stagnation_counter = 0\n            \n            # Update archive with successful F and Cr values using a weighted average\n            if self.success_F_memory:\n                weights = np.linspace(0.1, 1.0, len(self.success_F_memory))\n                weights /= weights.sum()  # Normalize weights\n\n                weighted_avg_F = np.average(self.success_F_memory, weights=weights)\n                weighted_avg_Cr = np.average(self.success_Cr_memory, weights=weights)\n                \n                # Trend-aware adaptation\n                if len(self.f_trend) == self.trend_window and self.f_trend[-1] > self.f_trend[0]:\n                   # If fitness is worsening, reduce F and Cr to promote exploration\n                    self.archive_F[self.archive_idx] = weighted_avg_F * 0.2 + self.archive_F[self.archive_idx] * 0.8\n                    self.archive_Cr[self.archive_idx] = weighted_avg_Cr * 0.2 + self.archive_Cr[self.archive_idx] * 0.8\n                else:\n                    self.archive_F[self.archive_idx] = weighted_avg_F * 0.5 + self.archive_F[self.archive_idx] * 0.5\n                    self.archive_Cr[self.archive_idx] = weighted_avg_Cr * 0.5 + self.archive_Cr[self.archive_idx] * 0.5\n                    \n                self.archive_idx = (self.archive_idx + 1) % self.archive_size\n\n            # Diversity check\n            diversity = np.std(self.pop)\n            if diversity < self.diversity_threshold:\n                # Introduce random perturbations to increase diversity\n                for i in range(self.pop_size):\n                    self.pop[i] += np.random.normal(0, 0.1, self.dim)\n                    self.pop[i] = np.clip(self.pop[i], func.bounds.lb, func.bounds.ub)\n                    self.fitness[i] = func(self.pop[i])\n                    fevals += 1\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.pop[i]\n                        self.best_idx = i\n                    if fevals >= self.budget:\n                        break\n                        \n            # Adjust population size based on success rate\n            success_rate = success_count / self.pop_size\n            success_count = 0 # Reset counter\n\n            if success_rate > 0.2 and self.pop_size < self.max_pop_size:\n                self.pop_size = min(self.pop_size + 1, self.max_pop_size)\n                new_individual = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(1, self.dim))\n                self.pop = np.vstack((self.pop, new_individual))\n                self.fitness = np.append(self.fitness, func(new_individual[0]))\n                self.fevals_per_individual = np.append(self.fevals_per_individual, self.budget // self.pop_size)\n                fevals += 1\n                if self.fitness[-1] < self.f_opt:\n                    self.f_opt = self.fitness[-1]\n                    self.x_opt = self.pop[-1]\n                    self.best_idx = self.pop_size - 1\n\n            elif success_rate < 0.05 and self.pop_size > self.min_pop_size:\n                # Rank-based population reduction\n                ranked_indices = np.argsort(self.fitness)[::-1]  # Sort in descending order (worst to best)\n                num_to_remove = min(int(0.1 * self.pop_size), self.pop_size - self.min_pop_size)  # Remove 10% or until min_pop_size\n                indices_to_remove = ranked_indices[:num_to_remove]\n                \n                self.pop = np.delete(self.pop, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size -= num_to_remove\n                self.fevals_per_individual = np.delete(self.fevals_per_individual, indices_to_remove)\n                self.best_idx = np.argmin(self.fitness)  # Update best index\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n\n            # Resource allocation\n            if iteration % self.resource_allocation_frequency == 0:\n                # Distribute remaining budget based on fitness rank\n                remaining_fevals = self.budget - fevals\n                if remaining_fevals > 0:\n                    ranked_indices = np.argsort(self.fitness) # Ascending order (best to worst)\n                    weights = np.linspace(1.0, 0.1, self.pop_size) # Assign weights from best to worst\n                    weights /= weights.sum() # Normalize weights\n                    \n                    # Allocate fevals, ensuring minimum allocation\n                    new_fevals_per_individual = (weights * remaining_fevals).astype(int) + self.min_fevals_per_individual\n                    \n                    # Ensure that the total fevals do not exceed remaining budget\n                    if np.sum(new_fevals_per_individual) > remaining_fevals:\n                        diff = np.sum(new_fevals_per_individual) - remaining_fevals\n                        new_fevals_per_individual[ranked_indices[-diff:]] -= 1\n\n                    self.fevals_per_individual = new_fevals_per_individual\n            \n            if stagnation_counter > self.stagnation_tolerance:\n                 # Restart strategy\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n                fevals += self.pop_size\n                self.fevals_per_individual = np.ones(self.pop_size, dtype=int) * (self.budget // self.pop_size)\n                stagnation_counter = 0\n                self.f_trend = []\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveResourceDE scored 0.693 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["18dbcc78-3c3d-4905-b420-a9bcb8c076ae"], "operator": null, "metadata": {"aucs": [0.3142695150794087, 0.7631586590938177, 0.7529071846169363, 0.9228272254927163, 0.7681204766003962, 0.8362412527878925, 0.35847189792872847, 0.7122662870313439, 0.794086289175595, 0.19936881278195295, 0.9317122131135863, 0.9979053370708456, 0.6897484718926745, 0.7386761150590543, 0.9561408847907136, 0.7880145849278462, 0.6812474492976761, 0.88488141534501, 0.22515957449959423, 0.535695759376229]}}
{"id": "e5c42679-0f58-437e-b303-1a450e6bf45b", "fitness": 0.28757623905127666, "name": "SOMA", "description": "Enhanced SOMA with adaptive step size and path length, combined with a niching strategy to maintain diversity and avoid premature convergence.", "code": "import numpy as np\n\nclass SOMA:\n    def __init__(self, budget=10000, dim=10, pop_size=40, step_size=0.1, path_length=2.0, min_div=0.001, archive_size=10, niche_radius=0.5):\n        \"\"\"\n        Self-Organizing Migrating Algorithm (SOMA) with dynamic step size and path length adaptation, and niching.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            step_size (float): The initial step size.\n            path_length (float): The maximum length of the path traveled by each individual.\n            min_div (float): Minimum accepted diversity\n            archive_size (int): The size of the archive for storing past best solutions.\n            niche_radius (float): Radius of the niche for niching strategy.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.path_length = path_length\n        self.min_div = min_div\n        self.pop = None\n        self.fitness = None\n        self.leader_idx = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = archive_size\n        self.niche_radius = niche_radius\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using SOMA with dynamic step size and path length adaptation, and niching.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.leader_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.leader_idx]\n        self.x_opt = self.pop[self.leader_idx]\n        fevals = self.pop_size\n\n        while fevals < self.budget:\n            # Migration loop\n            for i in range(self.pop_size):\n                if fevals >= self.budget:\n                    break\n                \n                # Calculate direction vector towards the leader\n                direction_vector = self.pop[self.leader_idx] - self.pop[i]\n                \n                # Migrate along the path\n                for j in np.arange(self.step_size, self.path_length + self.step_size, self.step_size):\n                    if fevals >= self.budget:\n                        break\n                    \n                    new_position = self.pop[i] + j * direction_vector\n                    new_position = np.clip(new_position, lb, ub)\n                    \n                    f_new = func(new_position)\n                    fevals += 1\n                    \n                    # Niching: If a solution is too close to another, penalize its fitness\n                    for k in range(self.pop_size):\n                        if i != k and np.linalg.norm(new_position - self.pop[k]) < self.niche_radius:\n                            f_new += 0.01 * abs(f_new)  # Penalty\n\n                    \n                    if f_new < self.fitness[i]:\n                        self.fitness[i] = f_new\n                        self.pop[i] = new_position\n                        \n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = new_position\n                            self.leader_idx = i\n            \n            # Diversity check and possible restart\n            diversity = np.std(self.pop)\n            if diversity < self.min_div:\n                self.pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                fevals += self.pop_size\n                self.leader_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[self.leader_idx]\n                self.x_opt = self.pop[self.leader_idx]\n                \n            # Adaptive step size and path length\n            if len(self.archive) > 0:\n                distances = np.linalg.norm(self.pop - np.mean(self.archive, axis=0), axis=1)\n                mean_distance = np.mean(distances)\n                self.step_size = 0.05 + 0.2 * mean_distance / np.linalg.norm(ub - lb)  # adapt depending on average distance to best solutions\n                self.path_length = 1.5 + 1.0 * mean_distance / np.linalg.norm(ub - lb) # adapt path length too\n                self.step_size = np.clip(self.step_size, 0.01, 0.5) # Adding constraints\n                self.path_length = np.clip(self.path_length, 0.5, 3.0) # Adding constraints\n\n            # Archive the best solution\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.x_opt)\n            else:\n                self.archive.pop(0)\n                self.archive.append(self.x_opt)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm SOMA scored 0.288 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["43b89f21-9865-4626-a4dd-51008e4af3a5"], "operator": null, "metadata": {"aucs": [0.19035334568383733, 0.1740589080494237, 0.28749190080144926, 0.28567054077818366, 0.2606354353741054, 0.24691937178252665, 0.31076945385248655, 0.2329923614590299, 0.24304622829142286, 0.18172451800898204, 0.22281659513411678, 0.9971600514079624, 0.24584841241490518, 0.2681604662711877, 0.18995542170210755, 0.30962892420081645, 0.2360412841927637, 0.22756685784515174, 0.16217018553008022, 0.47851451824499414]}}
{"id": "c255d301-d671-42a5-8bcf-2477dcb86a8d", "fitness": -Infinity, "name": "EnhancedSelfAdaptiveDE", "description": "Self-adaptive DE with ensemble of mutation strategies weighted by dynamic learning rates, covariance matrix adaptation for exploration, and a niching mechanism to maintain diversity.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_initial=0.5, Cr_initial=0.9, archive_size=10, stagnation_limit=500, num_strategies=4):\n        \"\"\"\n        Enhanced Differential Evolution with self-adaptive strategy selection, covariance matrix adaptation, niching, and stagnation handling.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            F_initial (float): The initial scaling factor for differential variation.\n            Cr_initial (float): The initial crossover rate.\n            archive_size (int): Size of the archive for storing successful F and Cr values.\n            stagnation_limit (int): Number of iterations without improvement before triggering a restart.\n            num_strategies (int): Number of mutation strategies to use in the ensemble.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_initial\n        self.Cr = Cr_initial\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.archive_F = []\n        self.archive_Cr = []\n        self.archive_size = archive_size\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.num_strategies = num_strategies\n        self.strategy_success = np.zeros(self.num_strategies)\n        self.strategy_selection_prob = np.ones(self.num_strategies) / self.num_strategies\n        self.learning_rates = np.ones(self.num_strategies) / self.num_strategies  # Dynamic learning rates for strategies\n        self.C = np.eye(dim)  # Covariance matrix for CMA-ES-like exploration\n        self.cma_learning_rate = 0.1  # Learning rate for covariance matrix adaptation\n        self.niching_radius = 0.5  # Radius for niching\n        self.min_distance = 0.01 * (func.bounds.ub - func.bounds.lb) # Minimum distance between individuals\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Enhanced Differential Evolution with self-adaptive strategy selection, covariance matrix adaptation, niching, and stagnation handling.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n        last_improvement = 0\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Strategy selection based on success probabilities and learning rates\n                strategy_idx = np.random.choice(self.num_strategies, p=self.strategy_selection_prob)\n\n                # Adaptation of F and Cr (using archive or default values)\n                if len(self.archive_F) > 0:\n                    self.F = np.random.choice(self.archive_F)\n                else:\n                    self.F = 0.5  # Default F\n                if len(self.archive_Cr) > 0:\n                    self.Cr = np.random.choice(self.archive_Cr)\n                else:\n                    self.Cr = 0.9  # Default Cr\n\n                # Mutation Strategies (Expanding the Strategy set)\n                if strategy_idx == 0:\n                    # Current-to-best/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F * (self.pop[self.best_idx] - self.pop[i]) + self.F * (x_r1 - x_r2)\n                elif strategy_idx == 1:\n                    # Rand/1\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[indices]\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                elif strategy_idx == 2:\n                    # Current/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F * (x_r1 - x_r2)\n                else:\n                    # CMA-ES-like exploration\n                    z = np.random.normal(0, 1, self.dim)\n                    x_mutated = self.pop[i] + self.F * np.dot(self.C, z) # Scaling the exploration\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                # Niching: Check distance to existing members. Replace only if far enough\n                min_dist = np.min(np.linalg.norm(self.pop - x_trial, axis=1))\n                if min_dist >= self.min_distance: #Niching condition\n                    if f_trial < self.fitness[i]:\n                        # Improvement\n                        self.fitness[i] = f_trial\n                        self.pop[i] = x_trial\n                        self.strategy_success[strategy_idx] += 1\n\n                        # Archive successful F and Cr\n                        self.archive_F.append(self.F)\n                        self.archive_Cr.append(self.Cr)\n                        if len(self.archive_F) > self.archive_size:\n                            self.archive_F.pop(0)\n                            self.archive_Cr.pop(0)\n\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = x_trial\n                            self.best_idx = i\n                            last_improvement = fevals\n                            self.stagnation_counter = 0\n                    else:\n                        self.stagnation_counter += 1\n                else:\n                    self.stagnation_counter += 1  #Penalize trials that are too close.\n\n                if fevals >= self.budget:\n                    break\n\n            # Update strategy selection probabilities based on success and learning rates\n            total_success = np.sum(self.strategy_success)\n            if total_success > 0:\n                #Update learning rates\n                self.learning_rates = self.strategy_success / total_success\n                #Softmax to ensure probabilities\n                self.strategy_selection_prob = np.exp(self.learning_rates) / np.sum(np.exp(self.learning_rates))\n\n            else:\n                self.strategy_selection_prob = np.ones(self.num_strategies) / self.num_strategies\n\n            self.strategy_success[:] = 0\n\n            # CMA-ES-like covariance matrix adaptation\n            if last_improvement > fevals - (self.budget // 10):  # Adapt only if there has been recent improvement\n                z = self.pop[self.best_idx] - self.x_opt\n                self.C = (1 - self.cma_learning_rate) * self.C + self.cma_learning_rate * np.outer(z, z)\n                # Ensure the covariance matrix is positive semi-definite\n                try:\n                    np.linalg.cholesky(self.C)\n                except np.linalg.LinAlgError:\n                    self.C = np.eye(self.dim)  # Reset if not positive semi-definite\n\n            # Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_limit:\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n                fevals += self.pop_size\n                self.stagnation_counter = 0\n                self.strategy_selection_prob = np.ones(self.num_strategies) / self.num_strategies # Reset strategy probabilities\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occurred: name 'func' is not defined.", "error": "", "parent_ids": ["39514fee-7312-4d41-a54d-8da791c4c73e"], "operator": null, "metadata": {}}
{"id": "09f69ee2-0b24-4fee-b82a-77cecc5e9f18", "fitness": 0.7563906398140774, "name": "EnhancedSelfAdaptiveDE", "description": "Self-adaptive DE with improved strategy adaptation using a weighted historical archive and dynamic F/Cr scaling.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_initial=0.5, Cr_initial=0.9, archive_size=10, stagnation_limit=500, p_selection=0.5):\n        \"\"\"\n        Enhanced Differential Evolution with self-adaptive strategy selection, diversity maintenance, and stagnation handling.\n        Uses a weighted historical archive and dynamic F/Cr scaling.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            F_initial (float): The initial scaling factor for differential variation.\n            Cr_initial (float): The initial crossover rate.\n            archive_size (int): Size of the archive for storing successful F and Cr values.\n            stagnation_limit (int): Number of iterations without improvement before triggering a restart.\n            p_selection (float): Probability of selecting F/Cr from the archive.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_initial\n        self.Cr = Cr_initial\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.archive_F = []\n        self.archive_Cr = []\n        self.archive_size = archive_size\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.strategy_success = np.zeros(3)  # Success count for each strategy\n        self.strategy_selection_prob = np.array([1/3, 1/3, 1/3]) # Initial probabilities\n        self.p_selection = p_selection # Probability of using archive values\n        self.archive_weights = []  # Weights for historical F/Cr values\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with enhanced self-adaptive strategy selection, diversity maintenance, and stagnation handling.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n        last_improvement = 0\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Strategy selection based on success probabilities\n                strategy_idx = np.random.choice(3, p=self.strategy_selection_prob)\n\n                # Adaptation of F and Cr (using archive or default values)\n                if np.random.rand() < self.p_selection and len(self.archive_F) > 0:\n                    # Weighted selection from the archive\n                    weights = np.array(self.archive_weights) / np.sum(self.archive_weights) if np.sum(self.archive_weights) > 0 else np.ones(len(self.archive_weights)) / len(self.archive_weights)\n                    idx = np.random.choice(len(self.archive_F), p=weights)\n                    self.F = self.archive_F[idx]\n                    self.Cr = self.archive_Cr[idx]\n                else:\n                    self.F = 0.5 + 0.3 * np.random.randn() # Default F with some noise\n                    self.Cr = 0.9 + 0.1 * np.random.randn()  # Default Cr with some noise\n                \n                self.F = np.clip(self.F, 0.1, 1.0)  # Ensure F is within reasonable bounds\n                self.Cr = np.clip(self.Cr, 0.1, 1.0) # Ensure Cr is within reasonable bounds\n\n                # Mutation Strategies\n                if strategy_idx == 0:\n                    # Current-to-best/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F * (self.pop[self.best_idx] - self.pop[i]) + self.F * (x_r1 - x_r2)\n                elif strategy_idx == 1:\n                    # Rand/1\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[indices]\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                else:\n                    # Current/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F * (x_r1 - x_r2)\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    # Improvement\n                    delta_fitness = self.fitness[i] - f_trial  # Calculate fitness improvement\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n                    self.strategy_success[strategy_idx] += 1 #Increase strategy success count\n\n                    # Archive successful F and Cr with fitness improvement weight\n                    self.archive_F.append(self.F)\n                    self.archive_Cr.append(self.Cr)\n                    self.archive_weights.append(delta_fitness) # Weight based on fitness improvement\n\n                    if len(self.archive_F) > self.archive_size:\n                        self.archive_F.pop(0)\n                        self.archive_Cr.pop(0)\n                        self.archive_weights.pop(0)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n                        last_improvement = fevals\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increase stagnation counter\n\n\n                if fevals >= self.budget:\n                    break\n\n            # Update strategy selection probabilities based on success\n            total_success = np.sum(self.strategy_success)\n            if total_success > 0:\n                self.strategy_selection_prob = self.strategy_success / total_success\n            else:\n                self.strategy_selection_prob = np.array([1/3, 1/3, 1/3]) # Reset if no success\n\n            self.strategy_success[:] = 0 #Reset success counters\n\n            # Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_limit:\n                # Option 1: Restart with new random population\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n                fevals += self.pop_size\n                self.stagnation_counter = 0\n                self.archive_F = []  # Clear archive upon restart\n                self.archive_Cr = []\n                self.archive_weights = []\n                # Resetting success history might also be a good idea here.\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedSelfAdaptiveDE scored 0.756 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["39514fee-7312-4d41-a54d-8da791c4c73e"], "operator": null, "metadata": {"aucs": [0.31540597304783735, 0.8034150472739314, 0.8302398696860745, 0.9251163527248603, 0.8203398293264634, 0.8691295436364588, 0.36157626386571684, 0.7852094181964419, 0.8444332726440811, 0.58938679864019, 0.9164283717761478, 0.9970416132627283, 0.8208194785746894, 0.8312648893561829, 0.9573776155068705, 0.8495011445283138, 0.7888377672638445, 0.9075679161524415, 0.20349582781432174, 0.7112258030039523]}}
{"id": "313dffef-d61b-4c78-9915-2b093a287f48", "fitness": -Infinity, "name": "OrthogonalDE", "description": "Hybrid DE with orthogonal learning, integrating orthogonal experimental design to generate promising candidate solutions.", "code": "import numpy as np\n\nclass OrthogonalDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, orthogonal_levels=3):\n        \"\"\"\n        Hybrid Differential Evolution with orthogonal learning, integrating orthogonal experimental design to generate promising candidate solutions.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            F (float): The scaling factor for differential variation.\n            Cr (float): The crossover rate.\n            orthogonal_levels (int): The number of levels for orthogonal design.  Must be a prime or prime power.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.orthogonal_levels = orthogonal_levels  # Number of levels for orthogonal design\n\n        # Generate orthogonal array (L_9(3^4) for example, if orthogonal_levels=3 and dim = 10, will use the first 4 columns. Needs adaptation for other cases.)\n        self.orthogonal_array = self._generate_orthogonal_array(orthogonal_levels, dim)\n\n    def _generate_orthogonal_array(self, levels, dim):\n      \"\"\"\n      Generates an orthogonal array for given levels and dimensions.\n      This is a simplified version and assumes levels are a prime or prime power\n      and that the number of factors (columns) doesn't exceed the array's capabilities.\n      \"\"\"\n      # For simplicity, we use a fixed L_9(3^4) array if levels=3 and dim <= 4.\n      # Otherwise, we would need a more general orthogonal array generator.\n      if levels == 3:\n          if dim <= 4:\n              array = np.array([\n                  [0, 0, 0, 0],\n                  [0, 1, 1, 1],\n                  [0, 2, 2, 2],\n                  [1, 0, 1, 2],\n                  [1, 1, 2, 0],\n                  [1, 2, 0, 1],\n                  [2, 0, 2, 1],\n                  [2, 1, 0, 2],\n                  [2, 2, 1, 0]\n              ])\n              return array[:, :dim]  # Use only the necessary columns\n          else:\n            raise ValueError(\"For orthogonal_levels=3, the dimension must be <= 4 for this simplified implementation.\")\n      else:\n          raise ValueError(\"Only orthogonal_levels=3 is supported in this simplified implementation.\")\n\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with orthogonal learning.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[indices]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Orthogonal Learning - Generate new candidates based on current individual\n                num_orthogonal_samples = self.orthogonal_array.shape[0]  # Number of rows in OA\n                orthogonal_candidates = np.zeros((num_orthogonal_samples, self.dim))\n                for k in range(num_orthogonal_samples):\n                    orthogonal_candidates[k] = x_trial.copy()  # Start with current trial vector\n                    for j in range(self.dim):\n                        # Map orthogonal levels to search space\n                        level = self.orthogonal_array[k, j]\n                        orthogonal_candidates[k, j] = func.bounds.lb + (func.bounds.ub - func.bounds.lb) * (level / (self.orthogonal_levels - 1)) if self.orthogonal_levels > 1 else (func.bounds.lb + func.bounds.ub) / 2\n\n                # Evaluate orthogonal candidates\n                orthogonal_fitness = np.array([func(x) for x in orthogonal_candidates])\n                fevals += num_orthogonal_samples\n\n                # Select the best from orthogonal candidates and current trial vector\n                best_orthogonal_idx = np.argmin(orthogonal_fitness)\n                if orthogonal_fitness[best_orthogonal_idx] < func(x_trial):\n                    f_trial = orthogonal_fitness[best_orthogonal_idx]\n                    x_trial = orthogonal_candidates[best_orthogonal_idx]\n                else:\n                    f_trial = func(x_trial)\n                    fevals += 1 #Added the missing func evaluation\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n\n                if fevals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["09f69ee2-0b24-4fee-b82a-77cecc5e9f18"], "operator": null, "metadata": {}}
{"id": "f0fd3a9b-cff3-46bb-8551-083122eb348c", "fitness": 0.0, "name": "SymbioticOrganismsSearch", "description": "Bio-inspired optimization using a symbiotic organisms search with adaptive population sizes and energy transfer mechanisms.", "code": "import numpy as np\n\nclass SymbioticOrganismsSearch:\n    def __init__(self, budget=10000, dim=10, population_size=50, mutualism_benefit=0.8, commensalism_benefit=0.2, parasitism_benefit=0.1, adaptation_rate=0.05):\n        \"\"\"\n        Symbiotic Organisms Search algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            population_size (int): The initial size of the population.\n            mutualism_benefit (float): Benefit factor for mutualism phase.\n            commensalism_benefit (float): Benefit factor for commensalism phase.\n            parasitism_benefit (float): Benefit factor for parasitism phase.\n            adaptation_rate (float): Rate at which population size adapts.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.mutualism_benefit = mutualism_benefit\n        self.commensalism_benefit = commensalism_benefit\n        self.parasitism_benefit = parasitism_benefit\n        self.adaptation_rate = adaptation_rate\n        self.population = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.fevals = 0\n\n    def initialize_population(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.fevals += self.population_size\n        return population, fitness\n\n    def update_best(self, population, fitness):\n        best_idx = np.argmin(fitness)\n        if fitness[best_idx] < self.best_fitness:\n            self.best_fitness = fitness[best_idx]\n            self.best_position = population[best_idx].copy()\n\n    def mutualism_phase(self, func):\n        for i in range(self.population_size):\n            partner_idx = np.random.randint(0, self.population_size)\n            while partner_idx == i:\n                partner_idx = np.random.randint(0, self.population_size)\n            \n            organism_i = self.population[i]\n            organism_partner = self.population[partner_idx]\n\n            bf_i = np.random.uniform(0, self.mutualism_benefit)\n            bf_partner = np.random.uniform(0, self.mutualism_benefit)\n            \n            mean_vector = (organism_i + organism_partner) / 2\n            \n            new_organism_i = organism_i + np.random.rand(self.dim) * (self.best_position - bf_i * mean_vector)\n            new_organism_partner = organism_partner + np.random.rand(self.dim) * (self.best_position - bf_partner * mean_vector)\n            \n            new_organism_i = np.clip(new_organism_i, func.bounds.lb, func.bounds.ub)\n            new_organism_partner = np.clip(new_organism_partner, func.bounds.lb, func.bounds.ub)\n\n            fitness_i = func(new_organism_i)\n            self.fevals += 1\n            fitness_partner = func(new_organism_partner)\n            self.fevals += 1\n\n            if fitness_i < self.fitness[i]:\n                self.population[i] = new_organism_i\n                self.fitness[i] = fitness_i\n            \n            if fitness_partner < self.fitness[partner_idx]:\n                self.population[partner_idx] = new_organism_partner\n                self.fitness[partner_idx] = fitness_partner\n\n    def commensalism_phase(self, func):\n        for i in range(self.population_size):\n            partner_idx = np.random.randint(0, self.population_size)\n            while partner_idx == i:\n                partner_idx = np.random.randint(0, self.population_size)\n\n            organism_i = self.population[i]\n            organism_partner = self.population[partner_idx]\n            \n            new_organism = organism_i + np.random.rand(self.dim) * (organism_partner - organism_i)\n            new_organism = np.clip(new_organism, func.bounds.lb, func.bounds.ub)\n\n            fitness = func(new_organism)\n            self.fevals += 1\n            if fitness < self.fitness[i]:\n                self.population[i] = new_organism\n                self.fitness[i] = fitness\n\n    def parasitism_phase(self, func):\n        for i in range(self.population_size):\n            host_idx = np.random.randint(0, self.population_size)\n            while host_idx == i:\n                host_idx = np.random.randint(0, self.population_size)\n\n            parasite = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            parasite_fitness = func(parasite)\n            self.fevals += 1\n            \n            if parasite_fitness < self.fitness[host_idx]:\n                self.population[host_idx] = parasite\n                self.fitness[host_idx] = parasite_fitness\n\n    def adapt_population_size(self):\n        if np.random.rand() < self.adaptation_rate:\n            # Adjust population size based on performance\n            if self.fitness.std() > 0.1:  # High diversity, increase population\n                self.population_size = min(self.population_size + 5, 100)\n            else:  # Low diversity, decrease population\n                self.population_size = max(self.population_size - 5, 10)\n\n            # Re-initialize population (simplified - can be improved)\n            #self.population = np.random.uniform(self.bounds.lb, self.bounds.ub, size=(self.population_size, self.dim))\n            #self.fitness = np.array([self.func(x) for x in self.population])\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Symbiotic Organisms Search.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.population, self.fitness = self.initialize_population(func)\n        self.update_best(self.population, self.fitness)\n\n        while self.fevals < self.budget:\n            self.mutualism_phase(func)\n            self.commensalism_phase(func)\n            self.parasitism_phase(func)\n            self.update_best(self.population, self.fitness)\n            #self.adapt_population_size()  # Consider re-enabling with caution\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 6, "feedback": "The algorithm SymbioticOrganismsSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2ad1d82e-6426-4804-9c8f-88a127cf94ed"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "266472bb-7447-418f-b2c7-9d31e7f30596", "fitness": 0.0, "name": "CooperativeSwarm", "description": "Cooperative Swarm with adaptive neighborhood size based on swarm diversity and stagnation detection for improved exploration and exploitation.", "code": "import numpy as np\n\nclass CooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, velocity_clamp_factor=0.2, initial_neighborhood_size=5, neighborhood_adaption_rate=0.1, stagnation_threshold=1e-5, stagnation_iterations=50):\n        \"\"\"\n        Cooperative Swarm Optimization with adaptive velocity clamping and neighborhood-based learning.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            swarm_size (int): The number of particles in the swarm.\n            inertia (float): Inertia weight for the particle's previous velocity.\n            cognitive_coeff (float): Cognitive acceleration coefficient.\n            social_coeff (float): Social acceleration coefficient.\n            velocity_clamp_factor (float): Factor for adaptive velocity clamping based on search space.\n            initial_neighborhood_size (int): Initial size of the neighborhood for social learning.\n            neighborhood_adaption_rate (float): Rate at which the neighborhood size is adapted.\n            stagnation_threshold (float): Threshold for detecting stagnation in global best fitness.\n            stagnation_iterations (int): Number of iterations to wait before declaring stagnation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp_factor = velocity_clamp_factor\n        self.neighborhood_size = initial_neighborhood_size\n        self.initial_neighborhood_size = initial_neighborhood_size\n        self.neighborhood_adaption_rate = neighborhood_adaption_rate\n        self.swarm = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_iterations = stagnation_iterations\n        self.stagnation_counter = 0\n        self.previous_global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Cooperative Swarm Optimization.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.swarm_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.swarm])\n        self.personal_best_positions = np.copy(self.swarm)\n        self.personal_best_fitness = np.copy(self.fitness)\n        self.global_best_position = self.swarm[np.argmin(self.fitness)]\n        self.global_best_fitness = np.min(self.fitness)\n        self.previous_global_best_fitness = self.global_best_fitness\n\n        fevals = self.swarm_size\n\n        while fevals < self.budget:\n            # Calculate swarm diversity (variance of particle positions)\n            diversity = np.mean(np.var(self.swarm, axis=0))\n\n            # Adaptive neighborhood size adjustment based on diversity\n            if diversity < 0.01:  # Tunable threshold\n                self.neighborhood_size = min(self.swarm_size, int(self.neighborhood_size * (1 + self.neighborhood_adaption_rate))) #Increase neighborhood size if diversity is low\n            else:\n                self.neighborhood_size = max(1, int(self.neighborhood_size * (1 - self.neighborhood_adaption_rate))) #Decrease if diversity is high\n\n            for i in range(self.swarm_size):\n                # Adaptive velocity clamping\n                v_max = self.velocity_clamp_factor * (func.bounds.ub - func.bounds.lb)\n                self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n                # Neighborhood selection (k-nearest neighbors based on Euclidean distance)\n                distances = np.linalg.norm(self.swarm - self.swarm[i], axis=1)\n                neighborhood_indices = np.argsort(distances)[:self.neighborhood_size]\n\n                # Cooperative Learning: Find best neighbor based on fitness and distance.\n                best_neighbor_idx = neighborhood_indices[0]\n                best_neighbor_fitness = self.personal_best_fitness[neighborhood_indices[0]]\n                for idx in neighborhood_indices[1:]:\n                    if self.personal_best_fitness[idx] < best_neighbor_fitness:\n                        best_neighbor_fitness = self.personal_best_fitness[idx]\n                        best_neighbor_idx = idx\n                    elif self.personal_best_fitness[idx] == best_neighbor_fitness and distances[idx] < distances[best_neighbor_idx]:\n                        # Break ties by preferring closer particles\n                        best_neighbor_idx = idx\n\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = (self.inertia * self.velocities[i]\n                                     + self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.swarm[i])\n                                     + self.social_coeff * r2 * (self.personal_best_positions[best_neighbor_idx] - self.swarm[i]))\n\n                # Update position\n                new_position = self.swarm[i] + self.velocities[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                new_fitness = func(new_position)\n                fevals += 1\n\n                # Update personal best\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position\n\n                # Update global best\n                if new_fitness < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness\n                    self.global_best_position = new_position\n                    self.stagnation_counter = 0 #Reset stagnation counter\n                else:\n                    self.stagnation_counter +=1\n\n\n                self.swarm[i] = new_position #Update swarm\n\n                if fevals >= self.budget:\n                    break\n\n            # Stagnation check and swarm reset\n            if self.stagnation_counter > self.stagnation_iterations:\n                # Reset a portion of the swarm to random locations\n                num_reset = int(0.2 * self.swarm_size)  # Reset 20% of the swarm\n                reset_indices = np.random.choice(self.swarm_size, num_reset, replace=False)\n                self.swarm[reset_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reset, self.dim))\n                self.velocities[reset_indices] = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(num_reset, self.dim))\n                self.fitness[reset_indices] = np.array([func(x) for x in self.swarm[reset_indices]])\n                for idx in reset_indices:\n                    self.personal_best_fitness[idx] = self.fitness[idx]\n                    self.personal_best_positions[idx] = self.swarm[idx]\n                \n                self.stagnation_counter = 0  # Reset stagnation counter\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm CooperativeSwarm scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b73699bf-7744-48de-a28b-ad8ed2bb5cd3"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "0daf22fa-1127-4d25-b4a4-14baec6ee025", "fitness": 0.0, "name": "EnhancedSelfAdaptiveDE", "description": "Enhanced self-adaptive DE with orthogonal learning, dynamically adjusted population size, and adaptive archive management.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_initial=50, F_initial=0.5, Cr_initial=0.9, archive_size=10, stagnation_limit=500, p_selection=0.5, orthogonal_learning_rate=0.1):\n        \"\"\"\n        Enhanced Differential Evolution with orthogonal learning, dynamic population size adjustment, and adaptive archive management.\n        Uses a weighted historical archive and dynamic F/Cr scaling, and orthogonal design for enhanced exploration.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size_initial (int): The initial population size.\n            F_initial (float): The initial scaling factor for differential variation.\n            Cr_initial (float): The initial crossover rate.\n            archive_size (int): Size of the archive for storing successful F and Cr values.\n            stagnation_limit (int): Number of iterations without improvement before triggering a restart.\n            p_selection (float): Probability of selecting F/Cr from the archive.\n            orthogonal_learning_rate (float): Probability of applying orthogonal learning.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_initial = pop_size_initial\n        self.pop_size = pop_size_initial  # Initialize with initial size\n        self.F = F_initial\n        self.Cr = Cr_initial\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.archive_F = []\n        self.archive_Cr = []\n        self.archive_size = archive_size\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.strategy_success = np.zeros(3)  # Success count for each strategy\n        self.strategy_selection_prob = np.array([1/3, 1/3, 1/3]) # Initial probabilities\n        self.p_selection = p_selection # Probability of using archive values\n        self.archive_weights = []  # Weights for historical F/Cr values\n        self.orthogonal_learning_rate = orthogonal_learning_rate #Probability of applying orthogonal learning\n        self.min_pop_size = 10  # Minimum population size\n        self.max_pop_size = 100 # Maximum population size\n        self.pop_size_adapt_freq = 10 # Frequency of population size adaptation\n\n    def orthogonal_design(self, x, num_levels=3):\n        \"\"\"\n        Generates a set of points based on orthogonal design around a given point x.\n        \"\"\"\n        design = []\n        for i in range(self.dim):\n            levels = np.linspace(x[i] - 0.5, x[i] + 0.5, num_levels) #explore around the current solution\n            design.append(levels)\n        \n        # Create a grid of all combinations\n        grid = np.array(np.meshgrid(*design)).T.reshape(-1, self.dim)\n\n        # Filter out-of-bounds points\n        grid = grid[np.all((grid >= -5.0) & (grid <= 5.0), axis=1)]\n        return grid\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with enhanced self-adaptive strategy selection, diversity maintenance, and stagnation handling.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n        last_improvement = 0\n\n        iter_count = 0 #Iteration counter\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Strategy selection based on success probabilities\n                strategy_idx = np.random.choice(3, p=self.strategy_selection_prob)\n\n                # Adaptation of F and Cr (using archive or default values)\n                if np.random.rand() < self.p_selection and len(self.archive_F) > 0:\n                    # Weighted selection from the archive\n                    weights = np.array(self.archive_weights) / np.sum(self.archive_weights) if np.sum(self.archive_weights) > 0 else np.ones(len(self.archive_weights)) / len(self.archive_weights)\n                    idx = np.random.choice(len(self.archive_F), p=weights)\n                    self.F = self.archive_F[idx]\n                    self.Cr = self.archive_Cr[idx]\n                else:\n                    self.F = 0.5 + 0.3 * np.random.randn() # Default F with some noise\n                    self.Cr = 0.9 + 0.1 * np.random.randn()  # Default Cr with some noise\n                \n                self.F = np.clip(self.F, 0.1, 1.0)  # Ensure F is within reasonable bounds\n                self.Cr = np.clip(self.Cr, 0.1, 1.0) # Ensure Cr is within reasonable bounds\n\n                # Mutation Strategies\n                if strategy_idx == 0:\n                    # Current-to-best/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F * (self.pop[self.best_idx] - self.pop[i]) + self.F * (x_r1 - x_r2)\n                elif strategy_idx == 1:\n                    # Rand/1\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[indices]\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                else:\n                    # Current/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F * (x_r1 - x_r2)\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Orthogonal Learning\n                if np.random.rand() < self.orthogonal_learning_rate:\n                    orthogonal_points = self.orthogonal_design(x_trial)\n                    if len(orthogonal_points) > 0: #Check if there are valid points\n                        fitness_values = [func(point) for point in orthogonal_points]\n                        fevals += len(orthogonal_points)\n                        best_orthogonal_idx = np.argmin(fitness_values)\n                        if fitness_values[best_orthogonal_idx] < func(x_trial):\n                            x_trial = orthogonal_points[best_orthogonal_idx]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    # Improvement\n                    delta_fitness = self.fitness[i] - f_trial  # Calculate fitness improvement\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n                    self.strategy_success[strategy_idx] += 1 #Increase strategy success count\n\n                    # Archive successful F and Cr with fitness improvement weight\n                    self.archive_F.append(self.F)\n                    self.archive_Cr.append(self.Cr)\n                    self.archive_weights.append(delta_fitness) # Weight based on fitness improvement\n\n                    if len(self.archive_F) > self.archive_size:\n                        self.archive_F.pop(0)\n                        self.archive_Cr.pop(0)\n                        self.archive_weights.pop(0)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n                        last_improvement = fevals\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increase stagnation counter\n\n\n                if fevals >= self.budget:\n                    break\n\n            # Update strategy selection probabilities based on success\n            total_success = np.sum(self.strategy_success)\n            if total_success > 0:\n                self.strategy_selection_prob = self.strategy_success / total_success\n            else:\n                self.strategy_selection_prob = np.array([1/3, 1/3, 1/3]) # Reset if no success\n\n            self.strategy_success[:] = 0 #Reset success counters\n            \n            iter_count += 1\n            \n            # Population size adaptation\n            if iter_count % self.pop_size_adapt_freq == 0:\n                if fevals - last_improvement > self.stagnation_limit / 2:\n                    self.pop_size = max(self.min_pop_size, int(self.pop_size * 0.9))  # Reduce population size\n                else:\n                    self.pop_size = min(self.max_pop_size, int(self.pop_size * 1.1)) #Increase population size\n                \n                #Ensure population size doesn't exceed budget constraints\n                self.pop_size = min(self.pop_size, int((self.budget - fevals) / 2))\n\n                # Regenerate the population with the new size\n                if self.pop_size != len(self.pop):\n                    self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    self.fitness = np.array([func(x) for x in self.pop])\n                    fevals += self.pop_size\n                    self.best_idx = np.argmin(self.fitness)\n                    self.f_opt = self.fitness[self.best_idx]\n                    self.x_opt = self.pop[self.best_idx]\n            # Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_limit:\n                # Option 1: Restart with new random population\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n                fevals += self.pop_size\n                self.stagnation_counter = 0\n                self.archive_F = []  # Clear archive upon restart\n                self.archive_Cr = []\n                self.archive_weights = []\n                # Resetting success history might also be a good idea here.\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedSelfAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["09f69ee2-0b24-4fee-b82a-77cecc5e9f18"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "5ea327e1-6f04-4714-9b81-f8bffa3d088f", "fitness": 0.0, "name": "EnhancedSelfAdaptiveDE", "description": "Enhanced Self-Adaptive DE with orthogonal learning, adaptive population size, and periodic archive refreshment for improved exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_min=20, pop_size_max=100, F_initial=0.5, Cr_initial=0.9, archive_size=10, stagnation_limit=500, p_selection=0.5, orthogonal_learning_rate=0.1, archive_refresh_interval=500):\n        \"\"\"\n        Enhanced Differential Evolution with self-adaptive strategy selection, diversity maintenance, stagnation handling,\n        orthogonal learning, adaptive population size, and periodic archive refreshment.\n        Uses a weighted historical archive and dynamic F/Cr scaling.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size_min (int): The minimum population size.\n            pop_size_max (int): The maximum population size.\n            F_initial (float): The initial scaling factor for differential variation.\n            Cr_initial (float): The initial crossover rate.\n            archive_size (int): Size of the archive for storing successful F and Cr values.\n            stagnation_limit (int): Number of iterations without improvement before triggering a restart.\n            p_selection (float): Probability of selecting F/Cr from the archive.\n            orthogonal_learning_rate (float): Probability of applying orthogonal learning.\n            archive_refresh_interval (int): Interval (in function evaluations) to refresh the archive.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max  # Start with max population and adapt\n        self.F = F_initial\n        self.Cr = Cr_initial\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.archive_F = []\n        self.archive_Cr = []\n        self.archive_size = archive_size\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.strategy_success = np.zeros(3)  # Success count for each strategy\n        self.strategy_selection_prob = np.array([1/3, 1/3, 1/3]) # Initial probabilities\n        self.p_selection = p_selection # Probability of using archive values\n        self.archive_weights = []  # Weights for historical F/Cr values\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n        self.archive_refresh_interval = archive_refresh_interval\n        self.last_archive_refresh = 0\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with enhanced self-adaptive strategy selection,\n        diversity maintenance, stagnation handling, orthogonal learning, adaptive population size, and periodic archive refreshment.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n        last_improvement = 0\n\n        while fevals < self.budget:\n            # Adaptive population size adjustment based on stagnation\n            if self.stagnation_counter > self.stagnation_limit / 2:\n                self.pop_size = max(self.pop_size_min, int(self.pop_size * 0.9))  # Reduce population size\n            else:\n                self.pop_size = min(self.pop_size_max, int(self.pop_size * 1.05))  # Increase population size slowly if improving\n\n            if self.pop_size != self.pop.shape[0]:\n                # Resize population if needed.  Handle edge cases.\n                if self.pop_size > self.pop.shape[0]:\n                    # Add new random individuals\n                    new_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - self.pop.shape[0], self.dim))\n                    new_fitness = np.array([func(x) for x in new_pop])\n                    self.pop = np.vstack((self.pop, new_pop))\n                    self.fitness = np.concatenate((self.fitness, new_fitness))\n                    fevals += new_pop.shape[0]\n                else:\n                    # Randomly remove individuals\n                    indices_to_remove = np.random.choice(self.pop.shape[0], self.pop.shape[0] - self.pop_size, replace=False)\n                    mask = np.ones(self.pop.shape[0], dtype=bool)\n                    mask[indices_to_remove] = False\n                    self.pop = self.pop[mask]\n                    self.fitness = self.fitness[mask]\n                self.best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n\n            for i in range(self.pop_size):\n                # Strategy selection based on success probabilities\n                strategy_idx = np.random.choice(3, p=self.strategy_selection_prob)\n\n                # Adaptation of F and Cr (using archive or default values)\n                if np.random.rand() < self.p_selection and len(self.archive_F) > 0:\n                    # Weighted selection from the archive\n                    weights = np.array(self.archive_weights) / np.sum(self.archive_weights) if np.sum(self.archive_weights) > 0 else np.ones(len(self.archive_weights)) / len(self.archive_weights)\n                    idx = np.random.choice(len(self.archive_F), p=weights)\n                    self.F = self.archive_F[idx]\n                    self.Cr = self.archive_Cr[idx]\n                else:\n                    self.F = 0.5 + 0.3 * np.random.randn() # Default F with some noise\n                    self.Cr = 0.9 + 0.1 * np.random.randn()  # Default Cr with some noise\n                \n                self.F = np.clip(self.F, 0.1, 1.0)  # Ensure F is within reasonable bounds\n                self.Cr = np.clip(self.Cr, 0.1, 1.0) # Ensure Cr is within reasonable bounds\n\n                # Mutation Strategies\n                if strategy_idx == 0:\n                    # Current-to-best/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F * (self.pop[self.best_idx] - self.pop[i]) + self.F * (x_r1 - x_r2)\n                elif strategy_idx == 1:\n                    # Rand/1\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[indices]\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                else:\n                    # Current/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F * (x_r1 - x_r2)\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Orthogonal Learning\n                if np.random.rand() < self.orthogonal_learning_rate:\n                    # Select two random individuals to create an orthogonal array\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n\n                    # Create an orthogonal array (a simple 2-level OA)\n                    oa = np.array([[x_trial[j], x_r1[j], x_r2[j]] for j in range(self.dim)])\n\n                    # Evaluate all combinations (only 4 combinations for 2 factors at 2 levels)\n                    level_fitness = []\n                    for j in range(self.dim):\n                      temp_x = np.copy(x_trial)\n                      temp_x[j] = x_r1[j]\n                      level_fitness.append(func(temp_x))\n                      fevals += 1\n\n                      temp_x = np.copy(x_trial)\n                      temp_x[j] = x_r2[j]\n                      level_fitness.append(func(temp_x))\n                      fevals += 1\n\n                    # Find the best level for each dimension\n                    for j in range(self.dim):\n                      if level_fitness[2*j] < func(x_trial):\n                        x_trial[j] = x_r1[j]\n                      elif level_fitness[2*j+1] < func(x_trial):\n                        x_trial[j] = x_r2[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    # Improvement\n                    delta_fitness = self.fitness[i] - f_trial  # Calculate fitness improvement\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n                    self.strategy_success[strategy_idx] += 1 #Increase strategy success count\n\n                    # Archive successful F and Cr with fitness improvement weight\n                    self.archive_F.append(self.F)\n                    self.archive_Cr.append(self.Cr)\n                    self.archive_weights.append(delta_fitness) # Weight based on fitness improvement\n\n                    if len(self.archive_F) > self.archive_size:\n                        self.archive_F.pop(0)\n                        self.archive_Cr.pop(0)\n                        self.archive_weights.pop(0)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n                        last_improvement = fevals\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increase stagnation counter\n\n\n                if fevals >= self.budget:\n                    break\n\n            # Update strategy selection probabilities based on success\n            total_success = np.sum(self.strategy_success)\n            if total_success > 0:\n                self.strategy_selection_prob = self.strategy_success / total_success\n            else:\n                self.strategy_selection_prob = np.array([1/3, 1/3, 1/3]) # Reset if no success\n\n            self.strategy_success[:] = 0 #Reset success counters\n\n            # Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_limit:\n                # Option 1: Restart with new random population\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n                fevals += self.pop_size\n                self.stagnation_counter = 0\n                self.archive_F = []  # Clear archive upon restart\n                self.archive_Cr = []\n                self.archive_weights = []\n                # Resetting success history might also be a good idea here.\n            \n            # Archive Refresh\n            if fevals - self.last_archive_refresh > self.archive_refresh_interval:\n                self.archive_F = []\n                self.archive_Cr = []\n                self.archive_weights = []\n                self.last_archive_refresh = fevals\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedSelfAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["09f69ee2-0b24-4fee-b82a-77cecc5e9f18"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "337cb29e-2711-433b-bbe4-60f015beb610", "fitness": 0.47968854243477554, "name": "HybridPSOSA", "description": "Hybrid Particle Swarm Optimization with Simulated Annealing for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, sa_initial_temp=1.0, sa_cooling_rate=0.95):\n        \"\"\"\n        Hybrid Particle Swarm Optimization with Simulated Annealing.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            swarm_size (int): The number of particles in the swarm.\n            inertia (float): Inertia weight for the particle's previous velocity.\n            cognitive_coeff (float): Cognitive acceleration coefficient.\n            social_coeff (float): Social acceleration coefficient.\n            sa_initial_temp (float): Initial temperature for Simulated Annealing.\n            sa_cooling_rate (float): Cooling rate for Simulated Annealing.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.sa_initial_temp = sa_initial_temp\n        self.sa_cooling_rate = sa_cooling_rate\n        self.swarm = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.temperature = sa_initial_temp\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Hybrid Particle Swarm Optimization with Simulated Annealing.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.swarm_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.swarm])\n        self.personal_best_positions = np.copy(self.swarm)\n        self.personal_best_fitness = np.copy(self.fitness)\n        self.global_best_position = self.swarm[np.argmin(self.fitness)]\n        self.global_best_fitness = np.min(self.fitness)\n\n        fevals = self.swarm_size\n\n        while fevals < self.budget:\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = (self.inertia * self.velocities[i]\n                                     + self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.swarm[i])\n                                     + self.social_coeff * r2 * (self.global_best_position - self.swarm[i]))\n\n                # Update position\n                new_position = self.swarm[i] + self.velocities[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                new_fitness = func(new_position)\n                fevals += 1\n\n                # Simulated Annealing acceptance criterion\n                delta_e = new_fitness - self.fitness[i]\n                if delta_e < 0:\n                    # Accept if better\n                    self.swarm[i] = new_position\n                    self.fitness[i] = new_fitness\n\n                    # Update personal best\n                    if new_fitness < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = new_fitness\n                        self.personal_best_positions[i] = new_position\n\n                    # Update global best\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position\n                else:\n                    #Accept with a probability\n                    acceptance_probability = np.exp(-delta_e / self.temperature)\n                    if np.random.rand() < acceptance_probability:\n                        self.swarm[i] = new_position\n                        self.fitness[i] = new_fitness\n\n                if fevals >= self.budget:\n                    break\n            \n            # Cool the temperature\n            self.temperature *= self.sa_cooling_rate\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSOSA scored 0.480 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b73699bf-7744-48de-a28b-ad8ed2bb5cd3"], "operator": null, "metadata": {"aucs": [0.11159545072372967, 0.2736331991238907, 0.7228965416164794, 0.9081436398315764, 0.31205052162108227, 0.8273077478456978, 0.33758888293282385, 0.22685951968936702, 0.7921693294448431, 0.2272452063222472, 0.2822617953393175, 0.998255673946044, 0.23746929123689975, 0.26315886872743854, 0.647235363859184, 0.8040908690663824, 0.5796470510704899, 0.3769639899416457, 0.1729903973957989, 0.4922075089605752]}}
{"id": "fa2a18db-59a3-49d9-8ba5-33355bb91ae9", "fitness": 0.37840230660674945, "name": "AdaptiveCooperativeSwarm", "description": "Cooperative Swarm Optimization with adaptive parameter control, dynamic sub-swarm merging, and a self-regulating exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=10, \n                 inertia_start=0.9, inertia_end=0.4, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, merge_threshold=0.1):\n        \"\"\"\n        Adaptive Cooperative Swarm Optimization algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            num_swarms (int): The number of sub-swarms.\n            swarm_size (int): The size of each sub-swarm.\n            inertia_start (float): Initial inertia weight.\n            inertia_end (float): Final inertia weight.\n            cognitive_coeff (float): Cognitive coefficient.\n            social_coeff (float): Social coefficient.\n            exploration_rate (float): Probability of exploration.\n            merge_threshold (float): Threshold for merging swarms.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_start = inertia_start\n        self.inertia_end = inertia_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.merge_threshold = merge_threshold\n        self.swarms = []\n        self.personal_best_positions = []\n        self.personal_best_fitness = []\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.swarm_ages = [0] * num_swarms # Track swarm age for parameter adaptation\n\n    def initialize_swarm(self, func):\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.fevals += self.swarm_size\n        return swarm, fitness\n\n    def update_personal_best(self, swarm, fitness):\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n        return personal_best_positions, personal_best_fitness\n\n    def get_inertia(self):\n        \"\"\"Linearly decrease inertia from start to end.\"\"\"\n        return self.inertia_start + (self.inertia_end - self.inertia_start) * (self.fevals / self.budget)\n\n    def should_merge(self, i, j):\n        \"\"\"Check if two swarms should be merged based on distance between their best positions.\"\"\"\n        best_i = self.personal_best_positions[i][np.argmin(self.personal_best_fitness[i])]\n        best_j = self.personal_best_positions[j][np.argmin(self.personal_best_fitness[j])]\n        distance = np.linalg.norm(best_i - best_j)\n        return distance < self.merge_threshold\n\n    def merge_swarms(self, i, j):\n        \"\"\"Merge two swarms into one.\"\"\"\n        combined_swarm = np.concatenate([self.swarms[i], self.swarms[j]])\n        combined_fitness = np.concatenate([self.personal_best_fitness[i], self.personal_best_fitness[j]])\n\n        # Select the best particles to form the new swarm\n        num_particles = min(self.swarm_size, len(combined_swarm))\n        best_indices = np.argsort(combined_fitness)[:num_particles]\n\n        new_swarm = combined_swarm[best_indices]\n        new_fitness = combined_fitness[best_indices]\n\n        new_personal_best_positions, new_personal_best_fitness = self.update_personal_best(new_swarm, new_fitness)\n\n        self.swarms[i] = new_swarm\n        self.personal_best_positions[i] = new_personal_best_positions\n        self.personal_best_fitness[i] = new_personal_best_fitness\n        self.swarm_ages[i] = 0 # Reset age\n        self.swarms.pop(j)\n        self.personal_best_positions.pop(j)\n        self.personal_best_fitness.pop(j)\n        self.swarm_ages.pop(j)\n        self.num_swarms -= 1\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Adaptive Cooperative Swarm Optimization.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        # Initialize swarms\n        for _ in range(self.num_swarms):\n            swarm, fitness = self.initialize_swarm(func)\n            self.swarms.append(swarm)\n            personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n            self.personal_best_positions.append(personal_best_positions)\n            self.personal_best_fitness.append(personal_best_fitness)\n\n            # Update global best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.global_best_fitness:\n                self.global_best_fitness = fitness[best_idx]\n                self.global_best_position = swarm[best_idx].copy()\n\n        velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n\n        while self.fevals < self.budget:\n            inertia = self.get_inertia()\n\n            # Check and merge swarms\n            if self.num_swarms > 1:\n                for i in range(self.num_swarms):\n                    for j in range(i + 1, self.num_swarms):\n                        if self.should_merge(i, j):\n                            self.merge_swarms(i, j)\n                            break  # Only merge one pair per iteration\n                    if self.num_swarms <= 1:\n                        break\n\n            for i in range(self.num_swarms):\n                self.swarm_ages[i] += 1\n                swarm = self.swarms[i]\n                personal_best_positions = self.personal_best_positions[i]\n                personal_best_fitness = self.personal_best_fitness[i]\n                velocity = velocities[i]\n\n                # Update velocities and positions\n                r1 = np.random.rand(self.swarm_size, self.dim)\n                r2 = np.random.rand(self.swarm_size, self.dim)\n\n                # Cooperative component: Influence from other swarms' best\n                cooperative_influence = np.zeros((self.swarm_size, self.dim))\n                for j in range(self.num_swarms):\n                    if i != j:\n                        best_idx_other = np.argmin(self.personal_best_fitness[j])\n                        cooperative_influence += (self.personal_best_positions[j][best_idx_other] - swarm)\n                if self.num_swarms > 1:\n                    cooperative_influence /= (self.num_swarms - 1) # Average influence\n\n                velocity = (inertia * velocity\n                            + self.cognitive_coeff * r1 * (personal_best_positions - swarm)\n                            + self.social_coeff * r2 * (self.global_best_position - swarm)\n                            + 0.1 * cooperative_influence) # Add cooperative influence with a small weight\n\n                new_swarm = swarm + velocity\n\n                # Exploration: Introduce random search with probability exploration_rate\n                for k in range(self.swarm_size):\n                    if np.random.rand() < self.exploration_rate:\n                        new_swarm[k] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Explore\n\n                new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n                new_fitness = np.array([func(x) for x in new_swarm])\n                self.fevals += self.swarm_size\n\n                # Update personal best\n                improvement = new_fitness < personal_best_fitness\n                personal_best_positions[improvement] = new_swarm[improvement].copy()\n                personal_best_fitness[improvement] = new_fitness[improvement].copy()\n\n                self.swarms[i] = new_swarm\n                self.personal_best_positions[i] = personal_best_positions\n                self.personal_best_fitness[i] = personal_best_fitness\n                velocities[i] = velocity\n\n                # Update global best\n                best_idx = np.argmin(personal_best_fitness)\n                if personal_best_fitness[best_idx] < self.global_best_fitness:\n                    self.global_best_fitness = personal_best_fitness[best_idx]\n                    self.global_best_position = personal_best_positions[best_idx].copy()\n                \n                if self.fevals >= self.budget:\n                    break\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveCooperativeSwarm scored 0.378 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2ad1d82e-6426-4804-9c8f-88a127cf94ed"], "operator": null, "metadata": {"aucs": [0.16311008104486557, 0.3116936573066287, 0.39236840463821065, 0.46130029844097076, 0.2699092756138677, 0.3077855436275576, 0.28578991393131237, 0.3154091461404338, 0.34256240957035244, 0.2045437877793318, 0.41640379962085694, 0.9984328889898867, 0.30079646959594597, 0.3261556086169015, 0.6440784222347065, 0.335837674352623, 0.34158752970170025, 0.47297472675800667, 0.19538656224941864, 0.48191993192141125]}}
{"id": "077c669e-20b2-4e2c-9d1c-6c2f58c62a80", "fitness": 0.3966427063531346, "name": "CooperativeSwarm", "description": "Cooperative Swarm Optimization with adaptive parameter control, dynamic sub-swarm communication, and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass CooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=10, inertia_range=(0.4, 0.9),\n                 cognitive_coeff_range=(1.5, 2.0), social_coeff_range=(1.5, 2.0), exploration_pressure=0.1,\n                 restart_trigger=0.05):\n        \"\"\"\n        Cooperative Swarm Optimization algorithm with adaptive parameters, dynamic sub-swarm communication and restart mechanism.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            num_swarms (int): The number of sub-swarms.\n            swarm_size (int): The size of each sub-swarm.\n            inertia_range (tuple): Range for inertia weight adaptation.\n            cognitive_coeff_range (tuple): Range for cognitive coefficient adaptation.\n            social_coeff_range (tuple): Range for social coefficient adaptation.\n            exploration_pressure (float): Probability of exploring a new region instead of exploiting.\n            restart_trigger (float): Trigger for swarm restart based on stagnation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_range = inertia_range\n        self.cognitive_coeff_range = cognitive_coeff_range\n        self.social_coeff_range = social_coeff_range\n        self.exploration_pressure = exploration_pressure\n        self.restart_trigger = restart_trigger\n        self.swarms = []\n        self.personal_best_positions = []\n        self.personal_best_fitness = []\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.stagnation_counter = 0\n        self.max_stagnation = 100 #arbitrary value, adjust based on the problem\n\n    def initialize_swarm(self, func):\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.fevals += self.swarm_size\n        return swarm, fitness\n\n    def update_personal_best(self, swarm, fitness):\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n        return personal_best_positions, personal_best_fitness\n\n    def adapt_parameters(self):\n        \"\"\"Adapt inertia, cognitive, and social coefficients.\"\"\"\n        self.inertia = np.random.uniform(self.inertia_range[0], self.inertia_range[1])\n        self.cognitive_coeff = np.random.uniform(self.cognitive_coeff_range[0], self.cognitive_coeff_range[1])\n        self.social_coeff = np.random.uniform(self.social_coeff_range[0], self.social_coeff_range[1])\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Cooperative Swarm Optimization.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        # Initialize swarms\n        for _ in range(self.num_swarms):\n            swarm, fitness = self.initialize_swarm(func)\n            self.swarms.append(swarm)\n            personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n            self.personal_best_positions.append(personal_best_positions)\n            self.personal_best_fitness.append(personal_best_fitness)\n\n            # Update global best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.global_best_fitness:\n                self.global_best_fitness = fitness[best_idx]\n                self.global_best_position = swarm[best_idx].copy()\n                self.stagnation_counter = 0 #reset counter if we improve\n\n        velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n\n        while self.fevals < self.budget:\n            old_global_best_fitness = self.global_best_fitness  # Store the previous global best\n\n            for i in range(self.num_swarms):\n                swarm = self.swarms[i]\n                personal_best_positions = self.personal_best_positions[i]\n                personal_best_fitness = self.personal_best_fitness[i]\n                velocity = velocities[i]\n\n                # Update velocities and positions\n                r1 = np.random.rand(self.swarm_size, self.dim)\n                r2 = np.random.rand(self.swarm_size, self.dim)\n\n                # Cooperative component: Influence from other swarms' best\n                cooperative_influence = np.zeros((self.swarm_size, self.dim))\n                num_contributing_swarms = 0\n                for j in range(self.num_swarms):\n                    if i != j:\n                        best_idx_other = np.argmin(self.personal_best_fitness[j])\n                        # Dynamic communication: only influence from better swarms\n                        if self.personal_best_fitness[j][best_idx_other] < np.min(personal_best_fitness):\n                            cooperative_influence += (self.personal_best_positions[j][best_idx_other] - swarm)\n                            num_contributing_swarms += 1\n                if num_contributing_swarms > 0:\n                    cooperative_influence /= num_contributing_swarms # Average influence\n\n                # Adapt parameters\n                self.adapt_parameters()\n\n                velocity = (self.inertia * velocity\n                            + self.cognitive_coeff * r1 * (personal_best_positions - swarm)\n                            + self.social_coeff * r2 * (self.global_best_position - swarm)\n                            + 0.1 * cooperative_influence) # Add cooperative influence with a small weight\n\n                new_swarm = swarm + velocity\n\n                # Exploration: Introduce random search with probability exploration_pressure\n                for k in range(self.swarm_size):\n                    if np.random.rand() < self.exploration_pressure:\n                        new_swarm[k] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Explore\n\n                new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n                new_fitness = np.array([func(x) for x in new_swarm])\n                self.fevals += self.swarm_size\n\n                # Update personal best\n                improvement = new_fitness < personal_best_fitness\n                personal_best_positions[improvement] = new_swarm[improvement].copy()\n                personal_best_fitness[improvement] = new_fitness[improvement].copy()\n\n                self.swarms[i] = new_swarm\n                self.personal_best_positions[i] = personal_best_positions\n                self.personal_best_fitness[i] = personal_best_fitness\n                velocities[i] = velocity\n\n                # Update global best\n                best_idx = np.argmin(personal_best_fitness)\n                if personal_best_fitness[best_idx] < self.global_best_fitness:\n                    self.global_best_fitness = personal_best_fitness[best_idx]\n                    self.global_best_position = personal_best_positions[best_idx].copy()\n                    self.stagnation_counter = 0 # Reset stagnation counter when a better solution is found\n                \n                if self.fevals >= self.budget:\n                    break\n\n            # Stagnation check and restart\n            if self.global_best_fitness >= old_global_best_fitness: # No improvement\n                self.stagnation_counter += 1\n            else:\n                 self.stagnation_counter = 0 # Reset stagnation counter when a better solution is found\n            \n            if self.stagnation_counter > self.max_stagnation:\n                # Restart the swarm\n                if np.random.rand() < self.restart_trigger:  # Probabilistic restart\n                    for i in range(self.num_swarms):\n                        swarm, fitness = self.initialize_swarm(func)\n                        self.swarms[i] = swarm\n                        personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n                        self.personal_best_positions[i] = personal_best_positions\n                        self.personal_best_fitness[i] = personal_best_fitness\n\n                        best_idx = np.argmin(fitness)\n                        if fitness[best_idx] < self.global_best_fitness:\n                            self.global_best_fitness = fitness[best_idx]\n                            self.global_best_position = swarm[best_idx].copy()\n                            self.stagnation_counter = 0 #reset counter if we improve\n\n                    velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n                    self.stagnation_counter = 0 #reset counter after restart\n                else:\n                    self.stagnation_counter = 0 #reset counter even if no restart to prevent continuous restarts\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm CooperativeSwarm scored 0.397 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2ad1d82e-6426-4804-9c8f-88a127cf94ed"], "operator": null, "metadata": {"aucs": [0.14425942222846466, 0.2811065467631658, 0.4414050938132771, 0.8504827365171826, 0.37429447518857006, 0.2810037084148239, 0.30446468349766964, 0.35243083939627684, 0.3582075623388261, 0.21764711384846813, 0.25716794632821216, 0.995042066132201, 0.274034470869444, 0.2648390079868419, 0.7238778741300087, 0.36712768306241206, 0.3058183019157674, 0.37959353738822643, 0.2701376654379425, 0.4899133918049109]}}
{"id": "9ee8b032-6944-4d9a-936b-a7ecb9fe5ea0", "fitness": 0.24324853785387165, "name": "RingDE", "description": "Population-based optimization using a ring topology, adaptive step size, and differential evolution-inspired updates within neighborhoods.", "code": "import numpy as np\n\nclass RingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, ring_radius=2, step_size=0.1, adapt_freq=10):\n        \"\"\"\n        Ring-topology Differential Evolution with adaptive step size.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.  Must be at least 3.\n            ring_radius (int): The radius of the ring neighborhood.\n            step_size (float): Initial step size for local search.\n            adapt_freq (int): Frequency of step size adaptation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.ring_radius = ring_radius\n        self.step_size = step_size\n        self.adapt_freq = adapt_freq\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Ring-topology Differential Evolution with adaptive step size.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n        fevals = self.pop_size\n        iteration = 0\n\n        while fevals < self.budget:\n            iteration += 1\n\n            for i in range(self.pop_size):\n                # Determine neighborhood\n                neighbors = [(i - r) % self.pop_size for r in range(1, self.ring_radius + 1)] + \\\n                            [(i + r) % self.pop_size for r in range(1, self.ring_radius + 1)]\n\n                # Select three distinct individuals from the neighborhood\n                if len(neighbors) < 3:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                else:\n                    indices = np.random.choice(neighbors, min(3, len(neighbors)), replace=False) #choose up to 3 distinct neighbors\n                    if len(indices) < 3: #not enough neighbors choose from the population\n                        remaining = 3 - len(indices)\n                        all_indices = set(range(self.pop_size))\n                        available = list(all_indices.difference(set(indices)))\n                        add_indices = np.random.choice(available, min(remaining, len(available)), replace=False)\n                        indices = np.concatenate([indices,add_indices])\n                \n                if len(indices) == 3:\n\n                    x_r1, x_r2, x_r3 = self.pop[indices]\n\n                    # Differential evolution update\n                    x_trial = self.pop[i] + self.step_size * (x_r1 - x_r2 + x_r3 - self.pop[i]) # DE/rand/1\n\n                    x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate trial vector\n                    f_trial = func(x_trial)\n                    fevals += 1\n\n                    # Selection\n                    if f_trial < self.fitness[i]:\n                        self.fitness[i] = f_trial\n                        self.pop[i] = x_trial\n\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = x_trial\n                            self.best_idx = i\n\n                if fevals >= self.budget:\n                    break\n            \n            # Adaptive step size\n            if iteration % self.adapt_freq == 0:\n                if np.std(self.fitness) < 1e-6:  # If population is converging\n                    self.step_size *= 1.2  # Increase step size to explore\n                else:\n                    self.step_size *= 0.9  # Decrease step size to exploit\n\n                self.step_size = np.clip(self.step_size, 0.01, 0.5) # Keep within reasonable bounds\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm RingDE scored 0.243 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["161ec2fc-6418-4deb-8186-119ae89e5ad1"], "operator": null, "metadata": {"aucs": [0.10077443764108573, 0.22909064996506878, 0.29917966811071883, 0.16361068364282616, 0.17690487448561065, 0.21997183964667888, 0.23266394413050662, 0.1994732004480605, 0.16287965023084994, 0.1492409815655068, 0.382833673800693, 0.22261387276073907, 0.2694836241133698, 0.15971795139800238, 0.5435193682879417, 0.2790610271793783, 0.2273987679344618, 0.21383109346706086, 0.173065254508024, 0.45965619376085]}}
{"id": "e1011cb1-1641-4bf0-ba1f-b8fe603c3637", "fitness": 0.6947489003307271, "name": "AdaptiveResourceDE", "description": "Adaptive DE with memory-guided F/Cr adaptation, population control based on success, stagnation detection with multiple restart strategies, and adaptive resource allocation using fitness and diversity.", "code": "import numpy as np\n\nclass AdaptiveResourceDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, F=0.5, Cr=0.9, archive_size=10, success_memory=10, diversity_threshold=0.1, stagnation_tolerance=50):\n        \"\"\"\n        Adaptive Differential Evolution with dynamic population size, success-history based parameter adaptation,\n        and a resource allocation strategy favoring promising individuals, and stagnation handling with restart.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            initial_pop_size (int): The initial population size.\n            min_pop_size (int): The minimum population size.\n            max_pop_size (int): The maximum population size.\n            F (float): The initial scaling factor for differential variation.\n            Cr (float): The initial crossover rate.\n            archive_size (int): The size of the archive for storing successful F and Cr values.\n            success_memory (int): Size of memory for storing successful F and Cr values for adaptation\n            diversity_threshold (float): Threshold for population diversity check\n            stagnation_tolerance (int): Number of iterations without improvement before triggering restart\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.pop_size = initial_pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.archive_F = np.full(archive_size, F)\n        self.archive_Cr = np.full(archive_size, Cr)\n        self.archive_idx = 0\n        self.archive_size = archive_size\n        self.success_F_memory = []\n        self.success_Cr_memory = []\n        self.success_memory = success_memory\n        self.fevals_per_individual = np.ones(initial_pop_size, dtype=int) * (budget // initial_pop_size)\n        self.min_fevals_per_individual = 1\n        self.resource_allocation_frequency = 10  # Adjust resource allocation every this many iterations\n        self.diversity_threshold = diversity_threshold\n        self.f_trend = []\n        self.trend_window = 5\n        self.stagnation_tolerance = stagnation_tolerance\n        self.stagnation_counter = 0\n        self.global_restart_patience = 3 * stagnation_tolerance\n        self.global_restart_counter = 0\n        self.local_search_prob = 0.1\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with dynamic population size, parameter adaptation, and resource allocation.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n        success_count = 0\n        iteration = 0\n\n        while fevals < self.budget:\n            iteration += 1\n            old_f_opt = self.f_opt\n\n            for i in range(self.pop_size):\n                if self.fevals_per_individual[i] <= 0:\n                    continue\n\n                # Parameter Adaptation\n                if self.success_F_memory:\n                    F = np.random.choice(self.success_F_memory)\n                    Cr = np.random.choice(self.success_Cr_memory)\n                else:\n                    F = self.F\n                    Cr = self.Cr\n\n                # Mutation: current-to-best/1\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.pop[indices]\n                x_mutated = self.pop[i] + F * (self.pop[self.best_idx] - self.pop[i]) + F * (x_r1 - x_r2)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Local Search with probability\n                if np.random.rand() < self.local_search_prob:\n                    step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                    x_trial += np.random.normal(0, step_size, self.dim)\n                    x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n                self.fevals_per_individual[i] -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.success_F_memory.append(F)\n                    self.success_Cr_memory.append(Cr)\n\n                    if len(self.success_F_memory) > self.success_memory:\n                        self.success_F_memory.pop(0)\n                        self.success_Cr_memory.pop(0)\n\n                    success_count += 1\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n\n                if fevals >= self.budget:\n                    break\n\n            # Track fitness trend\n            self.f_trend.append(self.f_opt)\n            if len(self.f_trend) > self.trend_window:\n                self.f_trend.pop(0)\n            \n            # Stagnation Detection\n            if self.f_opt >= old_f_opt:\n                self.stagnation_counter += 1\n                self.global_restart_counter += 1\n            else:\n                self.stagnation_counter = 0\n                self.global_restart_counter = 0\n            \n            # Update archive with successful F and Cr values using a weighted average\n            if self.success_F_memory:\n                weights = np.linspace(0.1, 1.0, len(self.success_F_memory))\n                weights /= weights.sum()  # Normalize weights\n\n                weighted_avg_F = np.average(self.success_F_memory, weights=weights)\n                weighted_avg_Cr = np.average(self.success_Cr_memory, weights=weights)\n\n                self.archive_F[self.archive_idx] = weighted_avg_F\n                self.archive_Cr[self.archive_idx] = weighted_avg_Cr\n                \n                self.archive_idx = (self.archive_idx + 1) % self.archive_size\n\n            # Diversity check and injection\n            diversity = np.std(self.pop)\n            if diversity < self.diversity_threshold:\n                # Replace worst individuals with random individuals\n                num_to_replace = int(0.1 * self.pop_size)\n                worst_indices = np.argsort(self.fitness)[-num_to_replace:]\n                for idx in worst_indices:\n                    self.pop[idx] = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n                    self.fitness[idx] = func(self.pop[idx])\n                    fevals += 1\n                    if self.fitness[idx] < self.f_opt:\n                        self.f_opt = self.fitness[idx]\n                        self.x_opt = self.pop[idx]\n                        self.best_idx = idx\n                    if fevals >= self.budget:\n                        break\n                        \n            # Adjust population size based on success rate\n            success_rate = success_count / self.pop_size\n            success_count = 0 # Reset counter\n\n            if success_rate > 0.2 and self.pop_size < self.max_pop_size:\n                self.pop_size = min(self.pop_size + 1, self.max_pop_size)\n                new_individual = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(1, self.dim))\n                self.pop = np.vstack((self.pop, new_individual))\n                self.fitness = np.append(self.fitness, func(new_individual[0]))\n                self.fevals_per_individual = np.append(self.fevals_per_individual, self.budget // self.pop_size)\n                fevals += 1\n                if self.fitness[-1] < self.f_opt:\n                    self.f_opt = self.fitness[-1]\n                    self.x_opt = self.pop[-1]\n                    self.best_idx = self.pop_size - 1\n\n            elif success_rate < 0.05 and self.pop_size > self.min_pop_size:\n                # Rank-based population reduction\n                ranked_indices = np.argsort(self.fitness)[::-1]  # Sort in descending order (worst to best)\n                num_to_remove = min(int(0.1 * self.pop_size), self.pop_size - self.min_pop_size)  # Remove 10% or until min_pop_size\n                indices_to_remove = ranked_indices[:num_to_remove]\n                \n                self.pop = np.delete(self.pop, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size -= num_to_remove\n                self.fevals_per_individual = np.delete(self.fevals_per_individual, indices_to_remove)\n                self.best_idx = np.argmin(self.fitness)  # Update best index\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n\n            # Resource allocation\n            if iteration % self.resource_allocation_frequency == 0:\n                # Distribute remaining budget based on fitness rank and diversity\n                remaining_fevals = self.budget - fevals\n                if remaining_fevals > 0:\n                    ranked_indices = np.argsort(self.fitness) # Ascending order (best to worst)\n                    weights = np.linspace(1.0, 0.1, self.pop_size) # Assign weights from best to worst\n                    weights /= weights.sum() # Normalize weights\n\n                    # Adjust weights based on individual diversity (distance to the mean)\n                    mean_position = np.mean(self.pop, axis=0)\n                    distances = np.linalg.norm(self.pop - mean_position, axis=1)\n                    diversity_weights = distances / np.sum(distances)\n                    \n                    # Combine fitness and diversity weights\n                    combined_weights = 0.7 * weights + 0.3 * diversity_weights\n                    combined_weights /= combined_weights.sum()\n\n                    # Allocate fevals, ensuring minimum allocation\n                    new_fevals_per_individual = (combined_weights * remaining_fevals).astype(int) + self.min_fevals_per_individual\n                    \n                    # Ensure that the total fevals do not exceed remaining budget\n                    if np.sum(new_fevals_per_individual) > remaining_fevals:\n                        diff = np.sum(new_fevals_per_individual) - remaining_fevals\n                        new_fevals_per_individual[ranked_indices[-diff:]] -= 1\n\n                    self.fevals_per_individual = new_fevals_per_individual\n            \n            # Stagnation handling\n            if self.stagnation_counter > self.stagnation_tolerance:\n                # Local restart: perturb the best individual\n                self.pop[self.best_idx] = self.x_opt + np.random.normal(0, 0.05 * (func.bounds.ub - func.bounds.lb), self.dim)\n                self.pop[self.best_idx] = np.clip(self.pop[self.best_idx], func.bounds.lb, func.bounds.ub)\n                self.fitness[self.best_idx] = func(self.pop[self.best_idx])\n                fevals += 1\n                self.stagnation_counter = 0  # Reset stagnation counter\n            \n            if self.global_restart_counter > self.global_restart_patience:\n                # Global restart: re-initialize population (excluding best)\n                for i in range(self.pop_size):\n                    if i != self.best_idx:\n                        self.pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n                        self.fitness[i] = func(self.pop[i])\n                        fevals += 1\n                self.global_restart_counter = 0\n                self.stagnation_counter = 0\n                if fevals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveResourceDE scored 0.695 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["161ec2fc-6418-4deb-8186-119ae89e5ad1"], "operator": null, "metadata": {"aucs": [0.3117203815010623, 0.7799505305287251, 0.7294395181628586, 0.9224151348972316, 0.7577585989797309, 0.8206074785924975, 0.35268288136785964, 0.6899539375363695, 0.7685752833581732, 0.3328112743719285, 0.9261401012404948, 0.9986656608852102, 0.6287035991285147, 0.7181897923620488, 0.9398820209464581, 0.8074922187618783, 0.646064030030902, 0.8810455711190815, 0.36836620452671753, 0.5145137883167992]}}
{"id": "184e313a-16b3-4ce0-82da-4b302000b896", "fitness": 0.0, "name": "NeighborhoodAdaptiveDE", "description": "DE with Neighborhood-based Mutation and Adaptive Population Scaling, adjusting the population size based on the search progress and using a neighborhood-based mutation for better exploitation.", "code": "import numpy as np\n\nclass NeighborhoodAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_initial=50, pop_size_min=10, pop_size_max=100, F=0.5, Cr=0.9, neighborhood_size=5, scaling_factor=0.1, adaptation_rate=0.1):\n        \"\"\"\n        Differential Evolution with Neighborhood-based Mutation and Adaptive Population Scaling.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size_initial (int): The initial population size.\n            pop_size_min (int): Minimum population size.\n            pop_size_max (int): Maximum population size.\n            F (float): The scaling factor for differential variation.\n            Cr (float): The crossover rate.\n            neighborhood_size (int): Size of the neighborhood for mutation.\n            scaling_factor (float): Scaling factor for population size adjustment.\n            adaptation_rate (float): Rate at which population size adapts.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_initial\n        self.pop_size_initial = pop_size_initial\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.neighborhood_size = neighborhood_size\n        self.scaling_factor = scaling_factor\n        self.adaptation_rate = adaptation_rate\n        self.fevals = 0\n        self.convergence_history = []\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with neighborhood-based mutation and adaptive population scaling.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.fevals += self.pop_size\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n        self.convergence_history.append(self.f_opt)\n\n        while self.fevals < self.budget:\n            for i in range(self.pop_size):\n                # Neighborhood-based Mutation\n                neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                x_neighbors = self.pop[neighbors]\n                \n                # Select three distinct neighbors (excluding the current individual)\n                indices = np.random.choice(self.neighborhood_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = x_neighbors[indices]\n\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n                \n                if self.fevals >= self.budget:\n                    break\n                    \n            # Adaptive Population Scaling\n            convergence_strength = np.std(self.fitness)\n            self.convergence_history.append(self.f_opt)\n            \n            if len(self.convergence_history) > 2:\n                improvement = self.convergence_history[-2] - self.convergence_history[-1]\n\n                if improvement > 0:\n                    # Increase population size if improvement is observed\n                    self.pop_size = int(min(self.pop_size * (1 + self.adaptation_rate), self.pop_size_max))\n                else:\n                    # Decrease population size if no improvement is observed\n                     self.pop_size = int(max(self.pop_size * (1 - self.adaptation_rate), self.pop_size_min))\n\n            if self.pop_size != len(self.pop):\n                # Resize the population (keeping the best individuals)\n                best_individuals_indices = np.argsort(self.fitness)[:min(self.pop_size, len(self.pop))]\n                best_individuals = self.pop[best_individuals_indices]\n                \n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.fevals += self.pop_size - len(best_individuals)\n                \n                self.pop[:len(best_individuals)] = best_individuals\n                self.fitness[:len(best_individuals)] = [func(x) for x in best_individuals]\n                self.fevals += len(best_individuals)\n                self.best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm NeighborhoodAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["09f69ee2-0b24-4fee-b82a-77cecc5e9f18"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "98e3d059-98f6-4809-9b2c-7477460a1966", "fitness": 0.5731508703562553, "name": "HybridPSO", "description": "Hybrid Particle Swarm Optimization with Lvy flight-based exploration and adaptive parameter control using a success-history based adaptation.", "code": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=30, inertia_max=0.9, inertia_min=0.2,\n                 cognitive_coeff=2.0, social_coeff=2.0, levy_exponent=1.5, p_mutation=0.05, sh_size=5):\n        \"\"\"\n        Hybrid Particle Swarm Optimization with Lvy flight and SHADE-inspired adaptation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            swarm_size (int): The size of the swarm.\n            inertia_max (float): Maximum inertia weight.\n            inertia_min (float): Minimum inertia weight.\n            cognitive_coeff (float): Cognitive coefficient.\n            social_coeff (float): Social coefficient.\n            levy_exponent (float): Exponent for Lvy flight distribution.\n            p_mutation (float): Probability of applying mutation.\n            sh_size (int): Size of the success history archive.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.levy_exponent = levy_exponent\n        self.p_mutation = p_mutation\n        self.sh_size = sh_size\n        self.swarm = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.success_history = [] # store successful parameter changes (inertia)\n        self.memory_inertia = np.full(self.sh_size, (inertia_max + inertia_min)/2) # initialize memory\n\n    def levy_flight(self, size):\n        \"\"\"\n        Generates Lvy flight steps.\n        \"\"\"\n        u = np.random.normal(0, 1, size=size)\n        v = np.random.normal(0, 1, size=size)\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) /\n                 (np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * (2 ** ((self.levy_exponent - 1) / 2)))) ** (1 / self.levy_exponent)\n        step = sigma * u / abs(v) ** (1 / self.levy_exponent)\n        return step\n\n    def initialize_swarm(self, func):\n        \"\"\"\n        Initializes the swarm with random positions and velocities.\n        \"\"\"\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim))  # Initialize velocities\n        fitness = np.array([func(x) for x in self.swarm])\n        self.fevals += self.swarm_size\n        self.personal_best_positions = self.swarm.copy()\n        self.personal_best_fitness = fitness.copy()\n        self.global_best_fitness = np.min(fitness)\n        self.global_best_position = self.swarm[np.argmin(fitness)].copy()\n\n    def update_parameters(self):\n        \"\"\"\n        Update parameters based on success history (SHADE-inspired).\n        \"\"\"\n        if self.success_history:\n            # Sample from success history\n            sampled_inertia = np.random.choice(self.success_history)\n            inertia = sampled_inertia\n        else:\n            # If no successful history, use mean of memory\n            inertia = np.mean(self.memory_inertia)\n\n        inertia = np.clip(inertia, self.inertia_min, self.inertia_max) # ensure bounds\n        return inertia\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Hybrid PSO.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.initialize_swarm(func)\n\n        while self.fevals < self.budget:\n            inertia = self.update_parameters()\n\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                self.velocities[i] = (inertia * self.velocities[i] +\n                                       self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.swarm[i]) +\n                                       self.social_coeff * r2 * (self.global_best_position - self.swarm[i]))\n\n                # Update position\n                new_position = self.swarm[i] + self.velocities[i]\n\n                # Lvy flight-based exploration\n                if np.random.rand() < self.p_mutation:\n                    levy_steps = self.levy_flight(self.dim)\n                    new_position += 0.01 * levy_steps  # Scale the steps\n                \n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.fevals += 1\n\n                # Update personal best\n                if new_fitness < self.personal_best_fitness[i]:\n                    delta = self.personal_best_fitness[i] - new_fitness # fitness improvement\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n                    \n                    # Update success history\n                    self.success_history.append(inertia)\n                    if len(self.success_history) > self.sh_size:\n                        self.success_history.pop(0) #FIFO\n                    \n                    # update memory of inertia values\n                    self.memory_inertia = np.roll(self.memory_inertia, 1)\n                    self.memory_inertia[0] = inertia  # store current inertia used\n\n                self.swarm[i] = new_position\n\n                # Update global best\n                if new_fitness < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness\n                    self.global_best_position = new_position.copy()\n                \n                if self.fevals >= self.budget:\n                    break\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSO scored 0.573 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2ad1d82e-6426-4804-9c8f-88a127cf94ed"], "operator": null, "metadata": {"aucs": [0.17710945707872672, 0.40947888653665054, 0.6595314884986305, 0.9391208991786458, 0.7399310129264494, 0.7694578522328839, 0.3186658081687537, 0.5928808619232278, 0.4832657542609119, 0.2021046751877721, 0.8930770062359012, 0.9965618009447103, 0.2680881620386203, 0.2622160203209746, 0.8481918283678548, 0.7991541080011455, 0.5910861637259515, 0.8529088830927543, 0.18558677243416, 0.4745999659703848]}}
{"id": "7e2d7e10-1e5f-45e2-b4e7-cf37c79b1369", "fitness": -Infinity, "name": "OrthogonalLearningSwarm", "description": "Population-based algorithm with a directed exploration strategy using orthogonal learning to create diverse candidate solutions and a restart mechanism based on population entropy.", "code": "import numpy as np\n\nclass OrthogonalLearningSwarm:\n    def __init__(self, budget=10000, dim=10, population_size=50, orthogonal_samples=5,\n                 learning_rate=0.1, entropy_threshold=0.1, restart_probability=0.05):\n        \"\"\"\n        Population-based algorithm with orthogonal learning and entropy-based restart.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            population_size (int): The number of individuals in the population.\n            orthogonal_samples (int): Number of samples generated using orthogonal design.\n            learning_rate (float): Step size for updating individual positions.\n            entropy_threshold (float): Threshold for population entropy to trigger restart.\n            restart_probability (float): Probability of restarting the population.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.orthogonal_samples = orthogonal_samples\n        self.learning_rate = learning_rate\n        self.entropy_threshold = entropy_threshold\n        self.restart_probability = restart_probability\n        self.population = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.fevals = 0\n\n    def initialize_population(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.fevals += self.population_size\n        return population, fitness\n\n    def orthogonal_design(self, current_position, func):\n        \"\"\"\n        Generate samples using orthogonal design around the current position.\n\n        Args:\n            current_position (np.ndarray): The current position (center point).\n            func: The objective function\n\n        Returns:\n            np.ndarray: Orthogonal samples.\n        \"\"\"\n        orthogonal_samples = np.zeros((self.orthogonal_samples, self.dim))\n        for i in range(self.orthogonal_samples):\n            sample = current_position.copy()\n            # Select two random dimensions to change\n            dims = np.random.choice(self.dim, 2, replace=False)\n            # Generate values around the current position for those dimensions\n            for d in dims:\n                sample[d] = np.random.uniform(max(func.bounds.lb, current_position[d] - 0.5), min(func.bounds.ub, current_position[d] + 0.5))\n            orthogonal_samples[i] = sample\n        return orthogonal_samples\n\n    def calculate_population_entropy(self):\n        \"\"\"Calculate the entropy of the population.\"\"\"\n        # Discretize the search space (crude approximation)\n        num_bins = 10\n        population_distributions = []\n        for d in range(self.dim):\n            histogram, _ = np.histogram(self.population[:, d], bins=num_bins, range=(-5,5))  # Assuming bounds are [-5, 5]\n            prob_distribution = histogram / np.sum(histogram)\n            population_distributions.append(prob_distribution)\n\n        # Calculate entropy for each dimension and average\n        entropy_values = []\n        for prob_distribution in population_distributions:\n            entropy = 0\n            for p in prob_distribution:\n                if p > 0:\n                    entropy -= p * np.log2(p)\n            entropy_values.append(entropy)\n        \n        return np.mean(entropy_values)\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Orthogonal Learning Swarm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.population, self.fitness = self.initialize_population(func)\n\n        # Update global best\n        best_idx = np.argmin(self.fitness)\n        self.best_fitness = self.fitness[best_idx]\n        self.best_position = self.population[best_idx].copy()\n\n        while self.fevals < self.budget:\n            for i in range(self.population_size):\n                # Generate orthogonal samples\n                orthogonal_samples = self.orthogonal_design(self.population[i], func)\n                orthogonal_fitness = np.array([func(x) for x in orthogonal_samples])\n                self.fevals += self.orthogonal_samples\n\n                # Select the best sample\n                best_sample_idx = np.argmin(orthogonal_fitness)\n                best_sample = orthogonal_samples[best_sample_idx]\n                best_sample_fitness = orthogonal_fitness[best_sample_idx]\n\n                # Update individual position if the best sample is better\n                if best_sample_fitness < self.fitness[i]:\n                    self.population[i] = self.population[i] + self.learning_rate * (best_sample - self.population[i])\n                    self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.fevals += 1  # Account for re-evaluation\n\n                    # Update global best\n                    if self.fitness[i] < self.best_fitness:\n                        self.best_fitness = self.fitness[i]\n                        self.best_position = self.population[i].copy()\n            \n            # Entropy-based restart\n            entropy = self.calculate_population_entropy()\n            if entropy < self.entropy_threshold and np.random.rand() < self.restart_probability:\n                self.population, self.fitness = self.initialize_population(func)\n                best_idx = np.argmin(self.fitness)\n                if self.fitness[best_idx] < self.best_fitness:\n                    self.best_fitness = self.fitness[best_idx]\n                    self.best_position = self.population[best_idx].copy()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 7, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["077c669e-20b2-4e2c-9d1c-6c2f58c62a80"], "operator": null, "metadata": {}}
{"id": "4e96c820-6ae3-4fc4-abe4-e70c31a4d9af", "fitness": -Infinity, "name": "SOM_PSO", "description": "An adaptive PSO variant that dynamically adjusts exploration-exploitation balance using a self-organizing map (SOM) to cluster particles based on their fitness and distance to the global best, and adapts inertia and acceleration coefficients accordingly.", "code": "import numpy as np\nfrom minisom import MiniSom\n\nclass SOM_PSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=30, som_grid_size=5,\n                 inertia_max=0.9, inertia_min=0.2, cognitive_coeff_max=2.5,\n                 cognitive_coeff_min=1.5, social_coeff_max=1.5, social_coeff_min=0.5):\n        \"\"\"\n        Self-Organizing Map (SOM) guided Particle Swarm Optimization.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            swarm_size (int): The size of the swarm.\n            som_grid_size (int): Size of the SOM grid (som_grid_size x som_grid_size).\n            inertia_max (float): Maximum inertia weight.\n            inertia_min (float): Minimum inertia weight.\n            cognitive_coeff_max (float): Maximum cognitive coefficient.\n            cognitive_coeff_min (float): Minimum cognitive coefficient.\n            social_coeff_max (float): Maximum social coefficient.\n            social_coeff_min (float): Minimum social coefficient.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.som_grid_size = som_grid_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff_max = cognitive_coeff_max\n        self.cognitive_coeff_min = cognitive_coeff_min\n        self.social_coeff_max = social_coeff_max\n        self.social_coeff_min = social_coeff_min\n        self.swarm = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.som = None\n\n    def initialize_swarm(self, func):\n        \"\"\"\n        Initializes the swarm with random positions and velocities.\n        \"\"\"\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim))  # Initialize velocities\n        fitness = np.array([func(x) for x in self.swarm])\n        self.fevals += self.swarm_size\n        self.personal_best_positions = self.swarm.copy()\n        self.personal_best_fitness = fitness.copy()\n        self.global_best_fitness = np.min(fitness)\n        self.global_best_position = self.swarm[np.argmin(fitness)].copy()\n        self.initialize_som()\n\n    def initialize_som(self):\n        \"\"\"\n        Initializes the Self-Organizing Map.\n        \"\"\"\n        self.som = MiniSom(self.som_grid_size, self.som_grid_size, 2, sigma=0.3, learning_rate=0.5)\n\n    def create_som_input(self):\n        \"\"\"\n        Creates input data for the SOM based on particle fitness and distance to global best.\n        \"\"\"\n        som_input = np.zeros((self.swarm_size, 2))\n        for i in range(self.swarm_size):\n            # Normalize fitness relative to global best\n            fitness_norm = (self.personal_best_fitness[i] - self.global_best_fitness) / (np.max(self.personal_best_fitness) - self.global_best_fitness + 1e-8)\n            \n            # Normalize distance to global best\n            distance = np.linalg.norm(self.swarm[i] - self.global_best_position)\n            distance_norm = distance / (np.linalg.norm(self.swarm[i] - self.global_best_position).max() + 1e-8)\n\n            som_input[i, 0] = fitness_norm\n            som_input[i, 1] = distance_norm\n        return som_input\n\n    def adapt_parameters(self, som_input):\n        \"\"\"\n        Adapts inertia and acceleration coefficients based on SOM clustering.\n        \"\"\"\n        self.som.train_random(som_input, 100)  # Train SOM for a short number of iterations\n        inertia = np.zeros(self.swarm_size)\n        cognitive_coeff = np.zeros(self.swarm_size)\n        social_coeff = np.zeros(self.swarm_size)\n\n        for i in range(self.swarm_size):\n            winner = self.som.winner(som_input[i])\n            # Adapt parameters based on SOM grid position\n            inertia[i] = self.inertia_min + (self.inertia_max - self.inertia_min) * (winner[0] / self.som_grid_size)\n            cognitive_coeff[i] = self.cognitive_coeff_min + (self.cognitive_coeff_max - self.cognitive_coeff_min) * (1 - winner[1] / self.som_grid_size)\n            social_coeff[i] = self.social_coeff_min + (self.social_coeff_max - self.social_coeff_min) * (winner[1] / self.som_grid_size)\n\n        return inertia, cognitive_coeff, social_coeff\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using SOM-guided PSO.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.initialize_swarm(func)\n\n        while self.fevals < self.budget:\n            som_input = self.create_som_input()\n            inertia, cognitive_coeff, social_coeff = self.adapt_parameters(som_input)\n\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                self.velocities[i] = (inertia[i] * self.velocities[i] +\n                                       cognitive_coeff[i] * r1 * (self.personal_best_positions[i] - self.swarm[i]) +\n                                       social_coeff[i] * r2 * (self.global_best_position - self.swarm[i]))\n\n                # Update position\n                new_position = self.swarm[i] + self.velocities[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.fevals += 1\n\n                # Update personal best\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                self.swarm[i] = new_position\n\n                # Update global best\n                if new_fitness < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness\n                    self.global_best_position = new_position.copy()\n                \n                if self.fevals >= self.budget:\n                    break\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "An exception occurred: No module named 'minisom'.", "error": "", "parent_ids": ["98e3d059-98f6-4809-9b2c-7477460a1966"], "operator": null, "metadata": {}}
{"id": "bee422ad-4e4f-42bc-a2b5-e491732258cb", "fitness": 0.0, "name": "HybridPSO", "description": "Enhanced Hybrid PSO with orthogonal learning and velocity clamping for better exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=30, inertia_max=0.9, inertia_min=0.2,\n                 cognitive_coeff=2.0, social_coeff=2.0, levy_exponent=1.5, p_mutation=0.05, sh_size=5, velocity_clamp=2.0, orthogonal_learning_rate=0.1):\n        \"\"\"\n        Hybrid Particle Swarm Optimization with Lvy flight, SHADE-inspired adaptation, and orthogonal learning.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            swarm_size (int): The size of the swarm.\n            inertia_max (float): Maximum inertia weight.\n            inertia_min (float): Minimum inertia weight.\n            cognitive_coeff (float): Cognitive coefficient.\n            social_coeff (float): Social coefficient.\n            levy_exponent (float): Exponent for Lvy flight distribution.\n            p_mutation (float): Probability of applying mutation.\n            sh_size (int): Size of the success history archive.\n            velocity_clamp (float): Maximum velocity value.\n            orthogonal_learning_rate (float): Learning rate for orthogonal learning.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.levy_exponent = levy_exponent\n        self.p_mutation = p_mutation\n        self.sh_size = sh_size\n        self.velocity_clamp = velocity_clamp\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n        self.swarm = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.success_history = [] # store successful parameter changes (inertia)\n        self.memory_inertia = np.full(self.sh_size, (inertia_max + inertia_min)/2) # initialize memory\n\n    def levy_flight(self, size):\n        \"\"\"\n        Generates Lvy flight steps.\n        \"\"\"\n        u = np.random.normal(0, 1, size=size)\n        v = np.random.normal(0, 1, size=size)\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) /\n                 (np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * (2 ** ((self.levy_exponent - 1) / 2)))) ** (1 / self.levy_exponent)\n        step = sigma * u / abs(v) ** (1 / self.levy_exponent)\n        return step\n\n    def initialize_swarm(self, func):\n        \"\"\"\n        Initializes the swarm with random positions and velocities.\n        \"\"\"\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim))  # Initialize velocities\n        fitness = np.array([func(x) for x in self.swarm])\n        self.fevals += self.swarm_size\n        self.personal_best_positions = self.swarm.copy()\n        self.personal_best_fitness = fitness.copy()\n        self.global_best_fitness = np.min(fitness)\n        self.global_best_position = self.swarm[np.argmin(fitness)].copy()\n\n    def update_parameters(self):\n        \"\"\"\n        Update parameters based on success history (SHADE-inspired).\n        \"\"\"\n        if self.success_history:\n            # Sample from success history\n            sampled_inertia = np.random.choice(self.success_history)\n            inertia = sampled_inertia\n        else:\n            # If no successful history, use mean of memory\n            inertia = np.mean(self.memory_inertia)\n\n        inertia = np.clip(inertia, self.inertia_min, self.inertia_max) # ensure bounds\n        return inertia\n\n    def orthogonal_learning(self, particle, func):\n        \"\"\"\n        Performs orthogonal learning to generate a candidate solution.\n        \"\"\"\n        basis_vectors = np.random.normal(0, 1, size=(self.dim, self.dim))\n        Q, _ = np.linalg.qr(basis_vectors)  # Orthogonalize basis vectors\n\n        candidate = particle.copy()\n        for i in range(self.dim):\n            step = self.orthogonal_learning_rate * Q[i]\n            new_candidate = particle + step\n            new_candidate = np.clip(new_candidate, func.bounds.lb, func.bounds.ub)\n            \n            if func(new_candidate) < func(candidate):\n                candidate = new_candidate\n        \n        return candidate\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Hybrid PSO.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.initialize_swarm(func)\n\n        while self.fevals < self.budget:\n            inertia = self.update_parameters()\n\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                self.velocities[i] = (inertia * self.velocities[i] +\n                                       self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.swarm[i]) +\n                                       self.social_coeff * r2 * (self.global_best_position - self.swarm[i]))\n\n                # Velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = self.swarm[i] + self.velocities[i]\n\n                # Lvy flight-based exploration\n                if np.random.rand() < self.p_mutation:\n                    levy_steps = self.levy_flight(self.dim)\n                    new_position += 0.01 * levy_steps  # Scale the steps\n\n                # Orthogonal learning\n                if np.random.rand() < 0.1:  # Apply with probability 0.1\n                    new_position = self.orthogonal_learning(self.swarm[i], func)\n\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.fevals += 1\n\n                # Update personal best\n                if new_fitness < self.personal_best_fitness[i]:\n                    delta = self.personal_best_fitness[i] - new_fitness # fitness improvement\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n                    \n                    # Update success history\n                    self.success_history.append(inertia)\n                    if len(self.success_history) > self.sh_size:\n                        self.success_history.pop(0) #FIFO\n                    \n                    # update memory of inertia values\n                    self.memory_inertia = np.roll(self.memory_inertia, 1)\n                    self.memory_inertia[0] = inertia  # store current inertia used\n\n                self.swarm[i] = new_position\n\n                # Update global best\n                if new_fitness < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness\n                    self.global_best_position = new_position.copy()\n                \n                if self.fevals >= self.budget:\n                    break\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["98e3d059-98f6-4809-9b2c-7477460a1966"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "b4e95010-1b47-4c57-b0fa-b0ae53a5c8d5", "fitness": 0.0, "name": "CooperativeSwarm", "description": "Cooperative Swarm Optimization with adaptive exploration and exploitation balance via a success-history based parameter adaptation and a more effective stagnation handling.", "code": "import numpy as np\n\nclass CooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=10,\n                 inertia_range=(0.4, 0.9), cognitive_coeff_range=(1.5, 2.0),\n                 social_coeff_range=(1.5, 2.0), exploration_pressure=0.1,\n                 restart_trigger=0.05, p_mutation=0.1):\n        \"\"\"\n        Cooperative Swarm Optimization algorithm with adaptive parameters, dynamic sub-swarm communication and restart mechanism.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            num_swarms (int): The number of sub-swarms.\n            swarm_size (int): The size of each sub-swarm.\n            inertia_range (tuple): Range for inertia weight adaptation.\n            cognitive_coeff_range (tuple): Range for cognitive coefficient adaptation.\n            social_coeff_range (tuple): Range for social coefficient adaptation.\n            exploration_pressure (float): Probability of exploring a new region instead of exploiting.\n            restart_trigger (float): Trigger for swarm restart based on stagnation.\n            p_mutation (float): Probability of applying mutation to a particle.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_range = inertia_range\n        self.cognitive_coeff_range = cognitive_coeff_range\n        self.social_coeff_range = social_coeff_range\n        self.exploration_pressure = exploration_pressure\n        self.restart_trigger = restart_trigger\n        self.p_mutation = p_mutation\n        self.swarms = []\n        self.personal_best_positions = []\n        self.personal_best_fitness = []\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.stagnation_counter = 0\n        self.max_stagnation = 50 # Reduced stagnation for faster response.\n        self.success_inertia = []\n        self.success_cognitive = []\n        self.success_social = []\n\n    def initialize_swarm(self, func):\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.fevals += self.swarm_size\n        return swarm, fitness\n\n    def update_personal_best(self, swarm, fitness):\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n        return personal_best_positions, personal_best_fitness\n\n    def adapt_parameters(self):\n        \"\"\"Adapt inertia, cognitive, and social coefficients using success history.\"\"\"\n        if self.success_inertia:\n            self.inertia = np.mean(self.success_inertia)\n        else:\n            self.inertia = np.random.uniform(self.inertia_range[0], self.inertia_range[1])\n\n        if self.success_cognitive:\n            self.cognitive_coeff = np.mean(self.success_cognitive)\n        else:\n            self.cognitive_coeff = np.random.uniform(self.cognitive_coeff_range[0], self.cognitive_coeff_range[1])\n\n        if self.success_social:\n            self.social_coeff = np.mean(self.success_social)\n        else:\n            self.social_coeff = np.random.uniform(self.social_coeff_range[0], self.social_coeff_range[1])\n\n        # Clear success history after adaptation.\n        self.success_inertia = []\n        self.success_cognitive = []\n        self.success_social = []\n        \n    def mutate(self, x, func):\n        \"\"\"Mutate a particle with a certain probability.\"\"\"\n        if np.random.rand() < self.p_mutation:\n            x = x + np.random.normal(0, 0.1, size=self.dim)  # Small perturbation\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n        return x\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Cooperative Swarm Optimization.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        # Initialize swarms\n        for _ in range(self.num_swarms):\n            swarm, fitness = self.initialize_swarm(func)\n            self.swarms.append(swarm)\n            personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n            self.personal_best_positions.append(personal_best_positions)\n            self.personal_best_fitness.append(personal_best_fitness)\n\n            # Update global best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.global_best_fitness:\n                self.global_best_fitness = fitness[best_idx]\n                self.global_best_position = swarm[best_idx].copy()\n                self.stagnation_counter = 0 #reset counter if we improve\n\n        velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n\n        while self.fevals < self.budget:\n            old_global_best_fitness = self.global_best_fitness  # Store the previous global best\n\n            for i in range(self.num_swarms):\n                swarm = self.swarms[i]\n                personal_best_positions = self.personal_best_positions[i]\n                personal_best_fitness = self.personal_best_fitness[i]\n                velocity = velocities[i]\n\n                # Update velocities and positions\n                r1 = np.random.rand(self.swarm_size, self.dim)\n                r2 = np.random.rand(self.swarm_size, self.dim)\n\n                # Cooperative component: Influence from other swarms' best\n                cooperative_influence = np.zeros((self.swarm_size, self.dim))\n                num_contributing_swarms = 0\n                for j in range(self.num_swarms):\n                    if i != j:\n                        best_idx_other = np.argmin(self.personal_best_fitness[j])\n                        # Dynamic communication: only influence from better swarms\n                        if self.personal_best_fitness[j][best_idx_other] < np.min(personal_best_fitness):\n                            cooperative_influence += (self.personal_best_positions[j][best_idx_other] - swarm)\n                            num_contributing_swarms += 1\n                if num_contributing_swarms > 0:\n                    cooperative_influence /= num_contributing_swarms # Average influence\n\n                # Adapt parameters\n                self.adapt_parameters()\n\n                velocity = (self.inertia * velocity\n                            + self.cognitive_coeff * r1 * (personal_best_positions - swarm)\n                            + self.social_coeff * r2 * (self.global_best_position - swarm)\n                            + 0.1 * cooperative_influence) # Add cooperative influence with a small weight\n\n                new_swarm = swarm + velocity\n\n                # Exploration: Introduce random search with probability exploration_pressure\n                for k in range(self.swarm_size):\n                    if np.random.rand() < self.exploration_pressure:\n                        new_swarm[k] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Explore\n                    else:\n                        new_swarm[k] = self.mutate(new_swarm[k], func)  # Apply mutation\n\n                new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n                new_fitness = np.array([func(x) for x in new_swarm])\n                self.fevals += self.swarm_size\n\n                # Update personal best\n                improvement = new_fitness < personal_best_fitness\n                \n                # Store successful parameter values\n                for idx in np.where(improvement)[0]:\n                    self.success_inertia.append(self.inertia)\n                    self.success_cognitive.append(self.cognitive_coeff)\n                    self.success_social.append(self.social_coeff)\n\n                personal_best_positions[improvement] = new_swarm[improvement].copy()\n                personal_best_fitness[improvement] = new_fitness[improvement].copy()\n\n                self.swarms[i] = new_swarm\n                self.personal_best_positions[i] = personal_best_positions\n                self.personal_best_fitness[i] = personal_best_fitness\n                velocities[i] = velocity\n\n                # Update global best\n                best_idx = np.argmin(personal_best_fitness)\n                if personal_best_fitness[best_idx] < self.global_best_fitness:\n                    self.global_best_fitness = personal_best_fitness[best_idx]\n                    self.global_best_position = personal_best_positions[best_idx].copy()\n                    self.stagnation_counter = 0 # Reset stagnation counter when a better solution is found\n                \n                if self.fevals >= self.budget:\n                    break\n\n            # Stagnation check and restart\n            if self.global_best_fitness >= old_global_best_fitness: # No improvement\n                self.stagnation_counter += 1\n            else:\n                 self.stagnation_counter = 0 # Reset stagnation counter when a better solution is found\n            \n            if self.stagnation_counter > self.max_stagnation:\n                # Restart the swarm\n                if np.random.rand() < self.restart_trigger:  # Probabilistic restart\n                    for i in range(self.num_swarms):\n                        swarm, fitness = self.initialize_swarm(func)\n                        self.swarms[i] = swarm\n                        personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n                        self.personal_best_positions[i] = personal_best_positions\n                        self.personal_best_fitness[i] = personal_best_fitness\n\n                        best_idx = np.argmin(fitness)\n                        if fitness[best_idx] < self.global_best_fitness:\n                            self.global_best_fitness = fitness[best_idx]\n                            self.global_best_position = swarm[best_idx].copy()\n                            self.stagnation_counter = 0 #reset counter if we improve\n\n                    velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n                    self.stagnation_counter = 0 #reset counter after restart\n                    self.success_inertia = []\n                    self.success_cognitive = []\n                    self.success_social = []\n                else:\n                    # Apply mutation to the global best to escape local optima.\n                    self.global_best_position = self.mutate(self.global_best_position, func)\n                    self.global_best_fitness = func(self.global_best_position)\n                    self.fevals += 1\n                    self.stagnation_counter = 0\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm CooperativeSwarm scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["077c669e-20b2-4e2c-9d1c-6c2f58c62a80"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "ae33f8db-20d1-4112-b5ce-309b8218984e", "fitness": -Infinity, "name": "AdaptiveResourceDE", "description": "Enhanced Adaptive DE with improved stagnation handling using trend analysis, adaptive local search probability, and enhanced diversity injection.", "code": "import numpy as np\n\nclass AdaptiveResourceDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, F=0.5, Cr=0.9, archive_size=10, success_memory=10, diversity_threshold=0.1, stagnation_tolerance=50, trend_window=5):\n        \"\"\"\n        Adaptive Differential Evolution with dynamic population size, success-history based parameter adaptation,\n        resource allocation, stagnation handling with trend analysis, adaptive local search, and enhanced diversity injection.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            initial_pop_size (int): The initial population size.\n            min_pop_size (int): The minimum population size.\n            max_pop_size (int): The maximum population size.\n            F (float): The initial scaling factor for differential variation.\n            Cr (float): The initial crossover rate.\n            archive_size (int): The size of the archive for storing successful F and Cr values.\n            success_memory (int): Size of memory for storing successful F and Cr values for adaptation\n            diversity_threshold (float): Threshold for population diversity check\n            stagnation_tolerance (int): Number of iterations without improvement before triggering restart\n            trend_window (int): Window size for fitness trend analysis\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.pop_size = initial_pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.archive_F = np.full(archive_size, F)\n        self.archive_Cr = np.full(archive_size, Cr)\n        self.archive_idx = 0\n        self.archive_size = archive_size\n        self.success_F_memory = []\n        self.success_Cr_memory = []\n        self.success_memory = success_memory\n        self.fevals_per_individual = np.ones(initial_pop_size, dtype=int) * (budget // initial_pop_size)\n        self.min_fevals_per_individual = 1\n        self.resource_allocation_frequency = 10  # Adjust resource allocation every this many iterations\n        self.diversity_threshold = diversity_threshold\n        self.f_trend = []\n        self.trend_window = trend_window\n        self.stagnation_tolerance = stagnation_tolerance\n        self.stagnation_counter = 0\n        self.global_restart_patience = 3 * stagnation_tolerance\n        self.global_restart_counter = 0\n        self.local_search_prob = 0.1\n        self.adaptive_ls_prob = self.local_search_prob # Adaptive local search probability\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with dynamic population size, parameter adaptation, and resource allocation.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n        success_count = 0\n        iteration = 0\n\n        while fevals < self.budget:\n            iteration += 1\n            old_f_opt = self.f_opt\n\n            for i in range(self.pop_size):\n                if self.fevals_per_individual[i] <= 0:\n                    continue\n\n                # Parameter Adaptation\n                if self.success_F_memory:\n                    F = np.random.choice(self.success_F_memory)\n                    Cr = np.random.choice(self.success_Cr_memory)\n                else:\n                    F = self.F\n                    Cr = self.Cr\n\n                # Mutation: current-to-best/1\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.pop[indices]\n                x_mutated = self.pop[i] + F * (self.pop[self.best_idx] - self.pop[i]) + F * (x_r1 - x_r2)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Local Search with adaptive probability\n                if np.random.rand() < self.adaptive_ls_prob:\n                    step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                    x_trial += np.random.normal(0, step_size, self.dim)\n                    x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n                self.fevals_per_individual[i] -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.success_F_memory.append(F)\n                    self.success_Cr_memory.append(Cr)\n\n                    if len(self.success_F_memory) > self.success_memory:\n                        self.success_F_memory.pop(0)\n                        self.success_Cr_memory.pop(0)\n\n                    success_count += 1\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n\n                if fevals >= self.budget:\n                    break\n\n            # Track fitness trend\n            self.f_trend.append(self.f_opt)\n            if len(self.f_trend) > self.trend_window:\n                self.f_trend.pop(0)\n            \n            # Stagnation Detection using trend analysis\n            if len(self.f_trend) >= self.trend_window:\n                trend = np.mean(np.diff(self.f_trend))\n                if abs(trend) < 1e-6:  # Consider stagnation if the fitness change is negligible\n                    self.stagnation_counter += 1\n                    self.global_restart_counter += 1\n                else:\n                    self.stagnation_counter = 0\n                    self.global_restart_counter = 0\n            else:\n                self.stagnation_counter = 0\n                self.global_restart_counter = 0\n            \n            # Update archive with successful F and Cr values using a weighted average\n            if self.success_F_memory:\n                weights = np.linspace(0.1, 1.0, len(self.success_F_memory))\n                weights /= weights.sum()  # Normalize weights\n\n                weighted_avg_F = np.average(self.success_F_memory, weights=weights)\n                weighted_avg_Cr = np.average(self.success_Cr_memory, weights=weights)\n\n                self.archive_F[self.archive_idx] = weighted_avg_F\n                self.archive_Cr[self.archive_idx] = weighted_avg_Cr\n                \n                self.archive_idx = (self.archive_idx + 1) % self.archive_size\n\n            # Enhanced Diversity injection\n            diversity = np.std(self.pop)\n            if diversity < self.diversity_threshold:\n                # Replace a larger portion of the population with solutions biased towards the best\n                num_to_replace = int(0.2 * self.pop_size)  # Increase replacement percentage\n                worst_indices = np.argsort(self.fitness)[-num_to_replace:]\n                for idx in worst_indices:\n                    # Generate new solution biased towards the best individual\n                    direction = self.x_opt - self.pop[idx]\n                    new_solution = self.x_opt + 0.5 * direction + np.random.normal(0, 0.1 * (func.bounds.ub - func.bounds.lb), self.dim)\n                    new_solution = np.clip(new_solution, func.bounds.lb, func.bounds.ub)\n                    \n                    self.pop[idx] = new_solution\n                    self.fitness[idx] = func(self.pop[idx])\n                    fevals += 1\n                    if self.fitness[idx] < self.f_opt:\n                        self.f_opt = self.fitness[idx]\n                        self.x_opt = self.pop[idx]\n                        self.best_idx = idx\n                    if fevals >= self.budget:\n                        break\n\n            # Adaptive local search probability\n            if success_rate > 0.2:\n                self.adaptive_ls_prob = min(self.adaptive_ls_prob + 0.01, 0.5) # Increase if successful\n            else:\n                self.adaptive_ls_prob = max(self.adaptive_ls_prob - 0.01, 0.01) # Decrease if unsuccessful\n                        \n            # Adjust population size based on success rate\n            success_rate = success_count / self.pop_size\n            success_count = 0 # Reset counter\n\n            if success_rate > 0.2 and self.pop_size < self.max_pop_size:\n                self.pop_size = min(self.pop_size + 1, self.max_pop_size)\n                new_individual = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(1, self.dim))\n                self.pop = np.vstack((self.pop, new_individual))\n                self.fitness = np.append(self.fitness, func(new_individual[0]))\n                self.fevals_per_individual = np.append(self.fevals_per_individual, self.budget // self.pop_size)\n                fevals += 1\n                if self.fitness[-1] < self.f_opt:\n                    self.f_opt = self.fitness[-1]\n                    self.x_opt = self.pop[-1]\n                    self.best_idx = self.pop_size - 1\n\n            elif success_rate < 0.05 and self.pop_size > self.min_pop_size:\n                # Rank-based population reduction\n                ranked_indices = np.argsort(self.fitness)[::-1]  # Sort in descending order (worst to best)\n                num_to_remove = min(int(0.1 * self.pop_size), self.pop_size - self.min_pop_size)  # Remove 10% or until min_pop_size\n                indices_to_remove = ranked_indices[:num_to_remove]\n                \n                self.pop = np.delete(self.pop, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size -= num_to_remove\n                self.fevals_per_individual = np.delete(self.fevals_per_individual, indices_to_remove)\n                self.best_idx = np.argmin(self.fitness)  # Update best index\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n\n            # Resource allocation\n            if iteration % self.resource_allocation_frequency == 0:\n                # Distribute remaining budget based on fitness rank and diversity\n                remaining_fevals = self.budget - fevals\n                if remaining_fevals > 0:\n                    ranked_indices = np.argsort(self.fitness) # Ascending order (best to worst)\n                    weights = np.linspace(1.0, 0.1, self.pop_size) # Assign weights from best to worst\n                    weights /= weights.sum() # Normalize weights\n\n                    # Adjust weights based on individual diversity (distance to the mean)\n                    mean_position = np.mean(self.pop, axis=0)\n                    distances = np.linalg.norm(self.pop - mean_position, axis=1)\n                    diversity_weights = distances / np.sum(distances)\n                    \n                    # Combine fitness and diversity weights\n                    combined_weights = 0.7 * weights + 0.3 * diversity_weights\n                    combined_weights /= combined_weights.sum()\n\n                    # Allocate fevals, ensuring minimum allocation\n                    new_fevals_per_individual = (combined_weights * remaining_fevals).astype(int) + self.min_fevals_per_individual\n                    \n                    # Ensure that the total fevals do not exceed remaining budget\n                    if np.sum(new_fevals_per_individual) > remaining_fevals:\n                        diff = np.sum(new_fevals_per_individual) - remaining_fevals\n                        new_fevals_per_individual[ranked_indices[-diff:]] -= 1\n\n                    self.fevals_per_individual = new_fevals_per_individual\n            \n            # Stagnation handling\n            if self.stagnation_counter > self.stagnation_tolerance:\n                # Local restart: perturb the best individual using a Cauchy distribution\n                cauchy_scale = 0.05 * (func.bounds.ub - func.bounds.lb)\n                perturbation = np.random.standard_cauchy(self.dim) * cauchy_scale\n                self.pop[self.best_idx] = self.x_opt + perturbation\n                self.pop[self.best_idx] = np.clip(self.pop[self.best_idx], func.bounds.lb, func.bounds.ub)\n                self.fitness[self.best_idx] = func(self.pop[self.best_idx])\n                fevals += 1\n                self.stagnation_counter = 0  # Reset stagnation counter\n            \n            if self.global_restart_counter > self.global_restart_patience:\n                # Global restart: re-initialize population (excluding best) with bias toward the current best\n                for i in range(self.pop_size):\n                    if i != self.best_idx:\n                        direction = self.x_opt - self.pop[i]\n                        new_solution = self.x_opt + 0.5 * direction + np.random.normal(0, 0.1 * (func.bounds.ub - func.bounds.lb), self.dim)\n                        new_solution = np.clip(new_solution, func.bounds.lb, func.bounds.ub)\n                        self.pop[i] = new_solution\n                        self.fitness[i] = func(self.pop[i])\n                        fevals += 1\n                self.global_restart_counter = 0\n                self.stagnation_counter = 0\n                if fevals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "An exception occurred: local variable 'success_rate' referenced before assignment.", "error": "", "parent_ids": ["e1011cb1-1641-4bf0-ba1f-b8fe603c3637"], "operator": null, "metadata": {}}
{"id": "e66f79ba-5343-4bce-8ad4-d0ec284df465", "fitness": 0.3642678275921566, "name": "KrillDE", "description": "An adaptive Differential Evolution strategy that dynamically adjusts its population size, mutation strategy, and search range based on the function's landscape and optimization progress using a combination of Krill Herd optimization and success-history adaptation.", "code": "import numpy as np\n\nclass KrillDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100,\n                 F=0.5, Cr=0.9, archive_size=10, success_memory=10, local_search_prob=0.1,\n                 N_max=0.01, V_f=0.01, D_max=0.005, stagnation_tolerance=50):\n        \"\"\"\n        Krill Herd inspired Differential Evolution with adaptive parameters and dynamic population size.\n        Incorporates Krill-like movement influences (induced motion, foraging motion, random diffusion)\n        to enhance exploration and exploitation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            initial_pop_size (int): The initial population size.\n            min_pop_size (int): The minimum population size.\n            max_pop_size (int): The maximum population size.\n            F (float): The initial scaling factor for differential variation.\n            Cr (float): The initial crossover rate.\n            archive_size (int): Size of archive for storing successful F and Cr values.\n            success_memory (int): Size of memory for storing successful F and Cr values for adaptation.\n            local_search_prob (float): Probability of performing local search.\n            N_max (float): Maximum induced motion.\n            V_f (float): Foraging speed.\n            D_max (float): Maximum diffusion speed.\n            stagnation_tolerance (int): Number of iterations without improvement before triggering restart.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.pop_size = initial_pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.archive_F = np.full(archive_size, F)\n        self.archive_Cr = np.full(archive_size, Cr)\n        self.archive_idx = 0\n        self.archive_size = archive_size\n        self.success_F_memory = []\n        self.success_Cr_memory = []\n        self.success_memory = success_memory\n        self.local_search_prob = local_search_prob\n        self.N_max = N_max\n        self.V_f = V_f\n        self.D_max = D_max\n        self.stagnation_tolerance = stagnation_tolerance\n        self.stagnation_counter = 0\n        self.global_restart_patience = 3 * stagnation_tolerance\n        self.global_restart_counter = 0\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Krill Herd inspired Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n        success_count = 0\n        iteration = 0\n\n        while fevals < self.budget:\n            iteration += 1\n            old_f_opt = self.f_opt\n\n            # Calculate induced motion, foraging motion, and diffusion for each krill\n            induced_motion = self.N_max * self._calculate_induced_motion(func)\n            foraging_motion = self.V_f * self._calculate_foraging_motion(func)\n            diffusion = self.D_max * np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n            for i in range(self.pop_size):\n                if fevals >= self.budget:\n                    break\n\n                # Parameter Adaptation\n                if self.success_F_memory:\n                    F = np.random.choice(self.success_F_memory)\n                    Cr = np.random.choice(self.success_Cr_memory)\n                else:\n                    F = self.F\n                    Cr = self.Cr\n\n                # Mutation: current-to-best/1 with Krill influence\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.pop[indices]\n                x_mutated = self.pop[i] + F * (self.pop[self.best_idx] - self.pop[i]) + F * (x_r1 - x_r2) + \\\n                             induced_motion[i] + foraging_motion[i] + diffusion[i]\n                x_mutated = np.clip(x_mutated, lb, ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Local Search with probability\n                if np.random.rand() < self.local_search_prob:\n                    step_size = 0.01 * (ub - lb)\n                    x_trial += np.random.normal(0, step_size, self.dim)\n                    x_trial = np.clip(x_trial, lb, ub)\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.success_F_memory.append(F)\n                    self.success_Cr_memory.append(Cr)\n\n                    if len(self.success_F_memory) > self.success_memory:\n                        self.success_F_memory.pop(0)\n                        self.success_Cr_memory.pop(0)\n\n                    success_count += 1\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n\n            # Stagnation Detection\n            if self.f_opt >= old_f_opt:\n                self.stagnation_counter += 1\n                self.global_restart_counter += 1\n            else:\n                self.stagnation_counter = 0\n                self.global_restart_counter = 0\n\n            # Update archive with successful F and Cr values using a weighted average\n            if self.success_F_memory:\n                weights = np.linspace(0.1, 1.0, len(self.success_F_memory))\n                weights /= weights.sum()\n\n                weighted_avg_F = np.average(self.success_F_memory, weights=weights)\n                weighted_avg_Cr = np.average(self.success_Cr_memory, weights=weights)\n\n                self.archive_F[self.archive_idx] = weighted_avg_F\n                self.archive_Cr[self.archive_idx] = weighted_avg_Cr\n\n                self.archive_idx = (self.archive_idx + 1) % self.archive_size\n\n            # Adjust population size based on success rate\n            success_rate = success_count / self.pop_size\n            success_count = 0\n\n            if success_rate > 0.2 and self.pop_size < self.max_pop_size:\n                self.pop_size = min(self.pop_size + 1, self.max_pop_size)\n                new_individual = np.random.uniform(lb, ub, size=(1, self.dim))\n                self.pop = np.vstack((self.pop, new_individual))\n                self.fitness = np.append(self.fitness, func(new_individual[0]))\n                fevals += 1\n                if self.fitness[-1] < self.f_opt:\n                    self.f_opt = self.fitness[-1]\n                    self.x_opt = self.pop[-1]\n                    self.best_idx = self.pop_size - 1\n\n            elif success_rate < 0.05 and self.pop_size > self.min_pop_size:\n                ranked_indices = np.argsort(self.fitness)[::-1]\n                num_to_remove = min(int(0.1 * self.pop_size), self.pop_size - self.min_pop_size)\n                indices_to_remove = ranked_indices[:num_to_remove]\n\n                self.pop = np.delete(self.pop, indices_to_remove, axis=0)\n                self.fitness = np.delete(self.fitness, indices_to_remove)\n                self.pop_size -= num_to_remove\n                self.best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n\n            # Stagnation handling\n            if self.stagnation_counter > self.stagnation_tolerance:\n                # Local restart: perturb the best individual\n                self.pop[self.best_idx] = self.x_opt + np.random.normal(0, 0.05 * (ub - lb), self.dim)\n                self.pop[self.best_idx] = np.clip(self.pop[self.best_idx], lb, ub)\n                self.fitness[self.best_idx] = func(self.pop[self.best_idx])\n                fevals += 1\n                self.stagnation_counter = 0  # Reset stagnation counter\n\n            if self.global_restart_counter > self.global_restart_patience:\n                # Global restart: re-initialize population (excluding best)\n                for i in range(self.pop_size):\n                    if i != self.best_idx:\n                        self.pop[i] = np.random.uniform(lb, ub, self.dim)\n                        self.fitness[i] = func(self.pop[i])\n                        fevals += 1\n                self.global_restart_counter = 0\n                self.stagnation_counter = 0\n                if fevals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt\n\n    def _calculate_induced_motion(self, func):\n        \"\"\"Calculates the induced motion component of Krill movement.\"\"\"\n        lb, ub = func.bounds.lb, func.bounds.ub\n        induced_motion = np.zeros((self.pop_size, self.dim))\n        for i in range(self.pop_size):\n            # Calculate attraction towards the best krill\n            attraction = 2 * (np.exp(-2 / self.pop_size) * (self.pop[self.best_idx] - self.pop[i]) / (ub - lb))\n            induced_motion[i] += attraction\n\n            # Calculate repulsion from the worst krill\n            worst_idx = np.argmax(self.fitness)\n            repulsion = -2 * (np.exp(-2 / self.pop_size) * (self.pop[worst_idx] - self.pop[i]) / (ub - lb))\n            induced_motion[i] += repulsion\n\n        return induced_motion\n\n    def _calculate_foraging_motion(self, func):\n        \"\"\"Calculates the foraging motion component of Krill movement.\"\"\"\n        lb, ub = func.bounds.lb, func.bounds.ub\n        foraging_motion = np.zeros((self.pop_size, self.dim))\n        for i in range(self.pop_size):\n            # Estimate food location based on fitness\n            food_location = self.pop[self.best_idx]  # Simplification: Assume best krill knows food\n            foraging_motion[i] = 2 * (np.random.rand(self.dim) * (food_location - self.pop[i]) / (ub - lb))\n        return foraging_motion", "configspace": "", "generation": 7, "feedback": "The algorithm KrillDE scored 0.364 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e1011cb1-1641-4bf0-ba1f-b8fe603c3637"], "operator": null, "metadata": {"aucs": [0.2880461760958586, 0.59747106463404, 0.5715540696387278, 0]}}
{"id": "d3521816-dc64-4307-bed1-fc5a7569404e", "fitness": 0.4152634509417455, "name": "CooperativeSwarm", "description": "Improved Cooperative Swarm with adaptive exploration pressure, a self-adaptive learning strategy, and Cauchy mutation for enhanced local search.", "code": "import numpy as np\n\nclass CooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=10, inertia_range=(0.4, 0.9),\n                 cognitive_coeff_range=(1.5, 2.0), social_coeff_range=(1.5, 2.0), initial_exploration_pressure=0.1,\n                 restart_trigger=0.05, stagnation_threshold=100, exploration_decay=0.995, cauchy_mutation_rate=0.05):\n        \"\"\"\n        Cooperative Swarm Optimization algorithm with adaptive parameters, dynamic sub-swarm communication,\n        restart mechanism, adaptive exploration pressure, self-adaptive learning, and Cauchy mutation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            num_swarms (int): The number of sub-swarms.\n            swarm_size (int): The size of each sub-swarm.\n            inertia_range (tuple): Range for inertia weight adaptation.\n            cognitive_coeff_range (tuple): Range for cognitive coefficient adaptation.\n            social_coeff_range (tuple): Range for social coefficient adaptation.\n            initial_exploration_pressure (float): Initial probability of exploring a new region instead of exploiting.\n            restart_trigger (float): Trigger for swarm restart based on stagnation.\n            stagnation_threshold (int): Number of iterations without improvement before considering stagnation.\n            exploration_decay (float): Decay rate for exploration pressure.\n            cauchy_mutation_rate (float): Probability of applying Cauchy mutation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_range = inertia_range\n        self.cognitive_coeff_range = cognitive_coeff_range\n        self.social_coeff_range = social_coeff_range\n        self.exploration_pressure = initial_exploration_pressure\n        self.initial_exploration_pressure = initial_exploration_pressure\n        self.restart_trigger = restart_trigger\n        self.stagnation_threshold = stagnation_threshold\n        self.exploration_decay = exploration_decay\n        self.cauchy_mutation_rate = cauchy_mutation_rate\n        self.swarms = []\n        self.personal_best_positions = []\n        self.personal_best_fitness = []\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.stagnation_counter = 0\n\n        # Self-adaptive learning parameters\n        self.success_rates = np.zeros(self.num_swarms)\n        self.learning_rates = np.ones(self.num_swarms) * 0.1\n\n    def initialize_swarm(self, func):\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.fevals += self.swarm_size\n        return swarm, fitness\n\n    def update_personal_best(self, swarm, fitness):\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n        return personal_best_positions, personal_best_fitness\n\n    def adapt_parameters(self):\n        \"\"\"Adapt inertia, cognitive, and social coefficients.\"\"\"\n        self.inertia = np.random.uniform(self.inertia_range[0], self.inertia_range[1])\n        self.cognitive_coeff = np.random.uniform(self.cognitive_coeff_range[0], self.cognitive_coeff_range[1])\n        self.social_coeff = np.random.uniform(self.social_coeff_range[0], self.social_coeff_range[1])\n\n    def cauchy_mutation(self, x):\n        \"\"\"Apply Cauchy mutation to a particle.\"\"\"\n        mutation = np.random.standard_cauchy(size=self.dim)\n        return x + 0.01 * mutation  # Scale the mutation\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Cooperative Swarm Optimization.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        # Initialize swarms\n        for _ in range(self.num_swarms):\n            swarm, fitness = self.initialize_swarm(func)\n            self.swarms.append(swarm)\n            personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n            self.personal_best_positions.append(personal_best_positions)\n            self.personal_best_fitness.append(personal_best_fitness)\n\n            # Update global best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.global_best_fitness:\n                self.global_best_fitness = fitness[best_idx]\n                self.global_best_position = swarm[best_idx].copy()\n                self.stagnation_counter = 0\n\n        velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n\n        while self.fevals < self.budget:\n            old_global_best_fitness = self.global_best_fitness\n\n            for i in range(self.num_swarms):\n                swarm = self.swarms[i]\n                personal_best_positions = self.personal_best_positions[i]\n                personal_best_fitness = self.personal_best_fitness[i]\n                velocity = velocities[i]\n\n                # Update velocities and positions\n                r1 = np.random.rand(self.swarm_size, self.dim)\n                r2 = np.random.rand(self.swarm_size, self.dim)\n\n                # Cooperative component: Influence from other swarms' best\n                cooperative_influence = np.zeros((self.swarm_size, self.dim))\n                num_contributing_swarms = 0\n                for j in range(self.num_swarms):\n                    if i != j:\n                        best_idx_other = np.argmin(self.personal_best_fitness[j])\n                        if self.personal_best_fitness[j][best_idx_other] < np.min(personal_best_fitness):\n                            cooperative_influence += (self.personal_best_positions[j][best_idx_other] - swarm)\n                            num_contributing_swarms += 1\n                if num_contributing_swarms > 0:\n                    cooperative_influence /= num_contributing_swarms\n\n                # Adapt parameters\n                self.adapt_parameters()\n\n                velocity = (self.inertia * velocity\n                            + self.cognitive_coeff * r1 * (personal_best_positions - swarm)\n                            + self.social_coeff * r2 * (self.global_best_position - swarm)\n                            + self.learning_rates[i] * cooperative_influence) # Adaptive learning rate for coop influence\n\n                new_swarm = swarm + velocity\n\n                # Exploration: Introduce random search with adaptive probability\n                for k in range(self.swarm_size):\n                    if np.random.rand() < self.exploration_pressure:\n                        new_swarm[k] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Explore\n                    elif np.random.rand() < self.cauchy_mutation_rate:\n                        new_swarm[k] = self.cauchy_mutation(new_swarm[k])\n\n\n                new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n                new_fitness = np.array([func(x) for x in new_swarm])\n                self.fevals += self.swarm_size\n\n                # Update personal best\n                improvement = new_fitness < personal_best_fitness\n                num_improvements = np.sum(improvement)\n                personal_best_positions[improvement] = new_swarm[improvement].copy()\n                personal_best_fitness[improvement] = new_fitness[improvement].copy()\n\n                self.swarms[i] = new_swarm\n                self.personal_best_positions[i] = personal_best_positions\n                self.personal_best_fitness[i] = personal_best_fitness\n                velocities[i] = velocity\n\n                # Update global best\n                best_idx = np.argmin(personal_best_fitness)\n                if personal_best_fitness[best_idx] < self.global_best_fitness:\n                    self.global_best_fitness = personal_best_fitness[best_idx]\n                    self.global_best_position = personal_best_positions[best_idx].copy()\n                    self.stagnation_counter = 0\n\n                # Self-adaptive learning rate update\n                self.success_rates[i] = 0.9 * self.success_rates[i] + 0.1 * (num_improvements / self.swarm_size)\n                if self.success_rates[i] > 0.2:\n                    self.learning_rates[i] *= 1.1  # Increase learning rate if successful\n                else:\n                    self.learning_rates[i] *= 0.9  # Decrease learning rate if not successful\n                self.learning_rates[i] = np.clip(self.learning_rates[i], 0.01, 0.5) # Keep rate within bounds\n\n\n                if self.fevals >= self.budget:\n                    break\n\n            # Stagnation check and restart\n            if self.global_best_fitness >= old_global_best_fitness:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                if np.random.rand() < self.restart_trigger:\n                    for i in range(self.num_swarms):\n                        swarm, fitness = self.initialize_swarm(func)\n                        self.swarms[i] = swarm\n                        personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n                        self.personal_best_positions[i] = personal_best_positions\n                        self.personal_best_fitness[i] = personal_best_fitness\n\n                        best_idx = np.argmin(fitness)\n                        if fitness[best_idx] < self.global_best_fitness:\n                            self.global_best_fitness = fitness[best_idx]\n                            self.global_best_position = swarm[best_idx].copy()\n                            self.stagnation_counter = 0\n\n                    velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter = 0\n\n            # Adaptive Exploration Pressure\n            self.exploration_pressure *= self.exploration_decay\n            self.exploration_pressure = max(self.exploration_pressure, 0.001) # Avoid vanishing exploration\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm CooperativeSwarm scored 0.415 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["077c669e-20b2-4e2c-9d1c-6c2f58c62a80"], "operator": null, "metadata": {"aucs": [0.19377028651200423, 0.3020149521145491, 0.4273975390455561, 0.7017563011602223, 0.25193404803952535, 0.4860205783410667, 0.2967980452971932, 0.39918557292158574, 0.3814274892703411, 0.3328522002873274, 0.4955286315984886, 0.9944627917981023, 0.2711853816052935, 0.277654873718741, 0.5880886439627376, 0.35215506956325826, 0.31246117145819086, 0.5163301808256588, 0.23646771832049684, 0.4877775429945702]}}
{"id": "ae6f5893-d06d-442b-9527-e8e13967c810", "fitness": 0.5562306771560604, "name": "HybridPSO", "description": "Hybrid PSO with SHADE-inspired adaptation, velocity clamping, and an adaptive mutation strategy based on the swarm's diversity.", "code": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=30, inertia_max=0.9, inertia_min=0.2,\n                 cognitive_coeff=2.0, social_coeff=2.0, levy_exponent=1.5, p_mutation_max=0.1, p_mutation_min=0.01, sh_size=5, velocity_clamp=2.0):\n        \"\"\"\n        Hybrid Particle Swarm Optimization with Lvy flight, SHADE-inspired adaptation, and adaptive mutation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            swarm_size (int): The size of the swarm.\n            inertia_max (float): Maximum inertia weight.\n            inertia_min (float): Minimum inertia weight.\n            cognitive_coeff (float): Cognitive coefficient.\n            social_coeff (float): Social coefficient.\n            levy_exponent (float): Exponent for Lvy flight distribution.\n            p_mutation_max (float): Maximum probability of applying mutation.\n            p_mutation_min (float): Minimum probability of applying mutation.\n            sh_size (int): Size of the success history archive.\n            velocity_clamp (float): Maximum velocity value.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.levy_exponent = levy_exponent\n        self.p_mutation_max = p_mutation_max\n        self.p_mutation_min = p_mutation_min\n        self.sh_size = sh_size\n        self.swarm = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.success_history = []  # store successful parameter changes (inertia)\n        self.memory_inertia = np.full(self.sh_size, (inertia_max + inertia_min) / 2)  # initialize memory\n        self.velocity_clamp = velocity_clamp\n\n    def levy_flight(self, size):\n        \"\"\"\n        Generates Lvy flight steps.\n        \"\"\"\n        u = np.random.normal(0, 1, size=size)\n        v = np.random.normal(0, 1, size=size)\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) /\n                 (np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * (2 ** ((self.levy_exponent - 1) / 2)))) ** (1 / self.levy_exponent)\n        step = sigma * u / abs(v) ** (1 / self.levy_exponent)\n        return step\n\n    def initialize_swarm(self, func):\n        \"\"\"\n        Initializes the swarm with random positions and velocities.\n        \"\"\"\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim))  # Initialize velocities\n        fitness = np.array([func(x) for x in self.swarm])\n        self.fevals += self.swarm_size\n        self.personal_best_positions = self.swarm.copy()\n        self.personal_best_fitness = fitness.copy()\n        self.global_best_fitness = np.min(fitness)\n        self.global_best_position = self.swarm[np.argmin(fitness)].copy()\n\n    def update_parameters(self):\n        \"\"\"\n        Update parameters based on success history (SHADE-inspired).\n        \"\"\"\n        if self.success_history:\n            # Sample from success history\n            sampled_inertia = np.random.choice(self.success_history)\n            inertia = sampled_inertia\n        else:\n            # If no successful history, use mean of memory\n            inertia = np.mean(self.memory_inertia)\n\n        inertia = np.clip(inertia, self.inertia_min, self.inertia_max)  # ensure bounds\n        return inertia\n\n    def calculate_diversity(self):\n        \"\"\"\n        Calculates the diversity of the swarm based on the average distance to the swarm's centroid.\n        \"\"\"\n        centroid = np.mean(self.swarm, axis=0)\n        distances = np.linalg.norm(self.swarm - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Hybrid PSO.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.initialize_swarm(func)\n\n        while self.fevals < self.budget:\n            inertia = self.update_parameters()\n            diversity = self.calculate_diversity()\n\n            # Adaptive mutation probability\n            p_mutation = self.p_mutation_min + (self.p_mutation_max - self.p_mutation_min) * (1 - diversity / (func.bounds.ub[0] - func.bounds.lb[0]))  # Scale with diversity\n\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                self.velocities[i] = (inertia * self.velocities[i] +\n                                       self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.swarm[i]) +\n                                       self.social_coeff * r2 * (self.global_best_position - self.swarm[i]))\n                \n                # Velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = self.swarm[i] + self.velocities[i]\n\n                # Lvy flight-based exploration\n                if np.random.rand() < p_mutation:\n                    levy_steps = self.levy_flight(self.dim)\n                    new_position += 0.01 * levy_steps  # Scale the steps\n\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.fevals += 1\n\n                # Update personal best\n                if new_fitness < self.personal_best_fitness[i]:\n                    delta = self.personal_best_fitness[i] - new_fitness  # fitness improvement\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    # Update success history\n                    self.success_history.append(inertia)\n                    if len(self.success_history) > self.sh_size:\n                        self.success_history.pop(0)  # FIFO\n\n                    # update memory of inertia values\n                    self.memory_inertia = np.roll(self.memory_inertia, 1)\n                    self.memory_inertia[0] = inertia  # store current inertia used\n\n                self.swarm[i] = new_position\n\n                # Update global best\n                if new_fitness < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness\n                    self.global_best_position = new_position.copy()\n\n                if self.fevals >= self.budget:\n                    break\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSO scored 0.556 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["98e3d059-98f6-4809-9b2c-7477460a1966"], "operator": null, "metadata": {"aucs": [0.24023822382447213, 0.22364521946452287, 0.5628695485833848, 0.9270198292774676, 0.26283240188331913, 0.6029105230440512, 0.5684323253214595, 0.5475486554778349, 0.6730021788127076, 0.2874310394865339, 0.897022820701422, 0.9986486710114233, 0.267025133732367, 0.48584685848512965, 0.89351931693894, 0.6943320309216077, 0.38326694849274523, 0.8438188147198828, 0.24533573609589499, 0.5198672668460416]}}
{"id": "987ae7d9-98be-4e84-859a-426e464f0a82", "fitness": 0.5008394718882794, "name": "CooperativeSwarmOL", "description": "Implements a cooperative swarm with orthogonal learning to enhance diversity and convergence by allowing particles to learn from orthogonal projections of the search space, and introduces a success-history based parameter adaptation.", "code": "import numpy as np\n\nclass CooperativeSwarmOL:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=10, inertia_range=(0.4, 0.9),\n                 cognitive_coeff_range=(1.5, 2.0), social_coeff_range=(1.5, 2.0), exploration_pressure=0.1,\n                 restart_trigger=0.05, ol_rate=0.1, learning_rate_inertia=0.1, learning_rate_cognitive=0.1, learning_rate_social=0.1):\n        \"\"\"\n        Cooperative Swarm Optimization algorithm with orthogonal learning, adaptive parameters,\n        dynamic sub-swarm communication and restart mechanism.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            num_swarms (int): The number of sub-swarms.\n            swarm_size (int): The size of each sub-swarm.\n            inertia_range (tuple): Range for inertia weight adaptation.\n            cognitive_coeff_range (tuple): Range for cognitive coefficient adaptation.\n            social_coeff_range (tuple): Range for social coefficient adaptation.\n            exploration_pressure (float): Probability of exploring a new region instead of exploiting.\n            restart_trigger (float): Trigger for swarm restart based on stagnation.\n            ol_rate (float): Rate of orthogonal learning.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_range = inertia_range\n        self.cognitive_coeff_range = cognitive_coeff_range\n        self.social_coeff_range = social_coeff_range\n        self.exploration_pressure = exploration_pressure\n        self.restart_trigger = restart_trigger\n        self.ol_rate = ol_rate\n        self.swarms = []\n        self.personal_best_positions = []\n        self.personal_best_fitness = []\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.stagnation_counter = 0\n        self.max_stagnation = 100 #arbitrary value, adjust based on the problem\n\n        # Success history adaptation\n        self.success_inertia = []\n        self.success_cognitive = []\n        self.success_social = []\n        self.learning_rate_inertia = learning_rate_inertia\n        self.learning_rate_cognitive = learning_rate_cognitive\n        self.learning_rate_social = learning_rate_social\n\n        self.inertia = np.random.uniform(self.inertia_range[0], self.inertia_range[1])\n        self.cognitive_coeff = np.random.uniform(self.cognitive_coeff_range[0], self.cognitive_coeff_range[1])\n        self.social_coeff = np.random.uniform(self.social_coeff_range[0], self.social_coeff_range[1])\n\n    def initialize_swarm(self, func):\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.fevals += self.swarm_size\n        return swarm, fitness\n\n    def update_personal_best(self, swarm, fitness):\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n        return personal_best_positions, personal_best_fitness\n\n    def adapt_parameters(self, delta_f):\n        \"\"\"Adapt inertia, cognitive, and social coefficients based on success history.\"\"\"\n        # Update inertia weight\n        if len(self.success_inertia) > 0:\n            success_rate_inertia = np.mean(self.success_inertia[-10:])  # Average over last 10 successes\n            self.inertia = self.inertia + self.learning_rate_inertia * (success_rate_inertia - 0.5)\n            self.inertia = np.clip(self.inertia, self.inertia_range[0], self.inertia_range[1])\n\n        # Update cognitive coefficient\n        if len(self.success_cognitive) > 0:\n            success_rate_cognitive = np.mean(self.success_cognitive[-10:])\n            self.cognitive_coeff = self.cognitive_coeff + self.learning_rate_cognitive * (success_rate_cognitive - 0.5)\n            self.cognitive_coeff = np.clip(self.cognitive_coeff, self.cognitive_coeff_range[0], self.cognitive_coeff_range[1])\n\n        # Update social coefficient\n        if len(self.success_social) > 0:\n            success_rate_social = np.mean(self.success_social[-10:])\n            self.social_coeff = self.social_coeff + self.learning_rate_social * (success_rate_social - 0.5)\n            self.social_coeff = np.clip(self.social_coeff, self.social_coeff_range[0], self.social_coeff_range[1])\n\n    def orthogonal_learning(self, x, func):\n        \"\"\"Perform orthogonal learning.\"\"\"\n        basis = np.random.randn(self.dim, self.dim)\n        q, r = np.linalg.qr(basis)\n        d = np.diag(r)\n        phase = np.sign(d)\n        q = np.multiply(q, phase)\n\n        new_x = x.copy()\n        delta = np.random.uniform(-1, 1, size=self.dim)\n        new_x += self.ol_rate * np.dot(q, delta)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Cooperative Swarm Optimization.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        # Initialize swarms\n        for _ in range(self.num_swarms):\n            swarm, fitness = self.initialize_swarm(func)\n            self.swarms.append(swarm)\n            personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n            self.personal_best_positions.append(personal_best_positions)\n            self.personal_best_fitness.append(personal_best_fitness)\n\n            # Update global best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.global_best_fitness:\n                self.global_best_fitness = fitness[best_idx]\n                self.global_best_position = swarm[best_idx].copy()\n                self.stagnation_counter = 0 #reset counter if we improve\n\n        velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n\n        while self.fevals < self.budget:\n            old_global_best_fitness = self.global_best_fitness  # Store the previous global best\n\n            for i in range(self.num_swarms):\n                swarm = self.swarms[i]\n                personal_best_positions = self.personal_best_positions[i]\n                personal_best_fitness = self.personal_best_fitness[i]\n                velocity = velocities[i]\n\n                # Update velocities and positions\n                r1 = np.random.rand(self.swarm_size, self.dim)\n                r2 = np.random.rand(self.swarm_size, self.dim)\n\n                # Cooperative component: Influence from other swarms' best\n                cooperative_influence = np.zeros((self.swarm_size, self.dim))\n                num_contributing_swarms = 0\n                for j in range(self.num_swarms):\n                    if i != j:\n                        best_idx_other = np.argmin(self.personal_best_fitness[j])\n                        # Dynamic communication: only influence from better swarms\n                        if self.personal_best_fitness[j][best_idx_other] < np.min(personal_best_fitness):\n                            cooperative_influence += (self.personal_best_positions[j][best_idx_other] - swarm)\n                            num_contributing_swarms += 1\n                if num_contributing_swarms > 0:\n                    cooperative_influence /= num_contributing_swarms # Average influence\n\n                # Adapt parameters\n                self.adapt_parameters(old_global_best_fitness - self.global_best_fitness)\n\n                velocity = (self.inertia * velocity\n                            + self.cognitive_coeff * r1 * (personal_best_positions - swarm)\n                            + self.social_coeff * r2 * (self.global_best_position - swarm)\n                            + 0.1 * cooperative_influence) # Add cooperative influence with a small weight\n\n                new_swarm = swarm + velocity\n\n                # Exploration: Introduce random search with probability exploration_pressure\n                for k in range(self.swarm_size):\n                    if np.random.rand() < self.exploration_pressure:\n                        new_swarm[k] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Explore\n\n                # Orthogonal Learning\n                for k in range(self.swarm_size):\n                    if np.random.rand() < self.ol_rate:\n                        new_swarm[k] = self.orthogonal_learning(new_swarm[k], func)\n\n                new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n                new_fitness = np.array([func(x) for x in new_swarm])\n                self.fevals += self.swarm_size\n\n                # Update personal best\n                improvement = new_fitness < personal_best_fitness\n                personal_best_positions[improvement] = new_swarm[improvement].copy()\n                personal_best_fitness[improvement] = new_fitness[improvement].copy()\n\n                self.swarms[i] = new_swarm\n                self.personal_best_positions[i] = personal_best_positions\n                self.personal_best_fitness[i] = personal_best_fitness\n                velocities[i] = velocity\n\n                # Update global best\n                best_idx = np.argmin(personal_best_fitness)\n                if personal_best_fitness[best_idx] < self.global_best_fitness:\n                    self.success_inertia.append(1)\n                    self.success_cognitive.append(1)\n                    self.success_social.append(1)\n                    self.global_best_fitness = personal_best_fitness[best_idx]\n                    self.global_best_position = personal_best_positions[best_idx].copy()\n                    self.stagnation_counter = 0 # Reset stagnation counter when a better solution is found\n                else:\n                    self.success_inertia.append(0)\n                    self.success_cognitive.append(0)\n                    self.success_social.append(0)\n                \n                if self.fevals >= self.budget:\n                    break\n\n            # Stagnation check and restart\n            if self.global_best_fitness >= old_global_best_fitness: # No improvement\n                self.stagnation_counter += 1\n            else:\n                 self.stagnation_counter = 0 # Reset stagnation counter when a better solution is found\n            \n            if self.stagnation_counter > self.max_stagnation:\n                # Restart the swarm\n                if np.random.rand() < self.restart_trigger:  # Probabilistic restart\n                    for i in range(self.num_swarms):\n                        swarm, fitness = self.initialize_swarm(func)\n                        self.swarms[i] = swarm\n                        personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n                        self.personal_best_positions[i] = personal_best_positions\n                        self.personal_best_fitness[i] = personal_best_fitness\n\n                        best_idx = np.argmin(fitness)\n                        if fitness[best_idx] < self.global_best_fitness:\n                            self.global_best_fitness = fitness[best_idx]\n                            self.global_best_position = swarm[best_idx].copy()\n                            self.stagnation_counter = 0 #reset counter if we improve\n\n                    velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n                    self.stagnation_counter = 0 #reset counter after restart\n                else:\n                    self.stagnation_counter = 0 #reset counter even if no restart to prevent continuous restarts\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm CooperativeSwarmOL scored 0.501 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["077c669e-20b2-4e2c-9d1c-6c2f58c62a80"], "operator": null, "metadata": {"aucs": [0.20246776109897768, 0.19405316329502798, 0.5530514953702101, 0.916062791456624, 0.25726408150308067, 0.6608956884858213, 0.3169486474284119, 0.45743463469879353, 0.6013986341111535, 0.23398311833770535, 0.5752263255144294, 0.9983027990316479, 0.26946385260934325, 0.3581641663347982, 0.8138434806356742, 0.6890436851198021, 0.35777185532057487, 0.8334927881411583, 0.22861839419503072, 0.49930207507732116]}}
{"id": "8de81a8b-1970-419c-809a-26c9c3c21561", "fitness": -Infinity, "name": "SelfOrganizingOptimDE", "description": "A self-organizing optimization algorithm using a dynamic fitness landscape and reinforcement learning to guide search behavior, balancing exploration and exploitation through landscape deformation and policy adaptation.", "code": "import numpy as np\n\nclass SelfOrganizingOptimDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, lr=0.1, landscape_param=0.1, exploration_prob=0.1, exploitation_prob=0.8, adaptation_interval=10):\n        \"\"\"\n        Self-Organizing Optimization with Dynamic Landscape and Reinforcement Learning.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            F (float): The scaling factor for differential variation.\n            Cr (float): The crossover rate.\n            lr (float): Learning rate for policy adaptation.\n            landscape_param (float): Parameter controlling the dynamic landscape deformation.\n            exploration_prob (float): Initial probability of exploration.\n            exploitation_prob (float): Initial probability of exploitation.\n            adaptation_interval (int): Interval for policy and landscape adaptation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lr = lr\n        self.landscape_param = landscape_param\n        self.exploration_prob = exploration_prob\n        self.exploitation_prob = exploitation_prob\n        self.adaptation_interval = adaptation_interval\n\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.deformed_fitness = None\n        self.iteration = 0\n\n    def dynamic_landscape(self, x, f, x_best, f_best):\n        \"\"\"\n        Deforms the fitness landscape based on the current best solution.\n        \"\"\"\n        distance = np.linalg.norm(x - x_best)\n        deformation = self.landscape_param * np.exp(-distance**2 / (2 * (self.dim**2))) * (f - f_best)\n        return f - deformation\n\n    def choose_action(self):\n        \"\"\"\n        Selects an action (exploration or exploitation) based on probabilities.\n        \"\"\"\n        if np.random.rand() < self.exploration_prob:\n            return \"explore\"\n        else:\n            return \"exploit\"\n\n    def update_policy(self, reward):\n        \"\"\"\n        Updates exploration and exploitation probabilities based on the reward.\n        \"\"\"\n        if reward > 0:\n            # Success: increase probability of the action taken\n            if self.last_action == \"explore\":\n                self.exploration_prob += self.lr * reward * (1 - self.exploration_prob)\n                self.exploitation_prob -= self.lr * reward * self.exploitation_prob\n            else:  # self.last_action == \"exploit\":\n                self.exploitation_prob += self.lr * reward * (1 - self.exploitation_prob)\n                self.exploration_prob -= self.lr * reward * self.exploration_prob\n        else:\n            # Failure: decrease probability of the action taken\n            if self.last_action == \"explore\":\n                self.exploration_prob -= self.lr * abs(reward) * self.exploration_prob\n                self.exploitation_prob += self.lr * abs(reward) * (1 - self.exploitation_prob)\n            else:  # self.last_action == \"exploit\":\n                self.exploitation_prob -= self.lr * abs(reward) * self.exploitation_prob\n                self.exploration_prob += self.lr * abs(reward) * (1 - self.exploration_prob)\n\n        # Ensure probabilities stay within [0, 1]\n        self.exploration_prob = np.clip(self.exploration_prob, 0.05, 0.95)\n        self.exploitation_prob = np.clip(self.exploitation_prob, 0.05, 0.95)\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Self-Organizing Optimization.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n        fevals = self.pop_size\n\n        while fevals < self.budget:\n            self.iteration += 1\n\n            # Deform the fitness landscape\n            self.deformed_fitness = np.array([self.dynamic_landscape(x, f, self.x_opt, self.f_opt) for x, f in zip(self.pop, self.fitness)])\n\n            for i in range(self.pop_size):\n                # Choose an action: explore or exploit\n                action = self.choose_action()\n                self.last_action = action\n\n                if action == \"explore\":\n                    # Exploration: Random mutation\n                    x_mutated = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                else:\n                    # Exploitation: Differential Evolution\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F * (x_r1 - x_r2) + self.F * (self.x_opt - x_r3)\n                    x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    x_trial = np.copy(self.pop[i])\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.Cr or j == j_rand:\n                            x_trial[j] = x_mutated[j]\n                \n                # Evaluate the trial solution\n                f_trial = func(x_trial)\n                fevals += 1\n\n                # Determine the reward\n                reward = self.fitness[i] - f_trial\n\n                # Selection: Replace if the trial solution is better in the original landscape\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n                    \n                    self.update_policy(reward)\n                else:\n                    self.update_policy(-abs(reward))\n                    \n                if fevals >= self.budget:\n                    break\n\n            # Adapt exploration/exploitation probabilities periodically\n            if self.iteration % self.adaptation_interval == 0:\n                # Further refine policy based on overall performance\n                if self.f_opt < self.f_opt_prev if hasattr(self, 'f_opt_prev') else True:\n                        self.update_policy(0.1)\n                else:\n                        self.update_policy(-0.1)\n                if hasattr(self, 'f_opt_prev'):\n                    del self.f_opt_prev\n                self.f_opt_prev = self.f_opt\n                \n                # Reset the landscape parameter periodically\n                self.landscape_param = 0.1 * np.random.rand()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "An exception occurred: local variable 'x_trial' referenced before assignment.", "error": "", "parent_ids": ["e1011cb1-1641-4bf0-ba1f-b8fe603c3637"], "operator": null, "metadata": {}}
{"id": "3f1ea16d-3930-4a5e-8bbc-e752b196a8e2", "fitness": -Infinity, "name": "EnsembleSwarm", "description": "Multi-strategy Ensemble Swarm Optimization with dynamic strategy allocation, incorporating velocity mutation, orthogonal learning, and a success-history based parameter adaptation.", "code": "import numpy as np\n\nclass EnsembleSwarm:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=10,\n                 inertia_range=(0.4, 0.9), cognitive_coeff_range=(1.5, 2.0),\n                 social_coeff_range=(1.5, 2.0), mutation_rate=0.1,\n                 ol_rate=0.1, strategy_weights=None):\n        \"\"\"\n        Ensemble Swarm Optimization algorithm with multiple strategies and dynamic strategy allocation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            num_swarms (int): The number of sub-swarms.\n            swarm_size (int): The size of each sub-swarm.\n            inertia_range (tuple): Range for inertia weight adaptation.\n            cognitive_coeff_range (tuple): Range for cognitive coefficient adaptation.\n            social_coeff_range (tuple): Range for social coefficient adaptation.\n            mutation_rate (float): Mutation rate for velocity mutation strategy.\n            ol_rate (float): Orthogonal learning rate.\n            strategy_weights (list): Initial weights for each strategy. If None, defaults to equal weights.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_range = inertia_range\n        self.cognitive_coeff_range = cognitive_coeff_range\n        self.social_coeff_range = social_coeff_range\n        self.mutation_rate = mutation_rate\n        self.ol_rate = ol_rate\n        self.swarms = []\n        self.personal_best_positions = []\n        self.personal_best_fitness = []\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.velocities = []\n\n        # Define strategies\n        self.strategies = ['standard_pso', 'velocity_mutation', 'orthogonal_learning']\n        self.num_strategies = len(self.strategies)\n        if strategy_weights is None:\n            self.strategy_weights = np.ones(self.num_strategies) / self.num_strategies\n        else:\n            self.strategy_weights = np.array(strategy_weights)\n\n        self.success_history = {strategy: [] for strategy in self.strategies}  # Store successful parameter settings\n\n    def initialize_swarm(self, func):\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.fevals += self.swarm_size\n        return swarm, fitness\n\n    def update_personal_best(self, swarm, fitness):\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n        return personal_best_positions, personal_best_fitness\n\n    def adapt_parameters(self, strategy):\n        \"\"\"Adapt inertia, cognitive, and social coefficients based on success history.\"\"\"\n        if self.success_history[strategy]:\n            # Sample from successful parameters\n            params = self.success_history[strategy][np.random.randint(len(self.success_history[strategy]))]\n            self.inertia = params['inertia']\n            self.cognitive_coeff = params['cognitive_coeff']\n            self.social_coeff = params['social_coeff']\n        else:\n            # If no success history, use random values\n            self.inertia = np.random.uniform(self.inertia_range[0], self.inertia_range[1])\n            self.cognitive_coeff = np.random.uniform(self.cognitive_coeff_range[0], self.cognitive_coeff_range[1])\n            self.social_coeff = np.random.uniform(self.social_coeff_range[0], self.social_coeff_range[1])\n\n    def standard_pso(self, swarm, personal_best_positions, global_best_position, velocity):\n        \"\"\"Standard PSO update.\"\"\"\n        r1 = np.random.rand(self.swarm_size, self.dim)\n        r2 = np.random.rand(self.swarm_size, self.dim)\n\n        velocity = (self.inertia * velocity\n                    + self.cognitive_coeff * r1 * (personal_best_positions - swarm)\n                    + self.social_coeff * r2 * (global_best_position - swarm))\n        new_swarm = swarm + velocity\n        return new_swarm, velocity\n\n    def velocity_mutation(self, swarm, velocity):\n        \"\"\"Velocity mutation strategy for exploration.\"\"\"\n        mutation_mask = np.random.rand(self.swarm_size, self.dim) < self.mutation_rate\n        velocity[mutation_mask] = np.random.uniform(-1, 1, size=np.sum(mutation_mask))  # Random velocity\n        new_swarm = swarm + velocity\n        return new_swarm, velocity\n\n    def orthogonal_learning(self, swarm, func):\n         \"\"\"Orthogonal Learning strategy to generate promising solutions.\"\"\"\n         new_swarm = swarm.copy()\n         for i in range(self.swarm_size):\n            if np.random.rand() < self.ol_rate:\n                 # Randomly select two dimensions\n                d1, d2 = np.random.choice(self.dim, 2, replace=False)\n\n                # Create orthogonal array (example: L9 array for 2 factors, 3 levels)\n                oa = np.array([[1, 1], [2, 3], [3, 2]])\n                levels = np.linspace(func.bounds.lb, func.bounds.ub, num=3)\n\n                # Generate new points based on orthogonal array\n                for j in range(oa.shape[0]):\n                    new_point = swarm[i].copy()\n                    new_point[d1] = levels[oa[j, 0] - 1]\n                    new_point[d2] = levels[oa[j, 1] - 1]\n                    new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness = func(new_point)\n                    self.fevals += 1\n\n                    # Replace if better\n                    current_fitness = func(swarm[i])\n                    self.fevals += 1\n                    if new_fitness < current_fitness:\n                         new_swarm[i] = new_point\n         return new_swarm, None\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Ensemble Swarm Optimization.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        # Initialize swarms\n        for _ in range(self.num_swarms):\n            swarm, fitness = self.initialize_swarm(func)\n            self.swarms.append(swarm)\n            personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n            self.personal_best_positions.append(personal_best_positions)\n            self.personal_best_fitness.append(personal_best_fitness)\n            self.velocities.append(np.zeros_like(swarm)) # Initialize velocities\n\n            # Update global best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.global_best_fitness:\n                self.global_best_fitness = fitness[best_idx]\n                self.global_best_position = swarm[best_idx].copy()\n\n        while self.fevals < self.budget:\n            for i in range(self.num_swarms):\n                # Select a strategy based on weights\n                strategy = np.random.choice(self.strategies, p=self.strategy_weights)\n                self.adapt_parameters(strategy) # Adapt parameters based on the selected strategy\n\n                swarm = self.swarms[i]\n                personal_best_positions = self.personal_best_positions[i]\n                velocity = self.velocities[i]\n\n                # Apply selected strategy\n                if strategy == 'standard_pso':\n                    new_swarm, new_velocity = self.standard_pso(swarm, personal_best_positions, self.global_best_position, velocity)\n                elif strategy == 'velocity_mutation':\n                    new_swarm, new_velocity = self.velocity_mutation(swarm, velocity)\n                elif strategy == 'orthogonal_learning':\n                    new_swarm, new_velocity = self.orthogonal_learning(swarm, func)\n                    new_velocity = velocity #keep the current velocity\n\n                new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n                new_fitness = np.array([func(x) for x in new_swarm])\n                self.fevals += self.swarm_size\n\n                # Update personal best\n                improvement = new_fitness < self.personal_best_fitness[i]\n                personal_best_positions[improvement] = new_swarm[improvement].copy()\n                self.personal_best_fitness[i][improvement] = new_fitness[improvement].copy()\n\n                # Update global best\n                best_idx = np.argmin(self.personal_best_fitness[i])\n                if self.personal_best_fitness[i][best_idx] < self.global_best_fitness:\n                    self.global_best_fitness = self.personal_best_fitness[i][best_idx]\n                    self.global_best_position = self.personal_best_positions[i][best_idx].copy()\n\n                self.swarms[i] = new_swarm\n                self.personal_best_positions[i] = personal_best_positions\n                self.velocities[i] = new_velocity\n\n                # Update strategy weights based on success (simplified)\n                if np.sum(improvement) > 0:\n                    # Reward the used strategy\n                    strategy_idx = self.strategies.index(strategy)\n                    self.strategy_weights[strategy_idx] *= 1.1\n                    self.strategy_weights /= np.sum(self.strategy_weights)  # Normalize\n\n                    # Store successful parameters\n                    self.success_history[strategy].append({\n                        'inertia': self.inertia,\n                        'cognitive_coeff': self.cognitive_coeff,\n                        'social_coeff': self.social_coeff\n                    })\n                    if len(self.success_history[strategy]) > 10: #keep the success history list bounded\n                        self.success_history[strategy].pop(0)\n\n                if self.fevals >= self.budget:\n                    break\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["077c669e-20b2-4e2c-9d1c-6c2f58c62a80"], "operator": null, "metadata": {}}
{"id": "4b8e9ea2-c87f-4a5f-98b8-d4d9ead4e8d9", "fitness": 0.41700016301233955, "name": "BioinspiredCooperativeSwarm", "description": "Bio-inspired Cooperative Swarm with adaptive exploration-exploitation balance based on swarm diversity and fitness landscape assessment.", "code": "import numpy as np\n\nclass BioinspiredCooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=10,\n                 inertia_range=(0.4, 0.9), cognitive_coeff_range=(1.5, 2.0),\n                 social_coeff_range=(1.5, 2.0), initial_exploration_rate=0.3,\n                 exploration_decay_rate=0.995, diversity_threshold=0.1,\n                 learning_factor=0.05):\n        \"\"\"\n        Bio-inspired Cooperative Swarm with adaptive exploration-exploitation balance based on swarm diversity.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            num_swarms (int): The number of sub-swarms.\n            swarm_size (int): The size of each sub-swarm.\n            inertia_range (tuple): Range for inertia weight adaptation.\n            cognitive_coeff_range (tuple): Range for cognitive coefficient adaptation.\n            social_coeff_range (tuple): Range for social coefficient adaptation.\n            initial_exploration_rate (float): Initial probability of exploration.\n            exploration_decay_rate (float): Decay rate for the exploration rate.\n            diversity_threshold (float): Threshold for swarm diversity below which exploration increases.\n            learning_factor (float): Step size for diversity adaptation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_range = inertia_range\n        self.cognitive_coeff_range = cognitive_coeff_range\n        self.social_coeff_range = social_coeff_range\n        self.exploration_rate = initial_exploration_rate\n        self.exploration_decay_rate = exploration_decay_rate\n        self.diversity_threshold = diversity_threshold\n        self.learning_factor = learning_factor\n        self.swarms = []\n        self.personal_best_positions = []\n        self.personal_best_fitness = []\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n\n    def initialize_swarm(self, func):\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.fevals += self.swarm_size\n        return swarm, fitness\n\n    def update_personal_best(self, swarm, fitness):\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n        return personal_best_positions, personal_best_fitness\n\n    def adapt_parameters(self):\n        \"\"\"Adapt inertia, cognitive, and social coefficients.\"\"\"\n        self.inertia = np.random.uniform(self.inertia_range[0], self.inertia_range[1])\n        self.cognitive_coeff = np.random.uniform(self.cognitive_coeff_range[0], self.cognitive_coeff_range[1])\n        self.social_coeff = np.random.uniform(self.social_coeff_range[0], self.social_coeff_range[1])\n\n    def calculate_diversity(self, swarm):\n        \"\"\"Calculate the diversity of a swarm based on average distance from the centroid.\"\"\"\n        centroid = np.mean(swarm, axis=0)\n        distances = np.linalg.norm(swarm - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def assess_fitness_landscape(self, fitness):\n        \"\"\"Assess the fitness landscape based on variance of fitness values.\"\"\"\n        return np.var(fitness)\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Bio-inspired Cooperative Swarm Optimization.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        # Initialize swarms\n        for _ in range(self.num_swarms):\n            swarm, fitness = self.initialize_swarm(func)\n            self.swarms.append(swarm)\n            personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n            self.personal_best_positions.append(personal_best_positions)\n            self.personal_best_fitness.append(personal_best_fitness)\n\n            # Update global best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.global_best_fitness:\n                self.global_best_fitness = fitness[best_idx]\n                self.global_best_position = swarm[best_idx].copy()\n\n        velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n\n        while self.fevals < self.budget:\n            for i in range(self.num_swarms):\n                swarm = self.swarms[i]\n                personal_best_positions = self.personal_best_positions[i]\n                personal_best_fitness = self.personal_best_fitness[i]\n                velocity = velocities[i]\n\n                # Update velocities and positions\n                r1 = np.random.rand(self.swarm_size, self.dim)\n                r2 = np.random.rand(self.swarm_size, self.dim)\n\n                # Cooperative component: Influence from other swarms' best\n                cooperative_influence = np.zeros((self.swarm_size, self.dim))\n                num_contributing_swarms = 0\n                for j in range(self.num_swarms):\n                    if i != j:\n                        best_idx_other = np.argmin(self.personal_best_fitness[j])\n                        # Dynamic communication: only influence from better swarms\n                        if self.personal_best_fitness[j][best_idx_other] < np.min(personal_best_fitness):\n                            cooperative_influence += (self.personal_best_positions[j][best_idx_other] - swarm)\n                            num_contributing_swarms += 1\n                if num_contributing_swarms > 0:\n                    cooperative_influence /= num_contributing_swarms # Average influence\n\n                # Adapt parameters\n                self.adapt_parameters()\n\n                velocity = (self.inertia * velocity\n                            + self.cognitive_coeff * r1 * (personal_best_positions - swarm)\n                            + self.social_coeff * r2 * (self.global_best_position - swarm)\n                            + 0.1 * cooperative_influence) # Add cooperative influence with a small weight\n\n                new_swarm = swarm + velocity\n\n                # Adaptive Exploration\n                diversity = self.calculate_diversity(swarm)\n                fitness_landscape = self.assess_fitness_landscape(personal_best_fitness)\n\n                # Adjust exploration rate based on diversity and fitness landscape.\n                if diversity < self.diversity_threshold or fitness_landscape < 1e-6:\n                    self.exploration_rate = min(1.0, self.exploration_rate + self.learning_factor)\n                else:\n                    self.exploration_rate *= self.exploration_decay_rate\n                \n                # Introduce random search with probability exploration_rate\n                for k in range(self.swarm_size):\n                    if np.random.rand() < self.exploration_rate:\n                        new_swarm[k] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Explore\n\n                new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n                new_fitness = np.array([func(x) for x in new_swarm])\n                self.fevals += self.swarm_size\n\n                # Update personal best\n                improvement = new_fitness < personal_best_fitness\n                personal_best_positions[improvement] = new_swarm[improvement].copy()\n                personal_best_fitness[improvement] = new_fitness[improvement].copy()\n\n                self.swarms[i] = new_swarm\n                self.personal_best_positions[i] = personal_best_positions\n                self.personal_best_fitness[i] = personal_best_fitness\n                velocities[i] = velocity\n\n                # Update global best\n                best_idx = np.argmin(personal_best_fitness)\n                if personal_best_fitness[best_idx] < self.global_best_fitness:\n                    self.global_best_fitness = personal_best_fitness[best_idx]\n                    self.global_best_position = personal_best_positions[best_idx].copy()\n                \n                if self.fevals >= self.budget:\n                    break\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm BioinspiredCooperativeSwarm scored 0.417 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["077c669e-20b2-4e2c-9d1c-6c2f58c62a80"], "operator": null, "metadata": {"aucs": [0.1555167635826219, 0.4036464826720121, 0.4216601441219908, 0.6603097590781868, 0.2922921038762999, 0.2510548023130281, 0.31295624233357766, 0.39836588422855634, 0.4641292486917249, 0.22076623977954768, 0.7555352783717357, 0.9955273461594484, 0.2431205692173556, 0.2827754372176403, 0.6352261827749577, 0.5232782808912095, 0.30550988728130846, 0.36584729386194526, 0.19221073691277446, 0.4602745768808687]}}
{"id": "3cb4c17a-56cd-47bb-bf96-2edaa98be94c", "fitness": -Infinity, "name": "AdaptiveCMAES", "description": "An adaptive covariance matrix adaptation evolution strategy (CMA-ES) with a population-based exploration strategy that adjusts the mutation strength based on the success rate of offspring and incorporates orthogonal learning.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_sigma=0.5, ol_rate=0.1, cs=0.1, damps=None):\n        \"\"\"\n        Adaptive Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with orthogonal learning.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): Population size (lambda). If None, it's calculated as 4 + int(3 * np.log(dim)).\n            initial_sigma (float): Initial standard deviation (mutation strength).\n            ol_rate (float): Rate of orthogonal learning.\n            cs (float): Cumulation factor for step-size control.\n            damps (float): Damping for step-size control.  If None, it's calculated.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_sigma = initial_sigma\n        self.ol_rate = ol_rate\n        self.sigma = initial_sigma\n        self.mean = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.eigenspace = None\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2)) # expectation of ||N(0,I)||\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2*max(0, (np.sqrt((self.pop_size-1)/(self.dim+1))-1)) + self.cs #damps=1\n\n        self.mu = self.pop_size // 2  # Number of parents\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights) #normalize\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1-self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.fevals = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        self.eigenspace = np.eye(self.dim) #Initial eigenspace\n\n    def orthogonal_learning(self, x, func):\n        \"\"\"Perform orthogonal learning.\"\"\"\n        basis = np.random.randn(self.dim, self.dim)\n        q, r = np.linalg.qr(basis)\n        d = np.diag(r)\n        phase = np.sign(d)\n        q = np.multiply(q, phase)\n\n        new_x = x.copy()\n        delta = np.random.uniform(-1, 1, size=self.dim)\n        new_x += self.ol_rate * np.dot(q, delta)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x\n\n    def __call__(self, func):\n        self.initialize(func)\n        while self.fevals < self.budget:\n            # 1. Generate offspring\n            z = np.random.randn(self.dim, self.pop_size)\n            x = self.mean[:, np.newaxis] + self.sigma * np.dot(self.eigenspace, z)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            # Orthogonal learning\n            for i in range(self.pop_size):\n                if np.random.rand() < self.ol_rate:\n                    x[:,i] = self.orthogonal_learning(x[:,i].copy(), func)\n                    x[i] = np.clip(x[:,i], func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x.T])\n            self.fevals += self.pop_size\n            \n            # 2. Selection and Recombination\n            idx = np.argsort(fitness)\n            x_sorted = x[:, idx]\n            fitness_sorted = fitness[idx]\n\n            if fitness_sorted[0] < self.f_opt:\n                self.f_opt = fitness_sorted[0]\n                self.x_opt = x_sorted[:, 0].copy()\n            \n            mean_old = self.mean.copy()\n            self.mean = np.dot(x_sorted[:, :self.mu], self.weights)\n\n            # 3. Update evolution paths\n            y = (self.mean - mean_old) / self.sigma\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * np.dot(self.eigenspace, np.dot(z[:, :self.mu], self.weights))\n            \n            norm_ps = np.linalg.norm(self.ps)\n            \n            condition_number = np.trace(self.C) / np.min(np.diag(self.C)) # Condition number calculation\n            \n            if (norm_ps/np.sqrt(1-(1-self.cs)**(2*self.fevals/self.pop_size))/self.chiN) < 1.1 + 0.2 * np.exp(-condition_number/2):\n                hsig = 1 #minor fix\n            else:\n                hsig = 0\n                self.ps = (1 - self.cs) * self.ps\n\n            self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * y\n            \n            # 4. Update covariance matrix C\n            delta = (1 - hsig**2) * self.cc * (2 - self.cc) #minor change\n\n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (np.outer(self.pc, self.pc) + delta * self.C) + self.cmu * np.dot(x_sorted[:, :self.mu], np.dot(np.diag(self.weights), x_sorted[:, :self.mu].T)) # corrected line\n\n            # Ensure C remains positive definite\n            try:\n                self.C = np.triu(self.C) + np.triu(self.C, 1).T  # enforce symmetry\n                L, Q = np.linalg.eigh(self.C)\n                L = np.maximum(L, 1e-10)  # Avoid negative eigenvalues\n                self.C = Q @ np.diag(L) @ Q.T\n            except:\n                self.C = np.eye(self.dim) # reset if fails.\n            \n            # 5. Adapt step size sigma\n            self.sigma *= np.exp((self.cs/self.damps) * (norm_ps/self.chiN - 1))\n            self.sigma = max(self.sigma, 1e-10) #avoid zero sigma\n\n            # Update B and D from C\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            L, Q = np.linalg.eigh(self.C)\n            self.eigenspace = Q @ np.diag(L**0.5) #B*D\n            \n            if self.fevals >= self.budget:\n                break\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["987ae7d9-98be-4e84-859a-426e464f0a82"], "operator": null, "metadata": {}}
{"id": "ee763eaa-cb1f-4402-b547-633e50071a34", "fitness": 0.0, "name": "CooperativeSwarm", "description": "Enhanced Cooperative Swarm with adaptive radius-based local search, dynamic velocity clamping, and a refined restart strategy to balance exploration and exploitation.", "code": "import numpy as np\n\nclass CooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=10, inertia_range=(0.4, 0.9),\n                 cognitive_coeff_range=(1.5, 2.0), social_coeff_range=(1.5, 2.0), initial_exploration_pressure=0.1,\n                 restart_trigger=0.05, stagnation_threshold=100, exploration_decay=0.995, cauchy_mutation_rate=0.05,\n                 local_search_probability=0.1, local_search_radius=0.5):\n        \"\"\"\n        Cooperative Swarm Optimization algorithm with adaptive parameters, dynamic sub-swarm communication,\n        restart mechanism, adaptive exploration pressure, self-adaptive learning, Cauchy mutation, adaptive\n        radius-based local search, and dynamic velocity clamping.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            num_swarms (int): The number of sub-swarms.\n            swarm_size (int): The size of each sub-swarm.\n            inertia_range (tuple): Range for inertia weight adaptation.\n            cognitive_coeff_range (tuple): Range for cognitive coefficient adaptation.\n            social_coeff_range (tuple): Range for social coefficient adaptation.\n            initial_exploration_pressure (float): Initial probability of exploring a new region instead of exploiting.\n            restart_trigger (float): Trigger for swarm restart based on stagnation.\n            stagnation_threshold (int): Number of iterations without improvement before considering stagnation.\n            exploration_decay (float): Decay rate for exploration pressure.\n            cauchy_mutation_rate (float): Probability of applying Cauchy mutation.\n            local_search_probability (float): Probability of performing local search around the best particle.\n            local_search_radius (float): Radius for the local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_range = inertia_range\n        self.cognitive_coeff_range = cognitive_coeff_range\n        self.social_coeff_range = social_coeff_range\n        self.exploration_pressure = initial_exploration_pressure\n        self.initial_exploration_pressure = initial_exploration_pressure\n        self.restart_trigger = restart_trigger\n        self.stagnation_threshold = stagnation_threshold\n        self.exploration_decay = exploration_decay\n        self.cauchy_mutation_rate = cauchy_mutation_rate\n        self.local_search_probability = local_search_probability\n        self.local_search_radius = local_search_radius\n        self.swarms = []\n        self.personal_best_positions = []\n        self.personal_best_fitness = []\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.stagnation_counter = 0\n\n        # Self-adaptive learning parameters\n        self.success_rates = np.zeros(self.num_swarms)\n        self.learning_rates = np.ones(self.num_swarms) * 0.1\n        self.velocity_clamp = 1.0  # Initial velocity clamp\n\n    def initialize_swarm(self, func):\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.fevals += self.swarm_size\n        return swarm, fitness\n\n    def update_personal_best(self, swarm, fitness):\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n        return personal_best_positions, personal_best_fitness\n\n    def adapt_parameters(self):\n        \"\"\"Adapt inertia, cognitive, and social coefficients.\"\"\"\n        self.inertia = np.random.uniform(self.inertia_range[0], self.inertia_range[1])\n        self.cognitive_coeff = np.random.uniform(self.cognitive_coeff_range[0], self.cognitive_coeff_range[1])\n        self.social_coeff = np.random.uniform(self.social_coeff_range[0], self.social_coeff_range[1])\n\n    def cauchy_mutation(self, x):\n        \"\"\"Apply Cauchy mutation to a particle.\"\"\"\n        mutation = np.random.standard_cauchy(size=self.dim)\n        return x + 0.01 * mutation  # Scale the mutation\n\n    def local_search(self, x, func):\n        \"\"\"Perform local search around a given position.\"\"\"\n        new_x = x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        f = func(new_x)\n        self.fevals += 1\n        return new_x, f\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Cooperative Swarm Optimization.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        # Initialize swarms\n        for _ in range(self.num_swarms):\n            swarm, fitness = self.initialize_swarm(func)\n            self.swarms.append(swarm)\n            personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n            self.personal_best_positions.append(personal_best_positions)\n            self.personal_best_fitness.append(personal_best_fitness)\n\n            # Update global best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.global_best_fitness:\n                self.global_best_fitness = fitness[best_idx]\n                self.global_best_position = swarm[best_idx].copy()\n                self.stagnation_counter = 0\n\n        velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n\n        while self.fevals < self.budget:\n            old_global_best_fitness = self.global_best_fitness\n\n            for i in range(self.num_swarms):\n                swarm = self.swarms[i]\n                personal_best_positions = self.personal_best_positions[i]\n                personal_best_fitness = self.personal_best_fitness[i]\n                velocity = velocities[i]\n\n                # Update velocities and positions\n                r1 = np.random.rand(self.swarm_size, self.dim)\n                r2 = np.random.rand(self.swarm_size, self.dim)\n\n                # Cooperative component: Influence from other swarms' best\n                cooperative_influence = np.zeros((self.swarm_size, self.dim))\n                num_contributing_swarms = 0\n                for j in range(self.num_swarms):\n                    if i != j:\n                        best_idx_other = np.argmin(self.personal_best_fitness[j])\n                        if self.personal_best_fitness[j][best_idx_other] < np.min(personal_best_fitness):\n                            cooperative_influence += (self.personal_best_positions[j][best_idx_other] - swarm)\n                            num_contributing_swarms += 1\n                if num_contributing_swarms > 0:\n                    cooperative_influence /= num_contributing_swarms\n\n                # Adapt parameters\n                self.adapt_parameters()\n\n                velocity = (self.inertia * velocity\n                            + self.cognitive_coeff * r1 * (personal_best_positions - swarm)\n                            + self.social_coeff * r2 * (self.global_best_position - swarm)\n                            + self.learning_rates[i] * cooperative_influence) # Adaptive learning rate for coop influence\n\n                # Velocity clamping\n                velocity = np.clip(velocity, -self.velocity_clamp, self.velocity_clamp)\n\n                new_swarm = swarm + velocity\n\n                # Exploration: Introduce random search with adaptive probability\n                for k in range(self.swarm_size):\n                    if np.random.rand() < self.exploration_pressure:\n                        new_swarm[k] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Explore\n                    elif np.random.rand() < self.cauchy_mutation_rate:\n                        new_swarm[k] = self.cauchy_mutation(new_swarm[k])\n                    elif np.random.rand() < self.local_search_probability:\n                        new_swarm[k], new_fitness_k = self.local_search(new_swarm[k], func) # Local search\n                        \n\n                new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n                new_fitness = np.array([func(x) for x in new_swarm])\n                self.fevals += self.swarm_size\n\n                # Update personal best\n                improvement = new_fitness < personal_best_fitness\n                num_improvements = np.sum(improvement)\n                personal_best_positions[improvement] = new_swarm[improvement].copy()\n                personal_best_fitness[improvement] = new_fitness[improvement].copy()\n\n                self.swarms[i] = new_swarm\n                self.personal_best_positions[i] = personal_best_positions\n                self.personal_best_fitness[i] = personal_best_fitness\n                velocities[i] = velocity\n\n                # Update global best\n                best_idx = np.argmin(personal_best_fitness)\n                if personal_best_fitness[best_idx] < self.global_best_fitness:\n                    self.global_best_fitness = personal_best_fitness[best_idx]\n                    self.global_best_position = personal_best_positions[best_idx].copy()\n                    self.stagnation_counter = 0\n\n                # Self-adaptive learning rate update\n                self.success_rates[i] = 0.9 * self.success_rates[i] + 0.1 * (num_improvements / self.swarm_size)\n                if self.success_rates[i] > 0.2:\n                    self.learning_rates[i] *= 1.1  # Increase learning rate if successful\n                else:\n                    self.learning_rates[i] *= 0.9  # Decrease learning rate if not successful\n                self.learning_rates[i] = np.clip(self.learning_rates[i], 0.01, 0.5) # Keep rate within bounds\n\n\n                if self.fevals >= self.budget:\n                    break\n\n            # Stagnation check and restart\n            if self.global_best_fitness >= old_global_best_fitness:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                if np.random.rand() < self.restart_trigger:\n                    # Restart strategy: Re-initialize only the worst performing swarms\n                    swarm_fitnesses = [np.min(pf) for pf in self.personal_best_fitness]\n                    worst_swarm_indices = np.argsort(swarm_fitnesses)[-int(self.num_swarms*0.5):] #Restart top 50% worst swarms\n\n                    for i in worst_swarm_indices:\n                        swarm, fitness = self.initialize_swarm(func)\n                        self.swarms[i] = swarm\n                        personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n                        self.personal_best_positions[i] = personal_best_positions\n                        self.personal_best_fitness[i] = personal_best_fitness\n\n                        best_idx = np.argmin(fitness)\n                        if fitness[best_idx] < self.global_best_fitness:\n                            self.global_best_fitness = fitness[best_idx]\n                            self.global_best_position = swarm[best_idx].copy()\n                            self.stagnation_counter = 0\n\n                    velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n                    self.stagnation_counter = 0\n                    self.velocity_clamp = 1.0\n                else:\n                    self.stagnation_counter = 0\n                    self.velocity_clamp *= 0.95  # Reduce velocity clamp after stagnation without restart\n                    self.velocity_clamp = max(self.velocity_clamp, 0.1) # prevent clamp from becoming too small.\n\n            # Adaptive Exploration Pressure\n            self.exploration_pressure *= self.exploration_decay\n            self.exploration_pressure = max(self.exploration_pressure, 0.001) # Avoid vanishing exploration\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm CooperativeSwarm scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d3521816-dc64-4307-bed1-fc5a7569404e"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "978c05cd-861b-4f5f-8d50-27802f9e6c09", "fitness": 0.1873817304653773, "name": "DirectedCooperativeSwarm", "description": "An enhanced cooperative swarm algorithm with a directed exploration strategy guided by the fitness landscape gradient and a self-organizing communication topology.", "code": "import numpy as np\n\nclass DirectedCooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=10, inertia_range=(0.4, 0.9),\n                 cognitive_coeff_range=(1.5, 2.0), social_coeff_range=(1.5, 2.0), initial_exploration_pressure=0.1,\n                 restart_trigger=0.05, stagnation_threshold=100, exploration_decay=0.995, cauchy_mutation_rate=0.05,\n                 gradient_learning_rate=0.01, topology_update_interval=50):\n        \"\"\"\n        Cooperative Swarm Optimization algorithm with adaptive parameters, dynamic sub-swarm communication,\n        restart mechanism, adaptive exploration pressure, self-adaptive learning, Cauchy mutation, and\n        a directed exploration strategy using fitness landscape gradient estimation, and a self-organizing communication topology.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            num_swarms (int): The number of sub-swarms.\n            swarm_size (int): The size of each sub-swarm.\n            inertia_range (tuple): Range for inertia weight adaptation.\n            cognitive_coeff_range (tuple): Range for cognitive coefficient adaptation.\n            social_coeff_range (tuple): Range for social coefficient adaptation.\n            initial_exploration_pressure (float): Initial probability of exploring a new region instead of exploiting.\n            restart_trigger (float): Trigger for swarm restart based on stagnation.\n            stagnation_threshold (int): Number of iterations without improvement before considering stagnation.\n            exploration_decay (float): Decay rate for exploration pressure.\n            cauchy_mutation_rate (float): Probability of applying Cauchy mutation.\n            gradient_learning_rate (float): Learning rate for gradient-based exploration.\n            topology_update_interval (int): Frequency of updating the communication topology.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_range = inertia_range\n        self.cognitive_coeff_range = cognitive_coeff_range\n        self.social_coeff_range = social_coeff_range\n        self.exploration_pressure = initial_exploration_pressure\n        self.initial_exploration_pressure = initial_exploration_pressure\n        self.restart_trigger = restart_trigger\n        self.stagnation_threshold = stagnation_threshold\n        self.exploration_decay = exploration_decay\n        self.cauchy_mutation_rate = cauchy_mutation_rate\n        self.gradient_learning_rate = gradient_learning_rate\n        self.topology_update_interval = topology_update_interval\n        self.swarms = []\n        self.personal_best_positions = []\n        self.personal_best_fitness = []\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.stagnation_counter = 0\n        self.iteration = 0\n\n        # Self-adaptive learning parameters\n        self.success_rates = np.zeros(self.num_swarms)\n        self.learning_rates = np.ones(self.num_swarms) * 0.1\n\n        # Communication topology: Each swarm initially connected to all others.  Represented as an adjacency matrix.\n        self.communication_topology = np.ones((self.num_swarms, self.num_swarms)) - np.eye(self.num_swarms)\n\n    def initialize_swarm(self, func):\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.fevals += self.swarm_size\n        return swarm, fitness\n\n    def update_personal_best(self, swarm, fitness):\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n        return personal_best_positions, personal_best_fitness\n\n    def adapt_parameters(self):\n        \"\"\"Adapt inertia, cognitive, and social coefficients.\"\"\"\n        self.inertia = np.random.uniform(self.inertia_range[0], self.inertia_range[1])\n        self.cognitive_coeff = np.random.uniform(self.cognitive_coeff_range[0], self.cognitive_coeff_range[1])\n        self.social_coeff = np.random.uniform(self.social_coeff_range[0], self.social_coeff_range[1])\n\n    def cauchy_mutation(self, x):\n        \"\"\"Apply Cauchy mutation to a particle.\"\"\"\n        mutation = np.random.standard_cauchy(size=self.dim)\n        return x + 0.01 * mutation  # Scale the mutation\n\n    def estimate_gradient(self, func, x, delta=1e-3):\n        \"\"\"Estimate the gradient of the function at a given point using finite differences.\"\"\"\n        gradient = np.zeros_like(x)\n        for i in range(self.dim):\n            x_plus = x.copy()\n            x_minus = x.copy()\n            x_plus[i] += delta\n            x_minus[i] -= delta\n            x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n            x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n            gradient[i] = (func(x_plus) - func(x_minus)) / (2 * delta)\n            self.fevals += 2  # Account for the 2 function evaluations in gradient estimation\n            if self.fevals >= self.budget:\n                break\n        return gradient\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Cooperative Swarm Optimization with directed exploration.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        # Initialize swarms\n        for _ in range(self.num_swarms):\n            swarm, fitness = self.initialize_swarm(func)\n            self.swarms.append(swarm)\n            personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n            self.personal_best_positions.append(personal_best_positions)\n            self.personal_best_fitness.append(personal_best_fitness)\n\n            # Update global best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.global_best_fitness:\n                self.global_best_fitness = fitness[best_idx]\n                self.global_best_position = swarm[best_idx].copy()\n                self.stagnation_counter = 0\n\n        velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n\n        while self.fevals < self.budget:\n            old_global_best_fitness = self.global_best_fitness\n\n            for i in range(self.num_swarms):\n                swarm = self.swarms[i]\n                personal_best_positions = self.personal_best_positions[i]\n                personal_best_fitness = self.personal_best_fitness[i]\n                velocity = velocities[i]\n\n                # Update velocities and positions\n                r1 = np.random.rand(self.swarm_size, self.dim)\n                r2 = np.random.rand(self.swarm_size, self.dim)\n\n                # Cooperative component: Influence from other swarms' best\n                cooperative_influence = np.zeros((self.swarm_size, self.dim))\n                num_contributing_swarms = 0\n                for j in range(self.num_swarms):\n                    if i != j and self.communication_topology[i, j] > 0:  # Check communication topology\n                        best_idx_other = np.argmin(self.personal_best_fitness[j])\n                        if self.personal_best_fitness[j][best_idx_other] < np.min(personal_best_fitness):\n                            cooperative_influence += (self.personal_best_positions[j][best_idx_other] - swarm)\n                            num_contributing_swarms += 1\n                if num_contributing_swarms > 0:\n                    cooperative_influence /= num_contributing_swarms\n\n                # Adapt parameters\n                self.adapt_parameters()\n\n                velocity = (self.inertia * velocity\n                            + self.cognitive_coeff * r1 * (personal_best_positions - swarm)\n                            + self.social_coeff * r2 * (self.global_best_position - swarm)\n                            + self.learning_rates[i] * cooperative_influence) # Adaptive learning rate for coop influence\n\n                new_swarm = swarm + velocity\n\n                # Exploration: Introduce directed search with adaptive probability\n                for k in range(self.swarm_size):\n                    if np.random.rand() < self.exploration_pressure:\n                        # Estimate gradient at the particle's position\n                        gradient = self.estimate_gradient(func, swarm[k])\n                        if self.fevals >= self.budget:\n                            break\n\n                        # Move particle in the opposite direction of the gradient (toward lower function values)\n                        new_swarm[k] = swarm[k] - self.gradient_learning_rate * gradient\n                        new_swarm[k] = np.clip(new_swarm[k], func.bounds.lb, func.bounds.ub)\n                    elif np.random.rand() < self.cauchy_mutation_rate:\n                        new_swarm[k] = self.cauchy_mutation(new_swarm[k])\n\n\n                new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n                new_fitness = np.array([func(x) for x in new_swarm])\n                self.fevals += self.swarm_size\n\n                # Update personal best\n                improvement = new_fitness < personal_best_fitness\n                num_improvements = np.sum(improvement)\n                personal_best_positions[improvement] = new_swarm[improvement].copy()\n                personal_best_fitness[improvement] = new_fitness[improvement].copy()\n\n                self.swarms[i] = new_swarm\n                self.personal_best_positions[i] = personal_best_positions\n                self.personal_best_fitness[i] = personal_best_fitness\n                velocities[i] = velocity\n\n                # Update global best\n                best_idx = np.argmin(personal_best_fitness)\n                if personal_best_fitness[best_idx] < self.global_best_fitness:\n                    self.global_best_fitness = personal_best_fitness[best_idx]\n                    self.global_best_position = personal_best_positions[best_idx].copy()\n                    self.stagnation_counter = 0\n\n                # Self-adaptive learning rate update\n                self.success_rates[i] = 0.9 * self.success_rates[i] + 0.1 * (num_improvements / self.swarm_size)\n                if self.success_rates[i] > 0.2:\n                    self.learning_rates[i] *= 1.1  # Increase learning rate if successful\n                else:\n                    self.learning_rates[i] *= 0.9  # Decrease learning rate if not successful\n                self.learning_rates[i] = np.clip(self.learning_rates[i], 0.01, 0.5) # Keep rate within bounds\n\n\n                if self.fevals >= self.budget:\n                    break\n\n            # Stagnation check and restart\n            if self.global_best_fitness >= old_global_best_fitness:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                if np.random.rand() < self.restart_trigger:\n                    for i in range(self.num_swarms):\n                        swarm, fitness = self.initialize_swarm(func)\n                        self.swarms[i] = swarm\n                        personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n                        self.personal_best_positions[i] = personal_best_positions\n                        self.personal_best_fitness[i] = personal_best_fitness\n\n                        best_idx = np.argmin(fitness)\n                        if fitness[best_idx] < self.global_best_fitness:\n                            self.global_best_fitness = fitness[best_idx]\n                            self.global_best_position = swarm[best_idx].copy()\n                            self.stagnation_counter = 0\n\n                    velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter = 0\n\n            # Adaptive Exploration Pressure\n            self.exploration_pressure *= self.exploration_decay\n            self.exploration_pressure = max(self.exploration_pressure, 0.001) # Avoid vanishing exploration\n\n            # Update Communication Topology\n            self.iteration += 1\n            if self.iteration % self.topology_update_interval == 0:\n                self.update_communication_topology()\n\n        return self.global_best_fitness, self.global_best_position\n\n    def update_communication_topology(self):\n        \"\"\"\n        Updates the communication topology based on the relative performance of the swarms.\n        Swarms that are performing well are more likely to influence others.\n        \"\"\"\n        # Calculate the average fitness of each swarm\n        avg_fitness = [np.mean(fitness) for fitness in self.personal_best_fitness]\n\n        # Determine which swarms are \"successful\" (lower average fitness)\n        successful_swarms = np.argsort(avg_fitness)[:self.num_swarms // 2]  # Top 50% are considered successful\n\n        # Reset the topology\n        self.communication_topology = np.zeros((self.num_swarms, self.num_swarms))\n\n        # Allow successful swarms to influence others\n        for i in successful_swarms:\n            for j in range(self.num_swarms):\n                if i != j:\n                    self.communication_topology[i, j] = 1  # Swarm i influences swarm j\n\n        # Ensure at least one connection for each swarm. If a swarm is isolated, connect it to the best swarm.\n        for i in range(self.num_swarms):\n            if np.sum(self.communication_topology[:, i]) == 0:  # Swarm i is isolated\n                best_swarm = np.argmin(avg_fitness)\n                if best_swarm != i:\n                    self.communication_topology[best_swarm, i] = 1\n                else: #If swarm i is the best, connect it to the second best.\n                     second_best = np.argsort(avg_fitness)[1]\n                     self.communication_topology[i, second_best] = 1", "configspace": "", "generation": 8, "feedback": "The algorithm DirectedCooperativeSwarm scored 0.187 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d3521816-dc64-4307-bed1-fc5a7569404e"], "operator": null, "metadata": {"aucs": [0.14528065874051177, 0.17718739321573684, 0.42705886990526054, 0]}}
{"id": "fe792e9e-0c55-41a7-9fcc-807ac53bc9c9", "fitness": 0.2859967481921762, "name": "SelfOrganizingSwarm", "description": "A swarm optimization algorithm with a self-organizing topology, adaptive neighborhood radius, and a velocity update rule that favors exploitation in promising regions.", "code": "import numpy as np\n\nclass SelfOrganizingSwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, initial_radius=1.0, radius_decay=0.995,\n                 min_radius=0.01, exploration_rate=0.1, attraction_coeff=1.0, repulsion_coeff=0.5,\n                 inertia_weight=0.7):\n        \"\"\"\n        Self-Organizing Swarm Optimization with adaptive neighborhood radius and dynamic topology.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            swarm_size (int): The number of particles in the swarm.\n            initial_radius (float): Initial neighborhood radius.\n            radius_decay (float): Decay rate for the neighborhood radius.\n            min_radius (float): Minimum allowed neighborhood radius.\n            exploration_rate (float): Probability of random exploration.\n            attraction_coeff (float): Coefficient for attraction to neighbors.\n            repulsion_coeff (float): Coefficient for repulsion from close neighbors.\n            inertia_weight (float): Inertia weight for velocity update.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.initial_radius = initial_radius\n        self.radius_decay = radius_decay\n        self.min_radius = min_radius\n        self.exploration_rate = exploration_rate\n        self.attraction_coeff = attraction_coeff\n        self.repulsion_coeff = repulsion_coeff\n        self.inertia_weight = inertia_weight\n        self.fevals = 0\n        self.radius = initial_radius\n\n    def initialize_swarm(self, func):\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.fevals += self.swarm_size\n        return swarm, fitness\n\n    def update_velocity(self, swarm, fitness, velocities):\n        \"\"\"Update velocities based on neighborhood interactions.\"\"\"\n        for i in range(self.swarm_size):\n            # Find neighbors within the current radius\n            distances = np.linalg.norm(swarm - swarm[i], axis=1)\n            neighbors = np.where(distances < self.radius)[0]\n            neighbors = neighbors[neighbors != i]  # Exclude self\n\n            if len(neighbors) > 0:\n                # Calculate attraction force towards better neighbors\n                better_neighbors = neighbors[fitness[neighbors] < fitness[i]]\n                if len(better_neighbors) > 0:\n                    attraction_direction = np.mean(swarm[better_neighbors] - swarm[i], axis=0)\n                    velocities[i] += self.attraction_coeff * attraction_direction\n\n                # Calculate repulsion force from worse neighbors that are very close\n                close_worse_neighbors = neighbors[(fitness[neighbors] >= fitness[i]) & (distances[neighbors] < self.radius / 2)]\n                if len(close_worse_neighbors) > 0:\n                    repulsion_direction = np.mean(swarm[i] - swarm[close_worse_neighbors], axis=0)\n                    velocities[i] += self.repulsion_coeff * repulsion_direction\n\n            # Inertia\n            velocities[i] *= self.inertia_weight\n\n            # Exploration\n            if np.random.rand() < self.exploration_rate:\n                velocities[i] += np.random.uniform(-1, 1, size=self.dim)\n\n        return velocities\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Self-Organizing Swarm Optimization.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        swarm, fitness = self.initialize_swarm(func)\n        best_idx = np.argmin(fitness)\n        best_fitness = fitness[best_idx]\n        best_position = swarm[best_idx].copy()\n        velocities = np.zeros_like(swarm)\n\n        while self.fevals < self.budget:\n            velocities = self.update_velocity(swarm, fitness, velocities)\n            new_swarm = swarm + velocities\n            new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n            new_fitness = np.array([func(x) for x in new_swarm])\n            self.fevals += self.swarm_size\n\n            # Update best solution\n            improvement = new_fitness < fitness\n            swarm[improvement] = new_swarm[improvement].copy()\n            fitness[improvement] = new_fitness[improvement].copy()\n            best_idx = np.argmin(fitness)\n\n            if fitness[best_idx] < best_fitness:\n                best_fitness = fitness[best_idx]\n                best_position = swarm[best_idx].copy()\n\n            # Decay the neighborhood radius\n            self.radius *= self.radius_decay\n            self.radius = max(self.radius, self.min_radius)\n\n            if self.fevals >= self.budget:\n                break\n\n        return best_fitness, best_position", "configspace": "", "generation": 8, "feedback": "The algorithm SelfOrganizingSwarm scored 0.286 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d3521816-dc64-4307-bed1-fc5a7569404e"], "operator": null, "metadata": {"aucs": [0.12407984118621807, 0.16693839498262164, 0.26434356757492283, 0.20919313534949646, 0.1880322314189189, 0.28384152633757187, 0.26524685523672864, 0.216280843227024, 0.19581242150254807, 0.15369935508983723, 0.1925274653534902, 0.9756168680932296, 0.2409094736020313, 0.2137947479174125, 0.5819486773736932, 0.2645041225283098, 0.24724622413487585, 0.308189735876769, 0.16694810198995114, 0.46078137506787364]}}
{"id": "994cb3c3-c219-4768-a401-43f724d93a8c", "fitness": 0.23362307934544566, "name": "CooperativeSwarmOL", "description": "Cooperative Swarm with orthogonal learning, dynamic parameter adaptation based on fitness landscape ruggedness, and a diversity-enhanced restart strategy.", "code": "import numpy as np\n\nclass CooperativeSwarmOL:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=10, inertia_range=(0.4, 0.9),\n                 cognitive_coeff_range=(1.5, 2.0), social_coeff_range=(1.5, 2.0), exploration_pressure=0.1,\n                 restart_trigger=0.05, ol_rate=0.1, learning_rate=0.1, ruggedness_window=10):\n        \"\"\"\n        Cooperative Swarm Optimization algorithm with orthogonal learning, adaptive parameters,\n        dynamic sub-swarm communication and restart mechanism.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            num_swarms (int): The number of sub-swarms.\n            swarm_size (int): The size of each sub-swarm.\n            inertia_range (tuple): Range for inertia weight adaptation.\n            cognitive_coeff_range (tuple): Range for cognitive coefficient adaptation.\n            social_coeff_range (tuple): Range for social coefficient adaptation.\n            exploration_pressure (float): Probability of exploring a new region instead of exploiting.\n            restart_trigger (float): Trigger for swarm restart based on stagnation.\n            ol_rate (float): Rate of orthogonal learning.\n            learning_rate (float): Learning rate for parameter adaptation.\n            ruggedness_window (int): Window size for estimating fitness landscape ruggedness.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_range = inertia_range\n        self.cognitive_coeff_range = cognitive_coeff_range\n        self.social_coeff_range = social_coeff_range\n        self.exploration_pressure = exploration_pressure\n        self.restart_trigger = restart_trigger\n        self.ol_rate = ol_rate\n        self.learning_rate = learning_rate\n        self.swarms = []\n        self.personal_best_positions = []\n        self.personal_best_fitness = []\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.stagnation_counter = 0\n        self.max_stagnation = 100 #arbitrary value, adjust based on the problem\n        self.fitness_history = []\n        self.ruggedness_window = ruggedness_window\n\n        self.inertia = np.random.uniform(self.inertia_range[0], self.inertia_range[1])\n        self.cognitive_coeff = np.random.uniform(self.cognitive_coeff_range[0], self.cognitive_coeff_range[1])\n        self.social_coeff = np.random.uniform(self.social_coeff_range[0], self.social_coeff_range[1])\n\n    def initialize_swarm(self, func):\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.fevals += self.swarm_size\n        return swarm, fitness\n\n    def update_personal_best(self, swarm, fitness):\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n        return personal_best_positions, personal_best_fitness\n\n    def estimate_ruggedness(self):\n        \"\"\"Estimates the ruggedness of the fitness landscape.\"\"\"\n        if len(self.fitness_history) < self.ruggedness_window:\n            return 0.0  # Not enough data\n\n        window = self.fitness_history[-self.ruggedness_window:]\n        delta = np.max(window) - np.min(window)\n        return delta / np.mean(window) # Normalized difference\n\n    def adapt_parameters(self):\n        \"\"\"Adapt inertia, cognitive, and social coefficients based on landscape ruggedness.\"\"\"\n        ruggedness = self.estimate_ruggedness()\n        \n        # Adjust inertia: higher ruggedness favors lower inertia (more exploration)\n        self.inertia = self.inertia_range[0] + (self.inertia_range[1] - self.inertia_range[0]) * (1 - ruggedness)\n        self.inertia = np.clip(self.inertia, self.inertia_range[0], self.inertia_range[1])\n        \n        # Adjust cognitive coefficient: higher ruggedness favors higher cognitive coeff (more self-reliance)\n        self.cognitive_coeff = self.cognitive_coeff_range[0] + (self.cognitive_coeff_range[1] - self.cognitive_coeff_range[0]) * ruggedness\n        self.cognitive_coeff = np.clip(self.cognitive_coeff, self.cognitive_coeff_range[0], self.cognitive_coeff_range[1])\n        \n        # Adjust social coefficient: higher ruggedness favors lower social coeff (less reliance on others)\n        self.social_coeff = self.social_coeff_range[0] + (self.social_coeff_range[1] - self.social_coeff_range[0]) * (1 - ruggedness)\n        self.social_coeff = np.clip(self.social_coeff, self.social_coeff_range[0], self.social_coeff_range[1])\n\n    def orthogonal_learning(self, x, func):\n        \"\"\"Perform orthogonal learning.\"\"\"\n        basis = np.random.randn(self.dim, self.dim)\n        q, r = np.linalg.qr(basis)\n        d = np.diag(r)\n        phase = np.sign(d)\n        q = np.multiply(q, phase)\n\n        new_x = x.copy()\n        delta = np.random.uniform(-1, 1, size=self.dim)\n        new_x += self.ol_rate * np.dot(q, delta)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Cooperative Swarm Optimization.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        # Initialize swarms\n        for _ in range(self.num_swarms):\n            swarm, fitness = self.initialize_swarm(func)\n            self.swarms.append(swarm)\n            personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n            self.personal_best_positions.append(personal_best_positions)\n            self.personal_best_fitness.append(personal_best_fitness)\n\n            # Update global best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.global_best_fitness:\n                self.global_best_fitness = fitness[best_idx]\n                self.global_best_position = swarm[best_idx].copy()\n                self.stagnation_counter = 0 #reset counter if we improve\n                self.fitness_history.append(self.global_best_fitness) # Store initial fitness\n\n        velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n\n        while self.fevals < self.budget:\n            old_global_best_fitness = self.global_best_fitness  # Store the previous global best\n\n            # Adapt parameters based on landscape ruggedness\n            self.adapt_parameters()\n\n            for i in range(self.num_swarms):\n                swarm = self.swarms[i]\n                personal_best_positions = self.personal_best_positions[i]\n                personal_best_fitness = self.personal_best_fitness[i]\n                velocity = velocities[i]\n\n                # Update velocities and positions\n                r1 = np.random.rand(self.swarm_size, self.dim)\n                r2 = np.random.rand(self.swarm_size, self.dim)\n\n                # Cooperative component: Influence from other swarms' best\n                cooperative_influence = np.zeros((self.swarm_size, self.dim))\n                num_contributing_swarms = 0\n                for j in range(self.num_swarms):\n                    if i != j:\n                        best_idx_other = np.argmin(self.personal_best_fitness[j])\n                        # Dynamic communication: only influence from better swarms\n                        if self.personal_best_fitness[j][best_idx_other] < np.min(personal_best_fitness):\n                            cooperative_influence += (self.personal_best_positions[j][best_idx_other] - swarm)\n                            num_contributing_swarms += 1\n                if num_contributing_swarms > 0:\n                    cooperative_influence /= num_contributing_swarms # Average influence\n\n\n                velocity = (self.inertia * velocity\n                            + self.cognitive_coeff * r1 * (personal_best_positions - swarm)\n                            + self.social_coeff * r2 * (self.global_best_position - swarm)\n                            + 0.1 * cooperative_influence) # Add cooperative influence with a small weight\n\n                new_swarm = swarm + velocity\n\n                # Exploration: Introduce random search with probability exploration_pressure\n                for k in range(self.swarm_size):\n                    if np.random.rand() < self.exploration_pressure:\n                        new_swarm[k] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Explore\n\n                # Orthogonal Learning\n                for k in range(self.swarm_size):\n                    if np.random.rand() < self.ol_rate:\n                        new_swarm[k] = self.orthogonal_learning(new_swarm[k], func)\n\n                new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n                new_fitness = np.array([func(x) for x in new_swarm])\n                self.fevals += self.swarm_size\n\n                # Update personal best\n                improvement = new_fitness < personal_best_fitness\n                personal_best_positions[improvement] = new_swarm[improvement].copy()\n                personal_best_fitness[improvement] = new_fitness[improvement].copy()\n\n                self.swarms[i] = new_swarm\n                self.personal_best_positions[i] = personal_best_positions\n                self.personal_best_fitness[i] = personal_best_fitness\n                velocities[i] = velocity\n\n                # Update global best\n                best_idx = np.argmin(personal_best_fitness)\n                if personal_best_fitness[best_idx] < self.global_best_fitness:\n                    self.global_best_fitness = personal_best_fitness[best_idx]\n                    self.global_best_position = personal_best_positions[best_idx].copy()\n                    self.stagnation_counter = 0 # Reset stagnation counter when a better solution is found\n                    self.fitness_history.append(self.global_best_fitness)\n                \n                if self.fevals >= self.budget:\n                    break\n\n            # Stagnation check and restart\n            if self.global_best_fitness >= old_global_best_fitness: # No improvement\n                self.stagnation_counter += 1\n            else:\n                 self.stagnation_counter = 0 # Reset stagnation counter when a better solution is found\n            \n            if self.stagnation_counter > self.max_stagnation:\n                # Restart the swarm - Enhanced Diversity Restart\n                if np.random.rand() < self.restart_trigger:  # Probabilistic restart\n                    for i in range(self.num_swarms):\n                        #Instead of re-initializing completely, perturb the current best locations\n                        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n                        #Introduce diversity by perturbing around the current best\n                        perturbation = np.random.normal(0, 0.1, size=(self.swarm_size, self.dim)) \n                        swarm = self.global_best_position + perturbation\n                        swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n                        fitness = np.array([func(x) for x in swarm])\n\n                        self.swarms[i] = swarm\n                        personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n                        self.personal_best_positions[i] = personal_best_positions\n                        self.personal_best_fitness[i] = personal_best_fitness\n\n                        best_idx = np.argmin(fitness)\n                        if fitness[best_idx] < self.global_best_fitness:\n                            self.global_best_fitness = fitness[best_idx]\n                            self.global_best_position = swarm[best_idx].copy()\n                            self.stagnation_counter = 0 #reset counter if we improve\n                            self.fitness_history.append(self.global_best_fitness)\n\n                    velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n                    self.stagnation_counter = 0 #reset counter after restart\n                else:\n                    self.stagnation_counter = 0 #reset counter even if no restart to prevent continuous restarts\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm CooperativeSwarmOL scored 0.234 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["987ae7d9-98be-4e84-859a-426e464f0a82"], "operator": null, "metadata": {"aucs": [0.1387770660293296, 0.25318716276110076, 0.3151762654815988, 0.2521007957697827, 0.24983074679928685, 0.26851928616960663, 0.26714237312616884, 0.3578740179721367, 0]}}
{"id": "f76209ca-973e-46ff-b9b5-9ad58dc3a773", "fitness": 0.5732695299325112, "name": "CooperativeSwarmTimeVariant", "description": "A cooperative swarm algorithm with a fitness-weighted inter-swarm communication strategy and a time-varying flight length.", "code": "import numpy as np\n\nclass CooperativeSwarmTimeVariant:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=10,\n                 inertia_range=(0.4, 0.9), cognitive_coeff_range=(1.5, 2.0),\n                 social_coeff_range=(1.5, 2.0), inter_swarm_coeff=0.1,\n                 restart_trigger=0.05, stagnation_threshold=100, time_decay=0.995):\n        \"\"\"\n        Cooperative Swarm Optimization with time-variant flight length, fitness-weighted inter-swarm communication and restart mechanism.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            num_swarms (int): The number of sub-swarms.\n            swarm_size (int): The size of each sub-swarm.\n            inertia_range (tuple): Range for inertia weight adaptation.\n            cognitive_coeff_range (tuple): Range for cognitive coefficient adaptation.\n            social_coeff_range (tuple): Range for social coefficient adaptation.\n            inter_swarm_coeff (float): Coefficient for inter-swarm communication.\n            restart_trigger (float): Trigger for swarm restart based on stagnation.\n            stagnation_threshold (int): Number of iterations without improvement before considering stagnation.\n            time_decay (float): Decay rate for time_variant flight length.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_range = inertia_range\n        self.cognitive_coeff_range = cognitive_coeff_range\n        self.social_coeff_range = social_coeff_range\n        self.inter_swarm_coeff = inter_swarm_coeff\n        self.restart_trigger = restart_trigger\n        self.stagnation_threshold = stagnation_threshold\n        self.time_decay = time_decay\n        self.swarms = []\n        self.personal_best_positions = []\n        self.personal_best_fitness = []\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.stagnation_counter = 0\n        self.time_variant_length = 1.0\n\n    def initialize_swarm(self, func):\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.fevals += self.swarm_size\n        return swarm, fitness\n\n    def update_personal_best(self, swarm, fitness):\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n        return personal_best_positions, personal_best_fitness\n\n    def adapt_parameters(self):\n        \"\"\"Adapt inertia, cognitive, and social coefficients.\"\"\"\n        self.inertia = np.random.uniform(self.inertia_range[0], self.inertia_range[1])\n        self.cognitive_coeff = np.random.uniform(self.cognitive_coeff_range[0], self.cognitive_coeff_range[1])\n        self.social_coeff = np.random.uniform(self.social_coeff_range[0], self.social_coeff_range[1])\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Cooperative Swarm Optimization with time-variant flight length.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        # Initialize swarms\n        for _ in range(self.num_swarms):\n            swarm, fitness = self.initialize_swarm(func)\n            self.swarms.append(swarm)\n            personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n            self.personal_best_positions.append(personal_best_positions)\n            self.personal_best_fitness.append(personal_best_fitness)\n\n            # Update global best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.global_best_fitness:\n                self.global_best_fitness = fitness[best_idx]\n                self.global_best_position = swarm[best_idx].copy()\n                self.stagnation_counter = 0\n\n        velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n\n        while self.fevals < self.budget:\n            old_global_best_fitness = self.global_best_fitness\n\n            for i in range(self.num_swarms):\n                swarm = self.swarms[i]\n                personal_best_positions = self.personal_best_positions[i]\n                personal_best_fitness = self.personal_best_fitness[i]\n                velocity = velocities[i]\n\n                # Update velocities and positions\n                r1 = np.random.rand(self.swarm_size, self.dim)\n                r2 = np.random.rand(self.swarm_size, self.dim)\n\n                # Fitness-weighted Inter-swarm communication\n                inter_swarm_influence = np.zeros((self.swarm_size, self.dim))\n                total_fitness = np.sum([np.sum(self.personal_best_fitness[j]) for j in range(self.num_swarms) if j != i])\n                for j in range(self.num_swarms):\n                    if i != j:\n                        # Weight by fitness (lower is better, so use inverse)\n                        swarm_fitness_sum = np.sum(self.personal_best_fitness[j])\n                        if total_fitness > 0:\n                            weight = (total_fitness - swarm_fitness_sum) / total_fitness\n                        else:\n                            weight = 1.0 / (self.num_swarms - 1)  # Equal weight if all fitnesses are the same\n                        best_idx_other = np.argmin(self.personal_best_fitness[j])\n                        inter_swarm_influence += weight * (self.personal_best_positions[j][best_idx_other] - swarm)\n\n                # Adapt parameters\n                self.adapt_parameters()\n\n                velocity = (self.inertia * velocity\n                            + self.cognitive_coeff * r1 * (personal_best_positions - swarm)\n                            + self.social_coeff * r2 * (self.global_best_position - swarm)\n                            + self.inter_swarm_coeff * inter_swarm_influence)\n\n                new_swarm = swarm + self.time_variant_length * velocity\n\n                new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n                new_fitness = np.array([func(x) for x in new_swarm])\n                self.fevals += self.swarm_size\n\n                # Update personal best\n                improvement = new_fitness < personal_best_fitness\n                personal_best_positions[improvement] = new_swarm[improvement].copy()\n                personal_best_fitness[improvement] = new_fitness[improvement].copy()\n\n                self.swarms[i] = new_swarm\n                self.personal_best_positions[i] = personal_best_positions\n                self.personal_best_fitness[i] = personal_best_fitness\n                velocities[i] = velocity\n\n                # Update global best\n                best_idx = np.argmin(personal_best_fitness)\n                if personal_best_fitness[best_idx] < self.global_best_fitness:\n                    self.global_best_fitness = personal_best_fitness[best_idx]\n                    self.global_best_position = personal_best_positions[best_idx].copy()\n                    self.stagnation_counter = 0\n\n                if self.fevals >= self.budget:\n                    break\n\n            # Stagnation check and restart\n            if self.global_best_fitness >= old_global_best_fitness:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                if np.random.rand() < self.restart_trigger:\n                    for i in range(self.num_swarms):\n                        swarm, fitness = self.initialize_swarm(func)\n                        self.swarms[i] = swarm\n                        personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n                        self.personal_best_positions[i] = personal_best_positions\n                        self.personal_best_fitness[i] = personal_best_fitness\n\n                        best_idx = np.argmin(fitness)\n                        if fitness[best_idx] < self.global_best_fitness:\n                            self.global_best_fitness = fitness[best_idx]\n                            self.global_best_position = swarm[best_idx].copy()\n                            self.stagnation_counter = 0\n\n                    velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter = 0\n\n            # Time variant flight length\n            self.time_variant_length *= self.time_decay\n            self.time_variant_length = max(self.time_variant_length, 0.01)  # Minimum flight length\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm CooperativeSwarmTimeVariant scored 0.573 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d3521816-dc64-4307-bed1-fc5a7569404e"], "operator": null, "metadata": {"aucs": [0.18818301852925834, 0.7959944966778968, 0.7780111889913387, 0.9048432605529725, 0.716823739445547, 0.8415206585337555, 0.3271948446071832, 0.426351310935014, 0.7649659007487672, 0.26058095717311247, 0.711799164680495, 0.9955865769910026, 0.24365853184692177, 0.25408896941049774, 0.7357513421343815, 0.7673747132176179, 0.6876144695663688, 0.3782211218025403, 0.1666871271801843, 0.5201392056253678]}}
{"id": "f89bf7ea-b62e-4511-a3ef-5744775a9dc5", "fitness": 0.6032747719650605, "name": "AdaptiveCooperativeSwarm", "description": "An adaptive cooperative swarm algorithm that dynamically adjusts its search behavior based on the swarm's diversity, fitness improvements, and stagnation, incorporating a novel 'attraction-repulsion' mechanism to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=10,\n                 inertia_range=(0.4, 0.9), cognitive_coeff_range=(1.5, 2.0),\n                 social_coeff_range=(1.5, 2.0), attraction_repulsion_rate=0.1,\n                 diversity_threshold=0.1, stagnation_threshold=50,\n                 local_search_probability=0.1, local_search_radius=0.1):\n        \"\"\"\n        Adaptive Cooperative Swarm Optimization algorithm with dynamic parameter adaptation,\n        an attraction-repulsion mechanism, swarm diversity control, and stagnation handling.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            num_swarms (int): The number of sub-swarms.\n            swarm_size (int): The size of each sub-swarm.\n            inertia_range (tuple): Range for inertia weight adaptation.\n            cognitive_coeff_range (tuple): Range for cognitive coefficient adaptation.\n            social_coeff_range (tuple): Range for social coefficient adaptation.\n            attraction_repulsion_rate (float): Probability of attraction or repulsion.\n            diversity_threshold (float): Threshold for considering the swarm diverse.\n            stagnation_threshold (int): Number of iterations without improvement before stagnation.\n            local_search_probability (float): Probability of performing local search.\n            local_search_radius (float): Radius for local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_range = inertia_range\n        self.cognitive_coeff_range = cognitive_coeff_range\n        self.social_coeff_range = social_coeff_range\n        self.attraction_repulsion_rate = attraction_repulsion_rate\n        self.diversity_threshold = diversity_threshold\n        self.stagnation_threshold = stagnation_threshold\n        self.local_search_probability = local_search_probability\n        self.local_search_radius = local_search_radius\n        self.swarms = []\n        self.personal_best_positions = []\n        self.personal_best_fitness = []\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.stagnation_counter = 0\n        self.inertia = np.random.uniform(self.inertia_range[0], self.inertia_range[1])\n        self.cognitive_coeff = np.random.uniform(self.cognitive_coeff_range[0], self.cognitive_coeff_range[1])\n        self.social_coeff = np.random.uniform(self.social_coeff_range[0], self.social_coeff_range[1])\n        self.fitness_history = []\n\n    def initialize_swarm(self, func):\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.fevals += self.swarm_size\n        return swarm, fitness\n\n    def update_personal_best(self, swarm, fitness):\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n        return personal_best_positions, personal_best_fitness\n\n    def calculate_diversity(self, swarm):\n        \"\"\"Calculates the diversity of a swarm.\"\"\"\n        centroid = np.mean(swarm, axis=0)\n        distances = np.linalg.norm(swarm - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def attraction_repulsion(self, swarm, global_best_position):\n        \"\"\"Applies an attraction-repulsion mechanism.\"\"\"\n        for i in range(self.swarm_size):\n            if np.random.rand() < self.attraction_repulsion_rate:\n                if np.random.rand() < 0.5:  # Attraction\n                    swarm[i] += 0.1 * (global_best_position - swarm[i])\n                else:  # Repulsion\n                    swarm[i] -= 0.1 * (global_best_position - swarm[i])\n        return swarm\n\n    def local_search(self, x, func):\n        \"\"\"Performs local search around a particle.\"\"\"\n        new_x = x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Adaptive Cooperative Swarm Optimization.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        # Initialize swarms\n        for _ in range(self.num_swarms):\n            swarm, fitness = self.initialize_swarm(func)\n            self.swarms.append(swarm)\n            personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n            self.personal_best_positions.append(personal_best_positions)\n            self.personal_best_fitness.append(personal_best_fitness)\n\n            # Update global best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.global_best_fitness:\n                self.global_best_fitness = fitness[best_idx]\n                self.global_best_position = swarm[best_idx].copy()\n                self.stagnation_counter = 0\n\n        velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n\n        while self.fevals < self.budget:\n            old_global_best_fitness = self.global_best_fitness\n            self.fitness_history.append(old_global_best_fitness)\n\n            for i in range(self.num_swarms):\n                swarm = self.swarms[i]\n                personal_best_positions = self.personal_best_positions[i]\n                personal_best_fitness = self.personal_best_fitness[i]\n                velocity = velocities[i]\n\n                # Calculate swarm diversity\n                diversity = self.calculate_diversity(swarm)\n\n                # Adjust parameters based on diversity and fitness improvement\n                if diversity < self.diversity_threshold:\n                    # Increase exploration\n                    self.inertia = np.random.uniform(0.7, 0.9)\n                    self.cognitive_coeff = np.random.uniform(0.5, 1.0)\n                    self.social_coeff = np.random.uniform(2.0, 2.5)\n                else:\n                    # Increase exploitation\n                    self.inertia = np.random.uniform(0.4, 0.6)\n                    self.cognitive_coeff = np.random.uniform(2.0, 2.5)\n                    self.social_coeff = np.random.uniform(0.5, 1.0)\n\n                r1 = np.random.rand(self.swarm_size, self.dim)\n                r2 = np.random.rand(self.swarm_size, self.dim)\n\n                velocity = (self.inertia * velocity\n                            + self.cognitive_coeff * r1 * (personal_best_positions - swarm)\n                            + self.social_coeff * r2 * (self.global_best_position - swarm))\n\n                new_swarm = swarm + velocity\n                new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n\n                # Apply attraction-repulsion mechanism\n                new_swarm = self.attraction_repulsion(new_swarm, self.global_best_position)\n\n                # Local search\n                for k in range(self.swarm_size):\n                    if np.random.rand() < self.local_search_probability:\n                        new_swarm[k] = self.local_search(new_swarm[k], func)\n                        new_swarm[k] = np.clip(new_swarm[k], func.bounds.lb, func.bounds.ub)\n\n                new_fitness = np.array([func(x) for x in new_swarm])\n                self.fevals += self.swarm_size\n\n                # Update personal best\n                improvement = new_fitness < personal_best_fitness\n                personal_best_positions[improvement] = new_swarm[improvement].copy()\n                personal_best_fitness[improvement] = new_fitness[improvement].copy()\n\n                self.swarms[i] = new_swarm\n                self.personal_best_positions[i] = personal_best_positions\n                self.personal_best_fitness[i] = personal_best_fitness\n                velocities[i] = velocity\n\n                # Update global best\n                best_idx = np.argmin(personal_best_fitness)\n                if personal_best_fitness[best_idx] < self.global_best_fitness:\n                    self.global_best_fitness = personal_best_fitness[best_idx]\n                    self.global_best_position = personal_best_positions[best_idx].copy()\n                    self.stagnation_counter = 0\n                if self.fevals >= self.budget:\n                    break\n\n            # Stagnation check\n            if self.global_best_fitness >= old_global_best_fitness:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Reset swarms\n                for i in range(self.num_swarms):\n                    swarm, fitness = self.initialize_swarm(func)\n                    self.swarms[i] = swarm\n                    personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n                    self.personal_best_positions[i] = personal_best_positions\n                    self.personal_best_fitness[i] = personal_best_fitness\n\n                    best_idx = np.argmin(fitness)\n                    if fitness[best_idx] < self.global_best_fitness:\n                        self.global_best_fitness = fitness[best_idx]\n                        self.global_best_position = swarm[best_idx].copy()\n                        self.stagnation_counter = 0\n\n                velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n                self.stagnation_counter = 0\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveCooperativeSwarm scored 0.603 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["987ae7d9-98be-4e84-859a-426e464f0a82"], "operator": null, "metadata": {"aucs": [0.1299873417058912, 0.27197385029191257, 0.599968073194754, 0.9338617131241213, 0.6316680890127696, 0.7338826644132954, 0.3729985883789897, 0.5291847783009082, 0.6067739970252359, 0.6292446808400773, 0.9344186961858904, 0.9959959748952363, 0.24793701476958907, 0.6185250214310161, 0.8765910168615324, 0.6843891727234392, 0.33787181193908944, 0.8297363527691031, 0.5848855105066828, 0.5156010909316762]}}
{"id": "d3641ff7-1247-419e-a3d5-6946452ecbfc", "fitness": 0.429452213886798, "name": "CooperativeSwarm", "description": "Cooperative Swarm with enhanced communication via a dynamic network topology, and a more robust self-adaptive learning rate combined with a novel aging mechanism.", "code": "import numpy as np\n\nclass CooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=10, inertia_range=(0.4, 0.9),\n                 cognitive_coeff_range=(1.5, 2.0), social_coeff_range=(1.5, 2.0), initial_exploration_pressure=0.1,\n                 restart_trigger=0.05, stagnation_threshold=100, exploration_decay=0.995, cauchy_mutation_rate=0.05,\n                 communication_probability=0.5):\n        \"\"\"\n        Cooperative Swarm Optimization algorithm with adaptive parameters, dynamic sub-swarm communication,\n        restart mechanism, adaptive exploration pressure, self-adaptive learning, and Cauchy mutation, and dynamic network topology.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            num_swarms (int): The number of sub-swarms.\n            swarm_size (int): The size of each sub-swarm.\n            inertia_range (tuple): Range for inertia weight adaptation.\n            cognitive_coeff_range (tuple): Range for cognitive coefficient adaptation.\n            social_coeff_range (tuple): Range for social coefficient adaptation.\n            initial_exploration_pressure (float): Initial probability of exploring a new region instead of exploiting.\n            restart_trigger (float): Trigger for swarm restart based on stagnation.\n            stagnation_threshold (int): Number of iterations without improvement before considering stagnation.\n            exploration_decay (float): Decay rate for exploration pressure.\n            cauchy_mutation_rate (float): Probability of applying Cauchy mutation.\n            communication_probability (float): Probability of a swarm communicating with another swarm.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_range = inertia_range\n        self.cognitive_coeff_range = cognitive_coeff_range\n        self.social_coeff_range = social_coeff_range\n        self.exploration_pressure = initial_exploration_pressure\n        self.initial_exploration_pressure = initial_exploration_pressure\n        self.restart_trigger = restart_trigger\n        self.stagnation_threshold = stagnation_threshold\n        self.exploration_decay = exploration_decay\n        self.cauchy_mutation_rate = cauchy_mutation_rate\n        self.communication_probability = communication_probability\n        self.swarms = []\n        self.personal_best_positions = []\n        self.personal_best_fitness = []\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.stagnation_counter = 0\n        self.particle_age = [np.zeros(self.swarm_size) for _ in range(self.num_swarms)] # Initialize particle ages\n\n        # Self-adaptive learning parameters\n        self.success_rates = np.zeros(self.num_swarms)\n        self.learning_rates = np.ones(self.num_swarms) * 0.1\n        self.learning_rate_decay = 0.99  # Decay factor for learning rate\n        self.learning_rate_min = 0.001  # Minimum learning rate\n\n    def initialize_swarm(self, func):\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.fevals += self.swarm_size\n        return swarm, fitness\n\n    def update_personal_best(self, swarm, fitness):\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n        return personal_best_positions, personal_best_fitness\n\n    def adapt_parameters(self):\n        \"\"\"Adapt inertia, cognitive, and social coefficients.\"\"\"\n        self.inertia = np.random.uniform(self.inertia_range[0], self.inertia_range[1])\n        self.cognitive_coeff = np.random.uniform(self.cognitive_coeff_range[0], self.cognitive_coeff_range[1])\n        self.social_coeff = np.random.uniform(self.social_coeff_range[0], self.social_coeff_range[1])\n\n    def cauchy_mutation(self, x):\n        \"\"\"Apply Cauchy mutation to a particle.\"\"\"\n        mutation = np.random.standard_cauchy(size=self.dim)\n        return x + 0.01 * mutation  # Scale the mutation\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Cooperative Swarm Optimization.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        # Initialize swarms\n        for _ in range(self.num_swarms):\n            swarm, fitness = self.initialize_swarm(func)\n            self.swarms.append(swarm)\n            personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n            self.personal_best_positions.append(personal_best_positions)\n            self.personal_best_fitness.append(personal_best_fitness)\n\n            # Update global best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.global_best_fitness:\n                self.global_best_fitness = fitness[best_idx]\n                self.global_best_position = swarm[best_idx].copy()\n                self.stagnation_counter = 0\n\n        velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n\n        while self.fevals < self.budget:\n            old_global_best_fitness = self.global_best_fitness\n\n            for i in range(self.num_swarms):\n                swarm = self.swarms[i]\n                personal_best_positions = self.personal_best_positions[i]\n                personal_best_fitness = self.personal_best_fitness[i]\n                velocity = velocities[i]\n\n                # Update velocities and positions\n                r1 = np.random.rand(self.swarm_size, self.dim)\n                r2 = np.random.rand(self.swarm_size, self.dim)\n\n                # Cooperative component: Influence from other swarms' best\n                cooperative_influence = np.zeros((self.swarm_size, self.dim))\n                num_contributing_swarms = 0\n                for j in range(self.num_swarms):\n                    if i != j and np.random.rand() < self.communication_probability:  # Dynamic communication\n                        best_idx_other = np.argmin(self.personal_best_fitness[j])\n                        if self.personal_best_fitness[j][best_idx_other] < np.min(personal_best_fitness):\n                            cooperative_influence += (self.personal_best_positions[j][best_idx_other] - swarm)\n                            num_contributing_swarms += 1\n                if num_contributing_swarms > 0:\n                    cooperative_influence /= num_contributing_swarms\n\n                # Adapt parameters\n                self.adapt_parameters()\n\n                velocity = (self.inertia * velocity\n                            + self.cognitive_coeff * r1 * (personal_best_positions - swarm)\n                            + self.social_coeff * r2 * (self.global_best_position - swarm)\n                            + self.learning_rates[i] * cooperative_influence) # Adaptive learning rate for coop influence\n\n                new_swarm = swarm + velocity\n\n                # Exploration: Introduce random search with adaptive probability\n                for k in range(self.swarm_size):\n                    if np.random.rand() < self.exploration_pressure:\n                        new_swarm[k] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Explore\n                        self.particle_age[i][k] = 0  # Reset age after exploration\n                    elif np.random.rand() < self.cauchy_mutation_rate:\n                        new_swarm[k] = self.cauchy_mutation(new_swarm[k])\n                        self.particle_age[i][k] = 0 # Reset age after mutation\n                    else:\n                        self.particle_age[i][k] += 1 # Increment age\n\n                new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n                new_fitness = np.array([func(x) for x in new_swarm])\n                self.fevals += self.swarm_size\n\n                # Update personal best\n                improvement = new_fitness < personal_best_fitness\n                num_improvements = np.sum(improvement)\n                personal_best_positions[improvement] = new_swarm[improvement].copy()\n                personal_best_fitness[improvement] = new_fitness[improvement].copy()\n\n                self.swarms[i] = new_swarm\n                self.personal_best_positions[i] = personal_best_positions\n                self.personal_best_fitness[i] = personal_best_fitness\n                velocities[i] = velocity\n\n                # Update global best\n                best_idx = np.argmin(personal_best_fitness)\n                if personal_best_fitness[best_idx] < self.global_best_fitness:\n                    self.global_best_fitness = personal_best_fitness[best_idx]\n                    self.global_best_position = personal_best_positions[best_idx].copy()\n                    self.stagnation_counter = 0\n\n                # Self-adaptive learning rate update (more robust)\n                self.success_rates[i] = 0.8 * self.success_rates[i] + 0.2 * (num_improvements / self.swarm_size) # Higher inertia for smoother update\n                if self.success_rates[i] > 0.2:\n                    self.learning_rates[i] *= 1.05  # Increase learning rate if successful (smaller step)\n                else:\n                    self.learning_rates[i] *= self.learning_rate_decay  # Decrease learning rate if not successful\n\n                self.learning_rates[i] = max(self.learning_rates[i], self.learning_rate_min) # Floor the learning rate\n                self.learning_rates[i] = np.clip(self.learning_rates[i], 0.01, 0.5) # Keep rate within bounds\n\n\n                if self.fevals >= self.budget:\n                    break\n\n            # Stagnation check and restart\n            if self.global_best_fitness >= old_global_best_fitness:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                if np.random.rand() < self.restart_trigger:\n                    for i in range(self.num_swarms):\n                        swarm, fitness = self.initialize_swarm(func)\n                        self.swarms[i] = swarm\n                        personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n                        self.personal_best_positions[i] = personal_best_positions\n                        self.personal_best_fitness[i] = personal_best_fitness\n                        self.particle_age[i] = np.zeros(self.swarm_size) # Reset age after restart\n\n                        best_idx = np.argmin(fitness)\n                        if fitness[best_idx] < self.global_best_fitness:\n                            self.global_best_fitness = fitness[best_idx]\n                            self.global_best_position = swarm[best_idx].copy()\n                            self.stagnation_counter = 0\n\n                    velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter = 0\n\n            # Adaptive Exploration Pressure\n            self.exploration_pressure *= self.exploration_decay\n            self.exploration_pressure = max(self.exploration_pressure, 0.001) # Avoid vanishing exploration\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm CooperativeSwarm scored 0.429 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d3521816-dc64-4307-bed1-fc5a7569404e"], "operator": null, "metadata": {"aucs": [0.15188087852202792, 0.3852592523251521, 0.38806944601132765, 0.7352685961439955, 0.2477791303302168, 0.5225603599584243, 0.31447764197354444, 0.3904428982803503, 0.40057592492084837, 0.17364752421076846, 0.46372876219882153, 1.0, 0.27687809862459034, 0.2713473650802304, 0.7315539932325148, 0.49563013618843177, 0.32109421535813054, 0.5542226274530231, 0.28392431997340495, 0.4807031069501573]}}
{"id": "107c9952-16e9-4347-b61e-e35c5f1aeb4a", "fitness": 0.5486524134563802, "name": "AdaptiveDEOrthogonalCrossover", "description": "An adaptive differential evolution algorithm with a population-based mutation factor and orthogonal crossover, dynamically adjusting exploration and exploitation based on the function evaluations remaining.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonalCrossover:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_factor_initial=0.5, crossover_rate_initial=0.7,\n                 orthogonal_components=5):\n        \"\"\"\n        Adaptive Differential Evolution with Population-Based Mutation Factor and Orthogonal Crossover.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            mutation_factor_initial (float): Initial mutation factor.\n            crossover_rate_initial (float): Initial crossover rate.\n            orthogonal_components (int): Number of orthogonal components for crossover.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_factor = mutation_factor_initial\n        self.crossover_rate = crossover_rate_initial\n        self.orthogonal_components = orthogonal_components\n        self.population = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.fevals = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly.\"\"\"\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.fevals += self.pop_size\n        return population, fitness\n\n    def orthogonal_crossover(self, parent, mutant):\n        \"\"\"Perform orthogonal crossover between parent and mutant.\"\"\"\n        num_components = min(self.orthogonal_components, self.dim)\n        indices = np.random.choice(self.dim, size=num_components, replace=False)\n        child = parent.copy()\n        child[indices] = mutant[indices]\n        return child\n\n    def adapt_parameters(self, remaining_evaluations):\n        \"\"\"Adapt mutation factor and crossover rate based on remaining evaluations.\"\"\"\n        # Linear reduction of mutation factor\n        self.mutation_factor = 0.1 + 0.9 * (remaining_evaluations / self.budget)\n        # Dynamic crossover rate\n        self.crossover_rate = 0.5 + 0.4 * np.sin(np.pi * (1 - remaining_evaluations / self.budget))\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Adaptive Differential Evolution with Orthogonal Crossover.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.population, self.fitness = self.initialize_population(func)\n        best_idx = np.argmin(self.fitness)\n        self.best_fitness = self.fitness[best_idx]\n        self.best_solution = self.population[best_idx].copy()\n\n        while self.fevals < self.budget:\n            remaining_evaluations = self.budget - self.fevals\n            self.adapt_parameters(remaining_evaluations)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = x1 + self.mutation_factor * (x2 - x3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                if np.random.rand() < self.crossover_rate:\n                     child = self.orthogonal_crossover(self.population[i], mutant)\n                else:\n                    child = self.population[i].copy()\n\n\n                # Evaluation\n                f_child = func(child)\n                self.fevals += 1\n\n                # Selection\n                if f_child < self.fitness[i]:\n                    self.population[i] = child\n                    self.fitness[i] = f_child\n\n                    if f_child < self.best_fitness:\n                        self.best_fitness = f_child\n                        self.best_solution = child.copy()\n                \n                if self.fevals >= self.budget:\n                    break\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDEOrthogonalCrossover scored 0.549 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4b8e9ea2-c87f-4a5f-98b8-d4d9ead4e8d9"], "operator": null, "metadata": {"aucs": [0.2286469987857216, 0.5330445751118151, 0.46460209710439504, 0.7346770198147041, 0.520913451870731, 0.595582306199146, 0.4123654325226215, 0.44379288814588413, 0.5131554689840397, 0.48830316569945453, 0.7151026742194874, 0.9902629539463931, 0.5696046057062918, 0.5175727225264386, 0.8461532001159761, 0.5708205773936446, 0.43758309671590534, 0.6705669684756141, 0.2259718533951517, 0.4943262123941893]}}
{"id": "874d404f-f771-43d7-91b2-12c6c2470c8a", "fitness": 0.35861917081910744, "name": "DynamicSubswarmCMA", "description": "Swarm with dynamic sub-swarms, adaptive topology, and covariance matrix adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicSubswarmCMA:\n    def __init__(self, budget=10000, dim=10, swarm_size=30, num_subswarms=3, \n                 inertia_max=0.9, inertia_min=0.2, cognitive_coeff=2.0, social_coeff=2.0,\n                 cma_learning_rate=0.1, topology_change_rate=0.05):\n        \"\"\"\n        Dynamic Subswarm CMA: PSO with dynamic sub-swarms, adaptive topology, and covariance matrix adaptation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            swarm_size (int): The total size of the swarm.\n            num_subswarms (int): The number of sub-swarms.\n            inertia_max (float): Maximum inertia weight.\n            inertia_min (float): Minimum inertia weight.\n            cognitive_coeff (float): Cognitive coefficient.\n            social_coeff (float): Social coefficient.\n            cma_learning_rate (float): Learning rate for CMA.\n            topology_change_rate (float): Probability of changing subswarm topology.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.num_subswarms = num_subswarms\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.cma_learning_rate = cma_learning_rate\n        self.topology_change_rate = topology_change_rate\n\n        self.swarm = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n\n        self.subswarm_sizes = np.full(num_subswarms, swarm_size // num_subswarms)\n        self.subswarm_assignments = np.repeat(np.arange(num_subswarms), swarm_size // num_subswarms)\n        remaining = swarm_size % num_subswarms\n        self.subswarm_assignments = np.concatenate([self.subswarm_assignments, np.random.choice(num_subswarms, remaining, replace=False)])\n        np.random.shuffle(self.subswarm_assignments)\n\n        self.means = None\n        self.covariances = None\n\n    def initialize_swarm(self, func):\n        \"\"\"\n        Initializes the swarm with random positions and velocities.\n        \"\"\"\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in self.swarm])\n        self.fevals += self.swarm_size\n        self.personal_best_positions = self.swarm.copy()\n        self.personal_best_fitness = fitness.copy()\n        self.global_best_fitness = np.min(fitness)\n        self.global_best_position = self.swarm[np.argmin(fitness)].copy()\n\n        # Initialize CMA parameters for each subswarm\n        self.means = np.array([np.mean(self.swarm[self.subswarm_assignments == i], axis=0) for i in range(self.num_subswarms)])\n        self.covariances = np.array([np.eye(self.dim) for _ in range(self.num_subswarms)])\n\n\n    def update_subswarm_topology(self):\n        \"\"\"\n        Randomly changes the assignment of particles to subswarms.\n        \"\"\"\n        if np.random.rand() < self.topology_change_rate:\n            np.random.shuffle(self.subswarm_assignments)\n\n\n    def sample_from_covariance(self, subswarm_id):\n        \"\"\"\n        Samples a vector from a multivariate Gaussian distribution using CMA.\n        \"\"\"\n        return np.random.multivariate_normal(self.means[subswarm_id], self.covariances[subswarm_id])\n\n\n    def update_covariance_matrix(self, subswarm_id, particle_positions):\n        \"\"\"\n        Updates the covariance matrix for a subswarm based on CMA.\n        \"\"\"\n        self.means[subswarm_id] = np.mean(particle_positions, axis=0)\n        diff = particle_positions - self.means[subswarm_id]\n        self.covariances[subswarm_id] = (1 - self.cma_learning_rate) * self.covariances[subswarm_id] + \\\n                                         self.cma_learning_rate * (diff.T @ diff) / len(particle_positions)\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Dynamic Subswarm CMA.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.initialize_swarm(func)\n\n        while self.fevals < self.budget:\n            self.update_subswarm_topology()\n\n            for i in range(self.swarm_size):\n                subswarm_id = self.subswarm_assignments[i]\n\n                # Update velocity (PSO component)\n                inertia = self.inertia_min + (self.inertia_max - self.inertia_min) * np.random.rand()\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                self.velocities[i] = (inertia * self.velocities[i] +\n                                       self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.swarm[i]) +\n                                       self.social_coeff * r2 * (self.global_best_position - self.swarm[i]))\n\n                # Update position (PSO component)\n                new_position = self.swarm[i] + self.velocities[i]\n\n                # CMA-based exploration\n                cma_sample = self.sample_from_covariance(subswarm_id)\n                new_position += 0.1 * cma_sample # scaling factor\n\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.fevals += 1\n\n                # Update personal best\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                self.swarm[i] = new_position\n\n                # Update global best\n                if new_fitness < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness\n                    self.global_best_position = new_position.copy()\n\n                if self.fevals >= self.budget:\n                    break\n            \n            # Update CMA parameters for each subswarm\n            for j in range(self.num_subswarms):\n                positions_in_subswarm = self.swarm[self.subswarm_assignments == j]\n                if len(positions_in_subswarm) > 0:\n                    self.update_covariance_matrix(j, positions_in_subswarm)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm DynamicSubswarmCMA scored 0.359 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ae6f5893-d06d-442b-9527-e8e13967c810"], "operator": null, "metadata": {"aucs": [0.16857452676899087, 0.23255630484587064, 0.39123947710207063, 0.4313350125768429, 0.24921309984530948, 0.28032347614054753, 0.28640037995641054, 0.3199692937319021, 0.30911861651329864, 0.22356251770969715, 0.43138453664292564, 0.9975996336393291, 0.2168666766898456, 0.278153276819719, 0.648797607074775, 0.34372655920307393, 0.32315656074167454, 0.376604372560557, 0.20856524281598954, 0.4552362450033194]}}
{"id": "7d6f9b0d-adab-4bdb-8685-fe81cb28209a", "fitness": 0.0, "name": "CooperativeSwarmOL", "description": "Cooperative swarm optimization with adaptive exploration, enhanced orthogonal learning using opposition-based learning, and dynamic parameter adaptation based on fitness improvement.", "code": "import numpy as np\n\nclass CooperativeSwarmOL:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=10, inertia_range=(0.4, 0.9),\n                 cognitive_coeff_range=(1.5, 2.0), social_coeff_range=(1.5, 2.0), exploration_pressure=0.1,\n                 restart_trigger=0.05, ol_rate=0.1, learning_rate_inertia=0.1, learning_rate_cognitive=0.1, learning_rate_social=0.1,\n                 obl_probability=0.2):\n        \"\"\"\n        Cooperative Swarm Optimization algorithm with orthogonal learning, adaptive parameters,\n        dynamic sub-swarm communication, restart mechanism, and opposition-based learning.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            num_swarms (int): The number of sub-swarms.\n            swarm_size (int): The size of each sub-swarm.\n            inertia_range (tuple): Range for inertia weight adaptation.\n            cognitive_coeff_range (tuple): Range for cognitive coefficient adaptation.\n            social_coeff_range (tuple): Range for social coefficient adaptation.\n            exploration_pressure (float): Probability of exploring a new region instead of exploiting.\n            restart_trigger (float): Trigger for swarm restart based on stagnation.\n            ol_rate (float): Rate of orthogonal learning.\n            obl_probability (float): Probability of applying opposition-based learning.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_range = inertia_range\n        self.cognitive_coeff_range = cognitive_coeff_range\n        self.social_coeff_range = social_coeff_range\n        self.exploration_pressure = exploration_pressure\n        self.restart_trigger = restart_trigger\n        self.ol_rate = ol_rate\n        self.obl_probability = obl_probability\n        self.swarms = []\n        self.personal_best_positions = []\n        self.personal_best_fitness = []\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.stagnation_counter = 0\n        self.max_stagnation = 100 #arbitrary value, adjust based on the problem\n\n        # Success history adaptation\n        self.success_inertia = []\n        self.success_cognitive = []\n        self.success_social = []\n        self.learning_rate_inertia = learning_rate_inertia\n        self.learning_rate_cognitive = learning_rate_cognitive\n        self.learning_rate_social = learning_rate_social\n\n        self.inertia = np.random.uniform(self.inertia_range[0], self.inertia_range[1])\n        self.cognitive_coeff = np.random.uniform(self.cognitive_coeff_range[0], self.cognitive_coeff_range[1])\n        self.social_coeff = np.random.uniform(self.social_coeff_range[0], self.social_coeff_range[1])\n\n    def initialize_swarm(self, func):\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.fevals += self.swarm_size\n        return swarm, fitness\n\n    def update_personal_best(self, swarm, fitness):\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n        return personal_best_positions, personal_best_fitness\n\n    def adapt_parameters(self, delta_f):\n        \"\"\"Adapt inertia, cognitive, and social coefficients based on success history.\"\"\"\n        # Update inertia weight\n        if len(self.success_inertia) > 0:\n            success_rate_inertia = np.mean(self.success_inertia[-10:])  # Average over last 10 successes\n            self.inertia = self.inertia + self.learning_rate_inertia * (success_rate_inertia - 0.5)\n            self.inertia = np.clip(self.inertia, self.inertia_range[0], self.inertia_range[1])\n\n        # Update cognitive coefficient\n        if len(self.success_cognitive) > 0:\n            success_rate_cognitive = np.mean(self.success_cognitive[-10:])\n            self.cognitive_coeff = self.cognitive_coeff + self.learning_rate_cognitive * (success_rate_cognitive - 0.5)\n            self.cognitive_coeff = np.clip(self.cognitive_coeff, self.cognitive_coeff_range[0], self.cognitive_coeff_range[1])\n\n        # Update social coefficient\n        if len(self.success_social) > 0:\n            success_rate_social = np.mean(self.success_social[-10:])\n            self.social_coeff = self.social_coeff + self.learning_rate_social * (success_rate_social - 0.5)\n            self.social_coeff = np.clip(self.social_coeff, self.social_coeff_range[0], self.social_coeff_range[1])\n\n    def orthogonal_learning(self, x, func):\n        \"\"\"Perform orthogonal learning.\"\"\"\n        basis = np.random.randn(self.dim, self.dim)\n        q, r = np.linalg.qr(basis)\n        d = np.diag(r)\n        phase = np.sign(d)\n        q = np.multiply(q, phase)\n\n        new_x = x.copy()\n        delta = np.random.uniform(-1, 1, size=self.dim)\n        new_x += self.ol_rate * np.dot(q, delta)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n        # Apply opposition-based learning with probability\n        if np.random.rand() < self.obl_probability:\n            x_opp = func.bounds.lb + func.bounds.ub - new_x\n            x_opp = np.clip(x_opp, func.bounds.lb, func.bounds.ub)\n            f_opp = func(x_opp)\n            self.fevals += 1\n\n            if f_opp < func(new_x):\n                return x_opp\n            else:\n                return new_x\n        else:\n            return new_x\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Cooperative Swarm Optimization.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        # Initialize swarms\n        for _ in range(self.num_swarms):\n            swarm, fitness = self.initialize_swarm(func)\n            self.swarms.append(swarm)\n            personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n            self.personal_best_positions.append(personal_best_positions)\n            self.personal_best_fitness.append(personal_best_fitness)\n\n            # Update global best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.global_best_fitness:\n                self.global_best_fitness = fitness[best_idx]\n                self.global_best_position = swarm[best_idx].copy()\n                self.stagnation_counter = 0 #reset counter if we improve\n\n        velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n\n        while self.fevals < self.budget:\n            old_global_best_fitness = self.global_best_fitness  # Store the previous global best\n\n            for i in range(self.num_swarms):\n                swarm = self.swarms[i]\n                personal_best_positions = self.personal_best_positions[i]\n                personal_best_fitness = self.personal_best_fitness[i]\n                velocity = velocities[i]\n\n                # Update velocities and positions\n                r1 = np.random.rand(self.swarm_size, self.dim)\n                r2 = np.random.rand(self.swarm_size, self.dim)\n\n                # Cooperative component: Influence from other swarms' best\n                cooperative_influence = np.zeros((self.swarm_size, self.dim))\n                num_contributing_swarms = 0\n                for j in range(self.num_swarms):\n                    if i != j:\n                        best_idx_other = np.argmin(self.personal_best_fitness[j])\n                        # Dynamic communication: only influence from better swarms\n                        if self.personal_best_fitness[j][best_idx_other] < np.min(personal_best_fitness):\n                            cooperative_influence += (self.personal_best_positions[j][best_idx_other] - swarm)\n                            num_contributing_swarms += 1\n                if num_contributing_swarms > 0:\n                    cooperative_influence /= num_contributing_swarms # Average influence\n\n                # Adapt parameters\n                if old_global_best_fitness > self.global_best_fitness:\n                    delta_f = old_global_best_fitness - self.global_best_fitness\n                    self.adapt_parameters(delta_f)\n                else:\n                    delta_f = 0\n\n                velocity = (self.inertia * velocity\n                            + self.cognitive_coeff * r1 * (personal_best_positions - swarm)\n                            + self.social_coeff * r2 * (self.global_best_position - swarm)\n                            + 0.1 * cooperative_influence) # Add cooperative influence with a small weight\n\n                new_swarm = swarm + velocity\n\n                # Exploration: Introduce random search with probability exploration_pressure\n                for k in range(self.swarm_size):\n                    if np.random.rand() < self.exploration_pressure:\n                        new_swarm[k] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Explore\n\n                # Orthogonal Learning\n                for k in range(self.swarm_size):\n                    if np.random.rand() < self.ol_rate:\n                        new_swarm[k] = self.orthogonal_learning(new_swarm[k], func)\n\n                new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n                new_fitness = np.array([func(x) for x in new_swarm])\n                self.fevals += self.swarm_size\n\n                # Update personal best\n                improvement = new_fitness < personal_best_fitness\n                personal_best_positions[improvement] = new_swarm[improvement].copy()\n                personal_best_fitness[improvement] = new_fitness[improvement].copy()\n\n                self.swarms[i] = new_swarm\n                self.personal_best_positions[i] = personal_best_positions\n                self.personal_best_fitness[i] = personal_best_fitness\n                velocities[i] = velocity\n\n                # Update global best\n                best_idx = np.argmin(personal_best_fitness)\n                if personal_best_fitness[best_idx] < self.global_best_fitness:\n                    self.success_inertia.append(1)\n                    self.success_cognitive.append(1)\n                    self.success_social.append(1)\n                    self.global_best_fitness = personal_best_fitness[best_idx]\n                    self.global_best_position = personal_best_positions[best_idx].copy()\n                    self.stagnation_counter = 0 # Reset stagnation counter when a better solution is found\n                else:\n                    self.success_inertia.append(0)\n                    self.success_cognitive.append(0)\n                    self.success_social.append(0)\n                \n                if self.fevals >= self.budget:\n                    break\n\n            # Stagnation check and restart\n            if self.global_best_fitness >= old_global_best_fitness: # No improvement\n                self.stagnation_counter += 1\n            else:\n                 self.stagnation_counter = 0 # Reset stagnation counter when a better solution is found\n            \n            if self.stagnation_counter > self.max_stagnation:\n                # Restart the swarm\n                if np.random.rand() < self.restart_trigger:  # Probabilistic restart\n                    for i in range(self.num_swarms):\n                        swarm, fitness = self.initialize_swarm(func)\n                        self.swarms[i] = swarm\n                        personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n                        self.personal_best_positions[i] = personal_best_positions\n                        self.personal_best_fitness[i] = personal_best_fitness\n\n                        best_idx = np.argmin(fitness)\n                        if fitness[best_idx] < self.global_best_fitness:\n                            self.global_best_fitness = fitness[best_idx]\n                            self.global_best_position = swarm[best_idx].copy()\n                            self.stagnation_counter = 0 #reset counter if we improve\n\n                    velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n                    self.stagnation_counter = 0 #reset counter after restart\n                else:\n                    self.stagnation_counter = 0 #reset counter even if no restart to prevent continuous restarts\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm CooperativeSwarmOL scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["987ae7d9-98be-4e84-859a-426e464f0a82"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "ce3689f1-c1dd-4513-abd2-e594608b2415", "fitness": 0.5070399341851145, "name": "CooperativeSwarmOL", "description": "Cooperative Swarm with improved parameter adaptation using exponential moving average, adaptive exploration pressure, and a more robust stagnation detection with dynamic swarm merging.", "code": "import numpy as np\n\nclass CooperativeSwarmOL:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=10, inertia_range=(0.4, 0.9),\n                 cognitive_coeff_range=(1.5, 2.0), social_coeff_range=(1.5, 2.0), exploration_pressure=0.1,\n                 restart_trigger=0.05, ol_rate=0.1, learning_rate=0.1, stagnation_threshold=50,\n                 merge_trigger=0.2):\n        \"\"\"\n        Cooperative Swarm Optimization algorithm with orthogonal learning, adaptive parameters,\n        dynamic sub-swarm communication and restart mechanism. Includes exponential moving average for parameter adaptation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            num_swarms (int): The number of sub-swarms.\n            swarm_size (int): The size of each sub-swarm.\n            inertia_range (tuple): Range for inertia weight adaptation.\n            cognitive_coeff_range (tuple): Range for cognitive coefficient adaptation.\n            social_coeff_range (tuple): Range for social coefficient adaptation.\n            exploration_pressure (float): Initial probability of exploring a new region instead of exploiting.\n            restart_trigger (float): Trigger for swarm restart based on stagnation.\n            ol_rate (float): Rate of orthogonal learning.\n            learning_rate (float): Learning rate for parameter adaptation.\n            stagnation_threshold (int): Number of iterations without improvement before triggering restart/merge.\n            merge_trigger (float): Probability to merge swarms when stagnation is detected.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_range = inertia_range\n        self.cognitive_coeff_range = cognitive_coeff_range\n        self.social_coeff_range = social_coeff_range\n        self.exploration_pressure = exploration_pressure\n        self.restart_trigger = restart_trigger\n        self.ol_rate = ol_rate\n        self.swarms = []\n        self.personal_best_positions = []\n        self.personal_best_fitness = []\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.stagnation_counter = 0\n        self.stagnation_threshold = stagnation_threshold\n        self.merge_trigger = merge_trigger\n\n        # Adaptive exploration pressure\n        self.initial_exploration_pressure = exploration_pressure\n        self.exploration_decay = 0.995\n        self.exploration_floor = 0.01\n\n        # Exponential moving average for parameter adaptation\n        self.learning_rate = learning_rate\n        self.inertia = np.random.uniform(self.inertia_range[0], self.inertia_range[1])\n        self.cognitive_coeff = np.random.uniform(self.cognitive_coeff_range[0], self.cognitive_coeff_range[1])\n        self.social_coeff = np.random.uniform(self.social_coeff_range[0], self.social_coeff_range[1])\n\n        self.inertia_ema = self.inertia\n        self.cognitive_ema = self.cognitive_coeff\n        self.social_ema = self.social_coeff\n\n    def initialize_swarm(self, func):\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.fevals += self.swarm_size\n        return swarm, fitness\n\n    def update_personal_best(self, swarm, fitness):\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n        return personal_best_positions, personal_best_fitness\n\n    def adapt_parameters(self, delta_f):\n        \"\"\"Adapt inertia, cognitive, and social coefficients based on exponential moving average.\"\"\"\n        if delta_f > 0:\n            # Reward successful parameters\n            self.inertia += self.learning_rate * (self.inertia_range[1] - self.inertia)\n            self.cognitive_coeff += self.learning_rate * (self.cognitive_coeff_range[1] - self.cognitive_coeff)\n            self.social_coeff += self.learning_rate * (self.social_coeff_range[1] - self.social_coeff)\n        else:\n            # Penalize unsuccessful parameters\n            self.inertia -= self.learning_rate * (self.inertia - self.inertia_range[0])\n            self.cognitive_coeff -= self.learning_rate * (self.cognitive_coeff - self.cognitive_coeff_range[0])\n            self.social_coeff -= self.learning_rate * (self.social_coeff - self.social_coeff_range[0])\n\n        self.inertia = np.clip(self.inertia, self.inertia_range[0], self.inertia_range[1])\n        self.cognitive_coeff = np.clip(self.cognitive_coeff, self.cognitive_coeff_range[0], self.cognitive_coeff_range[1])\n        self.social_coeff = np.clip(self.social_coeff, self.social_coeff_range[0], self.social_coeff_range[1])\n\n        # Exponential moving average update\n        self.inertia_ema = (1 - self.learning_rate) * self.inertia_ema + self.learning_rate * self.inertia\n        self.cognitive_ema = (1 - self.learning_rate) * self.cognitive_ema + self.learning_rate * self.cognitive_coeff\n        self.social_ema = (1 - self.learning_rate) * self.social_ema + self.learning_rate * self.social_coeff\n\n    def orthogonal_learning(self, x, func):\n        \"\"\"Perform orthogonal learning.\"\"\"\n        basis = np.random.randn(self.dim, self.dim)\n        q, r = np.linalg.qr(basis)\n        d = np.diag(r)\n        phase = np.sign(d)\n        q = np.multiply(q, phase)\n\n        new_x = x.copy()\n        delta = np.random.uniform(-1, 1, size=self.dim)\n        new_x += self.ol_rate * np.dot(q, delta)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x\n\n    def merge_swarms(self):\n        \"\"\"Merges the two worst performing swarms into a single swarm.\"\"\"\n        if self.num_swarms > 1:\n            # Find the two worst performing swarms\n            avg_fitness = [np.mean(fitness) for fitness in self.personal_best_fitness]\n            worst_idx1 = np.argmax(avg_fitness)\n            avg_fitness[worst_idx1] = -np.inf  # Avoid selecting the same swarm twice\n            worst_idx2 = np.argmax(avg_fitness)\n\n            # Merge the two swarms\n            self.swarms[worst_idx1] = np.concatenate((self.swarms[worst_idx1], self.swarms[worst_idx2]))\n            self.personal_best_positions[worst_idx1] = np.concatenate((self.personal_best_positions[worst_idx1], self.personal_best_positions[worst_idx2]))\n            self.personal_best_fitness[worst_idx1] = np.concatenate((self.personal_best_fitness[worst_idx1], self.personal_best_fitness[worst_idx2]))\n\n            # Remove the second swarm\n            del self.swarms[worst_idx2]\n            del self.personal_best_positions[worst_idx2]\n            del self.personal_best_fitness[worst_idx2]\n            self.num_swarms -= 1\n\n            # Reduce swarm size to original\n            indices = np.argsort(self.personal_best_fitness[worst_idx1])[:self.swarm_size]\n            self.swarms[worst_idx1] = self.swarms[worst_idx1][indices]\n            self.personal_best_positions[worst_idx1] = self.personal_best_positions[worst_idx1][indices]\n            self.personal_best_fitness[worst_idx1] = self.personal_best_fitness[worst_idx1][indices]\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Cooperative Swarm Optimization.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        # Initialize swarms\n        self.swarms = []\n        self.personal_best_positions = []\n        self.personal_best_fitness = []\n        self.num_swarms = 5\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.fevals = 0\n        self.stagnation_counter = 0\n        self.exploration_pressure = self.initial_exploration_pressure\n\n        for _ in range(self.num_swarms):\n            swarm, fitness = self.initialize_swarm(func)\n            self.swarms.append(swarm)\n            personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n            self.personal_best_positions.append(personal_best_positions)\n            self.personal_best_fitness.append(personal_best_fitness)\n\n            # Update global best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.global_best_fitness:\n                self.global_best_fitness = fitness[best_idx]\n                self.global_best_position = swarm[best_idx].copy()\n                self.stagnation_counter = 0 #reset counter if we improve\n\n        velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n\n        while self.fevals < self.budget:\n            old_global_best_fitness = self.global_best_fitness  # Store the previous global best\n\n            for i in range(self.num_swarms):\n                swarm = self.swarms[i]\n                personal_best_positions = self.personal_best_positions[i]\n                personal_best_fitness = self.personal_best_fitness[i]\n                velocity = velocities[i]\n\n                # Update velocities and positions\n                r1 = np.random.rand(self.swarm_size, self.dim)\n                r2 = np.random.rand(self.swarm_size, self.dim)\n\n                # Cooperative component: Influence from other swarms' best\n                cooperative_influence = np.zeros((self.swarm_size, self.dim))\n                num_contributing_swarms = 0\n                for j in range(self.num_swarms):\n                    if i != j:\n                        best_idx_other = np.argmin(self.personal_best_fitness[j])\n                        # Dynamic communication: only influence from better swarms\n                        if self.personal_best_fitness[j][best_idx_other] < np.min(personal_best_fitness):\n                            cooperative_influence += (self.personal_best_positions[j][best_idx_other] - swarm)\n                            num_contributing_swarms += 1\n                if num_contributing_swarms > 0:\n                    cooperative_influence /= num_contributing_swarms # Average influence\n\n                # Adapt parameters\n                delta_f = old_global_best_fitness - self.global_best_fitness\n                self.adapt_parameters(delta_f)\n\n                velocity = (self.inertia_ema * velocity\n                            + self.cognitive_ema * r1 * (personal_best_positions - swarm)\n                            + self.social_ema * r2 * (self.global_best_position - swarm)\n                            + 0.1 * cooperative_influence) # Add cooperative influence with a small weight\n\n                new_swarm = swarm + velocity\n\n                # Exploration: Introduce random search with probability exploration_pressure\n                for k in range(self.swarm_size):\n                    if np.random.rand() < self.exploration_pressure:\n                        new_swarm[k] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Explore\n\n                # Orthogonal Learning\n                for k in range(self.swarm_size):\n                    if np.random.rand() < self.ol_rate:\n                        new_swarm[k] = self.orthogonal_learning(new_swarm[k], func)\n\n                new_swarm = np.clip(new_swarm, func.bounds.lb, func.bounds.ub)\n                new_fitness = np.array([func(x) for x in new_swarm])\n                self.fevals += self.swarm_size\n\n                # Update personal best\n                improvement = new_fitness < personal_best_fitness\n                personal_best_positions[improvement] = new_swarm[improvement].copy()\n                personal_best_fitness[improvement] = new_fitness[improvement].copy()\n\n                self.swarms[i] = new_swarm\n                self.personal_best_positions[i] = personal_best_positions\n                self.personal_best_fitness[i] = personal_best_fitness\n                velocities[i] = velocity\n\n                # Update global best\n                best_idx = np.argmin(personal_best_fitness)\n                if personal_best_fitness[best_idx] < self.global_best_fitness:\n                    self.global_best_fitness = personal_best_fitness[best_idx]\n                    self.global_best_position = personal_best_positions[best_idx].copy()\n                    self.stagnation_counter = 0 # Reset stagnation counter when a better solution is found\n\n                if self.fevals >= self.budget:\n                    break\n\n            # Adaptive exploration pressure\n            self.exploration_pressure = max(self.exploration_pressure * self.exploration_decay, self.exploration_floor)\n\n            # Stagnation check and restart or merge\n            if self.global_best_fitness >= old_global_best_fitness: # No improvement\n                self.stagnation_counter += 1\n            else:\n                 self.stagnation_counter = 0 # Reset stagnation counter when a better solution is found\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                if np.random.rand() < self.restart_trigger:\n                    # Restart the swarm\n                    for i in range(self.num_swarms):\n                        swarm, fitness = self.initialize_swarm(func)\n                        self.swarms[i] = swarm\n                        personal_best_positions, personal_best_fitness = self.update_personal_best(swarm, fitness)\n                        self.personal_best_positions[i] = personal_best_positions\n                        self.personal_best_fitness[i] = personal_best_fitness\n\n                        best_idx = np.argmin(fitness)\n                        if fitness[best_idx] < self.global_best_fitness:\n                            self.global_best_fitness = fitness[best_idx]\n                            self.global_best_position = swarm[best_idx].copy()\n                            self.stagnation_counter = 0 #reset counter if we improve\n\n                    velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n                    self.stagnation_counter = 0 #reset counter after restart\n                elif np.random.rand() < self.merge_trigger:\n                    # Merge swarms\n                    self.merge_swarms()\n                    # Reinitialize velocities after merging.\n                    velocities = [np.zeros_like(swarm) for swarm in self.swarms]\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter = 0 # Reset counter even if no restart to prevent continuous restarts\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm CooperativeSwarmOL scored 0.507 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["987ae7d9-98be-4e84-859a-426e464f0a82"], "operator": null, "metadata": {"aucs": [0.1746322412421425, 0.21051533253724164, 0.5215911167867282, 0.8965073062870987, 0.6433787443719237, 0.6478180705119979, 0.3458755391518402, 0.4990133295817072, 0.5204509043314425, 0.2348915486432709, 0.776547719592438, 0.995535808327318, 0.30436296788638184, 0.2616945310051182, 0.5865212494289274, 0.6729034589716674, 0.36671138065370545, 0.7523358025966662, 0.22405962474543317, 0.5054520070492416]}}
