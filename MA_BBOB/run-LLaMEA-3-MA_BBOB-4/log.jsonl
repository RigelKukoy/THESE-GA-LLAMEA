{"id": "102953e9-88a9-4f46-936d-8a8b70ba165b", "fitness": -Infinity, "name": "SimpleCMAES", "description": "Covariance matrix adaptation evolution strategy with a simplified update rule and adaptive population size.", "code": "import numpy as np\n\nclass SimpleCMAES:\n    def __init__(self, budget=10000, dim=10, mu_factor=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(dim * mu_factor)\n        self.lambda_ = 4 + int(3 * np.log(dim))\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n        self.m = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.pc = np.zeros(dim)\n        self.chiN = np.sqrt(dim) * (1 - (1 / (4 * dim)) + (1 / (21 * dim**2)))\n\n        self.c_sigma = (self.mu / self.lambda_) / (np.linalg.norm(self.ps) + 1e-8)\n        self.d_sigma = 1 + 2 * np.max([0, 1 - (np.linalg.norm(self.ps) / self.chiN)])\n\n        self.c_c = (4 + (self.mu / self.dim)) / (dim + 4)\n\n        self.mu_weights = np.log(self.lambda_ + 1) - np.log(np.arange(1, self.mu + 1))\n        self.mu_weights = self.mu_weights / np.sum(self.mu_weights)\n        self.mueff = np.sum(self.mu_weights)**2 / np.sum(self.mu_weights**2)\n        self.c_mu = np.min([1 - (1/self.mueff), (2*(self.mueff-2+(1/self.mueff))) / ((dim+2)**2 + (self.mueff/2))])\n        self.c_1 = 0.3 / ((dim + 1.3)**2 + self.mueff) # simplified rank-one update\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        used_budget = 0\n\n        while used_budget < self.budget:\n            z = np.random.randn(self.dim, self.lambda_)\n            A = np.linalg.cholesky(self.C)\n            x = self.m[:, None] + self.sigma * A @ z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x.T])\n            used_budget += self.lambda_\n            \n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[:, np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_mu = x[:, idx[:self.mu]]\n            z_mu = z[:, idx[:self.mu]]\n\n            y_w = z_mu @ self.mu_weights\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * y_w\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / self.chiN) - 1))\n            self.sigma = np.clip(self.sigma, 1e-10, 1)\n            \n            self.m = self.m + self.sigma * A @ y_w\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2-self.c_c) * self.mueff) * A @ y_w\n            self.C = (1-self.c_1) * self.C + self.c_1 * (np.outer(self.pc, self.pc))\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "e422cde9-bb59-45d4-b5f2-a9caed9c5175", "fitness": -Infinity, "name": "CMAES", "description": "Covariance matrix adaptation evolution strategy (CMA-ES) with restarts and a budget-aware step size adaptation.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, c1=None, cmu=None, sigma0=0.2, restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.restarts = restarts\n\n        self.cs = cs\n        self.c1 = c1 if c1 is not None else 2 / (self.dim + 1.3)**2\n        self.cmu = cmu if cmu is not None else min(1 - self.c1, 2 + (self.popsize / 3) / self.dim)\n        self.sigma0 = sigma0\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        evals_used = 0\n\n        for restart in range(self.restarts):\n            # Initialization\n            mu = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            sigma = self.sigma0\n            C = np.eye(self.dim)\n            pc = np.zeros(self.dim)\n            ps = np.zeros(self.dim)\n            weights = np.log(self.popsize + 1/2) - np.log(np.arange(1, self.popsize + 1))\n            weights = weights / np.sum(weights)\n            mu_eff = 1 / np.sum(weights**2)\n\n            C_eig_sqrt = None # Delayed calculation of C_eig_sqrt\n\n            while evals_used < self.budget:\n                # Sample lambda candidate solutions\n                z = np.random.randn(self.dim, self.popsize)\n                \n                if C_eig_sqrt is None:\n                    C_eig_val, C_eig_vec = np.linalg.eigh(C)\n                    C_eig_sqrt = C_eig_vec @ np.diag(np.sqrt(C_eig_val))\n                    \n                x = mu[:, np.newaxis] + sigma * (C_eig_sqrt @ z)  # broadcasting\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                \n                f = np.array([func(xi) for xi in x.T])\n                evals_used += self.popsize\n\n                if np.any(f < self.f_opt):\n                    best_idx = np.argmin(f)\n                    if f[best_idx] < self.f_opt:\n                        self.f_opt = f[best_idx]\n                        self.x_opt = x[:, best_idx].copy()  #important to copy\n            \n                # Selection and Recombination\n                idx = np.argsort(f)\n                x_sorted = x[:, idx]\n                z_sorted = z[:, idx]\n\n                mu_new = np.sum(weights * x_sorted, axis=1)\n\n                # Step-size adaptation\n                ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * mu_eff) * (C_eig_sqrt @ (mu_new - mu) / sigma)\n                \n                norm_ps = np.linalg.norm(ps)\n                sigma = sigma * np.exp((self.cs / 0.841) * (norm_ps - np.sqrt(self.dim)))\n                \n                if sigma > 2:\n                    sigma = 2\n                elif sigma < 1e-8:\n                    sigma = 1e-8\n                \n                mu = mu_new\n\n                # Covariance matrix adaptation\n                pc = (1 - self.c1) * pc + np.sqrt(self.c1 * (2 - self.c1) * mu_eff) * (mu - mu_new) / sigma\n                C = (1 - self.c1 - self.cmu) * C + self.c1 * np.outer(pc, pc) + self.cmu * (z_sorted @ np.diag(weights) @ z_sorted.T)\n\n                C = np.triu(C) + np.triu(C, 1).T  # enforce symmetry\n                \n                #check C matrix for being positive definite:\n                try:\n                    np.linalg.cholesky(C)\n                except np.linalg.LinAlgError:\n                     C = np.eye(self.dim)\n\n                C_eig_sqrt = None # Recalculate C_eig_sqrt\n\n                if evals_used >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "ef5089bb-806f-4ee0-bc39-fbb2c7bcf837", "fitness": -Infinity, "name": "AdaptiveEvolutionaryStrategy", "description": "Population-based algorithm with adaptive mutation and crossover rates based on the population diversity, coupled with a restart mechanism when stagnation is detected.", "code": "import numpy as np\n\nclass AdaptiveEvolutionaryStrategy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, restart_trigger=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.restart_trigger = restart_trigger  # Percentage decrease in best fitness to trigger restart\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def initialize_population(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        return population, fitness\n\n    def calculate_diversity(self, population):\n        \"\"\"Calculates the average distance between individuals in the population.\"\"\"\n        centroid = np.mean(population, axis=0)\n        distances = np.linalg.norm(population - centroid, axis=1)\n        return np.mean(distances)\n\n    def adapt_rates(self, diversity):\n        \"\"\"Adapts mutation and crossover rates based on population diversity.\"\"\"\n        # If diversity is high, increase crossover, decrease mutation\n        # If diversity is low, decrease crossover, increase mutation\n\n        # Normalize diversity to [0, 1] - assuming diversity is roughly proportional to scale of the search space (10)\n        normalized_diversity = diversity / (5 - (-5))  #Scale of search space\n        \n        self.mutation_rate = 0.1 + 0.4 * (1 - normalized_diversity)  # Increase mutation when diversity is low\n        self.crossover_rate = 0.3 + 0.7 * normalized_diversity  # Increase crossover when diversity is high\n        self.mutation_rate = np.clip(self.mutation_rate, 0.05, 0.5)\n        self.crossover_rate = np.clip(self.crossover_rate, 0.2, 0.95)\n    \n\n    def evolve(self, population, fitness, func):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            # Mutation\n            if np.random.rand() < self.mutation_rate:\n                mutation_indices = np.random.choice(self.dim, size=int(self.dim * self.mutation_rate), replace=False)  # Mutate a fraction of dimensions\n                mutation_values = np.random.normal(0, 1, size=len(mutation_indices)) * (func.bounds.ub - func.bounds.lb) * 0.05  # Scale mutation by search space and a small factor\n                new_population[i, mutation_indices] = population[i, mutation_indices] + mutation_values\n                new_population[i] = np.clip(new_population[i], func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            if np.random.rand() < self.crossover_rate:\n                other_individual = np.random.randint(0, self.pop_size)\n                crossover_points = np.random.rand(self.dim) < self.crossover_rate\n                new_population[i, crossover_points] = population[other_individual, crossover_points]\n\n        new_fitness = np.array([func(x) for x in new_population])\n\n        # Selection (replace if better)\n        for i in range(self.pop_size):\n            if new_fitness[i] < fitness[i]:\n                population[i] = new_population[i]\n                fitness[i] = new_fitness[i]\n\n        return population, fitness\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        eval_count = 0\n\n        population, fitness = self.initialize_population(func)\n        eval_count += self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        initial_best_fitness = self.f_opt\n\n        while eval_count < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.adapt_rates(diversity)\n            population, fitness = self.evolve(population, fitness, func)\n            eval_count += self.pop_size\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n            \n            # Restart mechanism\n            if (initial_best_fitness - self.f_opt) / initial_best_fitness < self.restart_trigger and eval_count > self.budget * 0.1:  # Check for stagnation after some initial exploration\n                population, fitness = self.initialize_population(func)\n                eval_count += self.pop_size\n                best_index = np.argmin(fitness)\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                initial_best_fitness = self.f_opt # Reset initial best fitness\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occurred: operands could not be broadcast together with shapes (0,) (2,) .", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "b82a00cd-c8d2-4027-ae54-8cd6edad51e7", "fitness": 0.6682151427297766, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with ensemble mutation strategies and archive.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.archive_size = archive_size\n        self.archive = []\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation Strategies\n                mutation_strategy = np.random.choice([1, 2, 3]) # Ensemble of mutation strategies\n                \n                if mutation_strategy == 1: # DE/rand/1\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[indices]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n                elif mutation_strategy == 2: # DE/current-to-best/1\n                    x_best = population[np.argmin(fitness)]\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = population[indices]\n                    mutant = population[i] + self.F * (x_best - population[i]) + self.F * (x_r1 - x_r2)\n                elif mutation_strategy == 3: # DE/rand/2\n                    indices = np.random.choice(self.pop_size, 5, replace=False)\n                    x_r1, x_r2, x_r3, x_r4, x_r5 = population[indices]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3) + self.F * (x_r4 - x_r5)\n                \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub) # Clip to bounds\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    # Add replaced individual to archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        # Replace random element in archive\n                        replace_index = np.random.randint(0, self.archive_size)\n                        self.archive[replace_index] = population[i].copy()\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.668 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.26047021337681275, 0.4576348949255742, 0.6807757250821962, 0.8501026102574075, 0.7420984053677531, 0.8034318572729819, 0.6417873252883548, 0.6752026223722565, 0.7587045388441982, 0.6705656180375894, 0.8473934477761202, 0.9868225061675818, 0.37938586435514143, 0.7101322867199483, 0.9169589053524132, 0.7963749439063291, 0.6112340387300789, 0.8537524051615216, 0.206533492844016, 0.5149411527572536]}}
{"id": "91ba986d-183a-42a1-a0fb-9b1ff8e4f1ab", "fitness": -Infinity, "name": "SimpleCMAES", "description": "Simplified CMA-ES with rank-one update and adaptive step-size focusing on efficiency and reduced parameter set.", "code": "import numpy as np\n\nclass SimpleCMAES:\n    def __init__(self, budget=10000, dim=10, mu_factor=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(dim * mu_factor)\n        self.lambda_ = 4 + int(3 * np.log(dim))\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n        self.m = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.chiN = np.sqrt(dim) * (1 - (1 / (4 * dim)) + (1 / (21 * dim**2)))\n        self.c_sigma = (self.mu / self.lambda_) / (np.linalg.norm(self.ps) + 1e-8)\n        self.d_sigma = 1 + 2 * np.max([0, 1 - (np.linalg.norm(self.ps) / self.chiN)])\n        self.mu_weights = np.log(self.lambda_ + 1) - np.log(np.arange(1, self.mu + 1))\n        self.mu_weights = self.mu_weights / np.sum(self.mu_weights)\n        self.mueff = np.sum(self.mu_weights)**2 / np.sum(self.mu_weights**2)\n        self.c_1 = 0.3 / ((dim + 1.3)**2 + self.mueff)\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        used_budget = 0\n\n        while used_budget < self.budget:\n            z = np.random.randn(self.dim, self.lambda_)\n            A = np.linalg.cholesky(self.C)\n            x = self.m[:, None] + self.sigma * A @ z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x.T])\n            used_budget += self.lambda_\n            \n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[:, np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_mu = x[:, idx[:self.mu]]\n            z_mu = z[:, idx[:self.mu]]\n\n            y_w = np.sum(z_mu * self.mu_weights, axis=1)\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * y_w\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / self.chiN) - 1))\n            self.sigma = np.clip(self.sigma, 1e-10, 1)\n            \n            self.m = self.m + self.sigma * A @ y_w\n            self.C = (1-self.c_1) * self.C + self.c_1 * np.outer(self.ps, self.ps)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["102953e9-88a9-4f46-936d-8a8b70ba165b"], "operator": null, "metadata": {}}
{"id": "8bd19654-d341-4906-a706-5f85c22e9cf8", "fitness": -Infinity, "name": "CMAES", "description": "CMA-ES with simplified covariance update and step size adaptation, clipping sigma, and handling non-positive definite covariance matrices using eigenvalue clipping.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, c1=None, cmu=None, sigma0=0.2, restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.restarts = restarts\n\n        self.cs = cs\n        self.c1 = c1 if c1 is not None else 2 / (self.dim + 1.3)**2\n        self.cmu = cmu if cmu is not None else min(1 - self.c1, 2 + (self.popsize / 3) / self.dim)\n        self.sigma0 = sigma0\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        evals_used = 0\n\n        for restart in range(self.restarts):\n            # Initialization\n            mu = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            sigma = self.sigma0\n            C = np.eye(self.dim)\n            ps = np.zeros(self.dim)\n            weights = np.log(self.popsize + 1/2) - np.log(np.arange(1, self.popsize + 1))\n            weights = weights / np.sum(weights)\n            mu_eff = 1 / np.sum(weights**2)\n\n            while evals_used < self.budget:\n                # Sample lambda candidate solutions\n                z = np.random.randn(self.dim, self.popsize)\n                \n                C_eig_val, C_eig_vec = np.linalg.eigh(C)\n                C_eig_sqrt = C_eig_vec @ np.diag(np.sqrt(np.maximum(C_eig_val, 0))) # Ensure positive eigenvalues\n                \n                x = mu[:, np.newaxis] + sigma * (C_eig_sqrt @ z)  # broadcasting\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                \n                f = np.array([func(xi) for xi in x.T])\n                evals_used += self.popsize\n\n                if np.any(f < self.f_opt):\n                    best_idx = np.argmin(f)\n                    if f[best_idx] < self.f_opt:\n                        self.f_opt = f[best_idx]\n                        self.x_opt = x[:, best_idx].copy()\n            \n                # Selection and Recombination\n                idx = np.argsort(f)\n                x_sorted = x[:, idx]\n                z_sorted = z[:, idx]\n\n                mu_new = np.sum(weights * x_sorted, axis=1)\n\n                # Step-size adaptation\n                ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * mu_eff) * ((mu_new - mu) / sigma)\n                \n                norm_ps = np.linalg.norm(ps)\n                sigma = sigma * np.exp((self.cs / 0.841) * (norm_ps - np.sqrt(self.dim)))\n                \n                sigma = np.clip(sigma, 1e-8, 2) # Clip sigma\n\n                mu = mu_new\n\n                # Covariance matrix adaptation\n                C = (1 - self.c1 - self.cmu) * C + self.c1 * np.outer(ps, ps) + self.cmu * (z_sorted @ np.diag(weights) @ z_sorted.T)\n                C = np.triu(C) + np.triu(C, 1).T  # enforce symmetry\n\n                if evals_used >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["e422cde9-bb59-45d4-b5f2-a9caed9c5175"], "operator": null, "metadata": {}}
{"id": "bf1a43cf-649b-44be-a50a-06dc85e85244", "fitness": -Infinity, "name": "SimpleCMAES", "description": "Simplified CMA-ES with rank-one update and bound handling, fixing array broadcasting issues and simplifying parameter adaptation.", "code": "import numpy as np\n\nclass SimpleCMAES:\n    def __init__(self, budget=10000, dim=10, mu_factor=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(dim * mu_factor)\n        self.lambda_ = 4 + int(3 * np.log(dim))\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n        self.m = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.pc = np.zeros(dim)\n        self.chiN = np.sqrt(dim) * (1 - (1 / (4 * dim)) + (1 / (21 * dim**2)))\n\n        self.c_sigma = (self.mu / self.lambda_) / (np.linalg.norm(self.ps) + 1e-8)\n        self.d_sigma = 1 + 2 * np.max([0, 1 - (np.linalg.norm(self.ps) / self.chiN)])\n\n        self.c_c = (4 + (self.mu / self.dim)) / (dim + 4)\n\n        self.mu_weights = np.log(self.lambda_ + 1) - np.log(np.arange(1, self.mu + 1))\n        self.mu_weights = self.mu_weights / np.sum(self.mu_weights)\n        self.mueff = np.sum(self.mu_weights)**2 / np.sum(self.mu_weights**2)\n        self.c_mu = np.min([1 - (1/self.mueff), (2*(self.mueff-2+(1/self.mueff))) / ((dim+2)**2 + (self.mueff/2))])\n        self.c_1 = 0.3 / ((dim + 1.3)**2 + self.mueff) # simplified rank-one update\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        used_budget = 0\n\n        while used_budget < self.budget:\n            z = np.random.randn(self.dim, self.lambda_)\n            A = np.linalg.cholesky(self.C)\n            x = self.m[:, None] + self.sigma * A @ z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x.T])\n            used_budget += self.lambda_\n            \n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[:, np.argmin(f)].copy()\n\n            idx = np.argsort(f)\n            x_mu = x[:, idx[:self.mu]]\n            z_mu = z[:, idx[:self.mu]]\n\n            y_w = z_mu @ self.mu_weights\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * y_w\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / self.chiN) - 1))\n            self.sigma = np.clip(self.sigma, 1e-10, 1)\n            \n            delta_m = self.sigma * A @ y_w\n            self.m = self.m + delta_m\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2-self.c_c) * self.mueff) * A @ y_w\n            self.C = (1-self.c_1) * self.C + self.c_1 * np.outer(self.pc, self.pc)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["102953e9-88a9-4f46-936d-8a8b70ba165b"], "operator": null, "metadata": {}}
{"id": "18a856a0-0fab-405e-9c10-2a9167a95798", "fitness": -Infinity, "name": "AdaptiveEvolutionaryStrategy", "description": "Adaptive Evolutionary Strategy with simplified mutation and crossover, focusing on diversity maintenance and stagnation detection via fitness improvement rate.", "code": "import numpy as np\n\nclass AdaptiveEvolutionaryStrategy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, restart_trigger=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.restart_trigger = restart_trigger  # Percentage decrease in best fitness to trigger restart\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def initialize_population(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        return population, fitness\n\n    def calculate_diversity(self, population):\n        \"\"\"Calculates the average distance between individuals in the population.\"\"\"\n        centroid = np.mean(population, axis=0)\n        distances = np.linalg.norm(population - centroid, axis=1)\n        return np.mean(distances)\n\n    def adapt_rates(self, diversity):\n        \"\"\"Adapts mutation and crossover rates based on population diversity.\"\"\"\n        normalized_diversity = diversity / (func.bounds.ub[0] - func.bounds.lb[0]) # Normalize diversity by search space range\n\n        self.mutation_rate = 0.05 + 0.45 * (1 - normalized_diversity)  # Increase mutation when diversity is low\n        self.crossover_rate = 0.2 + 0.75 * normalized_diversity  # Increase crossover when diversity is high\n\n        self.mutation_rate = np.clip(self.mutation_rate, 0.05, 0.5)\n        self.crossover_rate = np.clip(self.crossover_rate, 0.2, 0.95)\n    \n\n    def evolve(self, population, fitness, func):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            # Mutation\n            if np.random.rand() < self.mutation_rate:\n                mutation_indices = np.random.choice(self.dim, size=int(self.dim * self.mutation_rate), replace=False)\n                mutation_values = np.random.normal(0, 1, size=len(mutation_indices)) * (func.bounds.ub[0] - func.bounds.lb[0]) * 0.05 # Scaling with single bound value\n                new_population[i, mutation_indices] = population[i, mutation_indices] + mutation_values\n                new_population[i] = np.clip(new_population[i], func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            if np.random.rand() < self.crossover_rate:\n                other_individual = np.random.randint(0, self.pop_size)\n                crossover_points = np.random.rand(self.dim) < self.crossover_rate\n                new_population[i, crossover_points] = population[other_individual, crossover_points]\n\n        new_fitness = np.array([func(x) for x in new_population])\n\n        # Selection (replace if better)\n        for i in range(self.pop_size):\n            if new_fitness[i] < fitness[i]:\n                population[i] = new_population[i]\n                fitness[i] = new_fitness[i]\n\n        return population, fitness\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        eval_count = 0\n\n        population, fitness = self.initialize_population(func)\n        eval_count += self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        initial_best_fitness = self.f_opt\n\n        while eval_count < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.adapt_rates(diversity)\n            population, fitness = self.evolve(population, fitness, func)\n            eval_count += self.pop_size\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n            \n            # Restart mechanism\n            if eval_count > self.budget * 0.1 and (initial_best_fitness - self.f_opt) / abs(initial_best_fitness) < self.restart_trigger:  # Check for stagnation after some initial exploration\n                population, fitness = self.initialize_population(func)\n                eval_count += self.pop_size\n                best_index = np.argmin(fitness)\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                initial_best_fitness = self.f_opt # Reset initial best fitness\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: name 'func' is not defined.", "error": "", "parent_ids": ["ef5089bb-806f-4ee0-bc39-fbb2c7bcf837"], "operator": null, "metadata": {}}
{"id": "cb347791-b9d6-44a8-8033-1ff2a97143c3", "fitness": -Infinity, "name": "AdaptiveEvolutionaryStrategy", "description": "Adaptive Evolutionary Strategy with simplified diversity calculation and mutation.", "code": "import numpy as np\n\nclass AdaptiveEvolutionaryStrategy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, restart_trigger=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.restart_trigger = restart_trigger  # Percentage decrease in best fitness to trigger restart\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def initialize_population(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        return population, fitness\n\n    def calculate_diversity(self, population):\n        \"\"\"Calculates the average standard deviation of each dimension.\"\"\"\n        return np.mean(np.std(population, axis=0))\n\n    def adapt_rates(self, diversity):\n        \"\"\"Adapts mutation and crossover rates based on population diversity.\"\"\"\n        normalized_diversity = diversity / (5 - (-5))  #Scale of search space\n        \n        self.mutation_rate = 0.05 + 0.45 * (1 - normalized_diversity)  # Increase mutation when diversity is low\n        self.crossover_rate = 0.2 + 0.75 * normalized_diversity  # Increase crossover when diversity is high\n        self.mutation_rate = np.clip(self.mutation_rate, 0.05, 0.5)\n        self.crossover_rate = np.clip(self.crossover_rate, 0.2, 0.95)\n\n    def evolve(self, population, fitness, func):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            # Mutation\n            if np.random.rand() < self.mutation_rate:\n                mutation_indices = np.random.choice(self.dim, size=int(self.dim * self.mutation_rate), replace=False)  # Mutate a fraction of dimensions\n                mutation_values = np.random.normal(0, 1, size=len(mutation_indices)) * (func.bounds.ub - func.bounds.lb) * 0.05  # Scale mutation by search space and a small factor\n                new_population[i, mutation_indices] = population[i, mutation_indices] + mutation_values\n                new_population[i] = np.clip(new_population[i], func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            if np.random.rand() < self.crossover_rate:\n                other_individual = np.random.randint(0, self.pop_size)\n                crossover_points = np.random.rand(self.dim) < self.crossover_rate\n                new_population[i, crossover_points] = population[other_individual, crossover_points]\n\n        new_fitness = np.array([func(x) for x in new_population])\n\n        # Selection (replace if better)\n        for i in range(self.pop_size):\n            if new_fitness[i] < fitness[i]:\n                population[i] = new_population[i]\n                fitness[i] = new_fitness[i]\n\n        return population, fitness\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        eval_count = 0\n\n        population, fitness = self.initialize_population(func)\n        eval_count += self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        initial_best_fitness = self.f_opt\n\n        while eval_count < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.adapt_rates(diversity)\n            population, fitness = self.evolve(population, fitness, func)\n            eval_count += self.pop_size\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n            \n            # Restart mechanism\n            if (initial_best_fitness - self.f_opt) / initial_best_fitness < self.restart_trigger and eval_count > self.budget * 0.1 and initial_best_fitness != 0:  # Check for stagnation after some initial exploration\n                population, fitness = self.initialize_population(func)\n                eval_count += self.pop_size\n                best_index = np.argmin(fitness)\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                initial_best_fitness = self.f_opt # Reset initial best fitness\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (0,) (2,) .", "error": "", "parent_ids": ["ef5089bb-806f-4ee0-bc39-fbb2c7bcf837"], "operator": null, "metadata": {}}
{"id": "0bc4dba4-0b9a-4f8a-81ef-12bb6389f359", "fitness": -Infinity, "name": "CMAES", "description": "Covariance matrix adaptation evolution strategy (CMA-ES) with restarts, budget-aware step size adaptation, and corrected broadcasting errors.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, c1=None, cmu=None, sigma0=0.2, restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.restarts = restarts\n\n        self.cs = cs\n        self.c1 = c1 if c1 is not None else 2 / (self.dim + 1.3)**2\n        self.cmu = cmu if cmu is not None else min(1 - self.c1, 2 + (self.popsize / 3) / self.dim)\n        self.sigma0 = sigma0\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        evals_used = 0\n\n        for restart in range(self.restarts):\n            # Initialization\n            mu = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            sigma = self.sigma0\n            C = np.eye(self.dim)\n            pc = np.zeros(self.dim)\n            ps = np.zeros(self.dim)\n            weights = np.log(self.popsize + 1/2) - np.log(np.arange(1, self.popsize + 1))\n            weights = weights / np.sum(weights)\n            mu_eff = 1 / np.sum(weights**2)\n\n            C_eig_sqrt = None # Delayed calculation of C_eig_sqrt\n\n            while evals_used < self.budget:\n                # Sample lambda candidate solutions\n                z = np.random.randn(self.dim, self.popsize)\n                \n                if C_eig_sqrt is None:\n                    C_eig_val, C_eig_vec = np.linalg.eigh(C)\n                    C_eig_sqrt = C_eig_vec @ np.diag(np.sqrt(C_eig_val))\n                    \n                x = mu[:, np.newaxis] + sigma * (C_eig_sqrt @ z)  # broadcasting\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                \n                f = np.array([func(xi) for xi in x.T])\n                evals_used += self.popsize\n\n                if np.any(f < self.f_opt):\n                    best_idx = np.argmin(f)\n                    if f[best_idx] < self.f_opt:\n                        self.f_opt = f[best_idx]\n                        self.x_opt = x[:, best_idx].copy()  #important to copy\n            \n                # Selection and Recombination\n                idx = np.argsort(f)\n                x_sorted = x[:, idx]\n                z_sorted = z[:, idx]\n\n                mu_new = np.sum(weights * x_sorted, axis=1)\n\n                # Step-size adaptation\n                ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * mu_eff) * (C_eig_sqrt @ ((mu_new - mu) / sigma))\n                \n                norm_ps = np.linalg.norm(ps)\n                sigma = sigma * np.exp((self.cs / 0.841) * (norm_ps - np.sqrt(self.dim)))\n                \n                if sigma > 2:\n                    sigma = 2\n                elif sigma < 1e-8:\n                    sigma = 1e-8\n                \n                mu = mu_new\n\n                # Covariance matrix adaptation\n                pc = (1 - self.c1) * pc + np.sqrt(self.c1 * (2 - self.c1) * mu_eff) * ((mu_new - mu) / sigma)\n                C = (1 - self.c1 - self.cmu) * C + self.c1 * np.outer(pc, pc) + self.cmu * (z_sorted @ np.diag(weights) @ z_sorted.T)\n\n                C = np.triu(C) + np.triu(C, 1).T  # enforce symmetry\n                \n                #check C matrix for being positive definite:\n                try:\n                    np.linalg.cholesky(C)\n                except np.linalg.LinAlgError:\n                     C = np.eye(self.dim)\n\n                C_eig_sqrt = None # Recalculate C_eig_sqrt\n\n                if evals_used >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["e422cde9-bb59-45d4-b5f2-a9caed9c5175"], "operator": null, "metadata": {}}
{"id": "72ec1ff7-9ac1-45fc-a373-af14678235d3", "fitness": -Infinity, "name": "CMAES", "description": "Covariance matrix adaptation evolution strategy with a budget-aware hard restart mechanism and simplified covariance update.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, c1=None, cmu=None, sigma0=0.2, restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.restarts = restarts\n\n        self.cs = cs\n        self.c1 = c1 if c1 is not None else 2 / (self.dim + 1.3)**2\n        self.cmu = cmu if cmu is not None else min(1 - self.c1, 2 + (self.popsize / 3) / self.dim)\n        self.sigma0 = sigma0\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        evals_used = 0\n\n        for restart in range(self.restarts):\n            # Initialization\n            mu = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            sigma = self.sigma0\n            C = np.eye(self.dim)\n            pc = np.zeros(self.dim)\n            ps = np.zeros(self.dim)\n            weights = np.log(self.popsize + 1/2) - np.log(np.arange(1, self.popsize + 1))\n            weights = weights / np.sum(weights)\n            mu_eff = 1 / np.sum(weights**2)\n\n            C_eig_sqrt = None # Delayed calculation of C_eig_sqrt\n\n            while evals_used < self.budget:\n                # Sample lambda candidate solutions\n                z = np.random.randn(self.dim, self.popsize)\n                \n                if C_eig_sqrt is None:\n                    C_eig_val, C_eig_vec = np.linalg.eigh(C)\n                    C_eig_sqrt = C_eig_vec @ np.diag(np.sqrt(C_eig_val))\n                    \n                x = mu[:, np.newaxis] + sigma * (C_eig_sqrt @ z)  # broadcasting\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                \n                f = np.array([func(xi) for xi in x.T])\n                evals_used += self.popsize\n\n                if np.any(f < self.f_opt):\n                    best_idx = np.argmin(f)\n                    if f[best_idx] < self.f_opt:\n                        self.f_opt = f[best_idx]\n                        self.x_opt = x[:, best_idx].copy()  #important to copy\n            \n                # Selection and Recombination\n                idx = np.argsort(f)\n                x_sorted = x[:, idx]\n                z_sorted = z[:, idx]\n\n                mu_new = np.sum(weights * x_sorted, axis=1)\n\n                # Step-size adaptation\n                ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * mu_eff) * (mu_new - mu) / sigma\n                \n                norm_ps = np.linalg.norm(ps)\n                sigma = sigma * np.exp((self.cs / 0.841) * (norm_ps - np.sqrt(self.dim)))\n                \n                if sigma > 2:\n                    sigma = 2\n                elif sigma < 1e-8:\n                    sigma = 1e-8\n                \n                mu = mu_new\n\n                # Covariance matrix adaptation\n                pc = (1 - self.c1) * pc + np.sqrt(self.c1 * (2 - self.c1) * mu_eff) * (mu_new - mu) / sigma\n                C = (1 - self.c1 - self.cmu) * C + self.c1 * np.outer(pc, pc) + self.cmu * (z_sorted @ np.diag(weights) @ z_sorted.T)\n                C = np.triu(C) + np.triu(C, 1).T  # enforce symmetry\n                \n                #check C matrix for being positive definite:\n                try:\n                    np.linalg.cholesky(C)\n                except np.linalg.LinAlgError:\n                     C = np.eye(self.dim)\n                     sigma = self.sigma0\n                     ps = np.zeros(self.dim)\n                     pc = np.zeros(self.dim)\n\n                C_eig_sqrt = None # Recalculate C_eig_sqrt\n\n                if evals_used >= self.budget:\n                    break\n            if evals_used >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["e422cde9-bb59-45d4-b5f2-a9caed9c5175"], "operator": null, "metadata": {}}
{"id": "d90f9aaa-cc63-4881-bf34-13b85d070928", "fitness": -Infinity, "name": "AdaptiveEvolutionaryStrategy", "description": "Population-based algorithm with adaptive mutation and crossover rates based on population diversity and a simplified restart mechanism.", "code": "import numpy as np\n\nclass AdaptiveEvolutionaryStrategy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, restart_trigger=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.restart_trigger = restart_trigger\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def initialize_population(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        return population, fitness\n\n    def calculate_diversity(self, population):\n        centroid = np.mean(population, axis=0)\n        distances = np.linalg.norm(population - centroid, axis=1)\n        return np.mean(distances)\n\n    def adapt_rates(self, diversity):\n        normalized_diversity = diversity / (func.bounds.ub[0] - func.bounds.lb[0])  # Using bounds directly from func\n        self.mutation_rate = 0.05 + 0.45 * (1 - normalized_diversity)\n        self.crossover_rate = 0.2 + 0.75 * normalized_diversity\n        self.mutation_rate = np.clip(self.mutation_rate, 0.05, 0.5)\n        self.crossover_rate = np.clip(self.crossover_rate, 0.2, 0.95)\n\n    def evolve(self, population, fitness, func):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            # Mutation\n            if np.random.rand() < self.mutation_rate:\n                mutation_indices = np.random.choice(self.dim, size=int(self.dim * self.mutation_rate), replace=False)\n                mutation_values = np.random.normal(0, 1, size=len(mutation_indices)) * (func.bounds.ub[0] - func.bounds.lb[0]) * 0.05  # Using bounds directly from func\n                new_population[i, mutation_indices] = population[i, mutation_indices] + mutation_values\n                new_population[i] = np.clip(new_population[i], func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            if np.random.rand() < self.crossover_rate:\n                other_individual = np.random.randint(0, self.pop_size)\n                crossover_points = np.random.rand(self.dim) < self.crossover_rate\n                new_population[i, crossover_points] = population[other_individual, crossover_points]\n\n        new_fitness = np.array([func(x) for x in new_population])\n\n        # Selection (replace if better)\n        for i in range(self.pop_size):\n            if new_fitness[i] < fitness[i]:\n                population[i] = new_population[i]\n                fitness[i] = new_fitness[i]\n\n        return population, fitness\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        eval_count = 0\n\n        population, fitness = self.initialize_population(func)\n        eval_count += self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        initial_best_fitness = self.f_opt\n\n        while eval_count < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.adapt_rates(diversity)\n            population, fitness = self.evolve(population, fitness, func)\n            eval_count += self.pop_size\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                \n            # Restart mechanism\n            if (initial_best_fitness - self.f_opt) / (abs(initial_best_fitness)+1e-8) < self.restart_trigger and eval_count > self.budget * 0.1:\n                population, fitness = self.initialize_population(func)\n                eval_count += self.pop_size\n                best_index = np.argmin(fitness)\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                initial_best_fitness = self.f_opt\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: name 'func' is not defined.", "error": "", "parent_ids": ["ef5089bb-806f-4ee0-bc39-fbb2c7bcf837"], "operator": null, "metadata": {}}
{"id": "27d0b3ae-1d27-487c-bb9e-0e2e4e894ddf", "fitness": 0.6382135723588, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive mutation factor and crossover rate, without archive.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Self-adaptive F and CR\n            F = np.random.normal(0.5, 0.3, self.pop_size)\n            F = np.clip(F, 0.1, 1.0)\n            CR = np.random.normal(0.7, 0.1, self.pop_size)\n            CR = np.clip(CR, 0.1, 1.0)\n\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + F[i] * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR[i]\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.638 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b82a00cd-c8d2-4027-ae54-8cd6edad51e7"], "operator": null, "metadata": {"aucs": [0.2480180031887863, 0.4924466332879077, 0.5727774125075795, 0.8432433834468498, 0.7153657603443728, 0.770435907662816, 0.6079335694035863, 0.6154870970865736, 0.698884256179769, 0.6345308474070546, 0.7972778809975589, 0.9988579994742757, 0.3401501834491474, 0.6635474289456458, 0.8806409620035608, 0.775588778564843, 0.5087029211713905, 0.8057384927035904, 0.27402209093539254, 0.5206218384153005]}}
{"id": "6cc5475a-0ab0-4f19-921e-d96bd2a67887", "fitness": 0.7929537462840902, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a smaller population size, reduced archive size, and a single mutation strategy (DE/rand/1) for efficiency.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, archive_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.archive_size = archive_size\n        self.archive = []\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub) # Clip to bounds\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    # Add replaced individual to archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        # Replace random element in archive\n                        if self.archive:  # Check if archive is not empty\n                            replace_index = np.random.randint(0, self.archive_size)\n                            self.archive[replace_index] = population[i].copy()\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.793 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b82a00cd-c8d2-4027-ae54-8cd6edad51e7"], "operator": null, "metadata": {"aucs": [0.44109752653364, 0.7585076040425329, 0.8153116968279788, 0.9298480735398905, 0.8714077420685163, 0.8973472115337947, 0.8222329131236322, 0.8315291709574678, 0.8629368011669941, 0.795362320658251, 0.914020358998258, 0.9961765074835652, 0.5190748875429798, 0.8628565228321422, 0.9192750502321463, 0.9061076535070662, 0.7623486759169454, 0.9216302396706693, 0.22034456699799798, 0.8116594020473367]}}
{"id": "237ea7d9-ecbf-4b91-9f6e-072b13b1e0c5", "fitness": -Infinity, "name": "SimpleCMAES", "description": "Simplified CMA-ES with rank-one update, clipping, and budget-aware population size adaptation.", "code": "import numpy as np\n\nclass SimpleCMAES:\n    def __init__(self, budget=10000, dim=10, mu_factor=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(dim * mu_factor)\n        self.lambda_ = 4 + int(3 * np.log(dim))\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n        self.m = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.pc = np.zeros(dim)\n        self.chiN = np.sqrt(dim) * (1 - (1 / (4 * dim)) + (1 / (21 * dim**2)))\n\n        self.c_sigma = (self.mu / self.lambda_) / (np.linalg.norm(self.ps) + 1e-8)\n        self.d_sigma = 1 + 2 * np.max([0, 1 - (np.linalg.norm(self.ps) / self.chiN)])\n\n        self.c_c = (4 + (self.mu / self.dim)) / (dim + 4)\n\n        self.mu_weights = np.log(self.lambda_ + 1) - np.log(np.arange(1, self.mu + 1))\n        self.mu_weights = self.mu_weights / np.sum(self.mu_weights)\n        self.mueff = np.sum(self.mu_weights)**2 / np.sum(self.mu_weights**2)\n        self.c_mu = np.min([1 - (1/self.mueff), (2*(self.mueff-2+(1/self.mueff))) / ((dim+2)**2 + (self.mueff/2))])\n        self.c_1 = 0.3 / ((dim + 1.3)**2 + self.mueff) # simplified rank-one update\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        used_budget = 0\n\n        while used_budget < self.budget:\n            remaining_budget = self.budget - used_budget\n            lambda_ = min(self.lambda_, remaining_budget)\n\n            z = np.random.randn(self.dim, lambda_)\n            A = np.linalg.cholesky(self.C)\n            x = self.m[:, None] + self.sigma * A @ z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x.T])\n            used_budget += lambda_\n            \n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[:, np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_mu = x[:, idx[:self.mu]]\n            z_mu = z[:, idx[:self.mu]]\n\n            y_w = z_mu @ self.mu_weights[:self.mu]  # Ensure weights match selected individuals\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * y_w\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / self.chiN) - 1))\n            self.sigma = np.clip(self.sigma, 1e-10, 1)\n            \n            self.m = self.m + self.sigma * A @ y_w\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2-self.c_c) * self.mueff) * A @ y_w\n            self.C = (1-self.c_1) * self.C + self.c_1 * (np.outer(self.pc, self.pc))\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["102953e9-88a9-4f46-936d-8a8b70ba165b"], "operator": null, "metadata": {}}
{"id": "75922865-d325-4375-81ab-cf464260a5a4", "fitness": -Infinity, "name": "AdaptiveEvolutionaryStrategy", "description": "Population-based algorithm with adaptive mutation and crossover rates based on population diversity, using a more robust diversity calculation and simplified adaptation, and avoiding zero-sized mutation indices.", "code": "import numpy as np\n\nclass AdaptiveEvolutionaryStrategy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, restart_trigger=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.restart_trigger = restart_trigger  # Percentage decrease in best fitness to trigger restart\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def initialize_population(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        return population, fitness\n\n    def calculate_diversity(self, population):\n        \"\"\"Calculates the average standard deviation of each dimension.\"\"\"\n        return np.mean(np.std(population, axis=0))\n\n    def adapt_rates(self, diversity):\n        \"\"\"Adapts mutation and crossover rates based on population diversity.\"\"\"\n        normalized_diversity = diversity / (5 - (-5))  # Scale of search space\n        self.mutation_rate = 0.1 + 0.4 * (1 - normalized_diversity)  # Increase mutation when diversity is low\n        self.crossover_rate = 0.3 + 0.7 * normalized_diversity  # Increase crossover when diversity is high\n        self.mutation_rate = np.clip(self.mutation_rate, 0.05, 0.5)\n        self.crossover_rate = np.clip(self.crossover_rate, 0.2, 0.95)\n\n    def evolve(self, population, fitness, func):\n        new_population = np.copy(population)\n        for i in range(self.pop_size):\n            # Mutation\n            if np.random.rand() < self.mutation_rate:\n                num_mutations = max(1, int(self.dim * self.mutation_rate)) # Ensure at least one mutation\n                mutation_indices = np.random.choice(self.dim, size=num_mutations, replace=False)\n                mutation_values = np.random.normal(0, 1, size=len(mutation_indices)) * (func.bounds.ub - func.bounds.lb) * 0.05\n                new_population[i, mutation_indices] = population[i, mutation_indices] + mutation_values\n                new_population[i] = np.clip(new_population[i], func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            if np.random.rand() < self.crossover_rate:\n                other_individual = np.random.randint(0, self.pop_size)\n                crossover_points = np.random.rand(self.dim) < self.crossover_rate\n                new_population[i, crossover_points] = population[other_individual, crossover_points]\n\n        new_fitness = np.array([func(x) for x in new_population])\n\n        # Selection (replace if better)\n        for i in range(self.pop_size):\n            if new_fitness[i] < fitness[i]:\n                population[i] = new_population[i]\n                fitness[i] = new_fitness[i]\n\n        return population, fitness\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        eval_count = 0\n\n        population, fitness = self.initialize_population(func)\n        eval_count += self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        initial_best_fitness = self.f_opt\n\n        while eval_count < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.adapt_rates(diversity)\n            population, fitness = self.evolve(population, fitness, func)\n            eval_count += self.pop_size\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n            \n            # Restart mechanism\n            if (initial_best_fitness - self.f_opt) / initial_best_fitness < self.restart_trigger and eval_count > self.budget * 0.1:  # Check for stagnation after some initial exploration\n                population, fitness = self.initialize_population(func)\n                eval_count += self.pop_size\n                best_index = np.argmin(fitness)\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                initial_best_fitness = self.f_opt # Reset initial best fitness\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: shape mismatch: value array of shape (2,) could not be broadcast to indexing result of shape (1,).", "error": "", "parent_ids": ["ef5089bb-806f-4ee0-bc39-fbb2c7bcf837"], "operator": null, "metadata": {}}
{"id": "c6acbc04-c47c-4793-b29e-e09a5a27b4a1", "fitness": -Infinity, "name": "CMAES", "description": "Simplified CMA-ES with eigenvalue decomposition for covariance update, step-size adaptation with clipping, and restarts for robustness.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, c1=None, cmu=None, sigma0=0.2, restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.restarts = restarts\n\n        self.cs = cs\n        self.c1 = c1 if c1 is not None else 2 / (self.dim + 1.3)**2\n        self.cmu = cmu if cmu is not None else min(1 - self.c1, 2 + (self.popsize / 3) / self.dim)\n        self.sigma0 = sigma0\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        evals_used = 0\n\n        for restart in range(self.restarts):\n            # Initialization\n            mu = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            sigma = self.sigma0\n            C = np.eye(self.dim)\n            ps = np.zeros(self.dim)\n            weights = np.log(self.popsize + 1/2) - np.log(np.arange(1, self.popsize + 1))\n            weights = weights / np.sum(weights)\n            mu_eff = 1 / np.sum(weights**2)\n\n            while evals_used < self.budget:\n                # Sample lambda candidate solutions\n                z = np.random.randn(self.dim, self.popsize)\n                \n                C_eig_val, C_eig_vec = np.linalg.eigh(C)\n                C_eig_sqrt = C_eig_vec @ np.diag(np.sqrt(np.maximum(C_eig_val, 0))) # Ensure positive eigenvalues\n                \n                x = mu[:, np.newaxis] + sigma * (C_eig_sqrt @ z)  # broadcasting\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                \n                f = np.array([func(xi) for xi in x.T])\n                evals_used += self.popsize\n\n                if np.any(f < self.f_opt):\n                    best_idx = np.argmin(f)\n                    if f[best_idx] < self.f_opt:\n                        self.f_opt = f[best_idx]\n                        self.x_opt = x[:, best_idx].copy()\n            \n                # Selection and Recombination\n                idx = np.argsort(f)\n                x_sorted = x[:, idx]\n                z_sorted = z[:, idx]\n\n                mu_new = np.sum(weights * x_sorted, axis=1)\n\n                # Step-size adaptation\n                ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * mu_eff) * (np.linalg.solve(C_eig_sqrt, (mu_new - mu)) / sigma)\n                \n                norm_ps = np.linalg.norm(ps)\n                sigma = sigma * np.exp((self.cs / 0.841) * (norm_ps - np.sqrt(self.dim)))\n                \n                sigma = np.clip(sigma, 1e-8, 2) # Clip sigma\n\n                mu = mu_new\n\n                # Covariance matrix adaptation\n                C = (1 - self.c1 - self.cmu) * C + self.c1 * np.outer(ps, ps) + self.cmu * (z_sorted @ np.diag(weights) @ z_sorted.T)\n                C = np.triu(C) + np.triu(C, 1).T  # enforce symmetry\n\n                if evals_used >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["8bd19654-d341-4906-a706-5f85c22e9cf8"], "operator": null, "metadata": {}}
{"id": "d944a877-d55d-416d-a453-86ac14e83390", "fitness": -Infinity, "name": "CMAES", "description": "Simplified CMA-ES with eigenvalue decomposition caching, sigma clipping, and vectorized numpy operations for faster execution.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, c1=None, cmu=None, sigma0=0.2, restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.restarts = restarts\n\n        self.cs = cs\n        self.c1 = c1 if c1 is not None else 2 / (self.dim + 1.3)**2\n        self.cmu = cmu if cmu is not None else min(1 - self.c1, 2 + (self.popsize / 3) / self.dim)\n        self.sigma0 = sigma0\n        self.C_eig_val = None\n        self.C_eig_vec = None\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        evals_used = 0\n\n        for restart in range(self.restarts):\n            # Initialization\n            mu = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            sigma = self.sigma0\n            C = np.eye(self.dim)\n            ps = np.zeros(self.dim)\n            weights = np.log(self.popsize + 1/2) - np.log(np.arange(1, self.popsize + 1))\n            weights = weights / np.sum(weights)\n            mu_eff = 1 / np.sum(weights**2)\n\n            while evals_used < self.budget:\n                # Sample lambda candidate solutions\n                z = np.random.randn(self.dim, self.popsize)\n                \n                # Eigen Decomposition (Cached)\n                if restart == 0 or evals_used == 0:\n                  self.C_eig_val, self.C_eig_vec = np.linalg.eigh(C)\n                C_eig_sqrt = self.C_eig_vec @ np.diag(np.sqrt(np.maximum(self.C_eig_val, 0))) # Ensure positive eigenvalues\n                \n                x = mu[:, np.newaxis] + sigma * (C_eig_sqrt @ z)  # broadcasting\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                \n                f = np.array([func(xi) for xi in x.T])\n                evals_used += self.popsize\n\n                if np.any(f < self.f_opt):\n                    best_idx = np.argmin(f)\n                    if f[best_idx] < self.f_opt:\n                        self.f_opt = f[best_idx]\n                        self.x_opt = x[:, best_idx].copy()\n            \n                # Selection and Recombination\n                idx = np.argsort(f)\n                x_sorted = x[:, idx]\n                z_sorted = z[:, idx]\n\n                mu_new = np.sum(weights * x_sorted, axis=1)\n\n                # Step-size adaptation\n                ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * mu_eff) * ((mu_new - mu) / sigma)\n                \n                norm_ps = np.linalg.norm(ps)\n                sigma = sigma * np.exp((self.cs / 0.841) * (norm_ps - np.sqrt(self.dim)))\n                \n                sigma = np.clip(sigma, 1e-8, 2) # Clip sigma\n\n                mu = mu_new\n\n                # Covariance matrix adaptation\n                C = (1 - self.c1 - self.cmu) * C + self.c1 * np.outer(ps, ps) + self.cmu * (z_sorted @ np.diag(weights) @ z_sorted.T)\n                C = np.triu(C) + np.triu(C, 1).T  # enforce symmetry\n\n                if evals_used >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["8bd19654-d341-4906-a706-5f85c22e9cf8"], "operator": null, "metadata": {}}
{"id": "286f1072-d6f0-46c5-98bc-45e2c2f8f8d6", "fitness": -Infinity, "name": "SimpleCMAES", "description": "Simplified CMA-ES with rank-one update, adaptive step-size, bound constraints and fixed population size, correcting broadcasting errors and increasing numerical stability.", "code": "import numpy as np\n\nclass SimpleCMAES:\n    def __init__(self, budget=10000, dim=10, mu_factor=0.25, lambda_factor=4):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(dim * mu_factor)\n        self.lambda_ = lambda_factor + int(3 * np.log(dim))\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n        self.m = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.chiN = np.sqrt(dim) * (1 - (1 / (4 * dim)) + (1 / (21 * dim**2)))\n        self.c_sigma = (self.mu / self.lambda_) / (np.linalg.norm(self.ps) + 1e-8)\n        self.d_sigma = 1 + 2 * np.max([0, 1 - (np.linalg.norm(self.ps) / self.chiN)])\n        self.mu_weights = np.log(self.lambda_ + 1) - np.log(np.arange(1, self.mu + 1))\n        self.mu_weights = self.mu_weights / np.sum(self.mu_weights)\n        self.mueff = np.sum(self.mu_weights)**2 / np.sum(self.mu_weights**2)\n        self.c_1 = 0.3 / ((dim + 1.3)**2 + self.mueff)\n        self.min_sigma = 1e-10\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        used_budget = 0\n\n        while used_budget < self.budget:\n            z = np.random.randn(self.dim, self.lambda_)\n            try:\n                A = np.linalg.cholesky(self.C)\n                x = self.m[:, None] + self.sigma * A @ z\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                A = np.eye(self.dim) * np.sqrt(np.diag(self.C))  # Use diagonal as approximation\n                x = self.m[:, None] + self.sigma * A @ z\n            \n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x.T])\n            used_budget += self.lambda_\n            \n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[:, np.argmin(f)].copy()\n\n            idx = np.argsort(f)\n            x_mu = x[:, idx[:self.mu]]\n            z_mu = z[:, idx[:self.mu]]\n\n            y_w = np.sum(z_mu * self.mu_weights[None, :], axis=1)\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * y_w\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / self.chiN) - 1))\n            self.sigma = np.clip(self.sigma, self.min_sigma, 1)\n            \n            self.m = self.m + self.sigma * A @ y_w\n            self.C = (1-self.c_1) * self.C + self.c_1 * np.outer(self.ps, self.ps)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["91ba986d-183a-42a1-a0fb-9b1ff8e4f1ab"], "operator": null, "metadata": {}}
{"id": "34d6b35b-0b67-4f77-8629-b3a62d6dd2ef", "fitness": -Infinity, "name": "SimpleCMAES", "description": "Simplified CMA-ES with rank-one update and adaptive step-size focusing on efficiency, using matrix adaptation without Cholesky decomposition to avoid errors and clipping sigma.", "code": "import numpy as np\n\nclass SimpleCMAES:\n    def __init__(self, budget=10000, dim=10, mu_factor=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(dim * mu_factor)\n        self.lambda_ = 4 + int(3 * np.log(dim))\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n        self.m = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.chiN = np.sqrt(dim) * (1 - (1 / (4 * dim)) + (1 / (21 * dim**2)))\n        self.c_sigma = (self.mu / self.lambda_) / (np.linalg.norm(self.ps) + 1e-8)\n        self.d_sigma = 1 + 2 * np.max([0, 1 - (np.linalg.norm(self.ps) / self.chiN)])\n        self.mu_weights = np.log(self.lambda_ + 1) - np.log(np.arange(1, self.mu + 1))\n        self.mu_weights = self.mu_weights / np.sum(self.mu_weights)\n        self.mueff = np.sum(self.mu_weights)**2 / np.sum(self.mu_weights**2)\n        self.c_1 = 0.3 / ((dim + 1.3)**2 + self.mueff)\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        used_budget = 0\n\n        while used_budget < self.budget:\n            z = np.random.randn(self.dim, self.lambda_)\n            # A = np.linalg.cholesky(self.C) # Remove Cholesky decomposition\n            x = self.m[:, None] + self.sigma * np.sqrt(np.diag(self.C))[:, None] * z # Use standard deviations from C\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x.T])\n            used_budget += self.lambda_\n            \n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[:, np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_mu = x[:, idx[:self.mu]]\n            z_mu = z[:, idx[:self.mu]]\n\n            y_w = np.sum(z_mu * self.mu_weights, axis=1)\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * y_w\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / self.chiN) - 1))\n            self.sigma = np.clip(self.sigma, 1e-10, 1)\n            \n            self.m = self.m + self.sigma * np.sqrt(np.diag(self.C)) * y_w\n            self.C = (1-self.c_1) * self.C + self.c_1 * np.outer(self.ps, self.ps)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["91ba986d-183a-42a1-a0fb-9b1ff8e4f1ab"], "operator": null, "metadata": {}}
{"id": "04d39afc-ca98-4e0f-a76e-373772abe82c", "fitness": -Infinity, "name": "CMAES", "description": "Simplified CMA-ES with enhanced numerical stability, adaptive population sizing, and robust handling of covariance matrix adaptation.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, c1=None, cmu=None, sigma0=0.2, restarts=1):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.restarts = restarts\n        self.cs = cs\n        self.c1 = c1 if c1 is not None else 2 / (self.dim + 1.3)**2\n        self.cmu = cmu if cmu is not None else min(1 - self.c1, 2 + (self.popsize / 3) / self.dim)\n        self.sigma0 = sigma0\n        self.min_sigma = 1e-8\n        self.max_sigma = 2\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals_used = 0\n\n        for restart in range(self.restarts):\n            # Initialization\n            mu = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            sigma = self.sigma0\n            C = np.eye(self.dim)\n            ps = np.zeros(self.dim)\n            weights = np.log(self.popsize + 1/2) - np.log(np.arange(1, self.popsize + 1))\n            weights = weights / np.sum(weights)\n            mu_eff = 1 / np.sum(weights**2)\n\n            while evals_used < self.budget:\n                # Sample lambda candidate solutions\n                z = np.random.randn(self.dim, self.popsize)\n\n                try:\n                    C_eig_val, C_eig_vec = np.linalg.eigh(C)\n                    C_eig_sqrt = C_eig_vec @ np.diag(np.sqrt(np.maximum(C_eig_val, 0)))  # Ensure positive eigenvalues\n                    x = mu[:, np.newaxis] + sigma * (C_eig_sqrt @ z)  # broadcasting\n                    x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                except np.linalg.LinAlgError:\n                    # If eigenvalue decomposition fails, reset C to identity matrix\n                    C = np.eye(self.dim)\n                    C_eig_val, C_eig_vec = np.linalg.eigh(C)\n                    C_eig_sqrt = C_eig_vec @ np.diag(np.sqrt(np.maximum(C_eig_val, 0)))  # Ensure positive eigenvalues\n                    x = mu[:, np.newaxis] + sigma * (C_eig_sqrt @ z)  # broadcasting\n                    x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n                f = np.array([func(xi) for xi in x.T])\n                evals_used += self.popsize\n\n                if np.any(f < self.f_opt):\n                    best_idx = np.argmin(f)\n                    if f[best_idx] < self.f_opt:\n                        self.f_opt = f[best_idx]\n                        self.x_opt = x[:, best_idx].copy()\n\n                # Selection and Recombination\n                idx = np.argsort(f)\n                x_sorted = x[:, idx]\n                z_sorted = z[:, idx]\n\n                mu_new = np.sum(weights * x_sorted, axis=1)\n\n                # Step-size adaptation\n                ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * mu_eff) * ((mu_new - mu) / sigma)\n\n                norm_ps = np.linalg.norm(ps)\n                sigma = sigma * np.exp((self.cs / 0.841) * (norm_ps - np.sqrt(self.dim)))\n\n                sigma = np.clip(sigma, self.min_sigma, self.max_sigma)  # Clip sigma\n\n                mu = mu_new\n\n                # Covariance matrix adaptation\n                C = (1 - self.c1 - self.cmu) * C + self.c1 * np.outer(ps, ps) + self.cmu * (z_sorted @ np.diag(weights) @ z_sorted.T)\n                C = np.triu(C) + np.triu(C, 1).T  # enforce symmetry\n\n                # Ensure C is positive definite\n                C_eig_val, C_eig_vec = np.linalg.eigh(C)\n                C_eig_val = np.maximum(C_eig_val, 0)  # Clip negative eigenvalues\n                C = C_eig_vec @ np.diag(C_eig_val) @ C_eig_vec.T\n\n                if evals_used >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["8bd19654-d341-4906-a706-5f85c22e9cf8"], "operator": null, "metadata": {}}
{"id": "63d7c861-0e0a-41e6-9098-79afa6ba2932", "fitness": -Infinity, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with dynamic population size adjustment and parameter adaptation based on success history.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_factor = pop_factor\n        self.pop_size = int(self.pop_factor * self.dim)\n        self.memory_size = 5  # Size of the success memory\n\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.CR_memory = np.ones(self.memory_size) * 0.7\n        self.memory_idx = 0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        success_F = []\n        success_CR = []\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation based on memory\n                F = np.random.choice(self.F_memory)\n                CR = np.random.choice(self.CR_memory)\n\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    success_F.append(F)\n                    success_CR.append(CR)\n                    \n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n            # Update memory with successful F and CR values\n            if success_F:\n                self.F_memory[self.memory_idx] = np.mean(success_F)\n                self.CR_memory[self.memory_idx] = np.mean(success_CR)\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                success_F = []\n                success_CR = []\n                \n            # Dynamic population size adjustment (simple heuristic)\n            if self.budget > 0:\n                if np.std(fitness) < 1e-6:\n                    self.pop_size = min(int(self.pop_size * 1.1), int(self.budget/2))\n                elif self.pop_size > self.dim * self.pop_factor:\n                     self.pop_size = int(self.dim * self.pop_factor)\n                \n                if self.pop_size != population.shape[0]:\n                    new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - population.shape[0], self.dim))\n                    new_fitness = np.array([func(x) for x in new_population])\n                    self.budget -= len(new_fitness)\n                    population = np.vstack((population, new_population))\n                    fitness = np.concatenate((fitness, new_fitness))\n                \n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: negative dimensions are not allowed.", "error": "", "parent_ids": ["27d0b3ae-1d27-487c-bb9e-0e2e4e894ddf"], "operator": null, "metadata": {}}
{"id": "436e171a-fb26-4996-8e6c-2717c6fcf88a", "fitness": 0.6207101777057844, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and mutation strategy for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F # Fixed mutation factor\n        self.CR = CR # Fixed crossover rate\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.621 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["27d0b3ae-1d27-487c-bb9e-0e2e4e894ddf"], "operator": null, "metadata": {"aucs": [0.23026304001097986, 0.42006492630689085, 0.5891846129932055, 0.8200531034064413, 0.6993703281401134, 0.7393654936141808, 0.5431886173434466, 0.5920814716467558, 0.6794853551765687, 0.5932422894858094, 0.7757926344341165, 0.9916220428454342, 0.33275674085713336, 0.6615191458126969, 0.8871340690767032, 0.753040182305871, 0.5003438606279285, 0.7988479059840822, 0.28907303094944226, 0.5177747030978861]}}
{"id": "99a712d5-334b-4ab7-bd14-97d6f0dae033", "fitness": 0.7595435878819934, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified mutation, crossover, and archive handling for improved efficiency.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1 - Simplified\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover - Simplified\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.760 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6cc5475a-0ab0-4f19-921e-d96bd2a67887"], "operator": null, "metadata": {"aucs": [0.30685061207766806, 0.716101921734624, 0.7988873452127245, 0.9313843722142418, 0.87308755213627, 0.8939055485661792, 0.7989659226372218, 0.8191765593745037, 0.8778060443143213, 0.8027699958779899, 0.9113557325455829, 0.9976674105738728, 0.3641635840683992, 0.8446471160719025, 0.7853201928323481, 0.8942125822072831, 0.7786712030029638, 0.9191758862874178, 0.34632318941155527, 0.5303989864928011]}}
{"id": "b40cffbe-da06-4b93-8dc4-1aac70e82a32", "fitness": 0.7456060180561435, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and reduced function evaluations by evaluating fitness only when the trial vector is different.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub) # Clip to bounds\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                if not np.array_equal(trial_vector, population[i]):  # Evaluate only if different\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        population[i] = trial_vector\n                        fitness[i] = f_trial\n\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial_vector\n                \n                if self.budget <= 0:\n                    break\n\n            # Adapt F and CR (simple adaptation)\n            self.F = np.clip(self.F + np.random.normal(0, 0.01), 0.1, 0.9)\n            self.CR = np.clip(self.CR + np.random.normal(0, 0.01), 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.746 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6cc5475a-0ab0-4f19-921e-d96bd2a67887"], "operator": null, "metadata": {"aucs": [0.27031416951895315, 0.672513331373999, 0.5204600860789923, 0.9205098354730044, 0.8554792246321437, 0.902367964559956, 0.7832856697085252, 0.7535754401282581, 0.8860649833341487, 0.8298249607681748, 0.9217280816876154, 0.9996735691607203, 0.39505992792378297, 0.8606597349387934, 0.9455906430921007, 0.9092080974213086, 0.7381988065223082, 0.9063410083412473, 0.3285025321208366, 0.5127622943379975]}}
{"id": "2a678fc3-7842-4165-ab58-635ca7724a5c", "fitness": 0.7803467718149175, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with a dynamically adjusted mutation factor and crossover rate based on success history.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=5, F_init=0.5, CR_init=0.7, F_adapt=True, CR_adapt=True):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.archive = []\n        self.F = F_init\n        self.CR = CR_init\n        self.F_adapt = F_adapt\n        self.CR_adapt = CR_adapt\n        self.success_F = []\n        self.success_CR = []\n        self.memory_size = 10\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    delta = np.abs(fitness[i] - f_trial)\n                    self.success_F.append((self.F, delta))\n                    self.success_CR.append((self.CR, delta))\n                    if len(self.success_F) > self.memory_size:\n                        self.success_F.pop(0)\n                        self.success_CR.pop(0)\n                    \n                    # Add replaced individual to archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        if self.archive:\n                            replace_index = np.random.randint(0, self.archive_size)\n                            self.archive[replace_index] = population[i].copy()\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n            # Adapt F and CR\n            if self.F_adapt and self.success_F:\n                weights = np.array([item[1] for item in self.success_F])\n                sum_weights = np.sum(weights)\n                if sum_weights > 0:\n                    weights /= sum_weights\n                    self.F = np.sum(np.array([item[0] for item in self.success_F]) * weights)\n                else:\n                    self.F = 0.5 # Reset if no improvement\n                self.F = np.clip(self.F, 0.1, 0.9)\n\n            if self.CR_adapt and self.success_CR:\n                weights = np.array([item[1] for item in self.success_CR])\n                sum_weights = np.sum(weights)\n                if sum_weights > 0:\n                    weights /= sum_weights\n                    self.CR = np.sum(np.array([item[0] for item in self.success_CR]) * weights)\n                else:\n                    self.CR = 0.7 # Reset if no improvement\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.780 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6cc5475a-0ab0-4f19-921e-d96bd2a67887"], "operator": null, "metadata": {"aucs": [0.34590120264865376, 0.6181828359044365, 0.8266677370565778, 0.9143750852082377, 0.8924819524042547, 0.9056769973712573, 0.7919819579786134, 0.8357037936295466, 0.8819113568854426, 0.7968729623150043, 0.9234306237730168, 0.993482010064962, 0.413496174540149, 0.8494334939452515, 0.8103472962072873, 0.9006751410345206, 0.7710789357882234, 0.9133660810998777, 0.7002428800052963, 0.5216269184377427]}}
{"id": "fd9badf8-017d-45cb-a95c-c1ec0d7c39d0", "fitness": -Infinity, "name": "SimpleCMAES", "description": "Simplified CMA-ES with rank-one update and adaptive step-size, fixing the broadcasting error and improving covariance matrix update.", "code": "import numpy as np\n\nclass SimpleCMAES:\n    def __init__(self, budget=10000, dim=10, mu_factor=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(dim * mu_factor)\n        self.lambda_ = 4 + int(3 * np.log(dim))\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n        self.m = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.chiN = np.sqrt(dim) * (1 - (1 / (4 * dim)) + (1 / (21 * dim**2)))\n        self.c_sigma = (self.mu / self.lambda_) / (np.linalg.norm(self.ps) + 1e-8)\n        self.d_sigma = 1 + 2 * np.max([0, 1 - (np.linalg.norm(self.ps) / self.chiN)])\n        self.mu_weights = np.log(self.lambda_ + 1) - np.log(np.arange(1, self.mu + 1))\n        self.mu_weights = self.mu_weights / np.sum(self.mu_weights)\n        self.mueff = np.sum(self.mu_weights)**2 / np.sum(self.mu_weights**2)\n        self.c_1 = 0.3 / ((dim + 1.3)**2 + self.mueff)\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        used_budget = 0\n\n        while used_budget < self.budget:\n            z = np.random.randn(self.dim, self.lambda_)\n            A = np.linalg.cholesky(self.C)\n            x = self.m[:, None] + self.sigma * A @ z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x.T])\n            used_budget += self.lambda_\n            \n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[:, np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_mu = x[:, idx[:self.mu]]\n            z_mu = z[:, idx[:self.mu]]\n\n            y_w = np.sum(z_mu * self.mu_weights[None, :], axis=1)\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * y_w\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / self.chiN) - 1))\n            self.sigma = np.clip(self.sigma, 1e-10, 1)\n            \n            self.m = self.m + self.sigma * A @ y_w\n            self.C = (1-self.c_1) * self.C + self.c_1 * np.outer(self.ps, self.ps)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["91ba986d-183a-42a1-a0fb-9b1ff8e4f1ab"], "operator": null, "metadata": {}}
{"id": "109a1568-ecc2-4f52-9e74-22277586a796", "fitness": 0.13325523472660694, "name": "SimpleCMAES", "description": "Simplified CMA-ES with rank-one update and adaptive step-size, fixing broadcasting errors and clipping, and simplified covariance matrix adaptation.", "code": "import numpy as np\n\nclass SimpleCMAES:\n    def __init__(self, budget=10000, dim=10, mu_factor=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(dim * mu_factor)\n        self.lambda_ = 4 + int(3 * np.log(dim))\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n        self.m = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.chiN = np.sqrt(dim) * (1 - (1 / (4 * dim)) + (1 / (21 * dim**2)))\n        self.c_sigma = (self.mu / self.lambda_) / (np.linalg.norm(self.ps) + 1e-8)\n        self.d_sigma = 1 + 2 * np.max([0, 1 - (np.linalg.norm(self.ps) / self.chiN)])\n        self.mu_weights = np.log(self.lambda_ + 1) - np.log(np.arange(1, self.mu + 1))\n        self.mu_weights = self.mu_weights / np.sum(self.mu_weights)\n        self.mueff = np.sum(self.mu_weights)**2 / np.sum(self.mu_weights**2)\n        self.c_1 = 0.3 / ((dim + 1.3)**2 + self.mueff)\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        used_budget = 0\n\n        while used_budget < self.budget:\n            z = np.random.randn(self.dim, self.lambda_)\n            A = np.linalg.cholesky(self.C)\n            x = self.m[:, None] + self.sigma * A @ z\n            x = np.clip(x, self.lb, self.ub)\n            \n            f = np.array([func(xi) for xi in x.T])\n            used_budget += self.lambda_\n            \n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[:, np.argmin(f)].copy()\n\n            idx = np.argsort(f)\n            x_mu = x[:, idx[:self.mu]]\n            z_mu = z[:, idx[:self.mu]]\n\n            y_w = np.sum(z_mu * self.mu_weights, axis=1)\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * y_w\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / self.chiN) - 1))\n            self.sigma = np.clip(self.sigma, 1e-10, 1)\n            \n            self.m = self.m + self.sigma * A @ y_w\n            self.C = (1-self.c_1) * self.C + self.c_1 * np.outer(self.ps, self.ps)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm SimpleCMAES scored 0.133 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["91ba986d-183a-42a1-a0fb-9b1ff8e4f1ab"], "operator": null, "metadata": {"aucs": [0.029932575071572876, 0.08612622541379766, 0.2608208570377465, 0.10120351056439958, 0.09880299541829951, 0.13806047822477663, 0.16720007112965063, 0.13695351440751025, 0.13172119857638864, 0.12268853364057164, 0.14911093329498903, 0.1591096296394795, 0.1856530249508923, 0.09632926860216995, 0.1103027129059061, 0.20123041988639379, 0.11079237596421099, 0.13862457577766196, 0.09666451998489534, 0.1437772740408263]}}
{"id": "4b46fc17-8f70-44bf-b391-759b25357c37", "fitness": 0.0, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified mutation and crossover, focusing on enhanced exploration and exploitation balance via parameter adaptation and population diversity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.archive_size = archive_size\n        self.archive = []\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        # Initialize archive with best solutions\n        sorted_indices = np.argsort(fitness)\n        self.archive = list(population[sorted_indices[:min(self.archive_size, self.pop_size)]])\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1 with archive\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = population[indices]\n                \n                if len(self.archive) > 0 and np.random.rand() < 0.1:  # Use archive occasionally\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n                else:\n                    indices2 = np.random.choice(self.pop_size, 1, replace=False)\n                    x_r3 = population[indices2[0]]\n                \n                mutant = population[i] + self.F * (x_r1 - x_r2) # Reduced exploration by adding to current vector.\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover - Simplified\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                    \n                    # Update archive if the trial vector is better\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(trial_vector)\n                    else:\n                        worst_archive_index = np.argmax([func(x) for x in self.archive])\n                        if f_trial < func(self.archive[worst_archive_index]):\n                            self.archive[worst_archive_index] = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["99a712d5-334b-4ab7-bd14-97d6f0dae033"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "3a915984-df08-4256-aefb-411bcaf483ac", "fitness": 0.7225430850192122, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution using only DE/rand/1 mutation with dynamic F and CR and vectorized operations for performance.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_min=0.1, F_max=0.9, CR_min=0.1, CR_max=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_min = F_min\n        self.F_max = F_max\n        self.CR_min = CR_min\n        self.CR_max = CR_max\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Dynamic F and CR\n            F = np.random.uniform(self.F_min, self.F_max, size=self.pop_size)\n            CR = np.random.uniform(self.CR_min, self.CR_max, size=self.pop_size)\n\n            # Mutation: DE/rand/1\n            indices = np.random.randint(0, self.pop_size, size=(self.pop_size, 3))\n            x_r1 = population[indices[:, 0]]\n            x_r2 = population[indices[:, 1]]\n            x_r3 = population[indices[:, 2]]\n            mutant = x_r1 + F[:, None] * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            crossover_mask = np.random.rand(self.pop_size, self.dim) < CR[:, None]\n            trial_vector = np.where(crossover_mask, mutant, population)\n\n            # Selection\n            fitness_trial = np.array([func(x) for x in trial_vector])\n            self.budget -= self.pop_size # Vectorized fitness calculation.\n\n            improved = fitness_trial < fitness\n            population[improved] = trial_vector[improved]\n            fitness[improved] = fitness_trial[improved]\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.723 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["99a712d5-334b-4ab7-bd14-97d6f0dae033"], "operator": null, "metadata": {"aucs": [0.2627511236253658, 0.5500135256687113, 0.7508324820572847, 0.8739738810368402, 0.8179054742899505, 0.8630998009326979, 0.788860439078508, 0.7925309652334676, 0.8306976451148715, 0.8092949162699584, 0.8813615976054969, 0.9939748709110988, 0.30251266759245043, 0.7800390427426791, 0.9453223765674219, 0.8908464930836412, 0.6412976276663727, 0.9164025583161824, 0.22613311321242235, 0.5330110993788222]}}
{"id": "510b2f56-832a-4c9a-9686-4e7838e6523d", "fitness": 0.6021185612477503, "name": "AdaptiveDE", "description": "Simplified Adaptive DE with reduced parameter tuning, directly updating population based on best fitness and using a more aggressive mutation strategy.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Find best individual\n            best_index = np.argmin(fitness)\n            best_individual = population[best_index]\n\n            for i in range(self.pop_size):\n                # Mutation: DE/best/1 - Simplified and Aggressive\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = population[indices]\n                mutant = best_individual + 0.5 * (x_r1 - x_r2)  # Aggressive mutation\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover - Fixed probability\n                crossover_mask = np.random.rand(self.dim) < 0.7\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.602 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["99a712d5-334b-4ab7-bd14-97d6f0dae033"], "operator": null, "metadata": {"aucs": [0.4159174441987772, 0.9072924195874137, 0.5521765811081533, 0.9652004614812586, 0.9403596804911273, 0.9565357596836495, 0.33820181062628596, 0.5697136855667879, 0.7151032543727422, 0.19996180226077487, 0.9611940392661056, 0.9989402214471018, 0.3269862241607552, 0.3482938961942593, 0.7263614415726369, 0.3507625908013663, 0.6437184534052258, 0.3813082263976242, 0.22270237757625577, 0.5216408547567036]}}
{"id": "93c77198-026e-495d-a14f-deca5e18de85", "fitness": 0.695368199153389, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and a reduced population size for faster convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub) # Clip to bounds\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                \n                if self.budget <= 0:\n                    break\n\n            # Adapt F and CR (simple adaptation)\n            self.F = np.clip(self.F + np.random.normal(0, 0.01), 0.1, 0.9)\n            self.CR = np.clip(self.CR + np.random.normal(0, 0.01), 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.695 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b40cffbe-da06-4b93-8dc4-1aac70e82a32"], "operator": null, "metadata": {"aucs": [0.28051182424900944, 0.40528127337695985, 0.32847975592982037, 0.9605716946166418, 0.9131829024926463, 0.9207571018291403, 0.8287016360763626, 0.8431571430974973, 0.7731139567270453, 0.8828634673785506, 0.48804503740626926, 0.9943228899068476, 0.26797515300658814, 0.9111080070137606, 0.7864813235440408, 0.9126184431737709, 0.6274377794033063, 0.9409460134179237, 0.31333909901762025, 0.5284694814039796]}}
{"id": "390d2a95-863e-4c76-9f1f-3694b431e7a9", "fitness": 0.7497101399802737, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and a focus on efficient memory management.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=5, F_init=0.5, CR_init=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.archive = []\n        self.F = F_init\n        self.CR = CR_init\n        self.success_F = []\n        self.success_CR = []\n        self.memory_size = 10\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Simplified success memory update\n                    if len(self.success_F) < self.memory_size:\n                        self.success_F.append(self.F)\n                        self.success_CR.append(self.CR)\n                    else:\n                        self.success_F.pop(0)\n                        self.success_CR.pop(0)\n                        self.success_F.append(self.F)\n                        self.success_CR.append(self.CR)\n\n                    # Simplified archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(0, self.archive_size)] = population[i].copy()\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n            # Adapt F and CR - simplified adaptation\n            if self.success_F:\n                self.F = np.mean(self.success_F)\n                self.F = np.clip(self.F, 0.1, 0.9)\n\n            if self.success_CR:\n                self.CR = np.mean(self.success_CR)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n            self.success_F = []\n            self.success_CR = []\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.750 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2a678fc3-7842-4165-ab58-635ca7724a5c"], "operator": null, "metadata": {"aucs": [0.3257837670274971, 0.7911811096934802, 0.8395498002391193, 0.938526793245569, 0.8815896908544074, 0.903105218307593, 0.8448261738659435, 0.8274966876801624, 0.8746520449085549, 0.842853102015812, 0.9278778888232446, 0.9861329020811797, 0.31439987123722946, 0.8545193061004129, 0.39196725627813933, 0.9191282960099973, 0.7651752541591471, 0.9123403124370058, 0.31870148828002665, 0.5343958363609537]}}
{"id": "397525ef-1008-4487-9446-256119d5427b", "fitness": 0.7699781375099659, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a weighted average of successful F and CR values, and jittering to prevent premature convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_init=0.5, CR_init=0.7, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.CR = CR_init\n        self.memory_size = memory_size\n        self.success_F = []\n        self.success_CR = []\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    delta = np.abs(fitness[i] - f_trial)\n                    self.success_F.append((self.F, delta))\n                    self.success_CR.append((self.CR, delta))\n                    if len(self.success_F) > self.memory_size:\n                        self.success_F.pop(0)\n                        self.success_CR.pop(0)\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n            # Adapt F and CR\n            if self.success_F:\n                weights = np.array([item[1] for item in self.success_F])\n                sum_weights = np.sum(weights)\n                if sum_weights > 0:\n                    weights /= sum_weights\n                    avg_F = np.sum(np.array([item[0] for item in self.success_F]) * weights)\n                    self.F = 0.9 * self.F + 0.1 * avg_F + 0.01 * np.random.randn() #Jittering\n                else:\n                    self.F = 0.5 # Reset if no improvement\n                self.F = np.clip(self.F, 0.1, 0.9)\n\n            if self.success_CR:\n                weights = np.array([item[1] for item in self.success_CR])\n                sum_weights = np.sum(weights)\n                if sum_weights > 0:\n                    weights /= sum_weights\n                    avg_CR = np.sum(np.array([item[0] for item in self.success_CR]) * weights)\n                    self.CR = 0.9 * self.CR + 0.1 * avg_CR + 0.01 * np.random.randn() #Jittering\n                else:\n                    self.CR = 0.7 # Reset if no improvement\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.770 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2a678fc3-7842-4165-ab58-635ca7724a5c"], "operator": null, "metadata": {"aucs": [0.3793073994276095, 0.7613182631921603, 0.8047190144004535, 0.932417543347577, 0.8824329253397573, 0.8954181769264179, 0.8512425715126852, 0.8174418938299277, 0.8294563123093175, 0.8631229041706647, 0.9112575373798686, 0.999646874375109, 0.34213028814279545, 0.907810809115602, 0.9554964161323828, 0.9068697063564608, 0.6930979687563994, 0.92548683513409, 0.22394974451545546, 0.5169395658345852]}}
{"id": "22b94b6c-56e4-43e5-abe8-8e5b28a69d49", "fitness": 0.6498850759116246, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameter control and reduced evaluations using caching.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5  # Initial Mutation factor\n        self.CR = 0.7  # Initial Crossover rate\n        self.fitness_cache = {} # Cache to store previously evaluated fitness values\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            fitness[i] = self._evaluate(func, population[i])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = self._evaluate(func, trial_vector)\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n            # Self-adaptive F and CR\n            self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 0.9)\n            self.CR = np.clip(np.random.normal(self.CR, 0.1), 0.1, 0.9)\n\n\n        return self.f_opt, self.x_opt\n\n    def _evaluate(self, func, x):\n        x_tuple = tuple(x)  # Convert numpy array to tuple for caching\n        if x_tuple in self.fitness_cache:\n            return self.fitness_cache[x_tuple]\n        else:\n            f = func(x)\n            self.fitness_cache[x_tuple] = f\n            self.budget -= 1\n            return f", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.650 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b40cffbe-da06-4b93-8dc4-1aac70e82a32"], "operator": null, "metadata": {"aucs": [0.2404060330229406, 0.7325442664766704, 0.7946400451699803, 0.8429948087615898, 0.8208114814324201, 0.8647008696805524, 0.7321316902689654, 0.36656077461498515, 0.819431794101164, 0.2553459435235722, 0.8843107438458486, 0.9965345647474344, 0.47729931574883044, 0.32787621640494025, 0.9439403530223354, 0.8815001231277125, 0.40747366358620174, 0.8564969568813525, 0.24484134170595295, 0.5078605321090389]}}
{"id": "7a4c7492-3727-4d64-a08c-fb7a5096d138", "fitness": 0.4525136597189213, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a self-adaptive mutation factor and reduced crossover rate to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, CR=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.CR = CR  # Reduced crossover rate\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1 with self-adaptive F\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                F = np.random.normal(0.5, 0.3)  # Self-adaptive mutation factor\n                F = np.clip(F, 0.1, 1.0) # Clip F to be between 0.1 and 1.0\n                mutant = x_r1 + F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.453 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["436e171a-fb26-4996-8e6c-2717c6fcf88a"], "operator": null, "metadata": {"aucs": [0.1508899543363692, 0.21600742434626952, 0.436734178103773, 0.5577590397258086, 0.4739621016188965, 0.5725791410432706, 0.3421101138546844, 0.42059048939166055, 0.4665740450385807, 0.226229097592075, 0.36069204168832325, 0.996755616238594, 0.2558405339831963, 0.42175829324027747, 0.7541585475439745, 0.6272405942608212, 0.35368561610113836, 0.6899484470371481, 0.21969812363821484, 0.5070597955953492]}}
{"id": "6c928a56-d2ab-4953-9e91-4c7eaf18e59d", "fitness": 0.8100056913544973, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with reduced parameter tuning and a focus on population diversity to enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1 - Simplified with dynamic F\n                F = np.random.uniform(0.2, 0.8)  # Dynamic F\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover - Simplified with dynamic CR\n                CR = np.random.uniform(0.5, 1.0)  # Dynamic CR\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.810 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["99a712d5-334b-4ab7-bd14-97d6f0dae033"], "operator": null, "metadata": {"aucs": [0.36644609282881524, 0.8505306024902094, 0.8080623475272763, 0.9214542024129286, 0.8839995505460734, 0.9015514336075455, 0.8398281216821889, 0.8174645513443474, 0.8772687283386124, 0.8452101723283241, 0.9205805732089554, 0.991171688129026, 0.5297420833339388, 0.8797180894386616, 0.8458013608511785, 0.8905037382038181, 0.8076409038481986, 0.930239977495973, 0.8036850924965936, 0.4892145169772808]}}
{"id": "0da6ba58-d4de-4ba5-8f98-8ca1019d1e1f", "fitness": 0.6202332482146617, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a dynamic archive to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=25):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.archive = []\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1 with archive\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = population[indices]\n                if len(self.archive) > 0:\n                    x_r3 = self.archive[np.random.randint(len(self.archive))]\n                else:\n                    x_r3 = population[np.random.randint(self.pop_size)]\n\n                F = np.random.uniform(0.2, 0.8) # Random F\n                mutant = x_r1 + F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                CR = np.random.uniform(0.3, 0.9) # Random CR\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    # Update population\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(self.archive_size)] = population[i].copy()\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.620 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["436e171a-fb26-4996-8e6c-2717c6fcf88a"], "operator": null, "metadata": {"aucs": [0.22685930241613506, 0.43456613092600993, 0.5861142179996892, 0.7973701750455228, 0.6711653804720797, 0.7296835494608129, 0.5987251827824898, 0.5688252333326875, 0.6662020465493057, 0.5804015777371625, 0.7662905514277871, 0.9930726668978336, 0.3539150797337859, 0.6343449377269956, 0.8632264062316454, 0.7690349972200585, 0.523362575146284, 0.791739599644787, 0.3273359421061748, 0.5224294114359884]}}
{"id": "875da80e-724e-4ae9-b494-47aae0227b34", "fitness": 0.0, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a weighted average of successful F and CR values and reduced function evaluations by checking for changes before evaluating fitness.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=5, F_init=0.5, CR_init=0.7, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.archive = []\n        self.F = F_init\n        self.CR = CR_init\n        self.success_F = []\n        self.success_CR = []\n        self.memory_size = memory_size\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Check if the trial vector is different from the current individual\n                if np.any(trial_vector != population[i]):\n                    # Selection\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        delta = np.abs(fitness[i] - f_trial)\n                        self.success_F.append((self.F, delta))\n                        self.success_CR.append((self.CR, delta))\n                        if len(self.success_F) > self.memory_size:\n                            self.success_F.pop(0)\n                            self.success_CR.pop(0)\n\n                        population[i] = trial_vector\n                        fitness[i] = f_trial\n\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial_vector\n\n            # Adapt F and CR\n            if self.success_F:\n                weights = np.array([item[1] for item in self.success_F])\n                sum_weights = np.sum(weights)\n                if sum_weights > 0:\n                    weights /= sum_weights\n                    self.F = np.sum(np.array([item[0] for item in self.success_F]) * weights)\n                else:\n                    self.F = 0.5 # Reset if no improvement\n                self.F = np.clip(self.F, 0.1, 0.9)\n\n            if self.success_CR:\n                weights = np.array([item[1] for item in self.success_CR])\n                sum_weights = np.sum(weights)\n                if sum_weights > 0:\n                    weights /= sum_weights\n                    self.CR = np.sum(np.array([item[0] for item in self.success_CR]) * weights)\n                else:\n                    self.CR = 0.7 # Reset if no improvement\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2a678fc3-7842-4165-ab58-635ca7724a5c"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "3415b8e0-68ec-4e2f-8bc8-dc874c183632", "fitness": 0.7430041545079104, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a reduced parameter set and focused adaptation on successful mutations.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = 0.7 # Fixed Crossover Rate\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        successful_mutations_F = []\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub) # Clip to bounds\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                if not np.array_equal(trial_vector, population[i]):  # Evaluate only if different\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        successful_mutations_F.append(self.F)\n                        population[i] = trial_vector\n                        fitness[i] = f_trial\n\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial_vector\n                \n                if self.budget <= 0:\n                    break\n\n            # Adapt F based on successful mutations\n            if successful_mutations_F:\n                self.F = np.mean(successful_mutations_F)\n                successful_mutations_F = []\n            \n            self.F = np.clip(self.F + np.random.normal(0, 0.01,1), 0.1, 0.9)[0] # Keep it as np array of size 1 to make it compatible with successful mutations being a list.\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.743 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b40cffbe-da06-4b93-8dc4-1aac70e82a32"], "operator": null, "metadata": {"aucs": [0.41056727855850617, 0.6714011716334891, 0.6256563726878923, 0.9289049116125401, 0.8778830689429735, 0.5197491169593988, 0.841359198863711, 0.7622885580792325, 0.8684618219220037, 0.7936614747036915, 0.9297911016713927, 0.9931938436019238, 0.5001925602744725, 0.8704290639942096, 0.9156773157808992, 0.9003290453266022, 0.7773743869935966, 0.8960575039417172, 0.24526683325187837, 0.5318384613580782]}}
{"id": "64116b8c-0686-4ca6-b1a6-d45db2596159", "fitness": 0.0, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a focus on population diversity through periodic re-initialization of poorly performing individuals.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_init=0.5, CR_init=0.7, refresh_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.CR = CR_init\n        self.refresh_rate = refresh_rate\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n            \n            # Refresh poorly performing individuals\n            num_to_refresh = int(self.refresh_rate * self.pop_size)\n            worst_indices = np.argsort(fitness)[-num_to_refresh:]\n            population[worst_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_refresh, self.dim))\n            fitness[worst_indices] = [func(x) for x in population[worst_indices]]\n            self.budget -= num_to_refresh\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["390d2a95-863e-4c76-9f1f-3694b431e7a9"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "8750e912-1434-4590-9e83-6430920ae80b", "fitness": 0.3132736026288293, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on successful mutations, combined with a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_init=0.5, CR_init=0.7, memory_size=10, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.CR = CR_init\n        self.memory_size = memory_size\n        self.success_F = []\n        self.success_CR = []\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n                    if len(self.success_F) > self.memory_size:\n                        self.success_F.pop(0)\n                        self.success_CR.pop(0)\n\n            # Adapt F and CR using mean of successful values\n            if self.success_F:\n                self.F = np.mean(self.success_F)\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.success_F = []\n\n            if self.success_CR:\n                self.CR = np.mean(self.success_CR)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n                self.success_CR = []\n            \n            # Restart mechanism\n            if np.random.rand() < self.restart_prob:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.313 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["397525ef-1008-4487-9446-256119d5427b"], "operator": null, "metadata": {"aucs": [0.1687458226312598, 0.27768127382932783, 0.4164544154864427, 0.39122353619089245, 0.3772478310658376, 0.5374287205984691, 0.33740722122840494, 0]}}
{"id": "61ec90cf-dfb8-4f26-b270-56e2f07f639d", "fitness": 0.7718430802644269, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a focus on reducing parameter adaptation complexity and enhancing local search using a neighborhood-based mutation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_init=0.5, CR_init=0.7, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.CR = CR_init\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1 or Local Search\n                if np.random.rand() < self.local_search_prob:\n                    # Local Search: Add small random perturbation\n                    mutant = population[i] + np.random.normal(0, 0.1, size=self.dim)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                else:\n                    # DE/rand/1 mutation\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[indices]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.772 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["390d2a95-863e-4c76-9f1f-3694b431e7a9"], "operator": null, "metadata": {"aucs": [0.3422657640961386, 0.7031025341191135, 0.8230261030663306, 0.9287926260651465, 0.871249272189797, 0.9019705137081154, 0.8227257940607667, 0.8237782698568221, 0.8602502851792221, 0.8132750525795815, 0.9018132403403446, 0.997156734267828, 0.4719890286054552, 0.8425784200619875, 0.9399894386279527, 0.8886836684624143, 0.6785252061865374, 0.9155849533495157, 0.3727234144569297, 0.5373812860085394]}}
{"id": "6b5d8ddf-669d-46a5-a3da-a4c9cd3fc379", "fitness": 0.7986753310605131, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a focus on reducing complexity and computational cost by using a fixed F and CR, and incorporating a simple perturbation mechanism to enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Perturbation - Simple exploration boost\n                if np.random.rand() < 0.05:  # 5% chance of perturbation\n                    trial_vector += np.random.normal(0, 0.1, self.dim)  # Add small random noise\n                    trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.799 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["390d2a95-863e-4c76-9f1f-3694b431e7a9"], "operator": null, "metadata": {"aucs": [0.3790189700368437, 0.8046159883359263, 0.8288399403956732, 0.9442172774161017, 0.8983876085520826, 0.8983406555854994, 0.7299884475462538, 0.817356421889261, 0.8488488823214604, 0.8183383099983466, 0.9269789581700375, 0.9933260781487986, 0.4747908152642777, 0.8529131708566262, 0.8930690412142358, 0.9129839481407235, 0.7628154595638471, 0.9252577104954774, 0.7614075465075993, 0.5020113907711906]}}
{"id": "a35f31e8-7795-4b43-b222-4a209af1a7c1", "fitness": 0.7485084102520774, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a single, self-adaptive F value for all dimensions and reduced parameter tuning.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        F = 0.5  # Initialize F \n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1 - Simplified\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover - Simplified (Binomial) with fixed CR\n                CR = 0.9\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                        # Adapt F based on success\n                        F = 0.5 * F + 0.5 * np.random.uniform(0.2, 0.8) # Adapt F if a new best is found\n                \n                else:\n                    F = 0.9 * F + 0.1 * np.random.uniform(0.2, 0.8) \n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.749 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6c928a56-d2ab-4953-9e91-4c7eaf18e59d"], "operator": null, "metadata": {"aucs": [0.2447514514771033, 0.8483123248133436, 0.7229363614781594, 0.9503562720914, 0.8967874479600741, 0.9150674183575689, 0.8514129535365045, 0.8660197505331207, 0.35831891378154446, 0.8526942222039341, 0.9231335602373877, 0.9976568194280161, 0.34671990597656854, 0.8994179716809652, 0.756323564418634, 0.8926778874736674, 0.8247849532889564, 0.938339940848658, 0.381040124611703, 0.5034163608442379]}}
{"id": "0311a8e3-44a5-4d8d-96e8-e0a9ac125132", "fitness": 0.7586329532049055, "name": "AdaptiveDE", "description": "Simplified Adaptive DE with self-adaptive parameters and reduced memory for faster convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_init=0.5, CR_init=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.CR = CR_init\n        self.F_memory = []\n        self.CR_memory = []\n        self.memory_size = 5\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Update memory with successful F and CR values\n                    self.F_memory.append(self.F)\n                    self.CR_memory.append(self.CR)\n                    if len(self.F_memory) > self.memory_size:\n                        self.F_memory.pop(0)\n                        self.CR_memory.pop(0)\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n            # Adapt F and CR\n            if self.F_memory:\n                self.F = np.mean(self.F_memory)\n                self.CR = np.mean(self.CR_memory)\n            \n            # Ensure F and CR remain within bounds\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.CR = np.clip(self.CR, 0.1, 0.9)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.759 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["390d2a95-863e-4c76-9f1f-3694b431e7a9"], "operator": null, "metadata": {"aucs": [0.3752793898478036, 0.4785149146717762, 0.8227475694521315, 0.9229579546408762, 0.8895453743151409, 0.9006800522816338, 0.8372739888425798, 0.8232769277053008, 0.8661572847345941, 0.8300326374724145, 0.9021810498876184, 0.9981946078439926, 0.3484112247739729, 0.8582179878481115, 0.9514714887655527, 0.9086043718475163, 0.7690972965954668, 0.9290014950335105, 0.22463306660340487, 0.536380380934714]}}
{"id": "f3bfef1b-313c-4fa9-8bc8-74bbf195069a", "fitness": 0.7647447970566439, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a weighted average of successful F and CR values, and a simplified jittering strategy.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_init=0.5, CR_init=0.7, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.CR = CR_init\n        self.memory_size = memory_size\n        self.success_F = []\n        self.success_CR = []\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    delta = np.abs(fitness[i] - f_trial)\n                    self.success_F.append((self.F, delta))\n                    self.success_CR.append((self.CR, delta))\n                    if len(self.success_F) > self.memory_size:\n                        self.success_F.pop(0)\n                        self.success_CR.pop(0)\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n            # Adapt F and CR\n            if self.success_F:\n                weights = np.array([item[1] for item in self.success_F])\n                avg_F = np.average([item[0] for item in self.success_F], weights=weights)\n                self.F = 0.9 * self.F + 0.1 * avg_F + 0.01 * np.random.randn() #Jittering\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.success_F = [] # Reset the memory\n\n            if self.success_CR:\n                weights = np.array([item[1] for item in self.success_CR])\n                avg_CR = np.average([item[0] for item in self.success_CR], weights=weights)\n                self.CR = 0.9 * self.CR + 0.1 * avg_CR + 0.01 * np.random.randn() #Jittering\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n                self.success_CR = [] # Reset the memory\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.765 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["397525ef-1008-4487-9446-256119d5427b"], "operator": null, "metadata": {"aucs": [0.24779572345189949, 0.5526500240284533, 0.6313706257118341, 0.9255812273880792, 0.8818993797974122, 0.9005527552737056, 0.793807484959191, 0.7857651576781219, 0.8893125687800667, 0.7958464818750981, 0.9279080509017886, 0.9957267526017646, 0.31238051803897793, 0.8723145501408773, 0.9463273007902373, 0.8931967703175131, 0.773438132139245, 0.9335080911212066, 0.7278909608462854, 0.5076233852911198]}}
{"id": "0af4cbc4-1af3-486c-9581-ce7ac0b8e6e6", "fitness": 0.6002988697007622, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with a simplified mutation strategy using only two random individuals and dynamic F and CR, coupled with a memory of successful parameters.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.memory_F = np.random.uniform(0.5, 0.7, size=memory_size)\n        self.memory_CR = np.random.uniform(0.8, 1.0, size=memory_size)\n        self.memory_idx = 0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter selection from memory\n                F = self.memory_F[np.random.randint(self.memory_size)]\n                CR = self.memory_CR[np.random.randint(self.memory_size)]\n\n                # Mutation: DE/rand/1 - Simplified with dynamic F and only two random individuals\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = population[indices]\n                mutant = population[i] + F * (x_r1 - x_r2)  # Simplified mutation\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover - Simplified with dynamic CR\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Memory update\n                    self.memory_F[self.memory_idx] = F\n                    self.memory_CR[self.memory_idx] = CR\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.600 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6c928a56-d2ab-4953-9e91-4c7eaf18e59d"], "operator": null, "metadata": {"aucs": [0.18675502753114193, 0.44293928690149387, 0.6039977684300066, 0.8575622945077346, 0.6275280467830333, 0.7566940441774517, 0.4355628645336793, 0.5491531046907768, 0.701322246716893, 0.2282738997814754, 0.8724786603400858, 0.9907132467820654, 0.6020699335227799, 0.521818526813937, 0.9132967418422618, 0.698860440730968, 0.48737489033627834, 0.8144321786527906, 0.2152367108261506, 0.4999074801142378]}}
{"id": "c6feb08c-a1ab-4460-8dd4-a16bb82cfa7e", "fitness": 0.6386999764052324, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on a shrinking population size and memory of successful parameters.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, archive_size=5, F_init=0.5, CR_init=0.7, shrink_factor=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_init = pop_size_init\n        self.pop_size = pop_size_init\n        self.archive_size = archive_size\n        self.archive = []\n        self.F = F_init\n        self.CR = CR_init\n        self.success_F = []\n        self.success_CR = []\n        self.memory_size = 5\n        self.shrink_factor = shrink_factor\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > self.pop_size:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Simplified success memory update\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n\n\n                    # Simplified archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(0, self.archive_size)] = population[i].copy()\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n            # Adapt F and CR - simplified adaptation\n            if self.success_F:\n                self.F = np.mean(self.success_F[-self.memory_size:])  # Use only the last memory_size values\n                self.F = np.clip(self.F, 0.1, 0.9)\n\n            if self.success_CR:\n                self.CR = np.mean(self.success_CR[-self.memory_size:]) # Use only the last memory_size values\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n            self.success_F = []\n            self.success_CR = []\n\n            # Shrink population size\n            self.pop_size = int(self.pop_size * self.shrink_factor)\n            self.pop_size = max(10, self.pop_size) # Ensure a minimum population size\n            \n            # Re-evaluate the population based on the new size\n            population = population[:self.pop_size]\n            fitness = fitness[:self.pop_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.639 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["390d2a95-863e-4c76-9f1f-3694b431e7a9"], "operator": null, "metadata": {"aucs": [0.49518724623526267, 0.3867945510288685, 0.5067912668591334, 0.928632174299505, 0.8961480386388733, 0.7077484699946999, 0.8257599368459232, 0.4413331149374805, 0.8889312295883236, 0.23511434434224043, 0.9243354903419085, 0.9988563108147878, 0.3579110396899796, 0.6247013632857044, 0.9079850582916755, 0.7865922656257442, 0.6259750637651103, 0.4773235311873182, 0.22327885864227137, 0.5346001736898383]}}
{"id": "4354195b-72e5-4552-8e2f-c3bd58c2b5b8", "fitness": 0.7765304094731671, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive mutation factor F and crossover rate CR based on previous success, with a memory of successful parameters.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_F = []\n        self.memory_CR = []\n        self.memory_size = 5  # Size of the memory\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                if self.memory_F:\n                    self.F = np.random.choice(self.memory_F)\n                else:\n                    self.F = 0.5  # Default value if memory is empty\n                \n                if self.memory_CR:\n                    self.CR = np.random.choice(self.memory_CR)\n                else:\n                    self.CR = 0.7 # Default value if memory is empty\n\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Update memory\n                    self.memory_F.append(self.F)\n                    self.memory_CR.append(self.CR)\n\n                    # Keep memory size limited\n                    if len(self.memory_F) > self.memory_size:\n                        self.memory_F.pop(0)\n                    if len(self.memory_CR) > self.memory_size:\n                        self.memory_CR.pop(0)\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.777 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3415b8e0-68ec-4e2f-8bc8-dc874c183632"], "operator": null, "metadata": {"aucs": [0.4377573614831506, 0.7438671576018758, 0.8102654636342326, 0.9423822989857672, 0.872240306375121, 0.9046424292707171, 0.8249531820230467, 0.8311722691167753, 0.8631135323138145, 0.8119012445341574, 0.9086301449183019, 0.9985323115853583, 0.37168732620855705, 0.8387674833732688, 0.9558745024924022, 0.8892651241529974, 0.7992589946089902, 0.9108969568490783, 0.34295359475367004, 0.472446505182057]}}
{"id": "56fc7c53-1b29-4cb9-841c-b6e9bfdf182b", "fitness": 0.0, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters F and CR, and reduced population size for faster convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5\n        self.CR = 0.7\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1 - Simplified with self-adaptive F\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover - Simplified with self-adaptive CR\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Update F and CR based on success\n                    self.F = 0.9 * self.F + 0.1 * np.random.rand()\n                    self.CR = 0.9 * self.CR + 0.1 * np.random.rand()\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6c928a56-d2ab-4953-9e91-4c7eaf18e59d"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "84dbf5c3-3db3-45f2-b7f4-67c38ad3dcd7", "fitness": 0.7739187265960915, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified mutation, crossover, and parameter adaptation based on success history.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n\n        self.memory_F = []\n        self.memory_CR = []\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                if self.memory_F:\n                  self.F = np.clip(np.random.choice(self.memory_F), 0.1, 0.9)\n                if self.memory_CR:\n                  self.CR = np.clip(np.random.choice(self.memory_CR), 0.1, 0.9)\n                \n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    self.memory_F.append(self.F)\n                    self.memory_CR.append(self.CR)\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.774 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3415b8e0-68ec-4e2f-8bc8-dc874c183632"], "operator": null, "metadata": {"aucs": [0.2947206534840646, 0.783319088855549, 0.8306087076614368, 0.9415934708116492, 0.8747758227096276, 0.9010460062660478, 0.8083174752174496, 0.8284212612379214, 0.8741007012456701, 0.8313728713374517, 0.9254530629682649, 0.9962602819204034, 0.45375838546199354, 0.8453266412619898, 0.9469600849446725, 0.8996367944371657, 0.7742418307945109, 0.9098723018794327, 0.23858092031596945, 0.520008169110558]}}
{"id": "9b78d6f7-9dd3-4152-9198-89070deb070d", "fitness": 0.7535489492610272, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with reduced perturbation and adjusted parameters for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Perturbation - Simple exploration boost (reduced frequency and magnitude)\n                if np.random.rand() < 0.02:  # 2% chance of perturbation\n                    trial_vector += np.random.normal(0, 0.05, self.dim)  # Add small random noise\n                    trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.754 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6b5d8ddf-669d-46a5-a3da-a4c9cd3fc379"], "operator": null, "metadata": {"aucs": [0.25249199295497937, 0.8030877661298698, 0.8520534363509128, 0.912629240571723, 0.8629701505910773, 0.9007587125772285, 0.8271434053466507, 0.8064646377614694, 0.8582279278568357, 0.83827366032845, 0.9121026538339033, 0.9959211032107723, 0.33198007573975796, 0.8514562413304827, 0.7127232298260996, 0.9007955022761963, 0.7640376511649014, 0.9162736025813032, 0.26077440148742514, 0.5108135933005065]}}
{"id": "be269fa9-2651-45f8-99d9-dbbec4aebecb", "fitness": 0.4166827670534851, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a decay mechanism for exploration control, and simplified mutation/crossover.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, decay_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.decay_rate = decay_rate  # Decay rate for F and CR\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1 simplified\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover simplified\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                    # Decay F and CR: Gradually reduce exploration\n                    self.F *= self.decay_rate\n                    self.CR *= self.decay_rate\n\n                    self.F = np.clip(self.F, 0.1, 0.9)\n                    self.CR = np.clip(self.CR, 0.1, 0.9)\n\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.417 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["84dbf5c3-3db3-45f2-b7f4-67c38ad3dcd7"], "operator": null, "metadata": {"aucs": [0.1340081458029797, 0.36875136527468544, 0.4853463740092936, 0.33558710687326954, 0.5162577796041761, 0.47998278221238155, 0.30969228288178263, 0.36728884445399357, 0.43446288193713267, 0.18574574809807454, 0.5077907699818811, 0.9934022880270478, 0.23373715254130178, 0.3104510054156149, 0.7510495174459088, 0.4788000180233083, 0.30515638465091866, 0.4021794663561814, 0.23807180317940724, 0.4958936243003639]}}
{"id": "d7eb0aca-7854-45cf-b410-8650aa36d855", "fitness": 0.5877795520038404, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with dynamic F and CR adaptation based on population fitness improvement, and a local search component for exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_init=0.5, CR_init=0.7, local_search_prob=0.1, F_adapt_rate=0.1, CR_adapt_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.CR = CR_init\n        self.local_search_prob = local_search_prob\n        self.F_adapt_rate = F_adapt_rate\n        self.CR_adapt_rate = CR_adapt_rate\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            old_fitness = np.copy(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1 or Local Search\n                if np.random.rand() < self.local_search_prob:\n                    # Local Search: Add small random perturbation\n                    mutant = population[i] + np.random.normal(0, 0.05, size=self.dim) # Reduced perturbation\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                else:\n                    # DE/rand/1 mutation\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[indices]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n            # Adapt F and CR based on population fitness change\n            fitness_improvement = np.mean(old_fitness - fitness)\n            if fitness_improvement > 0:\n                self.F = min(1.0, self.F * (1 + self.F_adapt_rate))  # Increase F if improvement\n                self.CR = min(1.0, self.CR * (1 + self.CR_adapt_rate)) # Increase CR if improvement\n            else:\n                self.F = max(0.1, self.F * (1 - self.F_adapt_rate))  # Decrease F if no improvement\n                self.CR = max(0.1, self.CR * (1 - self.CR_adapt_rate)) # Decrease CR if no improvement\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.588 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["61ec90cf-dfb8-4f26-b270-56e2f07f639d"], "operator": null, "metadata": {"aucs": [0.21167494473312887, 0.48928431676698647, 0.4996495947129008, 0.8591227946161577, 0.6460251534265059, 0.752772739019802, 0.3914255542664873, 0.45322890129313576, 0.48251997423326554, 0.5155583302442486, 0.7796302193116444, 0.9948891152615622, 0.6007104253899113, 0.5279229851997645, 0.9268048496719317, 0.6486862872031756, 0.4641171894910875, 0.6356443575373475, 0.37235481134340276, 0.5035684963543602]}}
{"id": "f0228362-9877-4880-9a23-d5707bb824b7", "fitness": 0.7555572880529063, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with reduced complexity by removing explicit parameter adaptation and adjusting the local search probability dynamically based on the algorithm's progress.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, local_search_prob_init=0.1, local_search_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_prob = local_search_prob_init\n        self.local_search_decay = local_search_decay\n        self.f_opt = np.inf  # Initialize f_opt to positive infinity\n        self.x_opt = None    # Initialize x_opt to None\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1 or Local Search\n                if np.random.rand() < self.local_search_prob:\n                    # Local Search: Add small random perturbation\n                    mutant = population[i] + np.random.normal(0, 0.1, size=self.dim)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                else:\n                    # DE/rand/1 mutation\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[indices]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                        self.local_search_prob = min(1.0, self.local_search_prob / self.local_search_decay) # Increase local search upon finding new optimum\n\n                else:\n                     self.local_search_prob *= self.local_search_decay   # Reduce local search when not improving\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.756 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["61ec90cf-dfb8-4f26-b270-56e2f07f639d"], "operator": null, "metadata": {"aucs": [0.31815206772349724, 0.6476194761418748, 0.7744040400245458, 0.9277865745828259, 0.8892040896360309, 0.9026848615290423, 0.8256907312061535, 0.8244886111929097, 0.8571756198273106, 0.8560842228998292, 0.9254292937589134, 0.9979699774451507, 0.37469135207979987, 0.827768777027428, 0.9528371157448519, 0.8913206650854852, 0.6551193189372857, 0.9255363541668316, 0.23796003220777662, 0.49922257984058227]}}
{"id": "21445fd9-861b-4b7b-a156-7c91b36024d8", "fitness": 0.7545265482220015, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified memory and parameter adaptation, focusing on population diversity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.memory_F = np.full(memory_size, 0.5)\n        self.memory_CR = np.full(memory_size, 0.7)\n        self.memory_idx = 0\n\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                F = self.memory_F[np.random.randint(self.memory_size)]\n                CR = self.memory_CR[np.random.randint(self.memory_size)]\n\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Update memory (circular buffer)\n                    self.memory_F[self.memory_idx] = F\n                    self.memory_CR[self.memory_idx] = CR\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.755 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4354195b-72e5-4552-8e2f-c3bd58c2b5b8"], "operator": null, "metadata": {"aucs": [0.36523138306346536, 0.2778274141773479, 0.827199730375276, 0.9258521391525926, 0.8730681311569514, 0.9005228858807999, 0.8140216042875984, 0.8157080462526122, 0.8673277535629768, 0.8117198185786509, 0.9090242810623063, 0.9966063628478298, 0.4579666618831568, 0.8398099247494963, 0.9158747476769051, 0.9053755274287003, 0.7921235240732434, 0.9219134514421293, 0.3444806068037698, 0.5288769699842191]}}
{"id": "3ab2f3fe-2ab6-4092-9e38-ae6d0f1c6645", "fitness": 0.7549856125187763, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with reduced parameter tuning and an adaptive perturbation strategy based on fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, perturb_freq=0.05, perturb_amount=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.perturb_freq = perturb_freq\n        self.perturb_amount = perturb_amount\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        improvement_count = 0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Perturbation - Adaptive exploration boost\n                if np.random.rand() < self.perturb_freq:\n                    trial_vector += np.random.normal(0, self.perturb_amount, self.dim)\n                    trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                        improvement_count += 1  # Track improvements\n                else:\n                    improvement_count = max(0, improvement_count - 1) # Decay improvement count\n\n                # Adapt perturbation frequency\n                if improvement_count > self.pop_size / 2:  # Increased improvement, reduce perturbation\n                    self.perturb_freq = max(0.01, self.perturb_freq * 0.95) # Reduce the frequence\n                    self.perturb_amount = max(0.01, self.perturb_amount * 0.95) # Reduce perturbation amount\n                elif improvement_count < self.pop_size / 4: # Stagnation, increase perturbation\n                    self.perturb_freq = min(0.2, self.perturb_freq * 1.05) # Increase perturbation frequency\n                    self.perturb_amount = min(0.2, self.perturb_amount * 1.05) # Increase perturbation amount\n\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.755 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6b5d8ddf-669d-46a5-a3da-a4c9cd3fc379"], "operator": null, "metadata": {"aucs": [0.30426084804419073, 0.7594632357918049, 0.8178854032923406, 0.9133127712715015, 0.8746139499871977, 0.89268658004233, 0.7801914635729721, 0.7964828507521948, 0.8521947746464741, 0.7540808086355706, 0.8996686081309165, 0.9998327993664642, 0.30317495128788075, 0.8210990653248165, 0.9395054312328903, 0.8751050989407747, 0.755431518373157, 0.9251569095992971, 0.3013361100851776, 0.5342290719975721]}}
{"id": "585e6770-2964-444b-bf0c-b7103491a4a2", "fitness": 0.6605728423748668, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a truncated power-law distribution for F and fixed CR, focusing on exploitation with DE/current-to-best/1.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_F = []\n        self.memory_size = memory_size\n        self.CR = 0.7  # Fixed crossover rate\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation: Truncated Power Law for F\n                if self.memory_F:\n                    self.F = np.random.choice(self.memory_F)\n                else:\n                    self.F = 0.5  # Default value if memory is empty\n                \n                # Mutation: DE/current-to-best/1\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = population[indices]\n                mutant = population[i] + self.F * (best_individual - population[i]) + self.F * (x_r1 - x_r2)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Update memory\n                    self.memory_F.append(self.F)\n\n                    # Keep memory size limited\n                    if len(self.memory_F) > self.memory_size:\n                        self.memory_F.pop(0)\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                        best_individual = trial_vector\n                        best_index = i\n                elif f_trial < fitness[best_index]:\n                    best_individual = trial_vector\n                    best_index = i\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.661 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4354195b-72e5-4552-8e2f-c3bd58c2b5b8"], "operator": null, "metadata": {"aucs": [0.28809041134963287, 0.8949288578941375, 0.44853678736350044, 0.9498988440789131, 0.9309818452112469, 0.39466256710750336, 0.2976642096531875, 0.9124505901918301, 0.8435385792597525, 0.8814680953907132, 0.9374334733023315, 0.9966054594392459, 0.35419107547808215, 0.4116835259384434, 0.7014135176711316, 0.6732213046279965, 0.5392635607447942, 0.9542088001500304, 0.308907494215389, 0.4923078484294747]}}
{"id": "e69cd430-370f-4e6b-8b4e-1f90319adf35", "fitness": 0.6004924223671031, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified memory-based parameter adaptation and jitter-based mutation for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_F = []\n        self.memory_CR = []\n        self.memory_size = memory_size\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                F = np.random.choice(self.memory_F) if self.memory_F else 0.5\n                CR = np.random.choice(self.memory_CR) if self.memory_CR else 0.7\n\n                # Mutation with Jitter\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                jitter = np.random.normal(0, 0.01, self.dim)  # Add small random jitter\n                mutant = x_r1 + F * (x_r2 - x_r3) + jitter\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Update memory\n                    self.memory_F.append(F)\n                    self.memory_CR.append(CR)\n\n                    # Keep memory size limited\n                    if len(self.memory_F) > self.memory_size:\n                        self.memory_F.pop(0)\n                    if len(self.memory_CR) > self.memory_size:\n                        self.memory_CR.pop(0)\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.600 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4354195b-72e5-4552-8e2f-c3bd58c2b5b8"], "operator": null, "metadata": {"aucs": [0.26616947000203695, 0.5500029197252474, 0.5655602774857893, 0.9456761670087176, 0.5776520892314223, 0.636469635474662, 0.48378832497123603, 0.48994702688627256, 0.5728283094721984, 0.5072049962645564, 0.8996655745218607, 0.9987917817012419, 0.27887951755738105, 0.5753568821620236, 0.894401702078197, 0.6498999629781181, 0.5093705202495304, 0.7801808588747587, 0.3246047696938985, 0.5033976610029102]}}
{"id": "07bb5129-6f53-4bf3-8554-a7ecd940bfa5", "fitness": 0.7921943444099487, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified mutation, crossover, and parameter adaptation using weighted average of successful parameters and simplified memory handling.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n\n        self.memory_F = []\n        self.memory_CR = []\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation: weighted average of successful F and CR\n                if self.memory_F:\n                    self.F = np.clip(np.mean(self.memory_F), 0.1, 0.9)  # Simple mean\n                if self.memory_CR:\n                    self.CR = np.clip(np.mean(self.memory_CR), 0.1, 0.9)  # Simple mean\n                \n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    self.memory_F.append(self.F)\n                    self.memory_CR.append(self.CR)\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                \n                    # Limit memory size to prevent unbounded growth\n                    if len(self.memory_F) > 20:\n                        self.memory_F.pop(0)\n                        self.memory_CR.pop(0)\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.792 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["84dbf5c3-3db3-45f2-b7f4-67c38ad3dcd7"], "operator": null, "metadata": {"aucs": [0.2918150948405728, 0.7633696560202061, 0.860502158370736, 0.9197454802173107, 0.8847689775589183, 0.9158612947886492, 0.7959503304147167, 0.8183623659103343, 0.8761227052368007, 0.8460600638613618, 0.9061588875162245, 0.9989728385182234, 0.5817846448839337, 0.8609153968440554, 0.934950432940555, 0.8954101083924154, 0.6985363296823588, 0.9119450924681571, 0.5473185238530487, 0.535336505880396]}}
{"id": "4e2f5c5f-7790-40dd-9ec7-891373ab5cf0", "fitness": 0.7829519583819258, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified mutation and crossover, using a success-history based parameter adaptation with a reduced memory size.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.memory_size = memory_size\n        self.memory_F = []\n        self.memory_CR = []\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                if self.memory_F:\n                    self.F = np.clip(np.random.choice(self.memory_F), 0.1, 0.9)\n                if self.memory_CR:\n                    self.CR = np.clip(np.random.choice(self.memory_CR), 0.1, 0.9)\n                \n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    if len(self.memory_F) >= self.memory_size:\n                        self.memory_F.pop(0)\n                        self.memory_CR.pop(0)\n                    self.memory_F.append(self.F)\n                    self.memory_CR.append(self.CR)\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.783 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["84dbf5c3-3db3-45f2-b7f4-67c38ad3dcd7"], "operator": null, "metadata": {"aucs": [0.3863442459580637, 0.7735731943743602, 0.8094264157668499, 0.9360895588089602, 0.8830047329806737, 0.9079418553688628, 0.8071216745740317, 0.8244206045528395, 0.8689371397978669, 0.8529130679032684, 0.9194192306656092, 0.9966514068698207, 0.465415064734475, 0.860207905196805, 0.9441068010652615, 0.9056980638148104, 0.7736929503866934, 0.9222922508078626, 0.2886401322849531, 0.5331428717264453]}}
{"id": "b04d012b-a52b-4452-93be-b0d628d4338c", "fitness": -Infinity, "name": "AdaptiveDE", "description": "Enhanced Adaptive Differential Evolution with simplified parameter adaptation based on the population's fitness landscape and adaptive local search probability.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_init=0.5, CR_init=0.7, local_search_init_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.CR = CR_init\n        self.local_search_prob = local_search_init_prob\n        self.archive = []\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Sort population by fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            # Adapt local search probability based on fitness variance\n            fitness_std = np.std(fitness)\n            self.local_search_prob = self.local_search_init_prob * (1 + fitness_std)\n            self.local_search_prob = np.clip(self.local_search_prob, 0.05, 0.5) # Keep it within reasonable bounds\n\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1 or Local Search\n                if np.random.rand() < self.local_search_prob:\n                    # Local Search: Add small random perturbation\n                    mutant = population[i] + np.random.normal(0, 0.05, size=self.dim) # Reduced perturbation\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                else:\n                    # DE/rand/1 mutation\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[indices]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Archive successful solutions\n                    self.archive.append(population[i].copy())\n                    if len(self.archive) > 10:\n                        self.archive.pop(0) # Limit archive size\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occurred: 'AdaptiveDE' object has no attribute 'local_search_init_prob'.", "error": "", "parent_ids": ["61ec90cf-dfb8-4f26-b270-56e2f07f639d"], "operator": null, "metadata": {}}
{"id": "f9065faa-0e2d-4a2a-8311-89f85a59427e", "fitness": 0.31581372081911263, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adjusting parameters F and CR based on successful iterations, using a ring topology for mutation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7  # Initial crossover rate\n        self.success_F = []\n        self.success_CR = []\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation using ring topology\n                neighbor_left = (i - 1) % self.pop_size\n                neighbor_right = (i + 1) % self.pop_size\n                mutant = population[i] + self.F * (population[neighbor_left] - population[neighbor_right])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                # Adjust F and CR (simplified adaptation)\n                if self.success_F:\n                    self.F = np.mean(self.success_F)\n                if self.success_CR:\n                    self.CR = np.mean(self.success_CR)\n                self.success_F = []  # Reset success memory\n                self.success_CR = []\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.316 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["84dbf5c3-3db3-45f2-b7f4-67c38ad3dcd7"], "operator": null, "metadata": {"aucs": [0.11766857458176383, 0.18597877650052674, 0.29975404542662065, 0.24045662373842502, 0.23235010723479455, 0.23394688882919723, 0.2562788356204231, 0.27310915763436605, 0.2027867345469484, 0.16174751965027334, 0.3031279479506348, 0.998300094183958, 0.28394906052160573, 0.2417096849828101, 0.7777358716394382, 0.2805856241500766, 0.27882359659924905, 0.32988243531675154, 0.1457551024266036, 0.4723277348477857]}}
{"id": "dcead69c-01b4-4e0e-9081-03a407585ba7", "fitness": -Infinity, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified mutation and crossover, using a population-weighted parameter adaptation and jittering to enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.memory_size = memory_size\n\n        self.memory_F = []\n        self.memory_CR = []\n        self.fitness_history = []\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        self.fitness_history = list(fitness) # Initialize fitness history\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation: population-weighted average of successful F and CR\n                if self.memory_F:\n                    weights = np.array([self.fitness_history[j] - fitness[j] if fitness[j] < self.fitness_history[j] else 0.0000001 for j in range(self.pop_size)]) # create a weights vector based on difference in fitness\n                    weights = weights / np.sum(weights)\n\n                    self.F = np.clip(np.average(self.memory_F, weights=weights), 0.1, 0.9)  # Weighted mean\n                if self.memory_CR:\n                    weights = np.array([self.fitness_history[j] - fitness[j] if fitness[j] < self.fitness_history[j] else 0.0000001 for j in range(self.pop_size)]) # create a weights vector based on difference in fitness\n                    weights = weights / np.sum(weights)\n                    self.CR = np.clip(np.average(self.memory_CR, weights=weights), 0.1, 0.9)  # Weighted mean\n                \n                # Mutation: DE/rand/1 with jitter\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant + np.random.normal(0, 0.05, self.dim), func.bounds.lb, func.bounds.ub) # Adding Jitter\n                \n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    self.memory_F.append(self.F)\n                    self.memory_CR.append(self.CR)\n                    population[i] = trial_vector\n                    \n                    # Update fitness history after population update\n                    self.fitness_history[i] = f_trial\n                    \n                    fitness[i] = f_trial\n                    \n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                else:\n                    # If trial is worse, keep the old fitness in history\n                    pass\n\n                # Limit memory size to prevent unbounded growth\n                if len(self.memory_F) > self.memory_size:\n                    self.memory_F.pop(0)\n                    self.memory_CR.pop(0)\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occurred: Axis must be specified when shapes of a and weights differ..", "error": "", "parent_ids": ["07bb5129-6f53-4bf3-8554-a7ecd940bfa5"], "operator": null, "metadata": {}}
{"id": "929bceac-fd48-40ff-9322-3e29e1138dee", "fitness": 0.30450023936634907, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive mutation factor and dynamic population size reduction based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, CR=0.7, stagnation_threshold=0.01, reduction_factor=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.CR = CR\n        self.stagnation_threshold = stagnation_threshold\n        self.reduction_factor = reduction_factor\n\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        stagnation_count = 0\n        last_improvement = self.f_opt\n\n        while self.budget > 0 and self.pop_size > 2: # Ensure population size is at least 2\n            for i in range(self.pop_size):\n                # Adaptive Mutation Factor\n                F = np.random.normal(0.5, 0.3) # Self-adaptive F\n                F = np.clip(F, 0.1, 1.0)       # Clip to a reasonable range\n\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                        stagnation_count = 0 # Reset stagnation count\n                        last_improvement = self.f_opt\n                else:\n                    stagnation_count += 1 # Increment stagnation count\n\n            # Check for stagnation and reduce population size\n            if abs(last_improvement - self.f_opt) < self.stagnation_threshold:\n                stagnation_count += 1\n            else:\n                stagnation_count = 0\n\n            if stagnation_count > self.pop_size:\n                self.pop_size = int(self.pop_size * self.reduction_factor)\n                self.pop_size = max(2, self.pop_size)  # Ensure minimum population size\n                population = population[:self.pop_size]  # Truncate population\n                fitness = fitness[:self.pop_size]\n                stagnation_count = 0 #reset the stagnation counter\n                # Re-evaluate best solution in the reduced population to ensure accuracy\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n                last_improvement = self.f_opt\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.305 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3ab2f3fe-2ab6-4092-9e38-ae6d0f1c6645"], "operator": null, "metadata": {"aucs": [0.11626381284628384, 0.18705161185815355, 0.27907134495736896, 0.20587187584776667, 0.2569601841210237, 0.23494551548610731, 0.24793566281862944, 0.26566505066769064, 0.23079040917759752, 0.14693327167632764, 0.2248928339258005, 0.9903698464101285, 0.30644507467510895, 0.2650351586264448, 0.630962485668052, 0.3096361804794109, 0.233309546264045, 0.35776348771252997, 0.1392688736015132, 0.4608325605069983]}}
{"id": "573599ed-fbd2-4e06-9797-1bfcef930fa2", "fitness": 0.7350315413364299, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and a focus on population diversity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                \n                # Adaptive F: Reduce F over time\n                F = self.F * (1 - generation / (self.budget // self.pop_size + 1)) \n                \n                mutant = x_r1 + F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.735 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4e2f5c5f-7790-40dd-9ec7-891373ab5cf0"], "operator": null, "metadata": {"aucs": [0.2797435334801337, 0.796454666663301, 0.6968415379684771, 0.9318097835937982, 0.875937393934063, 0.9012272779359268, 0.8423360807927328, 0.47898550343179813, 0.8624837218836192, 0.8097865449662627, 0.9083569529861553, 0.9950821621927032, 0.3261406782922712, 0.871654057478195, 0.8083916182860849, 0.9169224884842195, 0.6132643660419539, 0.9144276765871406, 0.3388077280687325, 0.5319770536610297]}}
{"id": "dc54a8a3-eb36-40bf-961b-9725a754d36f", "fitness": 0.5054800018789721, "name": "AdaptiveDE", "description": "Simplified Adaptive DE with dynamic local search probability based on the success rate of the population, and simplified mutation strategy.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, local_search_prob_init=0.1, local_search_decay=0.95, success_rate_threshold=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_prob = local_search_prob_init\n        self.local_search_decay = local_search_decay\n        self.success_rate_threshold = success_rate_threshold\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.success_count = 0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            self.success_count = 0  # Reset success count for each generation\n            for i in range(self.pop_size):\n                # Mutation: DE/current-to-rand/1 + Local Search\n                if np.random.rand() < self.local_search_prob:\n                    # Local Search: Add small random perturbation\n                    mutant = population[i] + np.random.normal(0, 0.05, size=self.dim) # reduced perturbation\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                else:\n                    # DE/current-to-rand/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = population[indices]\n                    mutant = population[i] + self.F * (x_r1 - x_r2)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n                    self.success_count += 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n\n            # Adjust local search probability based on success rate\n            success_rate = self.success_count / self.pop_size\n            if success_rate > self.success_rate_threshold:\n                self.local_search_prob = min(1.0, self.local_search_prob / self.local_search_decay) # Increase local search upon finding new optimum\n            else:\n                self.local_search_prob *= self.local_search_decay   # Reduce local search when not improving\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.505 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f0228362-9877-4880-9a23-d5707bb824b7"], "operator": null, "metadata": {"aucs": [0.15761991675553277, 0.3415387548167904, 0.5590083819775549, 0.7614895581267408, 0.4786388466899485, 0.6626618378644644, 0.3542178606725621, 0.46531308085170053, 0.525492350796978, 0.23702654712811022, 0.7812840453529633, 0.9874843341930533, 0.42968983649962766, 0.35723333601751606, 0.7646618875200322, 0.4603715859248445, 0.3893500386762837, 0.7033422297863721, 0.20272625290478985, 0.490449355023577]}}
{"id": "c01fc192-7977-43fd-b488-1b10b6ae830c", "fitness": 0.7822316222915633, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified mutation and crossover, employing a learning rate for parameter adaptation based on recent success.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.learning_rate = learning_rate\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        success_F = []\n        success_CR = []\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    success_F.append(self.F)\n                    success_CR.append(self.CR)\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n            \n            # Parameter adaptation based on success\n            if success_F:\n                self.F = (1 - self.learning_rate) * self.F + self.learning_rate * np.mean(success_F)\n                self.CR = (1 - self.learning_rate) * self.CR + self.learning_rate * np.mean(success_CR)\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n                success_F = []\n                success_CR = []\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.782 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4e2f5c5f-7790-40dd-9ec7-891373ab5cf0"], "operator": null, "metadata": {"aucs": [0.36222474479286804, 0.7740953790386603, 0.8530533235789841, 0.9374870925160407, 0.8687714703269449, 0.900218025482002, 0.836367003211931, 0.8421561894456279, 0.860486762918417, 0.8618003352725617, 0.9195786127771511, 0.9960361962359919, 0.3641327549802088, 0.8463837093432124, 0.9344924220636555, 0.9067804634533998, 0.7759127977214686, 0.9228345790499285, 0.3473157879951666, 0.5345047956270458]}}
{"id": "ce6ac31e-0011-42e6-8baf-9257ade2adf5", "fitness": 0.48135948863899747, "name": "AdaptiveDE", "description": "Simplified Adaptive DE with dynamic F and CR adjustments based on population diversity and success.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_init=0.5, CR_init=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.CR = CR_init\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                \n            # Adaptive F and CR: Dynamically adjust based on population diversity\n            pop_std = np.std(population)\n            if pop_std > 0.1:  # High diversity: encourage exploration\n                self.F = min(1.0, self.F + 0.05)\n                self.CR = max(0.3, self.CR - 0.05)\n            else:  # Low diversity: encourage exploitation\n                self.F = max(0.1, self.F - 0.05)\n                self.CR = min(0.9, self.CR + 0.05)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.481 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3ab2f3fe-2ab6-4092-9e38-ae6d0f1c6645"], "operator": null, "metadata": {"aucs": [0.16599441546245675, 0.24347324920630753, 0.5227052489179566, 0.6722534140472077, 0.4722354431241189, 0.7024987750145989, 0.3434050000570916, 0.45640266262281104, 0.529186083492817, 0.1951561553199055, 0.4223181030868428, 0.9981750921424141, 0.24566929979473284, 0.3395978900990022, 0.7835097536292285, 0.7652748823188282, 0.35320746975736406, 0.7312413783019194, 0.1881641387026387, 0.4967213176817077]}}
{"id": "44a3038b-b3e3-4242-a766-14942feed9fc", "fitness": 0.7102256338159582, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified mutation and crossover, focusing on aggressive parameter adaptation via fitness comparisons and reduced memory size.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, memory_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.memory_size = memory_size\n        self.memory_F = []\n        self.memory_CR = []\n        self.success_ratio = 0.0  # Track success ratio\n\n    def __call__(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        success_count = 0\n        generation = 0  # Track generations\n        while self.budget > 0:\n            generation += 1\n            success_count_gen = 0\n            for i in range(self.pop_size):\n                # Parameter adaptation: Aggressive adaptation based on success\n                if self.success_ratio > 0.2:\n                    self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 0.9)\n                    self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 0.9)\n                else:\n                    self.F = np.clip(np.random.normal(0.7, 0.3), 0.1, 0.9)\n                    self.CR = np.clip(np.random.normal(0.5, 0.1), 0.1, 0.9)\n                \n                # Mutation: DE/rand/1 - simplified\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    success_count += 1\n                    success_count_gen += 1\n\n                    if len(self.memory_F) >= self.memory_size:\n                        self.memory_F.pop(0)\n                        self.memory_CR.pop(0)\n                    self.memory_F.append(self.F)\n                    self.memory_CR.append(self.CR)\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if self.budget <= 0:\n                    break\n\n            # Update success ratio after each generation\n            self.success_ratio = success_count_gen / self.pop_size if self.pop_size > 0 else 0\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.710 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4e2f5c5f-7790-40dd-9ec7-891373ab5cf0"], "operator": null, "metadata": {"aucs": [0.2736573936041302, 0.4554024843874924, 0.7885914446403277, 0.9294301898353782, 0.869143100670054, 0.897831254739911, 0.7723511208110276, 0.7971446113927237, 0.8381906781776529, 0.6984581289008821, 0.8428919996951312, 0.996713073121594, 0.2943422449054772, 0.764224755187471, 0.5823422445037599, 0.8701668768156137, 0.6931421519035268, 0.9225121833580842, 0.41170915638295, 0.5062675832859779]}}
{"id": "bae6b373-8aee-491a-8056-5d0c09e374d1", "fitness": 0.6189148667450788, "name": "AdaptiveDE", "description": "Simplified Adaptive DE with self-adaptive parameters and a focused perturbation strategy based on successful mutations.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, perturb_freq=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.perturb_freq = perturb_freq  # Reduced perturbation to only adapt frequency\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        success_F = []\n        success_CR = []\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation (self-adaptive)\n                curr_F = np.random.normal(self.F, 0.1)\n                curr_CR = np.random.normal(self.CR, 0.1)\n                curr_F = np.clip(curr_F, 0.1, 0.9)\n                curr_CR = np.clip(curr_CR, 0.1, 0.9)\n\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + curr_F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < curr_CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Perturbation - Adaptive exploration boost, only after crossover\n                if np.random.rand() < self.perturb_freq:\n                    trial_vector += np.random.normal(0, 0.05, self.dim)  # Reduced amount of perturbation\n                    trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                    success_F.append(curr_F)\n                    success_CR.append(curr_CR)\n\n            # Update F and CR based on successful values\n            if success_F:\n                self.F = np.mean(success_F)\n                self.CR = np.mean(success_CR)\n                success_F = []\n                success_CR = []\n\n            # Adaptive perturbation frequency\n            if len(success_F) > self.pop_size / 4:  # More improvements, reduce\n                self.perturb_freq = max(0.01, self.perturb_freq * 0.95)\n            else:  # Stagnation, increase\n                self.perturb_freq = min(0.2, self.perturb_freq * 1.05)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.619 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3ab2f3fe-2ab6-4092-9e38-ae6d0f1c6645"], "operator": null, "metadata": {"aucs": [0.24367100078127024, 0.20640087293150133, 0.5680552000867618, 0.9024911171727277, 0.586999015568558, 0.8729397583771898, 0.3703434550023508, 0.4193954194266305, 0.7283865971038714, 0.8682557296815031, 0.931561919656156, 0.9985465928001672, 0.2794686664530538, 0.6706974954522914, 0.8661475580409439, 0.8833707949857401, 0.3717167881000387, 0.8493883211004128, 0.24887366567417424, 0.5115873665062314]}}
{"id": "a5c37903-8a4a-472a-ad1c-2c13c3cac323", "fitness": 0.7534326156482226, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified mutation, crossover, and parameter adaptation using a single success-weighted archive for both F and CR.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.memory = []  # Store successful F and CR values\n        self.F = 0.5\n        self.CR = 0.7\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                if self.memory:\n                    # Weighted random choice based on past successes\n                    weights = np.array([m[2] for m in self.memory])  # Use improvement as weight\n                    weights = weights / np.sum(weights)  # Normalize weights\n                    idx = np.random.choice(len(self.memory), p=weights)\n                    self.F = self.memory[idx][0]\n                    self.CR = self.memory[idx][1]\n                    self.F = np.clip(self.F, 0.1, 0.9)\n                    self.CR = np.clip(self.CR, 0.1, 0.9)\n                else:\n                    self.F = 0.5\n                    self.CR = 0.7\n\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    improvement = fitness[i] - f_trial\n                    if len(self.memory) >= self.memory_size:\n                        self.memory.pop(0)  # FIFO\n                    self.memory.append((self.F, self.CR, improvement))  # Store F, CR, and improvement\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.753 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4e2f5c5f-7790-40dd-9ec7-891373ab5cf0"], "operator": null, "metadata": {"aucs": [0.3104111232451675, 0.2297426488471157, 0.8445296043016943, 0.9379271379572536, 0.8659807343101806, 0.893249368905272, 0.8464628327067425, 0.8074307222010779, 0.8722332083530232, 0.8540742417008523, 0.9147996155651235, 0.9962041376513256, 0.5051449865691751, 0.8453043866284856, 0.9080930990166118, 0.8985715009604025, 0.7658320699842618, 0.9190347216022701, 0.3232497641992018, 0.530376408259216]}}
{"id": "69a9c5fe-936f-4dc2-a622-4692efb03b96", "fitness": 0.7620350932813672, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a self-adaptive mutation factor and crossover rate based on the population's success.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7  # Initial crossover rate\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        success_F = []\n        success_CR = []\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    success_F.append(self.F)\n                    success_CR.append(self.CR)\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                \n                # Adaptive F and CR update using the past successful values\n                if success_F:\n                    self.F = np.mean(success_F)\n                if success_CR:\n                    self.CR = np.mean(success_CR)\n                \n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.762 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4e2f5c5f-7790-40dd-9ec7-891373ab5cf0"], "operator": null, "metadata": {"aucs": [0.3677814868812114, 0.6878208761993407, 0.756455508894506, 0.9409234234809306, 0.8759057633145814, 0.8941436140417923, 0.8380537597052053, 0.8100874191500067, 0.8711450677032067, 0.7734334965425196, 0.9131932857963063, 0.9946733192764398, 0.354815494646586, 0.8505601629712685, 0.9452803992526969, 0.8994162486949355, 0.7823396319259046, 0.9140741588471746, 0.24014140035318254, 0.530457347949548]}}
{"id": "f1d9d888-c5e1-491e-910b-085acde9c41d", "fitness": 0.7463127862055272, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive mutation factor and crossover rate based on fitness improvement, using a population-based approach.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7  # Initial crossover rate\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Adapt parameters based on success\n                    self.F = np.random.normal(0.5, 0.1)  # Adapt F\n                    self.CR = np.random.normal(0.7, 0.1)  # Adapt CR\n\n                    self.F = np.clip(self.F, 0.1, 0.9)\n                    self.CR = np.clip(self.CR, 0.1, 0.9)\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.746 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["07bb5129-6f53-4bf3-8554-a7ecd940bfa5"], "operator": null, "metadata": {"aucs": [0.3679046086409642, 0.7334657166571137, 0.8170721117030183, 0.9261273398242431, 0.864893421701054, 0.8887384209463868, 0.8040420767781267, 0.81968517597751, 0.8609693231891523, 0.3263185450484559, 0.9140120284601015, 0.998183630918608, 0.4825981472356182, 0.8567293216386249, 0.8292093463454502, 0.8959533945578606, 0.7721421411224196, 0.9274241616822341, 0.3218881929861276, 0.5188986186974751]}}
{"id": "fc16ebc2-3a61-4d0f-b23c-1129a6f5346c", "fitness": 0.7667225931762657, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified mutation and crossover, using success-history based parameter adaptation with exponential moving averages and orthogonal crossover to improve population diversity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.memory_size = memory_size\n        self.memory_F = []\n        self.memory_CR = []\n        self.ema_alpha = 0.2  # EMA smoothing factor\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation: Exponential Moving Average of successful F and CR\n                if self.memory_F:\n                    self.F = np.clip((1 - self.ema_alpha) * self.F + self.ema_alpha * np.mean(self.memory_F), 0.1, 0.9)\n                if self.memory_CR:\n                    self.CR = np.clip((1 - self.ema_alpha) * self.CR + self.ema_alpha * np.mean(self.memory_CR), 0.1, 0.9)\n                \n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Crossover\n                j_rand = np.random.randint(self.dim)\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                crossover_mask[j_rand] = True  # Ensure at least one element is crossed over\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    self.memory_F.append(self.F)\n                    self.memory_CR.append(self.CR)\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                \n                    # Limit memory size\n                    if len(self.memory_F) > self.memory_size:\n                        self.memory_F.pop(0)\n                        self.memory_CR.pop(0)\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.767 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["07bb5129-6f53-4bf3-8554-a7ecd940bfa5"], "operator": null, "metadata": {"aucs": [0.3856440692990891, 0.7285807973080007, 0.8256986073905526, 0.9426599573573665, 0.8845020146407072, 0.8978153873896666, 0.8088268886961596, 0.8480682662878196, 0.8724076159578573, 0.402375846696291, 0.9207934514788827, 0.9997516593981176, 0.365558324124431, 0.8304401762714095, 0.958678934750842, 0.909572187450474, 0.8177128985408464, 0.9244671319682722, 0.35168256393732245, 0.6592150845812048]}}
{"id": "ddb7df96-bbf7-4160-a929-e9ff0336dc4b", "fitness": 0.7678851349828959, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified mutation, crossover, and parameter adaptation based on success, using a fixed mutation scaling factor and a reduced update frequency for enhanced stability.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Fixed mutation factor\n        self.CR = CR  # Initial crossover rate\n        self.update_freq = 10 # Update frequency for CR\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        success_CR = []\n        generation = 0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    success_CR.append(self.CR)\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n            \n            generation += 1\n            if generation % self.update_freq == 0:\n                if success_CR:\n                    self.CR = np.mean(success_CR)\n                    success_CR = []  # Reset success_CR list\n\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.768 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["69a9c5fe-936f-4dc2-a622-4692efb03b96"], "operator": null, "metadata": {"aucs": [0.3916562011958835, 0.6509615576737384, 0.8189109677302868, 0.9162283159349919, 0.8721728255974062, 0.9022988274397918, 0.8341754339148484, 0.8189841085126832, 0.8674235695042605, 0.8529375147781371, 0.9018843540150463, 0.9940362114911729, 0.30597962355456554, 0.8515542317238464, 0.8017672756328914, 0.8938664742765661, 0.8232601358422174, 0.921050746693295, 0.26985095312485663, 0.6687033710214332]}}
{"id": "ec429833-a3ee-42b3-bdb5-6a86702c9575", "fitness": 0.7777778710096029, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with success-history based parameter adaptation using a circular buffer and simplified update rules.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.memory_F = np.ones(memory_size) * 0.5\n        self.memory_CR = np.ones(memory_size) * 0.7\n        self.memory_idx = 0\n        self.F = 0.5\n        self.CR = 0.7\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                self.F = self.memory_F[self.memory_idx]\n                self.CR = self.memory_CR[self.memory_idx]\n\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    improvement = fitness[i] - f_trial\n\n                    self.memory_F[self.memory_idx] = self.F\n                    self.memory_CR[self.memory_idx] = self.CR\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.778 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a5c37903-8a4a-472a-ad1c-2c13c3cac323"], "operator": null, "metadata": {"aucs": [0.38553566936222883, 0.7955811427350075, 0.8391600120095573, 0.9397946380797559, 0.8740341762194751, 0.8957907635279344, 0.8172171406012767, 0.8314804494065647, 0.8681919808088254, 0.8454615803711656, 0.9172526900919915, 0.9961168407287387, 0.34270575451179197, 0.8479618795807831, 0.9270222511575134, 0.8959652661338237, 0.7602019435699329, 0.9219681427397077, 0.33809249564363963, 0.5160226029123449]}}
{"id": "d9d70362-e125-4aeb-b2ee-7be54ade1709", "fitness": 0.6779356843763822, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified mutation and crossover, using a success-rate based adaptation of F and CR, and reducing population diversity using best-guided mutation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.learning_rate = learning_rate\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        success_F = []\n        success_CR = []\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/current-to-best/1\n                best_index = np.argmin(fitness)\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = population[indices]\n                mutant = population[i] + self.F * (population[best_index] - population[i]) + self.F * (x_r1 - x_r2)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    success_F.append(self.F)\n                    success_CR.append(self.CR)\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n            \n            # Parameter adaptation based on success\n            if success_F:\n                mean_F = np.mean(success_F)\n                mean_CR = np.mean(success_CR)\n                self.F = (1 - self.learning_rate) * self.F + self.learning_rate * mean_F\n                self.CR = (1 - self.learning_rate) * self.CR + self.learning_rate * mean_CR\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n            success_F = []\n            success_CR = []\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.678 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c01fc192-7977-43fd-b488-1b10b6ae830c"], "operator": null, "metadata": {"aucs": [0.510189767883863, 0.8909047468941655, 0.6486932423981336, 0.954958843869526, 0.9354781511351, 0.9003010502694544, 0.34796434707964374, 0.3499378070905852, 0.9278700801134572, 0.2807273277114555, 0.9484832941494178, 0.9972853128493342, 0.3223802140505978, 0.8620875166957402, 0.8887587573551023, 0.30972194861968194, 0.7673894708717178, 0.9556197790340687, 0.25460382582583396, 0.5053582036307673]}}
{"id": "a083fc50-63fc-4d9d-bacb-090c601bf9f5", "fitness": 0.6803728611210673, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters and a more focused selection mechanism.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR  # Initial crossover rate\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                \n                # Adaptive F and CR update using a simple average of past F and CR values\n                self.F = 0.9 * self.F + 0.1 * np.random.rand()\n                self.CR = 0.9 * self.CR + 0.1 * np.random.rand()\n\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.680 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["69a9c5fe-936f-4dc2-a622-4692efb03b96"], "operator": null, "metadata": {"aucs": [0.24480405154308948, 0.39723712279640544, 0.773153159344723, 0.9028373339606746, 0.8452449989268596, 0.8733476619663213, 0.3412599795083763, 0.7794161124804004, 0.839531103340974, 0.7634129020982201, 0.8548046178368439, 0.9993465532770414, 0.2521978928393128, 0.7735880411694709, 0.7406245651425932, 0.8806265588528356, 0.6965635983753575, 0.901041680070327, 0.23481929108837762, 0.5135999978031426]}}
{"id": "a8c38af3-d4f7-43db-bc02-65f194c001b2", "fitness": 0.7449443475235986, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified mutation and crossover, using success-history based parameter adaptation with exponential moving averages and orthogonal crossover to improve population diversity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5, p=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.p = p # probability for choosing best solution\n        self.memory_F = np.ones(self.memory_size) * 0.5\n        self.memory_CR = np.ones(self.memory_size) * 0.7\n        self.memory_idx = 0\n        self.success_ratio = 0.0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                F = np.random.choice(self.memory_F)\n                CR = np.random.choice(self.memory_CR)\n\n                # Mutation: DE/rand/1 or DE/current-to-best/1\n                if np.random.rand() < self.p:\n                   best_idx = np.argmin(fitness)\n                   indices = np.random.choice(self.pop_size, 2, replace=False)\n                   x_r1, x_r2 = population[indices]\n                   mutant = population[i] + F * (population[best_idx] - population[i]) + F * (x_r1 - x_r2)\n                else:\n                   indices = np.random.choice(self.pop_size, 3, replace=False)\n                   x_r1, x_r2, x_r3 = population[indices]\n                   mutant = x_r1 + F * (x_r2 - x_r3)\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    delta = fitness[i] - f_trial\n                    self.success_ratio = 0.9 * self.success_ratio + 0.1\n                    self.memory_F[self.memory_idx] = F\n                    self.memory_CR[self.memory_idx] = CR\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                else:\n                    self.success_ratio = 0.9 * self.success_ratio\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.745 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a5c37903-8a4a-472a-ad1c-2c13c3cac323"], "operator": null, "metadata": {"aucs": [0.33032366234539146, 0.7306062967470264, 0.8523502097188691, 0.9277584197726021, 0.8866017196457281, 0.9155893811995812, 0.8320863276943431, 0.853264159201572, 0.8724674078984249, 0.20037458407203834, 0.9300344430061542, 0.9982182357520506, 0.2990361068608349, 0.8591300625287804, 0.954288820672247, 0.9076536414279112, 0.7965613194984708, 0.9307621326192996, 0.28653675282981306, 0.5352432669808329]}}
{"id": "da28d0f4-79b0-4326-b9e8-8ef807f85232", "fitness": 0.7517370181385676, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters and a limited-memory archive for parameter adaptation to reduce computational overhead.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5\n        self.CR = 0.7\n        self.success_F = []\n        self.success_CR = []\n\n    def __call__(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                mutant = population[idxs[0]] + self.F * (population[idxs[1]] - population[idxs[2]])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                # Update F and CR from archive (limited memory)\n                if len(self.success_F) > self.archive_size:\n                    self.success_F = self.success_F[-self.archive_size:]\n                if len(self.success_CR) > self.archive_size:\n                    self.success_CR = self.success_CR[-self.archive_size:]\n\n                if self.success_F:\n                    self.F = np.mean(self.success_F)\n                if self.success_CR:\n                    self.CR = np.mean(self.success_CR)\n\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n                if self.budget <= 0:\n                    break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.752 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["69a9c5fe-936f-4dc2-a622-4692efb03b96"], "operator": null, "metadata": {"aucs": [0.38630080362665076, 0.3363908208074988, 0.8401526293773188, 0.9004487618010494, 0.8533560274421482, 0.9121272066635687, 0.7957660658073702, 0.8165288780337783, 0.8740427226156102, 0.8635144918567369, 0.9091620692669439, 0.9968075013689984, 0.3713909487838618, 0.8625097649620637, 0.9490608013036754, 0.8946063500635901, 0.7825793756839745, 0.9198914972900257, 0.23110441462030507, 0.5389992313961838]}}
{"id": "704940cb-94e9-467a-9cb6-583f11fcb4f3", "fitness": 0.7754602153529622, "name": "AdaptiveDE", "description": "Simplified Adaptive DE with a focused memory update strategy that only stores the best-performing (F, CR) pairs and averages them for parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.memory = []  # Store successful F and CR values (F, CR, improvement)\n        self.F = 0.5\n        self.CR = 0.7\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation: Simple average of top memory entries\n                if self.memory:\n                    top_memory = sorted(self.memory, key=lambda x: x[2], reverse=True)[:min(len(self.memory), self.memory_size)]\n                    self.F = np.mean([m[0] for m in top_memory])\n                    self.CR = np.mean([m[1] for m in top_memory])\n                    self.F = np.clip(self.F, 0.1, 0.9)\n                    self.CR = np.clip(self.CR, 0.1, 0.9)\n                else:\n                    self.F = 0.5\n                    self.CR = 0.7\n\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    improvement = fitness[i] - f_trial\n                    # Replace least performing entry in memory if better\n                    if len(self.memory) < self.memory_size:\n                        self.memory.append((self.F, self.CR, improvement))\n                    else:\n                        min_improvement = min([m[2] for m in self.memory])\n                        if improvement > min_improvement:\n                            self.memory = [m for m in self.memory if m[2] > min_improvement]\n                            self.memory.append((self.F, self.CR, improvement))\n                    \n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.775 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a5c37903-8a4a-472a-ad1c-2c13c3cac323"], "operator": null, "metadata": {"aucs": [0.27898214777457775, 0.7258013336115943, 0.8234281430527637, 0.935648855360231, 0.8559236337700655, 0.8901521885437329, 0.8067003815218872, 0.8267749048709389, 0.8738973712395566, 0.8167101913018633, 0.9012703177504425, 0.9967587634042622, 0.4915085472917662, 0.8348060328762353, 0.9520476833542487, 0.9096112299534062, 0.7827682287022518, 0.92161330995412, 0.35898309964656705, 0.525817943078733]}}
{"id": "f06dea8a-eff1-403a-a23b-572b7f00ad5f", "fitness": 0.7898775284021566, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution using a success-weighted archive for parameter adaptation and a more aggressive mutation strategy to enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.memory = []  # Store successful F and CR values\n        self.F = 0.5\n        self.CR = 0.7\n        self.p = 0.1  # Probability for selecting best individual in mutation\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                if self.memory:\n                    # Weighted random choice based on past successes\n                    weights = np.array([m[2] for m in self.memory])  # Use improvement as weight\n                    weights = weights / np.sum(weights)  # Normalize weights\n                    idx = np.random.choice(len(self.memory), p=weights)\n                    self.F = self.memory[idx][0]\n                    self.CR = self.memory[idx][1]\n                    self.F = np.clip(self.F, 0.1, 0.9)\n                    self.CR = np.clip(self.CR, 0.1, 0.9)\n                else:\n                    self.F = 0.5\n                    self.CR = 0.7\n\n                # Mutation: DE/rand/1 or DE/current-to-best/1 with probability p\n                if np.random.rand() < self.p:\n                    # DE/current-to-best/1\n                    best_idx = np.argmin(fitness)\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = population[indices]\n                    mutant = population[i] + self.F * (population[best_idx] - population[i]) + self.F * (x_r1 - x_r2)\n                else:\n                    # DE/rand/1\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[indices]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    improvement = fitness[i] - f_trial\n                    if len(self.memory) >= self.memory_size:\n                        self.memory.pop(0)  # FIFO\n                    self.memory.append((self.F, self.CR, improvement))  # Store F, CR, and improvement\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.790 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a5c37903-8a4a-472a-ad1c-2c13c3cac323"], "operator": null, "metadata": {"aucs": [0.40729425406188025, 0.82829621209691, 0.8575043516010192, 0.933193938752829, 0.8869864492903583, 0.9061024727742519, 0.8336904117450444, 0.8328908471671401, 0.8919170627578885, 0.8141565045572041, 0.9201900861642319, 0.9962923095283489, 0.4045533763955206, 0.8640649514941628, 0.9321210945940286, 0.907392902707002, 0.843174136837176, 0.9216503012884704, 0.31008757224381855, 0.5059913319858491]}}
{"id": "9c5d922b-0b7c-4857-ab46-1527afc2497e", "fitness": 0.7467113531574058, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with success-rate based parameter adaptation and a memory to retain successful F and CR values.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7  # Initial crossover rate\n        self.F_memory = np.full(memory_size, self.F)\n        self.CR_memory = np.full(memory_size, self.CR)\n        self.memory_index = 0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Update memory with successful F and CR values\n                    self.F_memory[self.memory_index] = self.F\n                    self.CR_memory[self.memory_index] = self.CR\n                    self.memory_index = (self.memory_index + 1) % self.memory_size\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                # Adaptive F and CR update using the memory\n                self.F = np.median(self.F_memory)\n                self.CR = np.median(self.CR_memory)\n                \n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.747 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["69a9c5fe-936f-4dc2-a622-4692efb03b96"], "operator": null, "metadata": {"aucs": [0.35108432300418957, 0.7208682843775653, 0.8216325983523344, 0.9298288602338872, 0.8680996899248066, 0.8865637265688899, 0.839083781241958, 0.8254577457746688, 0.8698197526458282, 0.8468885647577488, 0.8991705178976441, 0.9963891017289332, 0.3393621641039264, 0.798029184652287, 0.9333213212408407, 0.9069846884730381, 0.40420043820469054, 0.9273022370949549, 0.25627231417805296, 0.5138677686918719]}}
{"id": "c157ad44-3ad1-40c5-9b66-cba325d05a8f", "fitness": 0.42303185484632494, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on success history, using a Cauchy distribution for mutation factor sampling.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR  # Initial crossover rate\n        self.memory_F = []\n        self.memory_CR = []\n        self.memory_size = 10  # Size of the memory for F and CR\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive F and CR update\n                if self.memory_F:\n                    self.F = self.sample_from_cauchy(np.median(self.memory_F), 0.1) #Sample F from Cauchy\n                if self.memory_CR:\n                    self.CR = np.random.uniform(0, np.mean(self.memory_CR)) #Sample CR from Uniform\n\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    self.memory_F.append(self.F)\n                    self.memory_CR.append(self.CR)\n                    if len(self.memory_F) > self.memory_size:\n                        self.memory_F.pop(0)\n                        self.memory_CR.pop(0)\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n\n    def sample_from_cauchy(self, loc, scale):\n        sampled_value = np.random.standard_cauchy() * scale + loc\n        return sampled_value", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.423 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["69a9c5fe-936f-4dc2-a622-4692efb03b96"], "operator": null, "metadata": {"aucs": [0.1569921546612415, 0.1913501938867853, 0.39157695617112953, 0.34810228756344663, 0.38803403002969583, 0.4944465644984465, 0.3349568331738414, 0.45020490662737256, 0.38641164455649746, 0.1878125641577192, 0.33762471164771546, 0.976498744392582, 0.23079104705839038, 0.39774784247407613, 0.7711491940918834, 0.6855616939668282, 0.40698770618617186, 0.6394508071031451, 0.19359215615308578, 0.4913450585264446]}}
{"id": "876f1b56-ac00-445a-adae-b4bdb7772dee", "fitness": 0.771908962815313, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with cumulative updates for F and CR and enhanced exploration using a mirrored population.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7  # Initial crossover rate\n        self.F_mem = [0.5] * 5  # Memory for F\n        self.CR_mem = [0.7] * 5  # Memory for CR\n        self.mem_idx = 0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Create a mirrored population for enhanced exploration\n        mirrored_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        mirrored_fitness = np.array([func(x) for x in mirrored_population])\n        self.budget -= self.pop_size\n\n        # Combine populations\n        combined_population = np.vstack((population, mirrored_population))\n        combined_fitness = np.concatenate((fitness, mirrored_fitness))\n\n        self.f_opt = np.min(combined_fitness)\n        self.x_opt = combined_population[np.argmin(combined_fitness)]\n        \n        success_F = []\n        success_CR = []\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    success_F.append(self.F)\n                    success_CR.append(self.CR)\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                \n            # Adaptive F and CR update using the past successful values and memory\n            if success_F:\n                self.F_mem[self.mem_idx] = np.mean(success_F)\n                self.F = np.mean(self.F_mem)\n            if success_CR:\n                self.CR_mem[self.mem_idx] = np.mean(success_CR)\n                self.CR = np.mean(self.CR_mem)\n\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.CR = np.clip(self.CR, 0.1, 0.9)\n            self.mem_idx = (self.mem_idx + 1) % 5  # Update memory index\n\n            success_F = []\n            success_CR = []\n\n            if self.budget <= 0:\n                break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.772 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["69a9c5fe-936f-4dc2-a622-4692efb03b96"], "operator": null, "metadata": {"aucs": [0.37914535389343096, 0.7112457345398906, 0.8326624530642958, 0.9409666321299879, 0.8670736526663932, 0.8942808136154532, 0.7912945796018044, 0.8013986097793758, 0.8476866883207679, 0.8009331141345074, 0.9153765687521196, 0.99670625850636, 0.5727976889025139, 0.8428920004383633, 0.8317594355261146, 0.9087772567875658, 0.7641811178411964, 0.9184162304645821, 0.2850705442494762, 0.535514523092062]}}
{"id": "bdb1a29e-ed3a-4047-a696-79c4cd17659e", "fitness": 0.7927044986007894, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using moving averages and a reduced population size for faster convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15):  # Reduced population size\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7  # Initial crossover rate\n        self.F_ema = 0.5 # Exponential Moving Average for F\n        self.CR_ema = 0.7 # Exponential Moving Average for CR\n        self.alpha = 0.2  # Learning rate for EMA\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Adaptive F and CR update using Exponential Moving Average\n                    self.F_ema = self.alpha * self.F + (1 - self.alpha) * self.F_ema\n                    self.CR_ema = self.alpha * self.CR + (1 - self.alpha) * self.CR_ema\n                    \n                    self.F = self.F_ema # Set current F to EMA\n                    self.CR = self.CR_ema # Set current CR to EMA\n                    \n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                \n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.793 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["69a9c5fe-936f-4dc2-a622-4692efb03b96"], "operator": null, "metadata": {"aucs": [0.4794514641379093, 0.796614105913781, 0.8883046816139485, 0.9592868796496764, 0.9123349836161687, 0.9226923916072485, 0.8511732214313901, 0.8734953626123934, 0.8879377244497451, 0.8854716027002802, 0.9258678028309857, 0.9925067422075576, 0.27453599987314803, 0.873271381858197, 0.750203925258516, 0.9276887252798682, 0.4509528342031631, 0.9331502668242181, 0.7378356284997887, 0.5313142474478052]}}
{"id": "094fd6ab-ccec-4959-9d19-8c92df221b30", "fitness": -Infinity, "name": "AdaptiveDE", "description": "Simplified Adaptive DE with per-dimension CR and a global F, plus jitter.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_F = np.ones(memory_size) * 0.5\n        self.memory_CR = np.ones(memory_size) * 0.7\n        self.memory_idx = 0\n        self.F = 0.5\n        self.CR = 0.7\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                self.F = self.memory_F[self.memory_idx]\n                self.CR = self.memory_CR[self.memory_idx]\n\n                # Mutation: DE/rand/1 with jitter\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + (self.F + 0.05*np.random.randn()) * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover: Per-dimension CR\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                    self.memory_F[self.memory_idx] = self.F\n                    self.memory_CR[self.memory_idx] = self.CR\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occurred: 'AdaptiveDE' object has no attribute 'memory_size'.", "error": "", "parent_ids": ["ec429833-a3ee-42b3-bdb5-6a86702c9575"], "operator": null, "metadata": {}}
{"id": "7215feee-4f02-4e31-83c2-ff880a11d219", "fitness": -Infinity, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with per-dimension CR adaptation and a focused approach to updating parameters based on successful mutations.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_F = np.ones(memory_size) * 0.5\n        self.memory_CR = np.ones(memory_size) * 0.7\n        self.memory_idx = 0\n        self.F = 0.5\n        self.CR = 0.7\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                F = self.memory_F[self.memory_idx]\n                CR = self.memory_CR[self.memory_idx]\n\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover - per dimension CR\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Simplified Memory Update: only update if improvement occurs\n                    self.memory_F[self.memory_idx] = F\n                    self.memory_CR[self.memory_idx] = CR\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occurred: 'AdaptiveDE' object has no attribute 'memory_size'.", "error": "", "parent_ids": ["ec429833-a3ee-42b3-bdb5-6a86702c9575"], "operator": null, "metadata": {}}
{"id": "f579f772-12ce-4c56-a219-46431f790b39", "fitness": 0.0, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and enhanced local search using a mirrored sampling technique.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5, mirror_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.memory = []\n        self.F = 0.5\n        self.CR = 0.7\n        self.mirror_rate = mirror_rate\n\n    def __call__(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation (simplified)\n                if self.memory:\n                    self.F = np.mean([m[0] for m in self.memory])\n                    self.CR = np.mean([m[1] for m in self.memory])\n                    self.F = np.clip(self.F, 0.1, 0.9)\n                    self.CR = np.clip(self.CR, 0.1, 0.9)\n\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Mirrored sampling around the trial vector for local search\n                if np.random.rand() < self.mirror_rate:\n                    mirror_vector = population[i] + (trial_vector - population[i]) * np.random.uniform(0.5, 1.5)\n                    mirror_vector = np.clip(mirror_vector, func.bounds.lb, func.bounds.ub)\n                    f_mirror = func(mirror_vector)\n                    self.budget -= 1\n                    if f_mirror < func(trial_vector):\n                        trial_vector = mirror_vector\n                    \n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    improvement = fitness[i] - f_trial\n                    if len(self.memory) >= self.memory_size:\n                        self.memory.pop(0)\n                    self.memory.append((self.F, self.CR, improvement))\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f06dea8a-eff1-403a-a23b-572b7f00ad5f"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "ad8b6341-3d54-4c3d-82a3-0f837736a959", "fitness": 0.7056391238988194, "name": "AdaptiveDE", "description": "Simplified Adaptive DE with self-adaptive F and CR, and a \"current-to-best\" mutation strategy to accelerate convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5\n        self.CR = 0.7\n\n    def __call__(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/current-to-best/1\n                best_index = np.argmin(fitness)\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = population[indices]\n                mutant = population[i] + self.F * (population[best_index] - population[i]) + self.F * (x_r1 - x_r2)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                    # Self-adaptive F and CR: Adapt only when the trial vector is better\n                    self.F = np.random.normal(0.5, 0.3)\n                    self.CR = np.random.normal(0.7, 0.1)\n                    self.F = np.clip(self.F, 0.1, 0.9)\n                    self.CR = np.clip(self.CR, 0.1, 0.9)\n\n\n                if self.budget <= 0:\n                    break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.706 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["bdb1a29e-ed3a-4047-a696-79c4cd17659e"], "operator": null, "metadata": {"aucs": [0.47045423506729145, 0.3904448182609249, 0.896502532737077, 0.9624622508908613, 0.2757655741806838, 0.9354389498666081, 0.9106695325083666, 0.8845829299900405, 0.9076999939377635, 0.21500002227555526, 0.9552026167840392, 0.9976253429906219, 0.3153111684386989, 0.8630133606184942, 0.9677196307233035, 0.9183355592402007, 0.4581124715254342, 0.9561887951220313, 0.31161554800308755, 0.5206371448153031]}}
{"id": "bc2ecaf0-898d-4919-bfec-dceb5bcd5429", "fitness": 0.7324955076837029, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified memory and parameter adaptation, focusing on population diversity and constraint handling.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.memory = []  # Store successful CR values\n        self.F = 0.5\n        self.CR = 0.7\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation: Average of successful CR values\n                if self.memory:\n                    self.CR = np.mean(self.memory)\n                    self.CR = np.clip(self.CR, 0.1, 0.9)\n                else:\n                    self.CR = 0.7\n\n                # Mutation: DE/rand/1 - Ensuring diversity\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n\n                # Repair: Simple bound handling\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Store successful CR\n                    self.memory.append(self.CR)\n                    if len(self.memory) > self.memory_size:\n                        self.memory.pop(0)  # Keep memory size constant\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.732 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["704940cb-94e9-467a-9cb6-583f11fcb4f3"], "operator": null, "metadata": {"aucs": [0.3346086542529799, 0.7027008582132834, 0.7533924798345331, 0.9102806749378286, 0.8843692659960969, 0.8951896531543869, 0.8045670412253352, 0.8100270242014902, 0.862140045647673, 0.8355546634226564, 0.9082142476069428, 0.9953610648398065, 0.406958230389145, 0.8003503227277259, 0.8322290357742496, 0.9140294518914893, 0.732943277461508, 0.45684880835561503, 0.2784787157951164, 0.5316666379461925]}}
{"id": "16db667c-847e-4eef-a3d1-6c54b1cdd138", "fitness": 0.7707255822888521, "name": "AdaptiveDE", "description": "Simplified Adaptive DE with focused memory and stochastic ranking for memory updates.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5, p_rank=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.memory = []  # Store successful F and CR values (F, CR, improvement)\n        self.F = 0.5\n        self.CR = 0.7\n        self.p_rank = p_rank # Probability for stochastic ranking\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation: Simple average of top memory entries\n                if self.memory:\n                    # Stochastic ranking to select memory entries\n                    ranked_memory = sorted(self.memory, key=lambda x: x[2], reverse=True)\n                    selected_memory = []\n                    for j in range(min(len(ranked_memory), self.memory_size)):\n                        if np.random.rand() < self.p_rank or j == 0: # Always pick best, then randomly pick others\n                            selected_memory.append(ranked_memory[j])\n\n                    if selected_memory:\n                        self.F = np.mean([m[0] for m in selected_memory])\n                        self.CR = np.mean([m[1] for m in selected_memory])\n                    else:\n                        self.F = 0.5\n                        self.CR = 0.7\n                    self.F = np.clip(self.F, 0.1, 0.9)\n                    self.CR = np.clip(self.CR, 0.1, 0.9)\n\n\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    improvement = fitness[i] - f_trial\n                    # Replace a random entry in memory if better\n                    if len(self.memory) < self.memory_size:\n                        self.memory.append((self.F, self.CR, improvement))\n                    else:\n                        index_to_replace = np.random.randint(self.memory_size)\n                        self.memory[index_to_replace] = (self.F, self.CR, improvement)\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.771 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["704940cb-94e9-467a-9cb6-583f11fcb4f3"], "operator": null, "metadata": {"aucs": [0.41268015625358256, 0.7711903381868633, 0.827544153804568, 0.9269209464716692, 0.8737137984396048, 0.8967388323414127, 0.8036107324944406, 0.8139320874244291, 0.8806324218272157, 0.8471326707985681, 0.911183877030889, 0.9996585959654118, 0.318434884051197, 0.8230757693853172, 0.9372762108809543, 0.8898152938081481, 0.43803129114045447, 0.9207945122548501, 0.5924384691946998, 0.5297066040227656]}}
{"id": "aa72a28d-5710-4b64-ad65-7b343a4e2954", "fitness": 0.753047056133422, "name": "AdaptiveDE", "description": "Simplified Adaptive DE with momentum-based F/CR adaptation and a probabilistic memory update for faster learning.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5, momentum=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.memory = []  # Store successful F and CR values\n        self.F = 0.5\n        self.CR = 0.7\n        self.momentum = momentum  # Momentum for F and CR updates\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation: Momentum-based average of memory entries\n                if self.memory:\n                    F_vals = [m[0] for m in self.memory]\n                    CR_vals = [m[1] for m in self.memory]\n                    \n                    #Momentum update for F and CR\n                    self.F = (1 - self.momentum) * self.F + self.momentum * np.mean(F_vals) if F_vals else self.F\n                    self.CR = (1 - self.momentum) * self.CR + self.momentum * np.mean(CR_vals) if CR_vals else self.CR\n\n                    self.F = np.clip(self.F, 0.1, 0.9)\n                    self.CR = np.clip(self.CR, 0.1, 0.9)\n\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Probabilistic memory update: Replace an existing entry with probability proportional to improvement\n                    improvement = fitness[i] - f_trial\n                    if len(self.memory) < self.memory_size:\n                        self.memory.append((self.F, self.CR))\n                    else:\n                        # Replace with a probability related to the improvement\n                        probabilities = np.array([improvement / (fitness[i] - fitness[j]) if (fitness[i] - fitness[j]) != 0 else 0.0 for j in range(self.pop_size)]) # Probability of replacing jth element, higher improvement more probability\n                        probabilities = probabilities / np.sum(probabilities) if np.sum(probabilities) > 0 else np.ones(self.pop_size) / self.pop_size\n                        \n                        if np.random.rand() < np.mean(probabilities):\n                            replace_index = np.random.randint(0, len(self.memory))\n                            self.memory[replace_index] = (self.F, self.CR)\n                    \n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.753 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["704940cb-94e9-467a-9cb6-583f11fcb4f3"], "operator": null, "metadata": {"aucs": [0.4142249098221814, 0.7353995268828272, 0.8414926532949913, 0.9299729243457534, 0.8553881610733313, 0.8998054194346995, 0.8468910649769004, 0.8243063161975257, 0.8838924458258723, 0.24056445194019105, 0.9222663730870113, 0.9959623141777546, 0.49147694987967283, 0.8707963034375692, 0.9424969932624824, 0.9020891664326135, 0.7792942282745563, 0.9186383944146809, 0.23086740241646486, 0.5351151234913627]}}
{"id": "8755aa75-ddcf-4bbf-9420-91deb88797a7", "fitness": 0.6763532530827281, "name": "AdaptiveDE", "description": "Simplified Adaptive DE with momentum-based F/CR adaptation and a larger population size for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, memory_size=5, momentum=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.memory = []  # Store successful F and CR values (F, CR, improvement)\n        self.F = 0.5\n        self.CR = 0.7\n        self.momentum = momentum\n        self.best_F = 0.5\n        self.best_CR = 0.7\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation: Momentum-based average of best memory entries\n                if self.memory:\n                    top_memory = sorted(self.memory, key=lambda x: x[2], reverse=True)[:min(len(self.memory), self.memory_size)]\n                    best_F = np.mean([m[0] for m in top_memory])\n                    best_CR = np.mean([m[1] for m in top_memory])\n\n                    self.best_F = (1 - self.momentum) * self.best_F + self.momentum * best_F\n                    self.best_CR = (1 - self.momentum) * self.best_CR + self.momentum * best_CR\n\n                    self.F = np.clip(self.best_F, 0.1, 0.9)\n                    self.CR = np.clip(self.best_CR, 0.1, 0.9)\n                else:\n                    self.F = 0.5\n                    self.CR = 0.7\n\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    improvement = fitness[i] - f_trial\n                    \n                    #Simplified memory update: Directly replace the worst entry\n                    if len(self.memory) < self.memory_size:\n                        self.memory.append((self.F, self.CR, improvement))\n                    else:\n                        worst_index = np.argmin([m[2] for m in self.memory])\n                        self.memory[worst_index] = (self.F, self.CR, improvement)\n                    \n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.676 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["704940cb-94e9-467a-9cb6-583f11fcb4f3"], "operator": null, "metadata": {"aucs": [0.23141503183520484, 0.6179542236130865, 0.7002859691754416, 0.8504730262235811, 0.7657018369971508, 0.804933401732989, 0.6342826194871329, 0.6580948938627953, 0.7482215630067793, 0.6672736441944997, 0.834711473338743, 0.9968598764405868, 0.3687024596819416, 0.689365406729734, 0.9002537522248211, 0.8207900986025176, 0.5846151718723782, 0.8582487261388534, 0.2734928041714815, 0.5213890823248419]}}
{"id": "fcdf305e-8c34-4940-9d10-6b129bc30021", "fitness": 0.512487677463483, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution using a success-weighted archive and adaptive mutation strategy with dynamic scaling factor for exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.memory = []  # Store successful F and CR values\n        self.F = 0.5\n        self.CR = 0.7\n        self.p = 0.1  # Probability for selecting best individual in mutation\n        self.scaling_factor = 1.0  # Dynamic scaling factor for mutation\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                if self.memory:\n                    # Weighted random choice based on past successes\n                    weights = np.array([m[2] for m in self.memory])  # Use improvement as weight\n                    weights = weights / np.sum(weights)  # Normalize weights\n                    idx = np.random.choice(len(self.memory), p=weights)\n                    self.F = self.memory[idx][0]\n                    self.CR = self.memory[idx][1]\n                    self.F = np.clip(self.F, 0.1, 0.9)\n                    self.CR = np.clip(self.CR, 0.1, 0.9)\n                else:\n                    self.F = 0.5\n                    self.CR = 0.7\n\n                # Mutation: DE/current-to-best/1 with probability p, else DE/rand/1\n                if np.random.rand() < self.p:\n                    # DE/current-to-best/1\n                    best_idx = np.argmin(fitness)\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = population[indices]\n                    mutant = population[i] + self.scaling_factor * self.F * (population[best_idx] - population[i]) + self.F * (x_r1 - x_r2)\n                else:\n                    # DE/rand/1\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[indices]\n                    mutant = x_r1 + self.scaling_factor * self.F * (x_r2 - x_r3)\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    improvement = fitness[i] - f_trial\n                    if len(self.memory) >= self.memory_size:\n                        self.memory.pop(0)  # FIFO\n                    self.memory.append((self.F, self.CR, improvement))  # Store F, CR, and improvement\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                        self.scaling_factor = min(1.5, self.scaling_factor * 1.05) # Increase scaling if better\n                    else:\n                        self.scaling_factor = max(0.5, self.scaling_factor * 0.95) # Decrease scaling if not better\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.512 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f06dea8a-eff1-403a-a23b-572b7f00ad5f"], "operator": null, "metadata": {"aucs": [0.2658993528866297, 0.9043839345385528, 0.3894183481659216, 0.3697023413833378, 0.5224458879348601, 0.43653514706212704, 0.8806629488269437, 0.4649892491376574, 0.5080226289326758, 0.6867008538995365, 0.40656048354699426, 0.9910878138964848, 0.27636025381227214, 0.5245646500015232, 0.5880469930964181, 0.3039833047459902, 0.2946925319686158, 0.658023781586409, 0.2589576561309125, 0.5187153877157983]}}
{"id": "f7aff0d0-843f-40ba-b79d-2657b59294a9", "fitness": 0.6545360346866576, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on a success-weighted memory and a mutation strategy that blends current-to-best and random components.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.memory = []  # Store successful F and CR values\n        self.F = 0.5\n        self.CR = 0.7\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                if self.memory:\n                    # Weighted random choice based on past successes\n                    weights = np.array([m[2] for m in self.memory])  # Use improvement as weight\n                    weights = weights / np.sum(weights)  # Normalize weights\n                    idx = np.random.choice(len(self.memory), p=weights)\n                    self.F = self.memory[idx][0]\n                    self.CR = self.memory[idx][1]\n                    self.F = np.clip(self.F, 0.1, 0.9)\n                    self.CR = np.clip(self.CR, 0.1, 0.9)\n                else:\n                    self.F = 0.5\n                    self.CR = 0.7\n\n                # Mutation: Blend DE/rand/1 and DE/current-to-best/1\n                best_idx = np.argmin(fitness)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n\n                # Combine mutation strategies\n                mutant = population[i] + self.F * (population[best_idx] - population[i]) + self.F * (x_r1 - x_r2) + self.F * (x_r2 - x_r3)\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    improvement = fitness[i] - f_trial\n                    if len(self.memory) >= self.memory_size:\n                        self.memory.pop(0)  # FIFO\n                    self.memory.append((self.F, self.CR, improvement))  # Store F, CR, and improvement\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.655 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f06dea8a-eff1-403a-a23b-572b7f00ad5f"], "operator": null, "metadata": {"aucs": [0.15382387610766546, 0.884797314363027, 0.41593365908948976, 0.9397393852724831, 0.7656614314438583, 0.8093977697625985, 0.37046948200731145, 0.453472926733281, 0.9318704198241333, 0.8046785332778977, 0.9547910532208981, 0.9988479097084679, 0.6828086482906117, 0.8662022494543815, 0.809031330268753, 0.34051882789906784, 0.3255878811216999, 0.8430892581326785, 0.23955512718378225, 0.5004436105710619]}}
{"id": "b15bd6e2-49ac-4d8a-b6e2-ae3a4639ac66", "fitness": 0.6145879878823566, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on the best-performing parameters in the current generation and a mutation strategy that balances exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5\n        self.CR = 0.7\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            best_f = np.min(fitness)\n            best_x = population[np.argmin(fitness)]\n            \n            successful_F = []\n            successful_CR = []\n            \n            for i in range(self.pop_size):\n                # Mutation: DE/current-to-best/1\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = population[indices]\n                mutant = population[i] + self.F * (best_x - population[i]) + self.F * (x_r1 - x_r2)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    successful_F.append(self.F)\n                    successful_CR.append(self.CR)\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                \n                if self.budget <= 0:\n                    break\n            \n            # Parameter Adaptation: Use the mean of successful parameters\n            if successful_F:\n                self.F = np.mean(successful_F)\n                self.F = np.clip(self.F, 0.1, 0.9)\n            if successful_CR:\n                self.CR = np.mean(successful_CR)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.615 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f06dea8a-eff1-403a-a23b-572b7f00ad5f"], "operator": null, "metadata": {"aucs": [0.12064333613479306, 0.3701204554305605, 0.37918098607649675, 0.9665462525955945, 0.9215313616786619, 0.9401858678629909, 0.37353515393491743, 0.8975777417969527, 0.38419644216227467, 0.5221457177617906, 0.9257494719513824, 0.9958272247007093, 0.38165561336066034, 0.34928612498538925, 0.9601971382886085, 0.9447673877792354, 0.5867884050538361, 0.5240432846324179, 0.2707677341717113, 0.47701405728814894]}}
{"id": "e9ef6285-3bfc-441c-a692-9399f57a4973", "fitness": 0.7753827180866804, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution using a smaller population and adaptive F/CR values with a focused update mechanism favoring successful parameter pairs to enhance exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15, memory_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.memory_F = np.ones(memory_size) * 0.5\n        self.memory_CR = np.ones(memory_size) * 0.7\n        self.F = 0.5\n        self.CR = 0.7\n        self.success_F = []\n        self.success_CR = []\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using mean of successful F and CR\n                if self.success_F:\n                    self.F = np.mean(self.success_F)\n                    self.CR = np.mean(self.success_CR)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.CR = np.clip(self.CR, 0.0, 1.0)\n\n                # Mutation: DE/rand/1\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Store successful F and CR values\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n                    if len(self.success_F) > self.memory_size:\n                        self.success_F.pop(0)\n                        self.success_CR.pop(0)\n                    \n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.775 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ec429833-a3ee-42b3-bdb5-6a86702c9575"], "operator": null, "metadata": {"aucs": [0.35456478656537804, 0.40270934640972644, 0.4887925020804871, 0.9473426515976485, 0.9102408533585126, 0.9215609412324536, 0.8642403518298857, 0.8803003208107805, 0.8963178893983375, 0.8587765246007983, 0.9361311294534147, 0.9980703345294464, 0.31501259444740337, 0.8558707682718221, 0.9407478911968574, 0.9258821905042319, 0.7371443655329271, 0.9367481676000678, 0.8089246364095045, 0.5282761159039255]}}
