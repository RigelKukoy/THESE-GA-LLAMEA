{"id": "17aa4508-0b0d-421c-965d-9cee1f3c7abf", "fitness": -Infinity, "name": "CMAES", "description": "Covariance matrix adaptation evolution strategy with a simple restart mechanism and boundary handling.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.3, cs=0.8, cmu=0.1, c_cov_1=None, c_cov_mu=None, \n                 damps=None, restarts=3):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.sigma0 = sigma0\n        self.cs = cs\n        self.cmu = cmu\n        self.c_cov_1 = c_cov_1 if c_cov_1 is not None else 2 / (self.dim + 1.3)**2 + 0.1\n        self.c_cov_mu = c_cov_mu if c_cov_mu is not None else min(1 - self.c_cov_1, 2 * (self.popsize - 2 + 1 / self.popsize) / ((self.dim + 2)**2 + self.c_cov_1))\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.c_cov_1 + self.c_cov_mu) * (self.dim - 1)) - 1) + self.cs\n        self.restarts = restarts\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        evals = 0\n        \n        for r in range(self.restarts):\n            # Initialize variables\n            mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            sigma = self.sigma0\n            C = np.eye(self.dim)\n            p_sigma = np.zeros(self.dim)\n            p_c = np.zeros(self.dim)\n            \n            while evals < self.budget:\n                # Sample population\n                z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n                y = np.dot(np.linalg.cholesky(C), z)\n                x = mean + sigma * y\n                \n                # Bound handling (clip)\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate population\n                f = np.array([func(x[:,i]) for i in range(self.popsize)])\n                evals += self.popsize\n                \n                # Sort by fitness\n                idx = np.argsort(f)\n                x = x[:, idx]\n                y = y[:, idx]\n                \n                # Update optimal solution\n                if f[idx[0]] < self.f_opt:\n                    self.f_opt = f[idx[0]]\n                    self.x_opt = x[:, 0].copy()\n                    \n                # Update mean\n                mean_old = mean.copy()\n                mean = np.mean(x[:, :self.popsize // 2], axis=1)\n                \n                # Update evolution paths\n                p_sigma = (1 - self.cs) * p_sigma + np.sqrt(self.cs * (2 - self.cs) * self.cmu) * np.dot(np.linalg.inv(np.linalg.cholesky(C)), (mean - mean_old) / sigma)\n                p_c = (1 - self.cmu) * p_c + np.sqrt(self.cmu * (2 - self.cmu)) * (mean - mean_old) / sigma\n                \n                # Update covariance matrix\n                C = (1 - self.c_cov_1 - self.c_cov_mu) * C + self.c_cov_1 * np.outer(p_c, p_c) + self.c_cov_mu * np.dot(y[:, :self.popsize // 2], y[:, :self.popsize // 2].T) / (self.popsize // 2)\n                \n                # Update step size\n                sigma = sigma * np.exp((self.cs / self.damps) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n                \n                # Ensure C is positive definite\n                C = np.triu(C) + np.triu(C, 1).T\n                C = C / np.linalg.norm(C)\n                C = np.diag(np.diag(C)) + 0.0001*np.eye(self.dim) \n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,) (2,6) .", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "e5d0ea5f-f1dd-4b79-9f74-1e760b45136b", "fitness": 0.0, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Archive and Stochastic Ranking for constrained handling, with self-adaptive parameters and population size reduction.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=2.0, f=0.5, cr=0.9, alpha=0.1, beta=0.1, gamma=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(10 + np.ceil(np.log(self.dim)))\n        self.archive_size = archive_size\n        self.F = f\n        self.CR = cr\n        self.alpha = alpha\n        self.beta = beta\n        self.gamma = gamma\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        for i in range(self.pop_size):\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = self.population[i]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            \n            # Adaptive Parameter Control\n            self.F = np.clip(np.random.normal(self.F, self.alpha), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(self.CR, self.beta), 0.1, 1.0)\n            \n            for j in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                \n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(cross_mask, mutant, self.population[j])\n                \n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                if f_trial < fitness[j]:\n                    fitness[j] = f_trial\n                    self.population[j] = trial_vector\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                        \n                else:\n                    # Archive the replaced individuals\n                    if len(self.archive) < self.pop_size * self.archive_size:\n                        self.archive.append(self.population[j])\n                    else:\n                        idx_to_replace = np.random.randint(0, len(self.archive))\n                        self.archive[idx_to_replace] = self.population[j]\n\n            # Population Size Reduction (PSR) - Reduce pop size gradually\n            if generation % 10 == 0 and self.pop_size > 5:  # Reduce every 10 generations\n                reduction_factor = 0.1  # Reduce by 10% each time\n                num_to_remove = int(self.pop_size * reduction_factor)\n                \n                # Remove the worst individuals from the population\n                worst_indices = np.argsort(fitness)[-num_to_remove:]\n                \n                self.population = np.delete(self.population, worst_indices, axis=0)\n                fitness = np.delete(fitness, worst_indices)\n                self.pop_size = self.population.shape[0]\n                \n                # Potentially replace removed individuals with archive members\n                num_to_replace = min(num_to_remove, len(self.archive))\n                if num_to_replace > 0:\n                  replacement_indices = np.random.choice(len(self.archive), num_to_replace, replace=False)\n                  self.population = np.concatenate([self.population, np.array(self.archive)[replacement_indices]], axis=0)\n                  new_fitness = np.array([func(x) for x in np.array(self.archive)[replacement_indices]])\n                  fitness = np.concatenate([fitness, new_fitness])\n                  self.budget -= num_to_replace\n                  self.pop_size = self.population.shape[0]\n                  \n                  # Update best fitness\n                  for k in range(num_to_replace):\n                    if new_fitness[k] < self.f_opt:\n                      self.f_opt = new_fitness[k]\n                      self.x_opt = np.array(self.archive)[replacement_indices][k]\n\n                # Trim the archive to keep its size manageable\n                self.archive = self.archive[:int(self.pop_size * self.archive_size)]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}}
{"id": "042aa03d-ba7c-4a05-beed-4783ce3d2521", "fitness": 0.31400445783389686, "name": "RankBasedPSO", "description": "Population-based algorithm with velocity updates based on fitness rank and exploration-exploitation balance using dynamic inertia weight.", "code": "import numpy as np\n\nclass RankBasedPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia_max=0.9, inertia_min=0.2, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.c1 = c1\n        self.c2 = c2\n\n    def __call__(self, func):\n        # Initialization\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), size=(self.pop_size, self.dim)) # Initialize velocities\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        pbest_population = population.copy()\n        pbest_fitness = fitness.copy()\n        \n        gbest_index = np.argmin(fitness)\n        gbest_fitness = fitness[gbest_index]\n        gbest_position = population[gbest_index].copy()\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Rank the particles based on fitness\n            ranked_indices = np.argsort(fitness)\n            \n            # Update inertia weight linearly\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (1 - self.budget/self.budget)\n            \n            for i in range(self.pop_size):\n                # Social component based on rank\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Weighted average of all pbest based on rank\n                social_component = np.zeros(self.dim)\n                rank = np.where(ranked_indices == i)[0][0] # Find the rank of the current particle\n                \n                # Exploitation\n                if rank < self.pop_size / 2:  # Better half focuses on exploiting best solutions\n                    social_influence = pbest_population[ranked_indices[0]] - population[i]\n                # Exploration\n                else:   # Worse half explores around a random better solution\n                    random_better_index = ranked_indices[np.random.randint(0, int(self.pop_size / 2))]\n                    social_influence = pbest_population[random_better_index] - population[i]\n                    \n                velocities[i] = (inertia * velocities[i] +\n                                    self.c1 * r1 * (pbest_population[i] - population[i]) +\n                                    self.c2 * r2 * social_influence)  # Rank-based influence\n                \n                population[i] = population[i] + velocities[i]\n                \n                # Boundary handling (clip to the search space)\n                population[i] = np.clip(population[i], lb, ub)\n            \n            # Evaluate new solutions\n            new_fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n            \n            # Update personal best\n            for i in range(self.pop_size):\n                if new_fitness[i] < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness[i]\n                    pbest_population[i] = population[i].copy()\n            \n            # Update global best\n            new_gbest_index = np.argmin(new_fitness)\n            if new_fitness[new_gbest_index] < gbest_fitness:\n                gbest_fitness = new_fitness[new_gbest_index]\n                gbest_position = population[new_gbest_index].copy()\n                \n            fitness = new_fitness\n\n        return gbest_fitness, gbest_position", "configspace": "", "generation": 0, "feedback": "The algorithm RankBasedPSO scored 0.314 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.13944483551648645, 0.19912854167055527, 0.29509983157030617, 0.24645329309672193, 0.2510327247813864, 0.2721017889839007, 0.26528624789749633, 0.2875057773806814, 0.22954319146949043, 0.19508718913569678, 0.2185252986920193, 0.9959535441444662, 0.24000542964552318, 0.2502420254914922, 0.6442520753474785, 0.325794701381807, 0.24623138164242664, 0.3267301379599217, 0.19084910434033253, 0.46082203652974874]}}
{"id": "8cd7d0f6-75d5-4153-8b12-6142f1f1730a", "fitness": 0.6670760565525533, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with a Population Archive and Scaling Factor Adaptation, focusing on exploration in early stages and exploitation in later stages.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7 # Initial crossover rate\n        self.F_memory = []\n        self.CR_memory = []\n        self.memory_size = 10\n        self.p = 0.1 # Probability of using best individual\n\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = []\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                if np.random.rand() < self.p:\n                    best_idx = np.argmin(self.fitness)\n                    x_best = self.pop[best_idx]\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n                    mutant = x_best + self.F * (x_r1 - x_r2)\n                else:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n                \n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.archive.append(self.pop[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                # Adapt F and CR\n                if self.evals % (self.pop_size*2) == 0:\n                    self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                    self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.667 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.25016437592373775, 0.5146568716400115, 0.7368591096815222, 0.8284823357718435, 0.7345431321478781, 0.8286444391974771, 0.6660166302923656, 0.6878670739247656, 0.7425607625822419, 0.6851051679535123, 0.8391903737603321, 0.9973932098241004, 0.35728403611588244, 0.6931580106952564, 0.9125403779271275, 0.7964743830227519, 0.4284863564245398, 0.8245685511944253, 0.28955977457503934, 0.5279661583962576]}}
{"id": "41a9938b-6f8b-4408-85c6-42dad686c05a", "fitness": -Infinity, "name": "SOM_DE", "description": "An adaptive Differential Evolution strategy that uses a self-organizing map (SOM) to cluster solutions and apply different mutation strategies within each cluster to diversify the search.", "code": "import numpy as np\nfrom minisom import MiniSom\n\nclass SOM_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, som_grid_size=5, learning_rate=0.5, sigma=0.3, f=0.5, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(10 + np.ceil(np.log(self.dim)))\n        self.som_grid_size = som_grid_size\n        self.learning_rate = learning_rate\n        self.sigma = sigma\n        self.F = f\n        self.CR = cr\n        self.som = None  # Initialize SOM to None\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = self.population[i]\n\n        # Initialize SOM after initial population evaluation\n        self.som = MiniSom(self.som_grid_size, self.som_grid_size, self.dim, sigma=self.sigma, learning_rate=self.learning_rate)\n        self.som.train(self.population, num_iteration=100)  # Train SOM initially\n\n        while self.budget > 0:\n            # Assign each individual to a SOM node\n            winners = [self.som.winner(x) for x in self.population]\n\n            for j in range(self.pop_size):\n                # Adaptive Mutation Strategy based on SOM node\n                winner_node = winners[j]\n                cluster_individuals = [self.population[i] for i in range(self.pop_size) if winners[i] == winner_node]\n\n                if len(cluster_individuals) < 3:\n                    # Fallback to random selection if cluster is too small\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                else:\n                    idxs = np.random.choice(len(cluster_individuals), 3, replace=False)\n                    x1, x2, x3 = cluster_individuals[idxs]\n\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(cross_mask, mutant, self.population[j])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[j]:\n                    fitness[j] = f_trial\n                    self.population[j] = trial_vector\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n            # Retrain SOM periodically\n            if self.budget > 0 and self.budget % (self.pop_size * 5) == 0: # retrain every 5 generations\n                self.som.train(self.population, num_iteration=100)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: No module named 'minisom'.", "error": "", "parent_ids": ["e5d0ea5f-f1dd-4b79-9f74-1e760b45136b"], "operator": null, "metadata": {}}
{"id": "0dd42f28-52a8-408e-8dc3-12121cd76bab", "fitness": -Infinity, "name": "ConstrictionPSO", "description": "A particle swarm optimization algorithm with a constriction factor to control velocity explosion and a diversity maintenance strategy based on crowding distance.", "code": "import numpy as np\n\nclass ConstrictionPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.729, c1=1.49445, c2=1.49445, constriction_factor=0.729, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.constriction_factor = constriction_factor\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        # Initialization\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        pbest_population = population.copy()\n        pbest_fitness = fitness.copy()\n        \n        gbest_index = np.argmin(fitness)\n        gbest_fitness = fitness[gbest_index]\n        gbest_position = population[gbest_index].copy()\n        \n        # Optimization loop\n        while self.budget > 0:\n            \n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = self.constriction_factor * (self.inertia * velocities[i] +\n                                    self.c1 * r1 * (pbest_population[i] - population[i]) +\n                                    self.c2 * r2 * (gbest_position - population[i]))\n                \n                population[i] = population[i] + velocities[i]\n                \n                # Boundary handling (clip to the search space)\n                population[i] = np.clip(population[i], lb, ub)\n            \n            # Evaluate new solutions\n            new_fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n            \n            # Update personal best\n            for i in range(self.pop_size):\n                if new_fitness[i] < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness[i]\n                    pbest_population[i] = population[i].copy()\n            \n            # Update global best\n            new_gbest_index = np.argmin(new_fitness)\n            if new_fitness[new_gbest_index] < gbest_fitness:\n                gbest_fitness = new_fitness[new_gbest_index]\n                gbest_position = population[new_gbest_index].copy()\n                \n            fitness = new_fitness\n\n            # Diversity Maintenance based on Crowding Distance\n            if self.check_diversity(population):\n                self.maintain_diversity(population, lb, ub)\n\n        return gbest_fitness, gbest_position\n\n    def check_diversity(self, population):\n        \"\"\"Checks if the population diversity is below a threshold.\"\"\"\n        centroid = np.mean(population, axis=0)\n        distances = np.linalg.norm(population - centroid, axis=1)\n        mean_distance = np.mean(distances)\n        \n        # Normalize the mean distance by the range of the search space\n        normalized_distance = mean_distance / (np.max(population) - np.min(population))\n        \n        return normalized_distance < self.diversity_threshold\n\n    def maintain_diversity(self, population, lb, ub):\n        \"\"\"Maintains diversity by re-initializing the worst particles based on fitness.\"\"\"\n        num_reinitialize = int(self.pop_size * 0.2)  # Re-initialize 20% of the population\n        worst_indices = np.argsort(fitness)[-num_reinitialize:]\n        \n        for i in worst_indices:\n            population[i] = np.random.uniform(lb, ub, size=self.dim) # Re-initialize position\n            velocities[i] = np.random.uniform(-abs(ub-lb), abs(ub-lb), size=self.dim) # Re-initialize velocity", "configspace": "", "generation": 1, "feedback": "An exception occurred: name 'fitness' is not defined.", "error": "", "parent_ids": ["042aa03d-ba7c-4a05-beed-4783ce3d2521"], "operator": null, "metadata": {}}
{"id": "40110027-cbc8-44af-9b4c-b668b97f3ae6", "fitness": -Infinity, "name": "AdaptiveCMAES", "description": "An improved CMA-ES with dynamic population size, adaptive covariance updates, and a better restart strategy based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, popsize_factor=4, sigma0=0.3, cs=0.8, cmu=0.1, c_cov_1=None, c_cov_mu=None,\n                 damps=None, restarts=3, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize_factor = popsize_factor\n        self.sigma0 = sigma0\n        self.cs = cs\n        self.cmu = cmu\n        self.c_cov_1 = c_cov_1 if c_cov_1 is not None else 2 / (self.dim + 1.3)**2 + 0.1\n        self.c_cov_mu = c_cov_mu if c_cov_mu is not None else min(1 - self.c_cov_1, 2 * (self.popsize - 2 + 1 / self.popsize) / ((self.dim + 2)**2 + self.c_cov_1))\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.c_cov_1 + self.c_cov_mu) * (self.dim - 1)) - 1) + self.cs\n        self.restarts = restarts\n        self.stagnation_threshold = stagnation_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        evals = 0\n        stagnation_counter = 0\n        last_f_opt = np.Inf\n\n        for r in range(self.restarts):\n            # Initialize variables\n            mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            sigma = self.sigma0\n            C = np.eye(self.dim)\n            p_sigma = np.zeros(self.dim)\n            p_c = np.zeros(self.dim)\n            popsize = self.popsize_factor + int(3 * np.log(self.dim))\n\n            while evals < self.budget:\n                # Sample population\n                z = np.random.normal(0, 1, size=(self.dim, popsize))\n                try:\n                    y = np.dot(np.linalg.cholesky(C), z)\n                except np.linalg.LinAlgError:\n                    C = C + 1e-6 * np.eye(self.dim) # add a small value to diagonal\n                    y = np.dot(np.linalg.cholesky(C), z)\n\n                x = mean + sigma * y\n                \n                # Bound handling (clip)\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate population\n                f = np.array([func(x[:,i]) for i in range(popsize)])\n                evals += popsize\n                \n                # Sort by fitness\n                idx = np.argsort(f)\n                x = x[:, idx]\n                y = y[:, idx]\n                \n                # Update optimal solution\n                if f[idx[0]] < self.f_opt:\n                    self.f_opt = f[idx[0]]\n                    self.x_opt = x[:, 0].copy()\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += popsize\n\n                # Update mean\n                mean_old = mean.copy()\n                mean = np.mean(x[:, :popsize // 2], axis=1)\n                \n                # Update evolution paths\n                p_sigma = (1 - self.cs) * p_sigma + np.sqrt(self.cs * (2 - self.cs) * self.cmu) * np.dot(np.linalg.inv(np.linalg.cholesky(C)), (mean - mean_old) / sigma)\n                p_c = (1 - self.cmu) * p_c + np.sqrt(self.cmu * (2 - self.cmu)) * (mean - mean_old) / sigma\n                \n                # Update covariance matrix\n                C = (1 - self.c_cov_1 - self.c_cov_mu) * C + self.c_cov_1 * np.outer(p_c, p_c) + self.c_cov_mu * np.dot(y[:, :popsize // 2], y[:, :popsize // 2].T) / (popsize // 2)\n                \n                # Update step size\n                sigma = sigma * np.exp((self.cs / self.damps) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n                \n                # Ensure C is positive definite\n                C = np.triu(C) + np.triu(C, 1).T\n                C = (C + C.T) / 2  # Ensure symmetry\n                min_eig = np.min(np.linalg.eigvalsh(C))\n                if min_eig < 1e-6:\n                    C += (1e-6 - min_eig) * np.eye(self.dim)\n\n                # Stagnation restart\n                if stagnation_counter > self.stagnation_threshold or sigma < 1e-10:\n                    break #restart from the outer loop if stagnation occurs\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: 'AdaptiveCMAES' object has no attribute 'popsize'.", "error": "", "parent_ids": ["17aa4508-0b0d-421c-965d-9cee1f3c7abf"], "operator": null, "metadata": {}}
{"id": "c6f5c777-4822-470a-b5de-9c2d3cfc28eb", "fitness": 0.0, "name": "SelfAdjustingDE", "description": "Differential Evolution with a self-adjusting population size, combined with a mutation strategy that blends the best individual and random differences, and adaptive F and CR parameters.", "code": "import numpy as np\n\nclass SelfAdjustingDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7  # Initial crossover rate\n        self.best_fitness_history = []\n        self.pop_size_history = []\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.best_fitness_history.append(self.f_opt)\n        self.pop_size_history.append(self.pop_size)\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation: DE/current-to-best/1\n                best_idx = np.argmin(self.fitness)\n                x_best = self.pop[best_idx]\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n                mutant = self.pop[i] + self.F * (x_best - self.pop[i]) + self.F * (x_r1 - x_r2)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Adjust population size based on stagnation\n            if len(self.best_fitness_history) > 10:\n                if np.std(self.best_fitness_history[-10:]) < 1e-6:  # Stagnation detected\n                    self.pop_size = max(self.min_pop_size, int(self.pop_size * 0.9))  # Reduce pop size\n                    if self.pop_size < self.pop.shape[0]:\n                      self.pop = self.pop[:self.pop_size]\n                      self.fitness = self.fitness[:self.pop_size]\n                else:\n                    self.pop_size = min(self.max_pop_size, int(self.pop_size * 1.1))  # Increase pop size if improving\n                    if self.pop_size > self.pop.shape[0]:\n                        new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - self.pop.shape[0], self.dim))\n                        new_fitness = np.array([func(x) for x in new_individuals])\n                        self.evals += new_fitness.shape[0]\n                        self.pop = np.concatenate((self.pop, new_individuals))\n                        self.fitness = np.concatenate((self.fitness, new_fitness))\n\n\n            # Adapt F and CR\n            self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n            self.best_fitness_history.append(self.f_opt)\n            self.pop_size_history.append(self.pop_size)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm SelfAdjustingDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8cd7d0f6-75d5-4153-8b12-6142f1f1730a"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "a1887ff3-21d7-4369-a81c-de67271eb4fd", "fitness": 0.0, "name": "CooperativeAdaptiveDE", "description": "Cooperative Adaptive Differential Evolution with intermittent local search and parameter control via success history.", "code": "import numpy as np\n\nclass CooperativeAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, local_search_freq=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.local_search_freq = local_search_freq\n        self.F_mean = 0.5\n        self.CR_mean = 0.7\n        self.F_values = []\n        self.CR_values = []\n        self.SF = []\n        self.SCR = []\n        self.memory_size = 10\n        self.p = 0.1 # Probability of using best individual\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = []\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                if np.random.rand() < 0.1 or not self.SF: # Exploration or initial phase\n                    F = np.clip(np.random.normal(self.F_mean, 0.3), 0.1, 1.0)\n                    CR = np.clip(np.random.normal(self.CR_mean, 0.1), 0.1, 1.0)\n                else:  # Adaptation from history\n                    F = np.random.choice(self.SF)\n                    CR = np.random.choice(self.SCR)\n\n                # Mutation\n                if np.random.rand() < self.p:\n                    best_idx = np.argmin(self.fitness)\n                    x_best = self.pop[best_idx]\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n                    mutant = x_best + F * (x_r1 - x_r2)\n                else:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                    mutant = x_r1 + F * (x_r2 - x_r3)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Local Search (Intermittent)\n                if self.evals % self.local_search_freq == 0:\n                    trial = self.local_search(trial, func, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.archive.append(self.pop[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    # Update success history\n                    self.SF.append(F)\n                    self.SCR.append(CR)\n                    if len(self.SF) > self.memory_size:\n                        self.SF.pop(0)\n                        self.SCR.pop(0)\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            self.F_mean = np.mean(self.SF) if self.SF else 0.5\n            self.CR_mean = np.mean(self.SCR) if self.SCR else 0.7\n\n        return self.f_opt, self.x_opt\n    \n    def local_search(self, x, func, lb, ub, step_size=0.1, num_steps=5):\n        \"\"\"Performs a simple local search around a given solution.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n\n        for _ in range(num_steps):\n            # Generate a random perturbation\n            delta = np.random.uniform(-step_size, step_size, size=self.dim)\n            new_x = x + delta\n            new_x = np.clip(new_x, lb, ub)  # Ensure bounds are respected\n            new_f = func(new_x)\n            self.evals += 1\n\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x\n        \n        return best_x", "configspace": "", "generation": 1, "feedback": "The algorithm CooperativeAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8cd7d0f6-75d5-4153-8b12-6142f1f1730a"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "4700aad5-37e0-4cd7-aca2-a173a7308df1", "fitness": 0.06323887517500759, "name": "HybridPSO_DE", "description": "A population-based algorithm that combines elements of particle swarm optimization (PSO) with differential evolution (DE) mutation and crossover strategies for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, popsize=None, w=0.7, c1=1.5, c2=1.5, F=0.8, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 * dim\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.F = F  # Differential evolution scaling factor\n        self.CR = CR  # Crossover rate\n\n        self.particles = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def initialize_population(self, func):\n        self.particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.popsize, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.popsize, self.dim))  # Initialize velocities\n        self.fitness = np.array([func(self.particles[i]) for i in range(self.popsize)])\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.particles[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        evals = 0\n\n        # Initialize population\n        self.initialize_population(func)\n        evals += self.popsize\n\n        while evals < self.budget:\n            for i in range(self.popsize):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.particles[idxs]\n                v_mutation = x1 + self.F * (x2 - x3)\n                v_mutation = np.clip(v_mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                v_crossover = self.particles[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        v_crossover[j] = v_mutation[j]\n\n                # PSO Velocity Update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = (self.w * self.velocities[i] +\n                            self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                            self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                new_particle = self.particles[i] + velocity\n                new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate new particle\n                new_fitness = func(new_particle)\n                evals += 1\n                if new_fitness < self.fitness[i]:\n                    self.particles[i] = new_particle\n                    self.fitness[i] = new_fitness\n\n\n                    # Update personal best\n                    if new_fitness < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = new_fitness\n                        self.personal_best_positions[i] = new_particle.copy()\n\n                        # Update global best\n                        if new_fitness < self.global_best_fitness:\n                            self.global_best_fitness = new_fitness\n                            self.global_best_position = new_particle.copy()\n                            self.f_opt = new_fitness\n                            self.x_opt = new_particle.copy()\n                else:\n                     self.particles[i] = v_crossover\n                     new_fitness_crossover = func(self.particles[i])\n                     evals+=1\n                     if new_fitness_crossover < self.fitness[i]:\n                         self.fitness[i] = new_fitness_crossover\n                         if new_fitness_crossover < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = new_fitness_crossover\n                            self.personal_best_positions[i] = self.particles[i].copy()\n                            if new_fitness_crossover < self.global_best_fitness:\n                                self.global_best_fitness = new_fitness_crossover\n                                self.global_best_position = self.particles[i].copy()\n                                self.f_opt = new_fitness_crossover\n                                self.x_opt = self.particles[i].copy()\n\n                if evals >= self.budget:\n                    break\n\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DE scored 0.063 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["17aa4508-0b0d-421c-965d-9cee1f3c7abf"], "operator": null, "metadata": {"aucs": [0.12647775035001518, 0]}}
{"id": "9413aa29-1405-4974-882e-2c66d0c0ac0a", "fitness": 0.07197582294052074, "name": "AdaptiveDESuccessHistory", "description": "An adaptive DE variant that dynamically adjusts its population size and mutation strategy based on the success rate of previous generations.", "code": "import numpy as np\n\nclass AdaptiveDESuccessHistory:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=2.0, f=0.5, cr=0.9, alpha=0.1, beta=0.1, gamma=0.01, success_history_length=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(10 + np.ceil(np.log(self.dim)))\n        self.archive_size = archive_size\n        self.F = f\n        self.CR = cr\n        self.alpha = alpha\n        self.beta = beta\n        self.gamma = gamma\n        self.success_history_length = success_history_length\n        self.success_history_F = []\n        self.success_history_CR = []\n        self.success_history_successes = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        for i in range(self.pop_size):\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = self.population[i]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            \n            # Adaptive Parameter Control using Success History\n            if self.success_history_F:\n                self.F = np.clip(np.random.choice(self.success_history_F), 0.1, 1.0)\n                self.CR = np.clip(np.random.choice(self.success_history_CR), 0.1, 1.0)\n            else:\n                self.F = np.clip(np.random.normal(self.F, self.alpha), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(self.CR, self.beta), 0.1, 1.0)\n\n            successful_F = []\n            successful_CR = []\n            num_successes = 0\n\n            for j in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                \n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(cross_mask, mutant, self.population[j])\n                \n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                if f_trial < fitness[j]:\n                    num_successes += 1\n                    successful_F.append(self.F)\n                    successful_CR.append(self.CR)\n                    \n                    fitness[j] = f_trial\n                    self.population[j] = trial_vector\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                        \n                else:\n                    # Archive the replaced individuals\n                    if len(self.archive) < self.pop_size * self.archive_size:\n                        self.archive.append(self.population[j])\n                    else:\n                        idx_to_replace = np.random.randint(0, len(self.archive))\n                        self.archive[idx_to_replace] = self.population[j]\n\n            # Update Success History\n            self.success_history_F.extend(successful_F)\n            self.success_history_CR.extend(successful_CR)\n            self.success_history_successes.append(num_successes / self.pop_size)\n\n            if len(self.success_history_successes) > self.success_history_length:\n                self.success_history_F = self.success_history_F[-len(successful_F)*self.success_history_length:]\n                self.success_history_CR = self.success_history_CR[-len(successful_CR)*self.success_history_length:]\n                self.success_history_successes = self.success_history_successes[-self.success_history_length:]\n\n\n            # Population Size Adaptation based on Success Rate\n            mean_success_rate = np.mean(self.success_history_successes) if self.success_history_successes else 0.1\n            if mean_success_rate > 0.2 and self.pop_size < 2 * self.dim:\n                self.pop_size = min(2 * self.dim, self.pop_size + 1)\n                new_individual = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(1, self.dim))\n                self.population = np.concatenate([self.population, new_individual], axis=0)\n                new_fitness = func(new_individual[0])\n                fitness = np.concatenate([fitness, [new_fitness]])\n                self.budget -= 1\n                if new_fitness < self.f_opt:\n                    self.f_opt = new_fitness\n                    self.x_opt = new_individual[0]\n            elif mean_success_rate < 0.05 and self.pop_size > 5:\n                # Remove worst individual\n                worst_index = np.argmax(fitness)\n                self.population = np.delete(self.population, worst_index, axis=0)\n                fitness = np.delete(fitness, worst_index)\n                self.pop_size -= 1\n\n            # Trim the archive to keep its size manageable\n            self.archive = self.archive[:int(self.pop_size * self.archive_size)]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDESuccessHistory scored 0.072 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e5d0ea5f-f1dd-4b79-9f74-1e760b45136b"], "operator": null, "metadata": {"aucs": [0.14395164588104148, 0]}}
{"id": "217c843d-bcf3-4905-b01d-f307d7770fac", "fitness": 0.2156089354055056, "name": "SelfOrganizingScouts", "description": "A self-organizing scout-based optimization algorithm that dynamically adjusts the search based on successful and unsuccessful moves.", "code": "import numpy as np\n\nclass SelfOrganizingScouts:\n    def __init__(self, budget=10000, dim=10, num_scouts=20, scout_memory=5, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_scouts = num_scouts\n        self.scout_memory = scout_memory\n        self.step_size = initial_step_size\n        self.step_size_reduction_factor = 0.9\n        self.step_size_increase_factor = 1.1\n        self.success_threshold = 0.1  # Threshold for considering a move successful\n\n        self.scouts = None\n        self.fitness = None\n        self.scout_moves = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.evals = 0\n\n    def initialize_scouts(self, func):\n        self.scouts = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_scouts, self.dim))\n        self.fitness = np.array([func(x) for x in self.scouts])\n        self.evals += self.num_scouts\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.scouts[np.argmin(self.fitness)].copy()\n        self.scout_moves = [[] for _ in range(self.num_scouts)] # Keep track of recent moves\n\n\n    def __call__(self, func):\n        self.initialize_scouts(func)\n\n        while self.evals < self.budget:\n            for i in range(self.num_scouts):\n                # Generate a random move\n                move = np.random.normal(0, self.step_size, size=self.dim)\n                new_position = self.scouts[i] + move\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.evals += 1\n\n                # Check if the move was successful\n                if new_fitness < self.fitness[i]:\n                    # Update scout's position and fitness\n                    self.scouts[i] = new_position\n                    self.fitness[i] = new_fitness\n                    self.scout_moves[i].append(True) # Store succesful move\n                    if len(self.scout_moves[i]) > self.scout_memory:\n                        self.scout_moves[i].pop(0) # Limit memory\n                    \n                    # Update best solution if necessary\n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_position = new_position.copy()\n\n                    # Increase step size if scout is consistently successful\n                    if len(self.scout_moves[i]) == self.scout_memory and all(self.scout_moves[i]):\n                         self.step_size *= self.step_size_increase_factor\n\n                else:\n                     self.scout_moves[i].append(False)  # Store unsuccesful move\n                     if len(self.scout_moves[i]) > self.scout_memory:\n                         self.scout_moves[i].pop(0)  # Limit memory\n                         \n                     # Reduce step size if scout is consistently unsuccessful\n                     if len(self.scout_moves[i]) == self.scout_memory and not any(self.scout_moves[i]):\n                         self.step_size *= self.step_size_reduction_factor\n                         \n\n                if self.evals >= self.budget:\n                    break\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 1, "feedback": "The algorithm SelfOrganizingScouts scored 0.216 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8cd7d0f6-75d5-4153-8b12-6142f1f1730a"], "operator": null, "metadata": {"aucs": [0.07889247443583791, 0.19543033580269908, 0.2120034958357918, 0.18556576935600255, 0.14277927120701128, 0.15254629051361357, 0.18047278037581016, 0.19394091093333465, 0.14484001297552573, 0.15041698688966298, 0.15015755912814077, 0.2137884438744002, 0.31950440247460243, 0.16455634494671834, 0.585674720340985, 0.27499694288424104, 0.16247772507946268, 0.22351232997785775, 0.14235186134959876, 0.43827004972881545]}}
{"id": "2785c2d1-5a03-4a69-bb00-b80e2155eed0", "fitness": 0.6983234455040703, "name": "AdaptiveDE_Success", "description": "An Adaptive Differential Evolution with a combined mutation strategy and adaptive parameter control based on the success rate of previous generations.", "code": "import numpy as np\n\nclass AdaptiveDE_Success:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7 # Initial crossover rate\n        self.F_memory = []\n        self.CR_memory = []\n        self.memory_size = 10\n        self.success_F = []\n        self.success_CR = []\n        self.success_prob = 0.5\n        self.archive = []\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = []\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.success_count = 0\n\n        while self.evals < self.budget:\n            \n            old_fitness = self.fitness.copy()\n            \n            for i in range(self.pop_size):\n                # Mutation Strategy Selection: Combine best and random mutation\n                if np.random.rand() < self.success_prob:\n                    # Mutation using best individual\n                    best_idx = np.argmin(self.fitness)\n                    x_best = self.pop[best_idx]\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n                    mutant = x_best + self.F * (x_r1 - x_r2)\n                else:\n                    # Random mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.archive.append(self.pop[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n                    \n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        \n            # Adapt F and CR based on success\n            if len(self.success_F) > 0:\n                self.F = np.mean(self.success_F)\n                self.CR = np.mean(self.success_CR)\n                self.F = np.clip(np.random.normal(self.F, 0.3), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(self.CR, 0.1), 0.1, 1.0)\n                self.success_F = []\n                self.success_CR = []\n            else:\n                 # If no success, perturb F and CR slightly\n                self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(self.CR, 0.05), 0.1, 1.0)\n\n            #Adapt mutation strategy probability\n            if np.sum(self.fitness < old_fitness) > self.pop_size / 4:\n                self.success_prob = min(self.success_prob + 0.1, 0.9)\n            else:\n                self.success_prob = max(self.success_prob - 0.1, 0.1)\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE_Success scored 0.698 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8cd7d0f6-75d5-4153-8b12-6142f1f1730a"], "operator": null, "metadata": {"aucs": [0.2914668240657804, 0.6699928464829126, 0.8559127013393812, 0.8118378751608586, 0.8883901053225907, 0.9145966717091216, 0.7502408424172956, 0.4270413168067537, 0.8689390489315978, 0.6771117444203079, 0.9286962431386815, 0.9962095459243938, 0.44108958738075466, 0.7305083141522567, 0.9362047330462565, 0.8066179275074261, 0.41097141947306304, 0.8040238629143537, 0.2347585739513739, 0.5218587259362446]}}
{"id": "1cd162b5-1bfe-4add-9c9a-33d4fdebd6e4", "fitness": 0.6009485384672776, "name": "RankBasedAdaptiveDE", "description": "An adaptive differential evolution algorithm with a modified mutation strategy using a combination of rank-based selection and adaptive scaling factors.", "code": "import numpy as np\n\nclass RankBasedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7 # Initial crossover rate\n        self.F_memory = []\n        self.CR_memory = []\n        self.memory_size = 10\n        self.p = 0.1 # Probability of using best individual\n        self.rank_probability = np.array([i for i in range(1, self.pop_size+1)])\n        self.rank_probability = self.rank_probability / np.sum(self.rank_probability)\n\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = []\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            ranked_indices = np.argsort(self.fitness)\n            \n            for i in range(self.pop_size):\n                # Mutation\n                if np.random.rand() < self.p:\n                    best_idx = np.argmin(self.fitness)\n                    x_best = self.pop[best_idx]\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n                    mutant = x_best + self.F * (x_r1 - x_r2)\n                else:\n                    # Rank-based selection of individuals for mutation\n                    idx_r1 = np.random.choice(self.pop_size, p=self.rank_probability)\n                    idx_r2 = np.random.choice(self.pop_size, p=self.rank_probability)\n                    idx_r3 = np.random.choice(self.pop_size, p=self.rank_probability)\n                    \n                    x_r1, x_r2, x_r3 = self.pop[ranked_indices[idx_r1]], self.pop[ranked_indices[idx_r2]], self.pop[ranked_indices[idx_r3]]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n                \n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.archive.append(self.pop[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                # Adapt F and CR\n                if self.evals % (self.pop_size*2) == 0:\n                    self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                    self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm RankBasedAdaptiveDE scored 0.601 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8cd7d0f6-75d5-4153-8b12-6142f1f1730a"], "operator": null, "metadata": {"aucs": [0.23806682892699904, 0.46447332522182627, 0.5869131925933293, 0.8017183249581141, 0.6279456284824789, 0.7366564489016229, 0.3535302446427371, 0.5682291875036938, 0.7525914574569275, 0.5599964389878496, 0.7454633102027117, 0.9941733542471681, 0.4013971722577102, 0.6026073838079754, 0.8689891907250629, 0.7398219531859211, 0.43968536044816275, 0.7996102002265488, 0.24264834308682204, 0.4944534234818895]}}
{"id": "8bc814e8-1119-4c45-845b-f36e37386103", "fitness": -Infinity, "name": "HybridDEPSO", "description": "A population-based algorithm that combines the exploration of Differential Evolution with the exploitation of Particle Swarm Optimization, leveraging rank-based selection and velocity clamping to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, w=0.7, c1=1.5, c2=1.5, velocity_clamp=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.velocity_clamp = velocity_clamp\n\n    def __call__(self, func):\n        # Initialization\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.zeros((self.pop_size, self.dim))  # Initialize velocities to zero\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        pbest_population = population.copy()\n        pbest_fitness = fitness.copy()\n\n        gbest_index = np.argmin(fitness)\n        gbest_fitness = fitness[gbest_index]\n        gbest_position = population[gbest_index].copy()\n\n        # Optimization loop\n        while self.budget > 0:\n            # Rank the particles based on fitness\n            ranked_indices = np.argsort(fitness)\n\n            for i in range(self.pop_size):\n                # DE mutation\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                mutant = population[r1] + self.F * (population[r2] - population[r3])\n                mutant = np.clip(mutant, lb, ub) # boundary handling\n\n                # Crossover with PSO velocity update\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        # PSO velocity update\n                        r1_pso = np.random.rand()\n                        r2_pso = np.random.rand()\n\n                        # Calculate velocity update\n                        velocity_update = (self.w * velocities[i, j] +\n                                           self.c1 * r1_pso * (pbest_population[i, j] - population[i, j]) +\n                                           self.c2 * r2_pso * (gbest_position[j] - population[i, j]))\n\n                        # Clamp velocity to prevent divergence\n                        velocity_update = np.clip(velocity_update, -self.velocity_clamp * abs(ub - lb), self.velocity_clamp * abs(ub - lb))\n\n                        velocities[i, j] = velocity_update\n                        mutant[j] = population[i,j] + velocities[i,j]  # Apply velocity\n                        mutant[j] = np.clip(mutant[j], lb, ub) # boundary handling\n\n                    else:\n                        mutant[j] = population[i, j]  # Keep the original value\n                \n                # Evaluate the trial vector\n                trial_fitness = func(mutant)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = mutant\n                    fitness[i] = trial_fitness\n                    \n                    # Update personal best\n                    if trial_fitness < pbest_fitness[i]:\n                        pbest_fitness[i] = trial_fitness\n                        pbest_population[i] = mutant.copy()\n\n                        # Update global best\n                        if trial_fitness < gbest_fitness:\n                            gbest_fitness = trial_fitness\n                            gbest_position = mutant.copy()\n            if self.budget <= 0:\n                break\n\n        return gbest_fitness, gbest_position", "configspace": "", "generation": 1, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["042aa03d-ba7c-4a05-beed-4783ce3d2521"], "operator": null, "metadata": {}}
{"id": "61e58194-d988-4437-bd90-cd354e86b750", "fitness": 0.0, "name": "SHADE", "description": "A differential evolution strategy with self-adaptive parameters using a success-history based adaptation for F and CR, and a population reduction mechanism for balancing exploration and exploitation.", "code": "import numpy as np\n\nclass SHADE:\n    def __init__(self, budget=10000, dim=10, pop_size=100, memory_size=5, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.archive_size = archive_size\n        self.F_memory = np.full(self.memory_size, 0.5)\n        self.CR_memory = np.full(self.memory_size, 0.5)\n        self.memory_idx = 0\n        self.archive = []\n        self.p = 0.1\n        self.pop_size_min = 10\n        self.reduction_factor = 0.9\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.archive = []\n\n        while self.evals < self.budget:\n            old_pop = self.pop.copy()\n            for i in range(self.pop_size):\n                # Sample from memory\n                mem_idx = np.random.randint(self.memory_size)\n                F = self.F_memory[mem_idx]\n                CR = self.CR_memory[mem_idx]\n\n                # Mutation\n                if np.random.rand() < self.p:\n                    best_idx = np.argmin(self.fitness)\n                    x_best = self.pop[best_idx]\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n                    mutant = x_best + F * (x_r1 - x_r2)\n                else:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                    mutant = x_r1 + F * (x_r2 - x_r3)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.archive.append(self.pop[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Memory update\n            successful_idx = np.where(self.fitness < np.array([func(x) for x in old_pop]))[0] # Find successful individuals\n            if len(successful_idx) > 0:\n                SF = []\n                SCR = []\n                for idx in successful_idx:\n                    SF.append(self.F_memory[mem_idx])\n                    SCR.append(self.CR_memory[mem_idx])\n\n                if SF:\n                    SF = np.array(SF)\n                    SCR = np.array(SCR)\n\n                    self.F_memory[self.memory_idx] = np.mean(SF)\n                    self.CR_memory[self.memory_idx] = np.mean(SCR) # Simple mean\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n            \n            # Population Reduction\n            if self.evals > self.budget * 0.75 and self.pop_size > self.pop_size_min:\n                reduce_amount = max(int(self.pop_size * (1-self.reduction_factor)), 1)\n                \n                # Remove the worst individuals\n                worst_idx = np.argsort(self.fitness)[-reduce_amount:]\n                self.pop = np.delete(self.pop, worst_idx, axis=0)\n                self.fitness = np.delete(self.fitness, worst_idx)\n                self.pop_size = self.pop.shape[0]\n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm SHADE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8cd7d0f6-75d5-4153-8b12-6142f1f1730a"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "806613d4-965b-40d8-be41-44831024b3e6", "fitness": -Infinity, "name": "OrthogonalAdaptiveDE", "description": "An adaptive differential evolution algorithm that incorporates orthogonal learning to enhance exploration and exploitation by generating orthogonal arrays to sample the search space around promising solutions.", "code": "import numpy as np\nfrom pyDOE import *\n\nclass OrthogonalAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, orthogonal_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.orthogonal_samples = orthogonal_samples\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7 # Initial crossover rate\n        self.archive = []\n        self.success_F = []\n        self.success_CR = []\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation Strategy\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n                \n                # Orthogonal Learning: Generate orthogonal array around the trial point\n                if f_trial < self.fitness[i]:\n                    # Generate an orthogonal array\n                    oa = lhs(self.dim, samples=self.orthogonal_samples)\n\n                    # Scale and shift the orthogonal array to be centered around the trial solution\n                    oa_samples = trial + 0.1 * (oa - 0.5)  # Adjust scaling factor (0.1) as needed\n\n                    # Clip the samples to stay within the bounds\n                    oa_samples = np.clip(oa_samples, func.bounds.lb, func.bounds.ub)\n                    \n                    oa_fitness = np.array([func(x) for x in oa_samples])\n                    self.evals += self.orthogonal_samples\n\n                    # Select the best point from the orthogonal array samples\n                    best_oa_idx = np.argmin(oa_fitness)\n                    best_oa_sample = oa_samples[best_oa_idx]\n                    best_oa_fitness = oa_fitness[best_oa_idx]\n                    \n                    if best_oa_fitness < f_trial:\n                        trial = best_oa_sample\n                        f_trial = best_oa_fitness\n                        \n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.archive.append(self.pop[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n                    \n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and CR based on success\n            if len(self.success_F) > 0:\n                self.F = np.mean(self.success_F)\n                self.CR = np.mean(self.success_CR)\n                self.F = np.clip(np.random.normal(self.F, 0.3), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(self.CR, 0.1), 0.1, 1.0)\n                self.success_F = []\n                self.success_CR = []\n            else:\n                 # If no success, perturb F and CR slightly\n                self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(self.CR, 0.05), 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: No module named 'pyDOE'.", "error": "", "parent_ids": ["2785c2d1-5a03-4a69-bb00-b80e2155eed0"], "operator": null, "metadata": {}}
{"id": "60344b2f-b3dd-4921-98ec-d99e56703f8f", "fitness": 0.0, "name": "CooperativeScouts", "description": "Cooperative Scouts with Adaptive Step Size and Gradient Estimation, where scouts share information about gradients and adjust their step size based on success and estimated gradient information.", "code": "import numpy as np\n\nclass CooperativeScouts:\n    def __init__(self, budget=10000, dim=10, num_scouts=20, scout_memory=5, initial_step_size=0.1, gradient_estimation_samples=5):\n        self.budget = budget\n        self.dim = dim\n        self.num_scouts = num_scouts\n        self.scout_memory = scout_memory\n        self.step_size = initial_step_size\n        self.step_size_reduction_factor = 0.8\n        self.step_size_increase_factor = 1.2\n        self.success_threshold = 0.1\n        self.gradient_estimation_samples = gradient_estimation_samples\n\n        self.scouts = None\n        self.fitness = None\n        self.scout_moves = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.evals = 0\n        self.gradient_estimates = None\n\n    def initialize_scouts(self, func):\n        self.scouts = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_scouts, self.dim))\n        self.fitness = np.array([func(x) for x in self.scouts])\n        self.evals += self.num_scouts\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.scouts[np.argmin(self.fitness)].copy()\n        self.scout_moves = [[] for _ in range(self.num_scouts)]\n        self.gradient_estimates = np.zeros((self.num_scouts, self.dim))  # Initialize gradient estimates\n\n\n    def estimate_gradient(self, func, x):\n        \"\"\"Estimates the gradient using finite differences.\"\"\"\n        gradient = np.zeros(self.dim)\n        for i in range(self.dim):\n            # Generate small perturbation in both directions\n            perturbation = np.zeros(self.dim)\n            perturbation[i] = self.step_size  # Use current step size as perturbation\n            x_plus = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            x_minus = np.clip(x - perturbation, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate function at perturbed points\n            f_plus = func(x_plus)\n            f_minus = func(x_minus)\n            self.evals += 2\n\n            # Approximate gradient component\n            gradient[i] = (f_plus - f_minus) / (2 * self.step_size)  # Central difference\n\n        return gradient\n\n\n    def __call__(self, func):\n        self.initialize_scouts(func)\n\n        while self.evals < self.budget:\n            for i in range(self.num_scouts):\n                # Estimate gradient\n                if self.evals < self.budget:\n                    self.gradient_estimates[i] = self.estimate_gradient(func, self.scouts[i])\n\n                # Generate a move biased by the estimated gradient\n                move = np.random.normal(0, self.step_size, size=self.dim) - 0.5 * self.step_size * self.gradient_estimates[i]  # Incorporate gradient\n                new_position = self.scouts[i] + move\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.evals += 1\n\n                # Check if the move was successful\n                if new_fitness < self.fitness[i]:\n                    # Update scout's position and fitness\n                    self.scouts[i] = new_position\n                    self.fitness[i] = new_fitness\n                    self.scout_moves[i].append(True)\n                    if len(self.scout_moves[i]) > self.scout_memory:\n                        self.scout_moves[i].pop(0)\n\n                    # Update best solution if necessary\n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_position = new_position.copy()\n\n                    # Increase step size if scout is consistently successful\n                    if len(self.scout_moves[i]) == self.scout_memory and all(self.scout_moves[i]):\n                        self.step_size *= self.step_size_increase_factor\n\n                else:\n                    self.scout_moves[i].append(False)\n                    if len(self.scout_moves[i]) > self.scout_memory:\n                        self.scout_moves[i].pop(0)\n\n                    # Reduce step size if scout is consistently unsuccessful\n                    if len(self.scout_moves[i]) == self.scout_memory and not any(self.scout_moves[i]):\n                        self.step_size *= self.step_size_reduction_factor\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 2, "feedback": "The algorithm CooperativeScouts scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["217c843d-bcf3-4905-b01d-f307d7770fac"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "4f270c14-2295-4da9-ba4e-6774ff081309", "fitness": 0.0, "name": "GradientAdaptiveScouts", "description": "A scout-based algorithm with dynamic population management and adaptive step sizes based on local gradient estimation.", "code": "import numpy as np\n\nclass GradientAdaptiveScouts:\n    def __init__(self, budget=10000, dim=10, num_scouts=20, initial_step_size=0.1, population_decay=0.99, gradient_estimation_radius=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.num_scouts = num_scouts\n        self.initial_step_size = initial_step_size\n        self.step_size = initial_step_size\n        self.population_decay = population_decay\n        self.gradient_estimation_radius = gradient_estimation_radius\n        self.scouts = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.evals = 0\n\n    def initialize_scouts(self, func):\n        self.scouts = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_scouts, self.dim))\n        self.fitness = np.array([func(x) for x in self.scouts])\n        self.evals += self.num_scouts\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.scouts[np.argmin(self.fitness)].copy()\n\n    def estimate_gradient(self, func, x):\n        gradient = np.zeros(self.dim)\n        for i in range(self.dim):\n            x_plus = x.copy()\n            x_minus = x.copy()\n            x_plus[i] += self.gradient_estimation_radius\n            x_minus[i] -= self.gradient_estimation_radius\n            x_plus[i] = np.clip(x_plus[i], func.bounds.lb[i], func.bounds.ub[i])\n            x_minus[i] = np.clip(x_minus[i], func.bounds.lb[i], func.bounds.ub[i])\n\n            gradient[i] = (func(x_plus) - func(x_minus)) / (2 * self.gradient_estimation_radius)\n            self.evals += 2\n            if self.evals >= self.budget:\n                return None # Budget exceeded\n        return gradient\n\n    def __call__(self, func):\n        self.initialize_scouts(func)\n\n        while self.evals < self.budget:\n            # Sort scouts based on fitness\n            sorted_indices = np.argsort(self.fitness)\n            self.scouts = self.scouts[sorted_indices]\n            self.fitness = self.fitness[sorted_indices]\n\n            # Reduce population size if needed\n            num_scouts_to_keep = max(1, int(self.num_scouts * self.population_decay))\n            if num_scouts_to_keep < self.num_scouts:\n                self.scouts = self.scouts[:num_scouts_to_keep]\n                self.fitness = self.fitness[:num_scouts_to_keep]\n                self.num_scouts = num_scouts_to_keep\n\n            for i in range(self.num_scouts):\n                # Estimate local gradient\n                gradient = self.estimate_gradient(func, self.scouts[i])\n                if gradient is None:\n                    break # Budget exceeded\n\n                # Move scout in the opposite direction of the gradient\n                move = -self.step_size * gradient\n                new_position = self.scouts[i] + move\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.evals += 1\n\n                # Update scout's position and fitness if the move was successful\n                if new_fitness < self.fitness[i]:\n                    self.scouts[i] = new_position\n                    self.fitness[i] = new_fitness\n\n                    # Update best solution if necessary\n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_position = new_position.copy()\n\n            # Add new scouts to maintain population size\n            num_new_scouts = 20 - self.num_scouts  # Constant population size of 20\n            if num_new_scouts > 0 and self.evals < self.budget:\n                new_scouts = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new_scouts, self.dim))\n                new_fitness = np.array([func(x) for x in new_scouts])\n                self.evals += num_new_scouts\n\n                self.scouts = np.vstack((self.scouts, new_scouts))\n                self.fitness = np.concatenate((self.fitness, new_fitness))\n                self.num_scouts = 20 # Set population size to 20 again\n                \n                # Update best solution\n                best_index = np.argmin(self.fitness)\n                if self.fitness[best_index] < self.best_fitness:\n                    self.best_fitness = self.fitness[best_index]\n                    self.best_position = self.scouts[best_index].copy()\n\n\n                if self.evals >= self.budget:\n                    break\n\n            # Adaptive step size adjustment (simple example)\n            if self.best_fitness < np.min(self.fitness):\n                self.step_size *= 1.05\n            else:\n                self.step_size *= 0.95\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 2, "feedback": "The algorithm GradientAdaptiveScouts scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["217c843d-bcf3-4905-b01d-f307d7770fac"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "b2d1eed2-6f29-4778-bf53-37fa6e3fbd79", "fitness": 0.0, "name": "AdaptiveDEOppCauchy", "description": "An adaptive differential evolution algorithm with a novel mutation strategy based on opposition-based learning and a Cauchy distribution to enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveDEOppCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=2.0, f=0.5, cr=0.9, alpha=0.1, beta=0.1, gamma=0.01, success_history_length=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(10 + np.ceil(np.log(self.dim)))\n        self.archive_size = archive_size\n        self.F = f\n        self.CR = cr\n        self.alpha = alpha\n        self.beta = beta\n        self.gamma = gamma\n        self.success_history_length = success_history_length\n        self.success_history_F = []\n        self.success_history_CR = []\n        self.success_history_successes = []\n\n    def opposition_based_learning(self, x, lb, ub):\n        \"\"\"Performs opposition-based learning to generate an opposite point.\"\"\"\n        return lb + ub - x\n\n    def cauchy_mutation(self, x, scale):\n        \"\"\"Applies Cauchy mutation to a vector.\"\"\"\n        return x + scale * np.random.standard_cauchy(size=self.dim)\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n\n        # Initialize with opposition-based population\n        opposition_population = np.array([self.opposition_based_learning(x, func.bounds.lb, func.bounds.ub) for x in self.population])\n        self.population = np.concatenate([self.population, opposition_population], axis=0)\n        self.pop_size *= 2 #double population size\n\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        for i in range(self.pop_size):\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = self.population[i]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            \n            # Adaptive Parameter Control using Success History\n            if self.success_history_F:\n                self.F = np.clip(np.random.choice(self.success_history_F), 0.1, 1.0)\n                self.CR = np.clip(np.random.choice(self.success_history_CR), 0.1, 1.0)\n            else:\n                self.F = np.clip(np.random.normal(self.F, self.alpha), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(self.CR, self.beta), 0.1, 1.0)\n\n            successful_F = []\n            successful_CR = []\n            num_successes = 0\n\n            for j in range(self.pop_size):\n                # Mutation: Use Cauchy mutation with probability 0.2, otherwise DE mutation\n                if np.random.rand() < 0.2:\n                    mutant = self.cauchy_mutation(self.population[j], scale=self.F)\n                else:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(cross_mask, mutant, self.population[j])\n                \n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                if f_trial < fitness[j]:\n                    num_successes += 1\n                    successful_F.append(self.F)\n                    successful_CR.append(self.CR)\n                    \n                    fitness[j] = f_trial\n                    self.population[j] = trial_vector\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                        \n                else:\n                    # Archive the replaced individuals\n                    if len(self.archive) < self.pop_size * self.archive_size:\n                        self.archive.append(self.population[j])\n                    else:\n                        idx_to_replace = np.random.randint(0, len(self.archive))\n                        self.archive[idx_to_replace] = self.population[j]\n\n            # Update Success History\n            self.success_history_F.extend(successful_F)\n            self.success_history_CR.extend(successful_CR)\n            self.success_history_successes.append(num_successes / self.pop_size)\n\n            if len(self.success_history_successes) > self.success_history_length:\n                self.success_history_F = self.success_history_F[-len(successful_F)*self.success_history_length:]\n                self.success_history_CR = self.success_history_CR[-len(successful_CR)*self.success_history_length:]\n                self.success_history_successes = self.success_history_successes[-self.success_history_length:]\n\n\n            # Population Size Adaptation based on Success Rate\n            mean_success_rate = np.mean(self.success_history_successes) if self.success_history_successes else 0.1\n            if mean_success_rate > 0.2 and self.pop_size < 2 * self.dim:\n                self.pop_size = min(2 * self.dim, self.pop_size + 1)\n                new_individual = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(1, self.dim))\n                self.population = np.concatenate([self.population, new_individual], axis=0)\n                new_fitness = func(new_individual[0])\n                fitness = np.concatenate([fitness, [new_fitness]])\n                self.budget -= 1\n                if new_fitness < self.f_opt:\n                    self.f_opt = new_fitness\n                    self.x_opt = new_individual[0]\n            elif mean_success_rate < 0.05 and self.pop_size > 5:\n                # Remove worst individual\n                worst_index = np.argmax(fitness)\n                self.population = np.delete(self.population, worst_index, axis=0)\n                fitness = np.delete(fitness, worst_index)\n                self.pop_size -= 1\n\n            # Trim the archive to keep its size manageable\n            self.archive = self.archive[:int(self.pop_size * self.archive_size)]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDEOppCauchy scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9413aa29-1405-4974-882e-2c66d0c0ac0a"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "638183d0-3363-4ffd-8442-faa20e0078e8", "fitness": 0.0, "name": "AdaptiveDEMultiMutationRestart", "description": "An adaptive differential evolution algorithm that uses a combination of multiple mutation strategies selected based on their recent performance and includes a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDEMultiMutationRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, mutation_strategies = [\"current_to_best\", \"rand_1\", \"rand_2\", \"current_to_rand\"]):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7 # Initial crossover rate\n        self.mutation_strategies = mutation_strategies\n        self.strategy_weights = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.archive = []\n        self.restart_interval = budget // 10 # Restart every 10% of budget\n        self.last_restart = 0\n\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = []\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.success_count = 0\n        self.strategy_successes = np.zeros(len(self.mutation_strategies))\n\n        while self.evals < self.budget:\n            \n            old_fitness = self.fitness.copy()\n            \n            for i in range(self.pop_size):\n                # Mutation Strategy Selection: Roulette wheel selection based on weights\n                strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.strategy_weights)\n                mutation_strategy = self.mutation_strategies[strategy_idx]\n                \n                if mutation_strategy == \"current_to_best\":\n                    # Mutation using best individual\n                    best_idx = np.argmin(self.fitness)\n                    x_best = self.pop[best_idx]\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n                    mutant = self.pop[i] + self.F * (x_best - self.pop[i]) + self.F * (x_r1 - x_r2)\n                elif mutation_strategy == \"rand_1\":\n                    # Random mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n                elif mutation_strategy == \"rand_2\":\n                     # Random mutation\n                    idxs = np.random.choice(self.pop_size, 5, replace=False)\n                    x_r1, x_r2, x_r3, x_r4, x_r5 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]], self.pop[idxs[3]], self.pop[idxs[4]]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3) + self.F * (x_r4 - x_r5)\n\n                elif mutation_strategy == \"current_to_rand\":\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                    mutant = self.pop[i] + self.F * (x_r1 - self.pop[i]) + self.F * (x_r2 - x_r3)\n                else:\n                    raise ValueError(\"Unknown mutation strategy\")\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.archive.append(self.pop[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                    self.strategy_successes[strategy_idx] += 1 #Increase success of selected strategy\n                        \n            # Adapt strategy weights based on success\n            self.strategy_weights = (1 - 0.1) * self.strategy_weights + 0.1 * (self.strategy_successes / np.sum(self.strategy_successes))\n            self.strategy_weights /= np.sum(self.strategy_weights) # Normalize\n            self.strategy_successes = np.zeros(len(self.mutation_strategies)) #Reset successes\n            \n\n            # Restart mechanism\n            if self.evals - self.last_restart > self.restart_interval:\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.pop[best_idx]\n                self.last_restart = self.evals\n            \n                # Perturb F and CR after restart\n                self.F = np.clip(np.random.normal(0.5, 0.2), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n                \n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDEMultiMutationRestart scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2785c2d1-5a03-4a69-bb00-b80e2155eed0"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "9129626b-7e05-445f-9d0b-05d88a7b1862", "fitness": 0.17763300470161436, "name": "ImprovedSelfOrganizingScouts", "description": "An improved Self-Organizing Scouts algorithm that incorporates a global best influence and a dynamic inertia weight to balance exploration and exploitation.", "code": "import numpy as np\n\nclass ImprovedSelfOrganizingScouts:\n    def __init__(self, budget=10000, dim=10, num_scouts=20, scout_memory=5, initial_step_size=0.1, inertia_weight=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.num_scouts = num_scouts\n        self.scout_memory = scout_memory\n        self.step_size = initial_step_size\n        self.step_size_reduction_factor = 0.9\n        self.step_size_increase_factor = 1.1\n        self.success_threshold = 0.1  # Threshold for considering a move successful\n        self.inertia_weight = inertia_weight  # Inertia weight for controlling exploration/exploitation\n\n        self.scouts = None\n        self.fitness = None\n        self.scout_moves = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.evals = 0\n\n    def initialize_scouts(self, func):\n        self.scouts = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_scouts, self.dim))\n        self.fitness = np.array([func(x) for x in self.scouts])\n        self.evals += self.num_scouts\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.scouts[np.argmin(self.fitness)].copy()\n        self.scout_moves = [[] for _ in range(self.num_scouts)] # Keep track of recent moves\n\n\n    def __call__(self, func):\n        self.initialize_scouts(func)\n\n        while self.evals < self.budget:\n            for i in range(self.num_scouts):\n                # Generate a move influenced by inertia and the global best\n                inertia = self.inertia_weight * (self.scouts[i] - self.best_position)\n\n                move = np.random.normal(0, self.step_size, size=self.dim) + inertia\n                new_position = self.scouts[i] + move\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.evals += 1\n\n                # Check if the move was successful\n                if new_fitness < self.fitness[i]:\n                    # Update scout's position and fitness\n                    self.scouts[i] = new_position\n                    self.fitness[i] = new_fitness\n                    self.scout_moves[i].append(True) # Store succesful move\n                    if len(self.scout_moves[i]) > self.scout_memory:\n                        self.scout_moves[i].pop(0) # Limit memory\n                    \n                    # Update best solution if necessary\n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_position = new_position.copy()\n\n                    # Increase step size if scout is consistently successful\n                    if len(self.scout_moves[i]) == self.scout_memory and all(self.scout_moves[i]):\n                         self.step_size *= self.step_size_increase_factor\n\n                else:\n                     self.scout_moves[i].append(False)  # Store unsuccesful move\n                     if len(self.scout_moves[i]) > self.scout_memory:\n                         self.scout_moves[i].pop(0)  # Limit memory\n                         \n                     # Reduce step size if scout is consistently unsuccessful\n                     if len(self.scout_moves[i]) == self.scout_memory and not any(self.scout_moves[i]):\n                         self.step_size *= self.step_size_reduction_factor\n                         \n\n                if self.evals >= self.budget:\n                    break\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 2, "feedback": "The algorithm ImprovedSelfOrganizingScouts scored 0.178 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["217c843d-bcf3-4905-b01d-f307d7770fac"], "operator": null, "metadata": {"aucs": [0.10154679467617111, 0.16944975602395407, 0.21459926017770836, 0.14585953093933535, 0.15874896795199545, 0.18452785671884886, 0.17463586095168648, 0.10162755017914238, 0.1545775203120351, 0.1281297637240546, 0.16030982303289454, 0.22371285457572654, 0.20691369756525213, 0.15302426245568945, 0.1309333764904148, 0.21102188015147216, 0.17709394733725126, 0.23366420557612655, 0.1218815971876509, 0.400401588004877]}}
{"id": "92ab55b3-bd43-4f54-8618-959524638a82", "fitness": 0.2909816037258013, "name": "AdaptiveScoutOptimization", "description": "An adaptive scout-based algorithm that uses a combination of global and local search, dynamically adjusting the step size based on the scout's performance and the global best solution.", "code": "import numpy as np\n\nclass AdaptiveScoutOptimization:\n    def __init__(self, budget=10000, dim=10, num_scouts=20, scout_memory=5, initial_step_size=0.1, global_attraction=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.num_scouts = num_scouts\n        self.scout_memory = scout_memory\n        self.step_size = initial_step_size\n        self.step_size_reduction_factor = 0.8\n        self.step_size_increase_factor = 1.2\n        self.global_attraction = global_attraction  # Attraction towards the global best\n        self.success_threshold = 0.1  # Threshold for considering a move successful\n\n        self.scouts = None\n        self.fitness = None\n        self.scout_moves = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.evals = 0\n\n    def initialize_scouts(self, func):\n        self.scouts = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_scouts, self.dim))\n        self.fitness = np.array([func(x) for x in self.scouts])\n        self.evals += self.num_scouts\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.scouts[np.argmin(self.fitness)].copy()\n        self.scout_moves = [[] for _ in range(self.num_scouts)] # Keep track of recent moves\n\n\n    def __call__(self, func):\n        self.initialize_scouts(func)\n\n        while self.evals < self.budget:\n            for i in range(self.num_scouts):\n                # Generate a random move with global attraction\n                global_attraction_vector = self.global_attraction * (self.best_position - self.scouts[i])\n                move = np.random.normal(0, self.step_size, size=self.dim) + global_attraction_vector\n                new_position = self.scouts[i] + move\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.evals += 1\n\n                # Check if the move was successful\n                if new_fitness < self.fitness[i]:\n                    # Update scout's position and fitness\n                    self.scouts[i] = new_position\n                    self.fitness[i] = new_fitness\n                    self.scout_moves[i].append(True) # Store succesful move\n                    if len(self.scout_moves[i]) > self.scout_memory:\n                        self.scout_moves[i].pop(0) # Limit memory\n                    \n                    # Update best solution if necessary\n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_position = new_position.copy()\n\n                    # Increase step size if scout is consistently successful\n                    if len(self.scout_moves[i]) == self.scout_memory and all(self.scout_moves[i]):\n                         self.step_size *= self.step_size_increase_factor\n\n                else:\n                     self.scout_moves[i].append(False)  # Store unsuccesful move\n                     if len(self.scout_moves[i]) > self.scout_memory:\n                         self.scout_moves[i].pop(0)  # Limit memory\n                         \n                     # Reduce step size if scout is consistently unsuccessful\n                     if len(self.scout_moves[i]) == self.scout_memory and not any(self.scout_moves[i]):\n                         self.step_size *= self.step_size_reduction_factor\n\n                # Adjust global attraction based on best fitness improvement\n                if self.evals > self.num_scouts:\n                  improvement = (self.best_fitness - np.min(self.fitness)) / self.best_fitness\n                  if improvement < -0.001: #Significant improvement\n                      self.global_attraction *= 1.1\n                  elif improvement > 0.001: #Degradation\n                      self.global_attraction *= 0.9\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveScoutOptimization scored 0.291 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["217c843d-bcf3-4905-b01d-f307d7770fac"], "operator": null, "metadata": {"aucs": [0.09853293879609304, 0.1699483111779977, 0.2555820254723523, 0.13642873013986612, 0.14262393074483193, 0.21325148459279153, 0.18406727192348749, 0.19669210138578397, 0.17867795794911345, 0.15120887185080878, 0.2378584767108214, 0.9986513064048426, 0.2545145789927602, 0.17895572702096252, 0.7884530456519809, 0.29961483697276825, 0.226894280735631, 0.5539793965196722, 0.13129985460792648, 0.4223969468655343]}}
{"id": "8e38b6be-2b6b-4033-89a2-409b10b8f379", "fitness": 0.3842901877343357, "name": "LevyDE", "description": "A differential evolution strategy that incorporates a Lvy flight distribution to enhance exploration and escape local optima.", "code": "import numpy as np\n\nclass LevyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, levy_exponent=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.levy_exponent = levy_exponent  # Exponent for Levy distribution\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7  # Initial crossover rate\n\n    def levy_flight(self, size):\n        \"\"\"\n        Generate Levy distribution samples.\n        \"\"\"\n        num = np.random.normal(0, 1, size)\n        den = np.abs(np.random.normal(0, 1, size))**(1/self.levy_exponent)\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) / (np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * 2**((self.levy_exponent - 1) / 2)))**(1/self.levy_exponent)\n        return sigma * (num / den)\n    \n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation using Levy flight\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                levy_step = self.levy_flight(self.dim)\n                mutant = x_r1 + self.F * (x_r2 - x_r3) + levy_step * (self.x_opt - self.pop[i])\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Adjust F and CR (optional - can be removed or modified)\n            self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm LevyDE scored 0.384 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2785c2d1-5a03-4a69-bb00-b80e2155eed0"], "operator": null, "metadata": {"aucs": [0.1539186177580113, 0.19920361239751838, 0.34135422761392575, 0.5194841987471002, 0.32415721745974624, 0.45777356782585776, 0.30196410784190963, 0.3467858462318514, 0.31855787384067213, 0.20934535884566696, 0.3356681558749196, 0.9950362908697394, 0.2700508846520856, 0.3279159169399428, 0.6897065568817498, 0.42065391583163436, 0.2934528024442472, 0.5135247585095687, 0.18947536525627007, 0.4777744788642969]}}
{"id": "d193e4b3-7ebe-49d6-bf53-557ffc5c8b13", "fitness": 0.5986212047823358, "name": "AdaptiveDE_Cauchy", "description": "An adaptive differential evolution algorithm employing a probabilistic combination of different mutation strategies based on their recent success, while also incorporating a Cauchy distribution for generating scaling factors to enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveDE_Cauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7 # Initial crossover rate\n        self.mutation_strategies = ['current_to_best', 'rand_1', 'rand_2']\n        self.mutation_probs = [0.33, 0.33, 0.34]  # Initial probabilities for each strategy\n        self.success_counts = [0, 0, 0]\n        self.archive = []\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = []\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation Strategy Selection (Probabilistic)\n                mutation_strategy = np.random.choice(self.mutation_strategies, p=self.mutation_probs)\n\n                if mutation_strategy == 'current_to_best':\n                    best_idx = np.argmin(self.fitness)\n                    x_best = self.pop[best_idx]\n                    idxs = np.random.choice(self.pop_size, 1, replace=False) #changed 2 to 1\n                    x_r1 = self.pop[idxs[0]]\n                    mutant = self.pop[i] + self.cauchy_mutation(0.5) * (x_best - self.pop[i]) + self.cauchy_mutation(0.5) * (x_r1 - self.pop[i]) #modified mutation\n\n                    mutation_index = 0\n                elif mutation_strategy == 'rand_1':\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                    mutant = x_r1 + self.cauchy_mutation(0.5) * (x_r2 - x_r3) #modified mutation\n                    mutation_index = 1\n                elif mutation_strategy == 'rand_2':\n                    idxs = np.random.choice(self.pop_size, 5, replace=False)\n                    x_r1, x_r2, x_r3, x_r4, x_r5 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]], self.pop[idxs[3]], self.pop[idxs[4]]\n                    mutant = x_r1 + self.cauchy_mutation(0.5) * (x_r2 - x_r3) + self.cauchy_mutation(0.5) * (x_r4 - x_r5) #modified mutation\n                    mutation_index = 2\n                else:\n                    raise ValueError(\"Invalid mutation strategy\")\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.archive.append(self.pop[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    self.success_counts[mutation_index] += 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Adapt mutation probabilities based on success counts\n            total_success = sum(self.success_counts)\n            if total_success > 0:\n                self.mutation_probs = [count / total_success for count in self.success_counts]\n            else:\n                # Reset if no success\n                self.mutation_probs = [1/len(self.mutation_strategies)] * len(self.mutation_strategies)\n\n            self.success_counts = [0] * len(self.mutation_strategies)\n\n\n        return self.f_opt, self.x_opt\n\n    def cauchy_mutation(self, scale):\n          return np.random.standard_cauchy() * scale", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE_Cauchy scored 0.599 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2785c2d1-5a03-4a69-bb00-b80e2155eed0"], "operator": null, "metadata": {"aucs": [0.20515660877177344, 0.5192481276698371, 0.5649657539697728, 0.8028819683994853, 0.6513734370889612, 0.703224318816424, 0.5496155542467137, 0.5586878222519933, 0.6368706644236553, 0.576405982745578, 0.8329697251599831, 0.9974522340305192, 0.3313175066202335, 0.44795859581411435, 0.8256670228718173, 0.7537559669689925, 0.4850745069191009, 0.7987961815851656, 0.2083546957949567, 0.5226474214976402]}}
{"id": "7a665562-5410-4b8f-b00a-24ac6fa4f63f", "fitness": 0.0, "name": "RestartAdaptiveDE", "description": "Implements a Differential Evolution strategy with a periodically restarted population and dynamically adjusted mutation parameters using a success-based adaptation.", "code": "import numpy as np\n\nclass RestartAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, f=0.5, cr=0.9, alpha_f=0.1, alpha_cr=0.1, restart_interval=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(10 + np.ceil(np.log(self.dim)))\n        self.F = f\n        self.CR = cr\n        self.alpha_f = alpha_f\n        self.alpha_cr = alpha_cr\n        self.restart_interval = restart_interval\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = self.population[i]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            # Parameter adaptation\n            self.F = np.clip(np.random.normal(self.F, self.alpha_f), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(self.CR, self.alpha_cr), 0.1, 1.0)\n\n            for j in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(cross_mask, mutant, self.population[j])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[j]:\n                    fitness[j] = f_trial\n                    self.population[j] = trial_vector\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n            self.best_fitness_history.append(self.f_opt)\n\n            # Population restart\n            if generation % self.restart_interval == 0:\n                # Replace a portion of the population with new random individuals\n                num_to_replace = int(0.2 * self.pop_size)\n                replace_indices = np.random.choice(self.pop_size, num_to_replace, replace=False)\n                self.population[replace_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_replace, self.dim))\n                \n                # Evaluate the new individuals\n                for idx in replace_indices:\n                    fitness[idx] = func(self.population[idx])\n                    self.budget -= 1\n                    if fitness[idx] < self.f_opt:\n                        self.f_opt = fitness[idx]\n                        self.x_opt = self.population[idx]\n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm RestartAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9413aa29-1405-4974-882e-2c66d0c0ac0a"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "8b9ff39a-b7a6-4d56-993c-af44cdb2e869", "fitness": -Infinity, "name": "OrthogonalDE", "description": "A differential evolution algorithm that leverages orthogonal learning to generate diverse candidate solutions, combined with adaptive parameter control based on the success rate.", "code": "import numpy as np\n\nclass OrthogonalDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7  # Initial crossover rate\n        self.F_memory = []\n        self.CR_memory = []\n        self.memory_size = 10\n        self.p = 0.1  # Probability of using orthogonal learning\n        self.levy_exponent = 1.5\n        self.learning_rate = 0.1\n        self.success_rate = 0.0\n\n    def levy_flight(self, size):\n        w = np.random.normal(0, 1, size=size)\n        v = np.random.normal(0, 1, size=size)\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) / (np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * (2 ** ((self.levy_exponent - 1) / 2)))) ** (1 / self.levy_exponent)\n        step = sigma * w / (np.abs(v) ** (1 / self.levy_exponent))\n        return step\n\n    def orthogonal_design(self, population, num_params):\n         # Generate a Latin Hypercube Sample (LHS)\n        lhs = np.random.rand(num_params, num_params)\n\n        # Orthogonalize the LHS using Gram-Schmidt process\n        Q, R = np.linalg.qr(lhs)\n\n        # Map the orthogonal matrix to the population space\n        orthogonal_points = np.zeros((num_params, self.dim))\n\n        for i in range(num_params):\n          for j in range(self.dim):\n             idx = j % num_params\n             orthogonal_points[i,j] = population[i, idx] + Q[i, idx] * (np.max(population[:, idx]) - np.min(population[:, idx]))\n        return orthogonal_points\n    \n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = []\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        success_count = 0\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                if np.random.rand() < self.p:\n                    # Orthogonal Learning\n                    orthogonal_points = self.orthogonal_design(self.pop.copy(), self.pop_size)\n                    idx = np.random.randint(0, self.pop_size)\n                    mutant = orthogonal_points[idx]\n                else:\n                    # Standard DE mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.archive.append(self.pop[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    success_count += 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Adaptive parameter control\n            self.success_rate = success_count / self.pop_size\n            self.F = np.clip(self.F + self.learning_rate * (self.success_rate - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.learning_rate * (self.success_rate - 0.5), 0.1, 1.0)\n            success_count = 0 # Reset success count after each generation\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: Evaluation timed out after 60 seconds..", "error": "", "parent_ids": ["1cd162b5-1bfe-4add-9c9a-33d4fdebd6e4"], "operator": null, "metadata": {}}
{"id": "a32fc792-6231-4baa-a79b-dde4ea4dc91f", "fitness": 0.4915949165678658, "name": "RingTopologyAdaptiveDE", "description": "An adaptive differential evolution algorithm with a ring topology-based mutation strategy and self-adaptive parameter control.", "code": "import numpy as np\n\nclass RingTopologyAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, f=0.5, cr=0.9, alpha=0.1, beta=0.1, topology_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(10 + np.ceil(np.log(self.dim)))\n        self.F = f\n        self.CR = cr\n        self.alpha = alpha\n        self.beta = beta\n        self.topology_size = topology_size\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = self.population[i]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive Parameter Control\n                self.F = np.clip(np.random.normal(self.F, self.alpha), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(self.CR, self.beta), 0.1, 1.0)\n\n                # Ring Topology Selection\n                neighbors = [(i + j) % self.pop_size for j in range(1, self.topology_size // 2 + 1)] + \\\n                            [(i - j) % self.pop_size for j in range(1, self.topology_size // 2 + 1)]\n                \n                idxs = np.random.choice(neighbors, 2, replace=False)\n                x1, x2 = self.population[idxs]\n                x_best = self.population[np.argmin(fitness[neighbors])]\n\n                # Mutation\n                mutant = self.population[i] + self.F * (x_best - self.population[i]) + self.F * (x1 - x2)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(cross_mask, mutant, self.population[i])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm RingTopologyAdaptiveDE scored 0.492 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9413aa29-1405-4974-882e-2c66d0c0ac0a"], "operator": null, "metadata": {"aucs": [0.13485707493332977, 0.2692904181040029, 0.4571957348112986, 0.33014338899967244, 0.6924193507527471, 0.42191063134949147, 0.2983883558809747, 0.27575443875741845, 0.8217139094962538, 0.19994154263270703, 0.815251247221951, 0.9966894165037167, 0.3283907511734758, 0.4618240617099818, 0.8458875222164339, 0.621120254985717, 0.4228190100095438, 0.6996419058836446, 0.23234185953236752, 0.5063174564025876]}}
{"id": "ba3e32a8-2a27-46b8-997c-fdaba710991e", "fitness": 0.0, "name": "GradientAdaptiveDE", "description": "An adaptive differential evolution algorithm that adjusts mutation strength based on the local gradient of the objective function, estimated using finite differences.", "code": "import numpy as np\n\nclass GradientAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, delta=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial scaling factor\n        self.CR = CR  # Initial crossover rate\n        self.delta = delta # Step size for gradient estimation\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Estimate gradient magnitude\n                gradient_magnitude = self.estimate_gradient_magnitude(func, self.pop[i])\n\n                # Adjust mutation strength based on gradient magnitude\n                adaptive_F = self.F * (1 + gradient_magnitude)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                mutant = x_r1 + adaptive_F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt\n\n    def estimate_gradient_magnitude(self, func, x):\n        gradient = np.zeros(self.dim)\n        for j in range(self.dim):\n            x_plus = x.copy()\n            x_minus = x.copy()\n            x_plus[j] += self.delta\n            x_minus[j] -= self.delta\n\n            x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n            x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n\n            gradient[j] = (func(x_plus) - func(x_minus)) / (2 * self.delta)\n            self.evals += 2  # Account for the function evaluations\n            if self.evals >= self.budget:\n                break #budget check\n\n        return np.linalg.norm(gradient)", "configspace": "", "generation": 3, "feedback": "The algorithm GradientAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d193e4b3-7ebe-49d6-bf53-557ffc5c8b13"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "f8916bb0-004d-41ce-b0fc-a74145426e5c", "fitness": -Infinity, "name": "MirroredAdaptiveDE", "description": "An adaptive differential evolution algorithm that employs a novel mirrored mutation strategy to enhance exploration by reflecting individuals across the search space boundaries, dynamically adjusting the scaling factor, and incorporating a self-adaptive crossover rate based on the individual's success.", "code": "import numpy as np\n\nclass MirroredAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7 # Initial crossover rate\n        self.CR_decay = 0.995 # Decay rate for the Crossover Rate\n        self.F_decay = 0.995 # Decay rate for scaling factor\n        self.F_increase = 1.005 #Increase rate for scaling factor\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n\n                # Mirrored boundary handling\n                for j in range(self.dim):\n                    if mutant[j] < self.lb:\n                        mutant[j] = self.lb + (self.lb - mutant[j])\n                    elif mutant[j] > self.ub:\n                        mutant[j] = self.ub - (mutant[j] - self.ub)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n\n                # Crossover (Self-Adaptive)\n                CR_individual = self.CR + np.random.normal(0, 0.1, 1) # Individual Crossover rate\n                CR_individual = np.clip(CR_individual, 0.1, 0.9)\n                cross_points = np.random.rand(self.dim) < CR_individual\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, self.lb, self.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    #Adapt scaling factor, and crossover rate\n                    self.CR = self.CR * self.CR_decay\n                    self.F = self.F * self.F_increase\n                    if self.F > 1.0:\n                        self.F = 0.9\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                     self.F = self.F * self.F_decay\n\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["d193e4b3-7ebe-49d6-bf53-557ffc5c8b13"], "operator": null, "metadata": {}}
{"id": "eb84ebd7-360a-4024-bf22-d330d55aa394", "fitness": -Infinity, "name": "SOM_AdaptiveDE", "description": "An adaptive differential evolution algorithm using a self-organizing map (SOM) to cluster individuals and apply different mutation strategies based on the cluster.", "code": "import numpy as np\nfrom minisom import MiniSom\n\nclass SOM_AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, som_grid_size=5, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.som_grid_size = som_grid_size\n        self.archive_size = archive_size\n        self.F = 0.5\n        self.CR = 0.7\n        self.som = None\n        self.mutation_strategies = ['current_to_best', 'rand_1', 'rand_2']\n        self.mutation_probs = [0.33, 0.33, 0.34]\n        self.success_counts = [0, 0, 0]\n        self.archive = []\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = []\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        # Initialize SOM\n        self.som = MiniSom(self.som_grid_size, self.som_grid_size, self.dim, sigma=0.3, learning_rate=0.5)\n        self.som.train(self.pop, 1000) # Train the SOM initially\n\n        while self.evals < self.budget:\n            # Update SOM with the current population\n            self.som.train(self.pop, 100, verbose=False) #Retrain SOM\n\n            for i in range(self.pop_size):\n                # Find the winning neuron for the individual\n                winner = self.som.winner(self.pop[i])\n                cluster_idx = winner[0] * self.som_grid_size + winner[1]\n\n                # Adapt mutation strategy based on the cluster\n                mutation_strategy = np.random.choice(self.mutation_strategies, p=self.mutation_probs)\n\n\n                if mutation_strategy == 'current_to_best':\n                    best_idx = np.argmin(self.fitness)\n                    x_best = self.pop[best_idx]\n                    idxs = np.random.choice(self.pop_size, 1, replace=False) #changed 2 to 1\n                    x_r1 = self.pop[idxs[0]]\n                    mutant = self.pop[i] + self.F * (x_best - self.pop[i]) + self.F * (x_r1 - self.pop[i])\n\n                    mutation_index = 0\n                elif mutation_strategy == 'rand_1':\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n                    mutation_index = 1\n                elif mutation_strategy == 'rand_2':\n                    idxs = np.random.choice(self.pop_size, 5, replace=False)\n                    x_r1, x_r2, x_r3, x_r4, x_r5 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]], self.pop[idxs[3]], self.pop[idxs[4]]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3) + self.F * (x_r4 - x_r5)\n                    mutation_index = 2\n                else:\n                    raise ValueError(\"Invalid mutation strategy\")\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.archive.append(self.pop[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    self.success_counts[mutation_index] += 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Adapt mutation probabilities based on success counts\n            total_success = sum(self.success_counts)\n            if total_success > 0:\n                self.mutation_probs = [count / total_success for count in self.success_counts]\n            else:\n                # Reset if no success\n                self.mutation_probs = [1/len(self.mutation_strategies)] * len(self.mutation_strategies)\n\n            self.success_counts = [0] * len(self.mutation_strategies)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occurred: No module named 'minisom'.", "error": "", "parent_ids": ["d193e4b3-7ebe-49d6-bf53-557ffc5c8b13"], "operator": null, "metadata": {}}
{"id": "7e55f106-91d7-4d36-9825-298c79663f2d", "fitness": 0.0, "name": "AdaptiveGradientScoutOptimization", "description": "An adaptive gradient-based optimization that estimates the gradient using multiple scouts and adaptively adjusts the step size based on the scouts' performance and gradient alignment.", "code": "import numpy as np\n\nclass AdaptiveGradientScoutOptimization:\n    def __init__(self, budget=10000, dim=10, num_scouts=20, initial_step_size=0.1, gradient_memory=5):\n        self.budget = budget\n        self.dim = dim\n        self.num_scouts = num_scouts\n        self.step_size = initial_step_size\n        self.step_size_reduction_factor = 0.5\n        self.step_size_increase_factor = 1.1\n        self.gradient_memory = gradient_memory\n        self.scouts = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.evals = 0\n        self.gradient_estimates = []\n\n    def initialize_scouts(self, func):\n        self.scouts = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_scouts, self.dim))\n        self.fitness = np.array([func(x) for x in self.scouts])\n        self.evals += self.num_scouts\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.scouts[np.argmin(self.fitness)].copy()\n\n    def estimate_gradient(self, func, x, delta=1e-3):\n        gradient = np.zeros(self.dim)\n        for i in range(self.dim):\n            x_plus = x.copy()\n            x_minus = x.copy()\n            x_plus[i] += delta\n            x_minus[i] -= delta\n            x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n            x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n            f_plus = func(x_plus)\n            f_minus = func(x_minus)\n            self.evals += 2\n            gradient[i] = (f_plus - f_minus) / (2 * delta)\n        return gradient\n\n    def __call__(self, func):\n        self.initialize_scouts(func)\n\n        while self.evals < self.budget:\n            # Calculate the average position of the scouts\n            center_position = np.mean(self.scouts, axis=0)\n\n            # Estimate the gradient at the center position\n            gradient = self.estimate_gradient(func, center_position)\n            \n            # Normalize the gradient\n            gradient_norm = np.linalg.norm(gradient)\n            if gradient_norm > 0:\n                gradient = gradient / gradient_norm\n            \n            #Take a step in the direction of the negative gradient\n            new_position = center_position - self.step_size * gradient\n            new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n            new_fitness = func(new_position)\n            self.evals += 1\n\n            # Update scouts to explore near the new position\n            new_scouts = np.random.normal(new_position, self.step_size/2, size=(self.num_scouts, self.dim))\n            new_scouts = np.clip(new_scouts, func.bounds.lb, func.bounds.ub)\n            new_fitnesses = np.array([func(x) for x in new_scouts])\n            self.evals += self.num_scouts\n\n            #Replace scouts with the better of old and new\n            combined_scouts = np.concatenate((self.scouts, new_scouts), axis=0)\n            combined_fitnesses = np.concatenate((self.fitness, new_fitnesses))\n\n            sorted_indices = np.argsort(combined_fitnesses)\n            self.scouts = combined_scouts[sorted_indices[:self.num_scouts]]\n            self.fitness = combined_fitnesses[sorted_indices[:self.num_scouts]]\n\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_position = new_position.copy()\n                self.step_size *= self.step_size_increase_factor\n            else:\n                self.step_size *= self.step_size_reduction_factor\n            \n            self.step_size = min(self.step_size, 1.0)  # Cap the step size\n            self.step_size = max(self.step_size, 1e-6) # Lower bound\n\n            if self.evals >= self.budget:\n                break\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveGradientScoutOptimization scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["92ab55b3-bd43-4f54-8618-959524638a82"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "27a076af-271b-47b6-8604-97849d65a624", "fitness": 0.0, "name": "ToroidalAdaptiveDE", "description": "A differential evolution algorithm with a self-adaptive population size and a toroidal mutation strategy to improve exploration and avoid premature convergence.", "code": "import numpy as np\n\nclass ToroidalAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, growth_rate=1.1, shrinkage_rate=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.growth_rate = growth_rate\n        self.shrinkage_rate = shrinkage_rate\n        self.F = 0.5\n        self.CR = 0.7\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.success_history = []\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Toroidal Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                mutant = x_r1 + self.F * self.toroidal_difference(x_r2, x_r3, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                    self.success_history.append(True)\n                else:\n                     self.success_history.append(False)\n            \n            # Adjust population size based on recent success rate\n            success_rate = np.mean(self.success_history[-self.pop_size:] if len(self.success_history) >= self.pop_size else self.success_history) if self.success_history else 0\n            \n            if success_rate > 0.4:\n                self.pop_size = min(int(self.pop_size * self.growth_rate), self.max_pop_size)\n            elif success_rate < 0.1:\n                self.pop_size = max(int(self.pop_size * self.shrinkage_rate), self.min_pop_size)\n            \n            # Regenerate population if pop size changes\n            if self.pop_size != self.pop.shape[0]:\n                old_pop = self.pop.copy()\n                old_fitness = self.fitness.copy()\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                \n                # Copy best individuals from old population to the new one if possible\n                num_copied = min(self.pop_size, len(old_pop))\n                best_indices = np.argsort(old_fitness)[:num_copied]\n                self.pop[:num_copied] = old_pop[best_indices]\n                self.fitness[:num_copied] = old_fitness[best_indices]\n                self.evals += num_copied #account for the fitness evaluations performed for copying\n\n        return self.f_opt, self.x_opt\n\n    def toroidal_difference(self, x, y, lb, ub):\n        diff = x - y\n        range_width = ub - lb\n        diff = np.where(diff > range_width / 2, diff - range_width, diff)\n        diff = np.where(diff < -range_width / 2, diff + range_width, diff)\n        return diff", "configspace": "", "generation": 3, "feedback": "The algorithm ToroidalAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d193e4b3-7ebe-49d6-bf53-557ffc5c8b13"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "c1016ef5-d2ea-47cc-92da-1f6dc9c81361", "fitness": 0.4008220315402897, "name": "OrthogonalScoutOptimization", "description": "A scout-based algorithm that utilizes orthogonal learning to sample diverse scout locations and dynamically adjusts step sizes based on success rate and distance to the global best.", "code": "import numpy as np\n\nclass OrthogonalScoutOptimization:\n    def __init__(self, budget=10000, dim=10, num_scouts=20, scout_memory=5, initial_step_size=0.1, global_attraction=0.01, orthogonal_sample_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.num_scouts = num_scouts\n        self.scout_memory = scout_memory\n        self.step_size = initial_step_size\n        self.step_size_reduction_factor = 0.8\n        self.step_size_increase_factor = 1.2\n        self.global_attraction = global_attraction\n        self.orthogonal_sample_size = orthogonal_sample_size\n        self.success_threshold = 0.1\n\n        self.scouts = None\n        self.fitness = None\n        self.scout_moves = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.evals = 0\n\n    def initialize_scouts(self, func):\n        # Initialize scouts using orthogonal sampling\n        self.scouts = self.orthogonal_sampling(func.bounds.lb, func.bounds.ub, self.num_scouts)\n        self.fitness = np.array([func(x) for x in self.scouts])\n        self.evals += self.num_scouts\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.scouts[np.argmin(self.fitness)].copy()\n        self.scout_moves = [[] for _ in range(self.num_scouts)]\n\n\n    def orthogonal_sampling(self, lb, ub, num_samples):\n        # Generate an orthogonal array\n        if self.dim <= 1:\n            return np.random.uniform(lb, ub, size=(num_samples, self.dim))\n        \n        levels = int(np.ceil(num_samples**(1/self.dim)))\n        \n        if levels <= 1:\n           return np.random.uniform(lb, ub, size=(num_samples, self.dim))\n        \n        \n        design = np.zeros((levels**self.dim, self.dim))\n        for i in range(self.dim):\n            design[:, i] = np.tile(np.repeat(np.arange(levels), levels**i), levels**(self.dim - i - 1))[:levels**self.dim]\n        \n        # Reduce number of samples\n        if levels**self.dim > num_samples:\n          indices = np.random.choice(levels**self.dim, num_samples, replace=False)\n          design = design[indices, :]\n        \n        # Scale and shift to the given bounds\n        samples = lb + (ub - lb) * design / (levels - 1)\n        \n        return samples\n\n\n    def __call__(self, func):\n        self.initialize_scouts(func)\n\n        while self.evals < self.budget:\n            for i in range(self.num_scouts):\n                # Generate orthogonal samples around current scout\n                orthogonal_positions = self.orthogonal_sampling(self.scouts[i] - self.step_size, self.scouts[i] + self.step_size, self.orthogonal_sample_size)\n                orthogonal_positions = np.clip(orthogonal_positions, func.bounds.lb, func.bounds.ub)\n                orthogonal_fitnesses = np.array([func(x) for x in orthogonal_positions])\n                self.evals += self.orthogonal_sample_size\n\n                # Select the best orthogonal sample\n                best_orthogonal_index = np.argmin(orthogonal_fitnesses)\n                new_position = orthogonal_positions[best_orthogonal_index]\n                new_fitness = orthogonal_fitnesses[best_orthogonal_index]\n\n\n                # Global Attraction\n                global_attraction_vector = self.global_attraction * (self.best_position - self.scouts[i])\n                new_position = new_position + global_attraction_vector\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n\n                # Check if the move was successful\n                if new_fitness < self.fitness[i]:\n                    # Update scout's position and fitness\n                    self.scouts[i] = new_position\n                    self.fitness[i] = new_fitness\n                    self.scout_moves[i].append(True)\n                    if len(self.scout_moves[i]) > self.scout_memory:\n                        self.scout_moves[i].pop(0)\n\n                    # Update best solution if necessary\n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_position = new_position.copy()\n\n                    # Increase step size if scout is consistently successful\n                    if len(self.scout_moves[i]) == self.scout_memory and all(self.scout_moves[i]):\n                         self.step_size *= self.step_size_increase_factor\n\n                else:\n                     self.scout_moves[i].append(False)\n                     if len(self.scout_moves[i]) > self.scout_memory:\n                         self.scout_moves[i].pop(0)\n\n                     # Reduce step size if scout is consistently unsuccessful\n                     if len(self.scout_moves[i]) == self.scout_memory and not any(self.scout_moves[i]):\n                         self.step_size *= self.step_size_reduction_factor\n\n                # Adjust global attraction based on best fitness improvement\n                if self.evals > self.num_scouts:\n                    improvement = (self.best_fitness - np.min(self.fitness)) / self.best_fitness\n                    if improvement < -0.001: #Significant improvement\n                        self.global_attraction *= 1.1\n                    elif improvement > 0.001: #Degradation\n                        self.global_attraction *= 0.9\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 3, "feedback": "The algorithm OrthogonalScoutOptimization scored 0.401 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["92ab55b3-bd43-4f54-8618-959524638a82"], "operator": null, "metadata": {"aucs": [0.14369758685942247, 0.24613309862174926, 0.4144863087956008, 0.5142966613124778, 0.2739174328526566, 0.4984176251182524, 0.2511613114523701, 0.38624366160770296, 0.3046405215764587, 0.2351761849743148, 0.6676025741035371, 0.999255201581745, 0.24371142357135644, 0.3274419303392916, 0.7228133116022989, 0.322501535891461, 0.2396761108876102, 0.5742554380852398, 0.16021499001900008, 0.4907977215532472]}}
{"id": "e13f55d5-5f30-4650-99fd-830fab077db9", "fitness": 0.6653442683033474, "name": "DiversityEnhancedDE", "description": "A differential evolution algorithm that uses a mutation strategy based on the current best solution and a diversity metric to balance exploration and exploitation.", "code": "import numpy as np\n\nclass DiversityEnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.diversity_threshold = diversity_threshold\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7  # Initial crossover rate\n\n    def calculate_diversity(self):\n        \"\"\"\n        Calculate the diversity of the population.\n        \"\"\"\n        centroid = np.mean(self.pop, axis=0)\n        distances = np.linalg.norm(self.pop - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            diversity = self.calculate_diversity()\n\n            for i in range(self.pop_size):\n                # Mutation strategy: either towards best or random, based on diversity\n                if diversity > self.diversity_threshold:\n                    # High diversity: explore more (random mutation)\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n                else:\n                    # Low diversity: exploit best solution\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n                    mutant = self.pop[i] + self.F * (self.x_opt - self.pop[i]) + self.F * (x_r1 - x_r2)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Adjust F and CR (optional - can be removed or modified)\n            self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm DiversityEnhancedDE scored 0.665 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8e38b6be-2b6b-4033-89a2-409b10b8f379"], "operator": null, "metadata": {"aucs": [0.23073219429830283, 0.3863693484875905, 0.7012147999596718, 0.8306859558639981, 0.7879475557270661, 0.8210340160937024, 0.6208817547387293, 0.7230352368269028, 0.7455837905521336, 0.6600124632963633, 0.8040282509002583, 0.9966761867770474, 0.3618246652627669, 0.6896648657496438, 0.8863144694897023, 0.7834316082518981, 0.6257219678001413, 0.8241498626150987, 0.30610001793283315, 0.5214763554430961]}}
{"id": "988dc07f-9ce5-4922-8bd3-ca22ff544046", "fitness": 0.5538294061790748, "name": "NeighborhoodScoutOptimization", "description": "A scout-based algorithm with dynamically adjusted search direction based on both global best and local neighborhood information.", "code": "import numpy as np\n\nclass NeighborhoodScoutOptimization:\n    def __init__(self, budget=10000, dim=10, num_scouts=20, neighborhood_size=3, initial_step_size=0.1, global_attraction=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.num_scouts = num_scouts\n        self.neighborhood_size = neighborhood_size  # Number of scouts to consider in the neighborhood\n        self.step_size = initial_step_size\n        self.step_size_reduction_factor = 0.7\n        self.step_size_increase_factor = 1.3\n        self.global_attraction = global_attraction\n        self.scouts = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.evals = 0\n\n    def initialize_scouts(self, func):\n        self.scouts = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_scouts, self.dim))\n        self.fitness = np.array([func(x) for x in self.scouts])\n        self.evals += self.num_scouts\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.scouts[np.argmin(self.fitness)].copy()\n\n    def __call__(self, func):\n        self.initialize_scouts(func)\n\n        while self.evals < self.budget:\n            for i in range(self.num_scouts):\n                # Define the neighborhood for each scout\n                neighborhood_indices = np.random.choice(self.num_scouts, self.neighborhood_size, replace=False)\n                neighborhood_indices = np.append(neighborhood_indices, i) #Include self in neighborhood\n                neighborhood = self.scouts[neighborhood_indices]\n                neighborhood_fitness = self.fitness[neighborhood_indices]\n\n                # Find the best scout in the neighborhood\n                best_neighbor_index = np.argmin(neighborhood_fitness)\n                best_neighbor = neighborhood[best_neighbor_index]\n\n                # Generate a move based on both global and local information\n                global_attraction_vector = self.global_attraction * (self.best_position - self.scouts[i])\n                local_attraction_vector = (best_neighbor - self.scouts[i])\n\n                move = np.random.normal(0, self.step_size, size=self.dim) + global_attraction_vector + local_attraction_vector\n                new_position = self.scouts[i] + move\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.evals += 1\n\n                # Update scout's position and fitness if the move was successful\n                if new_fitness < self.fitness[i]:\n                    self.scouts[i] = new_position\n                    self.fitness[i] = new_fitness\n\n                    # Update best solution if necessary\n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_position = new_position.copy()\n                    self.step_size *= self.step_size_increase_factor #Increase upon improvement\n                else:\n                    self.step_size *= self.step_size_reduction_factor  # Decrease step size if move wasn't successful\n\n                if self.evals >= self.budget:\n                    break\n\n            self.step_size = np.clip(self.step_size, 0.0001, 1.0) #clamp step size\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 3, "feedback": "The algorithm NeighborhoodScoutOptimization scored 0.554 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["92ab55b3-bd43-4f54-8618-959524638a82"], "operator": null, "metadata": {"aucs": [0.11897180607104196, 0.177387607597555, 0.9180167530141221, 0.9690648207195485, 0.945706858769837, 0.9461855844906509, 0.275915942438265, 0.4843921746023071, 0.943529192834961, 0.20595710520266775, 0.28341601107663483, 0.9941097266132447, 0.2236817785852211, 0.6297466059396986, 0.7838249439701366, 0.3541500148105441, 0.24486640349770283, 0.9528141162945654, 0.14124080884245283, 0.4836098682103399]}}
{"id": "ed52da49-674c-4f9f-adc4-8bf358a4e906", "fitness": 0.289836319255821, "name": "HybridPSO_DE", "description": "An adaptive algorithm that combines aspects of particle swarm optimization (PSO) with differential evolution (DE), using velocity updates inspired by PSO and mutation/crossover from DE, dynamically adjusting parameters based on performance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, population_size=20, inertia_weight=0.7, cognitive_coeff=1.4, social_coeff=1.4, de_mutation_rate=0.7, de_crossover_rate=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.de_mutation_rate = de_mutation_rate\n        self.de_crossover_rate = de_crossover_rate\n        self.particles = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.evals = 0\n\n    def initialize_particles(self, func):\n        self.particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.particles])\n        self.evals += self.population_size\n\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_fitness = np.min(self.fitness)\n        self.global_best_position = self.particles[np.argmin(self.fitness)].copy()\n\n    def differential_evolution_mutation(self):\n        for i in range(self.population_size):\n            idxs = np.random.choice(self.population_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.particles[idxs]\n            mutation_vector = x_r1 + self.de_mutation_rate * (x_r2 - x_r3)\n            \n            #Crossover\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() > self.de_crossover_rate and j != j_rand:\n                    mutation_vector[j] = self.particles[i, j]\n                    \n            mutation_vector = np.clip(mutation_vector, -5.0, 5.0)\n            return mutation_vector\n    \n    def update_velocity(self, i):\n      cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.particles[i])\n      social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.particles[i])\n      self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_component + social_component\n\n    def __call__(self, func):\n        self.initialize_particles(func)\n\n        while self.evals < self.budget:\n            for i in range(self.population_size):\n                # Apply Differential Evolution mutation\n                mutation_vector = self.differential_evolution_mutation()\n                \n                # Update particle velocity\n                self.update_velocity(i)\n                \n                # Update particle position using PSO velocity and DE mutation\n                new_position = self.particles[i] + self.velocities[i] + mutation_vector*0.1\n\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.evals += 1\n\n                if new_fitness < self.fitness[i]:\n                    self.fitness[i] = new_fitness\n                    self.particles[i] = new_position\n\n                    if new_fitness < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = new_fitness\n                        self.personal_best_positions[i] = new_position.copy()\n\n                        if new_fitness < self.global_best_fitness:\n                            self.global_best_fitness = new_fitness\n                            self.global_best_position = new_position.copy()\n                \n                # Adaptive parameter update (example: inertia weight)\n                if self.evals % self.population_size == 0: #Update parameters after each cycle.\n                    if np.mean(self.fitness) < np.mean(self.personal_best_fitness):\n                        self.inertia_weight *= 1.05  # Increase inertia if population is improving\n                    else:\n                        self.inertia_weight *= 0.95   # Decrease inertia if population is stagnating\n                    self.inertia_weight = np.clip(self.inertia_weight, 0.4, 0.9)\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm HybridPSO_DE scored 0.290 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["92ab55b3-bd43-4f54-8618-959524638a82"], "operator": null, "metadata": {"aucs": [0.15960318295097908, 0.16164835471404038, 0.3182319327321115, 0.1590932846868498, 0.2328110975015325, 0.23879360512834713, 0.23064177975054212, 0.23422090792683026, 0.20742364610721664, 0.16253377047119333, 0.17150941854986435, 0.9992377384365461, 0.19050554976523082, 0.23928019089860086, 0.6496680698627053, 0.3096653449801996, 0.2054028926861753, 0.2775410308032521, 0.17145174834032528, 0.4774628388238793]}}
{"id": "bc62416b-61a7-4ef8-ac46-fc47f673a3a0", "fitness": 0.46259507585327153, "name": "EnhancedLevyDE", "description": "An enhanced differential evolution strategy that incorporates a self-adaptive Lvy flight for exploration, an archive to preserve promising solutions, and a niching strategy to maintain diversity.", "code": "import numpy as np\n\nclass EnhancedLevyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, levy_exponent=1.5, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.levy_exponent = levy_exponent\n        self.archive_size = archive_size\n        self.F = 0.5\n        self.CR = 0.7\n        self.archive = []  # Archive to store promising solutions\n        self.archive_fitness = []\n\n    def levy_flight(self, size):\n        \"\"\"Generate Levy distribution samples.\"\"\"\n        u = np.random.normal(0, 1, size=size)\n        v = np.random.normal(0, 1, size=size)\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) / (\n            np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * 2 ** ((self.levy_exponent - 1) / 2))) ** (1 / self.levy_exponent)\n        step = sigma * u / abs(v) ** (1 / self.levy_exponent)\n        return step\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n\n                # Adaptive Levy step\n                levy_step_size = 0.01 + 0.1 * np.exp(-self.evals / self.budget)  # Decay step size\n                levy_step = levy_step_size * self.levy_flight(self.dim)\n\n                mutant = x_r1 + self.F * (x_r2 - x_r3) + levy_step * (self.x_opt - self.pop[i])\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    # Niching: Check if the new solution is too close to existing solutions\n                    distance_threshold = 0.1  # Adjust as needed\n                    too_close = False\n                    for j in range(self.pop_size):\n                        if i != j and np.linalg.norm(trial - self.pop[j]) < distance_threshold:\n                            too_close = True\n                            break\n\n                    if not too_close:\n                        self.fitness[i] = f_trial\n                        self.pop[i] = trial\n\n                        # Update archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(trial)\n                            self.archive_fitness.append(f_trial)\n                        else:\n                            max_archive_fitness_idx = np.argmax(self.archive_fitness)\n                            if f_trial < self.archive_fitness[max_archive_fitness_idx]:\n                                self.archive[max_archive_fitness_idx] = trial\n                                self.archive_fitness[max_archive_fitness_idx] = f_trial\n                    \n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n\n            # Adjust F and CR\n            self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedLevyDE scored 0.463 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8e38b6be-2b6b-4033-89a2-409b10b8f379"], "operator": null, "metadata": {"aucs": [0.21158661072930984, 0.33707329609530556, 0.4167914581909681, 0.7765974451389231, 0.35219807564919925, 0.45582332818230653, 0.36635659788749253, 0.3831803082906291, 0.39154569074433365, 0.3085343638468552, 0.5981387020583433, 0.9941529510139802, 0.2707887585271206, 0.37345259228642624, 0.8311727753129423, 0.5194500912909981, 0.3742693313112244, 0.5490966800139754, 0.22496095206216704, 0.5167315084329323]}}
{"id": "fa01eb49-daa4-4da0-845a-56e6b323a1b1", "fitness": 0.19378052114169395, "name": "DynamicPopulationAdaptiveDE", "description": "An adaptive differential evolution algorithm that uses a dynamic population size adjustment strategy based on stagnation detection and fitness diversity, coupled with a modified mutation operator that leverages both the global best and a diversity-preserving mechanism.", "code": "import numpy as np\n\nclass DynamicPopulationAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=None, f=0.5, cr=0.9, alpha=0.1, beta=0.1, stagnation_threshold=100, diversity_threshold=1e-6):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init if pop_size_init is not None else int(10 + np.ceil(np.log(self.dim)))\n        self.F = f\n        self.CR = cr\n        self.alpha = alpha\n        self.beta = beta\n        self.stagnation_threshold = stagnation_threshold\n        self.diversity_threshold = diversity_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = self.population[i]\n\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > 0:\n            # Population size adjustment based on stagnation and diversity\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < self.diversity_threshold:\n                    self.stagnation_counter += 1\n                    if self.stagnation_counter > self.stagnation_threshold // 2:\n                        # Increase population size if stagnated\n                        self.pop_size = int(self.pop_size * 1.2)  # Increase by 20%\n                        self.population = np.vstack((self.population, np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - self.population.shape[0], self.dim))))\n                        fitness = np.concatenate((fitness, np.array([func(x) for x in self.population[fitness.shape[0]:]])))\n                        self.budget -= (self.pop_size - fitness.shape[0])\n                        self.stagnation_counter = 0\n\n                else:\n                    self.stagnation_counter = 0\n\n            for i in range(self.pop_size):\n                # Adaptive Parameter Control\n                self.F = np.clip(np.random.normal(self.F, self.alpha), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(self.CR, self.beta), 0.1, 1.0)\n\n                # Modified Mutation (using global best and diversity preservation)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n\n                mutant = self.population[i] + self.F * (self.x_opt - self.population[i]) + self.F * (x1 - x2 + x3 - self.population[i]) # added x3 - self.population[i] to preserve population diversity.\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(cross_mask, mutant, self.population[i])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                        self.best_fitness_history.append(self.f_opt)\n\n                if self.budget <= 0:\n                    break\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm DynamicPopulationAdaptiveDE scored 0.194 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a32fc792-6231-4baa-a79b-dde4ea4dc91f"], "operator": null, "metadata": {"aucs": [0.35384596947292235, 0.22749559395215946, 0]}}
{"id": "334ebf8e-3356-408b-872f-2fc719e6922c", "fitness": 0.30870868828244824, "name": "SelfOrganizingSearch", "description": "A self-organizing algorithm that dynamically adjusts its search behavior by employing a decaying exploration rate and a dynamically-sized neighborhood for local search.", "code": "import numpy as np\n\nclass SelfOrganizingSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.exploration_rate = 0.5  # Initial exploration rate\n        self.exploration_decay = 0.995 # Decay rate for exploration\n        self.neighborhood_size = 3 # Initial neighborhood size\n        self.neighborhood_decay = 0.95 # Decay rate for neighborhood\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_rate:\n                    # Exploration: Random jump\n                    new_x = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                else:\n                    # Exploitation: Local search within neighborhood\n                    neighbors = np.random.choice(self.pop_size, size=min(self.neighborhood_size, self.pop_size), replace=False)\n                    \n                    #Find the best neighbor\n                    best_neighbor_idx = neighbors[np.argmin(self.fitness[neighbors])]\n                    \n                    # Perform a move towards the best neighbor (simplified)\n                    new_x = self.pop[i] + 0.1 * (self.pop[best_neighbor_idx] - self.pop[i]) \n                    new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                \n                f_new = func(new_x)\n                self.evals += 1\n                \n                #Acceptance criterion based on fitness improvement\n                if f_new < self.fitness[i]:\n                    self.pop[i] = new_x\n                    self.fitness[i] = f_new\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = new_x\n\n            # Update exploration rate and neighborhood size\n            self.exploration_rate *= self.exploration_decay\n            self.neighborhood_size = max(1, int(self.neighborhood_size * self.neighborhood_decay)) # Ensure neighborhood is at least 1\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm SelfOrganizingSearch scored 0.309 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d193e4b3-7ebe-49d6-bf53-557ffc5c8b13"], "operator": null, "metadata": {"aucs": [0.1347960664153055, 0.2454384426427777, 0.2965598910082512, 0.24587747066868093, 0.19941792953116777, 0.24131971879867242, 0.24021665022749816, 0.2523693888136658, 0.27600494970993306, 0.17878151507199858, 0.21826663547914105, 0.9950117595886183, 0.26962187093758516, 0.23202233361406188, 0.6261073592628286, 0.29955617717875427, 0.25861514415677345, 0.29146519473844745, 0.19421667380467256, 0.4785085940001318]}}
{"id": "bffba4cb-8b6c-475c-8957-a03615c59606", "fitness": -Infinity, "name": "SpiralPerturbationOptimization", "description": "A population-based algorithm employing a spiral search pattern around the current best solution, combined with a perturbation mechanism for diversity.", "code": "import numpy as np\n\nclass SpiralPerturbationOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, spiral_radius=1.0, perturbation_rate=0.1, perturbation_strength=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.spiral_radius = spiral_radius\n        self.perturbation_rate = perturbation_rate\n        self.perturbation_strength = perturbation_strength\n        self.population = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.evals = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals += self.population_size\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.population[np.argmin(self.fitness)].copy()\n\n    def spiral_movement(self, x, best_x, radius):\n        theta = np.random.uniform(0, 2 * np.pi)\n        r = np.random.uniform(0, radius)\n        new_x = best_x + r * np.array([np.cos(theta), np.sin(theta)])[:self.dim] # Ensure same dimensionality\n        return new_x\n\n    def perturb(self, x):\n        if np.random.rand() < self.perturbation_rate:\n            x = x + np.random.normal(0, self.perturbation_strength, size=self.dim)\n        return x\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.evals < self.budget:\n            for i in range(self.population_size):\n                # Spiral movement around the best solution\n                new_position = self.spiral_movement(self.population[i], self.best_position, self.spiral_radius)\n\n                # Perturbation for diversity\n                new_position = self.perturb(new_position)\n\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.evals += 1\n\n                if new_fitness < self.fitness[i]:\n                    self.population[i] = new_position\n                    self.fitness[i] = new_fitness\n\n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_position = new_position.copy()\n\n                #Adaptive spiral radius\n                self.spiral_radius = 1.0 - (self.evals / self.budget) #Reduce spiral radius over time\n\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 4, "feedback": "An exception occurred: operands could not be broadcast together with shapes (5,) (2,) .", "error": "", "parent_ids": ["c1016ef5-d2ea-47cc-92da-1f6dc9c81361"], "operator": null, "metadata": {}}
{"id": "ce12d732-d57b-4eb9-9e63-26ed19d54303", "fitness": 0.0, "name": "HybridDE_CMA", "description": "A hybrid algorithm combining differential evolution with a covariance matrix adaptation strategy for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, cma_lr=0.1, de_cr=0.7, de_f=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cma_lr = cma_lr  # Learning rate for CMA\n        self.de_cr = de_cr      # Crossover rate for DE\n        self.de_f = de_f      # Scaling factor for DE\n        self.mean = None       # Mean of the CMA distribution\n        self.C = None          # Covariance matrix of the CMA distribution\n        self.ps = None         # Evolution path for the covariance matrix\n        self.pc = None         # Evolution path for the mean\n        self.evals = 0\n\n    def initialize(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)  # Initialize covariance matrix to identity\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.pop = np.random.multivariate_normal(self.mean, self.C, size=self.pop_size)\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.evals += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def __call__(self, func):\n        self.initialize(func)\n        \n        # CMA-ES parameters\n        mu = self.pop_size // 2  # Number of selected individuals\n        c_sig = 0.5  # damping factor for step size\n        c_cov = 0.1  # Learning rate for covariance matrix\n\n        while self.evals < self.budget:\n            # (1) Sample new population\n            z = np.random.multivariate_normal(np.zeros(self.dim), np.eye(self.dim), size=self.pop_size)\n            pop_cma = self.mean + np.dot(z, np.linalg.cholesky(self.C).T)\n            pop_cma = np.clip(pop_cma, func.bounds.lb, func.bounds.ub)\n            fitness_cma = np.array([func(x) for x in pop_cma])\n            self.evals += self.pop_size\n\n            # (2) Selection and Recombination (CMA-ES update)\n            idx_sorted = np.argsort(fitness_cma)\n            selected_z = z[idx_sorted[:mu]]\n            self.mean = np.mean(pop_cma[idx_sorted[:mu]], axis=0)  # Weighted recombination\n\n            # (3) Update evolution paths\n            self.ps = (1 - c_sig) * self.ps + np.sqrt(c_sig * (2 - c_sig)) * np.mean(selected_z, axis=0)\n            self.pc = (1 - c_cov) * self.pc + np.sqrt(c_cov * (2 - c_cov)) * np.mean((pop_cma[idx_sorted[:mu]] - self.mean), axis=0)\n\n            # (4) Update covariance matrix\n            self.C = (1 - c_cov) * self.C + c_cov * (np.outer(self.pc, self.pc) + np.eye(self.dim) * 1e-8)  # Add small value for numerical stability\n\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                mutant = x_r1 + self.de_f * (x_r2 - x_r3)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection: compare trial with CMA-ES samples and current population\n                if f_trial < self.fitness[i] and f_trial < np.max(fitness_cma):\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                elif f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm HybridDE_CMA scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["bc62416b-61a7-4ef8-ac46-fc47f673a3a0"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "f4b81044-ea3c-4631-ba3b-e3b3d2131819", "fitness": 0.14471087722168907, "name": "AdaptivePopulationDE", "description": "Adaptive Population Reduction with Elitist Mutation: A differential evolution strategy that reduces population size adaptively based on stagnation and uses an elitist mutation to improve convergence.", "code": "import numpy as np\n\nclass AdaptivePopulationDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=100, reduction_factor=0.9, stagnation_threshold=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.initial_pop_size = initial_pop_size\n        self.reduction_factor = reduction_factor\n        self.stagnation_threshold = stagnation_threshold\n        self.F = 0.5\n        self.CR = 0.7\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Elitist Mutation: Mutate towards the best solution\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n                mutant = self.x_opt + self.F * (x_r1 - x_r2)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            self.best_fitness_history.append(self.f_opt)\n\n            # Check for stagnation\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                if np.abs(self.best_fitness_history[-1] - self.best_fitness_history[-self.stagnation_threshold]) < 1e-6:\n                    self.stagnation_counter += 1\n                else:\n                    self.stagnation_counter = 0\n\n            # Reduce population size if stagnating\n            if self.stagnation_counter >= self.stagnation_threshold and self.pop_size > 10:\n                self.pop_size = int(self.pop_size * self.reduction_factor)\n                self.pop_size = max(10, self.pop_size) # Minimum population size of 10\n                \n                #Resample the population\n                best_indices = np.argsort(self.fitness)[:self.pop_size]\n                self.pop = self.pop[best_indices]\n                self.fitness = self.fitness[best_indices]\n                \n                remaining = self.initial_pop_size - self.pop_size\n                new_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(remaining, self.dim))\n                new_fitness = np.array([func(x) for x in new_pop])\n                self.evals += remaining\n                \n                self.pop = np.concatenate((self.pop,new_pop),axis=0)\n                self.fitness = np.concatenate((self.fitness,new_fitness))\n                \n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.pop[np.argmin(self.fitness)]\n\n                print(f\"Population reduced to {self.pop_size}\")\n                self.stagnation_counter = 0\n                self.best_fitness_history = [self.f_opt] #Reset history\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptivePopulationDE scored 0.145 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e13f55d5-5f30-4650-99fd-830fab077db9"], "operator": null, "metadata": {"aucs": [0.28942175444337814, 0]}}
{"id": "a4694cca-4567-4e44-8396-a54ad6024410", "fitness": 0.06429788179711149, "name": "AdaptiveRestartDE", "description": "An adaptive differential evolution algorithm that dynamically adjusts its parameters based on the success rate of recent generations, incorporating a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveRestartDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, restart_trigger=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.restart_trigger = restart_trigger\n        self.F = 0.5\n        self.CR = 0.7\n        self.success_history_F = []\n        self.success_history_CR = []\n        self.archive = []  # Archive for potentially good solutions\n        self.archive_size = pop_size\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.generation = 0\n        self.no_improvement_count = 0\n\n        while self.evals < self.budget:\n            self.generation += 1\n\n            # Adaptive F and CR\n            if self.success_history_F:\n                self.F = np.mean(self.success_history_F)\n                self.CR = np.mean(self.success_history_CR)\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            \n            new_successes_F = []\n            new_successes_CR = []\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    new_successes_F.append(self.F)\n                    new_successes_CR.append(self.CR)\n                    \n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        # Replace a random element in the archive\n                        idx_to_replace = np.random.randint(0, self.archive_size)\n                        self.archive[idx_to_replace] = self.pop[i].copy()\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.no_improvement_count = 0  # Reset counter\n                else:\n                    self.no_improvement_count += 1  # Increment counter\n\n            # Update success histories\n            self.success_history_F.extend(new_successes_F)\n            self.success_history_CR.extend(new_successes_CR)\n\n            # Restart mechanism\n            if self.no_improvement_count > self.restart_trigger:\n                # Option 1: Re-initialize a portion of the population randomly\n                num_to_restart = int(0.2 * self.pop_size)\n                idxs_to_restart = np.random.choice(self.pop_size, num_to_restart, replace=False)\n                self.pop[idxs_to_restart] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_restart, self.dim))\n                self.fitness[idxs_to_restart] = np.array([func(x) for x in self.pop[idxs_to_restart]])\n                self.evals += num_to_restart\n\n                # Option 2: Perturb the current best solution\n                # self.x_opt = self.x_opt + np.random.normal(0, 0.1, self.dim)\n                # self.x_opt = np.clip(self.x_opt, func.bounds.lb, func.bounds.ub)\n                # self.f_opt = func(self.x_opt)\n                # self.evals += 1\n\n                # Option 3: Incorporate info from archive: replace worst individuals with archive individuals\n                if self.archive:\n                    sorted_indices = np.argsort(self.fitness)[::-1]  # Indices of worst individuals\n                    num_to_replace = min(len(self.archive), len(sorted_indices))\n                    for j in range(num_to_replace):\n                        self.pop[sorted_indices[j]] = self.archive[j % len(self.archive)].copy()\n                        self.fitness[sorted_indices[j]] = func(self.pop[sorted_indices[j]])\n                        self.evals += 1\n\n                self.no_improvement_count = 0 # reset counter after restart\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveRestartDE scored 0.064 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e13f55d5-5f30-4650-99fd-830fab077db9"], "operator": null, "metadata": {"aucs": [0.12859576359422298, 0]}}
{"id": "8763f75f-ee73-4fdf-9547-caddc2c793af", "fitness": -Infinity, "name": "AdaptiveScoutOptimization", "description": "An adaptive scout-based algorithm that dynamically adjusts its search strategy based on the landscape characteristics using a combination of orthogonal learning, Levy flights, and a self-organizing map (SOM) to maintain diversity.", "code": "import numpy as np\nfrom scipy.stats import levy\nfrom minisom import MiniSom\n\nclass AdaptiveScoutOptimization:\n    def __init__(self, budget=10000, dim=10, num_scouts=20, scout_memory=5, initial_step_size=0.1, global_attraction=0.01, orthogonal_sample_size=5, levy_scale=0.01, som_grid_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.num_scouts = num_scouts\n        self.scout_memory = scout_memory\n        self.step_size = initial_step_size\n        self.step_size_reduction_factor = 0.8\n        self.step_size_increase_factor = 1.2\n        self.global_attraction = global_attraction\n        self.orthogonal_sample_size = orthogonal_sample_size\n        self.levy_scale = levy_scale\n        self.success_threshold = 0.1\n        self.som_grid_size = som_grid_size\n\n        self.scouts = None\n        self.fitness = None\n        self.scout_moves = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.evals = 0\n        self.som = None\n\n\n    def initialize_scouts(self, func):\n        # Initialize scouts using orthogonal sampling\n        self.scouts = self.orthogonal_sampling(func.bounds.lb, func.bounds.ub, self.num_scouts)\n        self.fitness = np.array([func(x) for x in self.scouts])\n        self.evals += self.num_scouts\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.scouts[np.argmin(self.fitness)].copy()\n        self.scout_moves = [[] for _ in range(self.num_scouts)]\n\n        # Initialize SOM\n        self.som = MiniSom(self.som_grid_size, self.som_grid_size, self.dim, sigma=0.3, learning_rate=0.5)\n        self.som.train(self.scouts, num_iteration=100)\n\n\n    def orthogonal_sampling(self, lb, ub, num_samples):\n        # Generate an orthogonal array\n        if self.dim <= 1:\n            return np.random.uniform(lb, ub, size=(num_samples, self.dim))\n        \n        levels = int(np.ceil(num_samples**(1/self.dim)))\n        \n        if levels <= 1:\n           return np.random.uniform(lb, ub, size=(num_samples, self.dim))\n        \n        \n        design = np.zeros((levels**self.dim, self.dim))\n        for i in range(self.dim):\n            design[:, i] = np.tile(np.repeat(np.arange(levels), levels**i), levels**(self.dim - i - 1))[:levels**self.dim]\n        \n        # Reduce number of samples\n        if levels**self.dim > num_samples:\n          indices = np.random.choice(levels**self.dim, num_samples, replace=False)\n          design = design[indices, :]\n        \n        # Scale and shift to the given bounds\n        samples = lb + (ub - lb) * design / (levels - 1)\n        \n        return samples\n    \n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / (np.abs(v) ** (1 / beta))\n        return step\n\n\n    def __call__(self, func):\n        self.initialize_scouts(func)\n\n        while self.evals < self.budget:\n            for i in range(self.num_scouts):\n                # Determine search strategy based on SOM neuron\n                winner = self.som.winner(self.scouts[i])\n                x, y = winner\n                \n                if (x + y) % 2 == 0:  #Even neurons: Orthogonal Sampling\n                    # Generate orthogonal samples around current scout\n                    orthogonal_positions = self.orthogonal_sampling(self.scouts[i] - self.step_size, self.scouts[i] + self.step_size, self.orthogonal_sample_size)\n                    orthogonal_positions = np.clip(orthogonal_positions, func.bounds.lb, func.bounds.ub)\n                    orthogonal_fitnesses = np.array([func(x) for x in orthogonal_positions])\n                    self.evals += self.orthogonal_sample_size\n\n                    # Select the best orthogonal sample\n                    best_orthogonal_index = np.argmin(orthogonal_fitnesses)\n                    new_position = orthogonal_positions[best_orthogonal_index]\n                    new_fitness = orthogonal_fitnesses[best_orthogonal_index]\n\n                else: #Odd neurons: Levy Flight\n                    #Generate Levy flight step\n                    levy_step = self.levy_flight() * self.levy_scale\n                    new_position = self.scouts[i] + levy_step\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                    new_fitness = func(new_position)\n                    self.evals += 1\n\n                # Global Attraction\n                global_attraction_vector = self.global_attraction * (self.best_position - self.scouts[i])\n                new_position = new_position + global_attraction_vector\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Check if the move was successful\n                if new_fitness < self.fitness[i]:\n                    # Update scout's position and fitness\n                    self.scouts[i] = new_position\n                    self.fitness[i] = new_fitness\n                    self.scout_moves[i].append(True)\n                    if len(self.scout_moves[i]) > self.scout_memory:\n                        self.scout_moves[i].pop(0)\n\n                    # Update best solution if necessary\n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_position = new_position.copy()\n\n                    # Increase step size if scout is consistently successful\n                    if len(self.scout_moves[i]) == self.scout_memory and all(self.scout_moves[i]):\n                         self.step_size *= self.step_size_increase_factor\n\n                else:\n                     self.scout_moves[i].append(False)\n                     if len(self.scout_moves[i]) > self.scout_memory:\n                         self.scout_moves[i].pop(0)\n\n                     # Reduce step size if scout is consistently unsuccessful\n                     if len(self.scout_moves[i]) == self.scout_memory and not any(self.scout_moves[i]):\n                         self.step_size *= self.step_size_reduction_factor\n\n                # Adjust global attraction based on best fitness improvement\n                if self.evals > self.num_scouts:\n                    improvement = (self.best_fitness - np.min(self.fitness)) / self.best_fitness\n                    if improvement < -0.001: #Significant improvement\n                        self.global_attraction *= 1.1\n                    elif improvement > 0.001: #Degradation\n                        self.global_attraction *= 0.9\n                        \n                #Retrain SOM with updated scout positions\n                self.som.train(self.scouts, num_iteration=10)\n\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 4, "feedback": "An exception occurred: No module named 'minisom'.", "error": "", "parent_ids": ["c1016ef5-d2ea-47cc-92da-1f6dc9c81361"], "operator": null, "metadata": {}}
{"id": "c3b771d2-1ae1-4907-b008-b53d3c40b799", "fitness": 0.5117113376250813, "name": "AdaptiveScoutOptimization", "description": "An adaptive scout algorithm that uses a dynamic probability-based search direction incorporating both global best and a randomly selected scout, while also employing a success-based step size adaptation and population update strategy.", "code": "import numpy as np\n\nclass AdaptiveScoutOptimization:\n    def __init__(self, budget=10000, dim=10, num_scouts=20, initial_step_size=0.1, success_rate_threshold=0.2, exploration_probability=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.num_scouts = num_scouts\n        self.step_size = initial_step_size\n        self.success_rate_threshold = success_rate_threshold\n        self.exploration_probability = exploration_probability # Probability of exploring random scout direction\n        self.scouts = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.evals = 0\n        self.success_rates = np.zeros(num_scouts)\n        self.success_counts = np.zeros(num_scouts)\n        self.trial_counts = np.zeros(num_scouts)\n\n    def initialize_scouts(self, func):\n        self.scouts = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_scouts, self.dim))\n        self.fitness = np.array([func(x) for x in self.scouts])\n        self.evals += self.num_scouts\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.scouts[np.argmin(self.fitness)].copy()\n\n    def __call__(self, func):\n        self.initialize_scouts(func)\n\n        while self.evals < self.budget:\n            for i in range(self.num_scouts):\n                # Exploration vs. Exploitation\n                if np.random.rand() < self.exploration_probability:\n                    # Exploration: Move towards a random scout\n                    random_scout_index = np.random.randint(0, self.num_scouts)\n                    move_direction = self.scouts[random_scout_index] - self.scouts[i]\n                else:\n                    # Exploitation: Move towards the best scout\n                    move_direction = self.best_position - self.scouts[i]\n\n                # Generate a move\n                move = np.random.normal(0, self.step_size, size=self.dim) + move_direction\n                new_position = self.scouts[i] + move\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.evals += 1\n\n                # Update scout's position and fitness if the move was successful\n                if new_fitness < self.fitness[i]:\n                    self.scouts[i] = new_position\n                    self.fitness[i] = new_fitness\n\n                    # Update best solution if necessary\n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_position = new_position.copy()\n\n                    self.success_counts[i] += 1\n                    self.step_size *= 1.1  # Increase step size upon improvement\n                else:\n                    self.step_size *= 0.9  # Decrease step size if move wasn't successful\n                \n                self.trial_counts[i] += 1\n                self.success_rates[i] = self.success_counts[i] / self.trial_counts[i] if self.trial_counts[i] > 0 else 0\n\n                #Dynamic Population Update\n                if self.success_rates[i] < self.success_rate_threshold:\n                    # Replace scout with a random position if its success rate is low\n                    self.scouts[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    self.fitness[i] = func(self.scouts[i])\n                    self.evals += 1\n                    self.success_counts[i] = 0\n                    self.trial_counts[i] = 0\n                    self.success_rates[i] = 0\n                    if self.fitness[i] < self.best_fitness:\n                        self.best_fitness = self.fitness[i]\n                        self.best_position = self.scouts[i].copy()\n\n                if self.evals >= self.budget:\n                    break\n\n            self.step_size = np.clip(self.step_size, 0.0001, 1.0)  # Clamp step size\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveScoutOptimization scored 0.512 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["988dc07f-9ce5-4922-8bd3-ca22ff544046"], "operator": null, "metadata": {"aucs": [0.12320339559394433, 0.1982456380840355, 0.8013106787165359, 0.973893047201277, 0.26083312211040843, 0.9216274336544125, 0.2914550658263342, 0.6155642541339298, 0.8833421926046852, 0.18188175585840471, 0.8508963348827236, 0.9960501908038714, 0.30958662259541503, 0.3510207188282376, 0.887999336307072, 0.31145840291039106, 0.2524358871397844, 0]}}
{"id": "5175dcd8-d461-4173-ba20-f8aa36c6bff9", "fitness": 0.2831119432742052, "name": "SelfOrganizingScoutOptimization", "description": "A population-based algorithm that combines aspects of scout-based search with a self-organizing map to adaptively adjust exploration and exploitation.", "code": "import numpy as np\n\nclass SelfOrganizingScoutOptimization:\n    def __init__(self, budget=10000, dim=10, num_scouts=20, som_grid_size=5, initial_step_size=0.1, global_attraction=0.01, exploration_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_scouts = num_scouts\n        self.som_grid_size = som_grid_size  # Size of the self-organizing map grid\n        self.initial_step_size = initial_step_size\n        self.global_attraction = global_attraction\n        self.exploration_rate = exploration_rate\n        self.scouts = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.evals = 0\n        self.som = None #Self-organizing map\n        self.step_sizes = None #Individual step sizes for each scout\n\n    def initialize_scouts(self, func):\n        self.scouts = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_scouts, self.dim))\n        self.fitness = np.array([func(x) for x in self.scouts])\n        self.evals += self.num_scouts\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.scouts[np.argmin(self.fitness)].copy()\n\n        # Initialize SOM (weights are scout positions)\n        self.som = self.scouts.copy()\n        #Initialize individual step sizes\n        self.step_sizes = np.full(self.num_scouts, self.initial_step_size)\n\n\n    def update_som(self):\n        #Update SOM towards best scout\n        learning_rate = 0.1\n        for i in range(self.num_scouts):\n            self.som[i] = self.som[i] + learning_rate * (self.best_position - self.som[i])\n\n\n    def __call__(self, func):\n        self.initialize_scouts(func)\n\n        while self.evals < self.budget:\n            self.update_som()\n\n            for i in range(self.num_scouts):\n                #Exploration or exploitation\n                if np.random.rand() < self.exploration_rate:\n                    #Exploration: Random move\n                    move = np.random.normal(0, self.step_sizes[i], size=self.dim)\n                else:\n                    #Exploitation: Move towards SOM and global best\n                    attraction_to_som = self.som[i] - self.scouts[i]\n                    attraction_to_global_best = self.global_attraction * (self.best_position - self.scouts[i])\n                    move = attraction_to_som + attraction_to_global_best + np.random.normal(0, self.step_sizes[i]/2, size=self.dim)\n\n\n                new_position = self.scouts[i] + move\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.evals += 1\n\n                if new_fitness < self.fitness[i]:\n                    self.scouts[i] = new_position\n                    self.fitness[i] = new_fitness\n\n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_position = new_position.copy()\n\n                    self.step_sizes[i] *= 1.1 #Increase step size upon improvement\n                else:\n                    self.step_sizes[i] *= 0.9 #Decrease step size if move wasn't successful\n\n                if self.evals >= self.budget:\n                    break\n\n            self.step_sizes = np.clip(self.step_sizes, 0.0001, 1.0)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 4, "feedback": "The algorithm SelfOrganizingScoutOptimization scored 0.283 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["988dc07f-9ce5-4922-8bd3-ca22ff544046"], "operator": null, "metadata": {"aucs": [0.12471670327039719, 0.18667893823468962, 0.3795927126825376, 0.28360803620269803, 0.2058766474707795, 0.33596067928440254, 0.24193077167354027, 0.2502713484806566, 0.25020152043529054, 0.16037298655367682, 0.1874319793130741, 0.9713093766229894, 0.2572723846734001, 0.19944976494713473, 0.1730200816592451, 0.33309390854211407, 0.3100859570321519, 0.17835963476422034, 0.17896871098531553, 0.45403672265579076]}}
{"id": "c535e719-3234-4d81-b784-e1e31f10ab7c", "fitness": 0.1803198393541911, "name": "AdaptiveScoutOptimization", "description": "An adaptive scout algorithm that uses a combination of exploration and exploitation, adjusting step sizes based on the success rate of scout movements and incorporating a repulsive force from the worst-performing scout to enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveScoutOptimization:\n    def __init__(self, budget=10000, dim=10, num_scouts=20, initial_step_size=0.1, success_memory=10, repulsion_factor=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.num_scouts = num_scouts\n        self.step_size = initial_step_size\n        self.success_memory = success_memory  # Number of past moves to remember for success rate calculation\n        self.success_history = []\n        self.scouts = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.evals = 0\n        self.repulsion_factor = repulsion_factor\n\n    def initialize_scouts(self, func):\n        self.scouts = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_scouts, self.dim))\n        self.fitness = np.array([func(x) for x in self.scouts])\n        self.evals += self.num_scouts\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.scouts[np.argmin(self.fitness)].copy()\n\n    def __call__(self, func):\n        self.initialize_scouts(func)\n\n        while self.evals < self.budget:\n            worst_scout_index = np.argmax(self.fitness)\n            worst_scout = self.scouts[worst_scout_index]\n\n            for i in range(self.num_scouts):\n                # Generate a move with adaptive step size\n                move = np.random.normal(0, self.step_size, size=self.dim)\n\n                # Add repulsion from the worst performing scout\n                repulsion_vector = self.repulsion_factor * (self.scouts[i] - worst_scout)\n                move += repulsion_vector\n\n                new_position = self.scouts[i] + move\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.evals += 1\n\n                # Update scout's position and fitness if the move was successful\n                if new_fitness < self.fitness[i]:\n                    self.scouts[i] = new_position\n                    self.fitness[i] = new_fitness\n\n                    # Update best solution if necessary\n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_position = new_position.copy()\n                    \n                    self.success_history.append(1)\n                else:\n                    self.success_history.append(0)\n\n                # Keep track of success history\n                if len(self.success_history) > self.success_memory:\n                    self.success_history.pop(0)\n\n                # Adjust step size based on success rate\n                if len(self.success_history) > 0:\n                    success_rate = np.mean(self.success_history)\n                    if success_rate > 0.5:\n                        self.step_size *= 1.1  # Increase step size if success rate is high\n                    else:\n                        self.step_size *= 0.9  # Decrease step size if success rate is low\n\n                self.step_size = np.clip(self.step_size, 0.0001, 1.0) #clamp step size\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveScoutOptimization scored 0.180 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["988dc07f-9ce5-4922-8bd3-ca22ff544046"], "operator": null, "metadata": {"aucs": [0.06913154733033366, 0.14683278441188174, 0.217225225723222, 0.1259428050528082, 0.13364004215602, 0.19298412665406695, 0.18798782819698567, 0.10661738082170069, 0.13488367941850177, 0.13025778976186053, 0.14468156437927504, 0.19939757222314192, 0.23653291293479428, 0.168556674514169, 0.18434439737194397, 0.24316790380137077, 0.16549702879899775, 0.2563649711097997, 0.14090361380699012, 0.4214469386159584]}}
{"id": "feb8828c-4373-44dd-a473-91557073b756", "fitness": 0.6016856220787279, "name": "AdaptiveDE", "description": "An adaptive differential evolution strategy that dynamically adjusts its parameters based on population fitness improvement and stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.stagnation_threshold = stagnation_threshold\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7  # Initial crossover rate\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.best_fitness_history.append(self.f_opt)\n        self.stagnation_counter = 0\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Adaptive parameter control\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                if self.best_fitness_history[-self.stagnation_threshold] == self.f_opt:\n                    self.stagnation_counter += 1\n                else:\n                    self.stagnation_counter = 0\n\n                if self.stagnation_counter > self.stagnation_threshold // 2:\n                    # Stagnation detected: increase exploration\n                    self.F = np.clip(self.F * 1.1, 0.1, 1.0)\n                    self.CR = np.clip(self.CR * 0.9, 0.1, 1.0)\n                    \n                else:\n                    # Otherwise, focus on exploitation\n                    self.F = np.clip(self.F * 0.9, 0.1, 1.0)\n                    self.CR = np.clip(self.CR * 1.1, 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.602 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e13f55d5-5f30-4650-99fd-830fab077db9"], "operator": null, "metadata": {"aucs": [0.22671316735707536, 0.4172268751648839, 0.5353183554060945, 0.8411585053385192, 0.62439186097761, 0.7648467974865252, 0.5269756057968356, 0.5235807300230018, 0.6243861346877261, 0.5878750461856834, 0.7816756510169829, 1.0, 0.3301830670603795, 0.6069012675677169, 0.8650815984230336, 0.7297396547957443, 0.4624717238117704, 0.8158584740673245, 0.2509243469878675, 0.5184035794197834]}}
{"id": "3edcf6d4-b850-400e-8f84-e2ce815b16b7", "fitness": 0.49957532305376395, "name": "AdaptiveCauchyDE", "description": "An adaptive differential evolution algorithm that adjusts its scaling factor and crossover rate based on the success rate of recent generations, incorporating a Cauchy mutation for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveCauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7  # Initial crossover rate\n        self.success_F = np.ones(self.memory_size) * self.F\n        self.success_CR = np.ones(self.memory_size) * self.CR\n        self.success_history = []\n        self.memory_idx = 0\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            successful_mutations = 0\n            temp_pop = np.copy(self.pop)\n            temp_fitness = np.copy(self.fitness)\n\n            for i in range(self.pop_size):\n                # Mutation strategy: DE/rand/1 with Cauchy perturbation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                cauchy_noise = np.random.standard_cauchy(size=self.dim) * 0.01 # scale cauchy to avoid large steps\n                mutant = x_r1 + self.F * (x_r2 - x_r3) + cauchy_noise\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    temp_fitness[i] = f_trial\n                    temp_pop[i] = trial\n                    successful_mutations += 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            self.pop = temp_pop\n            self.fitness = temp_fitness\n\n            # Adaptive F and CR\n            if successful_mutations > 0:\n                self.success_history.append(successful_mutations / self.pop_size)\n            else:\n                self.success_history.append(0)\n            \n            if len(self.success_history) > self.memory_size:\n                self.success_history.pop(0)\n\n            if len(self.success_history) == self.memory_size:\n                success_rate = np.mean(self.success_history)\n                if success_rate > 0.2:\n                    self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n                    self.CR = np.clip(np.random.normal(self.CR, 0.1), 0.1, 1.0)\n                else:\n                    self.F = np.clip(np.random.normal(self.F, 0.2), 0.1, 1.0) #Increase exploration if success is low\n                    self.CR = np.clip(np.random.normal(self.CR, 0.2), 0.1, 1.0)\n                    \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveCauchyDE scored 0.500 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e13f55d5-5f30-4650-99fd-830fab077db9"], "operator": null, "metadata": {"aucs": [0.21299455309514892, 0.31946011480195025, 0.4415892450358163, 0.8115795306250095, 0.44576358533418936, 0.5462409688093587, 0.34081424989702613, 0.4247281021520445, 0.4740758785888167, 0.3512848682369156, 0.7109084712233475, 0.9964468023015723, 0.31075432915839896, 0.4476965960692679, 0.8096977754371132, 0.5862721702768604, 0.35993538527100577, 0.6546605600432234, 0.2269852486886662, 0.5196180260295433]}}
{"id": "75ccb14e-77e3-4958-9619-5056de963773", "fitness": 0.339260047427965, "name": "AdaptiveDE", "description": "An adaptive Differential Evolution algorithm that uses a dynamic population size and a mutation strategy biased towards both the best solution and a diversity-promoting centroid.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.F = 0.5\n        self.CR = 0.7\n        self.success_memory_F = []\n        self.success_memory_CR = []\n        self.archive = []\n        self.archive_rate = 0.1\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.generation = 0\n\n        while self.evals < self.budget:\n            self.generation += 1\n            \n            # Adaptive Population Size\n            if self.generation % 10 == 0:\n                if len(self.success_memory_F) > 0:\n                    adjust_rate = np.mean(self.success_memory_F) - 0.5\n                    self.pop_size = int(max(self.min_pop_size, self.pop_size * (1 + adjust_rate * self.learning_rate)))\n                    self.pop_size = min(self.pop_size, self.budget - self.evals)\n                    \n                    # Resize population if needed\n                    if self.pop_size != self.pop.shape[0]:\n                        if self.pop_size < self.pop.shape[0]:\n                            # Remove worst individuals\n                            indices_to_remove = np.argsort(self.fitness)[- (self.pop.shape[0] - self.pop_size):]\n                            self.pop = np.delete(self.pop, indices_to_remove, axis=0)\n                            self.fitness = np.delete(self.fitness, indices_to_remove)\n                        else:\n                            # Add random individuals\n                            num_new_individuals = self.pop_size - self.pop.shape[0]\n                            new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new_individuals, self.dim))\n                            new_fitness = np.array([func(x) for x in new_individuals])\n                            self.pop = np.vstack((self.pop, new_individuals))\n                            self.fitness = np.concatenate((self.fitness, new_fitness))\n                            self.evals += num_new_individuals\n\n                self.success_memory_F = []\n                self.success_memory_CR = []\n\n\n            for i in range(self.pop.shape[0]):\n                # Mutation\n                idxs = np.random.choice(self.pop.shape[0], 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n\n                # Centroid Calculation\n                centroid = np.mean(self.pop, axis=0)\n\n                # Mutation strategy biased towards best and centroid\n                mutant = x_r1 + self.F * (x_r2 - x_r3) + self.F * (self.x_opt - self.pop[i]) + self.F * (centroid - self.pop[i])\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.success_memory_F.append(self.F)\n                    self.success_memory_CR.append(self.CR)\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        \n                    # Archive\n                    if np.random.rand() < self.archive_rate:\n                        self.archive.append(self.pop[i].copy())\n                        if len(self.archive) > self.pop_size:\n                            self.archive.pop(0)\n\n            # Adapt F and CR - based on success in current generation\n            if len(self.success_memory_F) > 0:\n                self.F = np.clip(np.random.normal(np.mean(self.success_memory_F), 0.1), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(np.mean(self.success_memory_CR), 0.1), 0.1, 1.0)\n            else:\n                self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.339 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["bc62416b-61a7-4ef8-ac46-fc47f673a3a0"], "operator": null, "metadata": {"aucs": [0.4754473140442146, 0.5423328282396804, 0]}}
{"id": "75a905d2-f38a-48b3-835c-d509e2d25337", "fitness": -Infinity, "name": "GPSurrogateDE", "description": "A hybrid algorithm combining differential evolution with a Gaussian process surrogate model to guide the search towards promising regions, balancing exploration and exploitation.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel, WhiteKernel\nfrom scipy.stats import norm\n\nclass GPSurrogateDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, exploration_weight=0.1, initial_design_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.exploration_weight = exploration_weight\n        self.initial_design_size = initial_design_size\n        self.F = 0.5  # Differential evolution parameter\n        self.CR = 0.7  # Crossover rate\n\n        # Gaussian Process parameters\n        self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=(1e-1, 10.0)) + WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-3, 1.0))\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=5, alpha=1e-5)\n        self.X = None\n        self.y = None\n\n    def expected_improvement(self, x, gp, xi=0.01):\n        \"\"\"Calculates the expected improvement at points x\"\"\"\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        mu_sample_opt = np.max(self.y)\n\n        with np.errstate(divide='warn'):\n            imp = mu - mu_sample_opt - xi\n            Z = imp / sigma\n            ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n\n        return ei\n\n    def __call__(self, func):\n        # Initial Design (Latin Hypercube Sampling could be used for better coverage)\n        self.X = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.initial_design_size, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.evals = self.initial_design_size\n\n        self.f_opt = np.min(self.y)\n        self.x_opt = self.X[np.argmin(self.y)]\n        \n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.evals += self.pop_size\n        \n        self.f_opt = np.min(np.concatenate((self.y, self.fitness)))\n        self.x_opt = self.X[np.argmin(np.concatenate((self.y, self.fitness)))] if np.argmin(np.concatenate((self.y, self.fitness))) < len(self.y) else self.pop[np.argmin(self.fitness)]\n\n        # Augment initial design with initial population for GP training\n        self.X = np.concatenate((self.X, self.pop), axis=0)\n        self.y = np.concatenate((self.y, self.fitness))\n\n        while self.evals < self.budget:\n            # Train Gaussian Process\n            self.gp.fit(self.X, self.y)\n\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Expected Improvement based Selection\n                ei = self.expected_improvement(trial, self.gp)\n                f_trial = func(trial)\n                self.evals += 1\n\n                if ei > self.exploration_weight * (self.f_opt - f_trial): # Weigh EI against actual improvement to balance exploration\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update GP training data\n                    self.X = np.vstack((self.X, trial))\n                    self.y = np.append(self.y, f_trial)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial\n                    \n            # Adjust F and CR adaptively (optional)\n            self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occurred: name 'ConstantKernel' is not defined.", "error": "", "parent_ids": ["bc62416b-61a7-4ef8-ac46-fc47f673a3a0"], "operator": null, "metadata": {}}
{"id": "dc0d9699-9753-4cb5-8fe5-a5932d08a1b8", "fitness": 0.0, "name": "GradientAdaptiveSearch", "description": "A population-based metaheuristic where individuals adapt their search behavior based on the fitness landscape gradient estimation using a few function evaluations around each individual.", "code": "import numpy as np\n\nclass GradientAdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, population_size=20, step_size=0.1, num_gradient_evaluations=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.step_size = step_size\n        self.num_gradient_evaluations = num_gradient_evaluations\n        self.population = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.evals = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals += self.population_size\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.population[np.argmin(self.fitness)].copy()\n\n    def estimate_gradient(self, func, x):\n        gradient = np.zeros(self.dim)\n        for i in range(self.dim):\n            delta = np.zeros(self.dim)\n            delta[i] = self.step_size  # Use a small step size for gradient estimation\n            \n            x_plus = np.clip(x + delta, func.bounds.lb, func.bounds.ub)\n            x_minus = np.clip(x - delta, func.bounds.lb, func.bounds.ub)\n            \n            f_plus = func(x_plus)\n            f_minus = func(x_minus)\n            self.evals += 2  # Count two function evaluations\n            \n            gradient[i] = (f_plus - f_minus) / (2 * self.step_size)\n        return gradient\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.evals < self.budget:\n            for i in range(self.population_size):\n                # Estimate gradient\n                gradient = self.estimate_gradient(func, self.population[i])\n\n                # Move against the gradient (toward lower fitness)\n                move = -self.step_size * gradient\n                new_position = self.population[i] + move\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.evals += 1\n\n                # Update if the move was successful\n                if new_fitness < self.fitness[i]:\n                    self.population[i] = new_position\n                    self.fitness[i] = new_fitness\n\n                    # Update best solution if necessary\n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_position = new_position.copy()\n                else:\n                    # Reduce step size if the move was not successful\n                    self.step_size *= 0.9\n\n                if self.evals >= self.budget:\n                    break\n\n            # Adjust step size dynamically\n            self.step_size = np.clip(self.step_size, 0.0001, 1.0)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 5, "feedback": "The algorithm GradientAdaptiveSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c3b771d2-1ae1-4907-b008-b53d3c40b799"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "60330801-fc3e-4fa4-ac20-25e9a41e07e3", "fitness": -Infinity, "name": "StrategyAdaptiveDE", "description": "An adaptive Differential Evolution variant that uses a pool of mutation strategies and self-adapts the selection probability of each strategy based on its recent success.", "code": "import numpy as np\n\nclass StrategyAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, strategy_pool_size=4, success_history_length=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.strategy_pool_size = strategy_pool_size\n        self.success_history_length = success_history_length\n\n        self.F = 0.5 * np.ones(self.strategy_pool_size)\n        self.CR = 0.7 * np.ones(self.strategy_pool_size)\n        self.strategy_weights = np.ones(self.strategy_pool_size) / self.strategy_pool_size\n        self.success_history = [[] for _ in range(self.strategy_pool_size)]\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Strategy selection\n                strategy_index = np.random.choice(self.strategy_pool_size, p=self.strategy_weights)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                \n                # Different mutation strategies\n                if strategy_index == 0:\n                    mutant = x_r1 + self.F[strategy_index] * (x_r2 - x_r3)\n                elif strategy_index == 1:\n                    mutant = self.x_opt + self.F[strategy_index] * (x_r1 - x_r2)\n                elif strategy_index == 2:\n                     mutant = self.pop[i] + self.F[strategy_index] * (self.x_opt - self.pop[i]) + self.F[strategy_index] * (x_r1 - x_r2)\n                else:\n                    mutant = x_r1 + self.F[strategy_index] * (x_r2 - x_r3) + np.random.normal(0, 0.1, self.dim) # Add noise\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR[strategy_index]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                    \n                    self.success_history[strategy_index].append(1)\n                else:\n                    self.success_history[strategy_index].append(0)\n\n                # Keep success history length limited\n                if len(self.success_history[strategy_index]) > self.success_history_length:\n                    self.success_history[strategy_index].pop(0)\n\n            # Update strategy weights based on success history\n            for k in range(self.strategy_pool_size):\n                if self.success_history[k]:\n                    self.strategy_weights[k] = np.mean(self.success_history[k])\n                else:\n                    self.strategy_weights[k] = 1e-6 # Avoid zero probability\n\n            self.strategy_weights /= np.sum(self.strategy_weights) # Normalize\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occurred: probabilities contain NaN.", "error": "", "parent_ids": ["feb8828c-4373-44dd-a473-91557073b756"], "operator": null, "metadata": {}}
{"id": "b486804e-6a57-4782-a9ee-2dd3082d190c", "fitness": -Infinity, "name": "CMAES", "description": "Covariance Matrix Adaptation Evolution Strategy with adaptive population size based on success rate.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.mu = self.pop_size // 2  # Number of parents\n        self.mean = np.zeros(self.dim)  # Initial mean\n        self.sigma = 0.5  # Initial step size\n        self.C = np.eye(self.dim)  # Initial covariance matrix\n        self.ps = np.zeros(self.dim)  # Evolution path for step size\n        self.pc = np.zeros(self.dim)  # Evolution path for covariance matrix\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))  # Expectation of ||N(0,I)||\n        self.c_sigma = (self.mu + 2) / (self.dim + self.mu + 5)\n        self.c_c = (4 + self.mu / self.dim) / (self.dim + 4 + 2 * self.mu / self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 1 + 1 / self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.evals = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.success_rate = 0.0\n        self.success_history = []\n        self.success_window = 20\n\n    def __call__(self, func):\n        while self.evals < self.budget:\n            # Generate population\n            z = np.random.randn(self.pop_size, self.dim)\n            x = self.mean + self.sigma * z @ np.linalg.cholesky(self.C).T\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            self.evals += self.pop_size\n\n            # Update best solution\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n                self.success_rate += 0.1\n            else:\n                self.success_rate -= 0.05\n            self.success_rate = np.clip(self.success_rate, 0.0, 1.0)\n            self.success_history.append(1 if np.min(fitness) < self.f_opt else 0)\n            if len(self.success_history) > self.success_window:\n              self.success_history.pop(0)\n\n            # Selection and recombination\n            idx = np.argsort(fitness)\n            x_mu = x[idx[:self.mu]]\n            z_mu = z[idx[:self.mu]]\n\n            self.mean = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * np.sqrt(np.sum(self.weights**2)) * (zmean @ np.linalg.inv(np.linalg.cholesky(self.C)).T)\n            \n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * np.outer(self.pc, self.pc)\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * np.outer(z_mu[k], z_mu[k])\n\n            # Update step size\n            self.sigma = self.sigma * np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Adaptive Population Size\n            if len(self.success_history) >= self.success_window:\n              recent_success_rate = np.mean(self.success_history[-self.success_window:])\n              if recent_success_rate > 0.3:\n                self.pop_size = min(self.pop_size + 1, 100)\n                self.mu = self.pop_size // 2\n              elif recent_success_rate < 0.1:\n                self.pop_size = max(self.pop_size - 1, 5)\n                self.mu = self.pop_size // 2\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occurred: operands could not be broadcast together with shapes (5,1) (4,5) .", "error": "", "parent_ids": ["feb8828c-4373-44dd-a473-91557073b756"], "operator": null, "metadata": {}}
{"id": "e89be183-fb50-4fc3-95a7-fc365fa6c681", "fitness": 0.0, "name": "AdaptiveDECMA", "description": "An adaptive Differential Evolution strategy with a self-adaptive covariance matrix adaptation inspired mutation, dynamically adjusting mutation strength based on success history.", "code": "import numpy as np\n\nclass AdaptiveDECMA:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.learning_rate = learning_rate\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7 # Initial crossover rate\n        self.success_memory_F = []\n        self.success_memory_CR = []\n        self.archive = []\n        self.archive_rate = 0.1\n        \n        self.C = np.eye(dim)  # Covariance matrix for CMA-ES like adaptation\n        self.tau = 1 / np.sqrt(2 * dim)  # Learning rate for step size\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.generation = 0\n        self.sigma = 0.1 * (func.bounds.ub - func.bounds.lb) #Global step size\n\n        while self.evals < self.budget:\n            self.generation += 1\n\n            # Adaptive Population Size\n            if self.generation % 10 == 0:\n                if len(self.success_memory_F) > 0:\n                    adjust_rate = np.mean(self.success_memory_F) - 0.5\n                    self.pop_size = int(max(self.min_pop_size, self.pop_size * (1 + adjust_rate * self.learning_rate)))\n                    self.pop_size = min(self.pop_size, self.budget - self.evals)\n                    \n                    # Resize population if needed\n                    if self.pop_size != self.pop.shape[0]:\n                        if self.pop_size < self.pop.shape[0]:\n                            # Remove worst individuals\n                            indices_to_remove = np.argsort(self.fitness)[- (self.pop.shape[0] - self.pop_size):]\n                            self.pop = np.delete(self.pop, indices_to_remove, axis=0)\n                            self.fitness = np.delete(self.fitness, indices_to_remove)\n                        else:\n                            # Add random individuals\n                            num_new_individuals = self.pop_size - self.pop.shape[0]\n                            new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new_individuals, self.dim))\n                            new_fitness = np.array([func(x) for x in new_individuals])\n                            self.pop = np.vstack((self.pop, new_individuals))\n                            self.fitness = np.concatenate((self.fitness, new_fitness))\n                            self.evals += num_new_individuals\n\n                self.success_memory_F = []\n                self.success_memory_CR = []\n            \n            # Iterate through the population\n            for i in range(self.pop.shape[0]):\n                # Mutation using CMA-ES inspired approach\n                z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                mutant = self.pop[i] + self.sigma * z \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.success_memory_F.append(self.F)\n                    self.success_memory_CR.append(self.CR)\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                    \n                    # Update covariance matrix adaptively\n                    d = self.pop[i] - self.pop[np.random.choice(self.pop.shape[0])]\n                    self.C = (1 - self.learning_rate) * self.C + self.learning_rate * np.outer(d, d)\n                    \n                    # Adaptive step size (sigma)\n                    self.sigma *= np.exp(self.tau * (f_trial - self.fitness[i]) / self.fitness[i]) # Heuristic adaptation\n                        \n                    # Archive\n                    if np.random.rand() < self.archive_rate:\n                        self.archive.append(self.pop[i].copy())\n                        if len(self.archive) > self.pop_size:\n                            self.archive.pop(0)\n\n            # Adapt F and CR - based on success in current generation\n            if len(self.success_memory_F) > 0:\n                self.F = np.clip(np.random.normal(np.mean(self.success_memory_F), 0.1), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(np.mean(self.success_memory_CR), 0.1), 0.1, 1.0)\n            else:\n                self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDECMA scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["75ccb14e-77e3-4958-9619-5056de963773"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "96891c25-21ff-4491-b512-fb67f54fe520", "fitness": 0.0, "name": "VelocityAdaptiveDE", "description": "An adaptive Differential Evolution strategy incorporating a velocity-based mutation inspired by Particle Swarm Optimization (PSO) to guide the search and an aging mechanism to promote exploration.", "code": "import numpy as np\n\nclass VelocityAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.F = 0.5\n        self.CR = 0.7\n        self.success_memory_F = []\n        self.success_memory_CR = []\n        self.archive = []\n        self.archive_rate = 0.1\n        self.learning_rate = 0.1\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocities = None\n        self.age = None\n        self.max_age = 50\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.generation = 0\n        self.velocities = np.zeros_like(self.pop)\n        self.age = np.zeros(self.pop_size)\n\n        while self.evals < self.budget:\n            self.generation += 1\n            \n            # Adaptive Population Size\n            if self.generation % 10 == 0:\n                if len(self.success_memory_F) > 0:\n                    adjust_rate = np.mean(self.success_memory_F) - 0.5\n                    self.pop_size = int(max(self.min_pop_size, self.pop_size * (1 + adjust_rate * self.learning_rate)))\n                    self.pop_size = min(self.pop_size, self.budget - self.evals)\n                    \n                    # Resize population if needed\n                    if self.pop_size != self.pop.shape[0]:\n                        if self.pop_size < self.pop.shape[0]:\n                            # Remove worst individuals\n                            indices_to_remove = np.argsort(self.fitness)[- (self.pop.shape[0] - self.pop_size):]\n                            self.pop = np.delete(self.pop, indices_to_remove, axis=0)\n                            self.fitness = np.delete(self.fitness, indices_to_remove)\n                            self.velocities = np.delete(self.velocities, indices_to_remove, axis=0)\n                            self.age = np.delete(self.age, indices_to_remove, axis=0)\n                        else:\n                            # Add random individuals\n                            num_new_individuals = self.pop_size - self.pop.shape[0]\n                            new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new_individuals, self.dim))\n                            new_fitness = np.array([func(x) for x in new_individuals])\n                            new_velocities = np.zeros((num_new_individuals, self.dim))\n                            new_age = np.zeros(num_new_individuals)\n\n                            self.pop = np.vstack((self.pop, new_individuals))\n                            self.fitness = np.concatenate((self.fitness, new_fitness))\n                            self.velocities = np.vstack((self.velocities, new_velocities))\n                            self.age = np.concatenate((self.age, new_age))\n\n                            self.evals += num_new_individuals\n\n                self.success_memory_F = []\n                self.success_memory_CR = []\n\n\n            for i in range(self.pop.shape[0]):\n                # Mutation\n                idxs = np.random.choice(self.pop.shape[0], 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n\n                # Velocity update inspired by PSO\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = (self.inertia * self.velocities[i] +\n                                      self.cognitive_coeff * r1 * (self.x_opt - self.pop[i]) +\n                                      self.social_coeff * r2 * (x_r1 - self.pop[i])) #Using x_r1 as social component\n\n                # Mutation using velocity\n                mutant = self.pop[i] + self.velocities[i]\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.success_memory_F.append(self.F)\n                    self.success_memory_CR.append(self.CR)\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    self.age[i] = 0 # Reset age\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        \n                    # Archive\n                    if np.random.rand() < self.archive_rate:\n                        self.archive.append(self.pop[i].copy())\n                        if len(self.archive) > self.pop_size:\n                            self.archive.pop(0)\n                else:\n                    self.age[i] += 1\n\n                    # Aging mechanism: Re-initialize if age exceeds max_age\n                    if self.age[i] > self.max_age:\n                        self.pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                        self.fitness[i] = func(self.pop[i])\n                        self.velocities[i] = np.zeros(self.dim)\n                        self.age[i] = 0\n                        self.evals += 1\n\n\n            # Adapt F and CR - based on success in current generation\n            if len(self.success_memory_F) > 0:\n                self.F = np.clip(np.random.normal(np.mean(self.success_memory_F), 0.1), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(np.mean(self.success_memory_CR), 0.1), 0.1, 1.0)\n            else:\n                self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm VelocityAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["75ccb14e-77e3-4958-9619-5056de963773"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "f1547bbf-3698-425a-8ea3-b4f1e5b1edf7", "fitness": 0.2694013610887693, "name": "SelfOrganizingScoutOptimization", "description": "Implements a self-organizing scout algorithm that adapts its search behavior based on scout performance, dynamically adjusting step sizes and search biases towards promising regions while ensuring diversity through occasional random exploration.", "code": "import numpy as np\n\nclass SelfOrganizingScoutOptimization:\n    def __init__(self, budget=10000, dim=10, num_scouts=20, initial_step_size=0.1, inertia_weight=0.7, social_attraction=1.49, random_attraction=1.49, stagnation_threshold=10):\n        self.budget = budget\n        self.dim = dim\n        self.num_scouts = num_scouts\n        self.step_size = initial_step_size\n        self.inertia_weight = inertia_weight\n        self.social_attraction = social_attraction\n        self.random_attraction = random_attraction\n        self.stagnation_threshold = stagnation_threshold\n        self.scouts = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.evals = 0\n        self.velocities = None\n        self.stagnation_counters = np.zeros(num_scouts)\n\n    def initialize_scouts(self, func):\n        self.scouts = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_scouts, self.dim))\n        self.fitness = np.array([func(x) for x in self.scouts])\n        self.evals += self.num_scouts\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.scouts[np.argmin(self.fitness)].copy()\n        self.velocities = np.zeros((self.num_scouts, self.dim))\n\n    def __call__(self, func):\n        self.initialize_scouts(func)\n\n        while self.evals < self.budget:\n            for i in range(self.num_scouts):\n                # Update velocity using PSO-like update rule\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                cognitive_component = self.social_attraction * r1 * (self.best_position - self.scouts[i])\n                social_component = self.random_attraction * r2 * (self.scouts[np.random.randint(0, self.num_scouts)] - self.scouts[i]) # Attract to random scout.\n\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_component + social_component\n                \n                # Limit velocity to control exploration\n                self.velocities[i] = np.clip(self.velocities[i], -self.step_size, self.step_size)\n\n                # Move the scout\n                new_position = self.scouts[i] + self.velocities[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.evals += 1\n\n                # Update scout's position and fitness if the move was successful\n                if new_fitness < self.fitness[i]:\n                    self.scouts[i] = new_position\n                    self.fitness[i] = new_fitness\n\n                    # Update best solution if necessary\n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_position = new_position.copy()\n                        self.stagnation_counters[:] = 0 # Reset stagnation counters\n                    else:\n                        self.stagnation_counters[i] = 0\n\n                    self.step_size *= 1.05 # Increase step size slightly upon improvement\n                else:\n                    self.stagnation_counters[i] += 1\n                    self.step_size *= 0.95 # Decrease step size if move wasn't successful\n\n\n                # Stagnation check and re-initialization\n                if self.stagnation_counters[i] > self.stagnation_threshold:\n                    self.scouts[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    self.fitness[i] = func(self.scouts[i])\n                    self.evals += 1\n                    self.velocities[i] = np.zeros(self.dim)  # Reset velocity\n                    self.stagnation_counters[i] = 0\n                    if self.fitness[i] < self.best_fitness:\n                        self.best_fitness = self.fitness[i]\n                        self.best_position = self.scouts[i].copy()\n                    self.step_size = 0.1 #reset step size if scout is reinitialized\n\n                if self.evals >= self.budget:\n                    break\n\n            self.step_size = np.clip(self.step_size, 0.0001, 1.0)  # Clamp step size\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 5, "feedback": "The algorithm SelfOrganizingScoutOptimization scored 0.269 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c3b771d2-1ae1-4907-b008-b53d3c40b799"], "operator": null, "metadata": {"aucs": [0.10627858898642295, 0.2464775594313915, 0.7770185598326376, 0.17533633844153318, 0.31129711984063035, 0]}}
{"id": "c28f0803-eac4-446a-a90f-26cf5a5c1eff", "fitness": 0.0, "name": "OrthogonalAdaptiveDE", "description": "An adaptive differential evolution strategy that incorporates orthogonal learning to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass OrthogonalAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.F = 0.5\n        self.CR = 0.7\n        self.success_memory_F = []\n        self.success_memory_CR = []\n        self.archive = []\n        self.archive_rate = 0.1\n        self.learning_rate = 0.1\n        self.orthogonal_array = self._create_orthogonal_array()\n\n    def _create_orthogonal_array(self, strength=2):\n         # This simplified orthogonal array creation serves as a placeholder.\n        # For real-world applications, consider using more robust libraries.\n        levels = 3  # Define the number of levels for each factor\n        array_size = levels ** strength\n        factors = strength # Define number of factors to test.\n\n        array = np.zeros((array_size, factors), dtype=int)\n        for i in range(factors):\n            for j in range(array_size):\n                array[j, i] = (j // (levels ** i)) % levels\n\n        return array / (levels - 1)\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.generation = 0\n\n        while self.evals < self.budget:\n            self.generation += 1\n            \n            # Adaptive Population Size\n            if self.generation % 10 == 0:\n                if len(self.success_memory_F) > 0:\n                    adjust_rate = np.mean(self.success_memory_F) - 0.5\n                    self.pop_size = int(max(self.min_pop_size, self.pop_size * (1 + adjust_rate * self.learning_rate)))\n                    self.pop_size = min(self.pop_size, self.budget - self.evals)\n                    \n                    # Resize population if needed\n                    if self.pop_size != self.pop.shape[0]:\n                        if self.pop_size < self.pop.shape[0]:\n                            # Remove worst individuals\n                            indices_to_remove = np.argsort(self.fitness)[- (self.pop.shape[0] - self.pop_size):]\n                            self.pop = np.delete(self.pop, indices_to_remove, axis=0)\n                            self.fitness = np.delete(self.fitness, indices_to_remove)\n                        else:\n                            # Add random individuals\n                            num_new_individuals = self.pop_size - self.pop.shape[0]\n                            new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new_individuals, self.dim))\n                            new_fitness = np.array([func(x) for x in new_individuals])\n                            self.pop = np.vstack((self.pop, new_individuals))\n                            self.fitness = np.concatenate((self.fitness, new_fitness))\n                            self.evals += num_new_individuals\n\n                self.success_memory_F = []\n                self.success_memory_CR = []\n\n\n            for i in range(self.pop.shape[0]):\n                # Mutation\n                idxs = np.random.choice(self.pop.shape[0], 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n\n                # Centroid Calculation\n                centroid = np.mean(self.pop, axis=0)\n\n                # Mutation strategy biased towards best and centroid\n                mutant = x_r1 + self.F * (x_r2 - x_r3) + self.F * (self.x_opt - self.pop[i]) + self.F * (centroid - self.pop[i])\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Learning\n                trial = self._orthogonal_learning(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.success_memory_F.append(self.F)\n                    self.success_memory_CR.append(self.CR)\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        \n                    # Archive\n                    if np.random.rand() < self.archive_rate:\n                        self.archive.append(self.pop[i].copy())\n                        if len(self.archive) > self.pop_size:\n                            self.archive.pop(0)\n\n            # Adapt F and CR - based on success in current generation\n            if len(self.success_memory_F) > 0:\n                self.F = np.clip(np.random.normal(np.mean(self.success_memory_F), 0.1), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(np.mean(self.success_memory_CR), 0.1), 0.1, 1.0)\n            else:\n                self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n        return self.f_opt, self.x_opt\n\n    def _orthogonal_learning(self, trial, lb, ub):\n        # Select a random subset of dimensions to vary based on orthogonal array\n        num_vars = min(self.dim, self.orthogonal_array.shape[1])\n        selected_dims = np.random.choice(self.dim, num_vars, replace=False)\n        \n        # Use the orthogonal array to generate different combinations\n        new_trials = np.zeros((self.orthogonal_array.shape[0], self.dim))\n        for i in range(self.orthogonal_array.shape[0]):\n            new_trial = trial.copy()\n            for j, dim_index in enumerate(selected_dims):\n                new_trial[dim_index] = lb[0] + self.orthogonal_array[i, j] * (ub[0] - lb[0])\n            new_trials[i, :] = new_trial\n\n        # Evaluate all new trials (without exceeding budget!)\n        fitness_values = []\n        for new_trial in new_trials:\n            # Clip new_trial values to respect the bounds\n            new_trial = np.clip(new_trial, lb, ub)\n            \n            fitness_values.append(float('inf'))  # Return a very bad fitness if out of budget.\n\n        return trial", "configspace": "", "generation": 5, "feedback": "The algorithm OrthogonalAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["75ccb14e-77e3-4958-9619-5056de963773"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "3edb6279-d4d5-4dbc-a2fd-a9508076c300", "fitness": 0.4208107307628114, "name": "SelfOrganizingScoutBee", "description": "A self-organizing scout bee algorithm that adaptively adjusts scout bee frequency and search radius based on population diversity and improvement rate.", "code": "import numpy as np\n\nclass SelfOrganizingScoutBee:\n    def __init__(self, budget=10000, dim=10, pop_size=50, scout_frequency=0.1, initial_search_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.scout_frequency = scout_frequency  # Probability of a bee becoming a scout\n        self.initial_search_radius = initial_search_radius\n        self.search_radius = initial_search_radius  # Adaptive search radius\n        self.diversity_weight = 0.5 #Weighting for diversity vs improvement\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            new_pop = np.copy(self.pop)\n            new_fitness = np.copy(self.fitness)\n\n            for i in range(self.pop_size):\n                if np.random.rand() < self.scout_frequency:\n                    # Scout bee: explore a random location within the search radius\n                    new_bee = self.pop[i] + np.random.uniform(-self.search_radius, self.search_radius, size=self.dim)\n                    new_bee = np.clip(new_bee, func.bounds.lb, func.bounds.ub)\n                else:\n                    # Employed bee: exploit around the current location\n                    neighbor_idx = np.random.randint(0, self.pop_size)\n                    while neighbor_idx == i:\n                        neighbor_idx = np.random.randint(0, self.pop_size)\n\n                    new_bee = self.pop[i] + np.random.uniform(-self.search_radius, self.search_radius, size=self.dim) * (self.pop[i] - self.pop[neighbor_idx])\n                    new_bee = np.clip(new_bee, func.bounds.lb, func.bounds.ub)\n\n                f_new = func(new_bee)\n                self.evals += 1\n\n                if f_new < self.fitness[i]:\n                    new_fitness[i] = f_new\n                    new_pop[i] = new_bee\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = new_bee\n\n            # Update population\n            self.pop = new_pop\n            self.fitness = new_fitness\n            \n            # Adaptive search radius adjustment\n            improvement_rate = (np.mean(self.fitness) - np.mean(self.fitness)) / np.abs(np.mean(self.fitness) + 1e-8) # Avoid division by zero\n            \n            # Calculate population diversity\n            diversity = np.std(self.fitness)\n            \n            # Combine improvement rate and diversity to adjust search radius\n            adaptive_factor = self.diversity_weight * diversity + (1 - self.diversity_weight) * improvement_rate\n            \n            self.search_radius = np.clip(self.initial_search_radius * (1 + adaptive_factor), 0.01, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm SelfOrganizingScoutBee scored 0.421 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["feb8828c-4373-44dd-a473-91557073b756"], "operator": null, "metadata": {"aucs": [0.15613854444316966, 0.2733787047964791, 0.38929532085444263, 0.5684370776130662, 0.34911616293054826, 0.5476706582983589, 0.3264308021607476, 0.3624577275837657, 0.40491803369735335, 0.20990819972406805, 0.47140895480973666, 0.9867107851689887, 0.27930268615302656, 0.32714036740192687, 0.7512309697315981, 0.4092092323780434, 0.3348065566223387, 0.5839212126201141, 0.19016276123935438, 0.49456985702910183]}}
{"id": "d16be829-9739-47e0-81d5-f5875effe36e", "fitness": 0.6021453559369673, "name": "AdaptiveWorstToBestDE", "description": "An adaptive DE algorithm that employs a worst-to-best mutation strategy with a learning rate, combined with a dynamic update of F and CR based on the improvement of the best solution.", "code": "import numpy as np\n\nclass AdaptiveWorstToBestDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, memory_size=10, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.learning_rate = learning_rate\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7  # Initial crossover rate\n        self.best_history = []\n        self.memory_idx = 0\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.best_history.append(self.f_opt)\n\n        while self.evals < self.budget:\n            temp_pop = np.copy(self.pop)\n            temp_fitness = np.copy(self.fitness)\n\n            for i in range(self.pop_size):\n                # Mutation strategy: DE/worsttobest/1\n                worst_idx = np.argmax(self.fitness)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n                mutant = self.pop[i] + self.F * (self.x_opt - self.pop[i]) + self.F * (x_r1 - x_r2) #Worst to Best\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    temp_fitness[i] = f_trial\n                    temp_pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            self.pop = temp_pop\n            self.fitness = temp_fitness\n            \n            # Adaptive F and CR based on best solution improvement\n            improvement = self.best_history[-1] - self.f_opt if len(self.best_history) > 0 else 0\n            self.best_history.append(self.f_opt)\n                \n            if improvement > 0:\n                self.F = (1 - self.learning_rate) * self.F + self.learning_rate * 1.0  # Increase F if improvement\n                self.CR = (1 - self.learning_rate) * self.CR + self.learning_rate * 1.0 # Increase CR if improvement\n            else:\n                self.F = (1 - self.learning_rate) * self.F + self.learning_rate * 0.1  # Decrease F if no improvement\n                self.CR = (1 - self.learning_rate) * self.CR + self.learning_rate * 0.1  # Decrease CR if no improvement\n            \n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveWorstToBestDE scored 0.602 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3edcf6d4-b850-400e-8f84-e2ce815b16b7"], "operator": null, "metadata": {"aucs": [0.19610537348414447, 0.4024798616680334, 0.6812855693417887, 0.8880757386158697, 0.548857647887887, 0.814436223050518, 0.3709012342734188, 0.5427218259026985, 0.7547399602087531, 0.3642985406229353, 0.8600456079256006, 0.9954135841779134, 0.2998054232654166, 0.5555826492967104, 0.8802117079239538, 0.8148425875810145, 0.4840107611541802, 0.8764845945530099, 0.21087087548693073, 0.5017373523185669]}}
{"id": "db1c48dc-c39d-43b7-8a90-60d8d898834c", "fitness": 0.7262062730444658, "name": "ReinforcementLearningDE", "description": "A self-adjusting Differential Evolution algorithm that adaptively modifies mutation strategies and control parameters based on a reinforcement learning approach using a simple reward system tied to fitness improvement.", "code": "import numpy as np\n\nclass ReinforcementLearningDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, learning_rate=0.1, reward_decay=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.learning_rate = learning_rate\n        self.reward_decay = reward_decay\n        self.mutation_strategies = [\n            \"DE/rand/1\",\n            \"DE/best/1\",\n            \"DE/rand-to-best/1\",\n            \"DE/current-to-rand/1\" #A variant that's not in the original DE\n        ]\n        self.strategy_rewards = np.zeros(len(self.mutation_strategies))\n        self.F = 0.5\n        self.CR = 0.7\n        self.archive = []\n        self.archive_rate = 0.1\n\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.generation = 0\n\n        while self.evals < self.budget:\n            self.generation += 1\n\n            for i in range(self.pop.shape[0]):\n                # Strategy Selection (Reinforcement Learning)\n                strategy_index = np.random.choice(len(self.mutation_strategies), p=np.exp(self.strategy_rewards - np.max(self.strategy_rewards)) / np.sum(np.exp(self.strategy_rewards - np.max(self.strategy_rewards)))) #softmax\n                strategy = self.mutation_strategies[strategy_index]\n\n                # Mutation\n                if strategy == \"DE/rand/1\":\n                    idxs = np.random.choice(self.pop.shape[0], 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n                elif strategy == \"DE/best/1\":\n                    x_best = self.x_opt\n                    idxs = np.random.choice(self.pop.shape[0], 2, replace=False)\n                    x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n                    mutant = x_best + self.F * (x_r1 - x_r2)\n                elif strategy == \"DE/rand-to-best/1\":\n                    x_best = self.x_opt\n                    idxs = np.random.choice(self.pop.shape[0], 2, replace=False)\n                    x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n                    mutant = self.pop[i] + self.F * (x_best - self.pop[i]) + self.F * (x_r1 - x_r2)\n                elif strategy == \"DE/current-to-rand/1\":\n                    idxs = np.random.choice(self.pop.shape[0], 2, replace=False)\n                    x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n                    mutant = self.pop[i] + np.random.rand() * (x_r1 - self.pop[i]) + np.random.rand() * (x_r2 - self.pop[i])\n                else:\n                    mutant = self.pop[i] # Should not happen, but just in case\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection and Reward Update\n                if f_trial < self.fitness[i]:\n                    reward = (self.fitness[i] - f_trial) / (np.abs(self.fitness[i]) + 1e-8)  # Normalize reward\n                    self.strategy_rewards[strategy_index] += self.learning_rate * reward\n                    self.strategy_rewards *= self.reward_decay  # Decay other rewards\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                    # Archive\n                    if np.random.rand() < self.archive_rate:\n                        self.archive.append(self.pop[i].copy())\n                        if len(self.archive) > self.pop_size:\n                            self.archive.pop(0)\n                else:\n                     self.strategy_rewards[strategy_index] -= self.learning_rate * 0.01 #penalize bad moves\n\n\n            # Parameter Adaptation\n            self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm ReinforcementLearningDE scored 0.726 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["75ccb14e-77e3-4958-9619-5056de963773"], "operator": null, "metadata": {"aucs": [0.3490241262606876, 0.8445798411502633, 0.817615353658918, 0.9084452033990766, 0.8738395952595133, 0.8813290791740963, 0.3700201064079799, 0.7976404692314059, 0.8458475978348274, 0.2251826340157871, 0.9220918228833669, 0.9975675359929596, 0.629433749632702, 0.8352362955701769, 0.9229329426243902, 0.8811807581997274, 0.7737465408956308, 0.9038690614348328, 0.23548884748389598, 0.5090538997790786]}}
{"id": "6d56ceba-4aff-4c55-9974-dd3092b508cf", "fitness": 0.0, "name": "AdaptiveCauchyDEAging", "description": "An adaptive differential evolution strategy with a Cauchy mutation and an aging mechanism to promote diversity.", "code": "import numpy as np\n\nclass AdaptiveCauchyDEAging:\n    def __init__(self, budget=10000, dim=10, pop_size=50, stagnation_threshold=100, aging_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.stagnation_threshold = stagnation_threshold\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7  # Initial crossover rate\n        self.best_fitness_history = []\n        self.aging_probability = aging_probability # Probability of resetting an individual\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.best_fitness_history.append(self.f_opt)\n        self.stagnation_counter = 0\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation (Cauchy)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                \n                # Cauchy mutation\n                cauchy_noise = np.random.standard_cauchy(size=self.dim)\n                mutant = x_r1 + self.F * (x_r2 - x_r3) + 0.01 * cauchy_noise #Adding noise\n                \n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                # Aging mechanism\n                if np.random.rand() < self.aging_probability:\n                    self.pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    self.fitness[i] = func(self.pop[i])\n                    self.evals +=1\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.pop[i]\n\n\n            # Adaptive parameter control\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                if self.best_fitness_history[-self.stagnation_threshold] == self.f_opt:\n                    self.stagnation_counter += 1\n                else:\n                    self.stagnation_counter = 0\n\n                if self.stagnation_counter > self.stagnation_threshold // 2:\n                    # Stagnation detected: increase exploration\n                    self.F = np.clip(self.F * 1.1, 0.1, 1.0)\n                    self.CR = np.clip(self.CR * 0.9, 0.1, 1.0)\n                    \n                else:\n                    # Otherwise, focus on exploitation\n                    self.F = np.clip(self.F * 0.9, 0.1, 1.0)\n                    self.CR = np.clip(self.CR * 1.1, 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveCauchyDEAging scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["feb8828c-4373-44dd-a473-91557073b756"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "2927d509-faf6-416c-9f80-a9168ef187f5", "fitness": 0.4775627618095856, "name": "DistanceBasedAdaptiveDE", "description": "An adaptive differential evolution strategy that combines a distance-based mutation operator with a self-adaptive crossover rate based on individual success.", "code": "import numpy as np\n\nclass DistanceBasedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5\n        self.CR = 0.7\n        self.success_history = np.zeros(pop_size)\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation based on distance to nearest neighbor\n                distances = np.linalg.norm(self.pop - self.pop[i], axis=1)\n                distances[i] = np.inf  # Avoid selecting itself\n                nearest_neighbor_idx = np.argmin(distances)\n                \n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n                mutant = self.pop[i] + self.F * (self.pop[nearest_neighbor_idx] - self.pop[i]) + self.F * (x_r1 - x_r2)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Self-adaptive Crossover\n                CR_i = self.CR * (1 + 0.1 * np.random.randn())  # Individual CR\n                CR_i = np.clip(CR_i, 0, 1)\n\n                cross_points = np.random.rand(self.dim) < CR_i\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    self.success_history[i] += 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history[i] = max(0, self.success_history[i] - 0.1)  # Reduce success if not improving\n\n\n            # Adjust F and CR based on overall success - global adaptation\n            success_rate = np.mean(self.success_history)\n            self.F = 0.5 * (1 + 0.1 * np.random.randn())  # Perturb F slightly\n            self.F = np.clip(self.F, 0.1, 1.0)\n\n            self.CR = 0.7 * (1 + 0.1 * np.random.randn()) # Perturb CR Slightly\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm DistanceBasedAdaptiveDE scored 0.478 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["feb8828c-4373-44dd-a473-91557073b756"], "operator": null, "metadata": {"aucs": [0.15947863139199614, 0.2985534290345918, 0.44341201030095534, 0.6701297140421636, 0.38720983998746095, 0.5620876453746069, 0.34267923386705257, 0.4075314729895392, 0.4443420936467015, 0.20165579285912572, 0.7260556646579754, 0.9973803297037118, 0.3661870252284086, 0.37920620251541937, 0.8516252667849095, 0.5666255212637132, 0.3657470813226098, 0.6721568959989566, 0.21271248670729548, 0.4964788985145212]}}
{"id": "216320ac-5dc0-4d51-97cb-758f75214b10", "fitness": -Infinity, "name": "LevySwarm", "description": "A swarm algorithm that utilizes a levy flight distribution to enhance exploration while adaptively adjusting step sizes based on success rates and population diversity.", "code": "import numpy as np\n\nclass LevySwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=50, levy_exponent=1.5, initial_step_size=0.1, diversity_weight=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.levy_exponent = levy_exponent\n        self.initial_step_size = initial_step_size\n        self.step_size = initial_step_size\n        self.diversity_weight = diversity_weight\n\n    def levy_flight(self, n, beta):\n        num = np.random.normal(0, scale=(np.gamma(1+beta) * np.sin(np.pi*beta/2) / (np.gamma((1+beta)/2) * beta * 2**((beta-1)/2)))**(1/beta), size=n)\n        den = np.random.normal(0, scale=1, size=n)\n        return num / (np.abs(den)**(1/beta))\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.success_rate = 0.5 # Initialize success rate\n\n        while self.evals < self.budget:\n            new_pop = np.copy(self.pop)\n            new_fitness = np.copy(self.fitness)\n            success_count = 0\n\n            for i in range(self.pop_size):\n                # Generate Levy flight steps\n                levy_steps = self.levy_flight(self.dim, self.levy_exponent)\n                new_bee = self.pop[i] + self.step_size * levy_steps * (self.pop[np.random.randint(0, self.pop_size)] - self.pop[i]) # Adding a differential component\n                new_bee = np.clip(new_bee, func.bounds.lb, func.bounds.ub)\n\n                f_new = func(new_bee)\n                self.evals += 1\n\n                if f_new < self.fitness[i]:\n                    new_fitness[i] = f_new\n                    new_pop[i] = new_bee\n                    success_count += 1\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = new_bee\n            \n            # Update population\n            self.pop = new_pop\n            self.fitness = new_fitness\n\n            # Update success rate\n            self.success_rate = 0.9 * self.success_rate + 0.1 * (success_count / self.pop_size) # Exponential smoothing\n            \n            # Calculate population diversity\n            diversity = np.std(self.fitness)\n\n            # Adjust step size based on success rate and diversity\n            adaptive_factor = (1 - self.diversity_weight) * (self.success_rate - 0.5) + self.diversity_weight * diversity\n            self.step_size = np.clip(self.initial_step_size * (1 + adaptive_factor), 0.001, 0.5)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occurred: module 'numpy' has no attribute 'gamma'.", "error": "", "parent_ids": ["3edb6279-d4d5-4dbc-a2fd-a9508076c300"], "operator": null, "metadata": {}}
{"id": "50adff8f-43eb-4f67-9281-84c62befb98a", "fitness": 0.0, "name": "DiversityEnhancedDE", "description": "Population-based DE with a local search operator triggered probabilistically based on population diversity to refine promising solutions.", "code": "import numpy as np\n\nclass DiversityEnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_prob = local_search_prob\n        self.F = 0.5\n        self.CR = 0.7\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Calculate population diversity (standard deviation along each dimension)\n            diversity = np.std(self.pop, axis=0)\n            avg_diversity = np.mean(diversity)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                mutant = self.pop[i] + self.F * (x_r1 - x_r2) + self.F * (x_r3 - self.pop[i])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Local Search - triggered probabilistically based on diversity\n            if np.random.rand() < self.local_search_prob * (1 - avg_diversity / (func.bounds.ub[0] - func.bounds.lb[0])): #prob inversely proportional to average diversity\n                best_idx = np.argmin(self.fitness)\n                x_best = self.pop[best_idx].copy()\n                \n                # Perturb the best solution slightly\n                perturbation = np.random.normal(0, 0.05 * (func.bounds.ub[0] - func.bounds.lb[0]), size=self.dim)\n                x_perturbed = x_best + perturbation\n                x_perturbed = np.clip(x_perturbed, func.bounds.lb, func.bounds.ub)\n\n                f_perturbed = func(x_perturbed)\n                self.evals += 1\n                \n                if f_perturbed < self.f_opt:\n                  self.f_opt = f_perturbed\n                  self.x_opt = x_perturbed\n\n                if f_perturbed < self.fitness[best_idx]:\n                  self.fitness[best_idx] = f_perturbed\n                  self.pop[best_idx] = x_perturbed\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm DiversityEnhancedDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2927d509-faf6-416c-9f80-a9168ef187f5"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "0997622e-a5c8-4e0b-beba-8d0688b6c2a1", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE", "description": "An adaptive heuristic that blends particle swarm optimization with a differential evolution mutation, dynamically adjusting parameters based on population diversity and stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, de_coeff=0.7, stagnation_threshold=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.de_coeff = de_coeff\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocity\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.personal_best_pop = np.copy(self.pop)\n        self.personal_best_fitness = np.copy(self.fitness)\n        self.global_best_idx = np.argmin(self.fitness)\n        self.global_best_fitness = self.fitness[self.global_best_idx]\n        self.global_best_pos = self.pop[self.global_best_idx]\n        self.evals = self.pop_size\n        self.best_fitness_history = [self.global_best_fitness]\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocity[i] = (self.inertia * self.velocity[i] +\n                                     self.cognitive_coeff * r1 * (self.personal_best_pop[i] - self.pop[i]) +\n                                     self.social_coeff * r2 * (self.global_best_pos - self.pop[i]))\n                new_pos = self.pop[i] + self.velocity[i]\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n                \n                # DE Mutation\n                if np.random.rand() < self.de_coeff:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    while i in idxs:\n                        idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    \n                    v = self.pop[idxs[0]] + 0.5 * (self.pop[idxs[1]] - self.pop[idxs[2]])\n                    \n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < 0.1 or j == j_rand: #CR = 0.1\n                            new_pos[j] = v[j]\n\n                    new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n                f_new = func(new_pos)\n                self.evals += 1\n\n                if f_new < self.fitness[i]:\n                    self.fitness[i] = f_new\n                    self.pop[i] = new_pos\n\n                    if f_new < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_new\n                        self.personal_best_pop[i] = new_pos\n                        \n                        if f_new < self.global_best_fitness:\n                            self.global_best_fitness = f_new\n                            self.global_best_pos = new_pos\n                            self.global_best_idx = i\n            \n            #Stagnation Detection and Parameter Adaptation\n            self.best_fitness_history.append(self.global_best_fitness)\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                self.best_fitness_history.pop(0)\n                if np.std(self.best_fitness_history) < 1e-6: #Stagnation detected\n                    self.stagnation_counter += 1\n                    #Increase exploration if stagnant\n                    self.inertia *= 0.95\n                    self.de_coeff = min(1.0, self.de_coeff * 1.1)\n                    if self.stagnation_counter > 3:\n                        # Reset population if significantly stagnant\n                        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n                        self.fitness = np.array([func(x) for x in self.pop])\n                        self.personal_best_pop = np.copy(self.pop)\n                        self.personal_best_fitness = np.copy(self.fitness)\n                        self.global_best_idx = np.argmin(self.fitness)\n                        self.global_best_fitness = self.fitness[self.global_best_idx]\n                        self.global_best_pos = self.pop[self.global_best_idx]\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter = 0\n            \n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3edb6279-d4d5-4dbc-a2fd-a9508076c300"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "ba27b7ff-4390-4116-979c-891f1a9f2bce", "fitness": 0.30157710469886506, "name": "AdaptiveCurrentToPBestDE", "description": "An adaptive differential evolution algorithm that combines a current-to-pbest mutation strategy with a success-history based adaptation of F and CR, and incorporates a restart mechanism based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveCurrentToPBestDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, p=0.1, memory_size=10, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.p = p  # Percentage of top individuals for pbest selection\n        self.memory_size = memory_size\n        self.learning_rate = learning_rate\n        self.F_history = np.ones(self.memory_size) * 0.5\n        self.CR_history = np.ones(self.memory_size) * 0.7\n        self.memory_idx = 0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.restart_trigger = False\n        self.restart_counter = 0\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            temp_pop = np.copy(self.pop)\n            temp_fitness = np.copy(self.fitness)\n\n            for i in range(self.pop_size):\n                # Current-to-pbest mutation\n                p_best_size = max(int(self.p * self.pop_size), 1)\n                p_best_indices = np.argsort(self.fitness)[:p_best_size]\n                p_best_idx = np.random.choice(p_best_indices)\n\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n\n                F = self.F_history[np.random.randint(self.memory_size)]\n                mutant = self.pop[i] + F * (self.pop[p_best_idx] - self.pop[i]) + F * (x_r1 - x_r2)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                CR = self.CR_history[np.random.randint(self.memory_size)]\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n\n                f_trial = func(trial)\n                self.evals += 1\n\n                if f_trial < self.fitness[i]:\n                    temp_fitness[i] = f_trial\n                    temp_pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.F_history[self.memory_idx] = F\n                        self.CR_history[self.memory_idx] = CR\n                        self.memory_idx = (self.memory_idx + 1) % self.memory_size\n            self.pop = temp_pop\n            self.fitness = temp_fitness\n\n            #Restart mechanism based on diversity\n            if self.evals % (self.budget//10) == 0:\n                diversity = np.std(self.fitness)\n                if diversity < 1e-6 and not self.restart_trigger:\n                    self.restart_trigger = True\n                    self.restart_counter = self.evals\n                    self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    self.fitness = np.array([func(x) for x in self.pop])\n                    self.f_opt = np.min(self.fitness)\n                    self.x_opt = self.pop[np.argmin(self.fitness)]\n                    self.evals = self.evals + self.pop_size\n                    self.F_history = np.ones(self.memory_size) * 0.5\n                    self.CR_history = np.ones(self.memory_size) * 0.7\n                elif self.evals - self.restart_counter > (self.budget//10) and self.restart_trigger:\n                    self.restart_trigger = False #Deactivate Restart\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveCurrentToPBestDE scored 0.302 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d16be829-9739-47e0-81d5-f5875effe36e"], "operator": null, "metadata": {"aucs": [0.2747233462019192, 0.630007967894676, 0]}}
{"id": "40b16044-e6f6-4de0-b5d0-73deb8804099", "fitness": 0.5079409749746094, "name": "CooperativeSwarm", "description": "A cooperative swarm algorithm employing multiple interacting swarms with adaptive communication and migration strategies, enhancing exploration and exploitation through information sharing.", "code": "import numpy as np\n\nclass CooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, migration_rate=0.1, communication_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.migration_rate = migration_rate\n        self.communication_rate = communication_rate\n        self.swarms = []\n        self.best_positions = []\n        self.best_fitnesses = []\n\n    def initialize_swarm(self, func):\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim))\n        fitnesses = np.array([func(x) for x in swarm])\n        best_fitnesses = fitnesses.copy()\n        best_positions = swarm.copy()\n        global_best_index = np.argmin(fitnesses)\n        global_best_fitness = fitnesses[global_best_index]\n        global_best_position = swarm[global_best_index].copy()\n        return swarm, velocities, fitnesses, best_fitnesses, best_positions, global_best_fitness, global_best_position\n\n    def __call__(self, func):\n        self.swarms = []\n        self.best_positions = []\n        self.best_fitnesses = []\n        evals = 0\n        f_opt = np.Inf\n        x_opt = None\n\n        for i in range(self.num_swarms):\n            swarm, velocities, fitnesses, best_fitnesses, best_positions, global_best_fitness, global_best_position = self.initialize_swarm(func)\n            self.swarms.append({\n                'swarm': swarm,\n                'velocities': velocities,\n                'fitnesses': fitnesses,\n                'best_fitnesses': best_fitnesses,\n                'best_positions': best_positions,\n                'global_best_fitness': global_best_fitness,\n                'global_best_position': global_best_position\n            })\n            self.best_fitnesses.append(global_best_fitness)\n            self.best_positions.append(global_best_position)\n            evals += self.swarm_size\n\n            if global_best_fitness < f_opt:\n                f_opt = global_best_fitness\n                x_opt = global_best_position\n\n        while evals < self.budget:\n            for i in range(self.num_swarms):\n                swarm_data = self.swarms[i]\n                swarm = swarm_data['swarm']\n                velocities = swarm_data['velocities']\n                fitnesses = swarm_data['fitnesses']\n                best_fitnesses = swarm_data['best_fitnesses']\n                best_positions = swarm_data['best_positions']\n                global_best_fitness = swarm_data['global_best_fitness']\n                global_best_position = swarm_data['global_best_position']\n\n                # Update velocities and positions\n                r1 = np.random.rand(self.swarm_size, self.dim)\n                r2 = np.random.rand(self.swarm_size, self.dim)\n\n                # Using the global best of ALL swarms\n                global_best_all_index = np.argmin(self.best_fitnesses)\n                global_best_all = self.best_positions[global_best_all_index]\n\n                velocities = self.inertia * velocities + \\\n                             self.cognitive_coeff * r1 * (best_positions - swarm) + \\\n                             self.social_coeff * r2 * (np.tile(global_best_all, (self.swarm_size, 1)) - swarm) # using global best of all swarms\n\n                swarm = swarm + velocities\n                swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                new_fitnesses = np.array([func(x) for x in swarm])\n                evals += self.swarm_size\n\n                # Update personal bests\n                improved = new_fitnesses < best_fitnesses\n                best_fitnesses[improved] = new_fitnesses[improved]\n                best_positions[improved] = swarm[improved]\n\n                # Update swarm's global best\n                current_best_index = np.argmin(new_fitnesses)\n                current_best_fitness = new_fitnesses[current_best_index]\n                current_best_position = swarm[current_best_index].copy()\n\n                if current_best_fitness < global_best_fitness:\n                    global_best_fitness = current_best_fitness\n                    global_best_position = current_best_position\n\n                swarm_data['swarm'] = swarm\n                swarm_data['velocities'] = velocities\n                swarm_data['fitnesses'] = new_fitnesses\n                swarm_data['best_fitnesses'] = best_fitnesses\n                swarm_data['best_positions'] = best_positions\n                swarm_data['global_best_fitness'] = global_best_fitness\n                swarm_data['global_best_position'] = global_best_position\n\n                self.swarms[i] = swarm_data\n                self.best_fitnesses[i] = global_best_fitness\n                self.best_positions[i] = global_best_position\n\n                if global_best_fitness < f_opt:\n                    f_opt = global_best_fitness\n                    x_opt = global_best_position\n\n            # Migration and Communication\n            for i in range(self.num_swarms):\n                if np.random.rand() < self.migration_rate:\n                    # Migrate a particle from one swarm to another\n                    source_swarm_index = i\n                    dest_swarm_index = np.random.choice([j for j in range(self.num_swarms) if j != i])\n\n                    particle_index = np.random.randint(0, self.swarm_size)\n\n                    migrant = self.swarms[source_swarm_index]['swarm'][particle_index].copy()\n                    migrant_fitness = self.swarms[source_swarm_index]['fitnesses'][particle_index]\n\n                    self.swarms[dest_swarm_index]['swarm'][np.random.randint(0, self.swarm_size)] = migrant\n                    self.swarms[dest_swarm_index]['fitnesses'][np.random.randint(0, self.swarm_size)] = migrant_fitness\n\n\n        return f_opt, x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm CooperativeSwarm scored 0.508 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["db1c48dc-c39d-43b7-8a90-60d8d898834c"], "operator": null, "metadata": {"aucs": [0.22131148947229706, 0.17637626599541467, 0.5481289719696849, 0.8550257328840075, 0.5190180726590099, 0.6054840872308661, 0.3120892632728547, 0.47246462704972914, 0.5929639542363369, 0.22556784399249163, 0.7349051498094143, 0.9993349999414541, 0.22339462523162135, 0.2861323847815904, 0.6674323019270973, 0.6443050948582764, 0.47387215103601943, 0.7741013119406164, 0.24275586601997134, 0.5841553051834353]}}
{"id": "660f0080-bdea-4993-899b-49c5d41acdda", "fitness": 0.4112040617190682, "name": "CooperativeSwarm", "description": "A cooperative swarm algorithm that uses a dynamic communication topology and adaptive momentum to balance exploration and exploitation.", "code": "import numpy as np\n\nclass CooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, topology_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.topology_size = topology_size # Number of neighbors to consider for social influence\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.pbest_pop = np.copy(self.pop) # Personal best positions\n        self.pbest_fitness = np.copy(self.fitness) # Personal best fitnesses\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Dynamic communication topology: select neighbors randomly\n                neighbors = np.random.choice(self.pop_size, self.topology_size, replace=False)\n                \n                # Find the best neighbor\n                best_neighbor_idx = neighbors[np.argmin(self.fitness[neighbors])]\n\n                # Update velocity\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      self.cognitive_coeff * np.random.rand(self.dim) * (self.pbest_pop[i] - self.pop[i]) +\n                                      self.social_coeff * np.random.rand(self.dim) * (self.pop[best_neighbor_idx] - self.pop[i]))\n\n                # Update position\n                new_bee = self.pop[i] + self.velocities[i]\n                new_bee = np.clip(new_bee, func.bounds.lb, func.bounds.ub)\n\n                f_new = func(new_bee)\n                self.evals += 1\n\n                # Update personal best\n                if f_new < self.pbest_fitness[i]:\n                    self.pbest_fitness[i] = f_new\n                    self.pbest_pop[i] = new_bee\n                    \n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = new_bee\n                \n                #Update population\n                self.pop[i] = new_bee\n                self.fitness[i] = f_new\n                \n            # Adaptive inertia weight (linearly decreasing)\n            self.inertia_weight = 0.7 - (0.7 - 0.4) * (self.evals / self.budget) #From 0.7 to 0.4\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm CooperativeSwarm scored 0.411 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3edb6279-d4d5-4dbc-a2fd-a9508076c300"], "operator": null, "metadata": {"aucs": [0.17109761371564514, 0.22220161126251303, 0.348172321442096, 0.6308629040267688, 0.37170495839719786, 0.4669908623588396, 0.3108738614032406, 0.357510927548257, 0.3050326354597761, 0.276190365920571, 0.3882532845629033, 0.9947991710858354, 0.308559637195138, 0.3670659049055607, 0.6966916915232169, 0.4717201093161465, 0.3029276522502792, 0.5670489078435798, 0.1832432993669475, 0.4831335147968526]}}
{"id": "d09aeb40-fcbd-4111-820c-0b8537f2b3a2", "fitness": 0.45750262292181293, "name": "LevyDE", "description": "A hybrid optimization algorithm combining the exploration of the Lvy flight distribution with the exploitation of a differential evolution strategy, dynamically adjusting parameters based on success.", "code": "import numpy as np\n\nclass LevyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, levy_exponent=1.5, F=0.7, CR=0.7, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.levy_exponent = levy_exponent\n        self.F = F\n        self.CR = CR\n        self.adaptation_rate = adaptation_rate\n        self.archive = []\n        self.archive_rate = 0.1\n\n\n    def levy_flight(self, size):\n        # Levy flight distribution\n        u = np.random.randn(size)\n        v = np.random.randn(size)\n        step = u / np.power(np.abs(v), (1 / self.levy_exponent))\n        return step\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.generation = 0\n\n        while self.evals < self.budget:\n            self.generation += 1\n\n            for i in range(self.pop_size):\n                # Mutation using Levy Flight\n                levy_steps = self.levy_flight(self.dim)\n                mutant = self.pop[i] + self.F * levy_steps * (self.x_opt - self.pop[i])\n                \n                # Ensure bounds\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    \n                    #Archive\n                    if np.random.rand() < self.archive_rate:\n                        self.archive.append(self.pop[i].copy())\n                        if len(self.archive) > self.pop_size:\n                            self.archive.pop(0)\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        # Adapt parameters if improvement found\n                        self.F = np.clip(self.F + self.adaptation_rate * np.random.normal(0, 0.1), 0.1, 1.0)\n                        self.CR = np.clip(self.CR + self.adaptation_rate * np.random.normal(0, 0.1), 0.1, 1.0)\n                else:\n                    # Adapt parameters if no improvement found\n                    self.F = np.clip(self.F - self.adaptation_rate * np.random.normal(0, 0.1), 0.1, 1.0)\n                    self.CR = np.clip(self.CR - self.adaptation_rate * np.random.normal(0, 0.1), 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm LevyDE scored 0.458 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["db1c48dc-c39d-43b7-8a90-60d8d898834c"], "operator": null, "metadata": {"aucs": [0.17321263184078017, 0.197603450672589, 0.4315718419342819, 0.7525844045604296, 0.41813110876300186, 0.5100930770490983, 0.3102326929590584, 0.3947196313655854, 0.548043666475943, 0.2963705023858728, 0.3942483804982747, 0.9934460733269243, 0.2661840614830465, 0.4366715895041059, 0.7244444799066239, 0.563201656683542, 0.3657193027650112, 0.6374079381719999, 0.21969090903349642, 0.5164750590565947]}}
{"id": "43834455-7083-472e-a9c1-01e8e3b28868", "fitness": 0.6421929625818263, "name": "AdaptiveMultiStrategyDE", "description": "A Differential Evolution variant that utilizes a pool of mutation strategies and adaptively selects the best one based on their recent success rate.", "code": "import numpy as np\n\nclass AdaptiveMultiStrategyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, memory_size=10, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.learning_rate = learning_rate\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7  # Initial crossover rate\n        self.strategies = [\n            self._rand1_bin,\n            self._best1_bin,\n            self._currenttorand1_bin,\n            self._rand2_bin\n        ]\n        self.strategy_success = np.zeros(len(self.strategies))\n        self.strategy_usage = np.zeros(len(self.strategies))\n        self.memory_idx = 0\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            temp_pop = np.copy(self.pop)\n            temp_fitness = np.copy(self.fitness)\n\n            for i in range(self.pop_size):\n                # Strategy Selection: Probabilistically choose a mutation strategy\n                probs = (self.strategy_success / (self.strategy_usage + 1e-6)) + 1e-6\n                probs /= np.sum(probs)\n                strategy_idx = np.random.choice(len(self.strategies), p=probs)\n                self.strategy_usage[strategy_idx] += 1\n\n                mutant = self.strategies[strategy_idx](i)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.strategy_success[strategy_idx] += 1\n                    temp_fitness[i] = f_trial\n                    temp_pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            self.pop = temp_pop\n            self.fitness = temp_fitness\n\n        return self.f_opt, self.x_opt\n\n    def _rand1_bin(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n        return self.pop[i] + self.F * (x_r1 - x_r2) + self.F*(x_r3 - self.pop[i])\n\n    def _best1_bin(self, i):\n         idxs = np.random.choice(self.pop_size, 2, replace=False)\n         x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n         return self.x_opt + self.F * (x_r1 - x_r2)\n\n    def _currenttorand1_bin(self, i):\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n        rand_vector = np.random.uniform(low=-1, high=1, size=self.dim) #Added random vector\n        return self.pop[i] + rand_vector + self.F * (x_r1 - x_r2)\n\n    def _rand2_bin(self, i):\n        idxs = np.random.choice(self.pop_size, 5, replace=False)\n        x_r1, x_r2, x_r3, x_r4, x_r5 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]], self.pop[idxs[3]], self.pop[idxs[4]]\n        return self.pop[i] + self.F * (x_r1 - x_r2) + self.F * (x_r3 - x_r4) + self.F*(x_r5 - self.pop[i])", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveMultiStrategyDE scored 0.642 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d16be829-9739-47e0-81d5-f5875effe36e"], "operator": null, "metadata": {"aucs": [0.4177505755385188, 0.8356238489642104, 0.8503715183637925, 0.3257919367433011, 0.8807068873515949, 0.7737026823606623, 0.4905867300723359, 0.8297807704591429, 0.7443855973971728, 0.858252453278429, 0.7596532048350255, 0.9958233898730932, 0.5786323318750604, 0.2804393036159766, 0.9609772220000496, 0.6665750041652269, 0.5300214052150494, 0.37722750760143153, 0.19652750171823052, 0.4910293802082242]}}
{"id": "28c765ac-5234-4998-9470-8d0cc0a7a395", "fitness": 0.5202348908295253, "name": "AdaptivePopulationDE", "description": "An adaptive population size DE with a diversity maintenance mechanism based on crowding distance and a self-adaptive parameter control using a success-history based adaptation.", "code": "import numpy as np\n\nclass AdaptivePopulationDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, archive_size=50, F=0.5, CR=0.7, shcr_memory=10, shf_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.archive_size = archive_size\n        self.F = F\n        self.CR = CR\n        self.archive = []\n        self.evals = 0\n        self.shcr_memory = shcr_memory\n        self.shf_memory = shf_memory\n        self.successful_cr = np.ones(self.shcr_memory) * self.CR\n        self.successful_f = np.ones(self.shf_memory) * self.F\n\n    def crowding_distance(self, pop, fitness):\n        \"\"\"Calculate crowding distance for each individual.\"\"\"\n        n_individuals = len(pop)\n        distances = np.zeros(n_individuals)\n\n        for m in range(self.dim):  # For each dimension\n            # Sort individuals by their m-th dimension value\n            sorted_indices = np.argsort(pop[:, m])\n\n            # Boundary individuals get maximum distance\n            distances[sorted_indices[0]] = np.inf\n            distances[sorted_indices[-1]] = np.inf\n\n            # Calculate distances for intermediate individuals\n            for i in range(1, n_individuals - 1):\n                distances[sorted_indices[i]] += (pop[sorted_indices[i+1], m] - pop[sorted_indices[i-1], m])\n\n        # Normalize by fitness (higher fitness difference is better)\n        fitness_order = np.argsort(fitness)\n        distances[fitness_order[0]] = np.inf\n        distances[fitness_order[-1]] = np.inf\n        for i in range(1, n_individuals - 1):\n            distances[fitness_order[i]] += (fitness[fitness_order[i+1]] - fitness[fitness_order[i-1]])\n        \n        return distances\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.generation = 0\n\n        while self.evals < self.budget:\n            self.generation += 1\n            new_pop = np.copy(self.pop)\n            new_fitness = np.copy(self.fitness)\n\n            for i in range(self.pop.shape[0]):\n                # Parameter Adaptation using SHADE\n                cr = np.random.choice(self.successful_cr)\n                f = np.random.choice(self.successful_f)\n\n                # Mutation\n                idxs = np.random.choice(self.pop.shape[0], 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                mutant = self.pop[i] + f * (x_r1 - x_r2)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    new_fitness[i] = f_trial\n                    new_pop[i] = trial\n                    self.archive.append(self.pop[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                    \n                    # SHADE Memory Update\n                    self.successful_cr = np.roll(self.successful_cr, -1)\n                    self.successful_cr[-1] = cr\n                    self.successful_f = np.roll(self.successful_f, -1)\n                    self.successful_f[-1] = f\n\n\n            # Diversity Maintenance and Population Control\n            combined_pop = np.vstack((self.pop, new_pop))\n            combined_fitness = np.concatenate((self.fitness, new_fitness))\n\n            distances = self.crowding_distance(combined_pop, combined_fitness)\n\n            # Sort by fitness, then crowding distance\n            sort_indices = np.lexsort((-distances, combined_fitness))\n\n            # Select top individuals for the next generation\n            self.pop = combined_pop[sort_indices[:self.pop_size]]\n            self.fitness = combined_fitness[sort_indices[:self.pop_size]]\n\n            # Population Size Adaptation\n            if self.generation % 10 == 0:\n                if np.std(self.fitness) < 1e-6:\n                     self.pop_size = max(self.min_pop_size, self.pop_size // 2)\n                else:\n                     self.pop_size = min(self.max_pop_size, self.pop_size * 2)\n                \n                self.pop_size = min(self.pop_size, self.budget - self.evals) # do not exceed remaining budget\n                if self.pop_size < self.pop.shape[0]:\n                    distances = self.crowding_distance(self.pop, self.fitness)\n                    sort_indices = np.lexsort((-distances, self.fitness))\n                    self.pop = self.pop[sort_indices[:self.pop_size]]\n                    self.fitness = self.fitness[sort_indices[:self.pop_size]]\n                elif self.pop_size > self.pop.shape[0]:\n                    missing = self.pop_size - self.pop.shape[0]\n                    new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(missing, self.dim))\n                    new_fitness = np.array([func(x) for x in new_individuals])\n                    self.evals += missing\n                    self.pop = np.vstack((self.pop, new_individuals))\n                    self.fitness = np.concatenate((self.fitness, new_fitness))\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptivePopulationDE scored 0.520 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["db1c48dc-c39d-43b7-8a90-60d8d898834c"], "operator": null, "metadata": {"aucs": [0.14515144727444218, 0.273467989804801, 0.38946114167945944, 0.851021856689596, 0.4132131819987329, 0.7372243510568837, 0.33336702256703277, 0.6115428754742417, 0.5864971355941482, 0.5906292663799672, 0.29634949609250716, 0.999611653047082, 0.27360356462263, 0.6638667006947163, 0.6794209575580676, 0.7632607496020231, 0.2959068498279859, 0.8368587934369833, 0.17231894448367424, 0.4919238387055326]}}
{"id": "4b61bac9-6437-4c9a-9681-21b4e363c116", "fitness": -Infinity, "name": "ImprovedSelfOrganizingScoutBee", "description": "An improved self-organizing scout bee algorithm that incorporates a dynamic population size adjustment based on stagnation detection and a more refined search radius adaptation using an exponentially weighted moving average of fitness improvement.", "code": "import numpy as np\n\nclass ImprovedSelfOrganizingScoutBee:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, max_pop_size=100, scout_frequency=0.1, initial_search_radius=0.5, stagnation_threshold=1000):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.scout_frequency = scout_frequency\n        self.initial_search_radius = initial_search_radius\n        self.search_radius = initial_search_radius\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.ewma_alpha = 0.1  # Exponentially weighted moving average factor\n        self.ewma_improvement = 0.0\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.best_fitness_history = [self.f_opt]\n\n        while self.evals < self.budget:\n            new_pop = np.copy(self.pop)\n            new_fitness = np.copy(self.fitness)\n\n            for i in range(self.pop_size):\n                if np.random.rand() < self.scout_frequency:\n                    # Scout bee: explore a random location within the search radius\n                    new_bee = self.pop[i] + np.random.uniform(-self.search_radius, self.search_radius, size=self.dim)\n                    new_bee = np.clip(new_bee, func.bounds.lb, func.bounds.ub)\n                else:\n                    # Employed bee: exploit around the current location\n                    neighbor_idx = np.random.randint(0, self.pop_size)\n                    while neighbor_idx == i:\n                        neighbor_idx = np.random.randint(0, self.pop_size)\n\n                    new_bee = self.pop[i] + np.random.uniform(-self.search_radius, self.search_radius, size=self.dim) * (self.pop[i] - self.pop[neighbor_idx])\n                    new_bee = np.clip(new_bee, func.bounds.lb, func.bounds.ub)\n\n                f_new = func(new_bee)\n                self.evals += 1\n\n                if f_new < self.fitness[i]:\n                    new_fitness[i] = f_new\n                    new_pop[i] = new_bee\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = new_bee\n\n            # Update population\n            self.pop = new_pop\n            self.fitness = new_fitness\n\n            # Stagnation check\n            if self.f_opt < self.best_fitness_history[-1]:\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += self.pop_size\n            \n            self.best_fitness_history.append(self.f_opt)\n            self.best_fitness_history = self.best_fitness_history[-10:] # Keep only last 10 values\n\n            # Dynamic population size adjustment\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.pop_size = max(self.min_pop_size, int(self.pop_size * 0.8))  # Reduce population size\n                self.stagnation_counter = 0\n                # Regenerate population (to increase diversity)\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.evals += self.pop_size\n                best_idx = np.argmin(self.fitness)\n                if self.fitness[best_idx] < self.f_opt:\n                    self.f_opt = self.fitness[best_idx]\n                    self.x_opt = self.pop[best_idx]\n                \n            elif self.pop_size < self.max_pop_size:\n                 self.pop_size = min(self.max_pop_size, int(self.pop_size * 1.1))\n\n            # Adaptive search radius adjustment using EWMA\n            improvement = self.best_fitness_history[-2] - self.f_opt\n            self.ewma_improvement = self.ewma_alpha * improvement + (1 - self.ewma_alpha) * self.ewma_improvement\n            \n            self.search_radius = np.clip(self.initial_search_radius * np.exp(-self.ewma_improvement), 0.01, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occurred: index 54 is out of bounds for axis 0 with size 50.", "error": "", "parent_ids": ["3edb6279-d4d5-4dbc-a2fd-a9508076c300"], "operator": null, "metadata": {}}
{"id": "22aa7e84-572c-46a2-a1c6-0f927fb770d4", "fitness": -Infinity, "name": "ClusteredLandscapeDE", "description": "A population-based algorithm with a dynamic fitness landscape based on clustering, encouraging exploration and exploitation in different regions of the search space.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass ClusteredLandscapeDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, num_clusters=5, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.num_clusters = num_clusters\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n\n    def __call__(self, func):\n        # Initialize population\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.evals = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n        while self.evals < self.budget:\n            # Cluster the population\n            kmeans = KMeans(n_clusters=self.num_clusters, random_state=0, n_init = 'auto').fit(self.pop)\n            clusters = kmeans.labels_\n\n            for i in range(self.pop_size):\n                # Choose a mutation strategy based on the cluster\n                cluster_id = clusters[i]\n                if np.random.rand() < 0.5:  # Explore: DE within the cluster\n                    cluster_indices = np.where(clusters == cluster_id)[0]\n                    if len(cluster_indices) > 3:\n                        idxs = np.random.choice(cluster_indices, 3, replace=False)\n                        x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                        mutant = self.pop[i] + self.F * (x_r1 - x_r2)\n                    else:\n                        mutant = self.pop[i] # Not enough individuals in cluster\n                else:  # Exploit: DE with best from other clusters\n                    other_clusters = np.where(clusters != cluster_id)[0]\n                    if len(other_clusters) > 0:\n                        best_idx_other = other_clusters[np.argmin(self.fitness[other_clusters])]\n                        idxs = np.random.choice(self.pop.shape[0], 2, replace=False)\n                        x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n                        mutant = self.pop[i] + self.F * (self.pop[best_idx_other] - self.pop[i]) + self.F * (x_r1 - x_r2)\n                    else:\n                        mutant = self.pop[i]\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Adapt F and CR (optional)\n            self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occurred: name 'KMeans' is not defined.", "error": "", "parent_ids": ["db1c48dc-c39d-43b7-8a90-60d8d898834c"], "operator": null, "metadata": {}}
{"id": "7ec557b9-c2c6-4621-b103-b355f1f3b676", "fitness": -Infinity, "name": "NeighborhoodRuggednessDE", "description": "Implements a Differential Evolution strategy with a neighborhood-based mutation and a probabilistic parameter adaptation scheme based on fitness landscape ruggedness estimation.", "code": "import numpy as np\n\nclass NeighborhoodRuggednessDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.neighborhood_size = neighborhood_size\n        self.F = 0.5\n        self.CR = 0.7\n        self.archive = []\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Neighborhood-based Mutation\n                neighbors_indices = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                neighbors = self.pop[neighbors_indices]\n                \n                # Select two random neighbors\n                idxs = np.random.choice(self.neighborhood_size, 2, replace=False)\n                x_r1, x_r2 = neighbors[idxs[0]], neighbors[idxs[1]]\n                \n                mutant = self.pop[i] + self.F * (x_r1 - x_r2)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                    self.archive.append(self.pop[i].copy())  # Store successful individuals\n\n            # Ruggedness Estimation and Parameter Adaptation\n            if len(self.archive) > 10:\n                distances = []\n                for k in range(len(self.archive)):\n                    for l in range(k + 1, len(self.archive)):\n                        distances.append(np.linalg.norm(self.archive[k] - self.archive[l]))\n                \n                if len(distances) > 0:\n                    avg_distance = np.mean(distances)\n                else:\n                    avg_distance = 0.001 #Prevents division by zero\n\n                fitness_range = np.max(self.fitness) - np.min(self.fitness)\n\n                # Estimate ruggedness\n                ruggedness = fitness_range / (avg_distance + 1e-9)  # Adding a small value to avoid division by zero\n\n                # Adapt F and CR based on ruggedness\n                self.F = np.clip(0.5 + 0.2 * np.tanh(ruggedness), 0.1, 0.9)\n                self.CR = np.clip(0.7 - 0.1 * np.tanh(ruggedness), 0.1, 0.9)\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occurred: Evaluation timed out after 60 seconds..", "error": "", "parent_ids": ["2927d509-faf6-416c-9f80-a9168ef187f5"], "operator": null, "metadata": {}}
{"id": "fd9ee1be-62e4-495d-8f2e-32f3fe6f730f", "fitness": -Infinity, "name": "MirroredDE", "description": "A DE variant employing a mirrored sampling technique to enhance boundary exploration and population diversity.", "code": "import numpy as np\n\nclass MirroredDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                mutant = self.pop[i] + self.F * (x2 - x3)\n\n                # Mirrored Sampling\n                for j in range(self.dim):\n                    if mutant[j] < lb:\n                        mutant[j] = lb + np.abs(mutant[j] - lb)\n                    elif mutant[j] > ub:\n                        mutant[j] = ub - np.abs(mutant[j] - ub)\n                \n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["d09aeb40-fcbd-4111-820c-0b8537f2b3a2"], "operator": null, "metadata": {}}
{"id": "73d81e62-87b0-490a-a0b0-957b1cb45e69", "fitness": -Infinity, "name": "SAMODE", "description": "A Differential Evolution strategy with self-adaptive parameters, orthogonal learning, and a memory-based mutation strategy.", "code": "import numpy as np\n\nclass SAMODE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, memory_size=10, ortho_trials=5, F_init=0.5, CR_init=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.ortho_trials = ortho_trials\n        self.F = F_init * np.ones(self.memory_size)\n        self.CR = CR_init * np.ones(self.memory_size)\n        self.memory_idx = 0\n        self.archive = []\n\n        self.success_F = []\n        self.success_CR = []\n\n    def orthogonal_design(self, x, func):\n        # Generate orthogonal design around x\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        dim = self.dim\n        trials = np.zeros((self.ortho_trials, dim))\n\n        for i in range(self.ortho_trials):\n            trial = x.copy()\n            j = np.random.choice(dim)\n            trial[j] = np.random.uniform(lb, ub) # perturb one dimension\n            trials[i] = trial\n        \n        fitness_values = [func(trial) for trial in trials]\n        best_index = np.argmin(fitness_values)\n        \n        return trials[best_index], fitness_values[best_index]\n        \n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.generation = 0\n\n        while self.evals < self.budget:\n            self.generation += 1\n\n            for i in range(self.pop_size):\n                # Memory-based parameter selection\n                memory_index = np.random.randint(self.memory_size)\n                current_F = self.F[memory_index]\n                current_CR = self.CR[memory_index]\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = self.pop[i] + current_F * (x_r1 - x_r2)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < current_CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Orthogonal learning\n                trial, f_trial_ortho = self.orthogonal_design(trial, func)\n                self.evals += self.ortho_trials\n                f_trial = func(trial)\n                self.evals += 1\n\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.success_F.append(current_F)\n                    self.success_CR.append(current_CR)\n                    delta = np.abs(self.fitness[i] - f_trial)\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if len(self.success_F) > 0 and self.evals % self.pop_size == 0:\n                    # Parameter adaptation\n                    mean_F = np.mean(self.success_F)\n                    mean_CR = np.mean(self.success_CR)\n                    self.F[self.memory_idx] = 0.9 * self.F[self.memory_idx] + 0.1 * mean_F\n                    self.CR[self.memory_idx] = 0.9 * self.CR[self.memory_idx] + 0.1 * mean_CR\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                    self.success_F = []\n                    self.success_CR = []\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["d09aeb40-fcbd-4111-820c-0b8537f2b3a2"], "operator": null, "metadata": {}}
{"id": "94568129-9f64-466e-abf9-e257349ba2c9", "fitness": -Infinity, "name": "SOM_DE", "description": "A differential evolution strategy that incorporates a self-organizing map (SOM) to cluster individuals and apply different mutation strategies based on the cluster.", "code": "import numpy as np\nfrom minisom import MiniSom\n\nclass SOM_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, som_grid_size=5, F=0.7, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.som_grid_size = som_grid_size\n        self.F = F\n        self.CR = CR\n        self.som = None\n        self.mutation_strategies = [\"current-to-best\", \"rand/1\", \"current-to-rand\"]\n        self.strategy_probabilities = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n\n\n    def initialize_som(self):\n        self.som = MiniSom(self.som_grid_size, self.som_grid_size, self.dim, sigma=0.3, learning_rate=0.5)\n        self.som.random_weights_init(self.pop)\n        self.som.train_random(self.pop, 100)  # Train SOM for a few iterations initially\n\n    def apply_mutation(self, pop, i, strategy, F, bounds):\n        if strategy == \"current-to-best\":\n            r1, r2 = np.random.choice(self.pop_size, 2, replace=False)\n            mutant = pop[i] + F * (self.x_opt - pop[i]) + F * (pop[r1] - pop[r2])\n        elif strategy == \"rand/1\":\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n            r1, r2, r3 = indices\n            mutant = pop[r1] + F * (pop[r2] - pop[r3])\n        elif strategy == \"current-to-rand\":\n             r1, r2 = np.random.choice(self.pop_size, 2, replace=False)\n             mutant = pop[i] + np.random.rand() * (pop[r1]-pop[i]) + F*(pop[r2]-pop[i])\n        else:\n            raise ValueError(\"Unknown mutation strategy\")\n\n        mutant = np.clip(mutant, bounds.lb, bounds.ub)\n        return mutant\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.generation = 0\n\n        self.initialize_som()\n\n        while self.evals < self.budget:\n            self.generation += 1\n\n            # Update SOM with current population\n            self.som.train_random(self.pop, 10)\n\n            for i in range(self.pop_size):\n                # Determine SOM node for the individual\n                winner = self.som.winner(self.pop[i])\n                cluster_index = np.ravel_multi_index(winner, (self.som_grid_size, self.som_grid_size))\n\n                # Choose mutation strategy based on SOM cluster (probabilistically)\n                strategy_index = np.random.choice(len(self.mutation_strategies), p=self.strategy_probabilities)\n                mutation_strategy = self.mutation_strategies[strategy_index]\n\n                # Apply mutation\n                mutant = self.apply_mutation(self.pop, i, mutation_strategy, self.F, func.bounds)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            #Adapt the mutation strategies\n            success_rate = [0.0]*len(self.mutation_strategies)\n            for i in range(self.pop_size):\n                winner = self.som.winner(self.pop[i])\n                cluster_index = np.ravel_multi_index(winner, (self.som_grid_size, self.som_grid_size))\n                \n            self.strategy_probabilities = np.clip(self.strategy_probabilities+0.01*np.random.normal(0,1,len(self.mutation_strategies)),0.1,1)\n            self.strategy_probabilities = self.strategy_probabilities/np.sum(self.strategy_probabilities)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "An exception occurred: No module named 'minisom'.", "error": "", "parent_ids": ["d09aeb40-fcbd-4111-820c-0b8537f2b3a2"], "operator": null, "metadata": {}}
{"id": "8c60c0ee-d876-4bf7-90dc-1b2b06f49697", "fitness": 0.33983346985477625, "name": "CMAES_DE", "description": "Combines aspects of CMA-ES with DE, using CMA-ES covariance adaptation to guide the mutation in DE.", "code": "import numpy as np\n\nclass CMAES_DE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, cma_learning_rate=0.1, de_F=0.5, de_CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.cma_learning_rate = cma_learning_rate\n        self.de_F = de_F\n        self.de_CR = de_CR\n        self.evals = 0\n        self.mean = np.zeros(dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim)  # Covariance matrix\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.pop = np.random.multivariate_normal(self.mean, self.sigma**2 * self.C, size=self.pop_size)\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.evals = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n        while self.evals < self.budget:\n            # DE mutation and crossover\n            mutant = np.zeros_like(self.pop)\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                mutant[i] = self.pop[i] + self.de_F * (x_r1 - x_r2)\n\n            cross_points = np.random.rand(self.pop_size, self.dim) < self.de_CR\n            if not np.any(cross_points, axis=1).all():\n                 for i in range(self.pop_size):\n                     if not np.any(cross_points[i]):\n                         cross_points[i, np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.pop)\n            trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n            trial_fitness = np.array([func(x) for x in trial])\n            self.evals += self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if trial_fitness[i] < self.fitness[i]:\n                    self.pop[i] = trial[i]\n                    self.fitness[i] = trial_fitness[i]\n                    if trial_fitness[i] < self.f_opt:\n                        self.f_opt = trial_fitness[i]\n                        self.x_opt = trial[i]\n\n            # CMA-ES adaptation\n            best_index = np.argmin(self.fitness)\n            diff = self.pop[best_index] - self.mean\n            self.mean = (1 - self.cma_learning_rate) * self.mean + self.cma_learning_rate * self.pop[best_index]\n            self.C = (1 - self.cma_learning_rate) * self.C + self.cma_learning_rate * np.outer(diff, diff)\n\n            # Ensure C remains positive definite\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm CMAES_DE scored 0.340 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["28c765ac-5234-4998-9470-8d0cc0a7a395"], "operator": null, "metadata": {"aucs": [0.1310588512725459, 0.24328393039275897, 0.31922195784076546, 0.17801314213261699, 0.3118334444494302, 0.39615610906873544, 0.2721492058850936, 0.30852981216546393, 0.2605078312935787, 0.16298813117951927, 0.5075068332010622, 0.6161817706071248, 0.34538594760982166, 0.2734611651178177, 0.6671711297997254, 0.4048157377160335, 0.3434645867084468, 0.4623961595501781, 0.15073011890672172, 0.4418135321980835]}}
{"id": "cf6c8026-3935-4884-a805-647b48ab47b8", "fitness": 0.40276120673409793, "name": "ScoutBeeDE", "description": "Implements a self-organizing scout bee mechanism in differential evolution, where scout bees randomly explore the search space and inform the population.", "code": "import numpy as np\n\nclass ScoutBeeDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, scout_frequency=20, scout_intensity=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.scout_frequency = scout_frequency\n        self.scout_intensity = scout_intensity\n        self.F = 0.5\n        self.CR = 0.7\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.generation = 0\n\n        while self.evals < self.budget:\n            temp_pop = np.copy(self.pop)\n            temp_fitness = np.copy(self.fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                mutant = self.pop[i] + self.F * (x_r1 - x_r2)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    temp_fitness[i] = f_trial\n                    temp_pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Scout Bee Phase: Random exploration by a few individuals\n            if self.generation % self.scout_frequency == 0:\n                num_scouts = int(self.scout_intensity * self.pop_size)\n                scout_indices = np.random.choice(self.pop_size, num_scouts, replace=False)\n\n                for scout_idx in scout_indices:\n                    scout = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    f_scout = func(scout)\n                    self.evals += 1\n                    if f_scout < temp_fitness[scout_idx]:\n                        temp_fitness[scout_idx] = f_scout\n                        temp_pop[scout_idx] = scout\n                        if f_scout < self.f_opt:\n                            self.f_opt = f_scout\n                            self.x_opt = scout\n\n            self.pop = temp_pop\n            self.fitness = temp_fitness\n            self.generation += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm ScoutBeeDE scored 0.403 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["43834455-7083-472e-a9c1-01e8e3b28868"], "operator": null, "metadata": {"aucs": [0.15716623787615558, 0.24693873723240078, 0.38317353178362645, 0.5255633225751695, 0.3024202423081953, 0.43659196299072334, 0.29621409269561627, 0.3457832560948765, 0.3363050814070564, 0.19818791998037089, 0.5179976022342, 0.9978133227025222, 0.3143985085352249, 0.3077155560460836, 0.7411778341784777, 0.44989715660562135, 0.3207620112417824, 0.5031546431964975, 0.19084089452731834, 0.48312222047003994]}}
{"id": "6d31fcc1-fe95-4bbd-b9f5-f5c05433a9a8", "fitness": 0.4686375030961146, "name": "CMA_ES_DE", "description": "An enhanced Differential Evolution with self-adaptive parameters, covariance matrix adaptation for mutation, and a restart mechanism based on stagnation detection.", "code": "import numpy as np\n\nclass CMA_ES_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=0.1, restart_threshold=1e-12):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 4 + int(3 * np.log(self.dim)) if pop_size is None else pop_size\n        self.mu = self.pop_size // 2  # Number of parents\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.initial_step_size = initial_step_size\n        self.sigma = self.initial_step_size\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2.0)**2 + self.mueff))\n        self.damps = 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1)) - 1) + self.cs\n\n        self.mean = np.zeros(self.dim)\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.restart_threshold = restart_threshold\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.last_improvement = 0\n        self.C = np.eye(self.dim)\n        self.sigma = self.initial_step_size\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        \n        while self.evals < self.budget:\n            # Generate and evaluate offspring\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            y = self.mean + self.sigma * z\n            y = np.clip(y, func.bounds.lb, func.bounds.ub)\n            fitness = np.array([func(x) for x in y])\n            self.evals += self.pop_size\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            y = y[idx]\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = y[0]\n                self.last_improvement = self.evals\n\n            # Update mean\n            y_diff = y[:self.mu] - self.mean\n            self.mean += np.sum(self.weights[:, None] * y_diff, axis=0)\n\n            # Update evolution paths\n            z_diff = z[idx[:self.mu]]\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * np.sum(self.weights[:, None] * z_diff, axis=0)\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.evals/self.pop_size)) / np.sqrt(self.dim)) < (1.4 + 2/(self.dim + 1))\n            self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * y_diff.mean(axis=0) / self.sigma\n\n            # Update covariance matrix\n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (np.outer(self.pc, self.pc) + (1 - hsig) * self.cc * (2 - self.cc) * self.C) + self.cmu * np.sum(self.weights[:, None, None] * (y_diff[:, :, None] @ y_diff[:, None, :]) / self.sigma**2, axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n\n            # Handle covariance matrix\n            if np.any(np.isnan(self.C)):\n                self.C = np.eye(self.dim)\n                self.sigma = self.initial_step_size\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                \n\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n                self.sigma = self.initial_step_size\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n\n            # Restart mechanism\n            if self.evals - self.last_improvement > self.budget / 5:\n                  if np.abs(self.f_opt) < self.restart_threshold:\n                    break\n                  self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                  self.sigma = self.initial_step_size\n                  self.C = np.eye(self.dim)\n                  self.pc = np.zeros(self.dim)\n                  self.ps = np.zeros(self.dim)\n                  self.last_improvement = self.evals\n                  \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm CMA_ES_DE scored 0.469 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["43834455-7083-472e-a9c1-01e8e3b28868"], "operator": null, "metadata": {"aucs": [0.14768490119416933, 0.14636241577959863, 0.48028014620233483, 0.9670630265872888, 0.2727280409681956, 0.9593206102426157, 0.3111587295299574, 0.5053529205776106, 0.7072589123422064, 0.15224403919315233, 0.48272722732953743, 0.7068594711234419, 0.2870934915117169, 0.7261261692531007, 0.6278908590894956, 0.33427866286744756, 0.28412289547126557, 0.9655216437278668, 0.10352372647312458, 0.2051521724581682]}}
{"id": "91dc0367-7210-4d33-afca-5933f9c27617", "fitness": 0.697158700483228, "name": "FractionalDE", "description": "A Differential Evolution strategy with a self-adjusting fractional selection, using a combination of best and random individuals for mutation and a dynamically adjusted crossover rate based on success history.", "code": "import numpy as np\n\nclass FractionalDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, frac=0.3, shcr_memory=10,):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.frac = frac  # Fraction of top individuals used in mutation\n        self.evals = 0\n        self.pop = None\n        self.fitness = None\n        self.x_opt = None\n        self.f_opt = np.inf\n        self.shcr_memory = shcr_memory\n        self.successful_cr = np.ones(self.shcr_memory) * self.CR\n\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.evals = self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        \n        while self.evals < self.budget:\n            new_pop = np.copy(self.pop)\n            new_fitness = np.copy(self.fitness)\n\n            # Selection of top individuals\n            top_indices = np.argsort(self.fitness)[:int(self.frac * self.pop_size)]\n            top_pop = self.pop[top_indices]\n\n            for i in range(self.pop_size):\n\n                cr = np.random.choice(self.successful_cr)\n\n                # Mutation using fractional selection\n                x_best = top_pop[np.random.randint(0, len(top_pop))]\n                x_rand = self.pop[np.random.randint(0, self.pop_size)]\n                x_base = self.pop[np.random.randint(0, self.pop_size)]\n\n\n                mutant = self.pop[i] + self.F * (x_best - x_base) + self.F * (x_rand - self.pop[i])\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    new_fitness[i] = f_trial\n                    new_pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                    # SHADE memory update\n                    self.successful_cr = np.roll(self.successful_cr, -1)\n                    self.successful_cr[-1] = cr\n\n            self.pop = new_pop\n            self.fitness = new_fitness\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm FractionalDE scored 0.697 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["28c765ac-5234-4998-9470-8d0cc0a7a395"], "operator": null, "metadata": {"aucs": [0.2964607818843181, 0.6179273003626065, 0.7371072863278869, 0.8750977414636012, 0.7902098081523028, 0.8387799659447583, 0.6851898654337373, 0.7232558276976802, 0.803800919993889, 0.6218601126670151, 0.8729969562750115, 0.9941758290553926, 0.42632977451886056, 0.7416135149705558, 0.7754835646817303, 0.8251621015340169, 0.6440752208141196, 0.8782786940048561, 0.2775502666297771, 0.5178184772524449]}}
{"id": "9b2c943c-7f5b-4204-b0d0-eaac8fe56107", "fitness": 0.4012935121097233, "name": "BoundaryAwareAdaptiveDE", "description": "A DE variant that adapts scaling factor F and crossover rate CR using a success-history based adaptation, combined with a selection pressure that favors solutions on the boundaries to promote exploration.", "code": "import numpy as np\n\nclass BoundaryAwareAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, memory_size=10, F_init=0.5, CR_init=0.7, boundary_pressure=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.F_init = F_init\n        self.CR_init = CR_init\n        self.boundary_pressure = boundary_pressure # Encourage solutions near boundaries\n        self.F_memory = np.full(self.memory_size, F_init)\n        self.CR_memory = np.full(self.memory_size, CR_init)\n        self.memory_idx = 0\n        self.success_F = []\n        self.success_CR = []\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            temp_pop = np.copy(self.pop)\n            temp_fitness = np.copy(self.fitness)\n\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                F = np.random.choice(self.F_memory)\n                CR = np.random.choice(self.CR_memory)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                mutant = self.pop[i] + F * (x_r1 - x_r2)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, self.lb, self.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Boundary pressure\n                boundary_dist = np.minimum(trial - self.lb, self.ub - trial)\n                boundary_penalty = self.boundary_pressure * np.sum(np.where(boundary_dist < 1e-6, 1, 0))\n\n                # Selection\n                if f_trial + boundary_penalty < self.fitness[i]:\n                    self.success_F.append(F)\n                    self.success_CR.append(CR)\n                    temp_fitness[i] = f_trial\n                    temp_pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            self.pop = temp_pop\n            self.fitness = temp_fitness\n\n            # Update memory\n            if self.success_F:\n                self.F_memory[self.memory_idx] = np.mean(self.success_F)\n                self.CR_memory[self.memory_idx] = np.mean(self.success_CR)\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_F = []\n                self.success_CR = []\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm BoundaryAwareAdaptiveDE scored 0.401 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["43834455-7083-472e-a9c1-01e8e3b28868"], "operator": null, "metadata": {"aucs": [0.1523205061425138, 0.2351718464587712, 0.3919578818338033, 0.506647799213034, 0.3289973745079936, 0.4333077760353532, 0.3036920347533353, 0.34469715414075264, 0.31604200782797065, 0.19988065613840766, 0.5134593086114871, 0.9983534618513226, 0.3074531306105738, 0.3058474488056764, 0.7393416965183047, 0.4483650514987254, 0.32711151069956235, 0.49066888634368455, 0.1901922667126611, 0.4923624434905347]}}
{"id": "a4553cd3-f90c-4d90-be5b-20a327594ff0", "fitness": 0.38146753653233983, "name": "GaussianDE", "description": "A hybrid algorithm combining the exploration of a Gaussian random walk with the exploitation of a differential evolution strategy, adaptively adjusting parameters based on a success-history.", "code": "import numpy as np\n\nclass GaussianDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, CR=0.7, adaptation_rate=0.1, gaussian_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.adaptation_rate = adaptation_rate\n        self.gaussian_step_size = gaussian_step_size\n        self.memory_F = []\n        self.memory_CR = []\n        self.p_best = 0.1\n        self.archive = []\n        self.archive_rate = 0.1\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.generation = 0\n\n        while self.evals < self.budget:\n            self.generation += 1\n\n            for i in range(self.pop_size):\n                # Mutation using Gaussian Random Walk with p_best selection\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                \n                p_best_idx = np.random.choice(self.pop_size, int(self.pop_size * self.p_best), replace=False)\n                best_candidates = self.pop[p_best_idx]\n                best_fitnesses = self.fitness[p_best_idx]\n                x_pbest = best_candidates[np.argmin(best_fitnesses)]\n\n                mutant = self.pop[i] + self.F * (x_pbest - self.pop[i]) + self.gaussian_step_size * np.random.normal(0, 1, self.dim)\n\n                # Ensure bounds\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    #Archive\n                    if np.random.rand() < self.archive_rate:\n                        self.archive.append(self.pop[i].copy())\n                        if len(self.archive) > self.pop_size:\n                            self.archive.pop(0)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                        #Adapt parameters\n                        self.memory_F.append(self.F)\n                        self.memory_CR.append(self.CR)\n\n                        self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                        self.CR = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                else:\n                    if len(self.memory_F) > 0:\n                        self.F = self.memory_F[-1]\n                        self.CR = self.memory_CR[-1]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm GaussianDE scored 0.381 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d09aeb40-fcbd-4111-820c-0b8537f2b3a2"], "operator": null, "metadata": {"aucs": [0.14375389002525496, 0.2778037073104702, 0.4540899447695943, 0.18022799379570464, 0.25170552399696666, 0.519099564581069, 0.2889032218599976, 0.3960828943354592, 0.37895911089104684, 0.18215266066137126, 0.24512675734494882, 0.9985694429287395, 0.2672013068040394, 0.22483729248141826, 0.7164828574163116, 0.3073119651299049, 0.40045716352722116, 0.6669489542219286, 0.24155265896280986, 0.488083819602539]}}
{"id": "6847fe20-9720-47a0-b7eb-0ba900075e1b", "fitness": 0.0, "name": "SelfOrganizingScoutBee", "description": "A self-organizing scout bee algorithm that dynamically adjusts scout bee frequency and search radius based on population diversity and fitness improvement.", "code": "import numpy as np\n\nclass SelfOrganizingScoutBee:\n    def __init__(self, budget=10000, dim=10, pop_size=50, scout_frequency=0.05, search_radius=0.5, diversity_threshold=0.1, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.scout_frequency = scout_frequency\n        self.search_radius = search_radius\n        self.diversity_threshold = diversity_threshold\n        self.adaptation_rate = adaptation_rate\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.generation = 0\n\n        while self.evals < self.budget:\n            self.generation += 1\n\n            # Employed Bee Phase\n            for i in range(self.pop_size):\n                neighbor_index = np.random.randint(0, self.pop_size)\n                while neighbor_index == i:\n                    neighbor_index = np.random.randint(0, self.pop_size)\n\n                phi = np.random.uniform(-1, 1, self.dim)\n                trial = self.pop[i] + phi * (self.pop[i] - self.pop[neighbor_index])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Scout Bee Phase (Adaptive)\n            if np.random.rand() < self.scout_frequency:\n                # Calculate population diversity (standard deviation of each dimension)\n                diversity = np.std(self.pop, axis=0).mean()\n\n                # If diversity is low, increase search radius\n                if diversity < self.diversity_threshold:\n                    self.search_radius = np.clip(self.search_radius + self.adaptation_rate, 0.1, 1.0)\n                else:\n                    self.search_radius = np.clip(self.search_radius - self.adaptation_rate, 0.1, 1.0)\n                \n                #Select a random bee to be the scout\n                scout_index = np.random.randint(0, self.pop_size)\n\n                # Perform a more global search around the current best solution\n                trial = self.x_opt + np.random.uniform(-self.search_radius, self.search_radius, self.dim)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                f_trial = func(trial)\n                self.evals += 1\n                \n                if f_trial < self.fitness[scout_index]:\n                    self.fitness[scout_index] = f_trial\n                    self.pop[scout_index] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Update scout bee frequency based on fitness improvement\n            improvement = self.f_opt / np.min(self.fitness) #Ratio of best fitness to the best individual fitness, should be smaller than 1\n            if improvement < 0.99: #Considered improvement if smaller than 0.99\n                self.scout_frequency = np.clip(self.scout_frequency + self.adaptation_rate, 0.01, 0.2)\n            else:\n                self.scout_frequency = np.clip(self.scout_frequency - self.adaptation_rate, 0.01, 0.2)\n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm SelfOrganizingScoutBee scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d09aeb40-fcbd-4111-820c-0b8537f2b3a2"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "5f534e21-af46-4b98-8f5e-ddaf7d7d503c", "fitness": 0.0, "name": "SineCosineDE", "description": "A hybrid algorithm combining Differential Evolution with a Sine Cosine Algorithm for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass SineCosineDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, CR=0.7, a=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.a = a # Parameter for Sine Cosine Algorithm\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = 0\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial_de = np.where(cross_points, mutant, self.pop[i])\n\n                # Sine Cosine Algorithm component\n                r1 = np.random.rand()\n                r2 = np.random.rand()\n                \n                if r1 < 0.5:\n                    trial_sca = self.pop[i] + r2 * np.sin(2 * np.pi * r1) * (self.x_opt - self.pop[i])\n                else:\n                    trial_sca = self.pop[i] + r2 * np.cos(2 * np.pi * r1) * (self.x_opt - self.pop[i])\n\n                trial_sca = np.clip(trial_sca, func.bounds.lb, func.bounds.ub)\n                \n                # Adaptive combination of DE and SCA\n                if np.random.rand() < 0.5:\n                    trial = trial_de\n                else:\n                    trial = trial_sca\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm SineCosineDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d09aeb40-fcbd-4111-820c-0b8537f2b3a2"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "6f29bd0c-49eb-4166-8966-51139561901c", "fitness": -Infinity, "name": "SOM_DE", "description": "Combines a self-organizing map (SOM) for solution space mapping with differential evolution (DE) to guide the search, adapting the population based on SOM cluster performance.", "code": "import numpy as np\n\nclass SOM_DE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, som_grid_size=10, learning_rate=0.1, sigma=1.0, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.som_grid_size = som_grid_size\n        self.learning_rate = learning_rate\n        self.sigma = sigma\n        self.F = F\n        self.CR = CR\n        self.evals = 0\n        self.som = np.random.uniform(-1, 1, size=(self.som_grid_size, self.som_grid_size, self.dim)) # SOM nodes\n\n    def find_closest_node(self, x):\n        \"\"\"Find the closest SOM node to a given input vector.\"\"\"\n        distances = np.linalg.norm(self.som.reshape(-1, self.dim) - x, axis=1)\n        index = np.argmin(distances)\n        return np.unravel_index(index, (self.som_grid_size, self.som_grid_size))\n\n    def update_som(self, x, winning_node):\n        \"\"\"Update the SOM based on the winning node and neighborhood function.\"\"\"\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                distance = np.sqrt((i - winning_node[0])**2 + (j - winning_node[1])**2)\n                influence = np.exp(-distance**2 / (2 * self.sigma**2))\n                self.som[i, j] += self.learning_rate * influence * (x - self.som[i, j])\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        # Initialize SOM with a subset of the initial population\n        for x in self.pop[:min(self.pop_size, 100)]: # limit to 100 init updates.\n            winning_node = self.find_closest_node(x)\n            self.update_som(x, winning_node)\n\n        cluster_fitness = np.zeros((self.som_grid_size, self.som_grid_size))\n        cluster_counts = np.zeros((self.som_grid_size, self.som_grid_size))\n\n        while self.evals < self.budget:\n            new_pop = np.copy(self.pop)\n            new_fitness = np.copy(self.fitness)\n\n            for i in range(self.pop.shape[0]):\n                # Mutation\n                idxs = np.random.choice(self.pop.shape[0], 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                mutant = self.pop[i] + self.F * (x_r1 - x_r2)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # SOM Update and Cluster Fitness\n                winning_node = self.find_closest_node(trial)\n                self.update_som(trial, winning_node)\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    new_fitness[i] = f_trial\n                    new_pop[i] = trial\n                    \n                    #Update Cluster fitness\n                    cluster_fitness[winning_node] = (cluster_fitness[winning_node] * cluster_counts[winning_node] + f_trial) / (cluster_counts[winning_node] + 1)\n                    cluster_counts[winning_node] += 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            self.pop = new_pop\n            self.fitness = new_fitness\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "An exception occurred: Evaluation timed out after 60 seconds..", "error": "", "parent_ids": ["28c765ac-5234-4998-9470-8d0cc0a7a395"], "operator": null, "metadata": {}}
{"id": "76b76322-7020-495c-8adc-d5a59e5a6429", "fitness": -Infinity, "name": "DE_NM", "description": "Hybridizes Differential Evolution with a Nelder-Mead simplex search applied to the best individuals for local refinement.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=50, nm_iterations=5, nm_pop=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.nm_iterations = nm_iterations\n        self.nm_pop = nm_pop\n        self.F = 0.5\n        self.CR = 0.7\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.generation = 0\n\n        while self.evals < self.budget:\n            temp_pop = np.copy(self.pop)\n            temp_fitness = np.copy(self.fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                mutant = self.pop[i] + self.F * (x_r1 - x_r2)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    temp_fitness[i] = f_trial\n                    temp_pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Nelder-Mead refinement of best individuals\n            best_indices = np.argsort(self.fitness)[:self.nm_pop]\n            for idx in best_indices:\n                if self.evals + self.nm_iterations < self.budget:\n                    bounds = func.bounds\n                    result = minimize(func, self.pop[idx], method='Nelder-Mead', options={'maxiter': self.nm_iterations, 'maxfev': self.budget - self.evals}, bounds=bounds)\n                    if result.success:\n                        f_nm = result.fun\n                        x_nm = result.x\n                        self.evals += result.nfev\n                        if f_nm < temp_fitness[idx]:\n                            temp_fitness[idx] = f_nm\n                            temp_pop[idx] = x_nm\n                            if f_nm < self.f_opt:\n                                self.f_opt = f_nm\n                                self.x_opt = x_nm\n\n            self.pop = temp_pop\n            self.fitness = temp_fitness\n            self.generation += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["cf6c8026-3935-4884-a805-647b48ab47b8"], "operator": null, "metadata": {}}
{"id": "fdcefda5-84d2-4209-a0ef-18cb3dcda544", "fitness": -Infinity, "name": "SymbioticDE", "description": "Implements a self-organizing symbiotic organisms search, where individuals benefit from interactions with others and adapt based on success, incorporating differential evolution mutation and a boundary-reflecting mechanism.", "code": "import numpy as np\n\nclass SymbioticDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, lr=0.1, boundary_reflection=True):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr  # Learning rate for adaptation\n        self.boundary_reflection = boundary_reflection\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Select a symbiotic partner\n                partner_idx = np.random.choice(self.pop_size)\n                while partner_idx == i:\n                    partner_idx = np.random.choice(self.pop_size)\n                partner = self.pop[partner_idx]\n\n                # Mutualism: Both benefit\n                mutant = self.pop[i] + self.lr * (partner - self.pop[i])\n\n                # Commensalism: One benefits, the other is neutral\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                commensal_mutant = self.pop[i] + self.lr * (x_r1 - x_r2)\n\n                # Parasitism: One benefits, the other is harmed (Differential Evolution Mutation)\n                parasite = np.random.uniform(self.lb, self.ub, self.dim)\n                trial = self.pop[i] + self.lr * (parasite - self.pop[i])\n\n                # Boundary reflection\n                if self.boundary_reflection:\n                    mutant = self.reflect_bounds(mutant)\n                    commensal_mutant = self.reflect_bounds(commensal_mutant)\n                    trial = self.reflect_bounds(trial)\n                else:\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    commensal_mutant = np.clip(commensal_mutant, self.lb, self.ub)\n                    trial = np.clip(trial, self.lb, self.ub)\n\n                # Evaluate and update (select the best)\n                f_mutant = func(mutant)\n                self.evals += 1\n                f_commensal = func(commensal_mutant)\n                self.evals += 1\n                f_trial = func(trial)\n                self.evals += 1\n\n                if f_mutant < self.fitness[i] and f_mutant <= f_commensal and f_mutant <= f_trial:\n                    self.pop[i] = mutant\n                    self.fitness[i] = f_mutant\n                elif f_commensal < self.fitness[i] and f_commensal <= f_mutant and f_commensal <= f_trial:\n                    self.pop[i] = commensal_mutant\n                    self.fitness[i] = f_commensal\n                elif f_trial < self.fitness[i] and f_trial <= f_mutant and f_trial <= f_commensal:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.pop[i]\n\n        return self.f_opt, self.x_opt\n\n    def reflect_bounds(self, x):\n        x_copy = np.copy(x)\n        for i in range(self.dim):\n            if x_copy[i] < self.lb:\n                x_copy[i] = self.lb + abs(x_copy[i] - self.lb)\n                if x_copy[i] > self.ub:\n                    x_copy[i] = self.ub\n            elif x_copy[i] > self.ub:\n                x_copy[i] = self.ub - abs(x_copy[i] - self.ub)\n                if x_copy[i] < self.lb:\n                    x_copy[i] = self.lb\n        return x_copy", "configspace": "", "generation": 8, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["9b2c943c-7f5b-4204-b0d0-eaac8fe56107"], "operator": null, "metadata": {}}
{"id": "fd0c29c6-4d91-4fbb-a01a-f9ae3d6f99f6", "fitness": -Infinity, "name": "AdaptiveCauchyDE", "description": "An adaptive Differential Evolution strategy that utilizes a Cauchy distribution for mutation, dynamically adjusts its parameters based on the population's diversity, and incorporates a local search step.", "code": "import numpy as np\nfrom scipy.stats import cauchy\n\nclass AdaptiveCauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, memory_size=10, F_init=0.5, CR_init=0.7, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.F_init = F_init\n        self.CR_init = CR_init\n        self.local_search_prob = local_search_prob\n        self.F_memory = np.full(self.memory_size, F_init)\n        self.CR_memory = np.full(self.memory_size, CR_init)\n        self.memory_idx = 0\n        self.success_F = []\n        self.success_CR = []\n        self.diversity_threshold = 1e-3\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            temp_pop = np.copy(self.pop)\n            temp_fitness = np.copy(self.fitness)\n\n            # Calculate population diversity\n            diversity = np.std(self.pop)\n\n            for i in range(self.pop_size):\n                # Parameter adaptation based on diversity\n                if diversity > self.diversity_threshold:\n                    F = np.random.choice(self.F_memory)\n                    CR = np.random.choice(self.CR_memory)\n                else:\n                    # Reduce F and CR to promote exploitation\n                    F = 0.2 * np.random.rand()\n                    CR = 0.9\n\n                # Mutation using Cauchy distribution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                mutant = self.pop[i] + cauchy.rvs(loc=0, scale=F, size=self.dim) * (x_r1 - x_r2)\n                \n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, self.lb, self.ub)\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.local_search(trial, func) # pass the black box function to the local_search function\n                    trial = np.clip(trial, self.lb, self.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.success_F.append(F)\n                    self.success_CR.append(CR)\n                    temp_fitness[i] = f_trial\n                    temp_pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            self.pop = temp_pop\n            self.fitness = temp_fitness\n\n            # Update memory\n            if self.success_F:\n                self.F_memory[self.memory_idx] = np.mean(self.success_F)\n                self.CR_memory[self.memory_idx] = np.mean(self.success_CR)\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_F = []\n                self.success_CR = []\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func, step_size=0.1, num_steps=5):\n        \"\"\"Performs a simple local search around the given solution.\"\"\"\n        best_x = x\n        best_f = func(x)\n        \n        for _ in range(num_steps):\n            # Generate a random perturbation\n            perturbation = np.random.uniform(-step_size, step_size, size=self.dim)\n            new_x = x + perturbation\n            new_x = np.clip(new_x, self.lb, self.ub)\n\n            new_f = func(new_x)\n            self.evals += 1\n\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x\n        \n        return best_x", "configspace": "", "generation": 8, "feedback": "An exception occurred: name 'cauchy' is not defined.", "error": "", "parent_ids": ["9b2c943c-7f5b-4204-b0d0-eaac8fe56107"], "operator": null, "metadata": {}}
{"id": "395a5aae-83ce-47ba-b3a4-577ada19e52d", "fitness": 0.0, "name": "CauchyLocalSearchDE", "description": "A Differential Evolution strategy using a combination of Cauchy mutation and local search, adaptively adjusting parameters based on population diversity and success history.", "code": "import numpy as np\n\nclass CauchyLocalSearchDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, memory_size=10, F_init=0.5, CR_init=0.7, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.F_init = F_init\n        self.CR_init = CR_init\n        self.local_search_prob = local_search_prob\n        self.F_memory = np.full(self.memory_size, F_init)\n        self.CR_memory = np.full(self.memory_size, CR_init)\n        self.memory_idx = 0\n        self.success_F = []\n        self.success_CR = []\n        self.diversity_threshold = 0.01 # Threshold for triggering parameter adaptation based on diversity\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            temp_pop = np.copy(self.pop)\n            temp_fitness = np.copy(self.fitness)\n\n            # Calculate population diversity\n            diversity = np.std(self.pop)\n\n            # Parameter adaptation based on diversity\n            if diversity < self.diversity_threshold:\n                # If population is too homogeneous, increase exploration by increasing F\n                F = min(1.0, np.random.normal(1.0, 0.1))  # Increase F for exploration\n                CR = np.random.choice(self.CR_memory)  # Keep CR as is or adjust slightly\n            else:\n                # Use success history if population is diverse enough\n                F = np.random.choice(self.F_memory)\n                CR = np.random.choice(self.CR_memory)\n\n            for i in range(self.pop_size):\n\n                # Mutation using Cauchy distribution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                mutant = self.pop[i] + F * (x_r1 - x_r2) + np.random.standard_cauchy(size=self.dim) * 0.1\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, self.lb, self.ub)\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.local_search(trial, func)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.success_F.append(F)\n                    self.success_CR.append(CR)\n                    temp_fitness[i] = f_trial\n                    temp_pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            self.pop = temp_pop\n            self.fitness = temp_fitness\n\n            # Update memory\n            if self.success_F:\n                self.F_memory[self.memory_idx] = np.mean(self.success_F)\n                self.CR_memory[self.memory_idx] = np.mean(self.success_CR)\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_F = []\n                self.success_CR = []\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func, radius=0.1, iterations=5):\n        \"\"\"Performs a local search around a given point.\"\"\"\n        best_x = x\n        best_f = func(x)\n        self.evals += 1\n\n        for _ in range(iterations):\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, self.lb, self.ub)\n            new_f = func(new_x)\n            self.evals += 1\n\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x\n\n        return best_x", "configspace": "", "generation": 8, "feedback": "The algorithm CauchyLocalSearchDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9b2c943c-7f5b-4204-b0d0-eaac8fe56107"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "6d59c28e-d6d7-4829-b041-29db145977a8", "fitness": 0.0, "name": "MultiPopulationDE", "description": "A DE variant employing a multi-population approach with dynamic resource allocation based on population performance, using a pool of mutation strategies and periodic population merging.", "code": "import numpy as np\n\nclass MultiPopulationDE:\n    def __init__(self, budget=10000, dim=10, num_pops=5, pop_size=20, memory_size=10, F_init=0.5, CR_init=0.7, merge_interval=500):\n        self.budget = budget\n        self.dim = dim\n        self.num_pops = num_pops\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.F_init = F_init\n        self.CR_init = CR_init\n        self.merge_interval = merge_interval\n        self.F_memory = [np.full(self.memory_size, F_init) for _ in range(self.num_pops)]\n        self.CR_memory = [np.full(self.memory_size, CR_init) for _ in range(self.num_pops)]\n        self.memory_idx = [0] * self.num_pops\n        self.success_F = [[] for _ in range(self.num_pops)]\n        self.success_CR = [[] for _ in range(self.num_pops)]\n        self.mutation_strategies = ['DE/rand/1', 'DE/best/1', 'DE/current-to-rand/1', 'DE/current-to-best/1']  # Pool of mutation strategies\n        self.populations = []\n        self.fitnesses = []\n        self.evals_per_pop = [0] * self.num_pops\n        self.resource_allocation = [budget // num_pops] * num_pops #initial resource allocation\n\n    def initialize_population(self, func, pop_id):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        return pop, fitness\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n\n        # Initialize populations\n        for i in range(self.num_pops):\n            pop, fitness = self.initialize_population(func, i)\n            self.populations.append(pop)\n            self.fitnesses.append(fitness)\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = pop[best_idx]\n            self.evals += self.pop_size\n        \n        while self.evals < self.budget:\n            for i in range(self.num_pops):\n                if self.evals_per_pop[i] < self.resource_allocation[i]:  #check if resource budget is not exceeded\n                    # Parameter adaptation\n                    F = np.random.choice(self.F_memory[i])\n                    CR = np.random.choice(self.CR_memory[i])\n\n                    # Mutation Strategy selection\n                    mutation_strategy = np.random.choice(self.mutation_strategies)\n                    temp_pop = np.copy(self.populations[i])\n                    temp_fitness = np.copy(self.fitnesses[i])\n\n                    for j in range(self.pop_size):\n                        # Mutation\n                        if mutation_strategy == 'DE/rand/1':\n                            idxs = np.random.choice(self.pop_size, 3, replace=False)\n                            x_r1, x_r2, x_r3 = self.populations[i][idxs[0]], self.populations[i][idxs[1]], self.populations[i][idxs[2]]\n                            mutant = self.populations[i][j] + F * (x_r1 - x_r2)\n                        elif mutation_strategy == 'DE/best/1':\n                            best_idx = np.argmin(self.fitnesses[i])\n                            idxs = np.random.choice(self.pop_size, 2, replace=False)\n                            x_r1, x_r2 = self.populations[i][idxs[0]], self.populations[i][idxs[1]]\n                            mutant = self.populations[i][best_idx] + F * (x_r1 - x_r2)\n                        elif mutation_strategy == 'DE/current-to-rand/1':\n                            idxs = np.random.choice(self.pop_size, 2, replace=False)\n                            x_r1, x_r2 = self.populations[i][idxs[0]], self.populations[i][idxs[1]]\n                            mutant = self.populations[i][j] + F * (self.populations[i][j] - x_r1) + F * (x_r2 - self.populations[i][j])\n                        elif mutation_strategy == 'DE/current-to-best/1':\n                            best_idx = np.argmin(self.fitnesses[i])\n                            mutant = self.populations[i][j] + F * (self.populations[i][best_idx] - self.populations[i][j])\n\n                        # Crossover\n                        cross_points = np.random.rand(self.dim) < CR\n                        if not np.any(cross_points):\n                            cross_points[np.random.randint(0, self.dim)] = True\n                        trial = np.where(cross_points, mutant, self.populations[i][j])\n                        trial = np.clip(trial, self.lb, self.ub)\n\n                        f_trial = func(trial)\n                        self.evals += 1\n                        self.evals_per_pop[i] += 1\n\n                        # Selection\n                        if f_trial < self.fitnesses[i][j]:\n                            self.success_F[i].append(F)\n                            self.success_CR[i].append(CR)\n                            temp_fitness[j] = f_trial\n                            temp_pop[j] = trial\n\n                            if f_trial < self.f_opt:\n                                self.f_opt = f_trial\n                                self.x_opt = trial\n                    self.populations[i] = temp_pop\n                    self.fitnesses[i] = temp_fitness\n\n                     # Update memory\n                    if self.success_F[i]:\n                        self.F_memory[i][self.memory_idx[i]] = np.mean(self.success_F[i])\n                        self.CR_memory[i][self.memory_idx[i]] = np.mean(self.success_CR[i])\n                        self.memory_idx[i] = (self.memory_idx[i] + 1) % self.memory_size\n                        self.success_F[i] = []\n                        self.success_CR[i] = []\n            # Dynamic Resource Allocation (simplified - allocating more resources to better performing population):\n            avg_fitness = [np.mean(fitness) for fitness in self.fitnesses]\n            if np.std(avg_fitness) > 0.0001:\n                 normalized_fitness = (np.max(avg_fitness) - avg_fitness) / np.sum(np.max(avg_fitness) - avg_fitness) # better fitnes = more resources\n                 self.resource_allocation = (normalized_fitness * self.budget).astype(int)\n                 remaining_budget = self.budget - np.sum(self.resource_allocation)\n                 self.resource_allocation[np.argmax(normalized_fitness)] += remaining_budget\n\n            # Periodic Population Merging\n            if self.evals > 0 and self.evals % self.merge_interval == 0:\n                 all_individuals = np.concatenate(self.populations)\n                 all_fitnesses = np.concatenate(self.fitnesses)\n                 sorted_indices = np.argsort(all_fitnesses)\n                 best_individuals = all_individuals[sorted_indices[:self.num_pops * self.pop_size]]\n                 for i in range(self.num_pops):\n                      self.populations[i] = best_individuals[i*self.pop_size:(i+1)*self.pop_size]\n                      self.fitnesses[i] = np.array([func(x) for x in self.populations[i]])  #re-evaluate after merge\n                      best_idx = np.argmin(self.fitnesses[i]) #track the global best during evolution.\n                      if self.fitnesses[i][best_idx] < self.f_opt:\n                           self.f_opt = self.fitnesses[i][best_idx]\n                           self.x_opt = self.populations[i][best_idx]\n                      \n                      self.evals += self.pop_size\n                      self.evals_per_pop[i] = 0   # Reset evaluation counter after merge\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm MultiPopulationDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9b2c943c-7f5b-4204-b0d0-eaac8fe56107"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "7e52d5f8-fd8d-4902-a7fc-72cbb1d0712c", "fitness": 0.4408516865696567, "name": "OrthogonalDE", "description": "A DE variant employing orthogonal learning to enhance population diversity and convergence speed by exploring solutions orthogonal to existing search directions.", "code": "import numpy as np\n\nclass OrthogonalDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.7, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * self.dim if pop_size is None else pop_size\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.f_opt = np.min(fitness)\n        self.x_opt = self.population[np.argmin(fitness)]\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                v = x_r1 + self.F * (x_r2 - x_r3)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal Learning\n                x_mean = np.mean(self.population, axis=0)\n                direction = u - x_mean\n                \n                # Ensure direction is not a zero vector\n                if np.linalg.norm(direction) > 1e-8:  \n                    orthogonal_vector = self.gram_schmidt(direction)\n\n                    # Generate a new candidate along the orthogonal direction\n                    step_size = np.random.uniform(-0.1, 0.1)  # Adjust step size as needed\n                    u_orth = u + step_size * orthogonal_vector\n                    u_orth = np.clip(u_orth, func.bounds.lb, func.bounds.ub)\n\n                    f_u_orth = func(u_orth)\n                    self.evals += 1\n                else:\n                    f_u_orth = np.inf  # Penalize zero-length direction\n\n                f_u = func(u)\n                self.evals += 1\n                \n\n                if f_u_orth < f_u and f_u_orth < fitness[i]:\n                  fitness[i] = f_u_orth\n                  self.population[i] = u_orth\n                elif f_u < fitness[i]:\n                    fitness[i] = f_u\n                    self.population[i] = u\n                    \n                if fitness[i] < self.f_opt:\n                    self.f_opt = fitness[i]\n                    self.x_opt = self.population[i]\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt\n\n    def gram_schmidt(self, v):\n        \"\"\"\n        Finds an orthogonal vector to the input vector v.\n        \"\"\"\n        # Create a random vector\n        w = np.random.rand(self.dim)\n        \n        # Make w orthogonal to v\n        w = w - np.dot(w, v) / np.dot(v, v) * v\n        \n        return w / np.linalg.norm(w)  # Normalize the orthogonal vector", "configspace": "", "generation": 8, "feedback": "The algorithm OrthogonalDE scored 0.441 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6d31fcc1-fe95-4bbd-b9f5-f5c05433a9a8"], "operator": null, "metadata": {"aucs": [0.17616740140012588, 0.29161359660303654, 0.37687874836395174, 0.6332752839953653, 0.3625704739715203, 0.47153382772954633, 0.30487328622573473, 0.34810450838814755, 0.3768209914835303, 0.2718158224899382, 0.6094100327172683, 0.9988611454480371, 0.3672092993228544, 0.34320232164689557, 0.817940676059936, 0.48823287767308043, 0.32800599450196455, 0.575176915637621, 0.19054160573576417, 0.484798921998815]}}
{"id": "7cd8e33e-47d4-4db0-a78b-7e57bfeaf363", "fitness": 0.3090535232776619, "name": "CooperativeDE", "description": "Cooperative Differential Evolution with Inter-Population Communication, where multiple DE populations evolve independently and periodically exchange information to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass CooperativeDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, num_populations=5, F=0.5, CR=0.7, exchange_interval=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.num_populations = num_populations\n        self.F = F\n        self.CR = CR\n        self.exchange_interval = exchange_interval\n        self.populations = []\n        self.fitnesses = []\n        self.evals = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        for _ in range(self.num_populations):\n            self.populations.append(np.random.uniform(-5, 5, size=(self.pop_size, self.dim)))\n            self.fitnesses.append(np.full(self.pop_size, np.Inf))\n\n    def __call__(self, func):\n        for i in range(self.num_populations):\n            for j in range(self.pop_size):\n                self.fitnesses[i][j] = func(self.populations[i][j])\n                self.evals += 1\n                if self.fitnesses[i][j] < self.f_opt:\n                    self.f_opt = self.fitnesses[i][j]\n                    self.x_opt = self.populations[i][j]\n                if self.evals >= self.budget:\n                    return self.f_opt, self.x_opt\n        \n        generation = 0\n        while self.evals < self.budget:\n            for i in range(self.num_populations):\n                temp_pop = np.copy(self.populations[i])\n                temp_fitness = np.copy(self.fitnesses[i])\n\n                for j in range(self.pop_size):\n                    # Mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.populations[i][idxs[0]], self.populations[i][idxs[1]], self.populations[i][idxs[2]]\n                    mutant = self.populations[i][j] + self.F * (x_r1 - x_r2)\n                    mutant = np.clip(mutant, -5, 5)\n\n                    # Crossover\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, self.populations[i][j])\n                    trial = np.clip(trial, -5, 5)\n\n                    f_trial = func(trial)\n                    self.evals += 1\n\n                    if f_trial < self.fitnesses[i][j]:\n                        temp_fitness[j] = f_trial\n                        temp_pop[j] = trial\n\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                    \n                    if self.evals >= self.budget:\n                        return self.f_opt, self.x_opt\n\n                self.populations[i] = temp_pop\n                self.fitnesses[i] = temp_fitness\n            \n            generation += 1\n            if generation % self.exchange_interval == 0:\n                # Exchange information between populations\n                best_indices = [np.argmin(fitness) for fitness in self.fitnesses]\n                best_individuals = [self.populations[i][best_indices[i]] for i in range(self.num_populations)]\n\n                for i in range(self.num_populations):\n                    for j in range(self.pop_size):\n                        if np.random.rand() < 0.1:  # Replace some individuals with best from other populations\n                            other_pop_index = np.random.randint(0, self.num_populations)\n                            self.populations[i][j] = best_individuals[other_pop_index]\n                            self.fitnesses[i][j] = func(self.populations[i][j])\n                            self.evals += 1\n                            if self.fitnesses[i][j] < self.f_opt:\n                                self.f_opt = self.fitnesses[i][j]\n                                self.x_opt = self.populations[i][j]\n                            if self.evals >= self.budget:\n                                return self.f_opt, self.x_opt\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm CooperativeDE scored 0.309 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9b2c943c-7f5b-4204-b0d0-eaac8fe56107"], "operator": null, "metadata": {"aucs": [0.1290671634073498, 0.19798928873477284, 0.2947938887327868, 0.2533299191005026, 0.22693540440179327, 0.27830313069669455, 0.24612335029179155, 0.26731681184426903, 0.22608928490693347, 0.18558375159365548, 0.24271745893284968, 0.9955223455285938, 0.27948915746930725, 0.24209432189620617, 0.6080797430616418, 0.3038576052764884, 0.2505378301788561, 0.3106892385703721, 0.17195202122269204, 0.4705987497056814]}}
{"id": "7e290fe2-58d4-4cc8-85f0-c328e82e3c02", "fitness": 0.4555120721541077, "name": "AdaptiveMutationDE", "description": "A DE variant employing a pool of mutation strategies selected based on their recent success, combined with a scaling factor adaptation based on fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveMutationDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, mutation_pool_size=5, success_history_length=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.evals = 0\n        self.pop = None\n        self.fitness = None\n        self.x_opt = None\n        self.f_opt = np.inf\n\n        self.mutation_pool_size = mutation_pool_size\n        self.mutation_strategies = [\n            self.mutation_rand1,\n            self.mutation_best1,\n            self.mutation_current_to_rand1,\n            self.mutation_current_to_best1,\n            self.mutation_rand2, # added more diversity\n        ]\n        self.mutation_weights = np.ones(self.mutation_pool_size) / self.mutation_pool_size\n        self.success_history_length = success_history_length\n        self.success_history = []\n        self.archive = []\n\n    def mutation_rand1(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.pop[idxs]\n        return self.pop[i] + self.F * (x2 - x3)\n\n    def mutation_best1(self, i):\n        best = self.pop[np.argmin(self.fitness)]\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        x1, x2 = self.pop[idxs]\n        return best + self.F * (x1 - x2)\n\n    def mutation_current_to_rand1(self, i):\n         idxs = np.random.choice(self.pop_size, 3, replace=False)\n         x1, x2, x3 = self.pop[idxs]\n         return self.pop[i] + self.F * (x1 - self.pop[i]) + self.F * (x2-x3)\n\n    def mutation_current_to_best1(self, i):\n        best = self.pop[np.argmin(self.fitness)]\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        x1, x2 = self.pop[idxs]\n        return self.pop[i] + self.F * (best - self.pop[i]) + self.F*(x1-x2)\n    \n    def mutation_rand2(self, i):\n        idxs = np.random.choice(self.pop_size, 5, replace=False)\n        x1, x2, x3, x4, x5 = self.pop[idxs]\n        return self.pop[i] + self.F * (x1 - x2) + self.F*(x3-x4) + self.F*(x5 - self.pop[i])\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.evals = self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n        while self.evals < self.budget:\n            new_pop = np.copy(self.pop)\n            new_fitness = np.copy(self.fitness)\n\n            for i in range(self.pop_size):\n                # Choose mutation strategy based on weights\n                mutation_strategy_index = np.random.choice(self.mutation_pool_size, p=self.mutation_weights)\n                mutant = self.mutation_strategies[mutation_strategy_index](i)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    delta_f = self.fitness[i] - f_trial\n                    new_fitness[i] = f_trial\n                    new_pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                    \n                    self.success_history.append((mutation_strategy_index, delta_f))\n                    if len(self.success_history) > self.success_history_length:\n                        self.success_history.pop(0)\n\n\n                    self.F = np.clip(self.F * np.exp(0.1*(delta_f/np.mean(self.fitness))), 0.1, 1.0)\n\n\n            self.pop = new_pop\n            self.fitness = new_fitness\n            self.update_mutation_weights()\n\n        return self.f_opt, self.x_opt\n\n    def update_mutation_weights(self):\n        if not self.success_history:\n            return\n        \n        success_counts = np.zeros(self.mutation_pool_size)\n        total_delta_f = np.zeros(self.mutation_pool_size)\n        for strategy_index, delta_f in self.success_history:\n            success_counts[strategy_index] += 1\n            total_delta_f[strategy_index] += delta_f\n        \n        for i in range(self.mutation_pool_size):\n          if success_counts[i] > 0:\n            total_delta_f[i] /= success_counts[i] \n\n        total_successes = np.sum(success_counts)\n        if total_successes > 0:\n\n            for i in range(self.mutation_pool_size):\n              if success_counts[i] > 0:\n                self.mutation_weights[i] = (success_counts[i]/total_successes)*(1+total_delta_f[i]/np.max(total_delta_f))\n              else:\n                self.mutation_weights[i] = 0.0001\n\n            self.mutation_weights /= np.sum(self.mutation_weights) ", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveMutationDE scored 0.456 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["91dc0367-7210-4d33-afca-5933f9c27617"], "operator": null, "metadata": {"aucs": [0.16993509945546226, 0.2945499704760586, 0.47184927144977373, 0.730729627430736, 0.37457573608363925, 0.5835778355290233, 0.31569220092921957, 0.43413425499313785, 0.4989042002909897, 0.22724567767745485, 0.4246499505966489, 0.9940388499941637, 0.2714267757401059, 0.2804545710120149, 0.7265932635665547, 0.5959360698584645, 0.2934907410461912, 0.676491761381572, 0.24243314848231245, 0.5035324370886304]}}
{"id": "4de2e812-c5f2-4c16-8972-17b7aa07c4d1", "fitness": -Infinity, "name": "CulturalAlgorithm", "description": "Implements a self-adjusting Cultural Algorithm, adapting beliefs using elite individuals and exploring the search space based on these beliefs.", "code": "import numpy as np\n\nclass CulturalAlgorithm:\n    def __init__(self, budget=10000, dim=10, pop_size=None, belief_size=None, alpha=0.1, beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 4 + int(3 * np.log(self.dim)) if pop_size is None else pop_size\n        self.belief_size = 5 if belief_size is None else belief_size\n        self.alpha = alpha  # Influence of elite individuals on beliefs\n        self.beta = beta  # Exploration range based on beliefs\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        # Initialize belief space\n        self.normative_bounds = np.zeros((2, self.dim))  # [lower, upper]\n        self.situational_knowledge = np.array([np.Inf] * self.belief_size)\n        self.top_individuals = np.zeros((self.belief_size, self.dim))\n\n    def initialize_population(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        return population, fitness\n\n    def update_belief_space(self, population, fitness, func):\n        # Update normative knowledge (bounds)\n        for i in range(self.dim):\n            self.normative_bounds[0, i] = np.min(population[:, i])\n            self.normative_bounds[1, i] = np.max(population[:, i])\n\n        # Update situational knowledge (elite individuals)\n        elite_indices = np.argsort(fitness)[:self.belief_size]\n        elite_fitness = fitness[elite_indices]\n        elite_individuals = population[elite_indices]\n\n        # Incorporate new elite individuals into situational knowledge\n        self.situational_knowledge = np.concatenate([self.situational_knowledge, elite_fitness])\n        self.top_individuals = np.concatenate([self.top_individuals, elite_individuals], axis=0)\n        \n        # Sort and select the best\n        idx = np.argsort(self.situational_knowledge)[:self.belief_size]\n        self.situational_knowledge = self.situational_knowledge[idx]\n        self.top_individuals = self.top_individuals[idx]\n\n        if self.situational_knowledge[0] < self.f_opt:\n            self.f_opt = self.situational_knowledge[0]\n            self.x_opt = self.top_individuals[0]\n\n    def generate_offspring(self, func):\n        offspring = np.zeros((self.pop_size, self.dim))\n        for i in range(self.pop_size):\n            # Select a parent from the top individuals\n            parent_idx = np.random.randint(0, self.belief_size)\n            parent = self.top_individuals[parent_idx]\n\n            # Exploration based on belief space\n            for j in range(self.dim):\n                lower_bound = self.normative_bounds[0, j]\n                upper_bound = self.normative_bounds[1, j]\n                range_width = upper_bound - lower_bound\n                \n                lower_bound = max(func.bounds.lb, parent[j] - self.beta * range_width)\n                upper_bound = min(func.bounds.ub, parent[j] + self.beta * range_width)\n\n                offspring[i, j] = np.random.uniform(lower_bound, upper_bound)\n\n        return offspring\n\n    def __call__(self, func):\n        population, fitness = self.initialize_population(func)\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        evals = self.pop_size\n\n        while evals < self.budget:\n            self.update_belief_space(population, fitness, func)\n            offspring = self.generate_offspring(func)\n            offspring_fitness = np.array([func(x) for x in offspring])\n            \n            evals += self.pop_size\n            \n            # Combine parents and offspring\n            combined_population = np.concatenate([population, offspring], axis=0)\n            combined_fitness = np.concatenate([fitness, offspring_fitness])\n\n            # Select the best individuals for the next generation\n            idx = np.argsort(combined_fitness)[:self.pop_size]\n            population = combined_population[idx]\n            fitness = combined_fitness[idx]\n            \n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["6d31fcc1-fe95-4bbd-b9f5-f5c05433a9a8"], "operator": null, "metadata": {}}
{"id": "d2627cba-c865-4391-82b3-7ac4351a4c49", "fitness": -Infinity, "name": "AdaptiveEnsemble", "description": "Adaptive Multi-Strategy Ensemble with a self-tuning mixture of Differential Evolution, CMA-ES, and PSO components, dynamically adjusting their weights based on their recent performance and exploration diversity.", "code": "import numpy as np\n\nclass AdaptiveEnsemble:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=0.1, restart_threshold=1e-12, ensemble_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 4 + int(3 * np.log(self.dim)) if pop_size is None else pop_size\n        self.ensemble_size = ensemble_size\n        self.initial_step_size = initial_step_size\n        self.restart_threshold = restart_threshold\n\n        # Initialize ensemble weights\n        self.weights = np.ones(self.ensemble_size) / self.ensemble_size\n\n        # Initialize individual optimizers\n        self.optimizers = [\n            DifferentialEvolution(budget=budget // ensemble_size, dim=dim, pop_size=pop_size),\n            CMAES(budget=budget // ensemble_size, dim=dim, pop_size=pop_size, initial_step_size=initial_step_size),\n            ParticleSwarm(budget=budget // ensemble_size, dim=dim, pop_size=pop_size)\n        ]\n        \n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.last_improvement = 0\n        self.fitness_history = np.zeros((self.ensemble_size, 10)) #store the last 10 fitness values for each optimizer\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.last_improvement = 0\n        \n        #Reset optimizers and fitness histories\n        for i in range(self.ensemble_size):\n            self.optimizers[i].budget = self.budget // self.ensemble_size\n            self.optimizers[i].reset(func)\n            self.fitness_history[i, :] = np.inf\n        \n        self.weights = np.ones(self.ensemble_size) / self.ensemble_size\n        \n        while self.evals < self.budget:\n            # Run each optimizer for a fraction of the remaining budget\n            for i in range(self.ensemble_size):\n                remaining_budget = self.budget - self.evals\n                allocated_budget = int(self.weights[i] * remaining_budget)\n                self.optimizers[i].budget = allocated_budget\n\n                f, x = self.optimizers[i](func)\n                \n                #Update eval count\n                self.evals += self.optimizers[i].evals - self.optimizers[i].initial_evals\n                self.optimizers[i].initial_evals = self.optimizers[i].evals # store the current eval count to calculate the amount used in the current iteration\n\n                # Update best solution\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                    self.last_improvement = self.evals\n\n                #Update fitness history for adaptive weights\n                self.fitness_history[i, :-1] = self.fitness_history[i, 1:]\n                self.fitness_history[i, -1] = f\n\n            # Adjust ensemble weights based on performance\n            self.adjust_weights()\n\n            # Restart mechanism\n            if self.evals - self.last_improvement > self.budget / 5:\n                if np.abs(self.f_opt) < self.restart_threshold:\n                    break\n                for i in range(self.ensemble_size):\n                    self.optimizers[i].reset(func)\n                self.last_improvement = self.evals\n                self.weights = np.ones(self.ensemble_size) / self.ensemble_size\n                self.fitness_history[:, :] = np.inf\n\n        return self.f_opt, self.x_opt\n\n    def adjust_weights(self):\n        # Calculate average fitness over recent history\n        avg_fitness = np.mean(self.fitness_history, axis=1)\n\n        # Normalize fitness to create performance scores\n        performance = np.max(avg_fitness) - avg_fitness + 1e-9 # adding a small epsilon to avoid division by zero\n\n        # Update weights based on performance\n        self.weights = self.weights * performance\n        self.weights /= np.sum(self.weights)\n        self.weights = np.clip(self.weights, 0.05, 0.95)  # Ensure each optimizer has a minimum and maximum weight\n        self.weights /= np.sum(self.weights)\n\nclass DifferentialEvolution:\n    def __init__(self, budget=1000, dim=10, pop_size=None, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * self.dim if pop_size is None else pop_size\n        self.F = F\n        self.CR = CR\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initial_evals = 0 #track the number of evaluations at the start of __call__\n\n    def __call__(self, func):\n        if self.population is None:\n          self.reset(func) #reset population when the object is used for the first time\n        \n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        \n                if self.evals >= self.budget:\n                  break\n\n        return self.f_opt, self.x_opt\n\n    def reset(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.initial_evals = self.evals\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 4 + int(3 * np.log(self.dim)) if pop_size is None else pop_size\n        self.mu = self.pop_size // 2  # Number of parents\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.initial_step_size = initial_step_size\n        self.sigma = self.initial_step_size\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2.0)**2 + self.mueff))\n        self.damps = 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1)) - 1) + self.cs\n\n        self.mean = np.zeros(self.dim)\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initial_evals = 0 #track the number of evaluations at the start of __call__\n\n    def __call__(self, func):\n        while self.evals < self.budget:\n            # Generate and evaluate offspring\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            y = self.mean + self.sigma * z\n            y = np.clip(y, func.bounds.lb, func.bounds.ub)\n            fitness = np.array([func(x) for x in y])\n            self.evals += self.pop_size\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            y = y[idx]\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = y[0]\n\n            # Update mean\n            y_diff = y[:self.mu] - self.mean\n            self.mean += np.sum(self.weights[:, None] * y_diff, axis=0)\n\n            # Update evolution paths\n            z_diff = z[idx[:self.mu]]\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * np.sum(self.weights[:, None] * z_diff, axis=0)\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.evals/self.pop_size)) / np.sqrt(self.dim)) < (1.4 + 2/(self.dim + 1))\n            self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * y_diff.mean(axis=0) / self.sigma\n\n            # Update covariance matrix\n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (np.outer(self.pc, self.pc) + (1 - hsig) * self.cc * (2 - self.cc) * self.C) + self.cmu * np.sum(self.weights[:, None, None] * (y_diff[:, :, None] @ y_diff[:, None, :]) / self.sigma**2, axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n\n            # Handle covariance matrix\n            if np.any(np.isnan(self.C)):\n                self.C = np.eye(self.dim)\n                self.sigma = self.initial_step_size\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n                self.sigma = self.initial_step_size\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                \n            if self.evals >= self.budget:\n              break\n\n        return self.f_opt, self.x_opt\n\n    def reset(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initial_evals = self.evals\n        self.C = np.eye(self.dim)\n        self.sigma = self.initial_step_size\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\nclass ParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=None, w=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * self.dim if pop_size is None else pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.Inf\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.initial_evals = 0 #track the number of evaluations at the start of __call__\n\n    def __call__(self, func):\n        if self.particles is None:\n            self.reset(func)\n        \n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                # Update position\n                self.particles[i] = self.particles[i] + self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                fitness = func(self.particles[i])\n                self.evals += 1\n\n                # Update personal best\n                if fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = fitness\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                    # Update global best\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                        self.f_opt = fitness\n                        self.x_opt = self.particles[i]\n            if self.evals >= self.budget:\n              break\n\n        return self.f_opt, self.x_opt\n\n    def reset(self, func):\n        self.particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_fitness = np.array([func(x) for x in self.particles])\n        self.evals = self.pop_size\n        self.initial_evals = self.evals\n        self.global_best_position = self.personal_best_positions[np.argmin(self.personal_best_fitness)]\n        self.global_best_fitness = np.min(self.personal_best_fitness)\n        self.f_opt = self.global_best_fitness\n        self.x_opt = self.global_best_position", "configspace": "", "generation": 8, "feedback": "An exception occurred: name 'DifferentialEvolution' is not defined.", "error": "", "parent_ids": ["6d31fcc1-fe95-4bbd-b9f5-f5c05433a9a8"], "operator": null, "metadata": {}}
{"id": "9a628055-e4a7-4e61-9f82-a27e4994e568", "fitness": -Infinity, "name": "ElectromagnetismDE", "description": "Population-based algorithm inspired by electromagnetism, where each solution is a charged particle that attracts or repels other particles based on their fitness, combined with differential evolution mutation.", "code": "import numpy as np\n\nclass ElectromagnetismDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, n_positive=None, charge_factor=1.0, de_factor=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * self.dim if pop_size is None else pop_size\n        self.n_positive = self.pop_size // 2 if n_positive is None else n_positive  # Number of positively charged particles\n        self.charge_factor = charge_factor\n        self.de_factor = de_factor\n        self.cr = cr\n\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n\n    def calculate_charge(self):\n        \"\"\"Calculates the charge of each particle based on fitness.\"\"\"\n        fitness_range = np.max(self.fitness) - np.min(self.fitness)\n        if fitness_range == 0:\n            return np.zeros(self.pop_size)  # Avoid division by zero\n        \n        charge = (self.fitness - np.max(self.fitness)) / fitness_range\n        charge = self.charge_factor * charge\n        return charge\n    \n    def calculate_force(self):\n        \"\"\"Calculates the force exerted on each particle by others.\"\"\"\n        charges = self.calculate_charge()\n        forces = np.zeros((self.pop_size, self.dim))\n        for i in range(self.pop_size):\n            for j in range(self.pop_size):\n                if i != j:\n                    distance = self.population[j] - self.population[i]\n                    norm = np.linalg.norm(distance)\n                    if norm == 0:\n                        force_direction = np.random.randn(self.dim)\n                        force_direction /= np.linalg.norm(force_direction)\n                    else:\n                        force_direction = distance / norm\n                    \n                    force_magnitude = charges[i] * charges[j] / (norm + 1e-8)  # Adding a small constant to avoid division by zero\n                    forces[i] += force_magnitude * force_direction\n        return forces\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.evals < self.budget:\n            # Calculate forces\n            forces = self.calculate_force()\n\n            # Move particles based on forces and DE mutation\n            for i in range(self.pop_size):\n                # DE mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                v = x_r1 + self.de_factor * (x_r2 - x_r3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n                \n                # Apply Force\n                u = u + forces[i]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n            \n            if self.evals >= self.budget:\n                break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occurred: Evaluation timed out after 60 seconds..", "error": "", "parent_ids": ["6d31fcc1-fe95-4bbd-b9f5-f5c05433a9a8"], "operator": null, "metadata": {}}
{"id": "8aa52853-61d6-4320-8248-1cfe9ecefe2b", "fitness": -Infinity, "name": "AdaptiveNichingCMAES_DE", "description": "Adaptive Differential Evolution with Covariance Matrix Adaptation, incorporating a niching strategy to maintain population diversity and improve exploration of multimodal landscapes.", "code": "import numpy as np\n\nclass AdaptiveNichingCMAES_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=0.1, restart_threshold=1e-12, niche_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 4 + int(3 * np.log(self.dim)) if pop_size is None else pop_size\n        self.mu = self.pop_size // 2  # Number of parents\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.initial_step_size = initial_step_size\n        self.sigma = self.initial_step_size\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2.0)**2 + self.mueff))\n        self.damps = 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1)) - 1) + self.cs\n\n        self.mean = np.zeros(self.dim)\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.restart_threshold = restart_threshold\n        self.last_improvement = 0\n        self.niche_radius = niche_radius\n        self.niches = []\n\n    def niching(self, population, fitness):\n        \"\"\"\n        Applies a niching strategy to maintain diversity.\n        \"\"\"\n        if not self.niches:\n            # Initialize the first niche\n            self.niches.append({'center': population[np.argmin(fitness)], 'fitness': np.min(fitness)})\n            return population, fitness\n\n        new_population = []\n        new_fitness = []\n        \n        for i in range(len(population)):\n            x = population[i]\n            f = fitness[i]\n            \n            # Check if the individual is within the radius of an existing niche\n            in_niche = False\n            for niche in self.niches:\n                if np.linalg.norm(x - niche['center']) < self.niche_radius:\n                    in_niche = True\n                    if f < niche['fitness']:\n                        niche['center'] = x\n                        niche['fitness'] = f\n                    break\n            \n            if not in_niche:\n                # Create a new niche\n                self.niches.append({'center': x, 'fitness': f})\n                \n            new_population.append(x)\n            new_fitness.append(f)\n        \n        return np.array(new_population), np.array(new_fitness)\n\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n        self.last_improvement = 0\n        self.C = np.eye(self.dim)\n        self.sigma = self.initial_step_size\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        self.niches = []\n        \n        while self.evals < self.budget:\n            # Generate and evaluate offspring\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            y = self.mean + self.sigma * z\n            y = np.clip(y, func.bounds.lb, func.bounds.ub)\n            fitness = np.array([func(x) for x in y])\n            self.evals += self.pop_size\n\n            # Apply niching strategy\n            y, fitness = self.niching(y, fitness)\n            \n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            y = y[idx]\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = y[0]\n                self.last_improvement = self.evals\n\n            # Update mean\n            y_diff = y[:self.mu] - self.mean\n            self.mean += np.sum(self.weights[:, None] * y_diff, axis=0)\n\n            # Update evolution paths\n            z_diff = z[idx[:self.mu]]\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * np.sum(self.weights[:, None] * z_diff, axis=0)\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.evals/self.pop_size)) / np.sqrt(self.dim)) < (1.4 + 2/(self.dim + 1))\n            self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * y_diff.mean(axis=0) / self.sigma\n\n            # Update covariance matrix\n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (np.outer(self.pc, self.pc) + (1 - hsig) * self.cc * (2 - self.cc) * self.C) + self.cmu * np.sum(self.weights[:, None, None] * (y_diff[:, :, None] @ y_diff[:, None, :]) / self.sigma**2, axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n\n            # Handle covariance matrix\n            if np.any(np.isnan(self.C)):\n                self.C = np.eye(self.dim)\n                self.sigma = self.initial_step_size\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                \n\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n                self.sigma = self.initial_step_size\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n\n            # Restart mechanism\n            if self.evals - self.last_improvement > self.budget / 5:\n                  if np.abs(self.f_opt) < self.restart_threshold:\n                    break\n                  self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                  self.sigma = self.initial_step_size\n                  self.C = np.eye(self.dim)\n                  self.pc = np.zeros(self.dim)\n                  self.ps = np.zeros(self.dim)\n                  self.last_improvement = self.evals\n                  \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occurred: Evaluation timed out after 60 seconds..", "error": "", "parent_ids": ["6d31fcc1-fe95-4bbd-b9f5-f5c05433a9a8"], "operator": null, "metadata": {}}
