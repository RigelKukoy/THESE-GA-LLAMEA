{"method_name": "LLaMEA-1", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-1", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "5908a426-e448-4d00-9f48-12f180046988", "fitness": 0.6261833592700048, "name": "CMAES_with_Archive", "description": "Covariance matrix adaptation evolution strategy with adaptive population size and archive for diversity maintenance.", "code": "import numpy as np\n\nclass CMAES_with_Archive:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=None, c_cov=None, archive_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = cs\n        self.damps = damp if damp is not None else 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.ccov1 = c_cov[0] if c_cov is not None else 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.ccovmu = c_cov[1] if c_cov is not None else 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2.3)**2 + self.mueff)\n        self.ccovmu = min(1-self.ccov1, self.ccovmu)\n\n        self.mean = None\n        self.sigma = 0.5\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.archive = []\n        self.archive_size = archive_size\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize(self):\n        self.mean = np.random.uniform(-5, 5, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n    def sample(self):\n        z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n        C_sqrt = np.linalg.cholesky(self.C)\n        x = self.mean[:, np.newaxis] + self.sigma * C_sqrt @ z\n        return x.T\n\n    def update(self, x, f):\n        idx = np.argsort(f)\n        x = x[idx]\n        f = f[idx]\n\n        xmean = np.sum(x[:self.mu] * self.weights[:, np.newaxis], axis=0)\n\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (xmean - self.mean) / self.sigma\n        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.eval_count / self.popsize))) < (1.4 + 2 / (self.dim + 1))\n        self.pc = (1 - 1) * self.pc + hsig * np.sqrt(1 * (2 - 1) * self.mueff) * (xmean - self.mean) / self.sigma\n\n        y = (x[:self.mu] - self.mean) / self.sigma\n        self.C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * (1 - hsig**2)) * self.C \\\n                 + self.ccov1 * np.outer(self.pc, self.pc) \\\n                 + self.ccovmu * np.sum(self.weights[:, np.newaxis, np.newaxis] * y[:, :, np.newaxis] * y[:, np.newaxis, :], axis=0)\n\n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n        self.mean = xmean\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        self.C = self.C + 1e-8 * np.eye(self.dim)\n        \n        for i in range(len(x)):\n            if f[i] < self.f_opt:\n                self.f_opt = f[i]\n                self.x_opt = x[i]\n\n    def archive_management(self, x, f):\n        for i in range(len(x)):\n            if len(self.archive) < self.archive_size:\n                self.archive.append((x[i], f[i]))\n            else:\n                # Replace worst element in archive if current element is better\n                worst_idx = np.argmax([item[1] for item in self.archive])\n                if f[i] < self.archive[worst_idx][1]:\n                    self.archive[worst_idx] = (x[i], f[i])\n\n    def __call__(self, func):\n        self.initialize()\n\n        while self.eval_count < self.budget:\n            x = self.sample()\n            \n            # Ensure bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.eval_count += len(x)\n\n            self.update(x, f)\n            self.archive_management(x, f)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CMAES_with_Archive scored 0.626 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "Refine the strategy of the selected algorithm to improve it.", "metadata": {"aucs": [0.20705098038763925, 0.886954192747395, 0.5650152068702794, 0.9702481770809139, 0.9548863629204157, 0.9603153980072728, 0.30339303077465296, 0.6765677544072053, 0.8673222663306481, 0.17169826582294423, 0.815878189756413, 0.9869087789846127, 0.33433657039369746, 0.42110220881549376, 0.9622475693022657, 0.33489810572361445, 0.4605326913244304, 0.9724324642243866, 0.16434963050824314, 0.5075293410175721]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-1-MA_BBOB-0", "seed": 0}
{"method_name": "LLaMEA-1", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-1", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "f897025e-58cd-41d0-9b7d-5fa4cf67bc58", "fitness": 0.7497264272160729, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with a success-history based adaptive F and CR, combined archives with aging and adaptive size, orthogonal learning, dynamic restart with shrinking bounds, and a modified current-to-pbest mutation strategy.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=50, orthogonal_learning_rate=0.1, restart_patience=50, archive_prob=0.1, pbest_proportion=0.1, gamma_F=0.1, gamma_CR=0.1, F_init=0.5, CR_init=0.7, archive_decay_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n        self.restart_patience = restart_patience\n        self.stagnation_counter = 0\n        self.previous_best_fitness = np.Inf\n        self.F_success_history = []\n        self.CR_success_history = []\n        self.archive_prob = archive_prob\n        self.pbest_proportion = pbest_proportion\n        self.gamma_F = gamma_F\n        self.gamma_CR = gamma_CR\n        self.F_base = F_init\n        self.CR_base = CR_init\n        self.success_archive = []\n        self.failure_archive = []\n        self.archive_decay_rate = archive_decay_rate\n        self.bounds_lb = None\n        self.bounds_ub = None\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.bounds_lb = func.bounds.lb\n        self.bounds_ub = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(self.bounds_lb, self.bounds_ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Update optimal solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n            self.stagnation_counter = 0\n            self.previous_best_fitness = self.f_opt\n        else:\n            self.stagnation_counter +=1\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            \n            # Self-adaptive F and CR\n            if self.F_success_history:\n                self.F_base = (1 - self.gamma_F) * self.F_base + self.gamma_F * np.mean(self.F_success_history)\n                self.F_base = np.clip(self.F_base, 0.1, 1.0)\n            if self.CR_success_history:\n                self.CR_base = (1 - self.gamma_CR) * self.CR_base + self.gamma_CR * np.mean(self.CR_success_history)\n                self.CR_base = np.clip(self.CR_base, 0.1, 1.0)\n\n            for i in range(self.pop_size):\n                # Adaptive F and CR: Sample from log-normal distribution\n                F = np.exp(np.random.normal(np.log(self.F_base), 0.1))\n                CR = np.exp(np.random.normal(np.log(self.CR_base), 0.1))\n                F = np.clip(F, 0.1, 1.0)\n                CR = np.clip(CR, 0.1, 1.0)\n\n                # Mutation: current-to-pbest\n                pbest_count = max(1, int(self.pbest_proportion * self.pop_size))\n                pbest_indices = np.argsort(fitness)[:pbest_count]\n                pbest = population[np.random.choice(pbest_indices)]\n                \n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = population[indices]\n\n                mutant = population[i] + F * (pbest - population[i]) + F * (x1 - x2)\n                \n                # Incorporate archive\n                if len(self.success_archive) > 0 and np.random.rand() < self.archive_prob:  # archive_prob chance to use archive\n                    archive_index = np.random.randint(len(self.success_archive))\n                    mutant = x1 + F * (x2 - self.success_archive[archive_index])\n\n                mutant = np.clip(mutant, self.bounds_lb, self.bounds_ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                # Orthogonal Learning\n                if np.random.rand() < self.orthogonal_learning_rate:\n                    orthogonal_vector = self.x_opt + np.random.normal(0, 0.1, self.dim)  # Perturb best solution\n                    orthogonal_vector = np.clip(orthogonal_vector, self.bounds_lb, self.bounds_ub)\n                    trial = 0.5 * (trial + orthogonal_vector)  # Combine with trial vector\n                    trial = np.clip(trial, self.bounds_lb, self.bounds_ub)\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                if f_trial < fitness[i]:\n                    new_population[i] = trial\n                    new_fitness[i] = f_trial\n                    \n                    # Record successful F and CR values\n                    self.F_success_history.append(F)\n                    self.CR_success_history.append(CR)\n                    if len(self.F_success_history) > 50:\n                        self.F_success_history.pop(0)\n                        self.CR_success_history.pop(0)\n\n                    # Add replaced vector to success archive\n                    if len(self.success_archive) < self.archive_size:\n                        self.success_archive.append(population[i])\n                    else:\n                        self.success_archive[np.random.randint(len(self.success_archive))] = population[i]\n\n\n                    # Update optimal solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.stagnation_counter = 0\n                        self.previous_best_fitness = self.f_opt\n                else:\n                     # Add trial vector to failure archive\n                    if len(self.failure_archive) < self.archive_size:\n                        self.failure_archive.append(trial)\n                    else:\n                        self.failure_archive[np.random.randint(len(self.failure_archive))] = trial\n\n            population = new_population\n            fitness = new_fitness\n\n            # Decay archive to promote diversity and remove potentially bad solutions\n            self.success_archive = [self.success_archive[i] for i in range(len(self.success_archive)) if np.random.rand() < self.archive_decay_rate]\n            self.failure_archive = [self.failure_archive[i] for i in range(len(self.failure_archive)) if np.random.rand() < self.archive_decay_rate]\n            \n            # Restart population if stagnating using opposition-based learning and shrinking bounds\n            if self.stagnation_counter > self.restart_patience:\n                # Generate opposition population within shrunken bounds\n                center = self.x_opt\n                bound_range = (self.bounds_ub - self.bounds_lb) * 0.5  # Shrink by half\n                new_lb = np.maximum(self.bounds_lb, center - bound_range / 2)\n                new_ub = np.minimum(self.bounds_ub, center + bound_range / 2)\n\n                opposition_population = np.random.uniform(new_lb, new_ub, size=(self.pop_size, self.dim))\n                opposition_fitness = np.array([func(x) for x in opposition_population])\n                self.budget -= self.pop_size\n\n                # Combine original and opposition populations\n                combined_population = np.vstack((population, opposition_population))\n                combined_fitness = np.concatenate((fitness, opposition_fitness))\n\n                # Select the best individuals to form the new population\n                best_indices = np.argsort(combined_fitness)[:self.pop_size]\n                population = combined_population[best_indices]\n                fitness = combined_fitness[best_indices]\n\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                    self.stagnation_counter = 0\n                    self.previous_best_fitness = self.f_opt\n                else:\n                    self.stagnation_counter +=1\n                    \n                # Reset F and CR history\n                self.F_success_history = []\n                self.CR_success_history = []\n                \n                # Update bounds\n                self.bounds_lb = new_lb\n                self.bounds_ub = new_ub\n\n            if self.budget <= 0:\n                break\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.750 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c71a85b0-79cc-4ac0-8462-d189b70da42e"], "operator": "Refine the strategy of the selected algorithm to improve it.", "metadata": {"aucs": [0.2713732541026952, 0.6873169695666386, 0.7987066238722946, 0.935041191694186, 0.8381035901774854, 0.8629389667690132, 0.6935260682434774, 0.7661651318588651, 0.832440843774964, 0.40838916180959706, 0.9156637156845142, 0.9955334736865352, 0.7254852533307127, 0.8007956467400427, 0.954618437778863, 0.8497242333862232, 0.7132273230134398, 0.9034295321553631, 0.5089186070538201, 0.5331305196227281]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-1-MA_BBOB-1", "seed": 1}
{"method_name": "LLaMEA-1", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-1", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "0ed0e56c-569a-45b9-85d6-113405c7bdae", "fitness": 0.7811920062263702, "name": "CMAES_OLS_Mirrored", "description": "Adaptive CMA-ES with orthogonal subspace learning, dynamic population size, adaptive orthogonal learning frequency, and a mirrored sampling strategy to enhance exploration.", "code": "import numpy as np\n\nclass CMAES_OLS_Mirrored:\n    def __init__(self, budget=10000, dim=10, mu_ratio=0.25, cs=0.3, dsigma=0.2, ccov=0.3, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.mu_ratio = mu_ratio\n        self.cs = cs\n        self.dsigma = dsigma\n        self.ccov = ccov\n        self.lb = -5.0\n        self.ub = 5.0\n        self.initial_sigma = initial_sigma\n\n        self.lambda_ = int(4 + np.floor(3 * np.log(self.dim)))  # Initial population size\n        self.mu = int(self.lambda_ * self.mu_ratio)  # Number of parents\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))  # Weights for recombination\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.chiN = np.sqrt(self.dim) * (1 - (1/(4*self.dim)) + 1/(12*self.dim**2))\n        self.cs_damps = 1 + self.dsigma * max(0, np.sqrt((self.mueff-1)/(self.dim+1))-1) + self.cs  # Damping for step-size\n        self.c1 = self.ccov / ((self.dim+1.3)**2 + self.mueff)\n        self.cmu = min(1-self.c1, self.ccov * (self.mueff-2+1/self.mueff) / ((self.dim+2.0)**2 + self.mueff))\n        self.stagnation_threshold = 50\n        self.orthogonal_learning_threshold = 100\n        self.max_restarts = 5\n        self.mirror_prob = 0.2 # Probability of mirrored sampling\n\n    def __call__(self, func):\n        # Initialize variables\n        xmean = np.random.uniform(self.lb, self.ub, size=self.dim)  # Initial guess of mean\n        sigma = self.initial_sigma  # Overall step size\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim)  # Evolution path for C\n        ps = np.zeros(self.dim)  # Evolution path for sigma\n        \n        f_opt = np.Inf\n        x_opt = None\n        evals = 0\n\n        restart_iter = 0\n        stagnation_counter = 0\n        orthogonal_learning_counter = 0\n        performance_history = [] #Track last 'n' best fitness values\n\n        while evals < self.budget:\n            # Generate and evaluate offspring\n            z = np.random.normal(0, 1, size=(self.dim, self.lambda_))\n            y = np.dot(np.linalg.cholesky(C), z)\n            x = xmean.reshape(-1, 1) + sigma * y\n\n            #Mirrored Sampling\n            x_mirrored = xmean.reshape(-1, 1) - sigma * y\n            \n            # Clip and evaluate\n            x = np.clip(x, self.lb, self.ub)\n            x_mirrored = np.clip(x_mirrored, self.lb, self.ub)\n            \n            f = np.array([func(x[:,i]) if evals + i < self.budget else np.inf for i in range(self.lambda_//2)])\n            f_mirrored = np.array([func(x_mirrored[:,i]) if evals + self.lambda_//2 + i < self.budget else np.inf for i in range(self.lambda_//2)])\n\n            evals += self.lambda_\n            f = np.concatenate([f, f_mirrored])\n            x = np.concatenate([x[:,:self.lambda_//2], x_mirrored[:,:self.lambda_//2]], axis=1)\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            f = f[idx]\n            x = x[:, idx]\n            \n            # Update optimal solution\n            if f[0] < f_opt:\n                f_opt = f[0]\n                x_opt = x[:, 0].copy()  # Ensure x_opt is a copy\n                stagnation_counter = 0  # Reset stagnation counter\n                performance_history.append(f_opt)\n\n                # Adaptive Lambda: Increase lambda if consistently improving\n                if len(performance_history) > 5 and all(performance_history[i] > performance_history[i+1] for i in range(len(performance_history)-1)):\n                     self.lambda_ = int(self.lambda_ * 1.1) #Increase population size by 10%\n                     self.mu = int(self.lambda_ * self.mu_ratio)  # Update mu\n                     self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))  # Weights for recombination\n                     self.weights = self.weights / np.sum(self.weights)\n                     self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n                     self.c1 = self.ccov / ((self.dim+1.3)**2 + self.mueff)\n                     self.cmu = min(1-self.c1, self.ccov * (self.mueff-2+1/self.mueff) / ((self.dim+2.0)**2 + self.mueff))\n\n            else:\n                stagnation_counter += 1\n                if len(performance_history) > 0:\n                    performance_history.pop(0) #Remove oldest entry\n\n\n            # Update distribution parameters\n            xmean_new = np.sum(x[:, :self.mu] * self.weights, axis=1)\n            \n            ps = (1-self.cs) * ps + np.sqrt(self.cs*(2-self.cs)*self.mueff) * np.dot(np.linalg.inv(np.linalg.cholesky(C)), (xmean_new - xmean)) / sigma\n            hsig = np.linalg.norm(ps)/np.sqrt(1-(1-self.cs)**(2*evals/self.lambda_))/self.chiN < 1.4 + 2/(self.dim+1)\n            pc = (1-self.ccov) * pc + hsig * np.sqrt(self.ccov*(2-self.ccov)*self.mueff) * (xmean_new - xmean) / sigma\n            \n            C = (1-self.c1-self.cmu) * C + self.c1 * (np.outer(pc, pc) + (1-hsig) * self.ccov*(2-self.ccov) * C)\n            \n            # More robust covariance update\n            for i in range(self.mu):\n                y = (x[:, i] - xmean) / sigma\n                C += self.cmu * self.weights[i] * np.outer(y, y)\n\n            sigma = sigma * np.exp((self.cs/self.cs_damps) * (np.linalg.norm(ps)/self.chiN - 1))\n            \n            xmean = xmean_new\n\n            # Repair covariance matrix (ensure positive definiteness)\n            C = np.triu(C) + np.transpose(np.triu(C,1))\n            try:\n                np.linalg.cholesky(C)\n            except np.linalg.LinAlgError:\n                C = C + np.eye(self.dim) * 1e-6\n\n            # Orthogonal Subspace Learning\n            orthogonal_learning_counter +=1\n\n            #Adaptive orthogonal learning frequency\n            adaptive_orthogonal_learning_threshold = int(self.orthogonal_learning_threshold * (1 + 0.2*(f_opt-np.mean(func.bounds.ub))))\n\n            if orthogonal_learning_counter > adaptive_orthogonal_learning_threshold:\n                orthogonal_learning_counter = 0\n\n                # Calculate the change in xmean\n                delta_xmean = xmean_new - xmean\n\n                # Perform SVD on the covariance matrix\n                try:\n                    U, S, V = np.linalg.svd(C)\n                except np.linalg.LinAlgError:\n                    U, S, V = np.linalg.svd(C + np.eye(self.dim) * 1e-6) #Adding small value to diagonal\n\n                # Project delta_xmean onto the principal components\n                delta_xmean_projected = np.dot(U.T, delta_xmean)\n\n                # Update xmean along the principal components (only top components)\n                num_components_to_use = min(self.dim, 5)  # Limiting to top 5 for stability\n                xmean = xmean + np.dot(U[:, :num_components_to_use], delta_xmean_projected[:num_components_to_use])\n\n                xmean = np.clip(xmean, self.lb, self.ub)  # Ensure bounds are respected\n\n            # Restart mechanism\n            if np.max(np.diag(C)) > (10**7) * sigma or stagnation_counter > self.stagnation_threshold: # Aggressive restart\n                restart_iter += 1\n                xmean = np.random.uniform(self.lb, self.ub, size=self.dim)\n                sigma = self.initial_sigma # Reset sigma\n                C = np.eye(self.dim)\n                pc = np.zeros(self.dim)\n                ps = np.zeros(self.dim)\n                stagnation_counter = 0 #reset stagnation\n                orthogonal_learning_counter = 0 #reset orthogonal learning counter\n                self.lambda_ = int(4 + np.floor(3 * np.log(self.dim)))  # Reset population size to original\n                performance_history = []\n\n                if restart_iter > self.max_restarts:\n                    break\n\n            if np.any(np.isnan(C)):\n                C = np.eye(self.dim)\n                sigma = self.initial_sigma\n                pc = np.zeros(self.dim)\n                ps = np.zeros(self.dim)\n                stagnation_counter = 0\n                orthogonal_learning_counter = 0\n                self.lambda_ = int(4 + np.floor(3 * np.log(self.dim))) # Reset population size\n                performance_history = []\n                    \n        return f_opt, x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm CMAES_OLS_Mirrored scored 0.781 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e2372a10-8599-4023-9ab8-9d7906519cd6"], "operator": "Refine the strategy of the selected algorithm to improve it.", "metadata": {"aucs": [0.606938362806994, 0.9468963559107607, 0.940918683710628, 0.9656397266220709, 0.9478491028212874, 0.9573520566633044, 0.3251063423128875, 0.9371186634300916, 0.9490916941120605, 0.7648719610760829, 0.965882406663924, 0.9910779129865309, 0.30817084552344576, 0.9461967299054828, 0.9592151995398291, 0.3853289145398783, 0.9002891996966187, 0.9612324400475211, 0.33645699716549715, 0.528206528992506]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-1-MA_BBOB-2", "seed": 2}
{"method_name": "LLaMEA-1", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-1", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false, "eval_timeout": 60}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "496ac514-845a-411c-896f-ee0f392b4057", "fitness": 0.7780690378343315, "name": "CMAES_SimpleRankOneMirrorHyperbolic", "description": "CMA-ES with a simplified rank-one update, adaptive step size using a moving average, and a mirrored sampling fraction adapted by a hyperbolic decay function and enhanced bound handling.", "code": "import numpy as np\n\nclass CMAES_SimpleRankOneMirrorHyperbolic:\n    def __init__(self, budget=10000, dim=10, sigma0=0.5, history_length=5, initial_mirrored_fraction=0.5, mirrored_decay=0.99, hyperbolic_decay_factor=0.1, step_size_adaptation_rate=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.history_length = history_length\n        self.mirrored_fraction = initial_mirrored_fraction\n        self.mirrored_decay = mirrored_decay\n        self.hyperbolic_decay_factor = hyperbolic_decay_factor\n        self.step_size_adaptation_rate = step_size_adaptation_rate\n\n        self.popsize = 4 + int(np.floor(3 * np.log(self.dim)))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.step_history = []\n\n    def __call__(self, func):\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = self.sigma0\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        \n        c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        \n        chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + 1 / (21 * self.dim**2))\n\n        f_opt = np.Inf\n        x_opt = None\n        eval_count = 0\n\n        while eval_count < self.budget:\n            z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n            x = mean + sigma * (np.linalg.cholesky(C) @ z.T).T\n\n            # Mirrored sampling\n            mirrored_fraction = self.mirrored_fraction / (1 + self.hyperbolic_decay_factor * (eval_count / self.budget))\n            num_mirrored = int(self.popsize * mirrored_fraction)\n            x_mirrored = mean - sigma * (np.linalg.cholesky(C) @ z[:num_mirrored].T).T\n            x = np.vstack((x, x_mirrored))\n            z_mirrored = -z[:num_mirrored]\n            z = np.vstack((z, z_mirrored))\n            \n            # Enhanced bound handling - clipping and penalty\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) + 1e10 * (np.sum((xi < func.bounds.lb) | (xi > func.bounds.ub))) if eval_count + i < self.budget else np.inf for i, xi in enumerate(x)])\n            eval_count += len(x)\n\n            idx = np.argsort(f)\n            x = x[idx]\n            z = z[idx]\n            f = f[idx]\n\n            if f[0] < f_opt:\n                f_opt = f[0]\n                x_opt = x[0]\n\n            x_mu = x[:self.mu]\n            mean_new = np.sum(x_mu * self.weights[:,None], axis=0)\n\n            # Simplified Rank-One Update\n            pc = (1 - c_c) * pc + np.sqrt(c_c * (2 - c_c) * self.mueff) * (mean_new - mean) / sigma\n            C = (1 - c_1) * C + c_1 * np.outer(pc, pc)\n            \n            # Step size adaptation using moving average\n            step = (mean_new - mean) / sigma\n            self.step_history.append(np.linalg.norm(step))\n            if len(self.step_history) > self.history_length:\n                self.step_history.pop(0)\n\n            avg_step_size = np.mean(self.step_history) if self.step_history else 1\n            sigma *= np.exp(self.step_size_adaptation_rate * (avg_step_size - 1))\n\n            mean = mean_new\n            self.mirrored_fraction *= self.mirrored_decay\n\n            # Ensure C is positive definite\n            C = np.triu(C) + np.triu(C, 1).T\n            try:\n                C_evals = np.linalg.eigvalsh(C)\n                C_min_eig = np.min(C_evals)\n                if C_min_eig < 1e-10:\n                    C += (1e-10 - C_min_eig) * np.eye(self.dim)\n            except np.linalg.LinAlgError:\n                C = np.eye(self.dim)\n\n            if np.any(np.isnan(mean)) or np.any(np.isnan(C)):\n                mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                C = np.eye(self.dim)\n                pc = np.zeros(self.dim)\n                sigma = self.sigma0\n\n        return f_opt, x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm CMAES_SimpleRankOneMirrorHyperbolic scored 0.778 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ee0a84f2-5ebb-4fad-928d-809f48880481"], "operator": null, "metadata": {"aucs": [0.26168053669148383, 0.9367211290054905, 0.9003377898479122, 0.9741100184358661, 0.9327165366784371, 0.9321450396214885, 0.3424326882438825, 0.5895116634185629, 0.9359502896767209, 0.9095363264255969, 0.9526530878317695, 0.9954780344896524, 0.7514756647380343, 0.8817486709284064, 0.7539975482076088, 0.9367762748167834, 0.8881738930976871, 0.9504594298542121, 0.2396001437646299, 0.49587599091240564]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-1-MA_BBOB-3", "seed": 3}
{"method_name": "LLaMEA-2", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-2", "budget": 100, "kwargs": {"mutation_prompts": ["Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false, "eval_timeout": 60}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "cda08a6d-adea-4430-b67f-76352ae7ae81", "fitness": 0.7194469803443957, "name": "MirroredSamplingDE", "description": "A differential evolution strategy that uses a mirrored sampling technique to enhance exploration and exploitation around the best-so-far solution.", "code": "import numpy as np\n\nclass MirroredSamplingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mirror_rate=0.2, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mirror_rate = mirror_rate\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = self.population[i]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Mirrored Sampling\n                if np.random.rand() < self.mirror_rate:\n                    mirror_point = self.x_opt + np.random.normal(0, 0.1, self.dim)  # Sample around best solution\n                    mirror_point = np.clip(mirror_point, func.bounds.lb, func.bounds.ub)\n                    mutant = 0.5 * (mutant + mirror_point) # Combine with the mutant\n\n                # Crossover\n                crossover = np.random.uniform(size=self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    self.population[i] = trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm MirroredSamplingDE scored 0.719 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f0e55a70-292c-4a08-9a4f-8e6cd533fba8"], "operator": null, "metadata": {"aucs": [0.3244130087154825, 0.7479067383661102, 0.6933989186812615, 0.938253691664686, 0.7604096405475839, 0.8084466221868382, 0.656963863161068, 0.6375883607643273, 0.7785356773632128, 0.6480371994559223, 0.9125399198849633, 0.9923678946821141, 0.5941806014173163, 0.7591061065855604, 0.9426984561770838, 0.7840647178553957, 0.5710006828689762, 0.8848397638514371, 0.2529712330778745, 0.7012165095807006]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-2-MA_BBOB-0", "seed": 0}
{"method_name": "LLaMEA-2", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-2", "budget": 100, "kwargs": {"mutation_prompts": ["Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false, "eval_timeout": 60}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "b506287c-816e-41a8-bcbb-422cb8c10696", "fitness": 0.7568001680255396, "name": "MultiStrategyAdaptiveDE", "description": "An adaptive differential evolution strategy that uses a combination of multiple mutation strategies with probabilistic selection and dynamically adjusts parameters based on the success rate of different mutation operators.", "code": "import numpy as np\n\nclass MultiStrategyAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR  # Initial crossover rate\n        self.mutation_strategies = [self.mutation_strategy_1, self.mutation_strategy_2, self.mutation_strategy_3]\n        self.mutation_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)  # Initial probabilities for each strategy\n        self.success_counts = np.zeros(len(self.mutation_strategies))\n        self.strategy_usage = np.zeros(len(self.mutation_strategies))\n        self.learning_rate = 0.1\n\n\n    def mutation_strategy_1(self, population, i):\n        # DE/rand/1\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = population[indices]\n        return population[i] + self.F * (x_r1 - population[i]) + self.F * (x_r2 - x_r3)\n\n    def mutation_strategy_2(self, population, i):\n        # DE/current-to-rand/1\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = population[indices]\n        return population[i] + self.F * (x_r1 - population[i]) + self.F * (x_r2 - x_r3)\n\n    def mutation_strategy_3(self, population, i, best_x):\n         # DE/best/1\n        indices = np.random.choice(self.pop_size, 2, replace=False)\n        x_r1, x_r2 = population[indices]\n        return best_x + self.F * (x_r1 - x_r2)\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        best_x = self.x_opt.copy()\n\n        # Evolution loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Strategy selection\n                strategy_index = np.random.choice(len(self.mutation_strategies), p=self.mutation_probs)\n                self.strategy_usage[strategy_index] += 1\n                mutation_strategy = self.mutation_strategies[strategy_index]\n                \n                # Mutation\n                if mutation_strategy == self.mutation_strategy_3:\n                    v = mutation_strategy(population, i, best_x)\n                else:\n                    v = mutation_strategy(population, i)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                # Evaluation\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < fitness[i]:\n                    # Replacement\n                    fitness[i] = f_u\n                    population[i] = u\n\n                    # Update best solution\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u.copy()\n                        best_x = self.x_opt.copy()\n\n                    self.success_counts[strategy_index] += 1\n\n            # Update mutation probabilities\n            total_usage = np.sum(self.strategy_usage)\n            if total_usage > 0:\n                success_rates = self.success_counts / self.strategy_usage\n                for k in range(len(self.mutation_strategies)):\n                    self.mutation_probs[k] += self.learning_rate * (success_rates[k] - self.mutation_probs[k])\n                self.mutation_probs = np.maximum(self.mutation_probs, 0.01)  # Avoid zero probabilities\n                self.mutation_probs /= np.sum(self.mutation_probs)\n\n            self.success_counts[:] = 0\n            self.strategy_usage[:] = 0\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm MultiStrategyAdaptiveDE scored 0.757 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["15d46a40-bd89-473b-946f-484189b9f23e"], "operator": null, "metadata": {"aucs": [0.4752413375593374, 0.23384758964025754, 0.8076481052676519, 0.9153032063527071, 0.8581176588473404, 0.8904551569991683, 0.7670786515396602, 0.8128640886716194, 0.8504478107552234, 0.7728229827043895, 0.9117602113000752, 0.9926254001148997, 0.6091316453193878, 0.8530449394741241, 0.9392879011651594, 0.8777366632439746, 0.7423571803758638, 0.9088510594808693, 0.4078975813942909, 0.5094841903047922]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-2-MA_BBOB-1", "seed": 1}
{"method_name": "LLaMEA-2", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-2", "budget": 100, "kwargs": {"mutation_prompts": ["Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false, "eval_timeout": 60}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "cc204f72-c903-4864-96a0-b3db90b891ed", "fitness": 0.7938416120219675, "name": "AdaptiveDEArchiveLocalSearch", "description": "An improved adaptive Differential Evolution algorithm featuring a diversity maintenance mechanism using an archive of past solutions and a self-adaptive local search intensity.", "code": "import numpy as np\n\nclass AdaptiveDEArchiveLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, archive_size=10, local_search_prob=0.1, local_search_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.archive_size = archive_size\n        self.local_search_prob = local_search_prob\n        self.local_search_decay = local_search_decay # Decay rate for local search probability\n        self.mutation_strategies = [self._mutation_rand1, self._mutation_current_to_best_1, self._mutation_best1, self._mutation_rand_archive]\n        self.success_counts = [1] * len(self.mutation_strategies)\n        self.total_counts = [1] * len(self.mutation_strategies)\n        self.epsilon = 1e-6\n        self.archive = []\n        self.archive_fitness = []\n        self.archive_full = False\n\n\n    def _mutation_rand1(self, population, best_idx):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        return population[idxs[0]] + self.F * (population[idxs[1]] - population[idxs[2]])\n\n    def _mutation_current_to_best_1(self, population, best_idx, i):\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        return population[i] + self.F * (population[best_idx] - population[i]) + self.F * (population[idxs[0]] - population[idxs[1]])\n\n    def _mutation_best1(self, population, best_idx):\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        return population[best_idx] + self.F * (population[idxs[0]] - population[idxs[1]])\n\n    def _mutation_rand_archive(self, population):\n        if not self.archive:  # Ensure archive is not empty\n            return self._mutation_rand1(population, np.random.randint(self.pop_size))\n        \n        idx1 = np.random.choice(self.pop_size, 1, replace=False)[0]\n        idx_archive = np.random.choice(len(self.archive), 1, replace=False)[0]\n        idxs = np.random.choice(self.pop_size, 1, replace=False)[0]  # choosing only one index\n        return population[idx1] + self.F * (self.archive[idx_archive] - population[idxs])\n\n\n    def _local_search(self, x, func):\n        # Simple random walk local search\n        step_size = 0.1 * (func.bounds.ub - func.bounds.lb)\n        new_x = x + np.random.uniform(-step_size, step_size, size=self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        used_budget = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        \n        while used_budget < self.budget:\n            for i in range(self.pop_size):\n                # Adaptive mutation strategy selection\n                probabilities = np.array(self.success_counts) / np.array(self.total_counts)\n                probabilities /= np.sum(probabilities)\n                mutation_idx = np.random.choice(len(self.mutation_strategies), p=probabilities)\n                \n                if mutation_idx == 0:\n                    mutant = self._mutation_rand1(population, best_idx)\n                elif mutation_idx == 1:\n                    mutant = self._mutation_current_to_best_1(population, best_idx, i)\n                elif mutation_idx == 2:\n                    mutant = self._mutation_best1(population, best_idx)\n                else:\n                    mutant = self._mutation_rand_archive(population)\n                    \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial_vector = self._local_search(trial_vector, func)\n                    self.local_search_prob *= self.local_search_decay # Reduce local search intensity\n                \n                # Evaluation\n                f = func(trial_vector)\n                used_budget += 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    self.success_counts[mutation_idx] += 1\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n\n                    # Update archive\n                    if self.archive_full:\n                        if f < np.max(self.archive_fitness):\n                            worst_idx = np.argmax(self.archive_fitness)\n                            self.archive[worst_idx] = trial_vector\n                            self.archive_fitness[worst_idx] = f\n                    else:\n                        self.archive.append(trial_vector)\n                        self.archive_fitness.append(f)\n                        if len(self.archive) == self.archive_size:\n                            self.archive_full = True\n                \n                self.total_counts[mutation_idx] += 1\n            \n            best_idx = np.argmin(fitness)\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDEArchiveLocalSearch scored 0.794 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a86dc02-d5a6-4e45-9f38-1366ac69ed87"], "operator": null, "metadata": {"aucs": [0.6166584993218962, 0.869640622798669, 0.8550287914701845, 0.9238926460484338, 0.8793026372479534, 0.8835149185226009, 0.8074845052376618, 0.8356082219690585, 0.873779482189317, 0.849222237960959, 0.9260206041381563, 0.9989001238868584, 0.3756814081415172, 0.8694479161961688, 0.9552173147731207, 0.8801135049557453, 0.8270556753744704, 0.9176548763390975, 0.2262147834792061, 0.5063934703882735]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-2-MA_BBOB-2", "seed": 2}
{"method_name": "LLaMEA-2", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-2", "budget": 100, "kwargs": {"mutation_prompts": ["Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false, "eval_timeout": 60}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "691dd35d-22e9-4082-9d25-db1c22ae8480", "fitness": 0.773982447881189, "name": "AdaptiveDEArchive", "description": "An adaptive Differential Evolution strategy with a modified mutation operator utilizing both population-best and archive information to enhance exploration and exploitation, coupled with a dynamic adaptation of crossover rate.", "code": "import numpy as np\n\nclass AdaptiveDEArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=20, CR_init=0.5, F=0.5, CR_adapt_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.CR = CR_init\n        self.F = F\n        self.CR_adapt_rate = CR_adapt_rate\n        self.population = None\n        self.fitness = None\n        self.archive = []\n        self.archive_fitness = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def update_archive(self):\n        \"\"\"Update the archive with diverse and promising solutions.\"\"\"\n        for i in range(self.pop_size):\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i])\n                self.archive_fitness.append(self.fitness[i])\n            else:\n                worst_archive_index = np.argmax(self.archive_fitness)\n                if self.fitness[i] < self.archive_fitness[worst_archive_index]:\n                    self.archive[worst_archive_index] = self.population[i]\n                    self.archive_fitness[worst_archive_index] = self.fitness[i]\n\n    def mutate(self, x_i, best_x):\n        \"\"\"Modified mutation operator using population best and archive.\"\"\"\n        indices = np.random.choice(self.pop_size, size=2, replace=False)\n        x_r1 = self.population[indices[0]]\n        x_r2 = self.population[indices[1]]\n\n        if len(self.archive) > 0:\n            archive_index = np.random.randint(len(self.archive))\n            x_r3 = self.archive[archive_index]\n            v_i = x_i + self.F * (best_x - x_i) + self.F * (x_r1 - x_r2) + self.F * (x_r3 - x_i)\n        else:\n             v_i = x_i + self.F * (best_x - x_i) + self.F * (x_r1 - x_r2)\n\n        return v_i\n\n    def crossover(self, x_i, v_i):\n        \"\"\"Adaptive Crossover.\"\"\"\n        u_i = np.copy(x_i)\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() <= self.CR or j == j_rand:\n                u_i[j] = v_i[j]\n        return u_i\n\n    def repair(self, x, func):\n        return np.clip(x, func.bounds.lb, func.bounds.ub)\n\n    def adjust_crossover_rate(self):\n        \"\"\"Adjust CR based on the success rate of previous generations.\"\"\"\n        self.CR = np.clip(self.CR + self.CR_adapt_rate * (np.random.rand() - 0.5), 0.1, 0.9)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            best_index = np.argmin(self.fitness)\n            best_x = self.population[best_index]\n\n            self.adjust_crossover_rate()\n\n            for i in range(self.pop_size):\n                # Mutation\n                v_i = self.mutate(self.population[i], best_x)\n\n                # Crossover\n                u_i = self.crossover(self.population[i], v_i)\n\n                # Repair\n                u_i = self.repair(u_i, func)\n\n                # Selection\n                f_u_i = func(u_i)\n                self.budget -= 1\n\n                if f_u_i < self.fitness[i]:\n                    self.population[i] = u_i\n                    self.fitness[i] = f_u_i\n\n                    if f_u_i < self.f_opt:\n                        self.f_opt = f_u_i\n                        self.x_opt = u_i\n\n            self.update_archive()\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDEArchive scored 0.774 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5bc8ca0b-b981-465d-b471-65a7ddd94c89"], "operator": null, "metadata": {"aucs": [0.4424617400872527, 0.6842842052789162, 0.8400410199912165, 0.9483117270055592, 0.7559583467240213, 0.8875782042465254, 0.7979027288957256, 0.8244529032024674, 0.8855989926322653, 0.8568095609755758, 0.9069460558565039, 0.9964270515850396, 0.4914611139086802, 0.8572096309228918, 0.9242186867591958, 0.8960548315575139, 0.7690289145801243, 0.9181349925833668, 0.271048406756599, 0.5257198440743407]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-2-MA_BBOB-3", "seed": 3}
{"method_name": "LLaMEA-2", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-2", "budget": 100, "kwargs": {"mutation_prompts": ["Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false, "eval_timeout": 60}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "e6f27bc4-098e-496a-9c03-f1890a407edb", "fitness": 0.7132677563121383, "name": "AdaptiveDE", "description": "An adaptive differential evolution strategy that adjusts its parameters based on the function evaluations and maintains a diverse population.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index].copy()\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.population[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = x_trial\n                self.fitness[i] = f_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n            # Adaptive parameter adjustment\n            if self.eval_count % (self.budget // 10) == 0:  # Adjust every 10% of budget\n                self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)\n\n            if self.eval_count >= self.budget:\n                break\n                \n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.713 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.45258581579555035, 0.6761640663906656, 0.6789647808678401, 0.8659454379407654, 0.7224857697069544, 0.7994429681722723, 0.5887905844987715, 0.6431034348124101, 0.7429008554386459, 0.7009195347291302, 0.8589655817221933, 0.998917964381844, 0.5067156915059832, 0.7640805233942942, 0.9312525175072195, 0.7849221708524158, 0.5499467540114216, 0.8403210247825007, 0.544255440617992, 0.6146742091138974]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-2-MA_BBOB-4", "seed": 4}
{"method_name": "LLaMEA-3", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-3", "budget": 100, "kwargs": {"mutation_prompts": ["Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "b9b36023-05f0-44d3-addb-ba9a53a63120", "fitness": 0.7526635015701337, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and probabilistic re-initialization based on stagnation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1, stagnation_threshold=10, reinit_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n        self.stagnation_threshold = stagnation_threshold\n        self.reinit_prob = reinit_prob  # Probability of re-initialization\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.stagnation_counter = np.zeros(self.pop_size)\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Simple bound handling\n                u = np.clip(u, self.lb, self.ub)\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr using leaky integration\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.9\n                    self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * 0.9\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    self.stagnation_counter[i] = 0\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Adapt F and Cr when the trial vector is not better\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.1\n                    self.stagnation_counter[i] += 1\n\n                # Probabilistic Re-initialization\n                if self.stagnation_counter[i] > self.stagnation_threshold:\n                    if np.random.rand() < self.reinit_prob:\n                        self.pop[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                        self.fitness[i] = func(self.pop[i])\n                        self.evals += 1\n                        self.stagnation_counter[i] = 0\n                        if self.fitness[i] < self.f_opt:\n                            self.f_opt = self.fitness[i]\n                            self.x_opt = self.pop[i]\n                    else:\n                        self.stagnation_counter[i] = 0  # Reset even if not re-initialized\n                \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.753 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d5de8052-60c5-434e-8051-f4db43b6b415"], "operator": null, "metadata": {"aucs": [0.46758447607219655, 0.7529625664449676, 0.5966918953448006, 0.882915241513335, 0.7854722475795409, 0.8081892118302993, 0.7282410977231446, 0.7284211887509984, 0.7765587417170702, 0.7628445484248674, 0.8691914275345431, 0.9900550774584597, 0.5988265512234958, 0.786709753150314, 0.9153218890475904, 0.792651066230356, 0.7186467173686275, 0.8674199698122602, 0.7038410848890699, 0.5207252792867361]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-3-MA_BBOB-0", "seed": 0}
{"method_name": "LLaMEA-3", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-3", "budget": 100, "kwargs": {"mutation_prompts": ["Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "dbef4cbe-a47a-4a4a-bbfb-fbece2e0948e", "fitness": 0.8057121074271896, "name": "AdaptiveDE", "description": "Simplified Differential Evolution with reduced memory footprint, focused exploration, and adaptive bounds handling for efficiency.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=4, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget, dim * pop_factor)\n        self.CR = CR\n        self.F = 0.5  # Fixed F for simplicity\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                \n                # Simplified mutation\n                v = x_r1 + self.F * (x_r2 - x_r3)\n\n                # Adaptive bounds handling\n                v = np.where(v < func.bounds.lb, 2 * func.bounds.lb - v, v)\n                v = np.where(v > func.bounds.ub, 2 * func.bounds.ub - v, v)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u = population[i].copy()\n                mask = np.random.rand(self.dim) < self.CR\n                mask[j_rand] = True\n                u[mask] = v[mask]\n\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < fitness[i]:\n                    population[i] = u\n                    fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u.copy()\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.806 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c240275d-8ab1-4e2c-8451-774c1bd0cd55"], "operator": null, "metadata": {"aucs": [0.3853117135119376, 0.6710827040259603, 0.8583445673308748, 0.9218506899011232, 0.9000352955370547, 0.9001386932356925, 0.8066349366334192, 0.8428456481130434, 0.8725257691992097, 0.8487218547616723, 0.9090610291161072, 0.9962384607102368, 0.46562000951077676, 0.8799960085295784, 0.9446373574045911, 0.8972227366816694, 0.8038058782482929, 0.929537392126919, 0.7402544454191997, 0.5403769585464313]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-3-MA_BBOB-1", "seed": 1}
{"method_name": "LLaMEA-3", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-3", "budget": 100, "kwargs": {"mutation_prompts": ["Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "d3da3f1c-5bff-46ea-bd21-34a0d59891f8", "fitness": 0.809928395436479, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with jitter-based mutation and adaptive F/CR parameters promoting diversity and convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=25, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_F = np.ones(archive_size) * 0.5\n        self.memory_CR = np.ones(archive_size) * 0.9\n        self.p = 0.1\n        self.archive = []\n        self.success_count = 0\n    \n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history\n                ind = np.random.randint(0, self.archive_size)\n                F = self.memory_F[ind]\n                CR = self.memory_CR[ind]\n\n                # Mutation with jitter\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                # Adding jitter to F to increase diversity\n                F_jitter = F + 0.05 * np.random.normal(0, 1)\n                F_jitter = np.clip(F_jitter, 0.1, 1.0)  # Clip jittered F\n                v = x1 + F_jitter * (x2 - x3)\n\n                # Crossover\n                u = np.where(np.random.rand(self.dim) < CR, v, self.population[i])\n\n                # Repair: Clip to bounds\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.budget -= 1\n                if f_u < self.fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    self.population[i] = u\n                    self.fitness[i] = f_u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                    # Update F and CR memory - Simplified update\n                    self.memory_F[ind] = F  # Store the original F value\n                    self.memory_CR[ind] = CR\n\n                if self.budget <= 0:\n                    break\n\n            # Adapt F and CR - Simplified adaptation, less aggressive\n            success_indices = self.fitness < np.mean(self.fitness)\n            if np.any(success_indices):\n                F_mean = np.mean(self.memory_F[np.random.choice(self.archive_size, size=min(self.archive_size,sum(success_indices)), replace=False)]) #using only successful F\n                CR_mean = np.mean(self.memory_CR[np.random.choice(self.archive_size, size=min(self.archive_size,sum(success_indices)), replace=False)]) #using only successful CR\n\n                self.memory_F = 0.8 * self.memory_F + 0.2*F_mean\n                self.memory_CR = 0.8 * self.memory_CR + 0.2*CR_mean\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.810 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2c58b301-0344-4144-952d-3633b6409803"], "operator": null, "metadata": {"aucs": [0.5370269069214824, 0.8467479617085486, 0.4860831086774444, 0.9225278128486885, 0.8739406344036356, 0.9009175214000955, 0.810377017367675, 0.8229621177978368, 0.8724019445574098, 0.8631484927735478, 0.9259068129784389, 0.9914441298248073, 0.8064855501456573, 0.8618762962309606, 0.8105209303007351, 0.8745386486891914, 0.813528922534341, 0.9022687898712366, 0.7729351676149658, 0.5029291420828802]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-3-MA_BBOB-2", "seed": 2}
{"method_name": "LLaMEA-3", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-3", "budget": 100, "kwargs": {"mutation_prompts": ["Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "466b481c-ca88-4f0b-b74c-b18b160e02cf", "fitness": 0.8033986365348935, "name": "AdaptiveHybridPSO_DE", "description": "Adaptively adjusts PSO and DE parameters based on population diversity, focusing on exploration when diversity is high and exploitation when low.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE optimizer with population diversity-based parameter adaptation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.global_best_pos = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.best_pos = self.pop.copy()\n        self.best_fitness = np.array([np.inf] * self.pop_size)\n\n    def evaluate_population(self, func):\n        \"\"\"Evaluates population fitness and updates best positions.\"\"\"\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                self.fitness[i] = f\n                if f < self.best_fitness[i]:\n                    self.best_fitness[i] = f\n                    self.best_pos[i] = self.pop[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n    \n    def calculate_diversity(self):\n        \"\"\"Calculates population diversity based on distance from centroid.\"\"\"\n        centroid = np.mean(self.pop, axis=0)\n        distances = np.linalg.norm(self.pop - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n\n    def update_positions(self, func):\n        \"\"\"Updates particle positions using adaptive PSO and DE.\"\"\"\n        diversity = self.calculate_diversity()\n        normalized_diversity = diversity / (func.bounds.ub[0] - func.bounds.lb[0]) # Assuming same bounds for all dims\n\n        # Adapt PSO parameters based on diversity\n        w = self.w_start - (self.w_start - self.w_end) * (1 - normalized_diversity)  # Higher diversity, higher inertia\n        c1 = 1.5 + 0.5 * (1 - normalized_diversity) # Higher diversity, lower cognitive\n        c2 = 1.5 + 0.5 * (1 - normalized_diversity) # Higher diversity, lower social\n\n\n        for i in range(self.pop_size):\n            # PSO update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = w * (self.pop[i] - self.best_pos[i]) + self.c1 * r1 * (self.best_pos[i] - self.pop[i]) + self.c2 * r2 * (self.global_best_pos - self.pop[i])\n            new_pos = self.pop[i] + velocity\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n            # DE update\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            trial = new_pos.copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    trial[j] = mutant[j]\n\n            # Evaluate and update\n            if self.eval_count < self.budget:\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.best_fitness[i]:\n                        self.best_fitness[i] = f_trial\n                        self.best_pos[i] = self.pop[i].copy()\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_pos = self.pop[i].copy()\n            else:\n                break\n\n    def __call__(self, func):\n        \"\"\"Optimizes the function.\"\"\"\n        self.initialize_population(func)\n        self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_positions(func)\n\n        return self.global_best_fitness, self.global_best_pos", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.803 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a4579e28-5bce-4838-b7bf-867285f0c3f0"], "operator": null, "metadata": {"aucs": [0.2635082195957982, 0.8425829519286955, 0.9153782452082764, 0.9667359883766905, 0.9302623988253166, 0.9289466078540707, 0.8863389900600951, 0.9068062782068194, 0.9288974244645372, 0.9068809145714488, 0.9558769113183005, 0.9951264375121531, 0.3037822193831916, 0.8648504416315114, 0.952701852897866, 0.9401434643250576, 0.8952163224078789, 0.9565655054969251, 0.23409890346396256, 0.49327265316927305]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-3-MA_BBOB-3", "seed": 3}
{"method_name": "LLaMEA-3", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-3", "budget": 100, "kwargs": {"mutation_prompts": ["Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "6c928a56-d2ab-4953-9e91-4c7eaf18e59d", "fitness": 0.8100056913544973, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with reduced parameter tuning and a focus on population diversity to enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: DE/rand/1 - Simplified with dynamic F\n                F = np.random.uniform(0.2, 0.8)  # Dynamic F\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                mutant = x_r1 + F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover - Simplified with dynamic CR\n                CR = np.random.uniform(0.5, 1.0)  # Dynamic CR\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.810 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["99a712d5-334b-4ab7-bd14-97d6f0dae033"], "operator": null, "metadata": {"aucs": [0.36644609282881524, 0.8505306024902094, 0.8080623475272763, 0.9214542024129286, 0.8839995505460734, 0.9015514336075455, 0.8398281216821889, 0.8174645513443474, 0.8772687283386124, 0.8452101723283241, 0.9205805732089554, 0.991171688129026, 0.5297420833339388, 0.8797180894386616, 0.8458013608511785, 0.8905037382038181, 0.8076409038481986, 0.930239977495973, 0.8036850924965936, 0.4892145169772808]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-3-MA_BBOB-4", "seed": 4}
{"method_name": "LLaMEA-4", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-4", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "b4bffed7-cd5a-488e-801a-b2ca9d619c83", "fitness": 0.6009358184906194, "name": "CooperativeSwarm", "description": "Cooperative Swarm Optimization with dynamic sub-component assignment and adaptive velocity clamping.", "code": "import numpy as np\n\nclass CooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=None, w=0.7, c1=1.5, c2=1.5, v_max_ratio=0.2):\n        \"\"\"\n        Cooperative Swarm Optimization with dynamic sub-component assignment and adaptive velocity clamping.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimension of the problem.\n            num_swarms (int): Number of sub-swarms.\n            swarm_size (int, optional): The size of each swarm. Defaults to 10*dim/num_swarms.\n            w (float): Inertia weight.\n            c1 (float): Cognitive coefficient.\n            c2 (float): Social coefficient.\n            v_max_ratio (float): Ratio of search space to define maximum velocity.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size if swarm_size is not None else int(10 * dim / num_swarms)\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.lb = -5.0\n        self.ub = 5.0\n        self.v_max = v_max_ratio * (self.ub - self.lb)\n        self.eval_count = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        self.swarms_pos = [np.random.uniform(self.lb, self.ub, size=(self.swarm_size, dim)) for _ in range(num_swarms)]\n        self.swarms_vel = [np.random.uniform(-self.v_max, self.v_max, size=(self.swarm_size, dim)) for _ in range(num_swarms)]\n        self.swarms_best_pos = [np.copy(swarm_pos) for swarm_pos in self.swarms_pos]\n        self.swarms_best_fitness = [np.full(self.swarm_size, np.inf) for _ in range(num_swarms)]\n\n        self.global_best_pos = np.zeros(dim)\n        self.global_best_fitness = np.inf\n        self.component_assignment = self.assign_components()\n\n    def assign_components(self):\n        \"\"\"Assign dimensions to swarms in a cooperative manner.\"\"\"\n        components_per_swarm = self.dim // self.num_swarms\n        remaining_components = self.dim % self.num_swarms\n        assignment = []\n        start = 0\n        for i in range(self.num_swarms):\n            num_components = components_per_swarm + (1 if i < remaining_components else 0)\n            assignment.append(list(range(start, start + num_components)))\n            start += num_components\n        return assignment\n    \n    def evaluate_swarm(self, func, swarm_index):\n        \"\"\"Evaluate the fitness of each particle in a swarm.\"\"\"\n        for i in range(self.swarm_size):\n            x = self.swarms_pos[swarm_index][i]\n            f = func(x)\n            self.eval_count += 1\n\n            if f < self.swarms_best_fitness[swarm_index][i]:\n                self.swarms_best_fitness[swarm_index][i] = f\n                self.swarms_best_pos[swarm_index][i] = np.copy(x)\n\n            if f < self.global_best_fitness:\n                self.global_best_fitness = f\n                self.global_best_pos = np.copy(x)\n                self.f_opt = f\n                self.x_opt = x\n\n\n    def update_velocity(self, swarm_index):\n        \"\"\"Update the velocity of each particle in a swarm.\"\"\"\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n\n            cognitive_component = self.c1 * r1 * (self.swarms_best_pos[swarm_index][i] - self.swarms_pos[swarm_index][i])\n            social_component = self.c2 * r2 * (self.global_best_pos - self.swarms_pos[swarm_index][i])\n\n            self.swarms_vel[swarm_index][i] = self.w * self.swarms_vel[swarm_index][i] + cognitive_component + social_component\n\n            # Adaptive velocity clamping\n            v_max_adaptive = self.v_max * (1 - self.eval_count / self.budget)  # Reduce v_max over time\n\n            self.swarms_vel[swarm_index][i] = np.clip(self.swarms_vel[swarm_index][i], -v_max_adaptive, v_max_adaptive)\n\n\n    def update_position(self, swarm_index):\n        \"\"\"Update the position of each particle in a swarm.\"\"\"\n        self.swarms_pos[swarm_index] = self.swarms_pos[swarm_index] + self.swarms_vel[swarm_index]\n        self.swarms_pos[swarm_index] = np.clip(self.swarms_pos[swarm_index], self.lb, self.ub)\n    \n\n    def __call__(self, func):\n        \"\"\"Optimize the given function.\"\"\"\n        self.eval_count = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        while self.eval_count < self.budget:\n            for swarm_index in range(self.num_swarms):\n                self.update_velocity(swarm_index)\n                self.update_position(swarm_index)\n                self.evaluate_swarm(func, swarm_index)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm CooperativeSwarm scored 0.601 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["abbf79c0-f10c-496a-9c2c-d5eaff3183f1"], "operator": null, "metadata": {"aucs": [0.2731121000890224, 0.46819057014243104, 0.7282808162495181, 0.9156287475028951, 0.7597201038798624, 0.8178551613852515, 0.32985339060874364, 0.6442620047021215, 0.7624944683598638, 0.214223682776993, 0.898483414300026, 0.9936465289789266, 0.2531981431897521, 0.3047962056650002, 0.8491067829739942, 0.8150612775313935, 0.36916222546834876, 0.8531370821598709, 0.24906450544642278, 0.5194391584019509]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-4-MA_BBOB-0", "seed": 0}
{"method_name": "LLaMEA-4", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-4", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "2eb69273-6965-4076-a108-7c35adbe5e33", "fitness": 0.7060683363192007, "name": "EnhancedCooperativePSO", "description": "Cooperative PSO with a self-adaptive velocity scaling factor and a dynamic, stagnation-aware mutation strategy utilizing Lvy flights for enhanced exploration.", "code": "import numpy as np\n\nclass EnhancedCooperativePSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, initial_neighborhood_size=3, c1=1.49445, c2=1.49445, v_max_factor=0.2, stagnation_threshold=1000, mutation_rate=0.1, levy_flight_exponent=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.initial_neighborhood_size = initial_neighborhood_size\n        self.c1 = c1\n        self.c2 = c2\n        self.v_max_factor = v_max_factor\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.mutation_rate = mutation_rate\n        self.levy_flight_exponent = levy_flight_exponent\n\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.function_calls = 0\n\n        self.neighborhood_size = initial_neighborhood_size  # Dynamic neighborhood size\n        self.adaptive_v_max_factor = v_max_factor #initial v_max_factor\n\n\n    def initialize(self, func):\n        self.particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-self.v_max_factor * (func.bounds.ub - func.bounds.lb), self.v_max_factor * (func.bounds.ub - func.bounds.lb), size=(self.swarm_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = np.full(self.swarm_size, np.inf)\n\n        for i in range(self.swarm_size):\n            fitness = func(self.particles[i])\n            self.function_calls += 1\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best_positions[i] = self.particles[i].copy()\n\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best_position = self.particles[i].copy()\n        self.best_fitness_history.append(self.global_best_fitness)\n\n    def update_velocity(self, particle_index, inertia_weight, func):\n        # Dynamic Neighborhood Topology: Adjust neighborhood size based on stagnation\n        neighborhood_indices = np.random.choice(self.swarm_size, min(self.neighborhood_size, self.swarm_size), replace=False)\n        neighborhood_best_index = neighborhood_indices[np.argmin(self.personal_best_fitness[neighborhood_indices])]\n\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n\n        cognitive_component = self.c1 * r1 * (self.personal_best_positions[particle_index] - self.particles[particle_index])\n        social_component = self.c2 * r2 * (self.personal_best_positions[neighborhood_best_index] - self.particles[particle_index])\n\n        self.velocities[particle_index] = inertia_weight * self.velocities[particle_index] + cognitive_component + social_component\n\n        # Velocity Clamping with Adaptive Scaling: Scale the maximum velocity based on the current global best fitness\n        v_max = self.adaptive_v_max_factor * (func.bounds.ub - func.bounds.lb) \n        self.velocities[particle_index] = np.clip(self.velocities[particle_index], -v_max, v_max)\n\n    def update_position(self, particle_index, func):\n        self.particles[particle_index] = self.particles[particle_index] + self.velocities[particle_index]\n        \n        # Boundary Handling (Clip)\n        self.particles[particle_index] = np.clip(self.particles[particle_index], func.bounds.lb, func.bounds.ub)\n\n    def levy_flight(self, beta):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / (np.abs(v) ** (1 / beta))\n        return step\n\n    def mutate_particle(self, particle_index, func):\n        #Apply levy flight\n        levy_steps = self.levy_flight(self.levy_flight_exponent)\n        self.particles[particle_index] += self.mutation_rate * levy_steps * (func.bounds.ub - func.bounds.lb)\n        self.particles[particle_index] = np.clip(self.particles[particle_index], func.bounds.lb, func.bounds.ub)\n\n\n    def __call__(self, func):\n        self.initialize(func)\n        inertia_weight = 0.9  # Initial inertia weight\n        inertia_decay = 0.995 # Decay factor for inertia weight\n        \n        adaptive_c1 = self.c1\n        adaptive_c2 = self.c2\n\n        while self.function_calls < self.budget:\n            inertia_weight *= inertia_decay\n            inertia_weight = max(0.4, inertia_weight) # Ensure inertia weight does not become too small\n\n            # Adaptive parameter control (example: adjusting c1 and c2 based on stagnation)\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                if np.abs(self.best_fitness_history[-1] - self.best_fitness_history[-self.stagnation_threshold]) < 1e-6:  #Stagnation detected\n                    adaptive_c1 = min(self.c1 + 0.1, 2.0)  # Increase exploration\n                    adaptive_c2 = max(self.c2 - 0.1, 1.0)  # Reduce exploitation\n                    self.stagnation_counter +=1\n\n                    # Increase neighborhood size during stagnation to promote exploration\n                    self.neighborhood_size = min(self.neighborhood_size + 1, self.swarm_size)\n\n                    #Apply mutation to a subset of particles with adaptive mutation rate\n                    num_mutations = max(1, self.swarm_size // 5) #Ensure at least one mutation\n                    mutation_indices = np.random.choice(self.swarm_size, num_mutations, replace=False)\n\n                    for particle_index in mutation_indices:\n                        self.mutate_particle(particle_index,func)\n                    self.mutation_rate = min(self.mutation_rate + 0.01, 0.5) # increase mutation rate\n                    self.adaptive_v_max_factor = min(self.adaptive_v_max_factor * 1.1, 0.5) #Increase exploration\n\n                else:\n                    adaptive_c1 = self.c1 # Restore original values\n                    adaptive_c2 = self.c2\n                    self.stagnation_counter = 0\n                    self.neighborhood_size = self.initial_neighborhood_size  # Reset neighborhood size\n                    self.mutation_rate = 0.1 # reset mutation rate\n                    self.adaptive_v_max_factor = self.v_max_factor #Reset exploration\n\n            for i in range(self.swarm_size):\n                self.update_velocity(i, inertia_weight, func)\n                self.update_position(i, func)\n\n                fitness = func(self.particles[i])\n                self.function_calls += 1\n\n                if fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = fitness\n                    self.personal_best_positions[i] = self.particles[i].copy()\n\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = self.particles[i].copy()\n                \n                if self.function_calls >= self.budget:\n                    break\n            self.best_fitness_history.append(self.global_best_fitness)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedCooperativePSO scored 0.706 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0deba200-0a20-49ac-b682-cbf52715fab4"], "operator": null, "metadata": {"aucs": [0.29719744021418293, 0.7710142514463301, 0.8057994382148097, 0.8905005064747705, 0.8187347442381808, 0.8482193869671156, 0.7705974527645958, 0.7920278888464068, 0.8255729506909535, 0.7969168044213221, 0.8392586233649603, 0.9998320086023074, 0.26641348390567277, 0.8096408114905933, 0.7326652290523361, 0.8431743012901959, 0.753961138937445, 0.3786272381447787, 0.3489394507949357, 0.5322735765221234]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-4-MA_BBOB-1", "seed": 1}
{"method_name": "LLaMEA-4", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-4", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "0cbd1d26-c840-4a67-a83c-9634ba3bbc77", "fitness": 0.7970693270508339, "name": "SHADE", "description": "An adaptive differential evolution that uses a success history of mutation factors and crossover rates to guide future parameter choices.", "code": "import numpy as np\n\nclass SHADE:\n    def __init__(self, budget=10000, dim=10, memory_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(4 + 3 * np.log(budget))\n        self.memory_size = memory_size\n        self.memory_F = np.full(memory_size, 0.5)\n        self.memory_CR = np.full(memory_size, 0.5)\n        self.p = 0.1  # Percentage of top individuals for p-best selection\n        self.population = None\n        self.fitness = None\n        self.bounds_lb = None\n        self.bounds_ub = None\n        self.archive = [] # For storing inferior solutions\n        self.archive_size = self.pop_size  # Archive size, can be adjusted\n\n        self.memory_index = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n\n    def mutate(self, pop, i, F, Cr):\n        p_best_size = max(int(self.p * len(pop)), 1)\n        \n        # Tournament selection for p-best\n        indices = np.argsort(self.fitness)[:p_best_size]\n        p_best_idx = np.random.choice(indices)\n        p_best = pop[p_best_idx]\n\n        indices = [idx for idx in range(len(pop)) if idx != i]\n        if len(indices) < 2:\n            return pop[i]  # If only one element, no mutation\n\n        r1, r2 = np.random.choice(indices, 2, replace=False)\n\n        mutant = p_best + F * (pop[r1] - pop[r2])\n        return mutant\n\n\n    def crossover(self, mutant, target, Cr):\n        cross_points = np.random.rand(self.dim) < Cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n    \n    def update_archive(self, individual):\n        if len(self.archive) < self.archive_size:\n            self.archive.append(individual)\n        else:\n            idx = np.random.randint(0, self.archive_size)\n            self.archive[idx] = individual\n\n    def __call__(self, func):\n        self.bounds_lb = func.bounds.lb\n        self.bounds_ub = func.bounds.ub\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.initialize_population(func)\n        fevals = self.pop_size\n        \n        successful_F = []\n        successful_CR = []\n        \n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Sample F and CR from memory\n                mem_idx = np.random.randint(0, self.memory_size)\n                F = self.memory_F[mem_idx]\n                Cr = self.memory_CR[mem_idx]\n\n                mutant = self.mutate(self.population, i, F, Cr)\n                mutant = np.clip(mutant, self.bounds_lb, self.bounds_ub)\n                trial = self.crossover(mutant, self.population[i], Cr)\n                \n                f = func(trial)\n                fevals += 1\n\n                if f < self.fitness[i]:\n                    successful_F.append(F)\n                    successful_CR.append(Cr)\n                    \n                    if len(self.archive) < self.archive_size:\n                        self.update_archive(self.population[i])\n                    else:\n                        self.update_archive(self.population[i])\n\n\n                    self.fitness[i] = f\n                    self.population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                else:\n                     self.update_archive(trial)\n\n                if fevals >= self.budget:\n                    break\n            \n            # Update memory\n            if successful_F:\n                self.memory_F[self.memory_index] = np.mean(successful_F)\n                self.memory_CR[self.memory_index] = np.mean(successful_CR)\n                self.memory_index = (self.memory_index + 1) % self.memory_size\n            \n            successful_F = []\n            successful_CR = []\n            \n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm SHADE scored 0.797 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["362496cf-1ef2-41ac-950f-11944911fba6"], "operator": null, "metadata": {"aucs": [0.3358671525649425, 0.8059451112198965, 0.8536873475750335, 0.9228114590598238, 0.8915023839526408, 0.9159132330197748, 0.8600462300512554, 0.8465224953145012, 0.8801292344950892, 0.885328332325349, 0.9226382598209059, 0.9975141095704447, 0.34980353092192906, 0.8569596540570548, 0.7386108712892201, 0.9170211125007397, 0.7956847630131327, 0.9168559627004533, 0.7252988184681611, 0.5232464790963284]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-4-MA_BBOB-2", "seed": 2}
{"method_name": "LLaMEA-4", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-4", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "29150d1b-7cc5-4b01-9681-a4c06a76ffc2", "fitness": 0.7889518938452259, "name": "TrustRegionDE", "description": "Differential Evolution with a simplified adaptation mechanism for F and CR, combined with a focused local search guided by a trust region.", "code": "import numpy as np\n\nclass TrustRegionDE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, F=0.5, CR=0.9, ls_frequency=50, trust_region_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.ls_frequency = ls_frequency\n        self.trust_region_size = trust_region_size\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n    def repair(self, x, lb, ub):\n        return np.clip(x, lb, ub)\n\n    def local_search(self, x, func):\n        \"\"\"Local search within a trust region.\"\"\"\n        lb = np.maximum(x - self.trust_region_size, func.bounds.lb)\n        ub = np.minimum(x + self.trust_region_size, func.bounds.ub)\n        x_new = np.random.uniform(lb, ub)\n        f_new = func(x_new)\n        self.eval_count += 1\n        return f_new, x_new\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            indices = np.random.choice(range(self.pop_size), size=3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[indices]\n            v_i = x_r1 + self.F * (x_r2 - x_r3)\n            v_i = self.repair(v_i, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            u_i = np.copy(self.population[i])\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    u_i[j] = v_i[j]\n\n            u_i = self.repair(u_i, func.bounds.lb, func.bounds.ub)\n\n            # Selection\n            f_u_i = func(u_i)\n            self.eval_count += 1\n\n            if f_u_i < self.fitness[i]:\n                self.population[i] = u_i\n                self.fitness[i] = f_u_i\n                if f_u_i < self.f_opt:\n                    self.f_opt = f_u_i\n                    self.x_opt = u_i\n\n            #Simplified adaptation of F and CR\n            if np.random.rand() < 0.1:\n                self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n            if np.random.rand() < 0.1:\n                self.CR = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)\n\n    def __call__(self, func):\n        self.initialize(func)\n        generation = 0\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            generation += 1\n\n            if generation % self.ls_frequency == 0:\n                f_ls, x_ls = self.local_search(self.x_opt, func)\n                if f_ls < self.f_opt:\n                    self.f_opt = f_ls\n                    self.x_opt = x_ls\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm TrustRegionDE scored 0.789 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5a1dbfdf-0077-4c39-8e3c-56af43f4e2d1"], "operator": null, "metadata": {"aucs": [0.5361216610581353, 0.73144207918222, 0.7923072321246324, 0.9194848732094889, 0.8663107568331295, 0.8588574613325697, 0.7864345154393622, 0.8081795157715643, 0.8346024659310807, 0.8241813003184523, 0.9106913581459816, 0.9851440348557163, 0.8168223342096161, 0.8286084128689694, 0.9495824926389662, 0.884594306132571, 0.7892493848501688, 0.9044634126477629, 0.22681735454977137, 0.5251429248043585]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-4-MA_BBOB-3", "seed": 3}
{"method_name": "LLaMEA-4", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-4", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "5daa2838-e96d-41d5-be4d-bf926efdcb32", "fitness": 0.7011298273698469, "name": "CovarianceMatrixDE", "description": "An adaptive DE that leverages a covariance matrix adaptation strategy for mutation and parameter control inspired by CMA-ES, alongside a local search mechanism and population diversity maintenance.", "code": "import numpy as np\n\nclass CovarianceMatrixDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, memory_size=10, local_search_probability=0.1, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.memory_size = memory_size\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.p = 0.1\n        self.elite_ratio = 0.1\n        self.min_pop_size = 4\n        self.local_search_probability = local_search_probability\n        self.cr_learning_rate = 0.2\n        self.f_learning_rate = 0.2\n        self.initial_step_size = initial_step_size\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for step size\n        self.damps = 1 + (3 * np.log(self.dim)) / np.sqrt(self.dim) # Damping for step size\n        self.cs = 0.3  # Learning rate for step size\n        self.cc = 2 / (self.dim + np.sqrt(2)) # Learning rate for rank-one update of C\n        self.mu_eff = self.pop_size / 4\n        self.weights = np.log(self.pop_size + 1/2) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mu_eff)\n        self.cmu = min(1-self.c1, 2 * (self.mueff-2 + 1/self.mueff) / ((self.dim+2)**2 + self.mueff))\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.evals = self.pop_size\n        self.memory_idx = 0\n        self.success_cr = []\n        self.success_f = []\n        self.step_size = self.initial_step_size\n\n        while self.evals < self.budget:\n            if self.pop_size < self.min_pop_size:\n                self.pop_size = self.min_pop_size\n\n            sorted_indices = np.argsort(self.fitness)\n            elite_indices = sorted_indices[:self.pop_size]\n            xmean = np.sum(self.weights.reshape(-1, 1) * self.population[elite_indices], axis=0)\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                cr_i = np.random.choice(self.memory_cr)\n                f_i = np.random.choice(self.memory_f)\n                f_i = np.clip(f_i, 0.0, 1.0)\n\n                # Mutation using CMA-ES-inspired strategy\n                z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                v = xmean + self.step_size * z\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Local search with probability\n                if np.random.rand() < self.local_search_probability:\n                    step_size_local = 0.01 * (func.bounds.ub - func.bounds.lb)\n                    v = v + np.random.uniform(-step_size_local, step_size_local, size=self.dim)\n                    v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i, j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                delta_f = f_u - self.fitness[i]\n\n                if f_u < self.fitness[i]:\n                    self.success_cr.append(cr_i)\n                    self.success_f.append(f_i)\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n            # Update memory for SHADE\n            if self.success_cr and self.success_f:\n                mean_cr = np.mean(self.success_cr)\n                mean_f = np.mean(self.success_f)\n\n                self.memory_cr[self.memory_idx] = (1 - self.cr_learning_rate) * self.memory_cr[self.memory_idx] + self.cr_learning_rate * mean_cr\n                self.memory_f[self.memory_idx] = (1 - self.f_learning_rate) * self.memory_f[self.memory_idx] + self.f_learning_rate * mean_f\n\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_cr = []\n                self.success_f = []\n\n            # CMA-ES Adaptation\n            z = (self.population[sorted_indices[0]] - xmean) / self.step_size\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * z\n            self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc)) * z\n\n            self.C = (1-self.c1-self.cmu) * self.C + self.c1 * np.outer(self.pc, self.pc)\n            \n            for k in range(self.pop_size):\n                z = (self.population[sorted_indices[k]] - xmean) / self.step_size\n                self.C += self.cmu * self.weights[k] * np.outer(z, z)\n            \n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            self.step_size *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n            \n            # Ensure the covariance matrix is positive definite\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-6 * np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm CovarianceMatrixDE scored 0.701 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["730028f6-1054-4afc-9f9f-5d67771a46ba"], "operator": null, "metadata": {"aucs": [0.2848171237886762, 0.6478553889822936, 0.749093970944678, 0.8890741813808556, 0.8272734075461039, 0.8354517829909887, 0.3652514181137393, 0.7621257124405465, 0.8323621984613849, 0.7657537273667746, 0.8703505836740061, 0.9951735560314477, 0.37197244578901134, 0.8168835166165251, 0.8789279159686434, 0.835625352477571, 0.7074562037157959, 0.8615033792139254, 0.21647231273008816, 0.5091723691638822]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-4-MA_BBOB-4", "seed": 4}
{"method_name": "LLaMEA-5", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-5", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before.", "Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "fc30bdef-184b-4d2d-9553-e8a6973371ba", "fitness": 0.7840518143013481, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with population-based mutation parameter adaptation and a combined repair strategy for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.bounds_lb = -5.0\n        self.bounds_ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_size = archive_size\n        self.memory_F = np.ones(archive_size) * 0.5\n        self.memory_CR = np.ones(archive_size) * 0.9\n        self.memory_idx = 0\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(self.bounds_lb, self.bounds_ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n        \n        best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_idx]\n        self.x_opt = self.pop[best_idx]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter Adaptation: Population-based\n                F = 0.5 + 0.3 * np.random.randn()\n                CR = 0.9 + 0.1 * np.random.randn()\n                F = np.clip(F, 0.1, 1.0)\n                CR = np.clip(CR, 0.1, 1.0)\n                \n                # Mutation Strategy Selection: Combined rand/1 and best/1\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n                if np.random.rand() < 0.5:\n                    mutant = self.pop[i] + F * (self.x_opt - self.pop[i]) + F * (a - b) # best/1\n                else:\n                    mutant = a + F * (b - c) # rand/1\n\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Repair Mechanism: Clipping and Reflection (Combined)\n                trial = np.clip(trial, self.bounds_lb, self.bounds_ub)\n                \n                # Evaluate\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.784 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f20cf4f2-07ab-4b3c-957c-faf40ae695eb"], "operator": null, "metadata": {"aucs": [0.45813004222698406, 0.8091080055347178, 0.8250287654567463, 0.9384798403281649, 0.8473573493989718, 0.8723613992532263, 0.7340006285434255, 0.7801515518230973, 0.860381735143445, 0.764726181982867, 0.9202791492315666, 0.9943422079443693, 0.789568019394719, 0.81405356638209, 0.9584910580366836, 0.863531429267984, 0.7771115076452777, 0.8975548508810861, 0.25125508803932617, 0.5251239095122113]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-5-MA_BBOB-0", "seed": 0}
{"method_name": "LLaMEA-5", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-5", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before.", "Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "8e959804-f385-4ace-a0b5-40cd352c78da", "fitness": 0.7810463059470614, "name": "AdaptiveDifferentialEvolution", "description": "An adaptive Differential Evolution strategy that adjusts its parameters based on the function evaluations.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        \"\"\"\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            F (float): The mutation factor.\n            CR (float): The crossover rate.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.F_history = []\n        self.CR_history = []\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black box function using Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize population within the bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Update the best solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n\n                # Clip the mutant vector to the bounds\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update the best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Adaptive parameter control (example: adjusting F and CR based on success rate)\n            success_indices = fitness < np.mean(fitness)\n            if np.any(success_indices):\n                successful_F = self.F\n                successful_CR = self.CR\n                \n                # Simple adaptation: if there are successful individuals, keep the parameters.\n                self.F_history.append(successful_F)\n                self.CR_history.append(successful_CR)\n\n                if len(self.F_history) > 10: #Keep the history relatively short\n                    self.F = np.mean(self.F_history[-10:]) \n                    self.CR = np.mean(self.CR_history[-10:])\n            else:\n                # If no improvement, perturb parameters\n                self.F = np.clip(self.F + np.random.normal(0, 0.1), 0.1, 1.0)\n                self.CR = np.clip(self.CR + np.random.normal(0, 0.1), 0.1, 1.0)\n                self.F_history.append(self.F)\n                self.CR_history.append(self.CR)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.781 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.40418644160157224, 0.7066779889075344, 0.6453377046582734, 0.9400174036464308, 0.8724205024399635, 0.8960979355651781, 0.7584005800229672, 0.825782374147693, 0.8851511926755079, 0.8635525216055855, 0.9104490881809051, 0.9968169851235135, 0.3124520925088995, 0.863316202754252, 0.9471991313052901, 0.9092914885642593, 0.7865114036103831, 0.921593807124782, 0.45445646820296404, 0.7212148062952712]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-5-MA_BBOB-1", "seed": 1}
{"method_name": "LLaMEA-5", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-5", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before.", "Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "2bfc844b-330c-4a03-9044-54c9c7714210", "fitness": 0.7611949348567842, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with paired mutation and dynamic F/CR adaptation using population-level statistics, enhancing both convergence and exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_factor=5, F=0.5, CR=0.7):\n        \"\"\"\n        Initialize the Adaptive Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size_factor (int): Factor to determine the population size (pop_size = pop_size_factor * dim).\n            F (float): The initial scaling factor.\n            CR (float): The initial crossover rate.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_size_factor * dim)\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive F and CR\n            F = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n            CR = np.clip(np.random.normal(self.CR, 0.1), 0.1, 1.0)\n\n            for i in range(self.pop_size):\n                # Mutation (DE/rand/1)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = idxs[0], idxs[1], idxs[2]\n                mutant = self.pop[a] + F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f = func(trial)\n                self.eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.pop[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.761 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a2230d5f-2ba9-4fd6-88f0-6c3aa4f9e57a"], "operator": null, "metadata": {"aucs": [0.2764078106654473, 0.7962218305578039, 0.7284449366375623, 0.9135917808993749, 0.8516876978157658, 0.8769514173602535, 0.7433362636919636, 0.755515417724272, 0.8350968474187358, 0.7749647270216897, 0.892165166707541, 0.997803379893753, 0.30446923762972666, 0.821011198746229, 0.9381609326097317, 0.8740903004805377, 0.7269796867116871, 0.9026721534760505, 0.7070521962910558, 0.5072757147965041]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-5-MA_BBOB-2", "seed": 2}
{"method_name": "LLaMEA-5", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-5", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before.", "Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "af41a26f-f55f-4818-bcef-c7f42cac0ca4", "fitness": 0.7904206933426717, "name": "MirroredRankOneCMAES", "description": "CMA-ES with mirrored sampling, adaptive learning rate for covariance matrix update, and a rank-one update strategy for exploration.", "code": "import numpy as np\n\nclass MirroredRankOneCMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.popsize = self._adaptive_popsize()\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + 1 / (21 * self.dim**2))\n        self.mean = np.zeros(self.dim)\n        self.sigma = initial_sigma\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.lb = -5\n        self.ub = 5\n        self.evals = 0\n        self.c1 = 0.1 / (self.dim * self.mueff)  # Adaptive learning rate for rank-one update\n        self.cmu = min(0.1, 0.2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim+2)**2 + self.mueff))\n\n\n    def _adaptive_popsize(self):\n         # Dynamically adjust popsize based on dimension\n        return 4 + int(3 * np.log(self.dim))\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n\n        while self.evals < self.budget:\n            z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            \n            # Mirrored Sampling\n            z_mirrored = np.concatenate([z, -z], axis=1)\n            x = self.mean[:, np.newaxis] + self.sigma * np.linalg.cholesky(self.C) @ z_mirrored\n            \n            # Boundary Handling: Clipping\n            x = np.clip(x, self.lb, self.ub)\n\n            f = np.array([func(x[:, i]) for i in range(2*self.popsize)])\n            self.evals += 2*self.popsize\n            \n            if self.evals > self.budget:\n                f = f[:(self.budget - (self.evals - 2*self.popsize))]\n                x = x[:, :(self.budget - (self.evals - 2*self.popsize))]\n                \n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[:, np.argmin(f)]\n\n            idx = np.argsort(f)\n            x = x[:, idx]\n            xmean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (xmean - self.mean) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.evals / (2*self.popsize)))) < (1.4 + 2 / (self.dim + 1)) * self.chiN\n            self.pc = (1 - self.damps) * self.pc + hsig * np.sqrt(self.damps * (2 - self.damps) * self.mueff) * (xmean - self.mean) / self.sigma\n\n            artmp = (x[:, :self.mu] - self.mean[:, np.newaxis]) / self.sigma\n            \n            # Rank-one update for exploration\n            rank_one = np.outer(self.pc, self.pc)\n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * rank_one + self.cmu * artmp @ np.diag(self.weights) @ artmp.T\n\n            # Ensure C remains positive definite\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)  # Reset if not positive definite\n\n            self.mean = xmean\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.sigma = max(self.sigma, 1e-10)  # Avoid sigma collapsing to zero\n            self.c1 = min(0.4, self.c1 * 1.02) # Adaptive c1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm MirroredRankOneCMAES scored 0.790 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["88e74fe9-62f4-4835-99ac-1e02ae4a520d"], "operator": null, "metadata": {"aucs": [0.3649672748047975, 0.93012558353953, 0.9298902736977253, 0.9461087675396961, 0.9277808538842269, 0.9360149777051338, 0.31179013558140223, 0.9208203416405216, 0.9334002649519306, 0.9129988356650557, 0.9452073258352348, 0.9914923363884225, 0.3717899041102535, 0.9287047131652852, 0.9389563630226909, 0.9177843572640377, 0.8917428683883152, 0.9493242154673525, 0.24077345303858433, 0.5187410211632397]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-5-MA_BBOB-3", "seed": 3}
{"method_name": "LLaMEA-5", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-5", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before.", "Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "e3e53d43-50db-48b4-9e49-be10f682a0f9", "fitness": 0.7732308801229705, "name": "AdaptiveCauchyDE", "description": "Simplified Adaptive Differential Evolution with Cauchy mutation, reducing parameter count and complexity while retaining key features.", "code": "import numpy as np\n\nclass AdaptiveCauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, initial_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.scale = initial_scale\n        self.scale_decay = 0.995\n        self.exploration_prob = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Cauchy Mutation\n                if np.random.rand() < self.exploration_prob:\n                    cauchy_noise = self.scale * np.random.standard_cauchy(size=self.dim)\n                    mutant += cauchy_noise\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluate trial solution\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            self.scale = max(self.scale * self.scale_decay, 0.001)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveCauchyDE scored 0.773 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5b9d83ee-7904-4248-af09-e2549dfae948"], "operator": null, "metadata": {"aucs": [0.38933432649512145, 0.7270556354600106, 0.8254783583967267, 0.9191434751997501, 0.8779406061725752, 0.8809944281309144, 0.8262630723774987, 0.8160077751849106, 0.870784910354769, 0.8355016277151255, 0.8745590591735011, 0.9952960188136214, 0.466907825639865, 0.8635873773605215, 0.9327974785980986, 0.8730860949698953, 0.7750503901458625, 0.9125520792179447, 0.27310490129713294, 0.5291721617555653]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-5-MA_BBOB-4", "seed": 4}
{"method_name": "LLaMEA-3", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-3", "budget": 100, "kwargs": {"mutation_prompts": ["Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "2e009cab-5a27-4df0-8135-a27389010741", "fitness": 0.6087309942884123, "name": "AdaptiveCovarianceSampling", "description": "Adaptive covariance sampling with simplified rank-one covariance update and adaptive learning rate based on fitness improvement, dynamically adjusting regularization based on covariance condition number.", "code": "import numpy as np\n\nclass AdaptiveCovarianceSampling:\n    def __init__(self, budget=10000, dim=10, initial_samples=100, learning_rate=0.2, regularization_factor=1e-6, condition_number_threshold=1e6):\n        self.budget = budget\n        self.dim = dim\n        self.initial_samples = initial_samples\n        self.learning_rate = learning_rate\n        self.regularization_factor = regularization_factor\n        self.condition_number_threshold = condition_number_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mean = np.zeros(dim)\n        self.covariance = np.eye(dim)\n        self.best_x = None\n        self.best_f = np.Inf\n\n    def sample(self, num_samples):\n        try:\n            x = np.random.multivariate_normal(self.mean, self.covariance, num_samples)\n        except np.linalg.LinAlgError:\n            x = np.random.uniform(self.lb, self.ub, size=(num_samples, self.dim))\n        x = np.clip(x, self.lb, self.ub)\n        return x\n\n    def __call__(self, func):\n        # Initial sampling\n        x = np.random.uniform(self.lb, self.ub, size=(self.initial_samples, self.dim))\n        f = np.array([func(xi) for xi in x])\n        self.budget -= self.initial_samples\n\n        # Update best solution\n        best_index = np.argmin(f)\n        if f[best_index] < self.best_f:\n            self.best_f = f[best_index]\n            self.best_x = x[best_index]\n\n        while self.budget > 0:\n            # Adaptive sampling\n            num_samples = min(self.budget, self.initial_samples)\n            x = self.sample(num_samples)\n            f = np.array([func(xi) for xi in x])\n            self.budget -= num_samples\n\n            # Update best solution\n            best_index = np.argmin(f)\n            if f[best_index] < self.best_f:\n                improvement = self.best_f - f[best_index]\n                self.best_f = f[best_index]\n                self.best_x = x[best_index]\n                \n                # Adjust learning rate based on improvement\n                if improvement > 0:\n                    self.learning_rate = min(0.5, self.learning_rate * 1.1) # Increase if improving\n                else:\n                    self.learning_rate = max(0.05, self.learning_rate * 0.9) # Decrease if not improving\n            else:\n                 improvement = 0\n                \n\n            # Adaptation of mean and covariance using only the best\n            s = self.best_x - self.mean\n            self.mean = self.mean + self.learning_rate * s # Simplified mean update\n            \n            # Rank-one covariance update\n            self.covariance = (1 - self.learning_rate) * self.covariance + self.learning_rate * np.outer(s, s)\n\n            # Dynamic Regularization\n            condition_number = np.linalg.cond(self.covariance)\n            if condition_number > self.condition_number_threshold:\n                self.regularization_factor *= 1.1  # Increase regularization\n            else:\n                self.regularization_factor *= 0.9  # Decrease regularization\n\n            # Regularize covariance matrix\n            self.covariance += self.regularization_factor * np.eye(self.dim)\n\n        return self.best_f, self.best_x", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveCovarianceSampling scored 0.609 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4d7ef7fc-f096-4315-ab89-053a1007792f"], "operator": null, "metadata": {"aucs": [0.1934166349799149, 0.7377411501643848, 0.681872912573052, 0.8686509481099017, 0.6841012240827569, 0.7503900750452555, 0.3379746318350212, 0.45164801709699987, 0.6932466996739901, 0.20445547187467628, 0.880152372913535, 0.992437713649306, 0.3347834047202105, 0.7075216490745531, 0.7296227404347106, 0.7484320302637838, 0.641775114755086, 0.8074610291238761, 0.2248790881494267, 0.5040569772478044]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-3-MA_BBOB-5", "seed": 5}
{"method_name": "LLaMEA-3", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-3", "budget": 100, "kwargs": {"mutation_prompts": ["Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "673e796b-2bd4-4908-8420-40bee8059bf9", "fitness": 0.8063992165501093, "name": "AdaptiveDifferentialEvolution", "description": "Simplified Adaptive Differential Evolution with self-adaptive mutation strength and crossover rate, focusing on computational efficiency.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=25):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        self.F = 0.5  # Initialize F\n        self.Cr = 0.9 # Initialize Cr\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[idxs]\n\n                # Self-adaptive F:  Small random perturbation\n                F = np.clip(self.F + np.random.normal(0, 0.01), 0.1, 0.9)\n\n                mutated_vector = np.clip(a + F * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                # Self-adaptive CR: Small random perturbation\n                Cr = np.clip(self.Cr + np.random.normal(0, 0.01), 0.2, 1.0)\n                cross_mask = np.random.rand(self.dim) < Cr\n                trial_vector = np.where(cross_mask, mutated_vector, self.pop[i])\n                \n                f = func(trial_vector)\n                self.eval_count += 1\n                \n                if f < self.fitness[i]:\n                    self.pop[i] = trial_vector\n                    self.fitness[i] = f\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.806 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e9b38f43-8ab9-48fc-8c68-6f0d09078be0"], "operator": null, "metadata": {"aucs": [0.5925076802146142, 0.8207579599061585, 0.7846092348348583, 0.9098459813576792, 0.8493349705294412, 0.8904259166484934, 0.8222442182897919, 0.8247285928592725, 0.8936535419269743, 0.8191007412921382, 0.8640678844157258, 1.0, 0.8307478865779945, 0.8625905076239576, 0.9377886336870448, 0.8982409708778761, 0.8258122800878103, 0.9146778234377835, 0.2722379909378556, 0.514611515496717]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-3-MA_BBOB-6", "seed": 6}
{"method_name": "LLaMEA-3", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-3", "budget": 100, "kwargs": {"mutation_prompts": ["Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "0390d29a-198a-4735-a1da-0731880dfcbe", "fitness": 0.7962408550248591, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution using a single F and CR value for all population members in each generation, enhancing exploration and exploitation balance with decreased complexity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40):\n        \"\"\"\n        Initialize the Adaptive Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given black box function using Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.func = func\n        self.bounds = func.bounds\n        self.lb = self.bounds.lb\n        self.ub = self.bounds.ub\n\n        # Initialize population\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.evals < self.budget:\n            # Find the best individual\n            best_idx = np.argmin(self.fitness)\n            best = self.population[best_idx]\n            \n            # Parameter Adaptation: Generate F and CR for this generation\n            F = np.clip(np.random.normal(0.5, 0.3), 0.1, 0.9)\n            CR = np.clip(np.random.normal(0.9, 0.2), 0.1, 0.9)\n            \n\n            for i in range(self.pop_size):\n                # Mutation: Use the best individual and two random individuals\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n                mutant = self.population[i] + F * (best - self.population[i]) + F * (self.population[a] - self.population[b])\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f = func(trial)\n                self.evals += 1\n\n                # Selection\n                if f < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f\n\n                    # Update best solution\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.796 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a6aec335-ec5d-40ed-a4f6-123ed02e5aeb"], "operator": null, "metadata": {"aucs": [0.4590092683204102, 0.7704620942553451, 0.8239784752676923, 0.9293855590692807, 0.8500046056062007, 0.8835565742815383, 0.733649326085309, 0.787536987444626, 0.8368969057856805, 0.7845968963681283, 0.907927178353888, 0.9963537045565596, 0.7641461014888768, 0.7971048359935609, 0.9347207331298613, 0.876081680935216, 0.7701855956843366, 0.9117690592880193, 0.5865754830243584, 0.5208760355582933]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-3-MA_BBOB-7", "seed": 7}
{"method_name": "LLaMEA-3", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-3", "budget": 100, "kwargs": {"mutation_prompts": ["Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "1afee8e7-0b17-43fd-a82a-6bb8283000d0", "fitness": 0.7849767939168327, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified dynamic CR and a rank-based population update for better convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=30):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Sort population based on fitness\n        ranked_indices = np.argsort(fitness)\n        population = population[ranked_indices]\n        fitness = fitness[ranked_indices]\n        \n        while self.budget > 0:\n            # Dynamically adapt crossover rate\n            CR = 0.5 + 0.4 * (self.budget / 10000)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n                mutant = x1 + self.F * (x2 - x3)\n                \n                # Ensure mutant stays within bounds\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n\n                # Rank-based population update: Replace the worst individual if trial is better than it\n                if f < fitness[-1]:  # Compare against the worst\n                    fitness[-1] = f\n                    population[-1] = trial\n\n                    # Re-sort population based on fitness\n                    ranked_indices = np.argsort(fitness)\n                    population = population[ranked_indices]\n                    fitness = fitness[ranked_indices]\n                    \n                    # Update the best solution\n                    if fitness[0] < self.f_opt:\n                        self.f_opt = fitness[0]\n                        self.x_opt = population[0]\n\n                if self.budget <= 0:\n                    break\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.785 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d68ac237-fe3b-4893-b3f5-7372c3eb6dd2"], "operator": null, "metadata": {"aucs": [0.46626870736121795, 0.8294089071735135, 0.48244666679307424, 0.942553236217899, 0.8909431771010989, 0.9145094372985565, 0.8390788643350426, 0.8691803389764996, 0.9024901289360124, 0.8711914041316928, 0.9263972973993353, 0.9908684005039545, 0.5436548389110709, 0.87438069531931, 0.8623131219086085, 0.9103219533512079, 0.8713973248080611, 0.9336620338387422, 0.24110532373296012, 0.5373640202387969]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-3-MA_BBOB-8", "seed": 8}
{"method_name": "LLaMEA-3", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-3", "budget": 100, "kwargs": {"mutation_prompts": ["Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "afb9f2ac-5507-4791-b04c-1d06bac911ca", "fitness": 0.8111630619325169, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with mirrored boundary handling and simplified parameter adaptation based on success history, plus jittering to avoid stagnation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5, p=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.p = p  # Probability for mirrored sampling\n        self.successful_F = []\n        self.successful_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n\n            # Jittering to avoid stagnation\n            if np.random.rand() < 0.05:\n                x_mutated += np.random.normal(0, 0.01, size=self.dim)\n            \n            # Mirrored sampling\n            if np.random.rand() < self.p:\n                x_mutated = np.where(x_mutated < func.bounds.lb, func.bounds.lb + (func.bounds.lb - x_mutated), x_mutated)\n                x_mutated = np.where(x_mutated > func.bounds.ub, func.bounds.ub - (x_mutated - func.bounds.ub), x_mutated)\n            \n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.successful_F.append(self.F)\n                self.successful_Cr.append(self.Cr)\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr based on successful values\n        if self.successful_F:\n            self.F = np.mean(self.successful_F)\n            self.Cr = np.mean(self.successful_Cr)\n            self.successful_F = []\n            self.successful_Cr = []\n        else:\n            self.F = 0.5  # Reset if no successful updates\n            self.Cr = 0.9\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.811 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["47cafdbd-fc85-428a-9330-4c28a1a6b819"], "operator": null, "metadata": {"aucs": [0.5720839989880433, 0.8564821625680631, 0.843675895968033, 0.924000579356598, 0.8461778463397596, 0.8888252811127142, 0.800689056467862, 0.6765002965043361, 0.8777441699611941, 0.8399750611043783, 0.9431227381958958, 0.9989718690472015, 0.49229966975508166, 0.869015798075931, 0.9596226431355057, 0.8904354109567776, 0.764445992238981, 0.9190732433649168, 0.7451893955982725, 0.5149301299107916]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-3-MA_BBOB-9", "seed": 9}
{"method_name": "LLaMEA-1", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-1", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "968fc156-413c-4507-a137-7fb9697766aa", "fitness": 0.6313389923583932, "name": "AdaptiveShrinkingSearchLevy", "description": "Adaptive shrinking search with dynamic population size, restart mechanism, and exploration-exploitation balance using Levy flights.", "code": "import numpy as np\n\nclass AdaptiveShrinkingSearchLevy:\n    def __init__(self, budget=10000, dim=10, initial_population_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.initial_population_size = initial_population_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.restart_tolerance = 1e-6  # Tolerance for stagnation detection\n        self.stagnation_counter = 0\n        self.max_stagnation = 50 #Number of iterations before triggering a restart\n        self.shrink_factor = 0.9\n        self.levy_exponent = 1.5 # Levy flight exponent (1 < levy_exponent <= 2)\n\n    def levy_flight(self, mu, sigma):\n        \"\"\"Generate Levy flight step.\"\"\"\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.power(np.abs(v), (1 / self.levy_exponent))\n        return step\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        self.previous_f_opt = self.f_opt\n        \n        search_lb = np.full(self.dim, self.lb)\n        search_ub = np.full(self.dim, self.ub)\n\n        while self.budget > 0:\n            # Sort population by fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            \n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = population[0]\n                self.stagnation_counter = 0  # Reset stagnation counter\n            else:\n                self.stagnation_counter += 1\n\n            # Shrink the search space based on the best solution\n            search_lb = np.maximum(self.lb, self.x_opt - self.shrink_factor * np.abs(self.x_opt - search_lb))\n            search_ub = np.minimum(self.ub, self.x_opt + self.shrink_factor * np.abs(search_ub - self.x_opt))\n\n            # Generate new samples\n            new_population = np.zeros((self.population_size, self.dim))\n            for i in range(self.population_size):\n                if self.budget <= 0:\n                    break\n                    \n                # Exploration using Levy flight around the best solution\n                if np.random.rand() < 0.5:  # 50% probability for Levy flight\n                    sigma = (search_ub - search_lb) / 10  # Scale the Levy step\n                    levy_step = self.levy_flight(self.x_opt, sigma)\n                    new_x = self.x_opt + levy_step\n                    new_x = np.clip(new_x, self.lb, self.ub)  # Clip to bounds\n                # Exploitation using Gaussian distribution around the best solution\n                else:\n                    new_x = np.zeros(self.dim)\n                    for j in range(self.dim):\n                        mu = self.x_opt[j]\n                        sigma = (search_ub[j] - search_lb[j]) / 5\n                        new_x[j] = np.clip(np.random.normal(mu, sigma), search_lb[j], search_ub[j])\n                \n                new_population[i] = new_x\n                fitness_new = func(new_population[i])\n                self.budget -= 1\n                \n                # Replace the worst individual if the new one is better\n                if fitness_new < fitness[-1]:\n                    fitness[-1] = fitness_new\n                    population[-1] = new_population[i]\n            \n            # Adaptive population size\n            if self.stagnation_counter > self.max_stagnation:\n                # Restart mechanism: Re-initialize the search\n                if np.abs(self.f_opt - self.previous_f_opt) < self.restart_tolerance:\n                    self.population_size = int(self.population_size * 0.8)  # Reduce population size\n                    self.population_size = max(5, self.population_size)   # Ensure minimal population size\n\n                    population = np.random.uniform(self.lb, self.ub, size=(self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    self.budget -= self.population_size\n                    \n                    best_index = np.argmin(fitness)\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                    self.stagnation_counter = 0\n\n                else:\n                    self.stagnation_counter = 0\n\n                self.previous_f_opt = self.f_opt #Store the last best score\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveShrinkingSearchLevy scored 0.631 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f29161a4-6fd1-40fc-937b-3280ff9f12c8"], "operator": null, "metadata": {"aucs": [0.22905290439006554, 0.22465597220357114, 0.8820496582811698, 0.9540185693624169, 0.2422444694310122, 0.9110191867313817, 0.34820191850351223, 0.7582764909547224, 0.8960617841715532, 0.8925986327559802, 0.9526058174614763, 0.9961578085953119, 0.2130728560682087, 0.26601527794116164, 0.9594729061182345, 0.8401966465442654, 0.41342148442516524, 0.9376872645196516, 0.21471909107692932, 0.4952511076320738]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-1-MA_BBOB-5", "seed": 5}
{"method_name": "LLaMEA-1", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-1", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "750d3302-f1b3-42ae-ba9a-062b05ac5e63", "fitness": 0.6920155992045274, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Archive, Success-History Adaptation for F/CR, and Improved Restart Mechanism based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, archive_size=10, restart_threshold=1e-8, F_adapt_rate=0.1, Cr_adapt_rate=0.1, success_history_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = np.full(pop_size, F_init)\n        self.Cr = np.full(pop_size, Cr_init)\n        self.archive_size = archive_size\n        self.restart_threshold = restart_threshold\n        self.F_adapt_rate = F_adapt_rate\n        self.Cr_adapt_rate = Cr_adapt_rate\n        self.success_history_size = success_history_size\n        self.success_F = []\n        self.success_Cr = []\n        self.memory_F = np.full(self.success_history_size, F_init)\n        self.memory_Cr = np.full(self.success_history_size, Cr_init)\n        self.memory_pos = 0\n        self.min_F = 0.1\n        self.max_F = 1.0\n        self.min_Cr = 0.1\n        self.max_Cr = 0.9\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.archive = []\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.nevals = self.pop_size\n        self.best_fitness_history = []\n\n        while self.nevals < self.budget:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history\n                F_i = np.random.choice(self.memory_F)\n                Cr_i = np.random.choice(self.memory_Cr)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                \n                mutant = x_r1 + F_i * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                trial = self.pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < Cr_i or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                # Selection\n                f_trial = func(trial)\n                self.nevals += 1\n                \n                if f_trial < self.fitness[i]:\n                    # Update F and Cr adaptively using success history\n                    self.success_F.append(F_i)\n                    self.success_Cr.append(Cr_i)\n                    \n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        \n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i])\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_to_replace] = self.pop[i]\n\n            # Update memory of successful F and Cr values\n            if len(self.success_F) > 0:\n                self.memory_F[self.memory_pos] = np.mean(self.success_F)\n                self.memory_Cr[self.memory_pos] = np.mean(self.success_Cr)\n                self.memory_pos = (self.memory_pos + 1) % self.success_history_size\n                self.success_F = []\n                self.success_Cr = []\n                \n            # Restart strategy (check stagnation based on improvement in best fitness)\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > 50:\n                if np.abs(self.best_fitness_history[-1] - self.best_fitness_history[-50]) < self.restart_threshold:\n                    self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    self.fitness = np.array([func(x) for x in self.pop])\n                    self.nevals += self.pop_size # Correctly account for evaluations during restart\n                    self.best_fitness_history = []  # Reset the history to avoid repeated restarts\n                    self.memory_F = np.full(self.success_history_size, 0.5) # Reset memory\n                    self.memory_Cr = np.full(self.success_history_size, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.692 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["acb6881c-1dfd-4636-91e8-b8384cbb77f6"], "operator": null, "metadata": {"aucs": [0.3716996482866435, 0.6623694936194383, 0.6339035562589557, 0.8823531104956365, 0.7496195175762361, 0.7741188868914103, 0.5986224666063269, 0.6544031099157546, 0.7234373896279883, 0.656657833041186, 0.8388312096901636, 0.9968786733138368, 0.6501257668473406, 0.7255203333116351, 0.9273880777113075, 0.7955835092286679, 0.632226593679409, 0.8387477436172999, 0.2287998213537057, 0.4990252430176082]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-1-MA_BBOB-6", "seed": 6}
{"method_name": "LLaMEA-1", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-1", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "7e7da4ca-1e7c-4808-9ade-84a9b15e25e2", "fitness": 0.7089231265046749, "name": "EnhancedAdaptiveDE", "description": "Enhanced Adaptive DE with dimension-specific mutation factors, a diversity-guided population size adjustment, and a simplified archive update based on fitness improvement.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.max_pop_size = 100  # Maximum population size\n        self.min_pop_size = 10   # Minimum population size\n        self.archive_size = archive_size\n        self.F = np.ones(dim) * F  # Initial mutation factor for each dimension\n        self.CR = CR  # Initial Crossover rate\n        self.archive = []\n        self.success_rates = np.ones(dim) * 0.5  # Initialize success rates for each dimension\n        self.learning_rate = 0.1  # Learning rate for updating success rates\n        self.diversity_threshold = 0.01\n        self.population = None\n        self.fitness = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n    def calculate_diversity(self):\n        # Calculate the average distance of each individual to the population centroid\n        centroid = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - centroid, axis=1)\n        return np.mean(distances)\n\n    def adjust_population_size(self):\n        diversity = self.calculate_diversity()\n        if diversity < self.diversity_threshold and self.pop_size < self.max_pop_size:\n            self.pop_size = min(self.pop_size + 5, self.max_pop_size)  # Increase population size\n            print(f\"Increased population size to {self.pop_size}\")\n        elif diversity > 2 * self.diversity_threshold and self.pop_size > self.min_pop_size:\n            self.pop_size = max(self.pop_size - 5, self.min_pop_size)  # Decrease population size\n            print(f\"Decreased population size to {self.pop_size}\")\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            self.adjust_population_size()  # Adjust population size based on diversity\n\n            # Dynamically adjust CR based on population diversity\n            diversity = self.calculate_diversity()\n            CR_i = self.CR * (0.5 + 0.5 * (diversity / (func.bounds.ub[0] - func.bounds.lb[0])))  # Scale CR with diversity\n            CR_i = np.clip(CR_i, 0.1, 1.0)\n\n            for i in range(self.pop_size):\n                # Self-adaptive F (dimension-specific): Sample F from a Cauchy distribution and clip\n                F_i = np.random.standard_cauchy(size=self.dim) * 0.1 + self.F  # Cauchy distribution centered around F, dimension-specific\n                F_i = np.clip(F_i, 0.1, 1.0)\n\n                # Mutation Strategy Selection\n                rand = np.random.rand()\n                if rand < 0.3:\n                    # Strategy 1: Use archive with a probability of 0.3 for enhanced exploration\n                    if len(self.archive) > 0:\n                        candidates = list(range(self.pop_size))\n                        candidates.remove(i)\n                        candidates2 = list(range(len(self.archive)))\n                        a, b = np.random.choice(candidates, 2, replace=False)\n                        arc_ind = np.random.choice(candidates2, 1, replace=False)[0]\n                        mutant = self.population[a] + F_i * (self.archive[arc_ind] - self.population[b])\n                    else:\n                         # Fallback to basic DE if archive is empty\n                        candidates = list(range(self.pop_size))\n                        candidates.remove(i)\n                        a, b, c = np.random.choice(candidates, 3, replace=False)\n                        mutant = self.population[a] + F_i * (self.population[b] - self.population[c])\n\n\n                elif rand < 0.7:\n                    # Strategy 2: Standard DE with probability 0.4\n                    candidates = list(range(self.pop_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n                    mutant = self.population[a] + F_i * (self.population[b] - self.population[c])\n                else:\n                    # Strategy 3: Current-to-best with probability 0.3\n                    candidates = list(range(self.pop_size))\n                    candidates.remove(i)\n                    a = np.random.choice(candidates, 1, replace=False)[0]\n                    mutant = self.population[i] + F_i * (self.x_opt - self.population[a]) if self.x_opt is not None else self.population[i] # Fallback to current if best is not defined\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n\n                # Orthogonal Crossover with dynamic probability\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n\n                for j in range(self.dim):\n                    if np.random.rand() < CR_i or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    #Update success rates (simplified)\n                    delta = (self.fitness[i] - f_trial) / (abs(self.fitness[i]) + 1e-9)  # Avoid division by zero\n                    self.success_rates += self.learning_rate * delta * (trial != self.population[i])\n                    self.success_rates = np.clip(self.success_rates, 0.1, 0.9)\n\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial\n\n                    # Dynamic Archive Update (Simplified: Replace worst if better)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i])\n                    else:\n                        worst_index = np.argmax(self.fitness)\n                        if f_trial < self.fitness[worst_index]:\n                            self.archive[np.random.randint(len(self.archive))] = self.population[i] #Replace a random element\n                            \n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedAdaptiveDE scored 0.709 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4754ba34-77fd-4819-a89a-4f7e87707a8e"], "operator": null, "metadata": {"aucs": [0.40208600598895194, 0.8513391178132781, 0.8873136816640343, 0.8952261811556921, 0.908294626510666, 0.9366755082525208, 0.8657713732610579, 0.520873009944964, 0.2501135154771097, 0.8964291869335466, 0.6415248317196893, 0.9944408238147502, 0.3298314730420031, 0.8878834296301916, 0.9642665154956753, 0.9276759271117927, 0.4108369323060105, 0.940272705081762, 0.18925706030166833, 0.4783506245881335]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-1-MA_BBOB-8", "seed": 8}
{"method_name": "LLaMEA-1", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-1", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "186f383f-51b1-4a2c-851f-b90e6fefaea9", "fitness": 0.24825805912082322, "name": "EnhancedAdaptiveDE_CMA", "description": "Enhanced Adaptive DE with covariance matrix adaptation (CMA) inspired mutation, orthogonal learning, adaptive local search, and an archive to improve exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.7, local_search_iterations=5, ls_prob=0.1, archive_size=15):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.local_search_iterations = local_search_iterations\n        self.ls_prob = ls_prob # Probability of local search\n        self.archive = [] # Archive for storing removed solutions\n        self.archive_size = archive_size\n\n        # CMA-inspired initialization\n        self.mean = np.zeros(dim)\n        self.C = np.eye(dim)  # Covariance matrix\n        self.pc = np.zeros(dim)  # Evolution path for C\n        self.ps = np.zeros(dim)  # Evolution path for step size\n        self.chiN = np.sqrt(dim) * (1 - (1/(4*dim)) + 1/(21*dim**2))\n        self.c_sigma = (pop_size + 2) / (dim + pop_size + 5)\n        self.c_c = 4 / (dim + 4)\n        self.mu = pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.c_1 = 2 / ((dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((dim + 2)**2 + self.mu))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1)/(dim+1)) - 1) + self.c_sigma\n\n        self.sigma = 0.3  # Global step size\n\n\n    def levy_flight(self, beta=1.5):\n        \"\"\"Generates a Lvy flight step.\"\"\"\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.randn(self.dim) * sigma\n        v = np.random.randn(self.dim)\n        step = u / abs(v)**(1/beta)\n        return step\n\n    def local_search(self, func, x, iterations=5, step_size=0.1):\n        \"\"\"Performs a local search around a given solution.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        for _ in range(iterations):\n            x_new = best_x + np.random.uniform(-step_size, step_size, self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            if f_new < best_f:\n                best_f = f_new\n                best_x = x_new.copy()\n        return best_f, best_x\n\n    def orthogonal_learning(self, func, x, num_samples=5):\n        \"\"\"Performs orthogonal learning to generate better solutions.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        \n        for _ in range(num_samples):\n            # Generate a new solution based on orthogonal design (simplified)\n            direction = np.random.randn(self.dim)\n            step_size = np.random.uniform(-0.1, 0.1)  # Adjust step size as needed\n            x_new = x + step_size * direction\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(x_new)\n            \n            if f_new < best_f:\n                best_f = f_new\n                best_x = x_new.copy()\n        return best_f, best_x\n    \n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evaluations = self.pop_size #Keep track of function evaluations\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n        \n        # Momentum initialization\n        velocity = np.zeros_like(population) \n\n        # Main loop\n        while evaluations < self.budget:\n            # Adaptive F and CR (using success history)\n            SF = []\n            SCR = []\n            \n            # Adaptive Local Search probability\n            self.ls_prob = 0.1 + 0.4 * (1 - (evaluations / self.budget))  # Decrease LS prob over time\n\n            # Generate offspring\n            offspring = np.zeros_like(population)\n            for i in range(self.pop_size):\n                z = np.random.randn(self.dim)\n                offspring[i] = self.mean + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n                offspring[i] = np.clip(offspring[i], func.bounds.lb, func.bounds.ub)\n            \n            offspring_fitness = np.array([func(x) for x in offspring])\n            evaluations += self.pop_size\n\n            # Selection and update best\n            indices = np.argsort(offspring_fitness)[:self.mu]\n            best_offspring = offspring[indices]\n            best_fitness = offspring_fitness[indices]\n\n            if np.min(best_fitness) < self.f_opt:\n                self.f_opt = np.min(best_fitness)\n                self.x_opt = best_offspring[np.argmin(best_fitness)].copy()\n            \n            # CMA-ES update\n            y = best_offspring - self.mean\n            self.mean = np.sum(self.weights[:, None] * best_offspring, axis=0)\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), (self.mean - self.mean))\n            \n            if np.linalg.norm(self.ps) / self.chiN < 0.1:\n                hsig = 0\n            else:\n                hsig = 1\n\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c)) * (self.mean - self.mean)\n            \n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            \n            for k in range(self.mu):\n                yk = best_offspring[k] - self.mean\n                self.C += self.c_mu * self.weights[k] * (yk[:, None] @ yk[None, :])\n            \n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            #Adaptive F and CR updates, local search and archive phases removed to keep core logic focused on CMA inspired mutation.\n            \n            if evaluations >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedAdaptiveDE_CMA scored 0.248 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["81401c85-6881-4373-b640-af1c898ab84b"], "operator": null, "metadata": {"aucs": [0.0716302413127331, 0.16392729723532107, 0.2683440843764465, 0.17117944657023987, 0.16172024971766974, 0.1574841024009611, 0.19512924861735326, 0.1729782897238885, 0.15408888892075467, 0.147437504177663, 0.16777430841082785, 0.9973785655887217, 0.24956733023030575, 0.14158690585064726, 0.5505604608573935, 0.2305709592056292, 0.19312433097085735, 0.23705686384730984, 0.12274202983840732, 0.41088007456333386]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-1-MA_BBOB-9", "seed": 9}
{"method_name": "LLaMEA-2", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-2", "budget": 100, "kwargs": {"mutation_prompts": ["Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "fc7f0cfa-a316-4864-bd38-0f4d861adbf9", "fitness": 0.8431733748501034, "name": "DynamicPopulationDE", "description": "A differential evolution variant employing a dynamic population size adjustment based on the success rate of each subpopulation, encouraging better resource allocation between exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicPopulationDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, initial_exploit_ratio=0.3, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.exploit_ratio = initial_exploit_ratio\n        self.explore_size = int(pop_size * (1 - self.exploit_ratio))\n        self.exploit_size = pop_size - self.explore_size\n        self.F = F\n        self.Cr = Cr\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.adaptation_rate = adaptation_rate  # How quickly the population ratio adapts\n        self.explore_success_rate = 0.0\n        self.exploit_success_rate = 0.0\n\n    def __call__(self, func):\n        # Initialize populations\n        self.explore_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.explore_size, self.dim))\n        self.exploit_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.exploit_size, self.dim))\n        \n        # Initial evaluation\n        explore_fitness = np.array([func(x) for x in self.explore_pop])\n        exploit_fitness = np.array([func(x) for x in self.exploit_pop])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_explore_idx = np.argmin(explore_fitness)\n        best_exploit_idx = np.argmin(exploit_fitness)\n\n        if explore_fitness[best_explore_idx] < exploit_fitness[best_exploit_idx]:\n            self.f_opt = explore_fitness[best_explore_idx]\n            self.x_opt = self.explore_pop[best_explore_idx].copy()\n        else:\n            self.f_opt = exploit_fitness[best_exploit_idx]\n            self.x_opt = self.exploit_pop[best_exploit_idx].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            explore_successes = 0\n            exploit_successes = 0\n\n            # Explore population DE\n            for i in range(self.explore_size):\n                idxs = np.random.choice(self.explore_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.explore_pop[idxs]\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.explore_pop[i])\n                f_trial = func(trial)\n                self.budget -= 1\n                if f_trial < explore_fitness[i]:\n                    self.explore_pop[i] = trial\n                    explore_fitness[i] = f_trial\n                    explore_successes += 1\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n                    \n            if self.budget <= 0:\n                break\n            # Exploit population DE - biased towards x_opt\n            for i in range(self.exploit_size):\n                idxs = np.random.choice(self.exploit_size, 2, replace=False)\n                x_r1, x_r2 = self.exploit_pop[idxs]\n                mutant = self.x_opt + self.F * (x_r1 - x_r2) # Bias towards x_opt\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, self.exploit_pop[i])\n                f_trial = func(trial)\n                self.budget -= 1\n                if f_trial < exploit_fitness[i]:\n                    self.exploit_pop[i] = trial\n                    exploit_fitness[i] = f_trial\n                    exploit_successes += 1\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                        \n                if self.budget <= 0:\n                    break\n            \n            # Adapt population sizes based on success rates\n            self.explore_success_rate = explore_successes / self.explore_size\n            self.exploit_success_rate = exploit_successes / self.exploit_size\n\n            if self.explore_success_rate > self.exploit_success_rate:\n                # Increase explore, decrease exploit\n                self.exploit_ratio -= self.adaptation_rate * (1 - self.exploit_ratio)\n            else:\n                # Increase exploit, decrease explore\n                self.exploit_ratio += self.adaptation_rate * self.exploit_ratio\n            \n            self.exploit_ratio = np.clip(self.exploit_ratio, 0.1, 0.9)  # Keep ratio within bounds\n            new_exploit_size = int(self.pop_size * self.exploit_ratio)\n            new_explore_size = self.pop_size - new_exploit_size\n            \n            # Resize populations: simple reallocation (can be improved with more sophisticated migration)\n            if new_explore_size != self.explore_size or new_exploit_size != self.exploit_size:\n                # Resize populations (crude reallocation)\n                # Combine populations\n                combined_pop = np.vstack((self.explore_pop, self.exploit_pop))\n                combined_fitness = np.concatenate((explore_fitness, exploit_fitness))\n\n                # Sort by fitness\n                sorted_indices = np.argsort(combined_fitness)\n                combined_pop = combined_pop[sorted_indices]\n                combined_fitness = combined_fitness[sorted_indices]\n\n                # Split into new populations\n                self.explore_pop = combined_pop[:new_explore_size]\n                self.exploit_pop = combined_pop[new_explore_size:]\n                explore_fitness = combined_fitness[:new_explore_size]\n                exploit_fitness = combined_fitness[new_explore_size:]\n\n                # If the new sizes are bigger than current populations, fill with random individuals\n                if new_explore_size > self.explore_pop.shape[0]:\n                   num_new_individuals = new_explore_size - self.explore_pop.shape[0]\n                   new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new_individuals, self.dim))\n                   self.explore_pop = np.vstack((self.explore_pop, new_individuals))\n                   explore_fitness = np.concatenate((explore_fitness, np.array([func(x) for x in new_individuals])))\n                   self.budget -= num_new_individuals\n                if new_exploit_size > self.exploit_pop.shape[0]:\n                   num_new_individuals = new_exploit_size - self.exploit_pop.shape[0]\n                   new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new_individuals, self.dim))\n                   self.exploit_pop = np.vstack((self.exploit_pop, new_individuals))\n                   exploit_fitness = np.concatenate((exploit_fitness, np.array([func(x) for x in new_individuals])))\n                   self.budget -= num_new_individuals\n                \n                self.explore_size = new_explore_size\n                self.exploit_size = new_exploit_size\n\n            # Ensure populations are not empty: if so fill with random individuals\n            if self.explore_size == 0:\n                self.explore_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                explore_fitness = np.array([func(x) for x in self.explore_pop])\n                self.explore_size = self.pop_size\n                self.exploit_size = 0\n                self.budget -= self.pop_size\n            if self.exploit_size == 0:\n                self.exploit_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                exploit_fitness =  np.array([func(x) for x in self.exploit_pop])\n                self.exploit_size = self.pop_size\n                self.explore_size = 0\n                self.budget -= self.pop_size\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm DynamicPopulationDE scored 0.843 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4f520cf7-0ee4-4719-8da1-f50563122d5b"], "operator": null, "metadata": {"aucs": [0.2692557556990629, 0.8567057405785188, 0.9008606673175029, 0.9469888047824857, 0.9073939137114833, 0.9218564846697891, 0.8888904292818385, 0.6648160433486568, 0.9031725913029498, 0.899480938700964, 0.9330059916915304, 0.9930627629352403, 0.8299497288256164, 0.902153577173924, 0.9579578208788148, 0.9205640690366751, 0.8486951142348732, 0.9349831644420858, 0.8725479462776969, 0.5111259521123587]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-2-MA_BBOB-5", "seed": 5}
{"method_name": "LLaMEA-2", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-2", "budget": 100, "kwargs": {"mutation_prompts": ["Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "7b28f5a8-e1b5-4eab-8b05-9a6a8e2d52d6", "fitness": 0.7712580487831929, "name": "AdaptiveDE_SuccessHistory", "description": "An adaptive Differential Evolution with dynamically adjusted mutation strategy and parameter control based on success history.", "code": "import numpy as np\n\nclass AdaptiveDE_SuccessHistory:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.archive_size = archive_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n        self.success_F = []\n        self.success_Cr = []\n        self.memory_F = np.full(10, 0.5)\n        self.memory_Cr = np.full(10, 0.9)\n        self.memory_idx = 0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                F = np.random.choice(self.memory_F)\n                Cr = np.random.choice(self.memory_Cr)\n\n                # Mutation Strategy Adaptation: DE/current-to-best/1\n                best_idx = np.argmin(self.fitness)\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n                mutant = self.population[i] + F * (self.population[best_idx] - self.population[i]) + F * (self.population[a] - self.population[b])\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                cross_points = np.random.rand(self.dim) < Cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial[cross_points] = mutant[cross_points]\n\n                # Selection\n                f = func(trial)\n                self.eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.success_F.append(F)\n                    self.success_Cr.append(Cr)\n                    delta = abs(self.fitness[i] - f)\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            # Update memory\n            if self.success_F:\n                self.memory_F[self.memory_idx] = np.mean(self.success_F)\n                self.memory_Cr[self.memory_idx] = np.mean(self.success_Cr)\n                self.memory_idx = (self.memory_idx + 1) % 10\n                self.success_F = []\n                self.success_Cr = []\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE_SuccessHistory scored 0.771 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ef5566a8-cd2c-488e-a1da-976d142704d0"], "operator": null, "metadata": {"aucs": [0.4440767273622428, 0.8428486321183701, 0.8624911304834281, 0.9413599569222565, 0.876033207435462, 0.8978680311047095, 0.7856415154752946, 0.8417979744793519, 0.8798350383288438, 0.21740628500352321, 0.9310976783247834, 1.0, 0.831398176940053, 0.7159040707236765, 0.9642443764443321, 0.8978330764095687, 0.8111374936615832, 0.9267755057938813, 0.2605427242935938, 0.4968693743589062]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-2-MA_BBOB-6", "seed": 6}
{"method_name": "LLaMEA-2", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-2", "budget": 100, "kwargs": {"mutation_prompts": ["Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "db1c48dc-c39d-43b7-8a90-60d8d898834c", "fitness": 0.7262062730444658, "name": "ReinforcementLearningDE", "description": "A self-adjusting Differential Evolution algorithm that adaptively modifies mutation strategies and control parameters based on a reinforcement learning approach using a simple reward system tied to fitness improvement.", "code": "import numpy as np\n\nclass ReinforcementLearningDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, learning_rate=0.1, reward_decay=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.learning_rate = learning_rate\n        self.reward_decay = reward_decay\n        self.mutation_strategies = [\n            \"DE/rand/1\",\n            \"DE/best/1\",\n            \"DE/rand-to-best/1\",\n            \"DE/current-to-rand/1\" #A variant that's not in the original DE\n        ]\n        self.strategy_rewards = np.zeros(len(self.mutation_strategies))\n        self.F = 0.5\n        self.CR = 0.7\n        self.archive = []\n        self.archive_rate = 0.1\n\n\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.generation = 0\n\n        while self.evals < self.budget:\n            self.generation += 1\n\n            for i in range(self.pop.shape[0]):\n                # Strategy Selection (Reinforcement Learning)\n                strategy_index = np.random.choice(len(self.mutation_strategies), p=np.exp(self.strategy_rewards - np.max(self.strategy_rewards)) / np.sum(np.exp(self.strategy_rewards - np.max(self.strategy_rewards)))) #softmax\n                strategy = self.mutation_strategies[strategy_index]\n\n                # Mutation\n                if strategy == \"DE/rand/1\":\n                    idxs = np.random.choice(self.pop.shape[0], 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n                    mutant = x_r1 + self.F * (x_r2 - x_r3)\n                elif strategy == \"DE/best/1\":\n                    x_best = self.x_opt\n                    idxs = np.random.choice(self.pop.shape[0], 2, replace=False)\n                    x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n                    mutant = x_best + self.F * (x_r1 - x_r2)\n                elif strategy == \"DE/rand-to-best/1\":\n                    x_best = self.x_opt\n                    idxs = np.random.choice(self.pop.shape[0], 2, replace=False)\n                    x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n                    mutant = self.pop[i] + self.F * (x_best - self.pop[i]) + self.F * (x_r1 - x_r2)\n                elif strategy == \"DE/current-to-rand/1\":\n                    idxs = np.random.choice(self.pop.shape[0], 2, replace=False)\n                    x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n                    mutant = self.pop[i] + np.random.rand() * (x_r1 - self.pop[i]) + np.random.rand() * (x_r2 - self.pop[i])\n                else:\n                    mutant = self.pop[i] # Should not happen, but just in case\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(trial)\n                self.evals += 1\n\n                # Selection and Reward Update\n                if f_trial < self.fitness[i]:\n                    reward = (self.fitness[i] - f_trial) / (np.abs(self.fitness[i]) + 1e-8)  # Normalize reward\n                    self.strategy_rewards[strategy_index] += self.learning_rate * reward\n                    self.strategy_rewards *= self.reward_decay  # Decay other rewards\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                    # Archive\n                    if np.random.rand() < self.archive_rate:\n                        self.archive.append(self.pop[i].copy())\n                        if len(self.archive) > self.pop_size:\n                            self.archive.pop(0)\n                else:\n                     self.strategy_rewards[strategy_index] -= self.learning_rate * 0.01 #penalize bad moves\n\n\n            # Parameter Adaptation\n            self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm ReinforcementLearningDE scored 0.726 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["75ccb14e-77e3-4958-9619-5056de963773"], "operator": null, "metadata": {"aucs": [0.3490241262606876, 0.8445798411502633, 0.817615353658918, 0.9084452033990766, 0.8738395952595133, 0.8813290791740963, 0.3700201064079799, 0.7976404692314059, 0.8458475978348274, 0.2251826340157871, 0.9220918228833669, 0.9975675359929596, 0.629433749632702, 0.8352362955701769, 0.9229329426243902, 0.8811807581997274, 0.7737465408956308, 0.9038690614348328, 0.23548884748389598, 0.5090538997790786]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-2-MA_BBOB-7", "seed": 7}
{"method_name": "LLaMEA-2", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-2", "budget": 100, "kwargs": {"mutation_prompts": ["Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "ac3d01e3-c613-4f47-8600-7757539e73f1", "fitness": 0.7209315856873474, "name": "AdaptiveDECauchy", "description": "An adaptive population-based algorithm that combines aspects of differential evolution with a self-adjusting probability of either performing a standard DE update or a Cauchy mutation.", "code": "import numpy as np\n\nclass AdaptiveDECauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_prob=0.7, cauchy_scale=0.1, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_prob = de_prob\n        self.cauchy_scale = cauchy_scale\n        self.F = F\n        self.CR = CR\n\n    def cauchy_mutation(self, size):\n        return self.cauchy_scale * np.random.standard_cauchy(size=size)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.de_prob:\n                    # Differential Evolution update\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n\n                    # Mutation\n                    v_i = x_r1 + self.F * (x_r2 - x_r3)\n\n                    # Crossover\n                    u_i = np.zeros(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.CR:\n                            u_i[j] = v_i[j]\n                        else:\n                            u_i[j] = population[i, j]\n                    \n                    u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)\n                    f_u_i = func(u_i)\n                    self.budget -= 1\n\n                    if f_u_i < fitness[i]:\n                        population[i] = u_i.copy()\n                        fitness[i] = f_u_i\n                        if f_u_i < global_best_fitness:\n                            global_best_fitness = f_u_i\n                            global_best_position = u_i.copy()\n                else:\n                    # Cauchy Mutation\n                    mutation = self.cauchy_mutation(self.dim)\n                    new_position = population[i] + mutation\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness = func(new_position)\n                    self.budget -= 1\n\n                    if new_fitness < fitness[i]:\n                        population[i] = new_position.copy()\n                        fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best_fitness = new_fitness\n                            global_best_position = new_position.copy()\n\n            # Adapt de_prob (optional, based on success rate of DE vs Cauchy)\n            # This part is intentionally skipped to maintain simplicity and novelty\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDECauchy scored 0.721 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["437dd58f-7938-43fe-97eb-7180e87662c3"], "operator": null, "metadata": {"aucs": [0.23668897858978044, 0.6893025265192707, 0.6966775953324558, 0.905496127954969, 0.8372948021056756, 0.8491853812327936, 0.7130431347335733, 0.7476086896678593, 0.8189423796636055, 0.724516036330981, 0.8801141974212693, 0.9966673121604342, 0.3254323709571766, 0.792704696476255, 0.8486183511052976, 0.8544239350636047, 0.6494295132126882, 0.9008044784092669, 0.4328650810555048, 0.5188161257544852]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-2-MA_BBOB-8", "seed": 8}
{"method_name": "LLaMEA-2", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-2", "budget": 100, "kwargs": {"mutation_prompts": ["Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "d7b57c88-4ff4-46be-954c-c17ce1595a75", "fitness": 0.7532113945011866, "name": "EnsembleAdaptiveDE", "description": "Differential Evolution with an ensemble of mutation strategies and self-adaptive selection probabilities for each strategy.", "code": "import numpy as np\n\nclass EnsembleAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, CR=0.7, F=0.5, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.CR = CR\n        self.F = F\n        self.learning_rate = learning_rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n\n        # Define multiple mutation strategies\n        self.mutation_strategies = [\n            self.mutation_strategy_1,  # DE/rand/1\n            self.mutation_strategy_2,  # DE/current-to-best/1\n            self.mutation_strategy_3   # DE/best/1\n        ]\n        self.num_strategies = len(self.mutation_strategies)\n\n        # Initialize selection probabilities for each strategy\n        self.strategy_probabilities = np.ones(self.num_strategies) / self.num_strategies\n        self.successful_strategies = []\n\n    def mutation_strategy_1(self, population, i): # DE/rand/1\n        indices = np.random.choice(self.pop_size, 5, replace=False)\n        x_r1, x_r2, x_r3, x_r4, x_r5 = population[indices]\n        return x_r1 + self.F * (x_r2 - x_r3) + self.F * (x_r4 - x_r5)\n    \n    def mutation_strategy_2(self, population, i, best_index): # DE/current-to-best/1\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = population[indices]\n        return population[i] + self.F * (population[best_index] - population[i]) + self.F * (x_r1 - x_r2)\n\n    def mutation_strategy_3(self, population, i, best_index): # DE/best/1\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = population[indices]\n        return self.population[best_index] + self.F * (x_r1 - x_r2)\n\n    def __call__(self, func):\n        # Initialization\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_index]\n        self.x_opt = self.population[self.best_index]\n\n\n        # Optimization loop\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Strategy Selection\n                strategy_index = np.random.choice(self.num_strategies, p=self.strategy_probabilities)\n                mutation_strategy = self.mutation_strategies[strategy_index]\n\n                # Mutation\n                if mutation_strategy == self.mutation_strategy_1:\n                    mutant = mutation_strategy(self.population, i)\n                else:\n                    mutant = mutation_strategy(self.population, i, self.best_index)\n                    \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(trial)\n                self.evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.successful_strategies.append(strategy_index)\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.best_index = np.argmin(self.fitness)\n\n                if self.evals >= self.budget:\n                    break\n\n            # Update strategy probabilities\n            if self.successful_strategies:\n                strategy_counts = np.bincount(self.successful_strategies, minlength=self.num_strategies)\n                success_rates = strategy_counts / np.sum(strategy_counts)\n                self.strategy_probabilities = (1 - self.learning_rate) * self.strategy_probabilities + self.learning_rate * success_rates\n                self.strategy_probabilities /= np.sum(self.strategy_probabilities)  # Normalize\n\n            self.successful_strategies = []\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm EnsembleAdaptiveDE scored 0.753 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["327d2504-2cc4-49a0-89b2-09d57e3264d1"], "operator": null, "metadata": {"aucs": [0.30929140746654826, 0.7955683734876139, 0.8227192970229351, 0.90391198380083, 0.8547417858981421, 0.8851540485646643, 0.3403075934878893, 0.8076760462111129, 0.8495245329765861, 0.7865647772101094, 0.9239909305438856, 0.9989041130396963, 0.5616650447251925, 0.8126223768922113, 0.94070672510359, 0.8719913438664535, 0.7757801921187273, 0.9141796330567785, 0.3733584790070754, 0.5355692055436874]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-2-MA_BBOB-9", "seed": 9}
{"method_name": "LLaMEA-4", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-4", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "13ed561d-75ab-42f5-a809-874e99b9cf4d", "fitness": 0.735987449216026, "name": "NeighborhoodAdaptiveDE", "description": "Implements a Differential Evolution with success-history based parameter adaptation, a combined mutation strategy including a perturbated current-to-pbest mutation, and a neighborhood-based local search with adaptive step size.", "code": "import numpy as np\n\nclass NeighborhoodAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, archive_size=50, p_best=0.1, local_search_prob=0.1, neighborhood_size=5, eta_F=0.1, eta_CR=0.1, ls_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.archive_size = archive_size\n        self.p_best = p_best\n        self.local_search_prob = local_search_prob\n        self.neighborhood_size = neighborhood_size\n        self.eta_F = eta_F\n        self.eta_CR = eta_CR\n        self.ls_step_size = ls_step_size\n        self.archive = []\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.memory_F = np.ones(self.archive_size) * self.F\n        self.memory_CR = np.ones(self.archive_size) * self.CR\n        self.memory_idx = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n            if self.eval_count >= self.budget:\n                return\n\n    def adapt_parameters(self, success, F_trial, CR_trial):\n        if success:\n            self.memory_F[self.memory_idx] = F_trial\n            self.memory_CR[self.memory_idx] = CR_trial\n            self.memory_idx = (self.memory_idx + 1) % self.archive_size\n\n    def get_adapted_parameters(self):\n        valid_F = self.memory_F[self.memory_F > 0]\n        valid_CR = self.memory_CR[self.memory_CR >= 0]\n\n        if len(valid_F) > 0:\n             F = np.clip(np.random.normal(np.mean(valid_F), np.std(valid_F)), 0.1, 1.0)\n        else:\n            F = self.F #Fallback if not enough successful values\n\n        if len(valid_CR) > 0:\n            CR = np.clip(np.random.normal(np.mean(valid_CR), np.std(valid_CR)), 0.1, 1.0)\n        else:\n            CR = self.CR  # Fallback if not enough successful values\n        return F, CR\n\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                return\n\n            # Parameter adaptation\n            F, CR = self.get_adapted_parameters()\n            F_trial, CR_trial = F, CR\n            \n            # Mutation: Using a combination of DE/rand/1 and DE/current-to-pbest/1\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n            \n            # DE/rand/1\n            x_mutated_rand = x_r1 + F * (x_r2 - x_r3)\n\n            #DE/current-to-pbest/1\n            p_best_idx = np.random.choice(np.argsort(self.fitness)[:int(self.p_best * self.pop_size)])\n            x_pbest = self.population[p_best_idx]\n            x_mutated_pbest = self.population[i] + F * (x_pbest - self.population[i]) + F * (x_r1 - x_r2)\n\n            # Combine mutations (e.g., randomly choose one)\n            if np.random.rand() < 0.5:\n                x_mutated = x_mutated_rand\n            else:\n                x_mutated = x_mutated_pbest\n\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n\n            # Crossover\n            x_trial = self.population[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < CR or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Neighborhood-based Local Search\n            if np.random.rand() < self.local_search_prob:\n                # Find neighbors\n                distances = np.linalg.norm(self.population - self.population[i], axis=1)\n                neighbor_indices = np.argsort(distances)[1:self.neighborhood_size + 1]  # Exclude itself\n\n                # Perturb towards the best neighbor with adaptive step size\n                best_neighbor_idx = neighbor_indices[np.argmin(self.fitness[neighbor_indices])]\n                step_size = self.ls_step_size * (self.f_opt / self.fitness[i]) # Adaptive step size\n                x_trial = x_trial + step_size * (self.population[best_neighbor_idx] - x_trial)\n                x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.adapt_parameters(True, F_trial, CR_trial)\n                self.fitness[i] = f_trial\n                self.population[i] = x_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            else:\n                self.adapt_parameters(False, F_trial, CR_trial)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm NeighborhoodAdaptiveDE scored 0.736 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["342a7da1-c721-4509-8c23-18c7dd7a09ff"], "operator": null, "metadata": {"aucs": [0.29418565788693074, 0.738113209322748, 0.7561858263942186, 0.8968397510267566, 0.8076046827348708, 0.8511025891510908, 0.6632316562682614, 0.741981692803399, 0.8025239938927268, 0.6993428199391065, 0.8680766078024557, 0.9979033126593091, 0.520423277012212, 0.7840279206679022, 0.917170715545714, 0.8451985211666413, 0.6852670558765068, 0.8688214186731582, 0.4622529352871977, 0.5194953402093128]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-4-MA_BBOB-5", "seed": 5}
{"method_name": "LLaMEA-4", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-4", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "7e9856cc-2973-4f5c-b104-b40f9d91f3cd", "fitness": 0.6872982780082142, "name": "DE_CMAES_AdaptiveRepair_Enhanced", "description": "Enhanced DE-CMAES with adaptive repair, stagnation detection, and covariance matrix adaptation focusing on rank-one updates and path-based adaptation for faster convergence.", "code": "import numpy as np\n\nclass DE_CMAES_AdaptiveRepair_Enhanced:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.7, cma_sigma=0.1, repair_prob=0.1, stagnation_threshold=1e-6, stagnation_iter=50):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 2 * self.dim\n        self.F = F\n        self.CR = CR\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.cma_sigma = cma_sigma\n        self.cma_C = np.eye(dim)\n        self.cma_D = np.ones(dim)\n        self.cma_mu = self.popsize // 2\n        self.cma_weights = np.log(self.cma_mu + 1/2) - np.log(np.arange(1, self.cma_mu + 1))\n        self.cma_weights /= np.sum(self.cma_weights)\n        self.cma_mueff = np.sum(self.cma_weights)**2 / np.sum(self.cma_weights**2)\n        self.cma_cs = (self.cma_mueff + 2) / (self.dim + self.cma_mueff + 5)\n        self.cma_damps = 1 + 2 * max(0, np.sqrt((self.cma_mueff - 1)/(self.dim + 1)) - 1) + self.cma_cs\n        self.repair_prob = repair_prob\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_iter = stagnation_iter\n\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1/(4 * self.dim)) + 1/(21 * self.dim**2))\n\n        self.F_adaptive = self.F * np.ones(self.popsize)\n        self.CR_adaptive = self.CR * np.ones(self.popsize)\n\n        self.last_improvement = 0\n        self.best_fitness_history = []\n\n\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        self.population = np.random.uniform(bounds_lb, bounds_ub, size=(self.popsize, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        eval_count = self.popsize\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = self.population[np.argmin(fitness)].copy()\n        self.last_improvement = 0\n        self.best_fitness_history = [self.f_opt]\n\n        while eval_count < self.budget:\n            mean_pop = np.mean(self.population, axis=0)\n\n            for i in range(self.popsize):\n                # Adaptive F and CR\n                self.F_adaptive[i] = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n                self.CR_adaptive[i] = np.clip(np.random.normal(self.CR, 0.1), 0.1, 0.9)\n\n                # DE mutation\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant_de = self.population[i] + self.F_adaptive[i] * (x2 - x3)\n                mutant_de = np.clip(mutant_de, bounds_lb, bounds_ub)\n\n                # CMA-ES-like mutation\n                z = np.random.normal(0, 1, self.dim)\n                mutant_cmaes = self.population[i] + self.cma_sigma * np.dot(self.cma_C, z)  # Use covariance matrix directly\n\n                mutant_cmaes = np.clip(mutant_cmaes, bounds_lb, bounds_ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR_adaptive[i]\n                trial_vector = np.where(crossover_mask, mutant_de, mutant_cmaes)\n                \n                # Repair Mechanism\n                if np.random.rand() < self.repair_prob:\n                    trial_vector = 0.5 * (trial_vector + mean_pop)\n\n                trial_vector = np.clip(trial_vector, bounds_lb, bounds_ub)\n\n\n                # Selection\n                f_trial = func(trial_vector)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    self.population[i] = trial_vector.copy()\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector.copy()\n                        self.last_improvement = eval_count\n            \n            #Adapt CMA-ES parameters\n            indices = np.argsort(fitness)\n            xmean = np.sum(self.population[indices[:self.cma_mu]].T * self.cma_weights, axis=1)\n\n            y = (xmean - np.mean(self.population, axis=0)) / self.cma_sigma\n            self.ps = (1 - self.cma_cs) * self.ps + np.sqrt(self.cma_cs * (2 - self.cma_cs) * self.cma_mueff) * y\n            self.pc = (1 - self.cma_cs) * self.pc + np.sqrt(self.cma_cs * (2 - self.cma_cs) * self.cma_mueff) * y\n\n            self.cma_C = (1 - self.cma_cs) * self.cma_C + self.cma_cs * np.outer(self.pc, self.pc) # Rank-one update\n\n            self.cma_sigma *= np.exp((self.cma_cs / self.cma_damps) * (np.linalg.norm(self.ps)/ self.chiN -1))\n\n            self.best_fitness_history.append(self.f_opt)\n            if eval_count - self.last_improvement > self.stagnation_iter:\n                 self.cma_sigma *= 0.8  # Reduce step size upon stagnation\n                 self.F *= 0.9         # Reduce exploration\n                 self.CR *= 0.9         # Reduce exploration\n                 self.last_improvement = eval_count\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm DE_CMAES_AdaptiveRepair_Enhanced scored 0.687 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b633dbe7-c520-4d37-b25b-9f576cf8b935"], "operator": null, "metadata": {"aucs": [0.18504458499862453, 0.6914097772941383, 0.7242224974958144, 0.9241720129438699, 0.8325654715219882, 0.8951742490215961, 0.3370462969795409, 0.737518477534242, 0.8780757364471653, 0.8119916360603443, 0.9207876581691148, 0.998536448219818, 0.5323890025490392, 0.3775425111593629, 0.8851218945247933, 0.8669081488859027, 0.527644632245969, 0.9207207127309852, 0.19847555188384203, 0.5006182594981303]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-4-MA_BBOB-6", "seed": 6}
{"method_name": "LLaMEA-4", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-4", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "09f69ee2-0b24-4fee-b82a-77cecc5e9f18", "fitness": 0.7563906398140774, "name": "EnhancedSelfAdaptiveDE", "description": "Self-adaptive DE with improved strategy adaptation using a weighted historical archive and dynamic F/Cr scaling.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_initial=0.5, Cr_initial=0.9, archive_size=10, stagnation_limit=500, p_selection=0.5):\n        \"\"\"\n        Enhanced Differential Evolution with self-adaptive strategy selection, diversity maintenance, and stagnation handling.\n        Uses a weighted historical archive and dynamic F/Cr scaling.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            F_initial (float): The initial scaling factor for differential variation.\n            Cr_initial (float): The initial crossover rate.\n            archive_size (int): Size of the archive for storing successful F and Cr values.\n            stagnation_limit (int): Number of iterations without improvement before triggering a restart.\n            p_selection (float): Probability of selecting F/Cr from the archive.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_initial\n        self.Cr = Cr_initial\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n        self.archive_F = []\n        self.archive_Cr = []\n        self.archive_size = archive_size\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.strategy_success = np.zeros(3)  # Success count for each strategy\n        self.strategy_selection_prob = np.array([1/3, 1/3, 1/3]) # Initial probabilities\n        self.p_selection = p_selection # Probability of using archive values\n        self.archive_weights = []  # Weights for historical F/Cr values\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Differential Evolution with enhanced self-adaptive strategy selection, diversity maintenance, and stagnation handling.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        fevals = self.pop_size\n        last_improvement = 0\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                # Strategy selection based on success probabilities\n                strategy_idx = np.random.choice(3, p=self.strategy_selection_prob)\n\n                # Adaptation of F and Cr (using archive or default values)\n                if np.random.rand() < self.p_selection and len(self.archive_F) > 0:\n                    # Weighted selection from the archive\n                    weights = np.array(self.archive_weights) / np.sum(self.archive_weights) if np.sum(self.archive_weights) > 0 else np.ones(len(self.archive_weights)) / len(self.archive_weights)\n                    idx = np.random.choice(len(self.archive_F), p=weights)\n                    self.F = self.archive_F[idx]\n                    self.Cr = self.archive_Cr[idx]\n                else:\n                    self.F = 0.5 + 0.3 * np.random.randn() # Default F with some noise\n                    self.Cr = 0.9 + 0.1 * np.random.randn()  # Default Cr with some noise\n                \n                self.F = np.clip(self.F, 0.1, 1.0)  # Ensure F is within reasonable bounds\n                self.Cr = np.clip(self.Cr, 0.1, 1.0) # Ensure Cr is within reasonable bounds\n\n                # Mutation Strategies\n                if strategy_idx == 0:\n                    # Current-to-best/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F * (self.pop[self.best_idx] - self.pop[i]) + self.F * (x_r1 - x_r2)\n                elif strategy_idx == 1:\n                    # Rand/1\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.pop[indices]\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                else:\n                    # Current/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.pop[indices]\n                    x_mutated = self.pop[i] + self.F * (x_r1 - x_r2)\n\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                fevals += 1\n\n                if f_trial < self.fitness[i]:\n                    # Improvement\n                    delta_fitness = self.fitness[i] - f_trial  # Calculate fitness improvement\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n                    self.strategy_success[strategy_idx] += 1 #Increase strategy success count\n\n                    # Archive successful F and Cr with fitness improvement weight\n                    self.archive_F.append(self.F)\n                    self.archive_Cr.append(self.Cr)\n                    self.archive_weights.append(delta_fitness) # Weight based on fitness improvement\n\n                    if len(self.archive_F) > self.archive_size:\n                        self.archive_F.pop(0)\n                        self.archive_Cr.pop(0)\n                        self.archive_weights.pop(0)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.best_idx = i\n                        last_improvement = fevals\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increase stagnation counter\n\n\n                if fevals >= self.budget:\n                    break\n\n            # Update strategy selection probabilities based on success\n            total_success = np.sum(self.strategy_success)\n            if total_success > 0:\n                self.strategy_selection_prob = self.strategy_success / total_success\n            else:\n                self.strategy_selection_prob = np.array([1/3, 1/3, 1/3]) # Reset if no success\n\n            self.strategy_success[:] = 0 #Reset success counters\n\n            # Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_limit:\n                # Option 1: Restart with new random population\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[self.best_idx]\n                self.x_opt = self.pop[self.best_idx]\n                fevals += self.pop_size\n                self.stagnation_counter = 0\n                self.archive_F = []  # Clear archive upon restart\n                self.archive_Cr = []\n                self.archive_weights = []\n                # Resetting success history might also be a good idea here.\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedSelfAdaptiveDE scored 0.756 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["39514fee-7312-4d41-a54d-8da791c4c73e"], "operator": null, "metadata": {"aucs": [0.31540597304783735, 0.8034150472739314, 0.8302398696860745, 0.9251163527248603, 0.8203398293264634, 0.8691295436364588, 0.36157626386571684, 0.7852094181964419, 0.8444332726440811, 0.58938679864019, 0.9164283717761478, 0.9970416132627283, 0.8208194785746894, 0.8312648893561829, 0.9573776155068705, 0.8495011445283138, 0.7888377672638445, 0.9075679161524415, 0.20349582781432174, 0.7112258030039523]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-4-MA_BBOB-7", "seed": 7}
{"method_name": "LLaMEA-4", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-4", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "f5163171-3133-427f-a3fe-635f297afaa0", "fitness": 0.7958900692034565, "name": "DESOMClusterArchive", "description": "Adaptively adjusts SOM parameters and DE strategies based on the success history of different SOM regions, using a more targeted approach to parameter adaptation and exploration.", "code": "import numpy as np\n\nclass DESOMClusterArchive:\n    def __init__(self, budget=10000, dim=10, popsize=None, F=0.5, CR=0.9, archive_size=5, som_grid_size=5, num_clusters=4, neighborhood_radius_decay=0.99, learning_rate_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 5 * self.dim\n        self.F = F\n        self.CR = CR\n        self.count = 0\n        self.archive_size = archive_size\n        self.archive = []\n        self.archive_fitness = []\n        self.som_grid_size = som_grid_size\n        self.som = np.random.rand(som_grid_size, som_grid_size, self.dim)\n        self.learning_rate = 0.1\n        self.neighborhood_radius = som_grid_size // 2\n        self.neighborhood_radius_initial = self.neighborhood_radius\n        self.learning_rate_initial = self.learning_rate\n        self.num_clusters = num_clusters  # Number of clusters for parameter adaptation\n        self.cluster_assignments = np.zeros(self.popsize, dtype=int)  # Cluster assignments for each individual\n        self.cluster_F = np.full(self.num_clusters, self.F)  # F parameter for each cluster\n        self.cluster_CR = np.full(self.num_clusters, self.CR)  # CR parameter for each cluster\n        self.cluster_success = np.zeros(self.num_clusters) # Success count for each cluster\n        self.cluster_trials = np.zeros(self.num_clusters) # Trial count for each cluster\n        self.neighborhood_radius_decay = neighborhood_radius_decay\n        self.learning_rate_decay = learning_rate_decay\n        self.success_history_F = [[] for _ in range(self.num_clusters)]\n        self.success_history_CR = [[] for _ in range(self.num_clusters)]\n        self.success_memory_size = 10\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.popsize, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.count += self.popsize\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = self.population[best_index]\n        \n        # Initial Clustering using SOM\n        self.update_cluster_assignments()\n\n        while self.count < self.budget:\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(fitness)\n            \n            for i in range(self.popsize):\n                cluster_id = self.cluster_assignments[i]\n                self.cluster_trials[cluster_id] += 1\n                \n                # Adaptive F and CR based on success history\n                if self.success_history_F[cluster_id]:\n                    self.F = np.mean(self.success_history_F[cluster_id])\n                if self.success_history_CR[cluster_id]:\n                    self.CR = np.mean(self.success_history_CR[cluster_id])\n                \n                F = self.F\n                CR = self.CR\n                \n                # Mutation\n                idxs = np.random.choice(self.popsize, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n\n                # Incorporate Archive\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arch_idx = np.random.randint(0, len(self.archive))\n                    x1 = self.archive[arch_idx]\n                \n                # BMU Guided Jump with adaptive scaling\n                if np.random.rand() < 0.1:\n                    bmu_index = self.find_bmu(self.population[i])\n                    bmu = self.som[bmu_index]\n                    bmu_influence = np.linalg.norm(self.population[i] - bmu) / np.linalg.norm(ub - lb)\n                    mutant = x1 + F * (x2 - x3) + bmu_influence * (bmu - self.population[i])\n                else:\n                    mutant = x1 + F * (x2 - x3)\n\n\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(cross_points, mutant, self.population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                self.count += 1\n\n                if f < fitness[i]:\n                    new_fitness[i] = f\n                    new_population[i] = trial_vector\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                        \n                    # Update Archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i])\n                        self.archive_fitness.append(fitness[i])\n                    else:\n                        max_archive_fitness_index = np.argmax(self.archive_fitness)\n                        if fitness[i] < self.archive_fitness[max_archive_fitness_index]:\n                            self.archive[max_archive_fitness_index] = self.population[i]\n                            self.archive_fitness[max_archive_fitness_index] = fitness[i]\n                    self.cluster_success[cluster_id] += 1\n                    \n                    # Update Success History\n                    self.success_history_F[cluster_id].append(F)\n                    self.success_history_CR[cluster_id].append(CR)\n                    if len(self.success_history_F[cluster_id]) > self.success_memory_size:\n                        self.success_history_F[cluster_id].pop(0)\n                        self.success_history_CR[cluster_id].pop(0)\n\n\n            # Update population\n            self.population = new_population\n            fitness = new_fitness\n\n            # Update SOM\n            for j in range(self.popsize):\n                self.update_som(self.population[j], self.find_bmu(self.population[j]))\n                \n            self.update_cluster_assignments()\n\n            # Adjust F and CR for each cluster based on success ratio (less aggressive)\n            for k in range(self.num_clusters):\n                if self.cluster_trials[k] > 0:\n                    success_rate = self.cluster_success[k] / self.cluster_trials[k]\n                    if success_rate > 0.2:\n                        self.cluster_F[k] = max(0.1, self.cluster_F[k] - 0.02)\n                        self.cluster_CR[k] = min(0.95, self.cluster_CR[k] + 0.02)\n                    elif success_rate < 0.1:\n                        self.cluster_F[k] = min(0.9, self.cluster_F[k] + 0.02)\n                        self.cluster_CR[k] = max(0.05, self.cluster_CR[k] - 0.02)\n                self.cluster_success[k] = 0 # Reset success count\n                self.cluster_trials[k] = 0 # Reset trial count\n\n            # Decay SOM parameters (slower decay)\n            self.neighborhood_radius = self.neighborhood_radius * (0.99 + 0.005 * np.random.rand())\n            self.learning_rate = self.learning_rate * (0.99 + 0.005 * np.random.rand())\n            if self.count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n    \n\n    def find_bmu(self, individual):\n        \"\"\"Find the best matching unit (BMU) for an individual.\"\"\"\n        distances = np.linalg.norm(self.som - individual, axis=2)\n        return np.unravel_index(np.argmin(distances), distances.shape)\n\n    def update_som(self, individual, bmu_index):\n        \"\"\"Update the SOM nodes based on the individual and BMU.\"\"\"\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                distance = np.sqrt((i - bmu_index[0])**2 + (j - bmu_index[1])**2)\n                if distance <= self.neighborhood_radius:\n                    influence = np.exp(-distance**2 / (2 * self.neighborhood_radius**2))\n                    self.som[i, j] += self.learning_rate * influence * (individual - self.som[i, j])\n    \n    def update_cluster_assignments(self):\n        \"\"\"Assign each individual to a cluster based on SOM proximity.\"\"\"\n        for i in range(self.popsize):\n            bmu_index = self.find_bmu(self.population[i])\n            self.cluster_assignments[i] = (bmu_index[0] * self.som_grid_size + bmu_index[1]) % self.num_clusters", "configspace": "", "generation": 8, "feedback": "The algorithm DESOMClusterArchive scored 0.796 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7f9e83f2-08f3-4e87-97ab-a08adabf353e"], "operator": null, "metadata": {"aucs": [0.4960101689570965, 0.7778860745330748, 0.8005503188886578, 0.9161942543331223, 0.8290999588985348, 0.8652650226349599, 0.7835813201436734, 0.7888028992638646, 0.8460916082438447, 0.7958522239800078, 0.9029246665428216, 0.9959827079165584, 0.5350131942971887, 0.8615189875437689, 0.9407249605617661, 0.8617602992175057, 0.785757672057436, 0.896832304250373, 0.7146920870660456, 0.523260654738828]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-4-MA_BBOB-8", "seed": 8}
{"method_name": "LLaMEA-4", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-4", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "cbf38d94-b6ef-4882-a861-fa3ea9d17741", "fitness": 0.8236791201775165, "name": "AdaptiveDEwithSelfAdaptiveLocalSearchImproved", "description": "Adaptive Differential Evolution with Success-History based parameter adaptation, self-adaptive local search probability using a separate success rate for F and Cr, and improved local search with adaptive step size.", "code": "import numpy as np\n\nclass AdaptiveDEwithSelfAdaptiveLocalSearchImproved:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=10, initial_local_search_prob=0.1, archive_size=100, ls_decay=0.99, ls_increase=1.01, ls_step_size=0.1, ls_step_decay=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.local_search_prob = initial_local_search_prob\n        self.archive_size = archive_size\n        self.F_memory = np.ones(self.memory_size) * 0.5\n        self.Cr_memory = np.ones(self.memory_size) * 0.9\n        self.archive = []\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.ls_decay = ls_decay\n        self.ls_increase = ls_increase\n        self.ls_step_size = ls_step_size\n        self.ls_step_decay = ls_step_decay\n        self.successful_F = []\n        self.successful_Cr = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        previous_f_opt = self.f_opt\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation using success history with weighted sampling\n                if self.successful_F:\n                    F = np.random.choice(self.successful_F)\n                else:\n                    F = 0.5  # Default value if no successful F values yet\n\n                if self.successful_Cr:\n                    Cr = np.random.choice(self.successful_Cr)\n                else:\n                    Cr = 0.9  # Default value if no successful Cr values yet\n\n                indices = np.random.choice(self.pop_size, size=3, replace=False)\n                a, b, c = indices[0], indices[1], indices[2]\n\n                # Differential Evolution Mutation\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                mask = np.random.rand(self.dim) < Cr\n                trial[mask] = mutant[mask]\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.local_search(trial, func)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.archive.append(population[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    self.successful_F.append(F)\n                    self.successful_Cr.append(Cr)\n                    if len(self.successful_F) > self.memory_size:\n                        self.successful_F.pop(0)\n                        self.successful_Cr.pop(0)\n\n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            if self.f_opt < previous_f_opt:\n                self.local_search_prob = min(1.0, self.local_search_prob * self.ls_increase)\n                self.ls_step_size = min(0.1, self.ls_step_size/self.ls_step_decay)\n            else:\n                self.local_search_prob = max(0.01, self.local_search_prob * self.ls_decay)\n                self.ls_step_size = max(1e-6, self.ls_step_size * self.ls_step_decay)\n            previous_f_opt = self.f_opt\n                \n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func):\n        # Local search using random step with adaptive step size\n        new_x = x + np.random.uniform(-self.ls_step_size, self.ls_step_size, size=self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        return new_x", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDEwithSelfAdaptiveLocalSearchImproved scored 0.824 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["10a5f196-6334-4328-a26f-3b6271707947"], "operator": null, "metadata": {"aucs": [0.5958947280172151, 0.8702969814049015, 0.8493482650178965, 0.9490055551327065, 0.886825742276864, 0.9050782866004551, 0.8628925125169316, 0.48645612183221965, 0.9075214420039107, 0.876884365519842, 0.9480857152895359, 0.9894671411371215, 0.6433202198237803, 0.8734212803046704, 0.914215664615393, 0.8729691553504011, 0.8282714283278125, 0.9286593857915161, 0.7656396333939666, 0.5193287791931904]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-4-MA_BBOB-9", "seed": 9}
{"method_name": "LLaMEA-5", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-5", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before.", "Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "2624e7c3-75a3-42e2-9270-a9475be16690", "fitness": 0.6457775266787098, "name": "AdaptiveSuccessPSO_Enhanced", "description": "PSO with adaptive coefficients based on a combination of success rate and distance to the global best, employing a dynamic local search intensification based on particle fitness ranking.", "code": "import numpy as np\n\nclass AdaptiveSuccessPSO_Enhanced:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_max=2.0, social_max=2.0,\n                 initial_velocity_clamp=0.5, success_rate_window=10, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_max = cognitive_max\n        self.social_max = social_max\n        self.velocity_clamp = initial_velocity_clamp\n        self.success_rate_window = success_rate_window\n        self.success_rates = np.zeros(pop_size)\n        self.success_counts = np.zeros(pop_size)\n        self.iteration_count = 0\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-(ub - lb) * 0.1, (ub - lb) * 0.1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n\n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Optimization loop\n        inertia_weight = 0.9\n        inertia_decay = 0.995\n\n        while self.budget > 0:\n            # Sort fitnesses and get ranks\n            ranked_indices = np.argsort(fitness)\n            ranks = np.empty_like(ranked_indices)\n            ranks[ranked_indices] = np.arange(self.pop_size)\n\n            # Normalize ranks to [0, 1]\n            normalized_ranks = ranks / (self.pop_size - 1)\n\n            # Adaptive coefficients based on success rate and distance to global best\n            distance_to_global_best = np.linalg.norm(population - global_best_position, axis=1)\n            normalized_distances = distance_to_global_best / np.max(distance_to_global_best)  # Normalize distances\n\n            cognitive_coeffs = 1.0 + (self.cognitive_max - 1.0) * (1 - self.success_rates) * normalized_distances\n            social_coeffs = 1.0 + (self.social_max - 1.0) * self.success_rates * (1 - normalized_distances)\n\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeffs[i] * r1 * (personal_best_positions[i] - population[i]) +\n                                 social_coeffs[i] * r2 * (global_best_position - population[i]))\n\n                # Adaptive velocity clamping based on population diversity\n                diversity = np.mean(np.std(population, axis=0))\n                velocity_clamp = self.velocity_clamp * (1 + diversity)\n\n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -velocity_clamp * (ub - lb), velocity_clamp * (ub - lb))\n\n                # Update position\n                new_position = population[i] + velocities[i]\n\n                # Handle boundary constraints (clip)\n                new_position = np.clip(new_position, lb, ub)\n\n                # Local search intensification based on rank\n                if np.random.rand() < self.local_search_probability * (1 - normalized_ranks[i]):  # Higher ranked particles have higher probability\n                    # Perform a small random perturbation around the current position\n                    perturbation = np.random.uniform(-0.05 * (ub - lb), 0.05 * (ub - lb), size=self.dim)  # Smaller perturbation\n                    new_position = np.clip(new_position + perturbation, lb, ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    self.success_counts[i] += 1\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n                population[i] = new_position\n                fitness[i] = new_fitness  # Update fitness array\n\n            inertia_weight *= inertia_decay  # Decrease inertia weight\n\n            # Update success rates every window size iterations\n            if self.iteration_count % self.success_rate_window == 0:\n                self.success_rates = self.success_counts / self.success_rate_window\n                self.success_counts[:] = 0  # Reset success counts\n\n            self.iteration_count += 1\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveSuccessPSO_Enhanced scored 0.646 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["652c14c9-0ba1-4bed-8677-dfd3eaddad00"], "operator": null, "metadata": {"aucs": [0.17364312378051983, 0.2511960473069952, 0.7387339456281705, 0.9226278905304475, 0.8302678077753375, 0.7985827037243216, 0.32910250157891996, 0.5325767180559845, 0.8375514511274044, 0.8029466202127831, 0.8585920146711326, 0.9957016704676327, 0.2577558938791129, 0.5714136217557485, 0.831600971222395, 0.8441465858904459, 0.6176918004237784, 0.8938750217155754, 0.33764658380943646, 0.4898975600180583]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-5-MA_BBOB-5", "seed": 5}
{"method_name": "LLaMEA-5", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-5", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before.", "Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "6abbe250-3c78-4f4d-b5ce-47eed0df0862", "fitness": 0.8118225976101032, "name": "AdaptiveDEOrthogonalCauchy", "description": "Simplified Adaptive Differential Evolution with adaptive F and CR, orthogonal crossover, and a small Cauchy perturbation for enhanced exploration around the best solution.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonalCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, cauchy_scale=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.success_F = []\n        self.success_CR = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutation(self, i, func):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        mutation_vector = x_r1 + self.F * (x_r2 - x_r3)\n\n        # Cauchy perturbation near the best solution\n        mutation_vector += self.cauchy_scale * np.random.standard_cauchy(size=self.dim) * (self.best_position - self.pop[i])\n        \n        mutation_vector = np.clip(mutation_vector, func.bounds.lb, func.bounds.ub)\n        return mutation_vector\n\n    def orthogonal_crossover(self, v_i, i):\n        u_i = self.pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.CR:\n                u_i[j] = v_i[j]\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            self.success_F.append(self.F)\n            self.success_CR.append(self.CR)\n\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n\n\n    def update_parameters(self):\n        if self.success_F:\n            self.F = 0.8 * self.F + 0.2 * np.mean(self.success_F)\n            self.CR = 0.8 * self.CR + 0.2 * np.mean(self.success_CR)\n\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.CR = np.clip(self.CR, 0.1, 0.9)\n        self.success_F = []\n        self.success_CR = []\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutation(i, func)\n                u_i = self.orthogonal_crossover(v_i, i)\n                u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)                \n                self.selection(func, u_i, i)\n            self.update_parameters()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDEOrthogonalCauchy scored 0.812 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f308851b-34f6-42a2-8ce9-4ebb0aed553b"], "operator": null, "metadata": {"aucs": [0.4488915059812565, 0.8652781010594652, 0.7622936929031344, 0.953968372164209, 0.8911610156942859, 0.9109301432970347, 0.8606966146220654, 0.8744021345197681, 0.885349584017965, 0.8593049688323581, 0.9461468329606828, 0.9928928828959188, 0.3251906830223289, 0.8839938078778017, 0.9455972524526356, 0.9190132881631194, 0.8581987327373992, 0.942097882930384, 0.5824383650159874, 0.528606091054263]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-5-MA_BBOB-6", "seed": 6}
{"method_name": "LLaMEA-5", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-5", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before.", "Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "2090f1a6-3df7-41f3-b337-22436fd042a2", "fitness": 0.861289619460457, "name": "NeighborhoodAdaptiveDE", "description": "Adaptive Differential Evolution with a neighborhood-based mutation and orthogonal crossover.", "code": "import numpy as np\n\nclass NeighborhoodAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, adapt_freq=50, stagnation_threshold=1000, learning_rate=0.1, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.adapt_freq = adapt_freq\n        self.stagnation_threshold = stagnation_threshold\n        self.learning_rate = learning_rate\n        self.neighborhood_size = neighborhood_size\n        self.f = 0.5\n        self.cr = 0.9\n        self.success_f = []\n        self.success_cr = []\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.last_improvement = 0\n\n        best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_idx]\n        self.x_opt = self.population[best_idx]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Neighborhood-based Mutation\n                neighbors = np.random.choice(np.arange(self.pop_size), self.neighborhood_size, replace=False)\n                best_neighbor_idx = neighbors[np.argmin(self.fitness[neighbors])]\n                \n                idxs = np.random.choice(np.arange(self.pop_size), 2, replace=False)\n                x1, x2 = self.population[idxs]\n\n                v = self.population[best_neighbor_idx] + self.f * (x1 - x2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n                \n                # Orthogonal Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Evaluation\n                f_new = func(u)\n                self.evals += 1\n                \n                # Selection\n                if f_new < self.fitness[i]:\n                    self.success_f.append(self.f)\n                    self.success_cr.append(self.cr)\n                    self.fitness[i] = f_new\n                    self.population[i] = u\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = u\n                        self.best_fitness_history.append(self.f_opt)\n                        self.last_improvement = self.evals\n\n            # Adaptive Parameter Control\n            if self.evals % self.adapt_freq == 0:\n                if self.success_f:\n                    self.f = (1 - self.learning_rate) * self.f + self.learning_rate * np.mean(self.success_f)\n                    self.cr = (1 - self.learning_rate) * self.cr + self.learning_rate * np.mean(self.success_cr)\n                self.f = np.clip(self.f, 0.1, 0.9)\n                self.cr = np.clip(self.cr, 0.1, 1.0)\n                self.success_f = []\n                self.success_cr = []\n            \n            # Stagnation Check and Restart\n            if self.evals - self.last_improvement > self.stagnation_threshold:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size\n                best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.population[best_idx]\n                self.last_improvement = self.evals\n                self.best_fitness_history.append(self.f_opt)\n\n\n            if self.evals >= self.budget:\n                break\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm NeighborhoodAdaptiveDE scored 0.861 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e80c9b07-9e4a-47ea-b07f-4479fdb1d3e3"], "operator": null, "metadata": {"aucs": [0.6767843852158779, 0.8223678378167558, 0.865327560127738, 0.9527354756820765, 0.8823093556509845, 0.9036146726216274, 0.8532564712350131, 0.8612545530146006, 0.8937926821278295, 0.8544885369849906, 0.9414145770921373, 0.9956578664302538, 0.8629289357446537, 0.8911559092474174, 0.9662509858344767, 0.9050021526585408, 0.8342250038767512, 0.9297679784913813, 0.8112421338398238, 0.52221531551621]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-5-MA_BBOB-7", "seed": 7}
{"method_name": "LLaMEA-5", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-5", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before.", "Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "63c25a13-6cbe-461f-82fe-efd158076997", "fitness": 0.7692230969970691, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with ensemble of mutation strategies and archive.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=100, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = F  # Default scaling factor\n        self.CR = CR  # Default crossover rate\n        self.archive = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation strategies\n                if np.random.rand() < 0.3:  # \"DE/rand/1\"\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[indices]\n                    x_mutated = self.population[i] + self.F * (x_r1 - x_r2) + self.F * (x_r3-self.population[i])\n                elif np.random.rand() < 0.6:  # \"DE/best/1\"\n                    x_best = self.population[np.argmin(self.fitness)]\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.population[indices]\n                    x_mutated = x_best + self.F * (x_r1 - x_r2)\n                else: #DE/current-to-rand/1\n                    indices = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = self.population[indices]\n                    x_mutated = self.population[i] + np.random.rand()*(x_r1 - self.population[i]) + self.F * (x_r2 - self.population[i])\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n                    \n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(x_trial)\n                    else:\n                        # Replace a random element in the archive\n                        idx = np.random.randint(self.archive_size)\n                        self.archive[idx] = x_trial\n                        \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n                elif len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i])\n                else:\n                    idx = np.random.randint(self.archive_size)\n                    self.archive[idx] = self.population[i]\n\n                if self.budget <= 0:\n                    break\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.769 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.25868740517835, 0.8806979128001887, 0.8918485642435209, 0.9568083681570151, 0.8957113729748013, 0.9252000103992943, 0.3362418330544683, 0.8799151310256981, 0.9054898516395118, 0.24867985162749384, 0.9475182235050951, 0.9982375750684599, 0.8715111130498769, 0.910577563881524, 0.9582171956092693, 0.9270591883718351, 0.8547042069359616, 0.9444850830703352, 0.25265425803740704, 0.5402172313112796]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-5-MA_BBOB-8", "seed": 8}
{"method_name": "LLaMEA-5", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-5", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before.", "Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "1dc1ed7e-aeb5-49f8-bab6-b6067b5e1bb6", "fitness": 0.7738467675195311, "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with an improved parent selection mechanism using tournament selection and adaptive crossover rate based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=40, Cr=0.7, F=0.6, archive_size=10, tournament_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.Cr = Cr\n        self.F = F\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.archive = []\n        self.archive_fitness = []\n        self.archive_size = archive_size\n        self.success_history = []\n        self.tournament_size = tournament_size\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index].copy()\n\n    def update_archive(self, x, f):\n        if len(self.archive) < self.archive_size:\n            self.archive.append(x)\n            self.archive_fitness.append(f)\n        else:\n            worst_index = np.argmax(self.archive_fitness)\n            if f < self.archive_fitness[worst_index]:\n                self.archive[worst_index] = x\n                self.archive_fitness[worst_index] = f\n\n    def tournament_selection(self):\n        idxs = np.random.choice(self.pop_size, self.tournament_size, replace=False)\n        tournament_fitness = self.fitness[idxs]\n        winner_index = idxs[np.argmin(tournament_fitness)]\n        return winner_index\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Parent selection using tournament selection\n            idx_p = self.tournament_selection()\n            x_p = self.pop[idx_p]\n\n            # Adaptive F\n            if self.success_history:\n                self.F = np.clip(np.mean(self.success_history), 0.1, 0.9)\n            \n            # Mutation\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x_r1, x_r2 = self.pop[idxs]\n\n            # Stagnation check: If the improvement is very small, use archive\n            if np.abs(self.fitness[i] - self.f_opt) < 1e-6 and self.archive:\n                idx_a = np.random.randint(0, len(self.archive))\n                x_r1 = self.archive[idx_a]  # Use archive member for mutation\n            \n            x_mutated = x_p + self.F * (x_r1 - x_r2)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Adaptive Crossover\n            diversity = np.std(self.fitness)\n            Cr = self.Cr * (1 + diversity)  # Increase Cr when diversity is high\n            Cr = np.clip(Cr, 0.1, 0.9)\n            \n            # Crossover\n            x_trial = np.copy(self.pop[i])\n            j_rand = np.random.randint(0, self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Evaluation\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            # Selection\n            if f_trial < self.fitness[i]:\n                self.success_history.append(self.F)\n                if len(self.success_history) > 10:\n                    self.success_history.pop(0)\n                \n                self.pop[i] = x_trial\n                self.fitness[i] = f_trial\n                self.update_archive(x_trial, f_trial)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n            else:\n                self.success_history = [] # Reset success history if no improvement\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.archive = []\n        self.archive_fitness = []\n        self.success_history = []\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.774 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f40c4a00-3b8f-4bf9-8069-6b426133dd61"], "operator": null, "metadata": {"aucs": [0.37292608994133347, 0.7852077034043798, 0.8040402075589324, 0.9223878241762916, 0.8293779949741262, 0.8773518314569249, 0.7706309757591834, 0.7838076447497312, 0.8435641192700699, 0.801045077642591, 0.9112686132691148, 0.9980192825953372, 0.6740420456667684, 0.8077502696903915, 0.9536893133338884, 0.8637654247121893, 0.7330539732605006, 0.9046871073741699, 0.3124878687655822, 0.527831982789116]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-5-MA_BBOB-9", "seed": 9}
{"method_name": "LLaMEA-1", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-1", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "e7da9faf-4823-45b2-a7da-88bfc6a01fa6", "fitness": 0.6154249403276454, "name": "EnhancedAdaptiveHybridPSO_DE_SA", "description": "Enhanced Adaptive Hybrid PSO-DE with Self-Adaptive Parameters, Crossover-based Population Initialization, and Adaptive Temperature Schedule.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE_SA:\n    def __init__(self, budget=10000, dim=10, pop_size=40, \n                 pso_inertia_max=0.9, pso_inertia_min=0.4, \n                 pso_cognitive=1.5, pso_social=1.5, \n                 de_cr=0.7, de_f=0.8, \n                 restart_patience=500, switch_prob=0.5,\n                 success_history_size=10, inertia_adapt_rate=0.1,\n                 cr_adapt_rate=0.1, f_adapt_rate=0.1,\n                 sa_initial_temp=1.0, sa_cooling_rate=0.95,\n                 fitness_adapt_rate=0.1, param_adapt_prob=0.1,\n                 crossover_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pso_inertia_max = pso_inertia_max\n        self.pso_inertia_min = pso_inertia_min\n        self.pso_cognitive = pso_cognitive\n        self.pso_social = pso_social\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.restart_patience = restart_patience\n        self.switch_prob = switch_prob  # Probability of switching to DE\n        self.success_history_size = success_history_size\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.inertia_adapt_rate = inertia_adapt_rate\n        self.cr_adapt_rate = cr_adapt_rate\n        self.f_adapt_rate = f_adapt_rate\n        self.sa_initial_temp = sa_initial_temp\n        self.sa_cooling_rate = sa_cooling_rate\n        self.current_temp = sa_initial_temp\n        self.fitness_adapt_rate = fitness_adapt_rate\n        self.param_adapt_prob = param_adapt_prob\n        self.crossover_rate = crossover_rate\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.Inf\n        self.eval_count = 0\n        self.no_improvement_count = 0\n        self.pso_inertia = self.pso_inertia_max # Initialize inertia\n\n    def initialize_population(self, func):\n        # Crossover-based Initialization\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        for i in range(1, self.pop_size):\n            if np.random.rand() < self.crossover_rate:\n                idx = np.random.randint(0, i)\n                crossover_point = np.random.randint(0, self.dim)\n                self.population[i, :crossover_point] = self.population[idx, :crossover_point].copy()\n\n        self.velocities = np.zeros((self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        \n    def pso_update(self, func):\n        inertia = self.pso_inertia\n        cognitive_coeff = self.pso_cognitive\n        social_coeff = self.pso_social\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        cognitive_component = cognitive_coeff * r1 * (self.personal_best_positions - self.population)\n        social_component = social_coeff * r2 * (self.global_best_position - self.population)\n\n        self.velocities = inertia * self.velocities + cognitive_component + social_component\n        self.population += self.velocities\n        self.population = np.clip(self.population, func.bounds.lb, func.bounds.ub)\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n\n        improved_count = 0\n        fitness_improvement = 0.0\n        for i in range(self.pop_size):\n            if new_fitness[i] < self.fitness[i]:\n                fitness_improvement += (self.fitness[i] - new_fitness[i])\n                self.fitness[i] = new_fitness[i]\n                if new_fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n                    if new_fitness[i] < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness[i]\n                        self.global_best_position = self.population[i].copy()\n                        self.no_improvement_count = 0\n                        \n                improved_count += 1\n            else:\n                self.no_improvement_count += 1\n\n        improved = improved_count > 0\n        self.pso_success_history.append(improved)\n        if len(self.pso_success_history) > self.success_history_size:\n            self.pso_success_history.pop(0)\n            \n        if improved:\n            self.pso_inertia = max(self.pso_inertia_min, self.pso_inertia - self.inertia_adapt_rate)\n        else:\n            self.pso_inertia = min(self.pso_inertia_max, self.pso_inertia + self.inertia_adapt_rate)\n            \n        if improved_count > 0:\n            self.pso_cognitive = min(2.0, self.pso_cognitive + self.fitness_adapt_rate * (fitness_improvement / improved_count))\n            self.pso_social = max(1.0, self.pso_social - self.fitness_adapt_rate * (fitness_improvement / improved_count))\n\n        # Self-Adaptation of Parameters\n        if np.random.rand() < self.param_adapt_prob:\n            self.pso_cognitive += np.random.uniform(-0.1, 0.1)\n            self.pso_social += np.random.uniform(-0.1, 0.1)\n            self.pso_cognitive = np.clip(self.pso_cognitive, 1.0, 2.0)\n            self.pso_social = np.clip(self.pso_social, 1.0, 2.0)\n\n    def de_update(self, func):\n        improved_count = 0\n        fitness_improvement = 0.0\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            \n            mutant = self.population[a] + self.de_f * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            trial = self.population[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() <= self.de_cr or j == np.random.randint(0, self.dim):\n                    trial[j] = mutant[j]\n\n            f = func(trial)\n            self.eval_count += 1\n\n            delta_fitness = f - self.fitness[i]\n            if delta_fitness < 0 or np.random.rand() < np.exp(-delta_fitness / self.current_temp):\n                if delta_fitness < 0:\n                  fitness_improvement += abs(delta_fitness)\n                self.population[i] = trial\n                self.fitness[i] = f\n                \n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = trial.copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = trial.copy()\n                    self.no_improvement_count = 0\n                \n                improved_count += 1\n            else:\n                self.no_improvement_count +=1\n        \n        improved = improved_count > 0\n        self.de_success_history.append(improved)\n        if len(self.de_success_history) > self.success_history_size:\n            self.de_success_history.pop(0)\n\n        if improved:\n            self.de_cr = min(1.0, self.de_cr + self.cr_adapt_rate)\n            self.de_f = max(0.0, self.de_f - self.f_adapt_rate)\n        else:\n            self.de_cr = max(0.0, self.de_cr - self.cr_adapt_rate)\n            self.de_f = min(1.0, self.de_f + self.f_adapt_rate)\n\n        if improved_count > 0:\n            self.de_cr = max(0.0, min(1.0, self.de_cr + self.fitness_adapt_rate * (fitness_improvement / improved_count)))\n            self.de_f = max(0.0, min(1.0, self.de_f - self.fitness_adapt_rate * (fitness_improvement / improved_count)))\n\n        # Self-Adaptation of Parameters\n        if np.random.rand() < self.param_adapt_prob:\n            self.de_cr += np.random.uniform(-0.1, 0.1)\n            self.de_f += np.random.uniform(-0.1, 0.1)\n            self.de_cr = np.clip(self.de_cr, 0.0, 1.0)\n            self.de_f = np.clip(self.de_f, 0.0, 1.0)\n            \n    def should_use_de(self):\n        if not self.pso_success_history or not self.de_success_history:\n            return np.random.rand() < self.switch_prob\n\n        pso_success_rate = sum(self.pso_success_history) / len(self.pso_success_history)\n        de_success_rate = sum(self.de_success_history) / len(self.de_success_history)\n\n        return de_success_rate > pso_success_rate\n                    \n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        self.initialize_population(func)\n\n        # Adaptive Temperature Schedule\n        adaptive_cooling_rate = self.sa_cooling_rate\n\n        while self.eval_count < self.budget:\n            if self.should_use_de():\n                self.de_update(func)\n            else:\n                self.pso_update(func)\n            \n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position\n            \n            if self.no_improvement_count > self.restart_patience:\n                self.initialize_population(func)\n                self.no_improvement_count = 0 # reset no improvement counter\n            \n            # Adaptive Cooling\n            if self.global_best_fitness < self.f_opt:\n                 adaptive_cooling_rate = max(0.9, adaptive_cooling_rate - 0.01)  # Faster cooling if improving\n            else:\n                 adaptive_cooling_rate = min(0.999, adaptive_cooling_rate + 0.001)  # Slower cooling if stagnating\n            \n            self.current_temp *= adaptive_cooling_rate # cool down the temperature\n            self.current_temp = max(0.0001, self.current_temp) # avoid temp = 0\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_DE_SA scored 0.615 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9b26f5a9-5dba-40fd-a09d-d1364731ad11"], "operator": null, "metadata": {"aucs": [0.27460357808915525, 0.39677461654216817, 0.8961049642534943, 0.9426141903978844, 0.5484573798927903, 0.9229012317190346, 0.3741280600971487, 0.4790887908774244, 0.8969356410935361, 0.8857140787097244, 0.316037437158873, 0.9935409707001243, 0.34037644392280586, 0.2837065955524537, 0.7365850549613759, 0.9110350368046414, 0.4374739988143219, 0.9358123440304351, 0.21588005037853253, 0.5207283425569831]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-1-MA_BBOB-4", "seed": 4}
{"method_name": "LLaMEA-1", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-1", "budget": 100, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 12, "elitism": false}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "07743c4a-ad45-4537-9093-0eb96aacf4c0", "fitness": 0.7477768049650292, "name": "SelfAdaptiveDifferentialEvolution", "description": "A population-based algorithm where individuals explore and exploit the search space using a combination of differential evolution and a self-adaptive strategy for controlling exploration.", "code": "import numpy as np\n\nclass SelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        \"\"\"\n        Initialize the Self-Adaptive Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            F (float): The initial scaling factor for differential mutation.\n            CR (float): The initial crossover rate.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.best_x = None\n        self.best_f = np.inf\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random solutions within the bounds.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_x = self.pop[np.argmin(self.fitness)]\n        self.best_f = np.min(self.fitness)\n\n    def mutate(self, pop, F):\n        \"\"\"\n        Perform differential mutation to create a mutated population.\n        \"\"\"\n        mutated_pop = np.zeros_like(pop)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = pop[idxs]\n            mutated_pop[i] = x_r1 + F * (x_r2 - x_r3)\n        return mutated_pop\n\n    def crossover(self, pop, mutated_pop, CR):\n        \"\"\"\n        Perform crossover to create a trial population.\n        \"\"\"\n        trial_pop = np.zeros_like(pop)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() <= CR or j == np.random.randint(self.dim):\n                    trial_pop[i, j] = mutated_pop[i, j]\n                else:\n                    trial_pop[i, j] = pop[i, j]\n        return trial_pop\n\n    def selection(self, func, trial_pop):\n        \"\"\"\n        Perform selection to update the population.\n        \"\"\"\n        for i in range(self.pop_size):\n            f_trial = func(trial_pop[i])\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_pop[i]\n                self.fitness[i] = f_trial\n                if f_trial < self.best_f:\n                    self.best_f = f_trial\n                    self.best_x = trial_pop[i]\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using Self-Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The black-box function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.initialize_population(func)\n        evals = self.pop_size  # Account for initial population evaluations\n\n        while evals < self.budget:\n            # Self-adaptive parameters\n            F = np.random.normal(self.F, 0.1, self.pop_size)\n            F = np.clip(F, 0.1, 1.0)\n            CR = np.random.normal(self.CR, 0.1, self.pop_size)\n            CR = np.clip(CR, 0.1, 1.0)\n\n            mutated_pop = self.mutate(self.pop, self.F)\n\n            # Boundary handling: clip the mutated vectors\n            mutated_pop = np.clip(mutated_pop, func.bounds.lb, func.bounds.ub)\n\n            trial_pop = self.crossover(self.pop, mutated_pop, self.CR)\n\n            # Boundary handling: clip the trial vectors\n            trial_pop = np.clip(trial_pop, func.bounds.lb, func.bounds.ub)\n\n            self.selection(func, trial_pop)\n            evals += self.pop_size\n\n        return self.best_f, self.best_x", "configspace": "", "generation": 0, "feedback": "The algorithm SelfAdaptiveDifferentialEvolution scored 0.748 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.6314315649786415, 0.8483688389581377, 0.5531213020495869, 0.9348027588715511, 0.8908494026754679, 0.894046943842429, 0.8420350848161163, 0.8288593268912342, 0.8654247310067298, 0.25159801826845796, 0.9330094677596219, 0.9950144030216794, 0.4179124423620768, 0.8590982266390589, 0.8184213100047186, 0.8899789876833276, 0.8489075492914534, 0.914941271596707, 0.2329470180346821, 0.5047674505489048]}}, "log_dir": "results/MA_BBOB/run-LLaMEA-1-MA_BBOB-7", "seed": 7}
