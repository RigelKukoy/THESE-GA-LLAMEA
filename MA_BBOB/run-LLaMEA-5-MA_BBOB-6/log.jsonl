{"id": "7690e5ba-1f3e-42c5-844d-01bb3a3a91b8", "fitness": -Infinity, "name": "CMAES", "description": "Covariance matrix adaptation evolution strategy with a population size adaptation mechanism based on the success rate of individuals.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_mu=None, c_1=None, sigma0=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n\n        # Strategy parameter setting: Adaptation\n        self.cs = cs  # Path length control parameter\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.cs # Damping for step-size increasing\n        self.c_mu = c_mu if c_mu is not None else min(1, self.mu / self.popsize) # Learning rate for rank-mu update\n        self.c_1 = c_1 if c_1 is not None else min(1, self.dim / (self.popsize**2))# Learning rate for rank-one update\n        self.sigma = sigma0 # Overall stepsize\n\n        # Initialize dynamic (internal) strategy parameters and constants\n        self.pc = np.zeros(self.dim) # Evolution path for covariance matrix\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        self.B = np.eye(self.dim)       # B defines the coordinate system\n        self.D = np.ones(self.dim)       # Diagonal matrix D defines the scaling\n        self.C = self.B @ np.diag(self.D**2) @ self.B.T # Covariance matrix C = B*diag(D.^2)*B'\n        self.invC = self.B @ np.diag(self.D**-2) @ self.B.T # Inverse of C\n\n        self.m = np.zeros(self.dim)    # Mean value\n        self.weights = np.array([self.c_mu * (np.log(self.mu+1) - np.log(i+1)) for i in range(self.mu)])\n        self.weights /= sum(self.weights)\n        self.mueff = sum(self.weights)**2 / sum(self.weights**2)\n\n        self.success_rate = 0.5\n        self.adapt_rate = 0.1\n        self.min_popsize = 4\n        self.max_popsize = 100\n        self.archive_f = []\n        self.archive_x = []\n\n    def sample(self):\n        z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n        x = self.m + self.sigma * (self.B @ (self.D * z.T)).T\n        return x, z\n\n    def update(self, x, z, fvalues):\n        idx = np.argsort(fvalues)\n        x = x[idx]\n        z = z[idx]\n\n        # Save the best solution\n        if len(self.archive_f) < 10:\n            self.archive_f.append(fvalues[idx[0]])\n            self.archive_x.append(x[0])\n        else:\n            if fvalues[idx[0]] < max(self.archive_f):\n                self.archive_x[self.archive_f.index(max(self.archive_f))] = x[0]\n                self.archive_f[self.archive_f.index(max(self.archive_f))] = fvalues[idx[0]]\n        \n        # Mean update\n        m_old = self.m.copy()\n        self.m = np.sum(self.weights[:,None] * x[:self.mu], axis=0)\n        \n        # Cumulation\n        self.ps = (1-self.cs) * self.ps + np.sqrt(self.cs*(2-self.cs)*self.mueff) * self.B @ z[:self.mu].T @ self.weights\n        hsig = (np.linalg.norm(self.ps)/np.sqrt(1-(1-self.cs)**(2*self.budget/self.popsize))/np.sqrt(self.dim)) < (1.4 + 2/(self.dim+1))\n        self.pc = (1-self.damps) * self.pc + hsig * np.sqrt(self.damps*(2-self.damps)*self.mueff) * (self.m - m_old)/self.sigma\n\n        # Adapt Covariance Matrix C\n        self.C = (1-self.c_1-self.c_mu) * self.C \\\n            + self.c_1 * (self.pc[:,None] @ self.pc[None,:]) \\\n            + self.c_mu * (self.weights * z[:self.mu].T) @ (z[:self.mu] @ self.B.T * self.B)\n\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T # enforce symmetry\n        self.D, self.B = np.linalg.eig(self.C)    # Eigen decomposition, B == normalized eigenvectors\n        self.D = np.sqrt(self.D)             # D contains standard deviations of principal components\n\n        self.invC = self.B @ np.diag(self.D**-2) @ self.B.T\n\n        # Adapt step size sigma\n        self.sigma *= np.exp((self.cs/self.damps)*(np.linalg.norm(self.ps)/np.sqrt(self.dim) - 1))\n\n        # Population size adaptation\n        if fvalues[idx[0]] < fvalues[idx[self.popsize//10]]:\n            self.success_rate = (1 - self.adapt_rate) * self.success_rate + self.adapt_rate\n        else:\n            self.success_rate = (1 - self.adapt_rate) * self.success_rate\n\n        if self.success_rate > 0.6:\n            self.popsize = min(self.popsize + 1, self.max_popsize)\n            self.mu = self.popsize // 2\n        elif self.success_rate < 0.4:\n            self.popsize = max(self.popsize - 1, self.min_popsize)\n            self.mu = self.popsize // 2\n        self.weights = np.array([self.c_mu * (np.log(self.mu+1) - np.log(i+1)) for i in range(self.mu)])\n        self.weights /= sum(self.weights)\n        self.mueff = sum(self.weights)**2 / sum(self.weights**2)\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)  # Initialize mean within bounds\n        evals = 0\n        while evals < self.budget:\n            x, z = self.sample()\n            fvalues = np.array([func(xi) for xi in x if evals + len(x) <= self.budget])\n            x = x[:len(fvalues)]\n            z = z[:len(fvalues)]\n            evals += len(fvalues)\n\n            if len(fvalues) > 0:\n                self.update(x, z, fvalues)\n                if min(fvalues) < self.f_opt:\n                    self.f_opt = min(fvalues)\n                    self.x_opt = self.archive_x[self.archive_f.index(min(self.archive_f))]\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,) (2,6) .", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "f38f8cbb-9ede-44e5-8e1d-697061bfbe5c", "fitness": 0.5226804877658483, "name": "AdaptiveHybridOptimizer", "description": "A population-based algorithm that combines elements of particle swarm optimization and differential evolution with a focus on exploration and exploitation balance using adaptive parameter control.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_weight=0.7,\n                 c1=1.5, c2=1.5, F=0.8, CR=0.9):\n        \"\"\"\n        Initialize the Adaptive Hybrid Optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            inertia_weight (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.best_positions = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.best_positions = self.pop.copy()\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_pso(self, func):\n        \"\"\"\n        Update the population using Particle Swarm Optimization.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        cognitive_component = self.c1 * r1 * (self.best_positions - self.pop)\n        social_component = self.c2 * r2 * (self.global_best_position - self.pop)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_component + social_component\n        self.pop += self.velocities\n\n        # Clip to bounds\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n\n        new_fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        for i in range(self.pop_size):\n            if new_fitness[i] < self.fitness[i]:\n                self.fitness[i] = new_fitness[i]\n                self.best_positions[i] = self.pop[i].copy()\n                if new_fitness[i] < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness[i]\n                    self.global_best_position = self.pop[i].copy()\n\n    def update_de(self, func):\n        \"\"\"\n        Update the population using Differential Evolution.\n        \"\"\"\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            v_i = x_r1 + self.F * (x_r2 - x_r3)\n            v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_i = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n\n            # Selection\n            f_u_i = func(u_i)\n            self.eval_count += 1\n\n            if f_u_i < self.fitness[i]:\n                self.fitness[i] = f_u_i\n                self.pop[i] = u_i.copy()\n                self.best_positions[i] = u_i.copy()\n                if f_u_i < self.global_best_fitness:\n                    self.global_best_fitness = f_u_i\n                    self.global_best_position = u_i.copy()\n\n    def adapt_parameters(self):\n          \"\"\"\n          Adapt parameters based on performance.  Simple example: reduce inertia if global best not improving\n          \"\"\"\n          self.inertia_weight *= 0.99  # Reduce inertia to encourage exploitation\n          self.inertia_weight = max(0.4, self.inertia_weight)  # Keep inertia within reasonable bounds\n          self.CR = min(0.99, self.CR + 0.01) # increase CR\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using the Adaptive Hybrid Optimizer.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Alternate between PSO and DE\n            if self.eval_count % 2 == 0:\n                self.update_pso(func)\n            else:\n                self.update_de(func)\n\n            # Adapt parameters\n            self.adapt_parameters()\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridOptimizer scored 0.523 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.16520506483282404, 0.18234288927532338, 0.9110427630356741, 0.20675364770320803, 0.2647482340898095, 0.9355647403590011, 0.3787149733689299, 0.578576271415455, 0.9160887765907197, 0.9265619402710412, 0.9556657390345414, 0.9972596342790969, 0.23587994542699608, 0.27018303369194263, 0.5843440928683851, 0.6361953697754077, 0.24900488021579492, 0.37947822645313567, 0.19603508529733682, 0.4839644473323417]}}
{"id": "d2713460-0a77-4757-8120-b84a4204be1d", "fitness": 0.2644704130234948, "name": "AdaptivePopulationSearch", "description": "An adaptive population-based algorithm that dynamically adjusts its search behavior based on the observed function landscape, balancing exploration and exploitation through a combination of differential evolution-inspired mutation and a self-adaptive learning rate.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.exploration_rate = 0.7  # Probability of exploration (mutation)\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Exploration vs. Exploitation\n                if np.random.rand() < self.exploration_rate:\n                    # Differential Evolution-inspired mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_rand1, x_rand2, x_rand3 = self.population[idxs]\n                    mutant = self.population[i] + self.lr * (x_rand1 - x_rand2)\n                    \n                    # Clip to bounds\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                    \n                    f_mutant = func(mutant)\n                    self.budget -= 1\n\n                    if f_mutant < self.fitness[i]:\n                        self.population[i] = mutant\n                        self.fitness[i] = f_mutant\n\n                        if f_mutant < self.f_opt:\n                            self.f_opt = f_mutant\n                            self.x_opt = mutant\n                else:\n                    # Exploitation: Move towards the best solution\n                    step = self.lr * (self.x_opt - self.population[i])\n                    new_x = self.population[i] + step\n                    new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                    \n                    f_new = func(new_x)\n                    self.budget -= 1\n\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = f_new\n\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = new_x\n                \n                if self.budget <= 0:\n                    break\n            # Adaptive learning rate adjustment (simple version)\n            self.lr *= 0.99  # Gradually reduce learning rate\n            self.exploration_rate *= 0.995\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptivePopulationSearch scored 0.264 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.11340880892454663, 0.1804027967175038, 0.37231703658294624, 0.2089604567141562, 0.15319042956364737, 0.16558506031252562, 0.2562134372952529, 0.24216152977055916, 0.17263021928351008, 0.19254192011282178, 0.20292440662781996, 0.9720716174459678, 0.27451842305544605, 0.22725479828734474, 0.16901322276975084, 0.25811620350167797, 0.2033264370544141, 0.29437343747510514, 0.18567235105473934, 0.444725667920159]}}
{"id": "1ead0a92-0293-4bd9-8bbb-d2c0f1b060eb", "fitness": 0.6349271950096906, "name": "EnhancedDifferentialEvolution", "description": "A population-based algorithm that combines a differential evolution-inspired mutation with a selection mechanism favoring both exploitation and exploration based on fitness rank and distance to the population centroid.", "code": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self):\n        mutated_pop = np.copy(self.pop)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            mutated = x_r1 + self.F * (x_r2 - x_r3)\n            mutated_pop[i] = np.clip(mutated, -5.0, 5.0)  # Clip to bounds\n        return mutated_pop\n\n    def crossover(self, mutated_pop):\n        crossed_pop = np.copy(self.pop)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    crossed_pop[i, j] = mutated_pop[i, j]\n        return crossed_pop\n\n    def selection(self, func, crossed_pop):\n        new_fitness = np.array([func(x) for x in crossed_pop])\n        self.eval_count += self.pop_size\n\n        # Rank-based selection: Prefer better fitness\n        ranked_indices = np.argsort(np.concatenate((self.fitness, new_fitness)))\n        selected_indices = ranked_indices[:self.pop_size]\n\n        combined_pop = np.concatenate((self.pop, crossed_pop))\n        self.pop = combined_pop[selected_indices]\n        self.fitness = np.concatenate((self.fitness, new_fitness))[selected_indices]\n\n        # Calculate centroid\n        centroid = np.mean(self.pop, axis=0)\n        distances = np.linalg.norm(self.pop - centroid, axis=1)\n\n        # Sort by fitness AND distance (exploration)\n        # Use a weighted sum to combine fitness and distance. Adjust weights as needed.\n        fitness_rank = np.argsort(self.fitness)\n        distance_rank = np.argsort(distances)\n        combined_rank = 0.7 * fitness_rank + 0.3 * distance_rank # Weighted ranking\n        sorted_indices = np.argsort(combined_rank)\n        self.pop = self.pop[sorted_indices]\n        self.fitness = self.fitness[sorted_indices]\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutated_pop = self.mutate()\n            crossed_pop = self.crossover(mutated_pop)\n            self.selection(func, crossed_pop)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EnhancedDifferentialEvolution scored 0.635 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.23195495618736628, 0.5377572955921157, 0.6039361671621232, 0.8445922539420464, 0.6876498992520641, 0.7222393737992263, 0.5092333391108912, 0.5745615314772561, 0.6939916741601148, 0.5802771996099323, 0.8355573524850491, 0.9990046461964939, 0.5466616269055388, 0.6671268216120636, 0.9039173184273086, 0.7248029123350759, 0.49574125349449405, 0.8060886973837369, 0.2220768437904117, 0.5113727372705047]}}
{"id": "be17fb56-0d3d-4203-8145-2968ea8dcb50", "fitness": -Infinity, "name": "AdaptiveHybridOptimizer", "description": "Simplified hybrid PSO-DE algorithm with adaptive parameter control, focusing on efficiency and performance.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_weight=0.7,\n                 c1=1.5, c2=1.5, F=0.8, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.best_positions = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_positions = self.pop.copy()\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update(self, func):\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        # PSO component\n        cognitive_component = self.c1 * r1 * (self.best_positions - self.pop)\n        social_component = self.c2 * r2 * (self.global_best_position - self.pop)\n        velocities = self.inertia_weight * (self.pop - self.best_positions) + cognitive_component + social_component\n        pso_candidates = self.pop + velocities\n        pso_candidates = np.clip(pso_candidates, func.bounds.lb, func.bounds.ub)\n        \n        # DE component\n        de_candidates = np.zeros_like(self.pop)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            v_i = x_r1 + self.F * (x_r2 - x_r3)\n            v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n            \n            j_rand = np.random.randint(self.dim)\n            de_candidates[i] = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n\n        # Evaluate candidates\n        pso_fitness = np.array([func(x) for x in pso_candidates])\n        de_fitness = np.array([func(x) for x in de_candidates])\n        self.eval_count += 2 * self.pop_size\n        \n        # Selection: compare both DE and PSO candidates with current pop\n        for i in range(self.pop_size):\n            if pso_fitness[i] < self.fitness[i] and pso_fitness[i] <= de_fitness[i]:\n                self.pop[i] = pso_candidates[i].copy()\n                self.fitness[i] = pso_fitness[i]\n            elif de_fitness[i] < self.fitness[i]:\n                self.pop[i] = de_candidates[i].copy()\n                self.fitness[i] = de_fitness[i]\n\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_position = self.pop[i].copy()\n            \n            if self.fitness[i] < self.best_positions[i]:\n                self.best_positions[i] = self.pop[i].copy()\n\n\n    def adapt_parameters(self):\n          self.inertia_weight *= 0.99\n          self.inertia_weight = max(0.4, self.inertia_weight)\n          self.CR = min(0.99, self.CR + 0.01)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update(func)\n            self.adapt_parameters()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 1, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["f38f8cbb-9ede-44e5-8e1d-697061bfbe5c"], "operator": null, "metadata": {}}
{"id": "31438e8d-031e-4f0b-91f7-dbd540ca9dfa", "fitness": 0.0, "name": "DynamicDifferentialEvolution", "description": "A differential evolution variant that dynamically adjusts its mutation factor based on the population diversity and local gradient information.", "code": "import numpy as np\n\nclass DynamicDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, Cr=0.9, F_initial=0.7, F_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.Cr = Cr  # Crossover rate\n        self.F = F_initial  # Initial mutation factor\n        self.F_decay = F_decay # Decay rate for F\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def calculate_diversity(self):\n        centroid = np.mean(self.pop, axis=0)\n        distances = np.linalg.norm(self.pop - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def estimate_gradient(self, func, x, delta=1e-3):\n        \"\"\"Estimates the gradient at a point x using finite differences.\"\"\"\n        gradient = np.zeros_like(x)\n        for i in range(self.dim):\n            x_plus = x.copy()\n            x_minus = x.copy()\n            x_plus[i] += delta\n            x_minus[i] -= delta\n            gradient[i] = (func(x_plus) - func(x_minus)) / (2 * delta)\n            self.eval_count += 2\n        return gradient\n\n    def mutate(self, func):\n        mutated_pop = np.copy(self.pop)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Estimate gradient\n            gradient = self.estimate_gradient(func, self.pop[i])\n            gradient_norm = np.linalg.norm(gradient)\n\n            # Dynamic F: adjust based on diversity and gradient\n            diversity = self.calculate_diversity()\n            if diversity > 1.0: # High diversity\n                 F_dynamic = self.F * (1 + 0.5 * np.random.rand())  # Increase F\n            elif gradient_norm > 0.1:  # Significant gradient\n                 F_dynamic = self.F * (1 - 0.2 * np.random.rand())  # Decrease F\n            else:\n                 F_dynamic = self.F # keep F as is\n\n            mutated = x_r1 + F_dynamic * (x_r2 - x_r3)\n            mutated_pop[i] = np.clip(mutated, -5.0, 5.0)  # Clip to bounds\n        return mutated_pop\n\n    def crossover(self, mutated_pop):\n        crossed_pop = np.copy(self.pop)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    crossed_pop[i, j] = mutated_pop[i, j]\n        return crossed_pop\n\n    def selection(self, func, crossed_pop):\n        new_fitness = np.array([func(x) for x in crossed_pop])\n        self.eval_count += self.pop_size\n\n        for i in range(self.pop_size):\n            if new_fitness[i] < self.fitness[i]:\n                self.pop[i] = crossed_pop[i]\n                self.fitness[i] = new_fitness[i]\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutated_pop = self.mutate(func)\n            crossed_pop = self.crossover(mutated_pop)\n            self.selection(func, crossed_pop)\n\n            #Decay F\n            self.F *= self.F_decay\n            self.F = max(0.1, self.F) # Ensure F does not get too small\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm DynamicDifferentialEvolution scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1ead0a92-0293-4bd9-8bbb-d2c0f1b060eb"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "d6286c1c-e6e4-4716-a776-fdec8e0c7957", "fitness": 0.0, "name": "SimplexEnhancedPopulationSearch", "description": "A hybrid algorithm combining aspects of Nelder-Mead simplex method with a population-based search, adaptively adjusting the simplex size and population diversity.", "code": "import numpy as np\n\nclass SimplexEnhancedPopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=15, simplex_size_init=0.1, lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.simplex_size = simplex_size_init\n        self.lr = lr # Learning rate\n        self.exploration_rate = 0.6\n\n    def __call__(self, func):\n        # Initialize population\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            # Population-based Search\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_rate:\n                    # Differential evolution inspired exploration\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_rand1, x_rand2, x_rand3 = self.population[idxs]\n                    mutant = self.population[i] + self.lr * (x_rand1 - x_rand2)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    f_mutant = func(mutant)\n                    self.budget -= 1\n\n                    if f_mutant < self.fitness[i]:\n                        self.population[i] = mutant\n                        self.fitness[i] = f_mutant\n                        if f_mutant < self.f_opt:\n                            self.f_opt = f_mutant\n                            self.x_opt = mutant\n                else:\n                    # Exploitation: Move towards best\n                    step = self.lr * (self.x_opt - self.population[i])\n                    new_x = self.population[i] + step\n                    new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_x)\n                    self.budget -= 1\n\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = f_new\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = new_x\n\n                if self.budget <= 0:\n                    break\n\n            # Nelder-Mead Simplex inspired refinement around the best solution\n            simplex = self.x_opt + self.simplex_size * np.random.normal(size=(self.dim + 1, self.dim))\n            simplex = np.clip(simplex, func.bounds.lb, func.bounds.ub)\n\n            fitness_simplex = np.array([func(x) for x in simplex])\n            self.budget -= (self.dim + 1)\n\n            if self.budget <= 0:\n                break\n\n            # Order the simplex vertices by fitness\n            order = np.argsort(fitness_simplex)\n            simplex = simplex[order]\n            fitness_simplex = fitness_simplex[order]\n            \n            # Reflection\n            centroid = np.mean(simplex[:-1], axis=0)\n            reflected_point = centroid + 1.0 * (centroid - simplex[-1])\n            reflected_point = np.clip(reflected_point, func.bounds.lb, func.bounds.ub)\n\n            f_reflected = func(reflected_point)\n            self.budget -= 1\n\n            if self.budget <= 0:\n                break\n                \n            if fitness_simplex[0] < f_reflected < fitness_simplex[-2]:\n                simplex[-1] = reflected_point\n                fitness_simplex[-1] = f_reflected\n            elif f_reflected < fitness_simplex[0]:\n                # Expansion\n                expanded_point = centroid + 2.0 * (reflected_point - centroid)\n                expanded_point = np.clip(expanded_point, func.bounds.lb, func.bounds.ub)\n\n                f_expanded = func(expanded_point)\n                self.budget -= 1\n\n                if self.budget <= 0:\n                    break\n\n                if f_expanded < f_reflected:\n                    simplex[-1] = expanded_point\n                    fitness_simplex[-1] = f_expanded\n                else:\n                    simplex[-1] = reflected_point\n                    fitness_simplex[-1] = f_reflected\n\n            # Update best solution if necessary\n            if np.min(fitness_simplex) < self.f_opt:\n                self.f_opt = np.min(fitness_simplex)\n                self.x_opt = simplex[np.argmin(fitness_simplex)]\n\n            # Adaptive simplex size adjustment\n            self.simplex_size *= 0.995\n            self.lr *= 0.99\n            self.exploration_rate *= 0.995\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm SimplexEnhancedPopulationSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d2713460-0a77-4757-8120-b84a4204be1d"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "32bb9a40-7a7c-4ded-b1f1-5051fffdc336", "fitness": 0.30422041689187396, "name": "AdaptivePopulationSearch", "description": "A simplified adaptive population search that balances exploration and exploitation with adaptive learning rate and exploration rate decay for improved convergence.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1, exploration_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.exploration_rate = exploration_rate\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        f_opt = np.min(fitness)\n        x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Exploration vs. Exploitation\n                if np.random.rand() < self.exploration_rate:\n                    # Differential Evolution-inspired mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_rand1, x_rand2, x_rand3 = population[idxs]\n                    mutant = population[i] + self.lr * (x_rand1 - x_rand2)\n                    \n                    # Clip to bounds\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                    \n                    f_mutant = func(mutant)\n                    self.budget -= 1\n\n                    if f_mutant < fitness[i]:\n                        population[i] = mutant\n                        fitness[i] = f_mutant\n\n                        if f_mutant < f_opt:\n                            f_opt = f_mutant\n                            x_opt = mutant\n                else:\n                    # Exploitation: Move towards the best solution\n                    step = self.lr * (x_opt - population[i])\n                    new_x = population[i] + step\n                    new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                    \n                    f_new = func(new_x)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        population[i] = new_x\n                        fitness[i] = f_new\n\n                        if f_new < f_opt:\n                            f_opt = f_new\n                            x_opt = new_x\n                            \n            # Adaptive learning rate and exploration rate adjustment\n            self.lr *= 0.99  # Gradually reduce learning rate\n            self.exploration_rate *= 0.995\n            \n\n        return f_opt, x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptivePopulationSearch scored 0.304 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d2713460-0a77-4757-8120-b84a4204be1d"], "operator": null, "metadata": {"aucs": [0.09355880559055663, 0.20411077701634361, 0.33620365272436514, 0.17880448845150643, 0.1916906898150682, 0.46573829239018283, 0.21612693702830654, 0.18473670552847787, 0.16345719549398963, 0.15959194749060956, 0.21781902817085852, 0.998488415864931, 0.34521665728259754, 0.16138488823911434, 0.6053352663992324, 0.32936514023797303, 0.3094849465192063, 0.22509859070508675, 0.21659543637096634, 0.4816004765181079]}}
{"id": "dcfbe769-e6ce-46da-819a-2a22eb745870", "fitness": 0.27651672878538436, "name": "SelfAdjustingCauchySearch", "description": "A self-adjusting algorithm that combines a Cauchy mutation strategy with a shrinking search space to balance exploration and exploitation, dynamically adapting the mutation scale and search boundaries based on success.", "code": "import numpy as np\n\nclass SelfAdjustingCauchySearch:\n    def __init__(self, budget=10000, dim=10, initial_scale=1.0, shrink_factor=0.95, expand_factor=1.05, success_threshold=0.2, shrink_patience=10):\n        self.budget = budget\n        self.dim = dim\n        self.scale = initial_scale  # Mutation scale\n        self.shrink_factor = shrink_factor  # Factor to shrink the search space\n        self.expand_factor = expand_factor # Factor to expand the search space if stuck\n        self.success_threshold = success_threshold  # Threshold for adapting mutation scale\n        self.lb = -5.0 * np.ones(dim) # Initialize lower bound\n        self.ub = 5.0 * np.ones(dim) # Initialize upper bound\n        self.x_best = None\n        self.f_best = np.inf\n        self.success_count = 0\n        self.iteration_count = 0\n        self.shrink_patience = shrink_patience\n        self.no_improvement_count = 0\n\n    def cauchy_mutation(self, x):\n        return x + self.scale * np.random.standard_cauchy(size=self.dim)\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, size=self.dim) # Initialize within current bounds\n        f = func(x)\n        self.f_best = f\n        self.x_best = x\n        evals = 1\n\n        while evals < self.budget:\n            x_new = self.cauchy_mutation(x)\n            \n            # Clip to original bounds, not current bounds.\n            x_new = np.clip(x_new, -5.0, 5.0)\n            \n            f_new = func(x_new)\n            evals += 1\n\n            if f_new < f:\n                x = x_new\n                f = f_new\n                self.success_count += 1\n                self.no_improvement_count = 0 # Reset counter\n\n                if f_new < self.f_best:\n                    self.f_best = f_new\n                    self.x_best = x_new\n            else:\n                 self.no_improvement_count += 1\n\n            self.iteration_count += 1\n\n            # Adapt mutation scale\n            if self.iteration_count % 10 == 0:\n                success_rate = self.success_count / 10\n                if success_rate < self.success_threshold:\n                    self.scale *= self.expand_factor  # Increase scale for exploration\n                else:\n                    self.scale *= self.shrink_factor  # Decrease scale for exploitation\n                self.success_count = 0\n\n            # Shrink search space if stuck\n            if self.no_improvement_count > self.shrink_patience:\n                self.lb = self.x_best - 0.5 * (self.x_best - np.clip(self.lb, -5.0, 5.0)) # Shrink towards best\n                self.ub = self.x_best + 0.5 * (np.clip(self.ub, -5.0, 5.0) - self.x_best) # Shrink towards best\n                \n                #Ensure bounds stay within original limits\n                self.lb = np.maximum(self.lb, -5.0)\n                self.ub = np.minimum(self.ub, 5.0)\n                \n                self.no_improvement_count = 0 # Reset counter\n\n        return self.f_best, self.x_best", "configspace": "", "generation": 1, "feedback": "The algorithm SelfAdjustingCauchySearch scored 0.277 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7690e5ba-1f3e-42c5-844d-01bb3a3a91b8"], "operator": null, "metadata": {"aucs": [0.11307851629232246, 0.15672337371653344, 0.25722289928872333, 0.16385471823807096, 0.20678170882633473, 0.22210718173500077, 0.2279662874905346, 0.20488737123430645, 0.18710851543983575, 0.16378795571400984, 0.1968541603556213, 0.998528810652915, 0.22623716547005557, 0.22711752035371746, 0.576579361274042, 0.29873582564555134, 0.23518587655132484, 0.2651940615503685, 0.14096014377215216, 0.4614231221062651]}}
{"id": "723da4b0-477c-4c5f-8039-a6d57ed0fb06", "fitness": 0.31603492676008366, "name": "AdaptivePopulationSearch", "description": "An adaptive population-based algorithm that combines differential evolution, exploitation towards the best, and a self-adaptive learning rate, while also incorporating a Cauchy mutation to escape local optima and dynamically adjusting population size.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1, min_pop_size=5, max_pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.exploration_rate = 0.7\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n            for i in range(self.pop_size):\n                # Exploration vs. Exploitation\n                if np.random.rand() < self.exploration_rate:\n                    # Differential Evolution-inspired mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_rand1, x_rand2, x_rand3 = self.population[idxs]\n                    mutant = self.population[i] + self.lr * (x_rand1 - x_rand2)\n                    \n                    # Cauchy mutation for escaping local optima\n                    if np.random.rand() < 0.1:  # Apply Cauchy mutation with probability 0.1\n                        cauchy_step = np.random.standard_cauchy(size=self.dim) * self.lr\n                        mutant += cauchy_step\n\n                    # Clip to bounds\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                    \n                    f_mutant = func(mutant)\n                    self.budget -= 1\n\n                    if f_mutant < self.fitness[i]:\n                        self.population[i] = mutant\n                        self.fitness[i] = f_mutant\n\n                        if f_mutant < self.f_opt:\n                            self.f_opt = f_mutant\n                            self.x_opt = mutant\n                else:\n                    # Exploitation: Move towards the best solution\n                    step = self.lr * (self.x_opt - self.population[i])\n                    new_x = self.population[i] + step\n                    new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                    \n                    f_new = func(new_x)\n                    self.budget -= 1\n\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = f_new\n\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = new_x\n                \n                if self.budget <= 0:\n                    break\n            # Adaptive learning rate adjustment\n            self.lr *= 0.99  # Gradually reduce learning rate\n            self.exploration_rate *= 0.995\n\n            # Dynamic population size adjustment\n            if iteration % 10 == 0:  # Adjust population size every 10 iterations\n                fitness_std = np.std(self.fitness)\n                if fitness_std < 1e-3:  # If fitness variance is low, increase population\n                    self.pop_size = min(self.pop_size + 2, self.max_pop_size)\n                elif fitness_std > 0.1 and self.pop_size > self.min_pop_size:  # If fitness variance is high, decrease population\n                    self.pop_size = max(self.pop_size - 2, self.min_pop_size)\n\n                # Resize population (keeping the best individuals)\n                if self.pop_size != self.population.shape[0]:\n                    best_indices = np.argsort(self.fitness)[:self.pop_size]\n                    self.population = self.population[best_indices]\n                    self.fitness = self.fitness[best_indices]\n\n                    # Refill with new random individuals if pop_size increased\n                    if self.pop_size > self.population.shape[0]:\n                         num_new_individuals = self.pop_size - self.population.shape[0]\n                         new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new_individuals, self.dim))\n                         new_fitness = np.array([func(x) for x in new_individuals])\n                         self.budget -= num_new_individuals\n\n                         self.population = np.concatenate((self.population, new_individuals))\n                         self.fitness = np.concatenate((self.fitness, new_fitness))\n                         \n                         # Update best solution in case new individual is better\n                         new_best_fitness = np.min(self.fitness)\n                         if new_best_fitness < self.f_opt:\n                             self.f_opt = new_best_fitness\n                             self.x_opt = self.population[np.argmin(self.fitness)]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptivePopulationSearch scored 0.316 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d2713460-0a77-4757-8120-b84a4204be1d"], "operator": null, "metadata": {"aucs": [0.06251393697721874, 0.36869385156476386, 0.3409595283937179, 0.1782224159423227, 0.20814015802764518, 0.4133827429578756, 0.26678580415506115, 0.2236891310491962, 0.21209587605810698, 0.16438670239466024, 0.3010165900288905, 0.9882187722700396, 0.2658751874615347, 0.21719125151494534, 0.6277742738251206, 0.3253320703205327, 0.26608129039707573, 0.2892866036906153, 0.17063605478159172, 0.43041629339075793]}}
{"id": "ed0df5a3-5c6c-4122-a8ce-19ebfc843996", "fitness": 0.42437410877210374, "name": "AdaptivePopulationSearch", "description": "Adaptive population search with improved adaptive learning rate and mutation strategy based on fitness variance.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1, min_lr = 0.001):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.min_lr = min_lr\n        self.exploration_rate = 0.7\n        self.mutation_factor = 0.5\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            # Calculate fitness variance for learning rate adaptation\n            fitness_variance = np.var(self.fitness)\n\n            for i in range(self.pop_size):\n                # Exploration vs. Exploitation\n                if np.random.rand() < self.exploration_rate:\n                    # Enhanced Differential Evolution-inspired mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_rand1, x_rand2, x_rand3 = self.population[idxs]\n                    \n                    # Adaptive mutation factor based on fitness variance\n                    adaptive_mutation_factor = self.mutation_factor * (1 + fitness_variance)\n                    \n                    mutant = self.population[i] + adaptive_mutation_factor * (x_rand1 - x_rand2)\n\n                    # Clip to bounds\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                    \n                    f_mutant = func(mutant)\n                    self.budget -= 1\n\n                    if f_mutant < self.fitness[i]:\n                        self.population[i] = mutant\n                        self.fitness[i] = f_mutant\n\n                        if f_mutant < self.f_opt:\n                            self.f_opt = f_mutant\n                            self.x_opt = mutant\n                else:\n                    # Exploitation: Move towards the best solution\n                    step = self.lr * (self.x_opt - self.population[i])\n                    new_x = self.population[i] + step\n                    new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                    \n                    f_new = func(new_x)\n                    self.budget -= 1\n\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = f_new\n\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = new_x\n                \n                if self.budget <= 0:\n                    break\n\n            # Adaptive learning rate adjustment\n            if fitness_variance > 1e-6:  # Avoid division by zero\n                self.lr *= (1 - (0.1 / (1 + fitness_variance)))  # Reduce lr less when variance is high\n            else:\n                self.lr *= 0.9  # Reduce lr more aggressively when variance is low\n            \n            self.lr = max(self.lr, self.min_lr) # Ensure that lr doesn't go too low\n            self.exploration_rate *= 0.995 # Gradually reduce exploration rate\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptivePopulationSearch scored 0.424 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d2713460-0a77-4757-8120-b84a4204be1d"], "operator": null, "metadata": {"aucs": [0.11129624433054253, 0.20810569483414376, 0.38258400976555407, 0.8162816335206604, 0.20696828450645788, 0.47107225322030344, 0.2908499930245827, 0.3607779408597067, 0.37567533806153885, 0.17214028268167225, 0.7843241000407251, 0.9943914960246323, 0.27664249284674636, 0.28567093556748036, 0.6538105621011059, 0.5086718444491467, 0.33681458368553086, 0.6026663860032628, 0.1627709532916175, 0.4859671466266644]}}
{"id": "bfdce419-bcb7-4d05-9ab0-775ba14e301d", "fitness": 0.3871934380175732, "name": "AdaptiveHybridOptimizer", "description": "Simplified hybrid PSO-DE algorithm with dynamic parameter adaptation based on fitness variance.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_weight=0.7,\n                 c1=1.5, c2=1.5, F=0.8, CR=0.9, pso_ratio = 0.5):\n        \"\"\"\n        Initialize the Adaptive Hybrid Optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            inertia_weight (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            pso_ratio (float): Ratio of PSO updates to DE updates\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pso_ratio = pso_ratio\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.best_positions = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.pso_count = 0\n        self.de_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.best_positions = self.pop.copy()\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_pso(self, func):\n        \"\"\"\n        Update the population using Particle Swarm Optimization.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        cognitive_component = self.c1 * r1 * (self.best_positions - self.pop)\n        social_component = self.c2 * r2 * (self.global_best_position - self.pop)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_component + social_component\n        self.pop += self.velocities\n\n        # Clip to bounds\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n\n        new_fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.pso_count += self.pop_size\n\n        for i in range(self.pop_size):\n            if new_fitness[i] < self.fitness[i]:\n                self.fitness[i] = new_fitness[i]\n                self.best_positions[i] = self.pop[i].copy()\n                if new_fitness[i] < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness[i]\n                    self.global_best_position = self.pop[i].copy()\n\n    def update_de(self, func):\n        \"\"\"\n        Update the population using Differential Evolution.\n        \"\"\"\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            v_i = x_r1 + self.F * (x_r2 - x_r3)\n            v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_i = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n\n            # Selection\n            f_u_i = func(u_i)\n            self.eval_count += 1\n            self.de_count += 1\n\n            if f_u_i < self.fitness[i]:\n                self.fitness[i] = f_u_i\n                self.pop[i] = u_i.copy()\n                self.best_positions[i] = u_i.copy()\n                if f_u_i < self.global_best_fitness:\n                    self.global_best_fitness = f_u_i\n                    self.global_best_position = u_i.copy()\n\n    def adapt_parameters(self):\n        \"\"\"\n        Adapt parameters based on population fitness variance.\n        \"\"\"\n        fitness_variance = np.var(self.fitness)\n\n        if fitness_variance > 1e-3:  # High variance, explore\n            self.inertia_weight = min(0.9, self.inertia_weight + 0.01)\n            self.CR = max(0.1, self.CR - 0.01)\n        else:  # Low variance, exploit\n            self.inertia_weight = max(0.4, self.inertia_weight - 0.01)\n            self.CR = min(0.99, self.CR + 0.01)\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using the Adaptive Hybrid Optimizer.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        pso_prob = self.pso_ratio\n        while self.eval_count < self.budget:\n            # Decide between PSO and DE based on pso_ratio\n            if np.random.rand() < pso_prob:\n                self.update_pso(func)\n            else:\n                self.update_de(func)\n            \n            self.adapt_parameters()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveHybridOptimizer scored 0.387 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f38f8cbb-9ede-44e5-8e1d-697061bfbe5c"], "operator": null, "metadata": {"aucs": [0.1467262691637885, 0.1853697589416231, 0.32745005363139545, 0.6541450463423377, 0.2675431660107329, 0.4206224228950005, 0.2947345431063666, 0.3033205788296838, 0.27072497911897475, 0.2352128379582613, 0.3888011535120991, 0.9999175157269317, 0.29590398065561563, 0.2770670671666774, 0.7375774344932129, 0.5828827159601836, 0.28890808387950384, 0.3713206599518779, 0.19489929967505437, 0.5007411933321434]}}
{"id": "93a4fb57-8df4-435b-b007-3e58864d1405", "fitness": 0.7128303286548989, "name": "AdaptiveDifferentialEvolution", "description": "Simplified Differential Evolution with adaptive mutation factor and probabilistic selection based on fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        while i in idxs:\n          idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        # Adaptive F\n        F_adaptive = self.F * (1 + np.random.normal(0, 0.1)) # Adding some noise\n        mutated = x_r1 + F_adaptive * (x_r2 - x_r3)\n        return np.clip(mutated, -5.0, 5.0)\n\n    def crossover(self, mutated, i):\n        crossed = np.copy(self.pop[i])\n        for j in range(self.dim):\n            if np.random.rand() < self.Cr:\n                crossed[j] = mutated[j]\n        return crossed\n\n    def selection(self, func, crossed, i):\n        f_new = func(crossed)\n        self.eval_count += 1\n\n        if f_new < self.fitness[i]:\n            self.pop[i] = crossed\n            self.fitness[i] = f_new\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = crossed\n        # else: #Probabilistic replacement\n        #  if np.random.rand() < (self.fitness[i] - f_new) / self.fitness[i]: # If the new one is worse, replace with a probability proportional to how much worse it is.\n        #    self.pop[i] = crossed\n        #    self.fitness[i] = f_new\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutated = self.mutate(i)\n                crossed = self.crossover(mutated, i)\n                self.selection(func, crossed, i)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.713 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1ead0a92-0293-4bd9-8bbb-d2c0f1b060eb"], "operator": null, "metadata": {"aucs": [0.2908621555235471, 0.677499913945355, 0.7042601980978797, 0.8467828699586463, 0.7672434644721132, 0.8056253038154262, 0.6283361382914582, 0.6771066075132082, 0.7210219156752635, 0.6828199000237525, 0.8547913748099115, 0.9997501359936035, 0.6552276257739513, 0.7068535040802721, 0.8976530498835992, 0.7843316897592074, 0.6274978417494261, 0.8300291151350025, 0.4701150633877176, 0.6287987052086355]}}
{"id": "bb561be5-408b-48ae-bc8f-1a322409c738", "fitness": -Infinity, "name": "HybridPSO_NM", "description": "A hybrid algorithm that combines PSO with a local search strategy based on Nelder-Mead simplex, adapting the frequency of local search based on stagnation detection.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSO_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_weight=0.7,\n                 c1=1.5, c2=1.5, nm_freq=10, stagnation_threshold=100):\n        \"\"\"\n        Initialize the Hybrid PSO with Nelder-Mead.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            inertia_weight (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            nm_freq (int): Frequency of Nelder-Mead application (every nm_freq iterations).\n            stagnation_threshold (int): Number of iterations without improvement before increasing NM frequency.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.c1 = c1\n        self.c2 = c2\n        self.nm_freq = nm_freq\n        self.stagnation_threshold = stagnation_threshold\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.best_positions = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.current_nm_freq = nm_freq\n\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.best_positions = self.pop.copy()\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n\n    def update_pso(self, func):\n        \"\"\"\n        Update the population using Particle Swarm Optimization.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        cognitive_component = self.c1 * r1 * (self.best_positions - self.pop)\n        social_component = self.c2 * r2 * (self.global_best_position - self.pop)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_component + social_component\n        self.pop += self.velocities\n\n        # Clip to bounds\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n\n        new_fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        for i in range(self.pop_size):\n            if new_fitness[i] < self.fitness[i]:\n                self.fitness[i] = new_fitness[i]\n                self.best_positions[i] = self.pop[i].copy()\n                if new_fitness[i] < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness[i]\n                    self.global_best_position = self.pop[i].copy()\n                    self.stagnation_counter = 0 # Reset stagnation counter\n                else:\n                  self.stagnation_counter += 1\n            else:\n                self.stagnation_counter += 1\n\n\n    def apply_nelder_mead(self, func):\n        \"\"\"\n        Apply Nelder-Mead simplex algorithm to the best particle.\n        \"\"\"\n        result = minimize(func, self.global_best_position, method='Nelder-Mead',\n                            bounds=np.array([func.bounds.lb, func.bounds.ub]).T,\n                            options={'maxfev': self.budget - self.eval_count})  # Limit FE calls\n        if result.success:\n            if result.fun < self.global_best_fitness:\n                self.global_best_fitness = result.fun\n                self.global_best_position = result.x\n                self.stagnation_counter = 0  # Reset stagnation counter\n            self.eval_count += result.nfev\n        else:\n            self.eval_count += result.nfev\n            self.stagnation_counter +=1\n\n    def adapt_nm_frequency(self):\n        \"\"\"\n        Adapt the frequency of Nelder-Mead based on stagnation.\n        \"\"\"\n        if self.stagnation_counter > self.stagnation_threshold:\n            self.current_nm_freq = max(1, self.current_nm_freq // 2)  # Increase frequency\n            self.stagnation_counter = 0  # Reset stagnation counter\n        else:\n            self.current_nm_freq = self.nm_freq # restore initial value\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using the Hybrid PSO with Nelder-Mead.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        best_fitness_history = []\n        best_fitness_history.append(self.global_best_fitness)\n        while self.eval_count < self.budget:\n            self.update_pso(func)\n\n            if (self.eval_count // self.pop_size) % self.current_nm_freq == 0:\n                self.apply_nelder_mead(func)\n\n            self.adapt_nm_frequency()\n            best_fitness_history.append(self.global_best_fitness)\n\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 1, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["f38f8cbb-9ede-44e5-8e1d-697061bfbe5c"], "operator": null, "metadata": {}}
{"id": "669a00ab-a51f-4977-af17-e7a847383b3b", "fitness": 0.42989132283446985, "name": "HybridSAMutation", "description": "A hybrid algorithm combining aspects of PSO, DE, and Simulated Annealing with adaptive parameter control based on stagnation detection.", "code": "import numpy as np\n\nclass HybridSAMutation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_weight=0.7,\n                 c1=1.5, c2=1.5, F=0.8, CR=0.9, initial_temp=1.0, cooling_rate=0.95):\n        \"\"\"\n        Initialize the Hybrid SAMutation Optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            inertia_weight (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            initial_temp (float): Initial temperature for SA.\n            cooling_rate (float): Cooling rate for SA.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp = initial_temp\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.best_positions = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.max_stagnation = 50 #Number of iterations with no improvement\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.best_positions = self.pop.copy()\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_pso(self, func):\n        \"\"\"\n        Update the population using Particle Swarm Optimization.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        cognitive_component = self.c1 * r1 * (self.best_positions - self.pop)\n        social_component = self.c2 * r2 * (self.global_best_position - self.pop)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_component + social_component\n        self.pop += self.velocities\n\n        # Clip to bounds\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n\n        new_fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        for i in range(self.pop_size):\n            if new_fitness[i] < self.fitness[i]:\n                self.fitness[i] = new_fitness[i]\n                self.best_positions[i] = self.pop[i].copy()\n                if new_fitness[i] < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness[i]\n                    self.global_best_position = self.pop[i].copy()\n                    self.stagnation_counter = 0 #reset stagnation counter\n            else:\n                #Simulated Annealing inspired acceptance\n                delta_e = new_fitness[i] - self.fitness[i]\n                if np.random.rand() < np.exp(-delta_e / self.temp):\n                  self.fitness[i] = new_fitness[i]\n                  self.pop[i] = self.pop[i].copy()\n        \n\n    def update_de(self, func):\n        \"\"\"\n        Update the population using Differential Evolution.\n        \"\"\"\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            v_i = x_r1 + self.F * (x_r2 - x_r3)\n            v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_i = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n\n            # Selection\n            f_u_i = func(u_i)\n            self.eval_count += 1\n\n            if f_u_i < self.fitness[i]:\n                self.fitness[i] = f_u_i\n                self.pop[i] = u_i.copy()\n                self.best_positions[i] = u_i.copy()\n                if f_u_i < self.global_best_fitness:\n                    self.global_best_fitness = f_u_i\n                    self.global_best_position = u_i.copy()\n                    self.stagnation_counter = 0 #reset stagnation counter\n            else:\n                #Simulated Annealing inspired acceptance\n                delta_e = f_u_i - self.fitness[i]\n                if np.random.rand() < np.exp(-delta_e / self.temp):\n                  self.fitness[i] = f_u_i\n                  self.pop[i] = u_i.copy()\n\n\n    def adapt_parameters(self):\n          \"\"\"\n          Adapt parameters based on performance and stagnation.\n          \"\"\"\n          if self.stagnation_counter > self.max_stagnation:\n              # Increase exploration if stagnant\n              self.inertia_weight = min(0.9, self.inertia_weight + 0.05)\n              self.F = min(1.0, self.F + 0.05)\n              #increase temp if stuck\n              self.temp = self.initial_temp\n          else:\n              # Reduce inertia and temp to exploit\n              self.inertia_weight *= 0.99\n              self.inertia_weight = max(0.4, self.inertia_weight)\n              self.temp *= self.cooling_rate\n\n          self.CR = min(0.99, self.CR + 0.01)\n          self.stagnation_counter +=1\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using the Hybrid SAMutation Optimizer.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        best_fitness_history = []\n\n        while self.eval_count < self.budget:\n            # Alternate between PSO and DE\n            if self.eval_count % 2 == 0:\n                self.update_pso(func)\n            else:\n                self.update_de(func)\n\n            # Adapt parameters\n            self.adapt_parameters()\n            best_fitness_history.append(self.global_best_fitness)\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm HybridSAMutation scored 0.430 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f38f8cbb-9ede-44e5-8e1d-697061bfbe5c"], "operator": null, "metadata": {"aucs": [0.1873577013766129, 0.180131705227061, 0.7937974614046883, 0.3635653241997723, 0.3100428346770685, 0.28635724520586436, 0.3054484610502831, 0.5014473745910926, 0.21976838539778265, 0.2341221247612555, 0.48069255018124646, 0.9968324417423147, 0.22093121173422547, 0.30950243547482514, 0.6485163927252664, 0.9350165501608887, 0.41317492439115644, 0.38090670118686276, 0.32257030829188504, 0.5076443229092458]}}
{"id": "9b484321-d014-4725-9162-de37f271c349", "fitness": 0.26554980769554326, "name": "SelfOrganizingSearch", "description": "A self-organizing search algorithm that adapts its search pattern based on local gradient estimates and distance to previously visited points.", "code": "import numpy as np\n\nclass SelfOrganizingSearch:\n    def __init__(self, budget=10000, dim=10, step_size=0.1, decay_rate=0.99, neighbor_size=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = step_size\n        self.decay_rate = decay_rate\n        self.neighbor_size = neighbor_size\n        self.archive_x = []\n        self.archive_f = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.archive_x.append(x)\n        self.archive_f.append(f)\n        self.f_opt = f\n        self.x_opt = x\n        evals = 1\n\n        while evals < self.budget:\n            # Estimate local gradient\n            grad = np.zeros(self.dim)\n            for i in range(self.dim):\n                x_plus = x.copy()\n                x_minus = x.copy()\n\n                delta = self.step_size\n                x_plus[i] = min(func.bounds.ub[i], x[i] + delta)\n                x_minus[i] = max(func.bounds.lb[i], x[i] - delta)\n\n                if evals + 2 > self.budget:\n                    break # Check budget before evaluating the function\n\n                f_plus = func(x_plus)\n                evals += 1\n                f_minus = func(x_minus)\n                evals += 1\n\n                grad[i] = (f_plus - f_minus) / (2 * delta)\n\n            # Normalize gradient\n            grad_norm = np.linalg.norm(grad)\n            if grad_norm > 0:\n                grad = grad / grad_norm\n\n            # Adjust search direction based on archive\n            archive_influence = np.zeros(self.dim)\n            for i in range(len(self.archive_x)):\n                dist = np.linalg.norm(x - self.archive_x[i])\n                if dist < self.neighbor_size:\n                    diff = x - self.archive_x[i]\n                    if np.linalg.norm(diff) > 0:\n                      archive_influence += (self.archive_f[i] - f) * diff / np.linalg.norm(diff) \n\n            # Combine gradient and archive influence\n            search_direction = grad + archive_influence\n            search_direction_norm = np.linalg.norm(search_direction)\n            if search_direction_norm > 0:\n                search_direction = search_direction / search_direction_norm\n            \n\n            # Update position\n            x_new = x - self.step_size * search_direction\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            if evals + 1 > self.budget:\n                break # check budget before evaluating\n\n            f_new = func(x_new)\n            evals += 1\n\n            # Update step size\n            if f_new < f:\n                self.step_size *= 1.1\n            else:\n                self.step_size *= self.decay_rate\n\n            # Update current position\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n            \n            x = x_new\n            f = f_new\n            self.archive_x.append(x)\n            self.archive_f.append(f)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm SelfOrganizingSearch scored 0.266 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7690e5ba-1f3e-42c5-844d-01bb3a3a91b8"], "operator": null, "metadata": {"aucs": [0.14483253805715324, 0.18367708245732384, 0.3070612078416527, 0.1985636535482277, 0.1961116673507033, 0.25752242641887646, 0.22936937905436028, 0.2345371262398811, 0.16404333795840154, 0.16570815250186866, 0.23261748029284446, 0.9645672783389132, 9.999999999998899e-05, 0.24534117574338765, 0.5754348697667097, 0.29917941463580566, 0.06809724309942389, 0.27981377336054825, 0.14023571707058147, 0.4241826301742023]}}
{"id": "c02eb89c-a8bb-405a-985e-c82ba9e93ed7", "fitness": 0.0, "name": "RestartDE", "description": "A population-based algorithm that combines elements of Differential Evolution and a local search strategy, periodically re-initializing poorly performing individuals to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass RestartDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.7, CR=0.9, local_search_prob=0.1, restart_prob=0.05):\n        \"\"\"\n        Initialize the Restart Differential Evolution Optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            local_search_prob (float): Probability of performing local search.\n            restart_prob (float): Probability of restarting a particle.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_prob = local_search_prob\n        self.restart_prob = restart_prob\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n\n    def differential_evolution(self, func):\n        \"\"\"\n        Perform a Differential Evolution update.\n        \"\"\"\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            v_i = x_r1 + self.F * (x_r2 - x_r3)\n            v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_i = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n\n            # Selection\n            f_u_i = func(u_i)\n            self.eval_count += 1\n\n            if f_u_i < self.fitness[i]:\n                self.fitness[i] = f_u_i\n                self.pop[i] = u_i.copy()\n\n                if f_u_i < self.best_fitness:\n                    self.best_fitness = f_u_i\n                    self.best_position = u_i.copy()\n\n    def local_search(self, func, individual):\n        \"\"\"\n        Perform a simple local search around an individual.\n        \"\"\"\n        step_size = 0.1 * (func.bounds.ub - func.bounds.lb)  # Adjust step size as needed\n        new_individual = individual + np.random.uniform(-step_size, step_size, size=self.dim)\n        new_individual = np.clip(new_individual, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_individual)\n        self.eval_count += 1\n\n        if f_new < self.fitness[np.where((self.pop == individual).all(axis=1))[0][0]]: #find index and compare\n            return new_individual, f_new\n        else:\n            return individual, self.fitness[np.where((self.pop == individual).all(axis=1))[0][0]] #find index and return\n\n    def restart_particle(self, func, index):\n        \"\"\"\n        Restart a particle with a new random position.\n        \"\"\"\n        self.pop[index] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.fitness[index] = func(self.pop[index])\n        self.eval_count += 1\n\n        if self.fitness[index] < self.best_fitness:\n            self.best_fitness = self.fitness[index]\n            self.best_position = self.pop[index].copy()\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using the Restart Differential Evolution Optimizer.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func)\n\n            # Apply local search to some individuals\n            for i in range(self.pop_size):\n                if np.random.rand() < self.local_search_prob:\n                    self.pop[i], self.fitness[i] = self.local_search(func, self.pop[i])\n                    if self.fitness[i] < self.best_fitness:\n                        self.best_fitness = self.fitness[i]\n                        self.best_position = self.pop[i].copy()\n            #Restart poorly performing particles\n            for i in range(self.pop_size):\n                if np.random.rand() < self.restart_prob:\n                    self.restart_particle(func, i)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 2, "feedback": "The algorithm RestartDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["669a00ab-a51f-4977-af17-e7a847383b3b"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "b0af7c68-6ea9-4f62-8dc5-a5e0a53c2920", "fitness": -Infinity, "name": "PSOCMAES", "description": "Population-based algorithm that combines particle swarm optimization (PSO) with a covariance matrix adaptation evolution strategy (CMA-ES) for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass PSOCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_weight=0.7,\n                 c1=1.5, c2=1.5, cs=0.3, damp=0.9, mu_ratio=0.25):\n        \"\"\"\n        Initialize the PSOCMAES optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size for both PSO and CMA-ES.\n            inertia_weight (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cs (float): Step-size damping factor for CMA-ES.\n            damp (float): Step-size damping.\n            mu_ratio (float): Ratio of parents for recombination in CMA-ES.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.c1 = c1\n        self.c2 = c2\n        self.cs = cs\n        self.damp = damp\n        self.mu = int(self.pop_size * mu_ratio)\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.best_positions = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n\n        # CMA-ES specific parameters\n        self.mean = None\n        self.sigma = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.c_c = None\n        self.weights = None\n        self.D = None\n        self.B = None\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.best_positions = self.pop.copy()\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n        # Initialize CMA-ES parameters\n        self.mean = self.global_best_position.copy()  # Initialize mean at the global best position\n        self.sigma = 0.5  # Initial step size\n        self.C = np.eye(self.dim)  # Initial covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        self.chiN = np.sqrt(self.dim) * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))  # Expectation of ||N(0,I)||\n        self.c_sigma = (self.mu / np.sum(range(1, self.dim+1)))/4\n        self.c_c = (4 + self.mu/self.dim) / (self.dim + 4 + 2*self.mu/self.dim)\n        self.weights = np.array([np.log(self.mu + 1) - np.log(i) for i in range(1, self.mu + 1)])\n        self.weights = self.weights / np.sum(self.weights)\n        self.D = np.ones(self.dim)\n        self.B = np.eye(self.dim)\n        \n    def sample_cmaes(self):\n        \"\"\"\n        Sample new points from the CMA-ES distribution.\n        \"\"\"\n        z = np.random.randn(self.pop_size, self.dim)\n        y = np.dot(z, self.B) * np.tile(self.D, (self.pop_size, 1))\n        x = self.mean + self.sigma * y\n\n        # Clip to bounds\n        x = np.clip(x, func.bounds.lb, func.bounds.ub)\n        return x\n    \n    def update_cmaes(self, func):\n        \"\"\"\n        Update CMA-ES parameters based on the new population.\n        \"\"\"\n        # Sample new population\n        new_pop = self.sample_cmaes()\n        new_fitness = np.array([func(x) for x in new_pop])\n        self.eval_count += self.pop_size\n        \n        # Sort new population by fitness\n        idx = np.argsort(new_fitness)\n        new_pop = new_pop[idx]\n        new_fitness = new_fitness[idx]\n        \n        # Selection and recombination\n        x_mu = new_pop[:self.mu]\n        y_mu = (x_mu - self.mean) / self.sigma\n        \n        # Update mean\n        self.mean = np.sum(self.weights[:, np.newaxis] * x_mu, axis=0)\n        \n        # Update evolution paths\n        y_w = np.sum(self.weights[:, np.newaxis] * y_mu, axis=0)\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * y_w\n        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.eval_count / self.pop_size)) < self.chiN * (1.4 + 2 / (self.dim + 1))\n        self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c)) * (self.mean - self.global_best_position) / self.sigma  # Using global_best_position instead of old mean\n\n        # Update covariance matrix\n        self.C = (1 - self.c_c) * self.C + self.c_c * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :])\n        \n        # Update step size\n        self.sigma *= np.exp(min(0.5, self.cs / self.damp * (np.linalg.norm(self.ps) / self.chiN - 1)))\n        self.sigma = max(1e-10, self.sigma)\n\n        # Eigen decomposition (can be optimized with rank-one updates)\n        try:\n            self.D, self.B = np.linalg.eigh(self.C)\n            self.D = np.sqrt(np.maximum(self.D, 0))\n        except:\n            # If the covariance matrix is not positive definite, reset it to identity\n            self.C = np.eye(self.dim)\n            self.D = np.ones(self.dim)\n            self.B = np.eye(self.dim)\n\n        # Update population and fitness\n        self.pop = new_pop.copy()\n        self.fitness = new_fitness.copy()\n\n        # Update best solution\n        if new_fitness[0] < self.global_best_fitness:\n            self.global_best_fitness = new_fitness[0]\n            self.global_best_position = new_pop[0].copy()\n            \n    def update_pso(self, func):\n        \"\"\"\n        Update the population using Particle Swarm Optimization.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        cognitive_component = self.c1 * r1 * (self.best_positions - self.pop)\n        social_component = self.c2 * r2 * (self.global_best_position - self.pop)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_component + social_component\n        self.pop += self.velocities\n\n        # Clip to bounds\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n\n        new_fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        for i in range(self.pop_size):\n            if new_fitness[i] < self.fitness[i]:\n                self.fitness[i] = new_fitness[i]\n                self.best_positions[i] = self.pop[i].copy()\n                if new_fitness[i] < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness[i]\n                    self.global_best_position = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using the PSOCMAES optimizer.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n           \n            self.update_pso(func)\n            self.update_cmaes(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 2, "feedback": "An exception occurred: name 'func' is not defined.", "error": "", "parent_ids": ["bfdce419-bcb7-4d05-9ab0-775ba14e301d"], "operator": null, "metadata": {}}
{"id": "e1077cd2-1fd7-452a-b3a8-d6bd0ea4f0b0", "fitness": 0.41994375363959424, "name": "HybridSAMutation", "description": "Simplified hybrid algorithm with adaptive parameter control based on stagnation, alternating between PSO and DE with a simplified SA acceptance criterion.", "code": "import numpy as np\n\nclass HybridSAMutation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_weight=0.7,\n                 c1=1.5, c2=1.5, F=0.8, CR=0.9, initial_temp=1.0, cooling_rate=0.95,\n                 stagnation_threshold=50):\n        \"\"\"\n        Initialize the Hybrid SAMutation Optimizer.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp = initial_temp\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.best_positions = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.stagnation_threshold = stagnation_threshold\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.best_positions = self.pop.copy()\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_pso(self, func):\n        \"\"\"\n        Update the population using Particle Swarm Optimization.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        cognitive_component = self.c1 * r1 * (self.best_positions - self.pop)\n        social_component = self.c2 * r2 * (self.global_best_position - self.pop)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_component + social_component\n        self.pop += self.velocities\n\n        # Clip to bounds\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n\n        new_fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        for i in range(self.pop_size):\n            if new_fitness[i] < self.fitness[i]:\n                self.fitness[i] = new_fitness[i]\n                self.best_positions[i] = self.pop[i].copy()\n                if new_fitness[i] < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness[i]\n                    self.global_best_position = self.pop[i].copy()\n                    self.stagnation_counter = 0  # Reset stagnation counter\n            elif np.random.rand() < np.exp(-(new_fitness[i] - self.fitness[i]) / self.temp):\n                self.fitness[i] = new_fitness[i]\n                self.pop[i] = self.pop[i].copy()\n                self.best_positions[i] = self.pop[i].copy() #Also update best position\n\n\n\n    def update_de(self, func):\n        \"\"\"\n        Update the population using Differential Evolution.\n        \"\"\"\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            v_i = x_r1 + self.F * (x_r2 - x_r3)\n            v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_i = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n\n            # Selection\n            f_u_i = func(u_i)\n            self.eval_count += 1\n\n            if f_u_i < self.fitness[i]:\n                self.fitness[i] = f_u_i\n                self.pop[i] = u_i.copy()\n                self.best_positions[i] = u_i.copy()\n                if f_u_i < self.global_best_fitness:\n                    self.global_best_fitness = f_u_i\n                    self.global_best_position = u_i.copy()\n                    self.stagnation_counter = 0  # Reset stagnation counter\n            elif np.random.rand() < np.exp(-(f_u_i - self.fitness[i]) / self.temp):\n                self.fitness[i] = f_u_i\n                self.pop[i] = u_i.copy()\n                self.best_positions[i] = u_i.copy() #Also update best position\n\n    def adapt_parameters(self):\n        \"\"\"\n        Adapt parameters based on performance and stagnation.\n        \"\"\"\n        if self.stagnation_counter > self.stagnation_threshold:\n            # Increase exploration if stagnant\n            self.inertia_weight = min(0.9, self.inertia_weight + 0.05)\n            self.F = min(1.0, self.F + 0.05)\n            self.CR = min(0.99, self.CR + 0.05)\n            # Increase temp if stuck\n            self.temp = self.initial_temp\n        else:\n            # Reduce inertia and temp to exploit\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Keep inertia in reasonable range\n            self.temp *= self.cooling_rate\n            self.CR *= 0.99\n        self.stagnation_counter += 1\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using the Hybrid SAMutation Optimizer.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Alternate between PSO and DE\n            if self.eval_count % 2 == 0:\n                self.update_pso(func)\n            else:\n                self.update_de(func)\n\n            # Adapt parameters\n            self.adapt_parameters()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm HybridSAMutation scored 0.420 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["669a00ab-a51f-4977-af17-e7a847383b3b"], "operator": null, "metadata": {"aucs": [0.1932515248811837, 0.23591121996402675, 0.5494375823369944, 0.9607374787468064, 0.2630337866419502, 0.2441350218112306, 0.3050492829051993, 0.48758769838659044, 0.7529607095804489, 0.16409502320896374, 0.23806515385446314, 0.9952016249067585, 0.2879772134160996, 0.18717693451948114, 0.6505351268664102, 0.4786354734578502, 0.33063453850971436, 0.37752475566763977, 0.2274689831367065, 0.4694559399933671]}}
{"id": "6e222d6f-a724-4353-8297-e40a98052eaa", "fitness": 0.3705353075238504, "name": "AdaptivePopulationSearch", "description": "Improved adaptive population search with momentum, adaptive exploration rate annealing, and a more robust learning rate adaptation strategy based on both variance and best fitness improvement.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1, min_lr = 0.001, momentum=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.min_lr = min_lr\n        self.exploration_rate = 0.7\n        self.mutation_factor = 0.5\n        self.momentum = momentum\n        self.velocity = np.zeros((pop_size, dim)) # Initialize velocity for momentum\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy() #important to copy\n\n        best_fitness_history = [] # Track best fitness improvement\n\n        while self.budget > 0:\n            # Calculate fitness variance for learning rate adaptation\n            fitness_variance = np.var(self.fitness)\n            \n            # Calculate the improvement in best fitness over the recent iterations\n            if len(best_fitness_history) > 5:\n                fitness_improvement = best_fitness_history[-5] - self.f_opt\n            else:\n                fitness_improvement = 0\n                \n            best_fitness_history.append(self.f_opt)\n\n            for i in range(self.pop_size):\n                # Exploration vs. Exploitation\n                if np.random.rand() < self.exploration_rate:\n                    # Enhanced Differential Evolution-inspired mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_rand1, x_rand2, x_rand3 = self.population[idxs]\n                    \n                    # Adaptive mutation factor based on fitness variance\n                    adaptive_mutation_factor = self.mutation_factor * (1 + fitness_variance)\n                    \n                    mutant = self.population[i] + adaptive_mutation_factor * (x_rand1 - x_rand2)\n\n                    # Clip to bounds\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                    \n                    f_mutant = func(mutant)\n                    self.budget -= 1\n\n                    if f_mutant < self.fitness[i]:\n                        self.population[i] = mutant\n                        self.fitness[i] = f_mutant\n\n                        if f_mutant < self.f_opt:\n                            self.f_opt = f_mutant\n                            self.x_opt = mutant.copy() # important to copy\n                else:\n                    # Exploitation: Move towards the best solution with momentum\n                    step = self.lr * (self.x_opt - self.population[i])\n                    \n                    # Update velocity with momentum\n                    self.velocity[i] = self.momentum * self.velocity[i] + step\n                    \n                    new_x = self.population[i] + self.velocity[i]\n                    new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                    \n                    f_new = func(new_x)\n                    self.budget -= 1\n\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = f_new\n\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = new_x.copy() # important to copy\n                \n                if self.budget <= 0:\n                    break\n\n            # Adaptive learning rate adjustment\n            if fitness_variance > 1e-6:\n                self.lr *= (1 - (0.1 / (1 + fitness_variance)))  # Reduce lr less when variance is high\n            else:\n                self.lr *= 0.9  # Reduce lr more aggressively when variance is low\n\n            # Adapt learning rate based on best fitness improvement\n            if fitness_improvement > 0:\n                self.lr *= 1.05 # increase the learning rate if we've seen improvement\n            else:\n                self.lr *= 0.95 # decrease learning rate if we haven't seen improvement\n            \n            self.lr = max(self.lr, self.min_lr) # Ensure that lr doesn't go too low\n            \n            # Anneal exploration rate more aggressively.\n            self.exploration_rate *= 0.99 # Gradually reduce exploration rate\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptivePopulationSearch scored 0.371 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ed0df5a3-5c6c-4122-a8ce-19ebfc843996"], "operator": null, "metadata": {"aucs": [0.12032618838249587, 0.28507445926028185, 0.3626295375486619, 0.5160523450321819, 0.20921949108609172, 0.36657750626938146, 0.2745263308076492, 0.375253237937056, 0.2823933282727479, 0.19425510022744819, 0.5278586626686199, 0.9976065286731522, 0.21556474304152307, 0.28828952888885173, 0.6424805637994586, 0.36270896687970167, 0.3124047864606102, 0.47940341945307297, 0.11981963687604424, 0.4782617889119777]}}
{"id": "e15771d6-385f-4fbb-9032-f65e8b14c2ba", "fitness": 0.6320791324276817, "name": "AdaptivePopulationSearch", "description": "Simplified adaptive population search using a single, combined update rule based on best solution and random individuals.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1, min_lr=0.001, mutation_factor=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.min_lr = min_lr\n        self.mutation_factor = mutation_factor\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            # Calculate fitness variance for learning rate adaptation\n            fitness_variance = np.var(self.fitness)\n\n            for i in range(self.pop_size):\n                # Combined Update Rule\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_rand1, x_rand2 = self.population[idxs]\n\n                # Adaptive step size\n                step = self.lr * (self.x_opt - self.population[i]) + self.mutation_factor * (x_rand1 - x_rand2)\n                new_x = self.population[i] + step\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n                f_new = func(new_x)\n                self.budget -= 1\n\n                if f_new < self.fitness[i]:\n                    self.population[i] = new_x\n                    self.fitness[i] = f_new\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = new_x\n                \n                if self.budget <= 0:\n                    break\n\n            # Adaptive learning rate adjustment\n            if fitness_variance > 1e-6:\n                self.lr *= (1 - (0.1 / (1 + fitness_variance)))\n            else:\n                self.lr *= 0.9\n            self.lr = max(self.lr, self.min_lr)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptivePopulationSearch scored 0.632 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ed0df5a3-5c6c-4122-a8ce-19ebfc843996"], "operator": null, "metadata": {"aucs": [0.20279542178808696, 0.6647824079887077, 0.6296781106208803, 0.8858239135204927, 0.6784469965488307, 0.7704887182983532, 0.34519040507073073, 0.6114893761913788, 0.632887846730311, 0.3867027142016757, 0.8817770629668429, 0.9961849496902447, 0.7814291234796091, 0.464021552282317, 0.9206272222202764, 0.7448187542721298, 0.49434151586706476, 0.8481282527270435, 0.20133702585003876, 0.5006312782386185]}}
{"id": "9933447d-45d5-41d8-90cf-cb04bacce5c1", "fitness": 0.5583821461234965, "name": "AdaptiveHybridOptimizer", "description": "Combines PSO and DE with simplified parameter adaptation based on stagnation, using a dynamically adjusted probability to switch between PSO and DE based on their success rates.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_weight=0.7,\n                 c1=1.5, c2=1.5, F=0.8, CR=0.9, pso_prob=0.5, stagnation_threshold=100):\n        \"\"\"\n        Initialize the Adaptive Hybrid Optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            inertia_weight (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            pso_prob (float): Initial probability of using PSO.\n            stagnation_threshold (int): Number of iterations without improvement before adapting PSO/DE probability.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pso_prob = pso_prob\n        self.stagnation_threshold = stagnation_threshold\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.best_positions = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.last_global_best_fitness = np.inf\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.best_positions = self.pop.copy()\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_global_best_fitness = self.global_best_fitness\n\n    def update_pso(self, func):\n        \"\"\"\n        Update the population using Particle Swarm Optimization.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        cognitive_component = self.c1 * r1 * (self.best_positions - self.pop)\n        social_component = self.c2 * r2 * (self.global_best_position - self.pop)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_component + social_component\n        self.pop += self.velocities\n\n        # Clip to bounds\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n\n        new_fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        for i in range(self.pop_size):\n            if new_fitness[i] < self.fitness[i]:\n                self.fitness[i] = new_fitness[i]\n                self.best_positions[i] = self.pop[i].copy()\n                if new_fitness[i] < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness[i]\n                    self.global_best_position = self.pop[i].copy()\n\n    def update_de(self, func):\n        \"\"\"\n        Update the population using Differential Evolution.\n        \"\"\"\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            v_i = x_r1 + self.F * (x_r2 - x_r3)\n            v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_i = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n\n            # Selection\n            f_u_i = func(u_i)\n            self.eval_count += 1\n\n            if f_u_i < self.fitness[i]:\n                self.fitness[i] = f_u_i\n                self.pop[i] = u_i.copy()\n                self.best_positions[i] = u_i.copy()\n                if f_u_i < self.global_best_fitness:\n                    self.global_best_fitness = f_u_i\n                    self.global_best_position = u_i.copy()\n\n    def adapt_probability(self):\n        \"\"\"Adapt PSO/DE probability based on stagnation.\"\"\"\n        if self.global_best_fitness < self.last_global_best_fitness:\n            self.stagnation_counter = 0\n            self.last_global_best_fitness = self.global_best_fitness\n        else:\n            self.stagnation_counter += 1\n\n        if self.stagnation_counter > self.stagnation_threshold:\n            # Stagnation detected: adjust pso_prob\n            self.pso_prob = 0.5 - (0.5 - self.pso_prob) * 0.9  # Move pso_prob towards 0.5\n            self.stagnation_counter = 0  # Reset counter\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using the Adaptive Hybrid Optimizer.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Decide between PSO and DE based on pso_prob\n            if np.random.rand() < self.pso_prob:\n                self.update_pso(func)\n            else:\n                self.update_de(func)\n\n            self.adapt_probability()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridOptimizer scored 0.558 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["bfdce419-bcb7-4d05-9ab0-775ba14e301d"], "operator": null, "metadata": {"aucs": [0.1730677020224417, 0.26829083874306026, 0.6987085832072206, 0.8698404700576183, 0.26329858582714594, 0.8300422924926635, 0.32828123428494493, 0.7042954708581108, 0.786585511847501, 0.7328917702507, 0.8600295936643217, 0.9967576788091526, 0.30870665687235443, 0.32600751085411517, 0.7257346115343752, 0.3557089458686391, 0.3117236053078517, 0.9091669253847239, 0.22325715026068849, 0.4952477843222991]}}
{"id": "0cd53d51-e35b-4f0a-b621-0f0afb0edd12", "fitness": 0.44770089888660614, "name": "AdaptiveHybridCMAES", "description": "An adaptive hybrid algorithm that dynamically adjusts the exploration-exploitation balance using a combination of PSO, DE, and CMA-ES components, guided by the success rate of each component.", "code": "import numpy as np\n\nclass AdaptiveHybridCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_weight=0.7,\n                 c1=1.5, c2=1.5, F=0.8, CR=0.9, initial_sigma=0.1):\n        \"\"\"\n        Initialize the Adaptive Hybrid CMA-ES Optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles/individuals in the population.\n            inertia_weight (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            initial_sigma (float): Initial standard deviation for CMA-ES.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.initial_sigma = initial_sigma\n        self.sigma = initial_sigma\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.best_positions = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.max_stagnation = 50\n        self.pso_success_rate = 0.5\n        self.de_success_rate = 0.5\n        self.cmaes_success_rate = 0.5\n        self.success_memory = 10  # Number of iterations to remember success\n        self.pso_successes = []\n        self.de_successes = []\n        self.cmaes_successes = []\n\n        # CMA-ES specific parameters (simplified)\n        self.mean = None\n        self.C = None #covariance matrix\n        self.pc = None\n        self.ps = None\n        self.damps = 1 + (dim / 2)\n        self.cs = (self.damps - 1) / (dim + 5)\n        self.cc = (4 + (dim / 3)) / (dim + 4) #learning rate for the mean\n        self.mu = pop_size // 2 #number of individuals for recombination\n        self.weights = np.log(self.mu+0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.eigeneval = 0\n        self.chiN = dim**0.5 * (1 - 1 / (4 * dim) + 1 / (21 * dim**2)) #expectation of ||N(0,I)||\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.best_positions = self.pop.copy()\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n        # Initialize CMA-ES\n        self.mean = self.global_best_position.copy()\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n    def update_pso(self, func):\n        \"\"\"\n        Update the population using Particle Swarm Optimization.\n        \"\"\"\n        original_fitness = self.fitness.copy()\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        cognitive_component = self.c1 * r1 * (self.best_positions - self.pop)\n        social_component = self.c2 * r2 * (self.global_best_position - self.pop)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_component + social_component\n        self.pop += self.velocities\n\n        # Clip to bounds\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n\n        new_fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        improved = False\n        for i in range(self.pop_size):\n            if new_fitness[i] < self.fitness[i]:\n                self.fitness[i] = new_fitness[i]\n                self.best_positions[i] = self.pop[i].copy()\n                if new_fitness[i] < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness[i]\n                    self.global_best_position = self.pop[i].copy()\n                    self.stagnation_counter = 0\n                    improved = True\n        self.pso_successes.append(int(improved))\n        if len(self.pso_successes) > self.success_memory:\n            self.pso_successes.pop(0)\n        return original_fitness\n\n    def update_de(self, func):\n        \"\"\"\n        Update the population using Differential Evolution.\n        \"\"\"\n        original_fitness = self.fitness.copy()\n        improved = False\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            v_i = x_r1 + self.F * (x_r2 - x_r3)\n            v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_i = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n\n            # Selection\n            f_u_i = func(u_i)\n            self.eval_count += 1\n\n            if f_u_i < self.fitness[i]:\n                self.fitness[i] = f_u_i\n                self.pop[i] = u_i.copy()\n                self.best_positions[i] = u_i.copy()\n                if f_u_i < self.global_best_fitness:\n                    self.global_best_fitness = f_u_i\n                    self.global_best_position = u_i.copy()\n                    self.stagnation_counter = 0\n                    improved = True\n        self.de_successes.append(int(improved))\n        if len(self.de_successes) > self.success_memory:\n            self.de_successes.pop(0)\n        return original_fitness\n\n    def update_cmaes(self, func):\n        \"\"\"\n        Update the population using CMA-ES.\n        \"\"\"\n        original_fitness = self.fitness.copy()\n        z = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.pop_size)\n        x = self.mean + self.sigma * z\n        x = np.clip(x, func.bounds.lb, func.bounds.ub)\n        fitness = np.array([func(xi) for xi in x])\n        self.eval_count += self.pop_size\n\n        idx = np.argsort(fitness)\n        best_individuals = x[idx[:self.mu]]\n        old_mean = self.mean.copy()\n        self.mean = np.sum(best_individuals * self.weights[:, np.newaxis], axis=0)\n\n        ps_update = (self.cs * (self.mean - old_mean) / self.sigma)\n        self.ps = (1 - self.cs) * self.ps + ps_update\n\n        pc_update = (self.cc * (self.mean - old_mean) / self.sigma)\n\n        self.pc = (1-self.cc) * self.pc + pc_update\n        self.C = (1-self.cc) * self.C + self.cc * np.outer(self.pc, self.pc)\n\n        self.sigma *= np.exp(self.cs / self.damps * (np.linalg.norm(self.ps) / self.chiN - 1))\n        self.sigma = max(self.sigma, 1e-8)\n\n        improved = False\n        for i in range(self.pop_size):\n            if fitness[i] < self.fitness[i]:\n                self.fitness[i] = fitness[i]\n                self.pop[i] = x[i].copy()\n                self.best_positions[i] = x[i].copy()\n\n                if fitness[i] < self.global_best_fitness:\n                    self.global_best_fitness = fitness[i]\n                    self.global_best_position = x[i].copy()\n                    self.stagnation_counter = 0\n                    improved = True\n        self.cmaes_successes.append(int(improved))\n        if len(self.cmaes_successes) > self.success_memory:\n            self.cmaes_successes.pop(0)\n\n        return original_fitness\n\n\n    def adapt_probabilities(self):\n        \"\"\"\n        Adapt the probabilities of using PSO, DE, and CMA-ES based on their recent success.\n        \"\"\"\n        if self.pso_successes:\n            self.pso_success_rate = np.mean(self.pso_successes)\n        if self.de_successes:\n            self.de_success_rate = np.mean(self.de_successes)\n        if self.cmaes_successes:\n            self.cmaes_success_rate = np.mean(self.cmaes_successes)\n\n        total_success = self.pso_success_rate + self.de_success_rate + self.cmaes_success_rate\n        if total_success > 0:\n            self.pso_prob = self.pso_success_rate / total_success\n            self.de_prob = self.de_success_rate / total_success\n            self.cmaes_prob = self.cmaes_success_rate / total_success\n        else:\n            self.pso_prob = 1/3\n            self.de_prob = 1/3\n            self.cmaes_prob = 1/3\n\n    def adapt_parameters(self):\n        \"\"\"\n        Adapt parameters based on performance and stagnation.\n        \"\"\"\n        if self.stagnation_counter > self.max_stagnation:\n            # Increase exploration if stagnant\n            self.inertia_weight = min(0.9, self.inertia_weight + 0.05)\n            self.F = min(1.0, self.F + 0.05)\n            self.sigma *= 1.1\n        else:\n            # Reduce inertia and temp to exploit\n            self.inertia_weight *= 0.99\n            self.inertia_weight = max(0.4, self.inertia_weight)\n            self.sigma *= 0.99\n\n        self.CR = min(0.99, self.CR + 0.01)\n        self.stagnation_counter += 1\n        self.sigma = min(self.sigma, 1)\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using the Adaptive Hybrid CMA-ES Optimizer.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        best_fitness_history = []\n\n        self.pso_prob = 1/3\n        self.de_prob = 1/3\n        self.cmaes_prob = 1/3\n\n        while self.eval_count < self.budget:\n            # Choose between PSO, DE, and CMA-ES based on adaptive probabilities\n            rand = np.random.rand()\n            if rand < self.pso_prob:\n                self.update_pso(func)\n            elif rand < self.pso_prob + self.de_prob:\n                self.update_de(func)\n            else:\n                self.update_cmaes(func)\n\n            # Adapt probabilities and parameters\n            self.adapt_probabilities()\n            self.adapt_parameters()\n            best_fitness_history.append(self.global_best_fitness)\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridCMAES scored 0.448 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["669a00ab-a51f-4977-af17-e7a847383b3b"], "operator": null, "metadata": {"aucs": [0.13305609177232114, 0.22044357446834428, 0.9198554084719588, 0.1726845008861102, 0.26337776071625396, 0.9411389289360277, 0.38162971284763025, 0.513606827076077, 0.21394299138028572, 0.24438793916968304, 0.40762616040070443, 0.9966306620590913, 0.255689923401503, 0.2110259844399367, 0.5880179742208156, 0.6908461768880527, 0.7751916722343675, 0.2905250006472605, 0.19426865859158393, 0.5400720291241148]}}
{"id": "dd8e82a9-b2d6-432e-a22f-50f671ef4a93", "fitness": 0.46867106314075935, "name": "SelfAdaptiveDE", "description": "A self-adaptive Differential Evolution algorithm with a Cauchy mutation operator and a learning strategy based on successful mutations.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, tau1=0.1, tau2=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = np.full(pop_size, F)  # Mutation factor for each individual\n        self.Cr = np.full(pop_size, Cr)  # Crossover rate for each individual\n        self.tau1 = tau1\n        self.tau2 = tau2\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_F = []\n        self.success_Cr = []\n        self.success_history_length = 10\n        self.archive_F = []\n        self.archive_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        while i in idxs:\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n\n        # Self-adaptive F\n        if np.random.rand() < self.tau1:\n            self.F[i] = np.clip(np.random.normal(0.5, 0.3), 0.0, 1.0)\n\n        # Cauchy mutation\n        mutated = x_r1 + self.F[i] * (x_r2 - x_r3) * np.random.standard_cauchy(size=self.dim)\n        return np.clip(mutated, -5.0, 5.0)\n\n    def crossover(self, mutated, i):\n        # Self-adaptive Cr\n        if np.random.rand() < self.tau2:\n            self.Cr[i] = np.random.rand()\n\n        crossed = np.copy(self.pop[i])\n        for j in range(self.dim):\n            if np.random.rand() < self.Cr[i]:\n                crossed[j] = mutated[j]\n        return crossed\n\n    def selection(self, func, crossed, i):\n        f_new = func(crossed)\n        self.eval_count += 1\n\n        if f_new < self.fitness[i]:\n            # Store successful F and Cr values\n            self.success_F.append(self.F[i])\n            self.success_Cr.append(self.Cr[i])\n            if len(self.success_F) > self.success_history_length:\n                self.success_F.pop(0)\n                self.success_Cr.pop(0)\n\n            self.pop[i] = crossed\n            self.fitness[i] = f_new\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = crossed\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutated = self.mutate(i)\n                crossed = self.crossover(mutated, i)\n                self.selection(func, crossed, i)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm SelfAdaptiveDE scored 0.469 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["93a4fb57-8df4-435b-b007-3e58864d1405"], "operator": null, "metadata": {"aucs": [0.18160146634356433, 0.2814863363218558, 0.42999295280679295, 0.6389877825476028, 0.41821299714633564, 0.5363053172010763, 0.35256595192042306, 0.4283788131023042, 0.47707918395897064, 0.4176313832930282, 0.4307801960382548, 0.9930634644960201, 0.2917802918498351, 0.4292674808067639, 0.7035828827627799, 0.5738174721489093, 0.36354613513700373, 0.624892461211187, 0.3006492615805134, 0.4997994321419642]}}
{"id": "8e062f11-5acb-407f-bba5-e86abf4b738f", "fitness": 0.5948267231542343, "name": "HybridSAMutation", "description": "Combines PSO and DE with simulated annealing-inspired acceptance and adaptive parameter control, focusing on diversifying DE mutation using historical best information and dynamically adjusting PSO/DE balance.", "code": "import numpy as np\n\nclass HybridSAMutation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_weight=0.7,\n                 c1=1.5, c2=1.5, F=0.8, CR=0.9, initial_temp=1.0, cooling_rate=0.95, pso_ratio=0.5):\n        \"\"\"\n        Initialize the Hybrid SAMutation Optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            inertia_weight (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            initial_temp (float): Initial temperature for SA.\n            cooling_rate (float): Cooling rate for SA.\n            pso_ratio (float): Probability of using PSO update.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp = initial_temp\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.best_positions = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.max_stagnation = 50 #Number of iterations with no improvement\n        self.pso_ratio = pso_ratio\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.best_positions = self.pop.copy()\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_pso(self, func):\n        \"\"\"\n        Update the population using Particle Swarm Optimization.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        cognitive_component = self.c1 * r1 * (self.best_positions - self.pop)\n        social_component = self.c2 * r2 * (self.global_best_position - self.pop)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_component + social_component\n        self.pop += self.velocities\n\n        # Clip to bounds\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n\n        new_fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        for i in range(self.pop_size):\n            if new_fitness[i] < self.fitness[i]:\n                self.fitness[i] = new_fitness[i]\n                self.best_positions[i] = self.pop[i].copy()\n                if new_fitness[i] < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness[i]\n                    self.global_best_position = self.pop[i].copy()\n                    self.stagnation_counter = 0 #reset stagnation counter\n            else:\n                #Simulated Annealing inspired acceptance\n                delta_e = new_fitness[i] - self.fitness[i]\n                if np.random.rand() < np.exp(-delta_e / self.temp):\n                  self.fitness[i] = new_fitness[i]\n                  self.pop[i] = self.pop[i].copy()\n        \n\n    def update_de(self, func):\n        \"\"\"\n        Update the population using Differential Evolution with historical best.\n        \"\"\"\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x_r1, x_r2 = self.pop[idxs]\n            # Use global best to guide mutation\n            v_i = self.best_positions[i] + self.F * (x_r1 - x_r2)  # Use individual best instead of x_r1\n            v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_i = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n\n            # Selection\n            f_u_i = func(u_i)\n            self.eval_count += 1\n\n            if f_u_i < self.fitness[i]:\n                self.fitness[i] = f_u_i\n                self.pop[i] = u_i.copy()\n                self.best_positions[i] = u_i.copy()\n                if f_u_i < self.global_best_fitness:\n                    self.global_best_fitness = f_u_i\n                    self.global_best_position = u_i.copy()\n                    self.stagnation_counter = 0 #reset stagnation counter\n            else:\n                #Simulated Annealing inspired acceptance\n                delta_e = f_u_i - self.fitness[i]\n                if np.random.rand() < np.exp(-delta_e / self.temp):\n                  self.fitness[i] = f_u_i\n                  self.pop[i] = u_i.copy()\n\n\n    def adapt_parameters(self):\n          \"\"\"\n          Adapt parameters based on performance and stagnation.\n          \"\"\"\n          if self.stagnation_counter > self.max_stagnation:\n              # Increase exploration if stagnant\n              self.inertia_weight = min(0.9, self.inertia_weight + 0.05)\n              self.F = min(1.0, self.F + 0.05)\n              #increase temp if stuck\n              self.temp = self.initial_temp\n              self.pso_ratio = min(1.0, self.pso_ratio + 0.1) #Favor PSO more when stuck\n          else:\n              # Reduce inertia and temp to exploit\n              self.inertia_weight *= 0.99\n              self.inertia_weight = max(0.4, self.inertia_weight)\n              self.temp *= self.cooling_rate\n              self.pso_ratio = max(0.0, self.pso_ratio - 0.05) #Favor DE more when improving\n\n          self.CR = min(0.99, self.CR + 0.01)\n          self.stagnation_counter +=1\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using the Hybrid SAMutation Optimizer.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        best_fitness_history = []\n\n        while self.eval_count < self.budget:\n            # Alternate between PSO and DE based on pso_ratio\n            if np.random.rand() < self.pso_ratio:\n                self.update_pso(func)\n            else:\n                self.update_de(func)\n\n            # Adapt parameters\n            self.adapt_parameters()\n            best_fitness_history.append(self.global_best_fitness)\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm HybridSAMutation scored 0.595 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["669a00ab-a51f-4977-af17-e7a847383b3b"], "operator": null, "metadata": {"aucs": [0.17098775829120916, 0.6733557480216448, 0.5755626018145448, 0.80733303931278, 0.649416124007842, 0.6943907778991658, 0.4129368804503377, 0.5807652852309078, 0.6717124610823004, 0.1993015725510079, 0.8363617634786763, 0.996793267518312, 0.6950829632950171, 0.6547188379846065, 0.723776481528557, 0.6652035246070227, 0.49702382507089793, 0.727182187630331, 0.1822389264769273, 0.4823904368325994]}}
{"id": "a50af155-9055-4b90-b8db-fefb1841b576", "fitness": -Infinity, "name": "ImprovedAdaptiveDifferentialEvolution", "description": "Improved Adaptive Differential Evolution with archive for storing promising solutions and enhanced parameter adaptation based on population diversity.", "code": "import numpy as np\n\nclass ImprovedAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.archive = []\n        self.archive_fitness = []\n        self.archive_size = archive_size\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, i):\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        while i in idxs:\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n        x_r1, x_r2 = self.pop[idxs]\n\n        if len(self.archive) > 0 and np.random.rand() < 0.1:  # Use archive occasionally\n            arch_idx = np.random.randint(len(self.archive))\n            x_r3 = self.archive[arch_idx]\n        else:\n            idxs = np.random.choice(self.pop_size, 1, replace=False)\n            while i in idxs or idxs[0] in idxs[:2]:\n                idxs = np.random.choice(self.pop_size, 1, replace=False)\n            x_r3 = self.pop[idxs[0]]\n\n        # Adaptive F based on population diversity\n        pop_std = np.std(self.fitness)\n        if pop_std > 1e-3:\n            F_adaptive = self.F * (1 + np.random.normal(0, 0.1))\n        else:\n            F_adaptive = 1.0 # Increase exploration when population is too uniform\n\n\n        mutated = x_r1 + F_adaptive * (x_r2 - x_r3)\n        return np.clip(mutated, -5.0, 5.0)\n\n    def crossover(self, mutated, i):\n        crossed = np.copy(self.pop[i])\n        for j in range(self.dim):\n            if np.random.rand() < self.Cr:\n                crossed[j] = mutated[j]\n        return crossed\n\n    def selection(self, func, crossed, i):\n        f_new = func(crossed)\n        self.eval_count += 1\n\n        if f_new < self.fitness[i]:\n            self.pop[i] = crossed\n            self.fitness[i] = f_new\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = crossed\n            \n            # Update archive\n            if len(self.archive) < self.archive_size:\n                self.archive.append(crossed)\n                self.archive_fitness.append(f_new)\n            else:\n                max_archive_fitness_idx = np.argmax(self.archive_fitness)\n                if f_new < self.archive_fitness[max_archive_fitness_idx]:\n                    self.archive[max_archive_fitness_idx] = crossed\n                    self.archive_fitness[max_archive_fitness_idx] = f_new\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutated = self.mutate(i)\n                crossed = self.crossover(mutated, i)\n                self.selection(func, crossed, i)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: Evaluation timed out after 60 seconds..", "error": "", "parent_ids": ["93a4fb57-8df4-435b-b007-3e58864d1405"], "operator": null, "metadata": {}}
{"id": "177200b6-bfab-4e48-8f6c-7be745d80d6b", "fitness": 0.2358170304257942, "name": "AdaptivePopulationSearch", "description": "Adaptive population search with covariance matrix adaptation and dynamic exploration-exploitation balance based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1, min_lr = 0.001, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.min_lr = min_lr\n        self.exploration_rate = 0.7\n        self.mutation_factor = 0.5\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.covariance_matrix = np.eye(dim)\n        self.mean = None\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.mean = np.mean(self.population, axis=0)\n\n        while self.budget > 0:\n            # Calculate fitness variance for learning rate adaptation\n            fitness_variance = np.var(self.fitness)\n\n            # Stagnation Detection\n            if np.abs(self.f_opt - np.mean(self.fitness)) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            # Adjust exploration rate based on stagnation\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.exploration_rate = min(1.0, self.exploration_rate * 1.1)  # Increase exploration\n                self.lr = min(0.5, self.lr * 1.1) #Increase learning rate to escape local optima\n            else:\n                self.exploration_rate *= 0.995 # Gradually reduce exploration rate\n                \n            for i in range(self.pop_size):\n                # Exploration vs. Exploitation\n                if np.random.rand() < self.exploration_rate:\n                    # Covariance Matrix Adaptation for Exploration\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n                    mutant = self.mean + self.mutation_factor * z\n                    # Clip to bounds\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                    \n                    f_mutant = func(mutant)\n                    self.budget -= 1\n\n                    if f_mutant < self.fitness[i]:\n                        self.population[i] = mutant\n                        self.fitness[i] = f_mutant\n\n                        if f_mutant < self.f_opt:\n                            self.f_opt = f_mutant\n                            self.x_opt = mutant\n                else:\n                    # Exploitation: Move towards the best solution\n                    step = self.lr * (self.x_opt - self.population[i])\n                    new_x = self.population[i] + step\n                    new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                    \n                    f_new = func(new_x)\n                    self.budget -= 1\n\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = f_new\n\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = new_x\n                \n                if self.budget <= 0:\n                    break\n\n            # Adaptive learning rate adjustment\n            if fitness_variance > 1e-6:  # Avoid division by zero\n                self.lr *= (1 - (0.1 / (1 + fitness_variance)))  # Reduce lr less when variance is high\n            else:\n                self.lr *= 0.9  # Reduce lr more aggressively when variance is low\n            \n            self.lr = max(self.lr, self.min_lr) # Ensure that lr doesn't go too low\n            self.mean = np.mean(self.population, axis=0)\n            self.covariance_matrix = np.cov(self.population.T)\n            if not np.all(np.linalg.eigvals(self.covariance_matrix) > 0):\n                self.covariance_matrix = np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptivePopulationSearch scored 0.236 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ed0df5a3-5c6c-4122-a8ce-19ebfc843996"], "operator": null, "metadata": {"aucs": [0.0992725669977248, 0.16288863215721738, 0.2673424386895089, 0.13975754383462913, 0.1645850276978159, 0.19057082109726275, 0.2587177209361644, 0.18974683921794966, 0.1698235766698224, 0.14116030070882002, 0.15505832703843803, 0.9985035175305464, 0.25537992883488914, 0.13331944457671374, 0.14878940069627733, 0.24410818782274835, 0.21042013835837603, 0.18504910718474255, 0.15318867794391067, 0.44865841052232647]}}
{"id": "c8ba83b4-ca8c-42a8-8cc4-b97d4c20f5b9", "fitness": 0.7020949578296748, "name": "ImprovedAdaptiveDifferentialEvolution", "description": "Improved Adaptive Differential Evolution with archive for diversity, adaptive crossover rate, and self-adaptive mutation factor.", "code": "import numpy as np\n\nclass ImprovedAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.archive = []\n        self.archive_size = archive_size\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        while i in idxs:\n          idxs = np.random.choice(self.pop_size, 3, replace=False)\n\n        # Add archive individuals to the selection pool\n        available_individuals = list(self.pop)\n        if self.archive:\n            available_individuals.extend(self.archive)\n\n        if len(available_individuals) > 3:\n            selected_indices = np.random.choice(len(available_individuals), 3, replace=False)\n            x_r1, x_r2, x_r3 = [available_individuals[idx] for idx in selected_indices]\n\n            # Self-adaptive F\n            F_adaptive = self.F * np.random.uniform(0.5, 1.5)\n            mutated = x_r1 + F_adaptive * (x_r2 - x_r3)\n        else:\n            # Fallback to original mutation if not enough individuals\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            F_adaptive = self.F * np.random.uniform(0.5, 1.5)\n            mutated = x_r1 + F_adaptive * (x_r2 - x_r3)\n\n        return np.clip(mutated, -5.0, 5.0)\n\n    def crossover(self, mutated, i):\n        crossed = np.copy(self.pop[i])\n        # Adaptive Crossover Rate\n        Cr_adaptive = self.Cr + np.random.normal(0, 0.1, size=self.dim)\n        Cr_adaptive = np.clip(Cr_adaptive, 0, 1)\n\n        for j in range(self.dim):\n            if np.random.rand() < Cr_adaptive[j]:\n                crossed[j] = mutated[j]\n        return crossed\n\n    def selection(self, func, crossed, i):\n        f_new = func(crossed)\n        self.eval_count += 1\n\n        if f_new < self.fitness[i]:\n            # Update population\n            self.pop[i] = crossed\n            self.fitness[i] = f_new\n\n            # Update archive (if applicable)\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.pop[i].copy())\n            else:\n                # Replace a random archive member\n                replace_index = np.random.randint(0, self.archive_size)\n                self.archive[replace_index] = self.pop[i].copy()\n                \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = crossed\n        else:\n            # Add the old individual to the archive if the new one is worse\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.pop[i].copy())\n            else:\n                replace_index = np.random.randint(0, self.archive_size)\n                self.archive[replace_index] = self.pop[i].copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutated = self.mutate(i)\n                crossed = self.crossover(mutated, i)\n                self.selection(func, crossed, i)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm ImprovedAdaptiveDifferentialEvolution scored 0.702 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["93a4fb57-8df4-435b-b007-3e58864d1405"], "operator": null, "metadata": {"aucs": [0.29274686299925046, 0.6273061591579566, 0.7317744905390209, 0.8791143447564108, 0.7502479571402919, 0.7797477298219422, 0.6386747845524637, 0.6910447988884125, 0.7438630040555191, 0.682297459461847, 0.8506708714040703, 0.9947569180282866, 0.6438472236161497, 0.7363436634228239, 0.9151998801696354, 0.7882241517442267, 0.618498718492466, 0.8379308422991232, 0.3194198475299388, 0.5201894485136601]}}
{"id": "834e29fd-05c1-4bde-a07a-e5fc417656cc", "fitness": -Infinity, "name": "OrthogonalPopulationSearch", "description": "Population-based search with orthogonal learning, utilizing orthogonal arrays to sample diverse points in the search space and refine the population towards promising regions.", "code": "import numpy as np\nfrom scipy.stats import qmc\n\nclass OrthogonalPopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, num_orthogonal_points=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.num_orthogonal_points = num_orthogonal_points\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Generate orthogonal array centered around current individual\n                engine = qmc.LatinHypercube(d=self.dim)\n                orthogonal_points = engine.random(self.num_orthogonal_points)\n                orthogonal_points = func.bounds.lb + (func.bounds.ub - func.bounds.lb) * orthogonal_points\n                \n                # Evaluate orthogonal points\n                fitness_orthogonal = []\n                for j in range(self.num_orthogonal_points):\n                    f = func(orthogonal_points[j])\n                    fitness_orthogonal.append(f)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                \n                if self.budget <= 0:\n                    break\n\n                fitness_orthogonal = np.array(fitness_orthogonal)\n                \n                # Select the best orthogonal point\n                best_orthogonal_index = np.argmin(fitness_orthogonal)\n                best_orthogonal_point = orthogonal_points[best_orthogonal_index]\n                best_orthogonal_fitness = fitness_orthogonal[best_orthogonal_index]\n\n                # Update if the orthogonal point is better\n                if best_orthogonal_fitness < self.fitness[i]:\n                    self.population[i] = best_orthogonal_point\n                    self.fitness[i] = best_orthogonal_fitness\n                    \n                    if best_orthogonal_fitness < self.f_opt:\n                        self.f_opt = best_orthogonal_fitness\n                        self.x_opt = best_orthogonal_point\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occurred: name 'qmc' is not defined.", "error": "", "parent_ids": ["e15771d6-385f-4fbb-9032-f65e8b14c2ba"], "operator": null, "metadata": {}}
{"id": "4357488b-0216-4233-a004-cfa3c1b7beb8", "fitness": 0.0, "name": "EnhancedAdaptivePopulationSearch", "description": "Enhanced Adaptive Population Search with velocity-based momentum, restart mechanism, and adaptive mutation factor.", "code": "import numpy as np\n\nclass EnhancedAdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1, min_lr=0.001, mutation_factor=0.5, momentum=0.1, restart_trigger=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.min_lr = min_lr\n        self.mutation_factor = mutation_factor\n        self.momentum = momentum\n        self.restart_trigger = restart_trigger\n        self.velocities = None\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()  # Ensure a copy\n\n        # Initialize velocities\n        self.velocities = np.zeros((self.pop_size, self.dim))\n\n        stagnation_counter = 0\n        prev_f_opt = self.f_opt\n\n        while self.budget > 0:\n            # Calculate fitness variance for learning rate adaptation\n            fitness_variance = np.var(self.fitness)\n\n            for i in range(self.pop_size):\n                # Combined Update Rule with Momentum\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_rand1, x_rand2 = self.population[idxs]\n\n                # Adaptive step size\n                step = self.lr * (self.x_opt - self.population[i]) + self.mutation_factor * (x_rand1 - x_rand2)\n                \n                # Incorporate momentum\n                self.velocities[i] = self.momentum * self.velocities[i] + step\n                new_x = self.population[i] + self.velocities[i]\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n                f_new = func(new_x)\n                self.budget -= 1\n\n                if f_new < self.fitness[i]:\n                    self.population[i] = new_x\n                    self.fitness[i] = f_new\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = new_x.copy() # Ensure x_opt is a copy\n\n                if self.budget <= 0:\n                    break\n\n            # Adaptive learning rate adjustment\n            if fitness_variance > 1e-6:\n                self.lr *= (1 - (0.1 / (1 + fitness_variance)))\n            else:\n                self.lr *= 0.9\n            self.lr = max(self.lr, self.min_lr)\n            \n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.3 * np.sin(2 * np.pi * (self.budget / 10000))  # Example modulation\n\n            # Stagnation Check and Restart Mechanism\n            if abs(self.f_opt - prev_f_opt) < 1e-8:\n                stagnation_counter += 1\n            else:\n                stagnation_counter = 0\n\n            if stagnation_counter > int(self.budget * self.restart_trigger): #Dynamic stagnation trigger\n                # Restart a portion of the population\n                num_to_restart = int(self.pop_size * 0.2)\n                restart_indices = np.random.choice(self.pop_size, num_to_restart, replace=False)\n                self.population[restart_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_restart, self.dim))\n                self.fitness[restart_indices] = np.array([func(x) for x in self.population[restart_indices]])\n                \n                #Update optimal values\n                best_index = np.argmin(self.fitness)\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                \n                stagnation_counter = 0\n                self.lr = 0.1  # Reset learning rate\n                self.velocities = np.zeros((self.pop_size, self.dim))  # Reset velocities\n\n\n            prev_f_opt = self.f_opt\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedAdaptivePopulationSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e15771d6-385f-4fbb-9032-f65e8b14c2ba"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "9754e1c5-25d2-4bd3-9e9d-fe1386c8db8f", "fitness": -Infinity, "name": "HybridPSO_CMAES", "description": "A hybrid algorithm combining PSO and CMA-ES, dynamically switching between them based on performance and stagnation detection.", "code": "import numpy as np\nimport cma\n\nclass HybridPSO_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_weight=0.7,\n                 c1=1.5, c2=1.5, pso_prob=0.5, stagnation_threshold=100, sigma0=0.5):\n        \"\"\"\n        Initialize the Hybrid PSO-CMA-ES optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the PSO population. Also used to inform CMA-ES population size.\n            inertia_weight (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            pso_prob (float): Initial probability of using PSO.\n            stagnation_threshold (int): Number of iterations without improvement before adapting PSO/CMA-ES probability.\n            sigma0 (float): Initial step size for CMA-ES.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.c1 = c1\n        self.c2 = c2\n        self.pso_prob = pso_prob\n        self.stagnation_threshold = stagnation_threshold\n        self.sigma0 = sigma0\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.best_positions = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.last_global_best_fitness = np.inf\n        self.cmaes_es = None # CMA-ES object\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.best_positions = self.pop.copy()\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_global_best_fitness = self.global_best_fitness\n\n    def update_pso(self, func):\n        \"\"\"\n        Update the population using Particle Swarm Optimization.\n        \"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        cognitive_component = self.c1 * r1 * (self.best_positions - self.pop)\n        social_component = self.c2 * r2 * (self.global_best_position - self.pop)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_component + social_component\n        self.pop += self.velocities\n\n        # Clip to bounds\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n\n        new_fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        for i in range(self.pop_size):\n            if new_fitness[i] < self.fitness[i]:\n                self.fitness[i] = new_fitness[i]\n                self.best_positions[i] = self.pop[i].copy()\n                if new_fitness[i] < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness[i]\n                    self.global_best_position = self.pop[i].copy()\n\n    def update_cmaes(self, func):\n        \"\"\"\n        Update the population using CMA-ES.\n        \"\"\"\n        if self.cmaes_es is None:\n            # Initialize CMA-ES\n            options = {'bounds': [func.bounds.lb, func.bounds.ub], 'popsize': self.pop_size}\n            self.cmaes_es = cma.CMAEvolutionStrategy(self.global_best_position, self.sigma0, options)\n\n        solutions = []\n        for _ in range(self.cmaes_es.population_size):\n            x = self.cmaes_es.ask()\n            solutions.append(x)\n\n        fitness_values = [func(x) for x in solutions]\n        self.eval_count += len(solutions)\n        self.cmaes_es.tell(solutions, fitness_values)\n\n        best_index = np.argmin(fitness_values)\n        best_fitness = fitness_values[best_index]\n        best_solution = solutions[best_index]\n\n        if best_fitness < self.global_best_fitness:\n            self.global_best_fitness = best_fitness\n            self.global_best_position = best_solution.copy()\n\n    def adapt_probability(self):\n        \"\"\"Adapt PSO/CMA-ES probability based on stagnation.\"\"\"\n        if self.global_best_fitness < self.last_global_best_fitness:\n            self.stagnation_counter = 0\n            self.last_global_best_fitness = self.global_best_fitness\n        else:\n            self.stagnation_counter += 1\n\n        if self.stagnation_counter > self.stagnation_threshold:\n            # Stagnation detected: adjust pso_prob\n            self.pso_prob = 0.5 - (0.5 - self.pso_prob) * 0.9  # Move pso_prob towards 0.5\n            self.stagnation_counter = 0  # Reset counter\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using the Hybrid PSO-CMA-ES optimizer.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Decide between PSO and CMA-ES based on pso_prob\n            if np.random.rand() < self.pso_prob:\n                self.update_pso(func)\n            else:\n                self.update_cmaes(func)\n\n            self.adapt_probability()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 3, "feedback": "An exception occurred: No module named 'cma'.", "error": "", "parent_ids": ["9933447d-45d5-41d8-90cf-cb04bacce5c1"], "operator": null, "metadata": {}}
{"id": "d05d8438-5839-4b65-92f1-c9dfb6ad959b", "fitness": 0.0, "name": "GradientDE", "description": "Gradient-based mutation with adaptive step size combined with differential evolution and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass GradientDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, lr=0.01, restart_prob=0.05):\n        \"\"\"\n        Initialize the Gradient-based Differential Evolution optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            lr (float): Learning rate for gradient descent.\n            restart_prob (float): Probability of restarting a particle.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lr = lr\n        self.restart_prob = restart_prob\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n\n    def gradient_mutation(self, func, x):\n        \"\"\"\n        Perform gradient-based mutation on a particle.\n\n        Args:\n            func (callable): The function to optimize.\n            x (np.ndarray): The particle to mutate.\n\n        Returns:\n            np.ndarray: The mutated particle.\n        \"\"\"\n        # Numerical gradient approximation\n        gradient = np.zeros(self.dim)\n        h = 1e-5  # Small perturbation\n        for i in range(self.dim):\n            x_plus_h = x.copy()\n            x_plus_h[i] += h\n            x_minus_h = x.copy()\n            x_minus_h[i] -= h\n            \n            #Clamp to bounds\n            x_plus_h = np.clip(x_plus_h, func.bounds.lb, func.bounds.ub)\n            x_minus_h = np.clip(x_minus_h, func.bounds.lb, func.bounds.ub)\n            \n            gradient[i] = (func(x_plus_h) - func(x_minus_h)) / (2 * h)\n            self.eval_count += 2 # each gradient evaluation requires 2 function calls\n            if self.eval_count > self.budget:\n                return None\n        \n        # Adaptive step size based on gradient norm\n        step_size = self.lr / (np.linalg.norm(gradient) + 1e-8)\n        \n        # Gradient descent step\n        x_new = x - step_size * gradient\n        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n        \n        return x_new\n\n    def differential_evolution(self, func):\n        \"\"\"\n        Perform differential evolution update.\n        \"\"\"\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            v_i = x_r1 + self.F * (x_r2 - x_r3)\n            v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            u_i = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n\n            # Selection\n            f_u_i = func(u_i)\n            self.eval_count += 1\n            \n            if f_u_i < self.fitness[i]:\n                self.fitness[i] = f_u_i\n                self.pop[i] = u_i.copy()\n                if f_u_i < self.best_fitness:\n                    self.best_fitness = f_u_i\n                    self.best_position = u_i.copy()\n\n    def restart_population(self, func):\n        \"\"\"\n        Restart a particle with a certain probability.\n        \"\"\"\n        for i in range(self.pop_size):\n            if np.random.rand() < self.restart_prob:\n                self.pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.fitness[i] = func(self.pop[i])\n                self.eval_count += 1\n\n                if self.fitness[i] < self.best_fitness:\n                    self.best_fitness = self.fitness[i]\n                    self.best_position = self.pop[i].copy()\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using the Gradient-based Differential Evolution optimizer.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Apply gradient-based mutation to each particle\n            for i in range(self.pop_size):\n                x_new = self.gradient_mutation(func, self.pop[i])\n                if x_new is None:\n                  return self.best_fitness, self.best_position\n                f_new = func(x_new)\n                self.eval_count += 1\n                if self.eval_count > self.budget:\n                  return self.best_fitness, self.best_position\n                \n                if f_new < self.fitness[i]:\n                    self.fitness[i] = f_new\n                    self.pop[i] = x_new.copy()\n\n                    if f_new < self.best_fitness:\n                        self.best_fitness = f_new\n                        self.best_position = x_new.copy()\n\n            self.differential_evolution(func)\n            self.restart_population(func)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 3, "feedback": "The algorithm GradientDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8e062f11-5acb-407f-bba5-e86abf4b738f"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "cdeefc62-75a6-4bf2-b02a-51929328bed7", "fitness": -Infinity, "name": "AdaptiveHybridOptimizerPC", "description": "Implements a hybrid algorithm that dynamically adjusts the balance between PSO and CMA-ES based on performance feedback and diversity maintenance.", "code": "import numpy as np\nimport cmalib\nfrom scipy.spatial.distance import cdist\n\nclass AdaptiveHybridOptimizerPC:\n    def __init__(self, budget=10000, dim=10, pop_size=20, pso_inertia=0.7,\n                 pso_c1=1.5, pso_c2=1.5, cma_sigma=0.5, pso_prob=0.5, \n                 diversity_threshold=0.1, diversity_weight=0.1):\n        \"\"\"\n        Initialize the Adaptive Hybrid Optimizer with Performance-based CMA-ES Adaptation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles/individuals in the population.  Must be even for CMA-ES sampling.\n            pso_inertia (float): Inertia weight for PSO.\n            pso_c1 (float): Cognitive coefficient for PSO.\n            pso_c2 (float): Social coefficient for PSO.\n            cma_sigma (float): Initial sigma value for CMA-ES.\n            pso_prob (float): Initial probability of using PSO.\n            diversity_threshold (float): Threshold for population diversity (normalized distance).\n            diversity_weight (float): Weight for diversity component in CMA-ES sigma adaptation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size % 2 == 0 else pop_size + 1 # Ensure even pop_size for CMA-ES\n        self.pso_inertia = pso_inertia\n        self.pso_c1 = pso_c1\n        self.pso_c2 = pso_c2\n        self.cma_sigma = cma_sigma\n        self.pso_prob = pso_prob\n        self.diversity_threshold = diversity_threshold\n        self.diversity_weight = diversity_weight\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.best_positions = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.cma_es = None  # CMA-ES optimizer instance\n        self.cma_uses_budget = False\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.best_positions = self.pop.copy()\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_pso(self, func):\n        \"\"\"Update the population using Particle Swarm Optimization.\"\"\"\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        cognitive_component = self.pso_c1 * r1 * (self.best_positions - self.pop)\n        social_component = self.pso_c2 * r2 * (self.global_best_position - self.pop)\n\n        self.velocities = self.pso_inertia * self.velocities + cognitive_component + social_component\n        self.pop += self.velocities\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n\n        new_fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        for i in range(self.pop_size):\n            if new_fitness[i] < self.fitness[i]:\n                self.fitness[i] = new_fitness[i]\n                self.best_positions[i] = self.pop[i].copy()\n                if new_fitness[i] < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness[i]\n                    self.global_best_position = self.pop[i].copy()\n\n    def update_cma_es(self, func):\n        \"\"\"Update the population using CMA-ES.\"\"\"\n        if self.cma_es is None:\n            self.cma_es = cmalib.CMALib(self.dim, self.cma_sigma, lb=func.bounds.lb, ub=func.bounds.ub, popsize = self.pop_size)\n            self.cma_uses_budget = False\n\n        new_pop = []\n        for _ in range(self.pop_size):\n            if self.eval_count < self.budget:\n                x = self.cma_es.sample()\n                new_pop.append(x)\n                self.eval_count += 1\n            else:\n                new_pop = None\n                break\n        \n        if new_pop is None:\n            return\n\n        new_pop = np.array(new_pop)\n        new_fitness = np.array([func(x) for x in new_pop])\n        \n        for i in range(self.pop_size):\n            if new_fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = new_fitness[i]\n                self.global_best_position = new_pop[i].copy()\n        \n        self.cma_es.tell(new_pop, new_fitness)\n        self.pop = new_pop\n        self.fitness = new_fitness\n\n    def calculate_diversity(self):\n        \"\"\"Calculate population diversity based on normalized pairwise distances.\"\"\"\n        distances = cdist(self.pop, self.pop)\n        # Normalize distances by the range of the search space\n        normalized_distances = distances / (np.abs(func.bounds.ub - func.bounds.lb).max())\n        # Mean distance excluding self-distances\n        diversity = np.sum(normalized_distances) / (self.pop_size * (self.pop_size - 1)) if self.pop_size > 1 else 0\n        return diversity\n\n    def adapt_probability(self):\n        \"\"\"Adapt PSO/CMA-ES probability based on diversity.\"\"\"\n        diversity = self.calculate_diversity()\n        if diversity < self.diversity_threshold:\n            self.pso_prob = min(1.0, self.pso_prob + 0.1)  # Increase PSO prob\n            if self.cma_es is not None:\n                self.cma_sigma *= (1 - self.diversity_weight) # Decrease CMA-ES sigma to exploit\n        else:\n            self.pso_prob = max(0.0, self.pso_prob - 0.1)  # Decrease PSO prob\n            if self.cma_es is not None:\n                self.cma_sigma *= (1 + self.diversity_weight) # Increase CMA-ES sigma to explore\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using the Adaptive Hybrid Optimizer.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            if np.random.rand() < self.pso_prob:\n                self.update_pso(func)\n            else:\n                self.update_cma_es(func)\n\n            self.adapt_probability()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 3, "feedback": "An exception occurred: No module named 'cmalib'.", "error": "", "parent_ids": ["9933447d-45d5-41d8-90cf-cb04bacce5c1"], "operator": null, "metadata": {}}
{"id": "77e78418-2418-4ffb-8fc9-7c6809e4383b", "fitness": -Infinity, "name": "CooperativeAdaptiveDifferentialEvolution", "description": "Cooperative adaptive differential evolution with a dynamic subpopulation allocation and migration strategy based on performance.", "code": "import numpy as np\n\nclass CooperativeAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, num_subpops=5, pop_size=20, F=0.5, Cr=0.9, migration_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_subpops = num_subpops\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.migration_rate = migration_rate\n        self.subpops = []\n        self.fitnesses = []\n        self.eval_count = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.subpop_sizes = [pop_size // num_subpops] * num_subpops\n        remaining = pop_size % num_subpops\n        for i in range(remaining):\n            self.subpop_sizes[i] += 1\n\n\n    def initialize_subpopulations(self, func):\n        start_index = 0\n        for i in range(self.num_subpops):\n            subpop_size = self.subpop_sizes[i]\n            subpop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(subpop_size, self.dim))\n            self.subpops.append(subpop)\n            fitness = np.array([func(x) for x in subpop])\n            self.fitnesses.append(fitness)\n            self.eval_count += subpop_size\n            \n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = subpop[np.argmin(fitness)]\n            start_index += subpop_size\n\n    def mutate(self, subpop_index, i):\n        subpop = self.subpops[subpop_index]\n        subpop_size = subpop.shape[0]\n\n        idxs = np.random.choice(subpop_size, 3, replace=False)\n        while i in idxs:\n            idxs = np.random.choice(subpop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = subpop[idxs]\n\n        mutated = x_r1 + self.F * (x_r2 - x_r3)\n        return np.clip(mutated, -5.0, 5.0)\n\n    def crossover(self, mutated, subpop_index, i):\n        subpop = self.subpops[subpop_index]\n        crossed = np.copy(subpop[i])\n        for j in range(self.dim):\n            if np.random.rand() < self.Cr:\n                crossed[j] = mutated[j]\n        return crossed\n\n    def selection(self, func, crossed, subpop_index, i):\n        subpop = self.subpops[subpop_index]\n        fitnesses = self.fitnesses[subpop_index]\n\n        f_new = func(crossed)\n        self.eval_count += 1\n\n        if f_new < fitnesses[i]:\n            subpop[i] = crossed\n            fitnesses[i] = f_new\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = crossed\n\n    def migrate(self):\n        # Identify the best and worst performing subpopulations\n        avg_fitnesses = [np.mean(fitness) for fitness in self.fitnesses]\n        best_subpop_index = np.argmin(avg_fitnesses)\n        worst_subpop_index = np.argmax(avg_fitnesses)\n\n        # Migrate a fraction of individuals from the best to the worst subpopulation\n        num_migrants = int(self.migration_rate * self.subpop_sizes[best_subpop_index])\n\n        # Select migrants from the best subpop\n        best_subpop = self.subpops[best_subpop_index]\n        best_fitness = self.fitnesses[best_subpop_index]\n        migrant_indices = np.argsort(best_fitness)[:num_migrants]  # Select best individuals\n\n        migrants = best_subpop[migrant_indices].copy()\n\n        # Select victims from the worst subpop\n        worst_subpop = self.subpops[worst_subpop_index]\n        worst_fitness = self.fitnesses[worst_subpop_index]\n        victim_indices = np.argsort(worst_fitness)[-num_migrants:]  # Select worst individuals\n\n        # Replace victims with migrants\n        worst_subpop[victim_indices] = migrants\n\n        # Re-evaluate the fitness of the migrated individuals in the worst subpopulation\n        for i, idx in enumerate(victim_indices):\n            self.fitnesses[worst_subpop_index][idx] = func(worst_subpop[idx])\n            self.eval_count += 1\n            if self.fitnesses[worst_subpop_index][idx] < self.f_opt:\n                self.f_opt = self.fitnesses[worst_subpop_index][idx]\n                self.x_opt = worst_subpop[idx]\n\n    def adjust_subpopulation_sizes(self):\n          # Calculate average fitness for each subpopulation\n          avg_fitnesses = [np.mean(fitness) for fitness in self.fitnesses]\n\n          # Normalize fitnesses to get weights. Higher fitness means a smaller weight.\n          weights = np.max(avg_fitnesses) - np.array(avg_fitnesses) + 1e-6  # Adding a small value to avoid division by zero\n          weights /= np.sum(weights)\n\n          # Calculate new subpopulation sizes\n          new_subpop_sizes = (weights * self.pop_size).astype(int)\n\n          # Ensure the sum of new sizes is equal to the total population size\n          diff = self.pop_size - np.sum(new_subpop_sizes)\n          \n          # Distribute the difference randomly\n          indices = np.random.choice(self.num_subpops, size=abs(diff), replace=True)\n          for i in indices:\n              new_subpop_sizes[i] += np.sign(diff)\n\n          # Keep sizes within reasonable bounds\n          new_subpop_sizes = np.clip(new_subpop_sizes, 5, self.pop_size // 2)\n          \n          # Update sizes and populations\n          for i in range(self.num_subpops):\n              old_size = self.subpop_sizes[i]\n              new_size = new_subpop_sizes[i]\n\n              if new_size != old_size:\n                  if new_size > old_size:\n                      # Add new individuals randomly\n                      num_new = new_size - old_size\n                      new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new, self.dim))\n                      self.subpops[i] = np.vstack((self.subpops[i], new_individuals))\n                      new_fitnesses = np.array([func(x) for x in new_individuals])\n                      self.fitnesses[i] = np.concatenate((self.fitnesses[i], new_fitnesses))\n                      self.eval_count += num_new\n                      \n                      if np.min(new_fitnesses) < self.f_opt:\n                          self.f_opt = np.min(new_fitnesses)\n                          self.x_opt = new_individuals[np.argmin(new_fitnesses)]\n                  else:\n                      # Remove worst individuals\n                      num_remove = old_size - new_size\n                      indices_to_remove = np.argsort(self.fitnesses[i])[-num_remove:]\n                      self.subpops[i] = np.delete(self.subpops[i], indices_to_remove, axis=0)\n                      self.fitnesses[i] = np.delete(self.fitnesses[i], indices_to_remove)\n                  self.subpops[i] = self.subpops[i].reshape(new_size, self.dim) # Reshape to avoid errors\n                  self.fitnesses[i] = self.fitnesses[i].reshape(new_size)\n              self.subpop_sizes[i] = new_size\n          \n          \n\n    def __call__(self, func):\n        self.initialize_subpopulations(func)\n\n        while self.eval_count < self.budget:\n            # Adjust subpopulation sizes every few iterations\n            if self.eval_count % (self.pop_size * 2) == 0:\n                self.adjust_subpopulation_sizes()\n\n            for i in range(self.num_subpops):\n                subpop_size = self.subpop_sizes[i]\n                for j in range(subpop_size):\n                    mutated = self.mutate(i, j)\n                    crossed = self.crossover(mutated, i, j)\n                    self.selection(func, crossed, i, j)\n            \n            if self.eval_count % (self.pop_size) == 0 and self.num_subpops > 1:\n                self.migrate()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occurred: shape mismatch: value array of shape (0,2) could not be broadcast to indexing result of shape (4,2).", "error": "", "parent_ids": ["c8ba83b4-ca8c-42a8-8cc4-b97d4c20f5b9"], "operator": null, "metadata": {}}
{"id": "65e4f847-6f45-4803-9dc5-1e134307d8bf", "fitness": 0.2918791610010926, "name": "EnhancedAdaptivePopulationSearch", "description": "Enhanced adaptive population search using velocity-based movement with inertia, adaptive mutation, and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass EnhancedAdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1, min_lr=0.001, mutation_factor=0.5, inertia=0.7, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.min_lr = min_lr\n        self.mutation_factor = mutation_factor\n        self.inertia = inertia\n        self.restart_prob = restart_prob\n        self.velocity = np.zeros((pop_size, dim))  # Initialize velocities\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            # Calculate fitness variance for learning rate adaptation\n            fitness_variance = np.var(self.fitness)\n\n            for i in range(self.pop_size):\n                # Combined Update Rule with Velocity (PSO-like)\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_rand1, x_rand2 = self.population[idxs]\n\n                # Velocity update with inertia\n                self.velocity[i] = self.inertia * self.velocity[i] + \\\n                                    self.lr * (self.x_opt - self.population[i]) + \\\n                                    self.mutation_factor * (x_rand1 - x_rand2)\n\n                new_x = self.population[i] + self.velocity[i]\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n                f_new = func(new_x)\n                self.budget -= 1\n\n                if f_new < self.fitness[i]:\n                    self.population[i] = new_x\n                    self.fitness[i] = f_new\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = new_x\n                else:\n                    # Adaptive mutation: if no improvement, increase mutation\n                    self.mutation_factor *= 1.05  # Increase mutation strength\n                    self.mutation_factor = min(self.mutation_factor, 1.0) # cap at 1\n\n                # Restart mechanism\n                if np.random.rand() < self.restart_prob:\n                    self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    self.fitness[i] = func(self.population[i])\n                    self.budget -= 1\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n\n                if self.budget <= 0:\n                    break\n\n            # Adaptive learning rate adjustment\n            if fitness_variance > 1e-6:\n                self.lr *= (1 - (0.1 / (1 + fitness_variance)))\n            else:\n                self.lr *= 0.9\n            self.lr = max(self.lr, self.min_lr)\n\n            self.mutation_factor *= 0.95  # Decrease mutation over time\n            self.mutation_factor = max(self.mutation_factor, 0.1)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedAdaptivePopulationSearch scored 0.292 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e15771d6-385f-4fbb-9032-f65e8b14c2ba"], "operator": null, "metadata": {"aucs": [0.12804209395008015, 0.17529440047135336, 0.27272323958981415, 0.21532850455811248, 0.2193988151740104, 0.22891541039756624, 0.23137388580746288, 0.19853384728482149, 0.2019407813480818, 0.17357664508512738, 0.2695614103060212, 0.9958962567392021, 0.2731254218999708, 0.22020182289834767, 0.6071280878211778, 0.2965801319007738, 0.22932262416103577, 0.30139695798422395, 0.15331530472932242, 0.44592757791534654]}}
{"id": "9e3be36d-94e7-4ebb-8c60-a5baa2a6f869", "fitness": 0.43146036662411386, "name": "CauchyAdaptiveDE", "description": "Integrates a Cauchy mutation operator within DE to enhance exploration and escape local optima, adaptively adjusting mutation strength based on population diversity.", "code": "import numpy as np\n\nclass CauchyAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, cauchy_scale=1.0, diversity_threshold=0.1):\n        \"\"\"\n        Initialize the Cauchy Adaptive Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of individuals in the population.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            cauchy_scale (float): Scale parameter for the Cauchy distribution.\n            diversity_threshold (float): Threshold for population diversity to trigger increased Cauchy scale.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n        self.diversity_threshold = diversity_threshold\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def calculate_diversity(self):\n        \"\"\"Calculate population diversity based on the average distance from the mean.\"\"\"\n        mean_position = np.mean(self.pop, axis=0)\n        distances = np.linalg.norm(self.pop - mean_position, axis=1)\n        return np.mean(distances)\n\n    def mutate(self, func, i):\n        \"\"\"Apply Cauchy mutation to an individual.\"\"\"\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        cauchy_mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n        v_i = x_r1 + self.F * (x_r2 - x_r3) + cauchy_mutation\n        v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n        return v_i\n\n    def crossover(self, v_i, i):\n        \"\"\"Apply crossover to create a trial vector.\"\"\"\n        j_rand = np.random.randint(self.dim)\n        u_i = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n        return u_i\n\n    def selection(self, func, u_i, i):\n        \"\"\"Apply selection between the trial vector and the current individual.\"\"\"\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n\n    def adapt_cauchy_scale(self):\n        \"\"\"Adapt the Cauchy scale based on population diversity.\"\"\"\n        diversity = self.calculate_diversity()\n        if diversity < self.diversity_threshold:\n            self.cauchy_scale *= 1.2  # Increase Cauchy scale to enhance exploration\n        else:\n            self.cauchy_scale *= 0.9  # Decrease Cauchy scale to focus on exploitation\n        self.cauchy_scale = np.clip(self.cauchy_scale, 0.1, 2.0)  # Keep scale within reasonable bounds\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Cauchy Adaptive DE.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutate(func, i)\n                u_i = self.crossover(v_i, i)\n                self.selection(func, u_i, i)\n\n            self.adapt_cauchy_scale()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 3, "feedback": "The algorithm CauchyAdaptiveDE scored 0.431 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9933447d-45d5-41d8-90cf-cb04bacce5c1"], "operator": null, "metadata": {"aucs": [0.1944918643564164, 0.3416408766794393, 0.4113125576178116, 0.5399018772450328, 0.3284671791264058, 0.44579793249325617, 0.310001447598631, 0.36238095769229917, 0.33114496010359684, 0.29477036667783496, 0.4763600873235766, 0.9979217969403873, 0.3028801320600828, 0.3530974688774713, 0.831919955573857, 0.4228704025147988, 0.3484969990659047, 0.5346176137312291, 0.29556123245501, 0.5055716243492344]}}
{"id": "014b0809-cc4b-4c2c-89a0-8421e20da6ed", "fitness": 0.6939920646629231, "name": "HybridSADE", "description": "Simplified hybrid PSO-DE with adaptive temperature and velocity clamping for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridSADE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_weight=0.7,\n                 c1=1.5, c2=1.5, F=0.8, CR=0.9, initial_temp=1.0, cooling_rate=0.95):\n        \"\"\"\n        Initialize the Hybrid SADE Optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            inertia_weight (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            initial_temp (float): Initial temperature for SA.\n            cooling_rate (float): Cooling rate for SA.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp = initial_temp\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update(self, func):\n        \"\"\"\n        Combined PSO and DE update with SA acceptance.\n        \"\"\"\n        for i in range(self.pop_size):\n            # PSO Velocity Update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = (self.inertia_weight * self.velocities[i] +\n                        self.c1 * r1 * (self.pop[i] - self.pop[i]) +  # Self-attraction removed, direct comparison instead\n                        self.c2 * r2 * (self.global_best_position - self.pop[i]))\n\n            # Velocity Clamping\n            v_max = 0.1 * (func.bounds.ub - func.bounds.lb)  # Clamp based on problem bounds\n            velocity = np.clip(velocity, -v_max, v_max)\n            trial_position = self.pop[i] + velocity\n\n            # DE Mutation & Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            mutant = x_r1 + self.F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            trial_vector = np.array([mutant[j] if np.random.rand() < self.CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # SA-based Acceptance\n            delta_e = f_trial - self.fitness[i]\n            if delta_e < 0 or np.random.rand() < np.exp(-delta_e / self.temp):\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n            self.velocities[i] = velocity # update the velocity regardless of acceptance\n\n        #Cooling Schedule\n        self.temp *= self.cooling_rate\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm HybridSADE scored 0.694 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8e062f11-5acb-407f-bba5-e86abf4b738f"], "operator": null, "metadata": {"aucs": [0.40040859544397167, 0.6819343788980163, 0.6682374908294526, 0.8446280639519284, 0.698732326825751, 0.7138826189283787, 0.6227384581298342, 0.6292310837340185, 0.7066316170707851, 0.6910924717495281, 0.8434918603857299, 0.9940568621624485, 0.6831694423363148, 0.6872550501353942, 0.8040164597981684, 0.6910479830764102, 0.6177117241088741, 0.7502347307655488, 0.600548766391923, 0.5507913085359872]}}
{"id": "bee6c714-c4f0-491b-bc7c-d3360a79cf5c", "fitness": 0.30598506666160036, "name": "NeighborhoodAdaptiveDE", "description": "Adaptive Differential Evolution with Neighborhood-Based Mutation and Elitist Jumps.", "code": "import numpy as np\n\nclass NeighborhoodAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, neighborhood_size=5, elite_fraction=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.neighborhood_size = neighborhood_size\n        self.elite_count = int(elite_fraction * pop_size)\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, i):\n        # Select neighborhood\n        indices = np.arange(self.pop_size)\n        neighborhood_indices = indices[np.argsort(np.linalg.norm(self.pop - self.pop[i], axis=1))][:self.neighborhood_size]\n\n        # Ensure the current individual is not in the neighborhood\n        neighborhood_indices = neighborhood_indices[neighborhood_indices != i]\n\n        if len(neighborhood_indices) < 3: # Fallback to random selection if neighborhood is too small\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            while i in idxs:\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n        else:\n            idxs = np.random.choice(neighborhood_indices, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n        \n        # Adaptive F\n        F_adaptive = self.F * np.random.uniform(0.5, 1.5)\n        mutated = x_r1 + F_adaptive * (x_r2 - x_r3)\n        \n        # Elitist Jump: Move towards the best solution with a small probability\n        if np.random.rand() < 0.05: \n            mutated = mutated + 0.1 * (self.x_opt - mutated)\n\n        return np.clip(mutated, -5.0, 5.0)\n\n    def crossover(self, mutated, i):\n        crossed = np.copy(self.pop[i])\n        for j in range(self.dim):\n            if np.random.rand() < self.Cr:\n                crossed[j] = mutated[j]\n        return crossed\n\n    def selection(self, func, crossed, i):\n        f_new = func(crossed)\n        self.eval_count += 1\n\n        if f_new < self.fitness[i]:\n            self.pop[i] = crossed\n            self.fitness[i] = f_new\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = crossed\n        else:\n            # Only replace if the new solution is better than the worst elite member\n            if i < self.elite_count:  # Indices of the elite members (assuming they are stored first)\n                worst_elite_index = np.argmax(self.fitness[:self.elite_count])\n                if f_new < self.fitness[worst_elite_index]:\n                    self.pop[worst_elite_index] = crossed\n                    self.fitness[worst_elite_index] = f_new\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = crossed\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Sort population based on fitness (for elitism)\n            elite_indices = np.argsort(self.fitness)[:self.elite_count]  # Select the elite indices\n            temp_pop = self.pop.copy()\n            temp_fitness = self.fitness.copy()\n\n            self.pop[:self.elite_count] = temp_pop[elite_indices]\n            self.fitness[:self.elite_count] = temp_fitness[elite_indices]\n\n            remaining_indices = np.array([i for i in range(self.pop_size) if i not in elite_indices])\n            self.pop[self.elite_count:] = temp_pop[remaining_indices]\n            self.fitness[self.elite_count:] = temp_fitness[remaining_indices]\n            \n            for i in range(self.pop_size):\n                mutated = self.mutate(i)\n                crossed = self.crossover(mutated, i)\n                self.selection(func, crossed, i)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm NeighborhoodAdaptiveDE scored 0.306 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c8ba83b4-ca8c-42a8-8cc4-b97d4c20f5b9"], "operator": null, "metadata": {"aucs": [0.1416269336605308, 0.20270344732956902, 0.3030085489500419, 0.2971973431435153, 0.17535070521423457, 0.21904062776547895, 0.3156941140035937, 0.22695532011518782, 0.24403780408407505, 0.16525454852176213, 0.26448725345937896, 0.9800966546437938, 0.29118000109211695, 0.24316927526257448, 0.48363761515682, 0.29230124599312546, 0.2422534375436587, 0.35731742142137646, 0.1998904310881452, 0.4744986047830285]}}
{"id": "4e62f61a-d9bf-4aad-874b-cf38b9205fab", "fitness": -Infinity, "name": "AdaptiveCMAES_NM", "description": "Combines a simplified CMA-ES with a local search based on Nelder-Mead, adaptively switching between global exploration and local refinement.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveCMAES_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_sigma=0.5, local_search_interval=50):\n        \"\"\"\n        Initialize the Adaptive CMA-ES with Nelder-Mead Local Search Optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size for CMA-ES (default: 4 + int(3 * np.log(dim))).\n            initial_sigma (float): Initial step size for CMA-ES.\n            local_search_interval (int): Frequency of local search application.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 4 + int(3 * np.log(dim)) if pop_size is None else pop_size\n        self.initial_sigma = initial_sigma\n        self.sigma = initial_sigma\n        self.mean = None\n        self.C = None  # Covariance matrix\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.local_search_interval = local_search_interval\n        self.iteration = 0\n\n    def initialize(self, func):\n        \"\"\"\n        Initialize the CMA-ES parameters.\n        \"\"\"\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)  # Initialize covariance matrix to identity\n        self.best_position = self.mean.copy()\n        self.best_fitness = func(self.mean)\n        self.eval_count += 1\n\n    def sample_population(self, func):\n        \"\"\"\n        Sample a population from a multivariate Gaussian distribution.\n        \"\"\"\n        z = np.random.randn(self.pop_size, self.dim)\n        samples = self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n        samples = np.clip(samples, func.bounds.lb, func.bounds.ub)\n        return samples\n\n    def update_parameters(self, samples, fitness_values):\n        \"\"\"\n        Update the CMA-ES parameters based on the fitness values of the samples.\n        \"\"\"\n        # Sort the samples by fitness\n        indices = np.argsort(fitness_values)\n        sorted_samples = samples[indices]\n\n        # Update the mean\n        weights = np.log(self.pop_size + 1) - np.log(np.arange(1, self.pop_size + 1))\n        weights /= np.sum(weights)\n        self.mean = np.sum(weights[:, np.newaxis] * sorted_samples, axis=0)\n\n        # Update the covariance matrix (simplified)\n        diff = sorted_samples - self.mean\n        self.C = np.cov(diff.T, aweights=weights)\n        self.C = (self.C + self.C.T) * 0.5 # ensure symmetry\n\n        # Adapt step size (simplified)\n        self.sigma *= np.exp(0.5 * (np.mean(fitness_values) - self.best_fitness) / self.best_fitness) #Adapt sigma using fitness progression\n\n\n    def local_search(self, func):\n        \"\"\"\n        Apply Nelder-Mead local search around the current best solution.\n        \"\"\"\n        res = minimize(func, self.best_position, method='Nelder-Mead',\n                       bounds=func.bounds, options={'maxfev': self.local_search_interval})\n        if res.fun < self.best_fitness:\n            self.best_fitness = res.fun\n            self.best_position = res.x\n        self.eval_count += res.nfev\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using the Adaptive CMA-ES with Nelder-Mead Local Search Optimizer.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value and the corresponding position.\n        \"\"\"\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            # Sample a population\n            samples = self.sample_population(func)\n            fitness_values = np.array([func(x) for x in samples])\n            self.eval_count += self.pop_size\n\n            # Update best solution\n            best_index = np.argmin(fitness_values)\n            if fitness_values[best_index] < self.best_fitness:\n                self.best_fitness = fitness_values[best_index]\n                self.best_position = samples[best_index].copy()\n\n            # Update parameters\n            self.update_parameters(samples, fitness_values)\n\n            # Apply local search periodically\n            if self.iteration % self.local_search_interval == 0:\n                self.local_search(func)\n\n            self.iteration += 1\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 3, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["8e062f11-5acb-407f-bba5-e86abf4b738f"], "operator": null, "metadata": {}}
{"id": "0e99c2d6-80f3-422a-8299-6d55df57194d", "fitness": 0.33576761884297823, "name": "AdaptiveCMAES_DE", "description": "A population-based algorithm that combines elements of Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with Differential Evolution (DE) using an adaptive learning rate to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveCMAES_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_sigma=0.5, learning_rate=0.1, de_cr=0.7, de_f=0.8):\n        \"\"\"\n        Initialize the Adaptive CMA-ES with DE.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of individuals in the population.\n            initial_sigma (float): Initial standard deviation for CMA-ES.\n            learning_rate (float): Learning rate for adapting CMA-ES parameters.\n            de_cr (float): Crossover rate for DE.\n            de_f (float): Scaling factor for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_sigma = initial_sigma\n        self.sigma = initial_sigma\n        self.learning_rate = learning_rate\n        self.mean = None\n        self.C = None  # Covariance matrix\n        self.eval_count = 0\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_x = None\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.tau = 1 / np.sqrt(2 * self.dim)\n        self.tau_prime = 1 / np.sqrt(2 * np.sqrt(self.dim))\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.c_sig = 0.08  # Learning rate for sigma\n        self.c_cov = 2 / (self.pop_size + np.sqrt(self.pop_size))**2 + 0.3\n        self.damps = 1 + self.c_sig + 2  # Damping factor\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population and CMA-ES parameters.\n        \"\"\"\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.pop = np.random.normal(self.mean, self.sigma, size=(self.pop_size, self.dim))\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_fitness = np.min(self.fitness)\n        self.best_x = self.pop[np.argmin(self.fitness)].copy()\n\n    def sample_population(self, func):\n        \"\"\"\n        Sample a new population using CMA-ES.\n        \"\"\"\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        self.pop = self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n        \n        # Apply DE crossover\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            \n            v_i = x_r1 + self.de_f * (x_r2 - x_r3)\n            v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n            \n            j_rand = np.random.randint(self.dim)\n            u_i = np.array([v_i[j] if np.random.rand() < self.de_cr or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n            self.pop[i] = u_i\n\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n\n    def update_parameters(self):\n        \"\"\"\n        Update CMA-ES parameters.\n        \"\"\"\n        # Sort the population\n        idx = np.argsort(self.fitness)\n        elite_indices = idx[:self.pop_size // 2]\n        x_k = self.pop[elite_indices]\n        \n        # Mean update\n        old_mean = self.mean.copy()\n        self.mean = np.mean(x_k, axis=0)\n\n        #Update evolution path\n        z = (self.mean - old_mean) / self.sigma\n        self.ps = (1 - self.c_sig) * self.ps + np.sqrt(self.c_sig * (2 - self.c_sig)) * z\n        \n        #Update covariance matrix\n        self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * z\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * np.outer(self.pc, self.pc)\n\n        # Update sigma\n        norm_ps = np.linalg.norm(self.ps)\n        self.sigma *= np.exp((self.c_sig / self.damps) * (norm_ps / (0.1 + self.dim)**0.5 - 1))\n        self.sigma = max(self.sigma, 1e-6)\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using Adaptive CMA-ES with DE.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.sample_population(func)\n            self.update_parameters()\n\n            # Update best solution\n            current_best_fitness = np.min(self.fitness)\n            current_best_x = self.pop[np.argmin(self.fitness)].copy()\n\n            if current_best_fitness < self.best_fitness:\n                self.best_fitness = current_best_fitness\n                self.best_x = current_best_x\n\n        return self.best_fitness, self.best_x", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveCMAES_DE scored 0.336 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8e062f11-5acb-407f-bba5-e86abf4b738f"], "operator": null, "metadata": {"aucs": [0.13326259616496716, 0.16152303976446092, 0.2956578726953867, 0.3451166764468372, 0.2558714398329155, 0.470734254865533, 0.24246159470378292, 0.2547533031130865, 0.16906579438898517, 0.14644606037899632, 0.5180492845500839, 0.9850205750169123, 0.20791796550725616, 0.3139342506254049, 0.6675540639984284, 0.35181454359706454, 0.2901921959529201, 0.19071036002292496, 0.2295875212883859, 0.4856789839452309]}}
{"id": "4e18a9e5-fe17-4102-af52-416d95b078b8", "fitness": 0.0, "name": "SelfAdaptiveDE", "description": "A differential evolution strategy with self-adaptive parameters and a restart mechanism based on stagnation detection.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_min=0.1, F_max=0.9, CR_min=0.1, CR_max=0.9, stagnation_threshold=50):\n        \"\"\"\n        Initialize the Self-Adaptive Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of individuals in the population.\n            F_min (float): Minimum scaling factor.\n            F_max (float): Maximum scaling factor.\n            CR_min (float): Minimum crossover rate.\n            CR_max (float): Maximum crossover rate.\n            stagnation_threshold (int): Number of iterations without improvement before restart.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_min = F_min\n        self.F_max = F_max\n        self.CR_min = CR_min\n        self.CR_max = CR_max\n        self.stagnation_threshold = stagnation_threshold\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.F = None\n        self.CR = None\n        self.stagnation_counter = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population with random positions and self-adaptive parameters.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n        # Initialize scaling factors F and crossover rates CR for each individual\n        self.F = np.random.uniform(self.F_min, self.F_max, size=self.pop_size)\n        self.CR = np.random.uniform(self.CR_min, self.CR_max, size=self.pop_size)\n\n    def mutate(self, i, func):\n        \"\"\"Apply mutation to an individual.\"\"\"\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        v_i = x_r1 + self.F[i] * (x_r2 - x_r3)\n        v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n        return v_i\n\n    def crossover(self, v_i, i):\n        \"\"\"Apply crossover to create a trial vector.\"\"\"\n        j_rand = np.random.randint(self.dim)\n        u_i = np.array([v_i[j] if np.random.rand() < self.CR[i] or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n        return u_i\n\n    def selection(self, func, u_i, i):\n        \"\"\"Apply selection between the trial vector and the current individual.\"\"\"\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n\n            # Update scaling factor and crossover rate based on success\n            self.F[i] = np.random.uniform(self.F_min, self.F_max) if np.random.rand() < 0.1 else self.F[i]\n            self.CR[i] = np.random.uniform(self.CR_min, self.CR_max) if np.random.rand() < 0.1 else self.CR[i]\n\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n                self.stagnation_counter = 0 # Reset stagnation counter\n        else:\n             self.stagnation_counter += 1\n\n\n    def check_stagnation(self, func):\n        \"\"\"Check for stagnation and restart the population if necessary.\"\"\"\n        if self.stagnation_counter > self.stagnation_threshold:\n            # Restart population\n            self.initialize_population(func)\n            self.stagnation_counter = 0\n            \n    def __call__(self, func):\n        \"\"\"Optimize the given function using Self-Adaptive DE.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutate(i, func)\n                u_i = self.crossover(v_i, i)\n                self.selection(func, u_i, i)\n            self.check_stagnation(func)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 4, "feedback": "The algorithm SelfAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9e3be36d-94e7-4ebb-8c60-a5baa2a6f869"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "631d05c0-1dff-439a-916e-f6592faa8e42", "fitness": 0.0, "name": "AdaptiveDE_Restart", "description": "Adaptive Differential Evolution with a self-adaptive mutation factor, enhanced exploration near the best solution, and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDE_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, Cr=0.9, elite_fraction=0.1, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.Cr = Cr\n        self.elite_count = int(elite_fraction * pop_size)\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.restart_trigger = restart_trigger  # Probability of restarting if no improvement\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        while i in idxs:\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n\n        # Self-adaptive mutation factor (F)\n        F = np.random.normal(0.5, 0.3)\n        F = np.clip(F, 0.1, 1.0)\n\n        mutated = x_r1 + F * (x_r2 - x_r3)\n\n        # Enhanced Exploration near the best solution\n        if np.random.rand() < 0.1:\n            mutated = mutated + np.random.uniform(-0.1, 0.1, size=self.dim) * (self.x_opt - mutated)\n\n        return np.clip(mutated, -5.0, 5.0)\n\n    def crossover(self, mutated, i):\n        crossed = np.copy(self.pop[i])\n        for j in range(self.dim):\n            if np.random.rand() < self.Cr:\n                crossed[j] = mutated[j]\n        return crossed\n\n    def selection(self, func, crossed, i):\n        f_new = func(crossed)\n        self.eval_count += 1\n\n        if f_new < self.fitness[i]:\n            self.pop[i] = crossed\n            self.fitness[i] = f_new\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = crossed\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        last_improvement = 0\n\n        while self.eval_count < self.budget:\n            # Elitism: Sort and store the best solutions at the beginning of the population\n            elite_indices = np.argsort(self.fitness)[:self.elite_count]\n            temp_pop = self.pop.copy()\n            temp_fitness = self.fitness.copy()\n\n            self.pop[:self.elite_count] = temp_pop[elite_indices]\n            self.fitness[:self.elite_count] = temp_fitness[elite_indices]\n\n            remaining_indices = np.array([i for i in range(self.pop_size) if i not in elite_indices])\n            self.pop[self.elite_count:] = temp_pop[remaining_indices]\n            self.fitness[self.elite_count:] = temp_fitness[remaining_indices]\n            \n            for i in range(self.pop_size):\n                mutated = self.mutate(i)\n                crossed = self.crossover(mutated, i)\n                self.selection(func, crossed, i)\n\n            # Restart mechanism: if no improvement, re-initialize a portion of the population\n            if self.fitness.min() >= self.f_opt:\n                last_improvement += 1\n            else:\n                self.f_opt = self.fitness.min()\n                self.x_opt = self.pop[np.argmin(self.fitness)]\n                last_improvement = 0\n\n            if last_improvement > (self.budget / self.pop_size) * self.restart_trigger:\n                # Re-initialize a portion of the population around the current best\n                num_reinitialized = int(self.pop_size * 0.3)\n                indices_to_reinitialize = np.random.choice(self.pop_size, num_reinitialized, replace=False)\n                for i in indices_to_reinitialize:\n                    self.pop[i] = self.x_opt + np.random.normal(0, 0.5, size=self.dim)  # Small perturbation\n                    self.pop[i] = np.clip(self.pop[i], -5.0, 5.0)\n                    self.fitness[i] = func(self.pop[i])\n                    self.eval_count += 1\n                \n                # Update best solution if needed\n                if self.fitness.min() < self.f_opt:\n                    self.f_opt = self.fitness.min()\n                    self.x_opt = self.pop[np.argmin(self.fitness)]\n                last_improvement = 0\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE_Restart scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["bee6c714-c4f0-491b-bc7c-d3360a79cf5c"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "e71059ec-7938-4608-bc0d-b07b915bddf0", "fitness": 0.0, "name": "AdaptiveDELevy", "description": "Adaptive Differential Evolution with Lvy flight mutation and a self-adjusting population size based on fitness improvement rate to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDELevy:\n    def __init__(self, budget=10000, dim=10, pop_size_initial=50, levy_exponent=1.5, cr_initial=0.5, f_initial=0.7, pop_size_adapt_freq=500):\n        \"\"\"\n        Initialize the Adaptive DE with Lvy flight mutation.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size_initial (int): Initial population size.\n            levy_exponent (float): Exponent for Lvy flight.\n            cr_initial (float): Initial crossover rate.\n            f_initial (float): Initial scaling factor.\n            pop_size_adapt_freq (int): Frequency of adapting population size.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_initial\n        self.levy_exponent = levy_exponent\n        self.cr = cr_initial\n        self.f = f_initial\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_x = None\n        self.eval_count = 0\n        self.pop_size_adapt_freq = pop_size_adapt_freq\n        self.fitness_history = []\n\n    def levy_flight(self, shape, exponent=1.5):\n        \"\"\"\n        Generate Lvy flight steps.\n        \"\"\"\n        num = np.random.normal(0, 1, shape)\n        den = np.abs(np.random.normal(0, 1, shape))**(1/exponent)\n        sigma = (np.math.gamma(1 + exponent) * np.sin(np.pi * exponent / 2) / (np.math.gamma((1 + exponent) / 2) * exponent * 2**((exponent - 1) / 2)))**(1/exponent)\n        step = sigma * num / den\n        return step\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_fitness = np.min(self.fitness)\n        self.best_x = self.pop[np.argmin(self.fitness)].copy()\n        self.fitness_history.append(self.best_fitness)\n\n    def evolve(self, func):\n        \"\"\"\n        Evolve the population using DE with Lvy flight mutation.\n        \"\"\"\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Mutation with Lvy flight\n            levy_step = self.levy_flight(self.dim, self.levy_exponent)\n            v_i = x_r1 + self.f * (x_r2 - x_r3) + 0.01 * levy_step * (self.best_x - self.pop[i]) # Added best_x influence\n\n            v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            u_i = np.array([v_i[j] if np.random.rand() < self.cr or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n\n            f_u_i = func(u_i)\n            self.eval_count += 1\n\n            if f_u_i < self.fitness[i]:\n                self.pop[i] = u_i\n                self.fitness[i] = f_u_i\n\n                if f_u_i < self.best_fitness:\n                    self.best_fitness = f_u_i\n                    self.best_x = u_i.copy()\n        self.fitness_history.append(self.best_fitness)\n    def adapt_population_size(self):\n        \"\"\"\n        Adapt the population size based on fitness improvement.\n        \"\"\"\n        if len(self.fitness_history) < 2:\n            return\n\n        improvement = self.fitness_history[-2] - self.fitness_history[-1]\n        if improvement > 0.01: #Significant improvement\n            self.pop_size = min(self.pop_size + 5, 100) #Increase, but with a cap\n        elif improvement < 0.001: #Stagnation\n            self.pop_size = max(self.pop_size - 5, 10) #Decrease, but with a floor\n\n        if self.pop_size != self.pop.shape[0]:\n            # Resize population\n            new_pop = np.random.uniform(self.pop[0] - 0.5, self.pop[0] + 0.5, size=(self.pop_size, self.dim))  # Initialize new individuals near current best\n            new_pop = np.clip(new_pop, -5.0, 5.0) #Clip to bounds\n            self.pop = new_pop\n\n            #Evaluate new population\n            self.fitness = np.array([np.inf]*self.pop_size)\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using Adaptive DE with Lvy flight mutation.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            if self.eval_count % self.pop_size_adapt_freq == 0:\n                self.adapt_population_size()\n        return self.best_fitness, self.best_x", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDELevy scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0e99c2d6-80f3-422a-8299-6d55df57194d"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "4bfb58cf-0959-4bfd-9d2a-af8b617f08e1", "fitness": 0.3436234696798726, "name": "SimplifiedCauchyAdaptiveDE", "description": "Simplified Cauchy Adaptive DE with direct Cauchy mutation on the best individual and reduced parameter set.", "code": "import numpy as np\n\nclass SimplifiedCauchyAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, cauchy_scale=1.0):\n        \"\"\"\n        Initialize the Simplified Cauchy Adaptive Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of individuals in the population.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            cauchy_scale (float): Scale parameter for the Cauchy distribution.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutate(self, func, i):\n        \"\"\"Apply Cauchy mutation to the best individual.\"\"\"\n        cauchy_mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n        v_i = self.best_position + cauchy_mutation\n        v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n        return v_i\n\n    def crossover(self, v_i, i):\n        \"\"\"Apply crossover to create a trial vector.\"\"\"\n        j_rand = np.random.randint(self.dim)\n        u_i = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n        return u_i\n\n    def selection(self, func, u_i, i):\n        \"\"\"Apply selection between the trial vector and the current individual.\"\"\"\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Cauchy Adaptive DE.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutate(func, i)\n                u_i = self.crossover(v_i, i)\n                self.selection(func, u_i, i)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 4, "feedback": "The algorithm SimplifiedCauchyAdaptiveDE scored 0.344 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9e3be36d-94e7-4ebb-8c60-a5baa2a6f869"], "operator": null, "metadata": {"aucs": [0.1536332309434132, 0.254904285670459, 0.33725081867004325, 0.3193024695863468, 0.2493313141826491, 0.3066635073427426, 0.2676369815068427, 0.2743068147710652, 0.25892582287427335, 0.2108575792803019, 0.32203010507135854, 0.99792659968522, 0.2765748394469352, 0.27821540607718376, 0.6919908040216389, 0.3383208717346188, 0.2870890226020302, 0.38563508456046336, 0.17303291647629127, 0.48884091909357463]}}
{"id": "28f30d30-b101-4b8a-8c8c-f1f0227b204c", "fitness": 0.27426642718910454, "name": "HybridSADE", "description": "Simplified hybrid PSO-DE with SA and velocity clamping, focusing on essential components and adaptive parameter control for robustness.", "code": "import numpy as np\n\nclass HybridSADE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_temp=1.0, cooling_rate=0.95):\n        \"\"\"\n        Initialize the Hybrid SADE Optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            initial_temp (float): Initial temperature for SA.\n            cooling_rate (float): Cooling rate for SA.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp = initial_temp\n        self.pop = None\n        self.fitness = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.CR = 0.7  # Fixed Crossover Rate\n        self.F = 0.6   # Fixed Scaling Factor\n        self.inertia_weight = 0.5 #Fixed inertia weight\n        self.c1 = 1.0 #Fixed cognitive coefficient\n        self.c2 = 1.0 #Fixed social coefficient\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update(self, func):\n        \"\"\"\n        Combined PSO and DE update with SA acceptance.\n        \"\"\"\n        v_max = 0.1 * (func.bounds.ub - func.bounds.lb)  # Velocity Clamping limit\n\n        for i in range(self.pop_size):\n            # DE Mutation & Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            mutant = x_r1 + self.F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # PSO velocity update based on current position and best known positions\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = (self.inertia_weight * (mutant - self.pop[i]) + #simplified velocity component\n                        self.c1 * r1 * (self.global_best_position - self.pop[i]))\n            velocity = np.clip(velocity, -v_max, v_max)\n            trial_vector = self.pop[i] + velocity  #apply velocity to obtain trial vector\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # SA-based Acceptance\n            delta_e = f_trial - self.fitness[i]\n            if delta_e < 0 or np.random.rand() < np.exp(-delta_e / self.temp):\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n\n        #Cooling Schedule\n        self.temp *= self.cooling_rate\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm HybridSADE scored 0.274 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["014b0809-cc4b-4c2c-89a0-8421e20da6ed"], "operator": null, "metadata": {"aucs": [0.11288411505418827, 0.20069214646742095, 0.323576950636708, 0.22284529435643252, 0.22046389464045246, 0.19481196572911375, 0.19564991109329744, 0.2333623296508237, 0.1907434606565397, 0.27966881803806454, 0.1784854022409147, 0.9991560131960675, 0.27222213065889755, 0.23328788872099815, 0.5359957552358666, 0.3028796187539027, 0.2219931952580313, 0.19076336544156536, 0.19663099872576784, 0.17921528922703767]}}
{"id": "de023ed2-93cd-42bc-8792-226624549b0d", "fitness": 0.3076928289269224, "name": "AdaptiveCMAES_DE", "description": "Adaptively adjusts CMA-ES parameters and DE scaling factor based on population diversity and dynamically switches between exploration and exploitation phases.", "code": "import numpy as np\n\nclass AdaptiveCMAES_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_sigma=0.5, learning_rate=0.1, de_cr=0.7, de_f=0.8):\n        \"\"\"\n        Initialize the Adaptive CMA-ES with DE.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of individuals in the population.\n            initial_sigma (float): Initial standard deviation for CMA-ES.\n            learning_rate (float): Learning rate for adapting CMA-ES parameters.\n            de_cr (float): Crossover rate for DE.\n            de_f (float): Scaling factor for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_sigma = initial_sigma\n        self.sigma = initial_sigma\n        self.learning_rate = learning_rate\n        self.mean = None\n        self.C = None  # Covariance matrix\n        self.eval_count = 0\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_x = None\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.tau = 1 / np.sqrt(2 * self.dim)\n        self.tau_prime = 1 / np.sqrt(2 * np.sqrt(self.dim))\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.c_sig = 0.08  # Learning rate for sigma\n        self.c_cov = 2 / (self.pop_size + np.sqrt(self.pop_size))**2 + 0.3\n        self.damps = 1 + self.c_sig + 2  # Damping factor\n        self.exploration_phase = True\n        self.exploration_prob = 0.5  # Probability of exploration phase\n        self.diversity_threshold = 0.1\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population and CMA-ES parameters.\n        \"\"\"\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.pop = np.random.normal(self.mean, self.sigma, size=(self.pop_size, self.dim))\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_fitness = np.min(self.fitness)\n        self.best_x = self.pop[np.argmin(self.fitness)].copy()\n\n    def sample_population(self, func):\n        \"\"\"\n        Sample a new population using CMA-ES and DE.\n        \"\"\"\n        #Adaptive DE scaling factor\n        if self.eval_count > self.budget // 4 : # Reduce DE scaling factor after a while\n            self.de_f = 0.4\n        else:\n            self.de_f = 0.8\n            \n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        self.pop = self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n        \n        # Apply DE crossover\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            \n            v_i = x_r1 + self.de_f * (x_r2 - x_r3)\n            v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n            \n            j_rand = np.random.randint(self.dim)\n            u_i = np.array([v_i[j] if np.random.rand() < self.de_cr or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n            self.pop[i] = u_i\n\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n    def update_parameters(self):\n        \"\"\"\n        Update CMA-ES parameters.\n        \"\"\"\n        # Sort the population\n        idx = np.argsort(self.fitness)\n        elite_indices = idx[:self.pop_size // 2]\n        x_k = self.pop[elite_indices]\n        \n        # Mean update\n        old_mean = self.mean.copy()\n        self.mean = np.mean(x_k, axis=0)\n\n        #Update evolution path\n        z = (self.mean - old_mean) / self.sigma\n        self.ps = (1 - self.c_sig) * self.ps + np.sqrt(self.c_sig * (2 - self.c_sig)) * z\n        \n        #Update covariance matrix\n        self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * z\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * np.outer(self.pc, self.pc)\n\n        # Update sigma\n        norm_ps = np.linalg.norm(self.ps)\n        self.sigma *= np.exp((self.c_sig / self.damps) * (norm_ps / (0.1 + self.dim)**0.5 - 1))\n        self.sigma = max(self.sigma, 1e-6)\n\n        #Adapt learning rate\n        if self.eval_count % 1000 == 0:\n            self.learning_rate = np.random.uniform(0.05, 0.2)\n            self.c_sig = self.learning_rate\n            self.damps = 1 + self.c_sig + 2\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using Adaptive CMA-ES with DE.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.sample_population(func)\n            self.update_parameters()\n\n            # Update best solution\n            current_best_fitness = np.min(self.fitness)\n            current_best_x = self.pop[np.argmin(self.fitness)].copy()\n\n            if current_best_fitness < self.best_fitness:\n                self.best_fitness = current_best_fitness\n                self.best_x = current_best_x\n\n        return self.best_fitness, self.best_x", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveCMAES_DE scored 0.308 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0e99c2d6-80f3-422a-8299-6d55df57194d"], "operator": null, "metadata": {"aucs": [0.09094294331774144, 0.3496398681902255, 0.2650830978602311, 0.17385036887935623, 0.27445291169997066, 0.43110349654651814, 0.27553127219413664, 0.343408635631515, 0.17253990324141066, 0.1642515485285727, 0.1798095688150808, 0.15230775253008433, 0.24461244870322763, 0.23547170398455053, 0.6103918783414994, 0.33408197734775347, 0.218823461904596, 0.9195303099364087, 0.23938248249002492, 0.47864094839554316]}}
{"id": "8603061e-c916-4ee7-ab5a-3866bcc38a37", "fitness": 0.5311864704954744, "name": "AdaptiveDE", "description": "Simplified adaptive differential evolution with dynamic F and Cr, combined with elitism and a jitter-based mutation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, elite_fraction=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.elite_count = int(elite_fraction * pop_size)\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5  # Initial F value\n        self.Cr = 0.9 # Initial CR value\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        while i in idxs:\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        \n        # Dynamic F: adapt based on success\n        self.F = np.clip(self.F + 0.1 * np.random.normal(0, 1), 0.1, 0.9)\n\n        mutated = x_r1 + self.F * (x_r2 - x_r3)\n        \n        # Add jitter to prevent stagnation\n        mutated = mutated + np.random.normal(0, 0.01, size=self.dim)\n\n        return np.clip(mutated, -5.0, 5.0)\n\n    def crossover(self, mutated, i):\n        crossed = np.copy(self.pop[i])\n        \n        #Dynamic CR\n        if self.fitness[i] > self.f_opt:\n            self.Cr = np.clip(self.Cr + 0.1 * np.random.normal(0, 1), 0.1, 0.9)\n        else:\n            self.Cr = np.clip(self.Cr - 0.05 * np.random.normal(0,1), 0.1, 0.9)\n        \n        for j in range(self.dim):\n            if np.random.rand() < self.Cr:\n                crossed[j] = mutated[j]\n        return crossed\n\n    def selection(self, func, crossed, i):\n        f_new = func(crossed)\n        self.eval_count += 1\n\n        if f_new < self.fitness[i]:\n            self.pop[i] = crossed\n            self.fitness[i] = f_new\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = crossed\n        elif i < self.elite_count:  # Elitism: Replace worst elite if better\n            worst_elite_index = np.argmax(self.fitness[:self.elite_count])\n            if f_new < self.fitness[worst_elite_index]:\n                self.pop[worst_elite_index] = crossed\n                self.fitness[worst_elite_index] = f_new\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = crossed\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Sort population based on fitness for elitism\n            elite_indices = np.argsort(self.fitness)[:self.elite_count]\n            temp_pop = self.pop.copy()\n            temp_fitness = self.fitness.copy()\n\n            self.pop[:self.elite_count] = temp_pop[elite_indices]\n            self.fitness[:self.elite_count] = temp_fitness[elite_indices]\n\n            remaining_indices = np.array([i for i in range(self.pop_size) if i not in elite_indices])\n            self.pop[self.elite_count:] = temp_pop[remaining_indices]\n            self.fitness[self.elite_count:] = temp_fitness[remaining_indices]\n\n            for i in range(self.pop_size):\n                mutated = self.mutate(i)\n                crossed = self.crossover(mutated, i)\n                self.selection(func, crossed, i)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.531 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["bee6c714-c4f0-491b-bc7c-d3360a79cf5c"], "operator": null, "metadata": {"aucs": [0.22497382522465137, 0.4360978270496919, 0.487187026201495, 0.7976418553229722, 0.49953627233495046, 0.5852594422788713, 0.36195285693310864, 0.43276423214289883, 0.4867716221724647, 0.40385127851481695, 0.819810083069803, 0.9995555894624015, 0.31005814568424117, 0.483662532888569, 0.8517270121942311, 0.5882005763405278, 0.421540446238582, 0.6975397434043704, 0.22031051990037298, 0.5152885225504686]}}
{"id": "331aa4c6-31e6-4241-acca-f45e4525fcec", "fitness": 0.48695041908919035, "name": "AdaptiveMutationPoolDE", "description": "A DE variant that uses a pool of mutation strategies and adaptively selects the best one based on their recent success.", "code": "import numpy as np\n\nclass AdaptiveMutationPoolDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, mutation_pool=None, adaptation_rate=0.1):\n        \"\"\"\n        Initialize the Adaptive Mutation Pool Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of individuals in the population.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            mutation_pool (list): A list of mutation strategies (functions). If None, a default set is used.\n            adaptation_rate (float): Learning rate for adapting the selection probabilities of mutation strategies.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.adaptation_rate = adaptation_rate\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n\n        if mutation_pool is None:\n            self.mutation_pool = [\n                self.mutation_rand1,\n                self.mutation_current_to_best1,\n                self.mutation_best1,\n                self.mutation_rand2\n            ]\n        else:\n            self.mutation_pool = mutation_pool\n\n        self.num_mutation_strategies = len(self.mutation_pool)\n        self.strategy_successes = np.zeros(self.num_mutation_strategies) # track success\n        self.strategy_counts = np.ones(self.num_mutation_strategies) # track usage\n        self.strategy_probabilities = np.ones(self.num_mutation_strategies) / self.num_mutation_strategies # equal initial probabilities\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutation_rand1(self, i):\n        \"\"\"DE/rand/1 mutation strategy.\"\"\"\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        return x_r1 + self.F * (x_r2 - x_r3)\n\n    def mutation_current_to_best1(self, i):\n         \"\"\"DE/current-to-best/1 mutation.\"\"\"\n         idxs = np.random.choice(self.pop_size, 2, replace=False)\n         x_r1, x_r2 = self.pop[idxs]\n         return self.pop[i] + self.F * (self.best_position - self.pop[i]) + self.F * (x_r1 - x_r2)\n\n    def mutation_best1(self, i):\n        \"\"\"DE/best/1 mutation.\"\"\"\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        x_r1, x_r2 = self.pop[idxs]\n        return self.best_position + self.F * (x_r1 - x_r2)\n\n    def mutation_rand2(self, i):\n        \"\"\"DE/rand/2 mutation strategy.\"\"\"\n        idxs = np.random.choice(self.pop_size, 5, replace=False)\n        x_r1, x_r2, x_r3, x_r4, x_r5 = self.pop[idxs]\n        return x_r1 + self.F * (x_r2 - x_r3) + self.F * (x_r4 - x_r5)\n\n    def crossover(self, v_i, i):\n        \"\"\"Apply crossover to create a trial vector.\"\"\"\n        j_rand = np.random.randint(self.dim)\n        u_i = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n        return u_i\n\n    def selection(self, func, u_i, i, strategy_index):\n        \"\"\"Apply selection between the trial vector and the current individual.\"\"\"\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            self.strategy_successes[strategy_index] += 1 # strategy was successful\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n        \n\n    def update_strategy_probabilities(self):\n        \"\"\"Update the selection probabilities of the mutation strategies.\"\"\"\n        for i in range(self.num_mutation_strategies):\n            self.strategy_counts[i] += 1\n            self.strategy_probabilities[i] += self.adaptation_rate * (self.strategy_successes[i] / self.strategy_counts[i] - self.strategy_probabilities[i])\n            self.strategy_successes[i] = 0\n            self.strategy_counts[i] = 1\n\n        self.strategy_probabilities = np.maximum(0, self.strategy_probabilities)\n        self.strategy_probabilities /= np.sum(self.strategy_probabilities)\n    \n    def __call__(self, func):\n        \"\"\"Optimize the given function using Adaptive Mutation Pool DE.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Select a mutation strategy based on probabilities\n                strategy_index = np.random.choice(self.num_mutation_strategies, p=self.strategy_probabilities)\n                mutation_strategy = self.mutation_pool[strategy_index]\n\n                v_i = mutation_strategy(i)\n                v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n                u_i = self.crossover(v_i, i)\n                self.selection(func, u_i, i, strategy_index)\n\n            self.update_strategy_probabilities()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveMutationPoolDE scored 0.487 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9e3be36d-94e7-4ebb-8c60-a5baa2a6f869"], "operator": null, "metadata": {"aucs": [0.17287783206830976, 0.30074281796614966, 0.5552339569012672, 0.9736287391904923, 0.34747651068349594, 0.5539057069965498, 0.298872340330662, 0.29874351432673807, 0.2950611901260781, 0.17295152967394023, 0.5009565173550781, 0.9940816880260739, 0.30924772025669456, 0.8628686199279092, 0.8625924487005894, 0.37270926507425683, 0.34320269065542297, 0.8775584149913256, 0.18360644321747854, 0.4626904353152951]}}
{"id": "262dba6b-8d03-46bd-886a-64c3bd7fb77a", "fitness": 0.6893295553813161, "name": "HybridSADE", "description": "Simplified hybrid PSO-DE with enhanced velocity clamping and adaptive parameter control for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridSADE:\n    def __init__(self, budget=10000, dim=10, pop_size=20,\n                 c1=1.5, c2=1.5, F=0.5, CR=0.9):\n        \"\"\"\n        Initialize the Hybrid SADE Optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.inertia_weight = 0.7 # Fixed inertia weight\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim)) # scaled velocities\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update(self, func):\n        \"\"\"\n        Combined PSO and DE update.\n        \"\"\"\n        for i in range(self.pop_size):\n            # PSO Velocity Update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = (self.inertia_weight * self.velocities[i] +\n                        self.c1 * r1 * (self.global_best_position - self.pop[i]) +\n                        self.c2 * r2 * (self.pop[np.random.randint(self.pop_size)] - self.pop[i]))\n\n            # Velocity Clamping\n            v_max = 0.2 * (func.bounds.ub - func.bounds.lb)  # Clamp based on problem bounds\n            velocity = np.clip(velocity, -v_max, v_max)\n            trial_position = self.pop[i] + velocity\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n\n            # DE Mutation & Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            mutant = x_r1 + self.F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            trial_vector = np.array([mutant[j] if np.random.rand() < self.CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # Greedy Selection\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n\n            self.velocities[i] = velocity # update the velocity regardless of acceptance\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm HybridSADE scored 0.689 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["014b0809-cc4b-4c2c-89a0-8421e20da6ed"], "operator": null, "metadata": {"aucs": [0.38931429124354655, 0.6281796536718773, 0.8045303539529629, 0.1819946379548908, 0.7825148971329031, 0.8797882543119513, 0.7977162660832026, 0.8284123952353117, 0.863175415594569, 0.23741633977130372, 0.938082414036246, 0.9914305726307215, 0.3938215355502125, 0.8460622927972832, 0.9253562267814538, 0.8921915289606933, 0.7044708967819946, 0.9395167509786209, 0.24569799651997914, 0.5169183876365974]}}
{"id": "30614c79-b873-46ea-92ee-1c41a2234717", "fitness": 0.42784638644661993, "name": "EnhancedCauchyAdaptiveDE", "description": "Enhanced Cauchy Adaptive DE with self-adaptive mutation scaling, archive-based mutation, and diversity-based parameter adaptation for improved exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedCauchyAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, cauchy_scale=1.0, diversity_threshold=0.1, archive_size=5):\n        \"\"\"\n        Initialize the Enhanced Cauchy Adaptive Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of individuals in the population.\n            F (float): Initial scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            cauchy_scale (float): Scale parameter for the Cauchy distribution.\n            diversity_threshold (float): Threshold for population diversity to trigger increased Cauchy scale.\n            archive_size (int): Size of the archive to store past solutions.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n        self.diversity_threshold = diversity_threshold\n        self.archive_size = archive_size\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.archive = []  # Archive to store potentially useful solutions\n        self.archive_fitness = []\n        self.F_history = [F]  # Store F values to adapt it\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def calculate_diversity(self):\n        \"\"\"Calculate population diversity based on the average distance from the mean.\"\"\"\n        mean_position = np.mean(self.pop, axis=0)\n        distances = np.linalg.norm(self.pop - mean_position, axis=1)\n        return np.mean(distances)\n\n    def mutate(self, func, i):\n        \"\"\"Apply Cauchy mutation to an individual with archive interaction and self-adaptive F.\"\"\"\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        x_r1, x_r2 = self.pop[idxs]\n\n        # Self-adaptive F: Randomly sample from a Cauchy distribution\n        F_i = self.F + 0.1 * np.random.standard_cauchy()\n        F_i = np.clip(F_i, 0.1, 1.0) # Keep F within reasonable bounds\n        self.F_history.append(F_i)\n        self.F = np.mean(self.F_history[-5:])  # Average of last 5 F values\n        \n        if len(self.archive) > 0 and np.random.rand() < 0.2:  # Use archive with a small probability\n            arc_idx = np.random.randint(len(self.archive))\n            x_r3 = self.archive[arc_idx]\n        else:\n            idxs = np.random.choice(self.pop_size, 1, replace=False)\n            x_r3 = self.pop[idxs[0]]\n\n        cauchy_mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n        v_i = self.pop[i] + F_i * (x_r1 - x_r2) + cauchy_mutation\n        v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n        return v_i\n\n    def crossover(self, v_i, i):\n        \"\"\"Apply crossover to create a trial vector.\"\"\"\n        j_rand = np.random.randint(self.dim)\n        u_i = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n        return u_i\n\n    def selection(self, func, u_i, i):\n        \"\"\"Apply selection between the trial vector and the current individual and update the archive.\"\"\"\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            # Update archive\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.pop[i].copy())\n                self.archive_fitness.append(self.fitness[i])\n            else:\n                max_fitness_index = np.argmax(self.archive_fitness)\n                if self.fitness[i] < self.archive_fitness[max_fitness_index]:\n                    self.archive[max_fitness_index] = self.pop[i].copy()\n                    self.archive_fitness[max_fitness_index] = self.fitness[i]\n\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n\n    def adapt_cauchy_scale(self):\n        \"\"\"Adapt the Cauchy scale based on population diversity.\"\"\"\n        diversity = self.calculate_diversity()\n        if diversity < self.diversity_threshold:\n            self.cauchy_scale *= 1.1  # Increase Cauchy scale to enhance exploration\n        else:\n            self.cauchy_scale *= 0.9  # Decrease Cauchy scale to focus on exploitation\n        self.cauchy_scale = np.clip(self.cauchy_scale, 0.1, 2.0)  # Keep scale within reasonable bounds\n        self.CR = np.clip(self.CR + np.random.normal(0, 0.05), 0.1, 1.0)  # Adapt CR\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Cauchy Adaptive DE.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutate(func, i)\n                u_i = self.crossover(v_i, i)\n                self.selection(func, u_i, i)\n\n            self.adapt_cauchy_scale()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedCauchyAdaptiveDE scored 0.428 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9e3be36d-94e7-4ebb-8c60-a5baa2a6f869"], "operator": null, "metadata": {"aucs": [0.16285721903860217, 0.3038382664617534, 0.4305458415886173, 0.6095289873451362, 0.3171923304355482, 0.4848218542282059, 0.30726583417677245, 0.3470838096050626, 0.33172914437908063, 0.27328384457988253, 0.47665240448394786, 0.9923632754577939, 0.28258731332909914, 0.3503020446333942, 0.753012991433099, 0.48287576798082466, 0.3637450328470685, 0.57301925368986, 0.21232496356343977, 0.50189754967521]}}
{"id": "17ac39ac-c618-496b-a759-0fdab4ca6782", "fitness": 0.0, "name": "AdaptiveNeighborhoodDE", "description": "Neighborhood-based DE with adaptive mutation strength, dynamic population size, and a migration strategy to share information between subpopulations.", "code": "import numpy as np\n\nclass AdaptiveNeighborhoodDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=20, max_pop_size=100, F=0.5, Cr=0.9, neighborhood_size=5, elite_fraction=0.1, migration_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.pop_size = initial_pop_size\n        self.F = F\n        self.Cr = Cr\n        self.neighborhood_size = neighborhood_size\n        self.elite_count = int(elite_fraction * self.pop_size)\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.migration_prob = migration_prob\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, i):\n        # Select neighborhood\n        indices = np.arange(self.pop_size)\n        neighborhood_indices = indices[np.argsort(np.linalg.norm(self.pop - self.pop[i], axis=1))][:self.neighborhood_size]\n\n        # Ensure the current individual is not in the neighborhood\n        neighborhood_indices = neighborhood_indices[neighborhood_indices != i]\n\n        if len(neighborhood_indices) < 3: # Fallback to random selection if neighborhood is too small\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            while i in idxs:\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n        else:\n            idxs = np.random.choice(neighborhood_indices, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n        \n        # Adaptive F: dynamically adjust mutation strength based on population diversity\n        diversity = np.std(self.fitness)\n        F_adaptive = self.F * (1 + np.random.normal(0, diversity))\n        F_adaptive = np.clip(F_adaptive, 0.1, 1.0) # Ensure F stays within reasonable bounds\n        mutated = x_r1 + F_adaptive * (x_r2 - x_r3)\n        \n        return np.clip(mutated, -5.0, 5.0)\n\n    def crossover(self, mutated, i):\n        crossed = np.copy(self.pop[i])\n        for j in range(self.dim):\n            if np.random.rand() < self.Cr:\n                crossed[j] = mutated[j]\n        return crossed\n\n    def selection(self, func, crossed, i):\n        f_new = func(crossed)\n        self.eval_count += 1\n\n        if f_new < self.fitness[i]:\n            self.pop[i] = crossed\n            self.fitness[i] = f_new\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = crossed\n        else:\n            # Only replace if the new solution is better than the worst elite member\n            if i < self.elite_count:  # Indices of the elite members (assuming they are stored first)\n                worst_elite_index = np.argmax(self.fitness[:self.elite_count])\n                if f_new < self.fitness[worst_elite_index]:\n                    self.pop[worst_elite_index] = crossed\n                    self.fitness[worst_elite_index] = f_new\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = crossed\n\n    def dynamic_population_size(self):\n        # Adjust population size based on stagnation or progress\n        if np.std(self.fitness) < 1e-5 and self.pop_size < self.max_pop_size: # Stagnation\n            self.pop_size = min(self.pop_size + 5, self.max_pop_size)\n            print(f\"Increasing population size to {self.pop_size}\")\n            # Re-initialize new individuals\n            new_pop = np.random.uniform(-5.0, 5.0, size=(5, self.dim))\n            new_fitness = [func(x) for x in new_pop]\n            self.pop = np.concatenate((self.pop, new_pop), axis=0)\n            self.fitness = np.concatenate((self.fitness, new_fitness))\n            self.eval_count += 5\n\n        elif np.std(self.fitness) > 0.1 and self.pop_size > self.min_pop_size: # Good progress\n            self.pop_size = max(self.pop_size - 5, self.min_pop_size)\n            print(f\"Decreasing population size to {self.pop_size}\")\n            # Remove worst individuals\n            worst_indices = np.argsort(self.fitness)[-5:]\n            self.pop = np.delete(self.pop, worst_indices, axis=0)\n            self.fitness = np.delete(self.fitness, worst_indices)\n            \n        self.elite_count = int(0.1 * self.pop_size)\n\n\n    def migrate(self):\n        # Migrate individuals between subpopulations (here, only one subpopulation exists, so migrate within)\n        if np.random.rand() < self.migration_prob:\n            # Select a random individual to migrate\n            i = np.random.randint(self.pop_size)\n            # Select another random individual to replace\n            j = np.random.randint(self.pop_size)\n            self.pop[j] = self.pop[i].copy()\n            self.fitness[j] = self.fitness[i] #func(self.pop[j]) #Recalculate here for correctness\n            #self.eval_count+=1\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.dynamic_population_size()\n            # Sort population based on fitness (for elitism)\n            elite_indices = np.argsort(self.fitness)[:self.elite_count]  # Select the elite indices\n            temp_pop = self.pop.copy()\n            temp_fitness = self.fitness.copy()\n\n            self.pop[:self.elite_count] = temp_pop[elite_indices]\n            self.fitness[:self.elite_count] = temp_fitness[elite_indices]\n\n            remaining_indices = np.array([i for i in range(self.pop_size) if i not in elite_indices])\n            self.pop[self.elite_count:] = temp_pop[remaining_indices]\n            self.fitness[self.elite_count:] = temp_fitness[remaining_indices]\n            \n            for i in range(self.pop_size):\n                mutated = self.mutate(i)\n                crossed = self.crossover(mutated, i)\n                self.selection(func, crossed, i)\n\n            self.migrate()\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveNeighborhoodDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["bee6c714-c4f0-491b-bc7c-d3360a79cf5c"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "40912f63-5f89-49b5-9400-3fd2d29c98cc", "fitness": 0.42123682767814474, "name": "AdaptiveCMAES_DE", "description": "Adaptive CMA-ES with DE and improved parameter control, incorporating a restart mechanism and adaptive DE parameters based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveCMAES_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_sigma=0.5, learning_rate=0.1, de_cr=0.7, de_f=0.8, restart_trigger=1e-9):\n        \"\"\"\n        Initialize the Adaptive CMA-ES with DE.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of individuals in the population.\n            initial_sigma (float): Initial standard deviation for CMA-ES.\n            learning_rate (float): Learning rate for adapting CMA-ES parameters.\n            de_cr (float): Crossover rate for DE.\n            de_f (float): Scaling factor for DE.\n            restart_trigger (float): Threshold for restarting CMA-ES.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_sigma = initial_sigma\n        self.sigma = initial_sigma\n        self.learning_rate = learning_rate\n        self.mean = None\n        self.C = None  # Covariance matrix\n        self.eval_count = 0\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_x = None\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.tau = 1 / np.sqrt(2 * self.dim)\n        self.tau_prime = 1 / np.sqrt(2 * np.sqrt(self.dim))\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.c_sig = 0.08  # Learning rate for sigma\n        self.c_cov = 2 / (self.pop_size + np.sqrt(self.pop_size))**2 + 0.3\n        self.damps = 1 + self.c_sig + 2  # Damping factor\n        self.restart_trigger = restart_trigger\n        self.restart_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population and CMA-ES parameters.\n        \"\"\"\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)  # Initialize covariance matrix\n        self.pop = np.random.normal(self.mean, self.sigma, size=(self.pop_size, self.dim))\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_fitness = np.min(self.fitness)\n        self.best_x = self.pop[np.argmin(self.fitness)].copy()\n\n    def sample_population(self, func):\n        \"\"\"\n        Sample a new population using CMA-ES and DE.\n        \"\"\"\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        self.pop = self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n        \n        # Adaptive DE parameters based on population diversity\n        diversity = np.std(self.pop)\n        adaptive_cr = 0.1 + 0.8 * np.exp(-diversity * 10) # cr increases with lower diversity\n        adaptive_f = 0.1 + 0.9 * np.exp(-diversity * 5)   # f decreases with lower diversity\n\n        # Apply DE crossover\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            \n            v_i = x_r1 + adaptive_f * (x_r2 - x_r3)\n            v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n            \n            j_rand = np.random.randint(self.dim)\n            u_i = np.array([v_i[j] if np.random.rand() < adaptive_cr or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n            self.pop[i] = u_i\n\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n\n    def update_parameters(self):\n        \"\"\"\n        Update CMA-ES parameters.\n        \"\"\"\n        # Sort the population\n        idx = np.argsort(self.fitness)\n        elite_indices = idx[:self.pop_size // 2]\n        x_k = self.pop[elite_indices]\n        \n        # Mean update\n        old_mean = self.mean.copy()\n        self.mean = np.mean(x_k, axis=0)\n\n        #Update evolution path\n        z = (self.mean - old_mean) / self.sigma\n        self.ps = (1 - self.c_sig) * self.ps + np.sqrt(self.c_sig * (2 - self.c_sig)) * z\n        \n        #Update covariance matrix\n        self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov)) * z\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * np.outer(self.pc, self.pc)\n\n        # Update sigma\n        norm_ps = np.linalg.norm(self.ps)\n        self.sigma *= np.exp((self.c_sig / self.damps) * (norm_ps / (0.1 + self.dim)**0.5 - 1))\n        self.sigma = max(self.sigma, 1e-6)\n        \n        # Restart mechanism\n        if np.linalg.det(self.C) < self.restart_trigger or np.isnan(np.linalg.det(self.C)):\n            self.restart()\n\n    def restart(self):\n        \"\"\"\n        Restart CMA-ES parameters.\n        \"\"\"\n        self.sigma = self.initial_sigma\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.restart_count += 1\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using Adaptive CMA-ES with DE.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best fitness value and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.sample_population(func)\n            self.update_parameters()\n\n            # Update best solution\n            current_best_fitness = np.min(self.fitness)\n            current_best_x = self.pop[np.argmin(self.fitness)].copy()\n\n            if current_best_fitness < self.best_fitness:\n                self.best_fitness = current_best_fitness\n                self.best_x = current_best_x\n\n        return self.best_fitness, self.best_x", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveCMAES_DE scored 0.421 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0e99c2d6-80f3-422a-8299-6d55df57194d"], "operator": null, "metadata": {"aucs": [0.1954629249277957, 0.22338813648670985, 0.40837104301208715, 0.8524689918540364, 0.3966592440631982, 0.44585462732211056, 0.29512936294916103, 0.38741745920507664, 0.3874122685744511, 0.15995096856498825, 0.7084661694817432, 0.7728337682661495, 0.2362225760670028, 0.37862498004016276, 0.7281121512572122, 0.33181305148614615, 0.3630813172164504, 0.5361343453515932, 0.22568726819663243, 0.39164589924018733]}}
{"id": "6110bdac-d051-48c8-9353-94c4905e298d", "fitness": 0.0, "name": "SimplifiedCauchyAdaptiveDE", "description": "Simplified Cauchy Adaptive DE with adaptive F and CR, archive for exploitation, and Cauchy mutation for exploration.", "code": "import numpy as np\n\nclass SimplifiedCauchyAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.archive = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutate(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        F = np.random.uniform(0.2, 0.8)\n        if len(self.archive) > 0 and np.random.rand() < 0.1:\n            arc_idx = np.random.randint(len(self.archive))\n            x_r3 = self.archive[arc_idx]\n        return self.pop[i] + F * (x_r1 - x_r2) + 0.01 * np.random.standard_cauchy(size=self.dim)\n\n    def crossover(self, v_i, i):\n        CR = np.random.uniform(0.3, 0.9)\n        j_rand = np.random.randint(self.dim)\n        u_i = np.array([v_i[j] if np.random.rand() < CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.pop[i].copy())\n            else:\n                if self.fitness[i] > np.mean([func(x) for x in self.archive]):\n                    self.archive[np.random.randint(len(self.archive))] = self.pop[i].copy()\n\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutate(i)\n                v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n                u_i = self.crossover(v_i, i)\n                self.selection(func, u_i, i)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 5, "feedback": "The algorithm SimplifiedCauchyAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["30614c79-b873-46ea-92ee-1c41a2234717"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "c5e83e63-27ac-45d9-b4c3-3a7c3323beec", "fitness": -Infinity, "name": "AdaptiveMutationPoolDE", "description": "Improved adaptive mutation pool DE with softmax-weighted strategy selection, archive-based exploration, and dynamic parameter adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveMutationPoolDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, mutation_pool=None, adaptation_rate=0.1, archive_size=5):\n        \"\"\"\n        Initialize the Adaptive Mutation Pool Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of individuals in the population.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            mutation_pool (list): A list of mutation strategies (functions). If None, a default set is used.\n            adaptation_rate (float): Learning rate for adapting the selection probabilities of mutation strategies.\n            archive_size (int): Size of the archive for storing diverse solutions.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.adaptation_rate = adaptation_rate\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.archive_size = archive_size\n        self.archive = [] # Store diverse solutions\n\n        if mutation_pool is None:\n            self.mutation_pool = [\n                self.mutation_rand1,\n                self.mutation_current_to_best1,\n                self.mutation_best1,\n                self.mutation_rand2\n            ]\n        else:\n            self.mutation_pool = mutation_pool\n\n        self.num_mutation_strategies = len(self.mutation_pool)\n        self.strategy_successes = np.zeros(self.num_mutation_strategies) # track success\n        self.strategy_counts = np.ones(self.num_mutation_strategies) # track usage\n        self.strategy_probabilities = np.ones(self.num_mutation_strategies) # equal initial probabilities\n\n        self.F_memory = np.ones(self.pop_size) * self.F\n        self.CR_memory = np.ones(self.pop_size) * self.CR\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutation_rand1(self, i):\n        \"\"\"DE/rand/1 mutation strategy.\"\"\"\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        return x_r1 + self.F_memory[i] * (x_r2 - x_r3)\n\n    def mutation_current_to_best1(self, i):\n         \"\"\"DE/current-to-best/1 mutation.\"\"\"\n         idxs = np.random.choice(self.pop_size, 2, replace=False)\n         x_r1, x_r2 = self.pop[idxs]\n         return self.pop[i] + self.F_memory[i] * (self.best_position - self.pop[i]) + self.F_memory[i] * (x_r1 - x_r2)\n\n    def mutation_best1(self, i):\n        \"\"\"DE/best/1 mutation.\"\"\"\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        x_r1, x_r2 = self.pop[idxs]\n        return self.best_position + self.F_memory[i] * (x_r1 - x_r2)\n\n    def mutation_rand2(self, i):\n        \"\"\"DE/rand/2 mutation strategy.\"\"\"\n        idxs = np.random.choice(self.pop_size, 5, replace=False)\n        x_r1, x_r2, x_r3, x_r4, x_r5 = self.pop[idxs]\n        return x_r1 + self.F_memory[i] * (x_r2 - x_r3) + self.F_memory[i] * (x_r4 - x_r5)\n\n    def crossover(self, v_i, i):\n        \"\"\"Apply crossover to create a trial vector.\"\"\"\n        j_rand = np.random.randint(self.dim)\n        u_i = np.array([v_i[j] if np.random.rand() < self.CR_memory[i] or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n        return u_i\n\n    def selection(self, func, u_i, i, strategy_index):\n        \"\"\"Apply selection between the trial vector and the current individual.\"\"\"\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            self.strategy_successes[strategy_index] += 1 # strategy was successful\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n        else:\n            # Archive non-improving solutions for diversity\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.pop[i].copy())\n            else:\n                idx_to_replace = np.random.randint(self.archive_size)\n                self.archive[idx_to_replace] = self.pop[i].copy()\n\n\n    def update_strategy_probabilities(self):\n        \"\"\"Update the selection probabilities of the mutation strategies.\"\"\"\n        # Softmax selection\n        preferences = self.strategy_successes / self.strategy_counts\n        self.strategy_probabilities = np.exp(preferences) / np.sum(np.exp(preferences))\n\n        for i in range(self.num_mutation_strategies):\n            self.strategy_counts[i] += 1\n            self.strategy_successes[i] = 0\n\n    def adapt_parameters(self):\n        \"\"\"Adapt the F and CR parameters for each individual.\"\"\"\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.1:  # 10% chance to adapt\n                self.F_memory[i] = np.random.normal(self.F, 0.1)\n                self.CR_memory[i] = np.random.normal(self.CR, 0.1)\n                self.F_memory[i] = np.clip(self.F_memory[i], 0.1, 1.0)\n                self.CR_memory[i] = np.clip(self.CR_memory[i], 0.1, 1.0)\n\n    def exploit_archive(self, i):\n        \"\"\"Exploit the archive by using a solution from the archive in mutation.\"\"\"\n        if len(self.archive) > 0 and np.random.rand() < 0.1:  # 10% chance to use archive\n            archived_solution = self.archive[np.random.randint(len(self.archive))]\n            return archived_solution\n        else:\n            return None\n    \n    def __call__(self, func):\n        \"\"\"Optimize the given function using Adaptive Mutation Pool DE.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Select a mutation strategy based on probabilities\n                strategy_index = np.random.choice(self.num_mutation_strategies, p=self.strategy_probabilities)\n                mutation_strategy = self.mutation_pool[strategy_index]\n\n                archived_solution = self.exploit_archive(i)\n                if archived_solution is not None:\n                    v_i = archived_solution\n                else:\n                     v_i = mutation_strategy(i)\n\n                v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n                u_i = self.crossover(v_i, i)\n                self.selection(func, u_i, i, strategy_index)\n\n            self.update_strategy_probabilities()\n            self.adapt_parameters()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 5, "feedback": "An exception occurred: probabilities do not sum to 1.", "error": "", "parent_ids": ["331aa4c6-31e6-4241-acca-f45e4525fcec"], "operator": null, "metadata": {}}
{"id": "267e1d39-a261-4400-9c7a-b4d29f444d91", "fitness": 0.11882432757446944, "name": "OrthogonalCMAES", "description": "Population-based algorithm with orthogonal learning and covariance matrix adaptation for efficient exploration and exploitation.", "code": "import numpy as np\n\nclass OrthogonalCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_sigma = initial_sigma\n        self.mean = None\n        self.sigma = None\n        self.C = None  # Covariance matrix\n        self.pc = None # Evolution path for C\n        self.ps = None # Evolution path for sigma\n        self.chiN = None\n        self.eval_count = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.mu = None\n        self.weights = None\n        self.mueff = None\n\n\n    def initialize(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.sigma = self.initial_sigma\n        self.C = np.eye(self.dim)  # Initialize covariance matrix to identity\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2.3)**2 + self.mueff))\n        \n\n    def sample_population(self):\n        z = np.random.randn(self.dim, self.pop_size)\n        cholC = np.linalg.cholesky(self.C)\n        x = self.mean[:, np.newaxis] + self.sigma * cholC @ z\n        x = np.clip(x, -5.0, 5.0)\n        return x.T\n\n    def update_distribution(self, func, x):\n        fitness = np.array([func(xi) for xi in x])\n        self.eval_count += self.pop_size\n\n        idx = np.argsort(fitness)\n        fitness = fitness[idx]\n        x = x[idx]\n\n        if fitness[0] < self.f_opt:\n            self.f_opt = fitness[0]\n            self.x_opt = x[0]\n\n        z = (x[:self.mu] - self.mean) / self.sigma\n        \n        self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.inv(np.linalg.cholesky(self.C)) @ (self.mean - self.mean)) / self.sigma * np.sqrt(self.mueff)\n        hsig = np.linalg.norm(self.ps)/np.sqrt(1-(1-self.c_sigma)**(2*self.budget/self.pop_size))/self.chiN < 1.4 + 2/(self.dim+1)\n\n        self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2-self.c_c)) * (self.mean - self.mean) / self.sigma * np.sqrt(self.mueff)\n        \n        self.C = (1-self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:,None] @ self.pc[None,:]) + self.c_mu * (z.T @ np.diag(self.weights) @ z)\n\n        self.sigma *= np.exp((self.c_sigma/self.d_sigma) * (np.linalg.norm(self.ps)/self.chiN - 1))\n\n        self.mean = np.sum(x[:self.mu].T * self.weights, axis=1)\n\n        # Keep C positive definite\n        try:\n            np.linalg.cholesky(self.C)\n        except np.linalg.LinAlgError:\n            self.C = np.eye(self.dim)\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            x = self.sample_population()\n            self.update_distribution(func, x)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm OrthogonalCMAES scored 0.119 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8603061e-c916-4ee7-ab5a-3866bcc38a37"], "operator": null, "metadata": {"aucs": [0.07253493556610557, 0.17097700180360154, 0.1802826582319389, 0.07869293097887398, 0.2064234336444527, 0.17544753037551442, 0.18898914325487548, 0.08832780464532464, 0.14989896213359077, 0.06140897082431385, 0.12895385633654044, 0.1417356783528545, 9.999999999998899e-05, 0.05527537387134618, 0.0909371828642741, 0.12115660285196606, 0.08752480074322722, 0.1307540738866153, 0.11664382510640003, 0.13042178601757337]}}
{"id": "ef61999f-6c84-46d2-9812-7e1ff3a3afe9", "fitness": 0.29678488317061036, "name": "AdaptiveDE", "description": "Simplified adaptive differential evolution with dynamic F and Cr, using a single random vector for mutation and a more aggressive CR update.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5  # Initial F value\n        self.Cr = 0.9 # Initial CR value\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, i):\n        idx = np.random.randint(0, self.pop_size)\n        while idx == i:\n            idx = np.random.randint(0, self.pop_size)\n        \n        # Dynamic F: adapt based on success, simplified\n        self.F = np.clip(self.F + 0.1 * np.random.normal(0, 1), 0.1, 0.9)\n\n        mutated = self.pop[i] + self.F * (self.pop[idx] - self.pop[i])\n\n        return np.clip(mutated, -5.0, 5.0)\n\n    def crossover(self, mutated, i):\n        crossed = np.copy(self.pop[i])\n        \n        #Dynamic CR, more aggressive update\n        if self.fitness[i] > self.f_opt:\n            self.Cr = np.clip(self.Cr + 0.2 * np.random.normal(0, 1), 0.1, 0.9)\n        else:\n            self.Cr = np.clip(self.Cr - 0.1 * np.random.normal(0,1), 0.1, 0.9)\n        \n        for j in range(self.dim):\n            if np.random.rand() < self.Cr:\n                crossed[j] = mutated[j]\n        return crossed\n\n    def selection(self, func, crossed, i):\n        f_new = func(crossed)\n        self.eval_count += 1\n\n        if f_new < self.fitness[i]:\n            self.pop[i] = crossed\n            self.fitness[i] = f_new\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = crossed\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutated = self.mutate(i)\n                crossed = self.crossover(mutated, i)\n                self.selection(func, crossed, i)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.297 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8603061e-c916-4ee7-ab5a-3866bcc38a37"], "operator": null, "metadata": {"aucs": [0.12629068807608657, 0.2626125401852638, 0.3082472315136092, 0.19376292251746585, 0.17940705872727247, 0.22493874412617842, 0.2871736518281769, 0.26307579720613716, 0.2749742197155616, 0.20069512500654751, 0.23214595025438434, 0.9693671204441585, 0.31892473161428037, 0.20249384733810427, 0.2851361884198029, 0.30402299760682583, 0.27075436929947516, 0.2616208016850996, 0.29338207443809994, 0.4766716034096784]}}
{"id": "8152f1a6-84bb-41f5-8dc9-c78aa420f843", "fitness": 0.6463201858669905, "name": "SimplifiedAdaptiveDE", "description": "Simplified Adaptive DE with dynamically adjusted F and CR based on population diversity and individual success.", "code": "import numpy as np\n\nclass SimplifiedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.adaptation_rate = adaptation_rate\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.F_history = []\n        self.CR_history = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutation(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        return x_r1 + self.F * (x_r2 - x_r3)\n\n    def crossover(self, v_i, i):\n        j_rand = np.random.randint(self.dim)\n        u_i = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n            return True\n        return False\n\n    def update_parameters(self):\n        # Simple adaptation: If best fitness improved recently, increase CR, otherwise decrease\n        if len(self.F_history) > 10:\n             if self.best_fitness < min(self.F_history[-10:]):\n                self.CR = min(1.0, self.CR + self.adaptation_rate)\n                self.F = min(1.0, self.F + self.adaptation_rate)\n             else:\n                self.CR = max(0.1, self.CR - self.adaptation_rate)\n                self.F = max(0.1, self.F - self.adaptation_rate)\n        self.F_history.append(self.best_fitness)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutation(i)\n                v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n                u_i = self.crossover(v_i, i)\n                self.selection(func, u_i, i)\n            self.update_parameters()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 5, "feedback": "The algorithm SimplifiedAdaptiveDE scored 0.646 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["331aa4c6-31e6-4241-acca-f45e4525fcec"], "operator": null, "metadata": {"aucs": [0.17763159386768346, 0.25261995755792654, 0.7080067468421165, 0.9213108954654947, 0.8649472910829769, 0.9071961567135565, 0.8263260530363742, 0.411759035678694, 0.4734273753077257, 0.7714445148705618, 0.8904589654769742, 0.9935421851235003, 0.2790349543737298, 0.7988459495359099, 0.8044669670605955, 0.8957073796760996, 0.3483510160612886, 0.9158235413267405, 0.20478975310682368, 0.48071338517503903]}}
{"id": "6dd128c2-497f-4f3a-8c89-0b5eaa44af60", "fitness": 0.46985816099726635, "name": "AdaptiveDERestart", "description": "An adaptive differential evolution with a decaying exploration rate and a restart mechanism triggered by stagnation.", "code": "import numpy as np\n\nclass AdaptiveDERestart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, elite_fraction=0.1, restart_trigger=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.elite_count = int(elite_fraction * pop_size)\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5  # Initial F value\n        self.Cr = 0.9 # Initial CR value\n        self.exploration_rate = 1.0\n        self.exploration_decay = 0.999\n        self.restart_trigger = restart_trigger\n        self.stagnation_counter = 0\n        self.last_improvement = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.last_improvement = self.eval_count\n\n\n    def mutate(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        while i in idxs:\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        \n        # Dynamic F: adapt based on success\n        self.F = np.clip(self.F + 0.1 * np.random.normal(0, 1), 0.1, 0.9)\n\n        mutated = x_r1 + self.F * (x_r2 - x_r3)\n        \n        # Add exploration noise, decaying over time\n        mutated = mutated + self.exploration_rate * np.random.normal(0, 0.01, size=self.dim)\n\n        return np.clip(mutated, -5.0, 5.0)\n\n    def crossover(self, mutated, i):\n        crossed = np.copy(self.pop[i])\n        \n        #Dynamic CR\n        if self.fitness[i] > self.f_opt:\n            self.Cr = np.clip(self.Cr + 0.1 * np.random.normal(0, 1), 0.1, 0.9)\n        else:\n            self.Cr = np.clip(self.Cr - 0.05 * np.random.normal(0,1), 0.1, 0.9)\n        \n        for j in range(self.dim):\n            if np.random.rand() < self.Cr:\n                crossed[j] = mutated[j]\n        return crossed\n\n    def selection(self, func, crossed, i):\n        f_new = func(crossed)\n        self.eval_count += 1\n\n        if f_new < self.fitness[i]:\n            self.pop[i] = crossed\n            self.fitness[i] = f_new\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = crossed\n                self.last_improvement = self.eval_count\n\n        elif i < self.elite_count:  # Elitism: Replace worst elite if better\n            worst_elite_index = np.argmax(self.fitness[:self.elite_count])\n            if f_new < self.fitness[worst_elite_index]:\n                self.pop[worst_elite_index] = crossed\n                self.fitness[worst_elite_index] = f_new\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = crossed\n                    self.last_improvement = self.eval_count\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Sort population based on fitness for elitism\n            elite_indices = np.argsort(self.fitness)[:self.elite_count]\n            temp_pop = self.pop.copy()\n            temp_fitness = self.fitness.copy()\n\n            self.pop[:self.elite_count] = temp_pop[elite_indices]\n            self.fitness[:self.elite_count] = temp_fitness[elite_indices]\n\n            remaining_indices = np.array([i for i in range(self.pop_size) if i not in elite_indices])\n            self.pop[self.elite_count:] = temp_pop[remaining_indices]\n            self.fitness[self.elite_count:] = temp_fitness[remaining_indices]\n            \n            # Check for stagnation and restart if necessary\n            if self.eval_count - self.last_improvement > self.restart_trigger:\n                self.initialize_population(func) #Restart\n                self.exploration_rate = 1.0 #reset exploration\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n\n            for i in range(self.pop_size):\n                mutated = self.mutate(i)\n                crossed = self.crossover(mutated, i)\n                self.selection(func, crossed, i)\n\n            self.exploration_rate *= self.exploration_decay\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDERestart scored 0.470 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8603061e-c916-4ee7-ab5a-3866bcc38a37"], "operator": null, "metadata": {"aucs": [0.18440557137946612, 0.2662920406283559, 0.46722020997182423, 0.8106013852583785, 0.5089515870628046, 0.5752273855374366, 0.35280785064299647, 0.43507747526208385, 0.5260089161216279, 0.4696715383289951, 0.6986087318291265, 0.9999153234500381, 0.28322623848859485, 0]}}
{"id": "cdded74c-fd81-45bb-aadb-00a7e9e45aa8", "fitness": 0.3237441577348623, "name": "SimplifiedAdaptiveDE", "description": "Simplified adaptive DE with a reduced set of parameters, focusing on Cauchy mutation with self-adaptation and greedy selection for efficiency.", "code": "import numpy as np\n\nclass SimplifiedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, cauchy_scale=1.0):\n        \"\"\"\n        Initialize the Simplified Adaptive Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of individuals in the population.\n            F (float): Initial scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            cauchy_scale (float): Scale parameter for the Cauchy distribution.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutate(self, func, i):\n        \"\"\"Apply Cauchy mutation to an individual with self-adaptive scale.\"\"\"\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n\n        # Self-adaptive Cauchy scale\n        cauchy_scale_i = self.cauchy_scale * np.exp(np.random.normal(0, 0.1))\n        cauchy_mutation = cauchy_scale_i * np.random.standard_cauchy(size=self.dim)\n        \n        v_i = self.pop[i] + self.F * (x_r1 - x_r2) + cauchy_mutation\n        v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n        return v_i\n\n    def crossover(self, v_i, i):\n        \"\"\"Apply crossover to create a trial vector.\"\"\"\n        j_rand = np.random.randint(self.dim)\n        u_i = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n        return u_i\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Simplified Adaptive DE.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutate(func, i)\n                u_i = self.crossover(v_i, i)\n                f_u_i = func(u_i)\n                self.eval_count += 1\n\n                if f_u_i < self.fitness[i]:\n                    self.fitness[i] = f_u_i\n                    self.pop[i] = u_i.copy()\n\n                    if f_u_i < self.best_fitness:\n                        self.best_fitness = f_u_i\n                        self.best_position = u_i.copy()\n\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 5, "feedback": "The algorithm SimplifiedAdaptiveDE scored 0.324 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["30614c79-b873-46ea-92ee-1c41a2234717"], "operator": null, "metadata": {"aucs": [0.13363235175137722, 0.23823888556295192, 0.30262787012501635, 0.2915439380847591, 0.2405127004420744, 0.30021388315596953, 0.2711845944094784, 0.25801120376647857, 0.23795350744622956, 0.18272056995074104, 0.2875099749348393, 0.9984987844991096, 0.22689448234110288, 0.2608629368977273, 0.6617807361041235, 0.31729581786352157, 0.2578555633183327, 0.3474426005906496, 0.18332867395198416, 0.4767740795007799]}}
{"id": "99cbee48-a3fd-4d08-92f0-cc790358e20c", "fitness": 0.7289849960772903, "name": "HybridSADE", "description": "Simplified hybrid PSO-DE with dynamic inertia weight and simplified velocity clamping for better performance.", "code": "import numpy as np\n\nclass HybridSADE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.5, c2=1.5, F=0.5, CR=0.9, w_start=0.9, w_end=0.4):\n        \"\"\"\n        Initialize the Hybrid SADE Optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            w_start (float): Initial inertia weight.\n            w_end (float): Final inertia weight.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.w_start = w_start\n        self.w_end = w_end\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update(self, func, current_eval):\n        \"\"\"\n        Combined PSO and DE update.\n        \"\"\"\n        # Dynamic inertia weight\n        inertia_weight = self.w_start - (self.w_start - self.w_end) * (current_eval / self.budget)\n\n        for i in range(self.pop_size):\n            # PSO Velocity Update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = (inertia_weight * self.velocities[i] +\n                        self.c1 * r1 * (self.global_best_position - self.pop[i]) +\n                        self.c2 * r2 * (self.pop[np.random.randint(self.pop_size)] - self.pop[i]))\n\n            # Simplified Velocity Clamping (optional)\n            # v_max = 0.2 * (func.bounds.ub - func.bounds.lb)\n            # velocity = np.clip(velocity, -v_max, v_max)\n\n            trial_position = self.pop[i] + velocity\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n\n            # DE Mutation & Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            mutant = x_r1 + self.F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            trial_vector = np.array([mutant[j] if np.random.rand() < self.CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # Greedy Selection\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n\n            self.velocities[i] = velocity # update velocity\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n        current_eval = self.pop_size\n\n        while current_eval < self.budget:\n            self.update(func, current_eval)\n            current_eval = self.eval_count\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm HybridSADE scored 0.729 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["262dba6b-8d03-46bd-886a-64c3bd7fb77a"], "operator": null, "metadata": {"aucs": [0.2303931015777111, 0.8308191133424309, 0.7990469335273966, 0.9461694789991323, 0.8459623850381015, 0.8785829275757389, 0.8011113493189242, 0.8351491553594894, 0.8474999139554439, 0.8461294355027358, 0.7705353251629131, 0.9956606300605483, 0.30817250125584894, 0.8334815984847948, 0.8809126111186638, 0.8624936584734143, 0.3748420667281249, 0.920437383549481, 0.2677009316735194, 0.504599420841392]}}
{"id": "74c014bf-d354-43bf-999e-39fe6b6afbac", "fitness": 0.7201373195332463, "name": "HybridSADE", "description": "Simplified hybrid PSO-DE with adaptive velocity clamping based on current population spread and simplified parameter control.", "code": "import numpy as np\n\nclass HybridSADE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.5, c2=1.5, F=0.5, CR=0.9):\n        \"\"\"\n        Initialize the Hybrid SADE Optimizer.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.inertia_weight = 0.7\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.zeros((self.pop_size, self.dim))  # Initialize velocities to zero\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update(self, func):\n        \"\"\"\n        Combined PSO and DE update.\n        \"\"\"\n        # Calculate population spread for adaptive velocity clamping\n        pop_mean = np.mean(self.pop, axis=0)\n        pop_std = np.std(self.pop, axis=0)\n        v_max = pop_std # Clamp based on population standard deviation\n\n        for i in range(self.pop_size):\n            # PSO Velocity Update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = (self.inertia_weight * self.velocities[i] +\n                        self.c1 * r1 * (self.global_best_position - self.pop[i]) +\n                        self.c2 * r2 * (self.pop[np.random.randint(self.pop_size)] - self.pop[i]))\n\n            # Velocity Clamping\n            velocity = np.clip(velocity, -v_max, v_max)\n            trial_position = self.pop[i] + velocity\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n\n            # DE Mutation & Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            mutant = x_r1 + self.F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            trial_vector = np.array([mutant[j] if np.random.rand() < self.CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # Greedy Selection\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n\n            self.velocities[i] = velocity # update the velocity regardless of acceptance\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm HybridSADE scored 0.720 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["262dba6b-8d03-46bd-886a-64c3bd7fb77a"], "operator": null, "metadata": {"aucs": [0.20088279521402397, 0.8701081847758348, 0.5663014582323025, 0.19885734515421505, 0.7928155474637011, 0.9314515734101465, 0.8889920027413354, 0.8879750533719819, 0.9141879837099686, 0.8678072510095355, 0.9388207903127092, 0.9999174573113544, 0.4803736615536047, 0.9064610193118561, 0.6622358335999445, 0.9239574436130766, 0.6724359180206614, 0.9510265784834339, 0.22896833421079799, 0.5191701591644438]}}
{"id": "9a2c4c0a-e6cb-4991-a85e-4a312168e170", "fitness": 0.5611128042130547, "name": "AdaptiveMutationPoolDE", "description": "Adaptively adjust F and CR parameters based on the success of mutation strategies, alongside a tournament selection for parent selection.", "code": "import numpy as np\n\nclass AdaptiveMutationPoolDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, mutation_pool=None, adaptation_rate=0.1, tournament_size=3):\n        \"\"\"\n        Initialize the Adaptive Mutation Pool Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of individuals in the population.\n            F (float): Initial scaling factor for DE.\n            CR (float): Initial crossover rate for DE.\n            mutation_pool (list): A list of mutation strategies (functions). If None, a default set is used.\n            adaptation_rate (float): Learning rate for adapting the selection probabilities of mutation strategies.\n            tournament_size (int): Size of the tournament for parent selection.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.adaptation_rate = adaptation_rate\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.tournament_size = tournament_size\n\n        if mutation_pool is None:\n            self.mutation_pool = [\n                self.mutation_rand1,\n                self.mutation_current_to_best1,\n                self.mutation_best1,\n                self.mutation_rand2\n            ]\n        else:\n            self.mutation_pool = mutation_pool\n\n        self.num_mutation_strategies = len(self.mutation_pool)\n        self.strategy_successes = np.zeros(self.num_mutation_strategies) # track success\n        self.strategy_counts = np.ones(self.num_mutation_strategies) # track usage\n        self.strategy_probabilities = np.ones(self.num_mutation_strategies) / self.num_mutation_strategies # equal initial probabilities\n        self.F_memory = np.ones(self.num_mutation_strategies) * self.F # store F values used\n        self.CR_memory = np.ones(self.num_mutation_strategies) * self.CR # store CR values used\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population with random positions.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutation_rand1(self, i):\n        \"\"\"DE/rand/1 mutation strategy.\"\"\"\n        idxs = self.tournament_selection(3, i) # Tournament selection for parents\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        return x_r1 + self.F_memory[0] * (x_r2 - x_r3)\n\n    def mutation_current_to_best1(self, i):\n         \"\"\"DE/current-to-best/1 mutation.\"\"\"\n         idxs = self.tournament_selection(2, i) # Tournament selection for parents\n         x_r1, x_r2 = self.pop[idxs]\n         return self.pop[i] + self.F_memory[1] * (self.best_position - self.pop[i]) + self.F_memory[1] * (x_r1 - x_r2)\n\n    def mutation_best1(self, i):\n        \"\"\"DE/best/1 mutation.\"\"\"\n        idxs = self.tournament_selection(2, i) # Tournament selection for parents\n        x_r1, x_r2 = self.pop[idxs]\n        return self.best_position + self.F_memory[2] * (x_r1 - x_r2)\n\n    def mutation_rand2(self, i):\n        \"\"\"DE/rand/2 mutation strategy.\"\"\"\n        idxs = self.tournament_selection(5, i) # Tournament selection for parents\n        x_r1, x_r2, x_r3, x_r4, x_r5 = self.pop[idxs]\n        return x_r1 + self.F_memory[3] * (x_r2 - x_r3) + self.F_memory[3] * (x_r4 - x_r5)\n\n    def tournament_selection(self, num_participants, current_index):\n        \"\"\"Tournament selection for choosing parents.\"\"\"\n        candidates = np.random.choice(self.pop_size, self.tournament_size, replace=False)\n        while current_index in candidates:\n           candidates = np.random.choice(self.pop_size, self.tournament_size, replace=False) #ensure the current index is not selected\n        \n        \n        best_candidate = candidates[np.argmin(self.fitness[candidates])]\n        remaining_candidates = np.delete(candidates, np.argmin(self.fitness[candidates]))\n\n        if len(remaining_candidates) < num_participants -1 : #edge case handling if tournament size is too small\n            remaining_candidates = np.concatenate((remaining_candidates, np.random.choice(self.pop_size, num_participants - 1 - len(remaining_candidates), replace=False)))\n\n        \n        selected_indices = np.random.choice(remaining_candidates, num_participants - 1, replace=False)\n        return np.concatenate(([best_candidate], selected_indices))\n        \n\n    def crossover(self, v_i, i, strategy_index):\n        \"\"\"Apply crossover to create a trial vector.\"\"\"\n        j_rand = np.random.randint(self.dim)\n        u_i = np.array([v_i[j] if np.random.rand() < self.CR_memory[strategy_index] or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n        return u_i\n\n    def selection(self, func, u_i, i, strategy_index):\n        \"\"\"Apply selection between the trial vector and the current individual.\"\"\"\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            self.strategy_successes[strategy_index] += 1 # strategy was successful\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n        \n\n    def update_strategy_probabilities(self):\n        \"\"\"Update the selection probabilities of the mutation strategies.\"\"\"\n        for i in range(self.num_mutation_strategies):\n            self.strategy_counts[i] += 1\n            success_rate = self.strategy_successes[i] / self.strategy_counts[i]\n            self.strategy_probabilities[i] += self.adaptation_rate * (success_rate - self.strategy_probabilities[i])\n\n            # Adapt F and CR based on success rate\n            self.F_memory[i] = np.clip(self.F_memory[i] + self.adaptation_rate * (success_rate - 0.5), 0.1, 1.0) # Adjust F\n            self.CR_memory[i] = np.clip(self.CR_memory[i] + self.adaptation_rate * (success_rate - 0.5), 0.1, 1.0) # Adjust CR\n\n            self.strategy_successes[i] = 0\n            self.strategy_counts[i] = 1\n\n        self.strategy_probabilities = np.maximum(0, self.strategy_probabilities)\n        self.strategy_probabilities /= np.sum(self.strategy_probabilities)\n    \n    def __call__(self, func):\n        \"\"\"Optimize the given function using Adaptive Mutation Pool DE.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Select a mutation strategy based on probabilities\n                strategy_index = np.random.choice(self.num_mutation_strategies, p=self.strategy_probabilities)\n                mutation_strategy = self.mutation_pool[strategy_index]\n\n                v_i = mutation_strategy(i)\n                v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n                u_i = self.crossover(v_i, i, strategy_index)\n                self.selection(func, u_i, i, strategy_index)\n\n            self.update_strategy_probabilities()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveMutationPoolDE scored 0.561 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["331aa4c6-31e6-4241-acca-f45e4525fcec"], "operator": null, "metadata": {"aucs": [0.20622094445840788, 0.18936417768757252, 0.8494771254852985, 0.261623699450668, 0.8873351070126158, 0.283758940977045, 0.2906115010322544, 0.8412637405038985, 0.5146386343319573, 0.23469622197853346, 0.9157011484959943, 0.9999123310926825, 0.30627330053253987, 0.8040046229704741, 0.9577520918447653, 0.8897105555319296, 0.3749159483042128, 0.6667550542001714, 0.24102307831590486, 0.5072178600541642]}}
{"id": "2bcd4da1-e5e4-42db-a6a9-43b95262bc2f", "fitness": 0.34920875117053857, "name": "SimplifiedCauchyAdaptiveDE", "description": "Simplified Cauchy DE with self-adaptive mutation and crossover, focusing on reducing parameter bloat and improving adaptability through a moving average of past mutation factors.", "code": "import numpy as np\n\nclass SimplifiedCauchyAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, cauchy_scale=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.F_history = [F]\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutate(self, i, func):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n\n        # Self-adaptive F using Cauchy distribution\n        F_i = self.F + 0.1 * np.random.standard_cauchy()\n        F_i = np.clip(F_i, 0.1, 1.0)\n        self.F_history.append(F_i)\n        self.F = np.mean(self.F_history[-5:]) # Moving average\n\n        cauchy_mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n        v_i = x_r1 + F_i * (x_r2 - x_r3) + cauchy_mutation\n        v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n        return v_i\n\n    def crossover(self, v_i, i):\n        j_rand = np.random.randint(self.dim)\n        u_i = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutate(i, func)\n                u_i = self.crossover(v_i, i)\n                self.selection(func, u_i, i)\n\n            self.CR = np.clip(self.CR + np.random.normal(0, 0.05), 0.1, 1.0)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 5, "feedback": "The algorithm SimplifiedCauchyAdaptiveDE scored 0.349 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["30614c79-b873-46ea-92ee-1c41a2234717"], "operator": null, "metadata": {"aucs": [0.14837589279837116, 0.21868001207718168, 0.3431089434032689, 0.3984681667923444, 0.25817053992073047, 0.3066144939791072, 0.2962694449479618, 0.2868382419851079, 0.24987311963058978, 0.26227936055403245, 0.3037626148111806, 0.9931035407139236, 0.2629629951813861, 0.26348239905781234, 0.6898904138183521, 0.33033720586815984, 0.30351264862338745, 0.3761970630577619, 0.2097338122830621, 0.482514113907049]}}
{"id": "e1bc5b33-f77e-4bfa-92b5-e9ab5a08f3ed", "fitness": 0.7760081035551194, "name": "HybridSADE", "description": "Simplified hybrid PSO-DE with adaptive velocity clamping, reduced parameters, and improved exploration via a dynamic scaling factor.", "code": "import numpy as np\n\nclass HybridSADE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        \"\"\"\n        Initialize the Hybrid SADE Optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update(self, func):\n        \"\"\"\n        Combined PSO and DE update.\n        \"\"\"\n        F = 0.5 # Scaling factor for DE.\n        CR = 0.9 # Crossover rate for DE.\n\n        for i in range(self.pop_size):\n            # PSO Velocity Update with adaptive clamping\n            inertia_weight = 0.5 # Fixed inertia\n            c1 = 1.5 # Fixed cognitive parameter\n            c2 = 1.5 # Fixed social parameter\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = (inertia_weight * self.velocities[i] +\n                        c1 * r1 * (self.global_best_position - self.pop[i]) +\n                        c2 * r2 * (self.pop[np.random.randint(self.pop_size)] - self.pop[i]))\n\n            # Adaptive velocity clamping\n            v_max = 0.1 * (func.bounds.ub - func.bounds.lb) # Reduce clamping\n            velocity = np.clip(velocity, -v_max, v_max)\n            trial_position = self.pop[i] + velocity\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n\n            # DE Mutation & Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            mutant = x_r1 + F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            trial_vector = np.array([mutant[j] if np.random.rand() < CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # Greedy Selection\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n\n            self.velocities[i] = velocity # Update velocity\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm HybridSADE scored 0.776 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["262dba6b-8d03-46bd-886a-64c3bd7fb77a"], "operator": null, "metadata": {"aucs": [0.48942890498767033, 0.474726246812042, 0.8311829021655212, 0.9361951413146719, 0.901357063526804, 0.9112592963179239, 0.8428149339064812, 0.839846182541826, 0.8903105009069904, 0.2098515408057705, 0.9448137935488453, 0.9942250341298535, 0.7194635761494227, 0.8622090891343049, 0.9614047076354937, 0.8998172360257255, 0.6831818391563939, 0.9340950246653347, 0.6872419799466085, 0.5067370774247085]}}
{"id": "3c344298-70ec-4b2a-9853-fb2cfd3c1321", "fitness": -Infinity, "name": "AdaptiveDEArchive", "description": "Adaptive Differential Evolution with archive, stagnation detection, and parameter randomization for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDEArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, adaptation_rate=0.1, archive_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.adaptation_rate = adaptation_rate\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.archive = []\n        self.archive_fitness = []\n        self.archive_size = archive_size\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 50\n        self.F_history = []\n        self.CR_history = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutation(self, i, func):\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        x_r1, x_r2 = self.pop[idxs]\n        \n        #Use archive individuals in mutation with a small probability\n        if len(self.archive) > 0 and np.random.rand() < 0.1:\n            arch_idx = np.random.randint(len(self.archive))\n            x_r3 = self.archive[arch_idx]\n        else:\n             idxs2 = np.random.choice(self.pop_size, 1, replace=False)\n             x_r3 = self.pop[idxs2[0]]\n\n        F_rand = np.random.uniform(0.1, self.F) #randomize F\n        v_i = self.pop[i] + F_rand * (x_r1 - x_r2) #DE/rand/1 strategy\n        v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n        return v_i\n\n\n    def crossover(self, v_i, i):\n        j_rand = np.random.randint(self.dim)\n        CR_rand = np.random.uniform(0, self.CR) #randomize CR\n        u_i = np.array([v_i[j] if np.random.rand() < CR_rand or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            # Add replaced individual to archive\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.pop[i].copy())\n                self.archive_fitness.append(self.fitness[i])\n            else:\n                # Replace oldest member\n                self.archive[i % self.archive_size] = self.pop[i].copy()\n                self.archive_fitness[i % self.archive_size] = self.fitness[i]\n\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n                self.stagnation_counter = 0  # Reset stagnation counter\n            else:\n                self.stagnation_counter +=1\n            return True\n        else:\n            self.stagnation_counter +=1\n        return False\n\n    def update_parameters(self):\n        # Adaptation based on stagnation\n        if self.stagnation_counter > self.stagnation_threshold:\n            # Increase exploration by increasing F and CR\n            self.F = min(1.0, self.F + 0.2)\n            self.CR = min(1.0, self.CR + 0.2)\n            # Randomize a subset of the population\n            num_randomize = int(0.1 * self.pop_size)\n            idxs = np.random.choice(self.pop_size, num_randomize, replace=False)\n            for i in idxs:\n                self.pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.fitness[i] = func(self.pop[i])\n                self.eval_count += 1\n            self.stagnation_counter = 0  # Reset stagnation counter\n        else:\n             # Gradual reduction if things are improving\n             self.F = max(0.1, self.F - 0.01)\n             self.CR = max(0.1, self.CR - 0.01)\n        self.F_history.append(self.F)\n        self.CR_history.append(self.CR)\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutation(i, func)\n                u_i = self.crossover(v_i, i)\n                self.selection(func, u_i, i)\n            self.update_parameters()\n\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 6, "feedback": "An exception occurred: name 'func' is not defined.", "error": "", "parent_ids": ["8152f1a6-84bb-41f5-8dc9-c78aa420f843"], "operator": null, "metadata": {}}
{"id": "5b469f5c-6c21-42cd-92fd-b82e1e13fc00", "fitness": 0.0, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on population diversity and optional local search.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, local_search_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_prob = local_search_prob # Probability of applying local search\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.diversity_history = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutation(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        return x_r1 + self.F * (x_r2 - x_r3)\n\n    def crossover(self, v_i, i):\n        j_rand = np.random.randint(self.dim)\n        u_i = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n        return u_i\n\n    def local_search(self, func, x, step_size=0.1):\n        # Apply slight perturbation to each dimension\n        x_new = x.copy()\n        for j in range(self.dim):\n            x_new[j] += np.random.uniform(-step_size, step_size)\n        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n        f_new = func(x_new)\n        self.eval_count += 1\n        return f_new, x_new\n\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        # Local Search\n        if np.random.rand() < self.local_search_prob:\n            f_ls, u_ls = self.local_search(func, u_i)\n            if f_ls < f_u_i:\n                f_u_i = f_ls\n                u_i = u_ls\n\n        if f_u_i < self.fitness[i]:\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n            return True\n        return False\n\n    def calculate_diversity(self):\n        # Calculate the standard deviation of the population\n        return np.std(self.pop)\n\n    def update_parameters(self):\n        diversity = self.calculate_diversity()\n        self.diversity_history.append(diversity)\n\n        # Adjust parameters based on population diversity\n        if len(self.diversity_history) > 5:\n            if self.diversity_history[-1] < np.mean(self.diversity_history[-5:]):  # Population is converging\n                self.CR = min(1.0, self.CR + 0.1)\n                self.F = max(0.1, self.F - 0.05) # reduce F to exploit more.\n            else:  # Population is diverging\n                self.CR = max(0.1, self.CR - 0.1)\n                self.F = min(0.9, self.F + 0.05)  # increase F to explore more\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutation(i)\n                v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n                u_i = self.crossover(v_i, i)\n                u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)\n                self.selection(func, u_i, i)\n            self.update_parameters()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8152f1a6-84bb-41f5-8dc9-c78aa420f843"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "851c7fce-8af6-43f9-a8d0-579042f2c895", "fitness": 0.0, "name": "HybridSADE", "description": "Hybrid PSO-DE with periodic local search and adaptive parameter control based on success rate.", "code": "import numpy as np\n\nclass HybridSADE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.5, c2=1.5, F=0.5, CR=0.9, local_search_freq=100):\n        \"\"\"\n        Initialize the Hybrid SADE Optimizer.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.inertia_weight = 0.7\n        self.local_search_freq = local_search_freq\n        self.success_rate_F = 0.5\n        self.success_rate_CR = 0.5\n        self.successful_F = []\n        self.successful_CR = []\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.zeros((self.pop_size, self.dim))  # Initialize velocities to zero\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def local_search(self, func, x, radius=0.1):\n        \"\"\"Perform a simple local search around a given point.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.eval_count += 1\n\n        for _ in range(10):  # Limited local evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.eval_count += 1\n\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n\n        return best_f, best_x\n    \n    def update_adaptive_parameters(self):\n        \"\"\"Update F and CR based on the success rate.\"\"\"\n        if self.successful_F:\n            self.F = np.mean(self.successful_F)\n            self.F = np.clip(self.F, 0.1, 0.9)\n        if self.successful_CR:\n            self.CR = np.mean(self.successful_CR)\n            self.CR = np.clip(self.CR, 0.1, 0.9)\n\n        self.successful_F = []\n        self.successful_CR = []\n\n    def update(self, func):\n        \"\"\"\n        Combined PSO and DE update.\n        \"\"\"\n        # Calculate population spread for adaptive velocity clamping\n        pop_mean = np.mean(self.pop, axis=0)\n        pop_std = np.std(self.pop, axis=0)\n        v_max = pop_std # Clamp based on population standard deviation\n\n        for i in range(self.pop_size):\n            # PSO Velocity Update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = (self.inertia_weight * self.velocities[i] +\n                        self.c1 * r1 * (self.global_best_position - self.pop[i]) +\n                        self.c2 * r2 * (self.pop[np.random.randint(self.pop_size)] - self.pop[i]))\n\n            # Velocity Clamping\n            velocity = np.clip(velocity, -v_max, v_max)\n            trial_position = self.pop[i] + velocity\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n\n            # DE Mutation & Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            mutant = x_r1 + self.F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            trial_vector = np.array([mutant[j] if np.random.rand() < self.CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # Greedy Selection\n            if f_trial < self.fitness[i]:\n                self.successful_F.append(self.F)\n                self.successful_CR.append(self.CR)\n\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n\n            self.velocities[i] = velocity # update the velocity regardless of acceptance\n            \n        if self.eval_count % self.local_search_freq == 0:\n            best_index = np.argmin(self.fitness)\n            f_ls, x_ls = self.local_search(func, self.pop[best_index])\n            if f_ls < self.global_best_fitness:\n                 self.global_best_fitness = f_ls\n                 self.global_best_position = x_ls.copy()\n\n        self.update_adaptive_parameters()\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm HybridSADE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["74c014bf-d354-43bf-999e-39fe6b6afbac"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "bbbef417-1e45-4a73-8329-ed1d6de4945e", "fitness": 0.4131023220022332, "name": "AdaptiveHybridPSODE", "description": "Adaptive hybrid PSO-DE with self-adaptive parameters (F, CR, c1, c2), and a local search component triggered based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.F = 0.5  # Initial DE parameter\n        self.CR = 0.9 # Initial DE parameter\n        self.c1 = 1.5  # Initial PSO parameter\n        self.c2 = 1.5  # Initial PSO parameter\n        self.inertia_weight = 0.7\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 50  # Number of iterations without improvement before triggering local search\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.zeros((self.pop_size, self.dim))\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update(self, func):\n        best_fitness_before = self.global_best_fitness\n        for i in range(self.pop_size):\n            # Self-adaptive parameter update (example)\n            self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 0.9)\n            self.CR = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)\n            self.c1 = np.clip(np.random.normal(1.5, 0.2), 1.0, 2.0)\n            self.c2 = np.clip(np.random.normal(1.5, 0.2), 1.0, 2.0)\n\n            # PSO Velocity Update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = (self.inertia_weight * self.velocities[i] +\n                        self.c1 * r1 * (self.global_best_position - self.pop[i]) +\n                        self.c2 * r2 * (self.pop[np.random.randint(self.pop_size)] - self.pop[i]))\n\n            trial_position = self.pop[i] + velocity\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n\n            # DE Mutation & Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            mutant = x_r1 + self.F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            trial_vector = np.array([mutant[j] if np.random.rand() < self.CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # Greedy Selection\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n\n            self.velocities[i] = velocity # Update velocity regardless of acceptance\n\n        if self.global_best_fitness == best_fitness_before:\n            self.stagnation_counter += 1\n        else:\n            self.stagnation_counter = 0\n\n        if self.stagnation_counter > self.stagnation_threshold:\n            self.local_search(func)\n            self.stagnation_counter = 0\n\n    def local_search(self, func):\n        # Perform local search around the global best\n        sigma = 0.1 * (func.bounds.ub - func.bounds.lb)  # Define a step size\n        for _ in range(10): # limited local search evaluations\n            noise = np.random.normal(0, sigma, self.dim)\n            new_position = self.global_best_position + noise\n            new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n            new_fitness = func(new_position)\n            self.eval_count += 1\n\n            if new_fitness < self.global_best_fitness:\n                self.global_best_fitness = new_fitness\n                self.global_best_position = new_position.copy()\n                # Reset stagnation counter upon improvement\n                self.stagnation_counter = 0\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridPSODE scored 0.413 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["74c014bf-d354-43bf-999e-39fe6b6afbac"], "operator": null, "metadata": {"aucs": [0.36800059004744146, 0.871306375959258, 0]}}
{"id": "00fb3a65-b738-48b7-a391-ee37bd206c25", "fitness": 0.2640690470599404, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on population diversity and a distance-based mutation scaling factor.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutation(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        \n        # Distance-based scaling factor\n        distance = np.linalg.norm(x_r2 - x_r3)\n        F_scaled = self.F * (1 + distance)\n\n        return x_r1 + F_scaled * (x_r2 - x_r3)\n\n    def crossover(self, v_i, i):\n        j_rand = np.random.randint(self.dim)\n        u_i = np.array([v_i[j] if np.random.rand() < self.CR or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            \n            # Calculate population diversity\n            diversity = np.std(self.pop)\n            \n            #Adapt parameters based on diversity\n            if diversity > 0.1:\n                self.CR = min(1.0, self.CR + 0.05)\n                self.F = min(1.0, self.F + 0.05)\n            else:\n                self.CR = max(0.1, self.CR - 0.05)\n                self.F = max(0.1, self.F - 0.05)\n                \n            for i in range(self.pop_size):\n                v_i = self.mutation(i)\n                v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n                u_i = self.crossover(v_i, i)\n                self.selection(func, u_i, i)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.264 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8152f1a6-84bb-41f5-8dc9-c78aa420f843"], "operator": null, "metadata": {"aucs": [0.10832556622836786, 0.14151719982938216, 0.2522209460653646, 0.19470097766178118, 0.16024978804512535, 0.19646597698711277, 0.183862763665553, 0.18275631703274875, 0.22647205121774316, 0.15562513829204327, 0.18219936384859636, 0.9978118804315385, 0.21864138908082942, 0.16592484066594448, 0.5804943788071474, 0.2436906566819277, 0.23738870064558415, 0.25945773394501237, 0.13099319885664262, 0.4625820732103618]}}
{"id": "45d62270-9ed6-4f46-aab2-b6ecc35384dc", "fitness": 0.6765462033666262, "name": "HybridSADE", "description": "Simplified hybrid PSO-DE with reduced parameter count and population-based velocity scaling for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridSADE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        \"\"\"\n        Initialize the Hybrid SADE Optimizer.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.zeros((self.pop_size, self.dim))\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update(self, func):\n        \"\"\"\n        Combined PSO and DE update.\n        \"\"\"\n        # Population spread for velocity scaling\n        pop_mean = np.mean(self.pop, axis=0)\n        velocity_scale = np.std(self.pop, axis=0)\n\n        for i in range(self.pop_size):\n            # PSO-inspired Velocity Update\n            r1 = np.random.rand(self.dim)\n            velocity = (self.velocities[i] +\n                        r1 * (self.global_best_position - self.pop[i])) # Simplified PSO\n\n            # Velocity Scaling\n            velocity = velocity * velocity_scale\n            trial_position = self.pop[i] + velocity\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n\n            # DE Mutation & Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            mutant = x_r1 + self.F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            trial_vector = np.array([mutant[j] if np.random.rand() < self.CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # Greedy Selection\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n\n            self.velocities[i] = velocity # Update velocity\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm HybridSADE scored 0.677 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["74c014bf-d354-43bf-999e-39fe6b6afbac"], "operator": null, "metadata": {"aucs": [0.42549046441357763, 0.856588307183075, 0.4485798106025858, 0.9307797902494945, 0.9045129705606401, 0.8146384714093688, 0.33156630194687076, 0.8395138116786667, 0.6504582218322266, 0.5224111958939459, 0.9083980273344541, 0.9914838319019673, 0.4639347012705842, 0.36988722470794055, 0.7682467670643542, 0.8987277596329075, 0.6381609951461475, 0.9266209131077414, 0.3358263897348911, 0.505098111661084]}}
{"id": "1359e02b-3cca-48c9-806a-7c52abb1659d", "fitness": 0.5798945766495601, "name": "HybridSADE", "description": "Simplified hybrid PSO-DE with dynamic parameter adaptation based on population best fitness improvement.", "code": "import numpy as np\n\nclass HybridSADE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.5, c2=1.5, F=0.5, CR=0.9, w_start=0.9, w_end=0.4):\n        \"\"\"\n        Initialize the Hybrid SADE Optimizer with dynamic parameter adaptation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.w_start = w_start\n        self.w_end = w_end\n        self.best_history = []\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.best_history.append(self.global_best_fitness)\n\n    def update(self, func):\n        \"\"\"\n        Combined PSO and DE update with simplified parameter control.\n        \"\"\"\n        # Calculate inertia weight (linearly decreasing)\n        w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget)\n\n        for i in range(self.pop_size):\n            # PSO-inspired trial vector generation\n            personal_influence = self.c1 * np.random.rand(self.dim) * (self.global_best_position - self.pop[i])\n            social_influence = self.c2 * np.random.rand(self.dim) * (self.pop[np.random.randint(self.pop_size)] - self.pop[i])\n            trial_position = self.pop[i] + w * personal_influence + (1-w) * social_influence\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n\n            # DE-inspired mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            mutant = x_r1 + self.F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            trial_vector = np.array([mutant[j] if np.random.rand() < self.CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # Greedy Selection\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm HybridSADE scored 0.580 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["74c014bf-d354-43bf-999e-39fe6b6afbac"], "operator": null, "metadata": {"aucs": [0.25817965793377284, 0.4748358601767756, 0.4545765860487181, 0.6444992720701366, 0.37277041736819483, 0.30951521384635683, 0.8627100904101097, 0.5571063611240671, 0.8926635375069203, 0.5853444047230143, 0.9417240179488053, 0.9967962338116083, 0.3064017390104782, 0.39279684834953077, 0.8945030116056215, 0.9231412854685241, 0.3412191389248176, 0.49255018117057425, 0.378129464324927, 0.5184282111682483]}}
{"id": "65fb98f2-3399-44ad-9f8c-cbda339fb93f", "fitness": 0.6052037506136148, "name": "HybridSADE", "description": "Combines PSO and DE with self-adaptive parameters F and CR, and dynamic population size adjustment based on performance.", "code": "import numpy as np\n\nclass HybridSADE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.5, c2=1.5, F_start=0.3, F_end=0.9, CR_start=0.8, CR_end=0.2, w_start=0.9, w_end=0.4, pop_size_min=10):\n        \"\"\"\n        Initialize the Hybrid SADE Optimizer with self-adaptive F and CR, and dynamic population size.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The initial number of particles in the population.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F_start (float): Initial scaling factor for DE.\n            F_end (float): Final scaling factor for DE.\n            CR_start (float): Initial crossover rate for DE.\n            CR_end (float): Final crossover rate for DE.\n            w_start (float): Initial inertia weight.\n            w_end (float): Final inertia weight.\n            pop_size_min (int): Minimum population size.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.F_start = F_start\n        self.F_end = F_end\n        self.CR_start = CR_start\n        self.CR_end = CR_end\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.w_start = w_start\n        self.w_end = w_end\n        self.pop_size_min = pop_size_min\n        self.archive = [] # Archive for storing potentially useful solutions\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update(self, func, current_eval):\n        \"\"\"\n        Combined PSO and DE update with self-adaptive F and CR.\n        \"\"\"\n        # Dynamic inertia weight\n        inertia_weight = self.w_start - (self.w_start - self.w_end) * (current_eval / self.budget)\n\n        # Adaptive F and CR\n        F = self.F_start + (self.F_end - self.F_start) * (current_eval / self.budget)\n        CR = self.CR_start + (self.CR_end - self.CR_start) * (current_eval / self.budget)\n\n        for i in range(self.pop_size):\n            # PSO Velocity Update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = (inertia_weight * self.velocities[i] +\n                        self.c1 * r1 * (self.global_best_position - self.pop[i]) +\n                        self.c2 * r2 * (self.pop[np.random.randint(self.pop_size)] - self.pop[i]))\n\n            trial_position = self.pop[i] + velocity\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n\n            # DE Mutation & Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            mutant = x_r1 + F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            trial_vector = np.array([mutant[j] if np.random.rand() < CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # Greedy Selection\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n                # Update archive\n                self.archive.append((trial_vector.copy(), f_trial))\n\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n\n            self.velocities[i] = velocity # update velocity\n\n        # Dynamic population size adjustment (simple example - can be improved)\n        if current_eval % (self.budget // 10) == 0: # Adjust every 10% of budget\n            if np.std(self.fitness) < 1e-3 and self.pop_size > self.pop_size_min:  # If population is too homogeneous, reduce size\n                self.pop_size = max(self.pop_size // 2, self.pop_size_min)\n                self.pop = self.pop[:self.pop_size]\n                self.fitness = self.fitness[:self.pop_size]\n                self.velocities = self.velocities[:self.pop_size]\n            elif np.std(self.fitness) > 1e-1 and self.pop_size < 20: # Increase pop size up to limit of 20 if it's diverse and not stuck\n                self.pop_size = min(self.pop_size * 2, 20)\n                # Repopulate with random and archive individuals\n                new_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - len(self.pop), self.dim))\n                new_fitness = np.array([func(x) for x in new_pop])\n                self.eval_count += len(new_pop)\n\n                if len(self.archive) > 0:\n                    archive_samples = min(len(self.archive), self.pop_size - len(self.pop))\n                    best_archive_individuals = sorted(self.archive, key=lambda x: x[1])[:archive_samples]\n                    new_pop = np.concatenate((new_pop, np.array([x[0] for x in best_archive_individuals])))\n                    new_fitness = np.concatenate((new_fitness, np.array([x[1] for x in best_archive_individuals])))\n\n\n                self.pop = np.concatenate((self.pop, new_pop))\n                self.fitness = np.concatenate((self.fitness, new_fitness))\n                self.velocities = np.concatenate((self.velocities, np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(len(new_pop), self.dim))))\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n        current_eval = self.pop_size\n\n        while current_eval < self.budget:\n            self.update(func, current_eval)\n            current_eval = self.eval_count\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm HybridSADE scored 0.605 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["99cbee48-a3fd-4d08-92f0-cc790358e20c"], "operator": null, "metadata": {"aucs": [0.19504956101643167, 0.2369297785711174, 0.6299257268256165, 0.8619537692396294, 0.7050206402995147, 0.828263459528772, 0.40071901485582817, 0.6045806780482963, 0.7432024422815482, 0.6901656405413905, 0.794053777663131, 0.9948698666474282, 0.28249236738691086, 0.557024537816107, 0.9022013109197968, 0.8382146176287681, 0.2898140333946727, 0.835137514398015, 0.2352685914938205, 0.47918768371549847]}}
{"id": "fde41314-cb75-446e-98ac-b9f87d05e42d", "fitness": 0.43115099257634315, "name": "AdaptiveHybridPSODE", "description": "Adaptive Hybrid PSO-DE with simplified parameter adaptation based on success rate for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.5, c2=1.5, F=0.5, CR=0.9, w=0.7):\n        \"\"\"\n        Initialize the Adaptive Hybrid PSO-DE Optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            F (float): Scaling factor for DE.\n            CR (float): Crossover rate for DE.\n            w (float): Inertia weight.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.w = w\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.success_rate = 0.0  # Track success rate for parameter adaptation\n        self.success_history = []\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_parameters(self):\n        \"\"\"\n        Adapt parameters based on success rate.\n        \"\"\"\n        if len(self.success_history) > 10:\n          self.success_rate = np.mean(self.success_history[-10:])\n\n        if self.success_rate > 0.6:\n            self.F *= 0.99  # Reduce F if doing well - exploit\n            self.CR = min(1.0, self.CR * 1.01) # Increase CR if doing well\n        elif self.success_rate < 0.3:\n            self.F = min(1.0, self.F * 1.01)  # Increase F if not doing well - explore\n            self.CR *= 0.99  # Reduce CR if not doing well\n            \n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.CR = np.clip(self.CR, 0.1, 0.9)\n\n    def update(self, func):\n        \"\"\"\n        Combined PSO and DE update with adaptive parameters.\n        \"\"\"\n        successful_moves = 0\n\n        for i in range(self.pop_size):\n            # PSO Velocity Update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = (self.w * self.velocities[i] +\n                        self.c1 * r1 * (self.global_best_position - self.pop[i]) +\n                        self.c2 * r2 * (self.pop[np.random.randint(self.pop_size)] - self.pop[i]))\n\n            trial_position = self.pop[i] + velocity\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n\n            # DE Mutation & Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            mutant = x_r1 + self.F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            trial_vector = np.array([mutant[j] if np.random.rand() < self.CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # Greedy Selection\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n                successful_moves +=1\n                self.success_history.append(1)\n\n            else:\n                self.success_history.append(0)\n\n            self.velocities[i] = velocity # update velocity\n\n        self.update_parameters()\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridPSODE scored 0.431 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["99cbee48-a3fd-4d08-92f0-cc790358e20c"], "operator": null, "metadata": {"aucs": [0.15634402447538154, 0.25230753340350953, 0.3340284549671403, 0.7177101734676654, 0.32539423411066126, 0.5155792229357462, 0.31897453221134753, 0.3845029163833802, 0.3350826353534213, 0.19830430851935843, 0.4958507259160506, 0.9963053375206881, 0.30222983203827203, 0.33916800140717074, 0.8396065532299206, 0.5563164279547956, 0.2960398448926189, 0.6031800576413024, 0.16801003740792453, 0.48808499769050673]}}
{"id": "48be7d0b-c263-46aa-b7bb-9ffb970d1fb8", "fitness": 0.6963393323111304, "name": "HybridSADE", "description": "Simplified hybrid PSO-DE with self-adaptive F, CR, and velocity clamping based on bounds, focusing on exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridSADE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.5, c2=1.5, w_start=0.9, w_end=0.4):\n        \"\"\"\n        Initialize the Hybrid SADE Optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The number of particles in the population.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            w_start (float): Initial inertia weight.\n            w_end (float): Final inertia weight.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.w_start = w_start\n        self.w_end = w_end\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update(self, func, current_eval):\n        \"\"\"\n        Combined PSO and DE update.\n        \"\"\"\n        # Dynamic inertia weight\n        inertia_weight = self.w_start - (self.w_start - self.w_end) * (current_eval / self.budget)\n        v_max = 0.2 * (func.bounds.ub - func.bounds.lb)\n\n        for i in range(self.pop_size):\n            # PSO Velocity Update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = (inertia_weight * self.velocities[i] +\n                        self.c1 * r1 * (self.global_best_position - self.pop[i]) +\n                        self.c2 * r2 * (self.pop[np.random.randint(self.pop_size)] - self.pop[i]))\n\n            # Simplified Velocity Clamping\n            velocity = np.clip(velocity, -v_max, v_max)\n            trial_position = self.pop[i] + velocity\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n\n            # Self-adaptive DE parameters\n            F = np.random.normal(0.5, 0.3)\n            F = np.clip(F, 0.1, 1.0)\n            CR = np.random.normal(0.9, 0.2)\n            CR = np.clip(CR, 0.1, 1.0)\n\n            # DE Mutation & Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            mutant = x_r1 + F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            trial_vector = np.array([mutant[j] if np.random.rand() < CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # Greedy Selection\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n\n            self.velocities[i] = velocity # update velocity\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n        current_eval = self.pop_size\n\n        while current_eval < self.budget:\n            self.update(func, current_eval)\n            current_eval = self.eval_count\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm HybridSADE scored 0.696 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["99cbee48-a3fd-4d08-92f0-cc790358e20c"], "operator": null, "metadata": {"aucs": [0.22298068538326754, 0.3758132326731287, 0.8050889049369321, 0.9306383116177986, 0.7952205003593891, 0.8685005304071984, 0.7872819586292868, 0.5357347939935685, 0.8727985352014782, 0.23929611628400793, 0.8900306420997035, 0.9999114001051959, 0.4228055799465352, 0.8694534955005053, 0.9273330117006873, 0.8687973628725542, 0.7849909336187078, 0.8981145433181759, 0.33184076970526966, 0.5001553378692165]}}
{"id": "987815da-65a0-4cf5-bfd9-005dfb8feaed", "fitness": 0.7706538011696333, "name": "AdaptiveDEOrthogonal", "description": "Adaptive Differential Evolution with orthogonal crossover to enhance diversity and convergence speed.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonal:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.adaptation_rate = adaptation_rate\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.success_F = []\n        self.success_CR = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutation(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        return x_r1 + self.F * (x_r2 - x_r3)\n\n    def orthogonal_crossover(self, v_i, i):\n        # Orthogonal Crossover: Create an orthogonal array\n        u_i = self.pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.CR:\n                u_i[j] = v_i[j]\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            delta_fitness = self.fitness[i] - f_u_i\n            self.success_F.append(self.F)\n            self.success_CR.append(self.CR)\n\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n        \n\n    def update_parameters(self):\n        if self.success_F:\n            self.F = np.mean(self.success_F)\n            self.CR = np.mean(self.success_CR)\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.CR = np.clip(self.CR, 0.1, 0.9)\n        self.success_F = []\n        self.success_CR = []\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutation(i)\n                v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n                u_i = self.orthogonal_crossover(v_i, i)\n                u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)\n                \n                self.selection(func, u_i, i)\n            self.update_parameters()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDEOrthogonal scored 0.771 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8152f1a6-84bb-41f5-8dc9-c78aa420f843"], "operator": null, "metadata": {"aucs": [0.4695852345613025, 0.8628319265877532, 0.5098329356211051, 0.9386255956875236, 0.8079938149093282, 0.9064872544909941, 0.8436163349480355, 0.8645207171093515, 0.8686077892997808, 0.2261551239808629, 0.9403994330397124, 0.9964299854100881, 0.43946957851576895, 0.8930481317161801, 0.9611487781784083, 0.8973594779447482, 0.8543978361827271, 0.9463789007286157, 0.6967994898642288, 0.48938768461615134]}}
{"id": "b22db253-d625-4433-9531-bf25babe9ef7", "fitness": 0.6068718758535993, "name": "HybridSADE", "description": "Combines PSO and DE with a decaying inertia weight and self-adaptive CR for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridSADE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.5, c2=1.5, F=0.5, CR=0.9, CR_decay=0.99):\n        \"\"\"\n        Initialize the Hybrid SADE Optimizer.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.CR_decay = CR_decay # Decay factor for CR\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.inertia_weight = 0.7\n        self.inertia_decay = 0.995 # Decay factor for inertia weight\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.zeros((self.pop_size, self.dim))  # Initialize velocities to zero\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update(self, func):\n        \"\"\"\n        Combined PSO and DE update.\n        \"\"\"\n        # Calculate population spread for adaptive velocity clamping\n        pop_mean = np.mean(self.pop, axis=0)\n        pop_std = np.std(self.pop, axis=0)\n        v_max = pop_std # Clamp based on population standard deviation\n\n        for i in range(self.pop_size):\n            # PSO Velocity Update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = (self.inertia_weight * self.velocities[i] +\n                        self.c1 * r1 * (self.global_best_position - self.pop[i]) +\n                        self.c2 * r2 * (self.pop[np.random.randint(self.pop_size)] - self.pop[i]))\n\n            # Velocity Clamping\n            velocity = np.clip(velocity, -v_max, v_max)\n            trial_position = self.pop[i] + velocity\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n\n            # DE Mutation & Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            mutant = x_r1 + self.F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            # Self-adaptive CR\n            current_CR = self.CR * np.random.uniform(0.5, 1.5)  # Introduce some randomness in CR\n            current_CR = np.clip(current_CR, 0, 1) # Keep CR within [0,1]\n            trial_vector = np.array([mutant[j] if np.random.rand() < current_CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # Greedy Selection\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n\n            self.velocities[i] = velocity # update the velocity regardless of acceptance\n        \n        # Decay inertia weight and CR\n        self.inertia_weight *= self.inertia_decay\n        self.CR *= self.CR_decay\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm HybridSADE scored 0.607 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["74c014bf-d354-43bf-999e-39fe6b6afbac"], "operator": null, "metadata": {"aucs": [0.3255429805021035, 0.8652428753293516, 0.459426901152605, 0.9485246911409081, 0.7592312730496803, 0.7283501214699958, 0.37133805338948955, 0.3969798517937104, 0.5472951565555818, 0.2700277909160749, 0.3896142367903208, 0.9968666910341818, 0.3863773310970129, 0.4863769118690444, 0.7875569535654788, 0.9399561441146761, 0.5438924725757783, 0.9481383084348061, 0.4861852589384865, 0.5005135133526986]}}
{"id": "cb88f4bf-374b-4e27-8d04-acacc8982f53", "fitness": -Infinity, "name": "AdaptiveHybridPSODECO", "description": "Adaptive hybrid PSO-DE with orthogonal learning and a Cauchy mutation operator for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODECO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, omega=0.5, learning_rate=0.1):\n        \"\"\"\n        Initialize the Adaptive Hybrid PSO-DE Optimizer with Orthogonal Learning and Cauchy Mutation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.omega = omega  # Inertia weight for PSO\n        self.learning_rate = learning_rate # Learning rate for velocity updates\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) # Initialize velocities\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def cauchy_mutation(self, x, scale=0.1):\n         \"\"\"Apply Cauchy mutation to a vector.\"\"\"\n         return x + scale * np.random.standard_cauchy(size=x.shape)\n\n    def orthogonal_learning(self, func, position):\n        \"\"\"Perform orthogonal learning to generate a better candidate.\"\"\"\n        levels = 5  # Number of levels for orthogonal design\n        basis = np.linspace(func.bounds.lb, func.bounds.ub, levels)\n        orthogonal_matrix = self.generate_orthogonal_array(self.dim, levels)\n        candidates = np.zeros((levels, self.dim))\n\n        for i in range(levels):\n            candidates[i] = np.array([basis[orthogonal_matrix[i, j]] for j in range(self.dim)])\n            \n        fitness_values = np.array([func(x) for x in candidates])\n        best_index = np.argmin(fitness_values)\n        self.eval_count += levels\n        return candidates[best_index], fitness_values[best_index]\n\n    def generate_orthogonal_array(self, k, levels):\n        \"\"\"Generate an orthogonal array (simplified).\"\"\"\n        # This is a simplified version and might not be truly orthogonal for all k and levels.\n        # For a real implementation, use a library like pyDOE.\n        orthogonal_matrix = np.zeros((levels, k), dtype=int)\n        for j in range(k):\n            orthogonal_matrix[:, j] = np.arange(levels)\n            np.random.shuffle(orthogonal_matrix[:, j])\n        return orthogonal_matrix\n\n    def update(self, func):\n        \"\"\"\n        Combined PSO and DE update with Orthogonal Learning and Cauchy Mutation.\n        \"\"\"\n\n        for i in range(self.pop_size):\n            # PSO inspired Velocity Update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = (self.omega * self.velocities[i] +\n                        self.learning_rate * r1 * (self.global_best_position - self.pop[i]) +\n                        self.learning_rate * r2 * (self.pop[np.random.randint(self.pop_size)] - self.pop[i]))  # PSO with social component\n            self.velocities[i] = velocity\n            trial_position = self.pop[i] + velocity\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n            \n            # DE Mutation & Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            mutant = x_r1 + self.F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            trial_vector = np.array([mutant[j] if np.random.rand() < self.CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Cauchy Mutation\n            trial_vector = self.cauchy_mutation(trial_vector)\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Orthogonal Learning\n            orthogonal_candidate, orthogonal_fitness = self.orthogonal_learning(func, trial_vector)\n            \n            # Evaluation & Greedy Selection\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            if orthogonal_fitness < f_trial and orthogonal_fitness < self.fitness[i]:\n                f_trial = orthogonal_fitness\n                trial_vector = orthogonal_candidate\n            \n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "An exception occurred: could not broadcast input array from shape (2,2) into shape (2,).", "error": "", "parent_ids": ["45d62270-9ed6-4f46-aab2-b6ecc35384dc"], "operator": null, "metadata": {}}
{"id": "5c657245-d9a0-44ab-a660-116611fd7dd7", "fitness": -Infinity, "name": "EnhancedHybridSADE", "description": "Enhanced Hybrid SADE with adaptive population size, orthogonal learning, and a modified velocity update rule.", "code": "import numpy as np\n\nclass EnhancedHybridSADE:\n    def __init__(self, budget=10000, dim=10, pop_size_start=20, pop_size_end=5, c1=1.5, c2=1.5, w_start=0.9, w_end=0.4, ol_rate=0.1):\n        \"\"\"\n        Initialize the Enhanced Hybrid SADE Optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size_start (int): Initial population size.\n            pop_size_end (int): Final population size.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            w_start (float): Initial inertia weight.\n            w_end (float): Final inertia weight.\n            ol_rate (float): Orthogonal learning rate.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_start = pop_size_start\n        self.pop_size_end = pop_size_end\n        self.c1 = c1\n        self.c2 = c2\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.w_start = w_start\n        self.w_end = w_end\n        self.ol_rate = ol_rate\n\n    def get_pop_size(self, current_eval):\n        \"\"\"\n        Adaptive population size.\n        \"\"\"\n        return int(self.pop_size_start + (self.pop_size_end - self.pop_size_start) * (current_eval / self.budget))\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        pop_size = self.get_pop_size(0)\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += pop_size\n        self.velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(pop_size, self.dim))\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def orthogonal_learning(self, func, x):\n        \"\"\"\n        Orthogonal learning strategy to generate candidate solutions.\n        \"\"\"\n        level_num = int(np.sqrt(self.dim))\n        level_set = np.linspace(func.bounds.lb, func.bounds.ub, level_num)\n        basis = self.generate_orthogonal_basis(level_num)\n        candidates = np.zeros((level_num, self.dim))\n\n        for i in range(self.dim):\n            idx = np.floor((x[i] - func.bounds.lb) / (func.bounds.ub - func.bounds.lb) * (level_num - 1)).astype(int)\n            candidates[:, i] = level_set[((basis[:, i] + idx) % level_num)]\n\n        fitnesses = np.array([func(candidates[i]) for i in range(level_num)])\n        self.eval_count += level_num\n        best_index = np.argmin(fitnesses)\n        return candidates[best_index], fitnesses[best_index]\n\n    def generate_orthogonal_basis(self, level_num):\n        \"\"\"\n        Generate an orthogonal basis matrix.\n        \"\"\"\n        basis = np.zeros((level_num, level_num))\n        for i in range(level_num):\n            for j in range(level_num):\n                basis[i, j] = (i * j) % level_num\n        return basis\n\n    def update(self, func, current_eval):\n        \"\"\"\n        Combined PSO and DE update.\n        \"\"\"\n        pop_size = self.get_pop_size(current_eval)\n        if pop_size != self.pop.shape[0]:\n            # Resize population (simplified: keep the best, add random)\n            sorted_indices = np.argsort(self.fitness)\n            self.pop = self.pop[sorted_indices[:pop_size]]\n            self.fitness = self.fitness[sorted_indices[:pop_size]]\n            self.velocities = self.velocities[sorted_indices[:pop_size]]\n            \n            num_to_add = pop_size - self.pop.shape[0]\n            new_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_add, self.dim))\n            new_fitness = np.array([func(x) for x in new_pop])\n            self.eval_count += num_to_add\n            new_velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(num_to_add, self.dim))\n            \n            self.pop = np.concatenate((self.pop, new_pop), axis=0)\n            self.fitness = np.concatenate((self.fitness, new_fitness))\n            self.velocities = np.concatenate((self.velocities, new_velocities), axis=0)\n\n        # Dynamic inertia weight\n        inertia_weight = self.w_start - (self.w_start - self.w_end) * (current_eval / self.budget)\n        v_max = 0.2 * (func.bounds.ub - func.bounds.lb)\n\n        for i in range(pop_size):\n            # PSO Velocity Update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            \n            # Modified Velocity Update (using difference between current and global best)\n            velocity = (inertia_weight * self.velocities[i] +\n                        self.c1 * r1 * (self.global_best_position - self.pop[i]) +\n                        self.c2 * r2 * (self.pop[np.random.randint(pop_size)] - self.pop[i]))\n\n            # Simplified Velocity Clamping\n            velocity = np.clip(velocity, -v_max, v_max)\n            trial_position = self.pop[i] + velocity\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n\n            # Self-adaptive DE parameters\n            F = np.random.normal(0.5, 0.3)\n            F = np.clip(F, 0.1, 1.0)\n            CR = np.random.normal(0.9, 0.2)\n            CR = np.clip(CR, 0.1, 1.0)\n\n            # DE Mutation & Crossover\n            idxs = np.random.choice(pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            mutant = x_r1 + F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            trial_vector = np.array([mutant[j] if np.random.rand() < CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Orthogonal Learning\n            if np.random.rand() < self.ol_rate:\n                trial_vector, f_trial = self.orthogonal_learning(func, trial_vector)\n            else:\n                f_trial = func(trial_vector)\n                self.eval_count += 1\n\n            # Greedy Selection\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n\n            self.velocities[i] = velocity # update velocity\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n        current_eval = self.eval_count\n\n        while current_eval < self.budget:\n            self.update(func, current_eval)\n            current_eval = self.eval_count\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "An exception occurred: arrays used as indices must be of integer (or boolean) type.", "error": "", "parent_ids": ["48be7d0b-c263-46aa-b7bb-9ffb970d1fb8"], "operator": null, "metadata": {}}
{"id": "ff686142-d2bc-48df-94ad-1853f0d7515d", "fitness": -Infinity, "name": "AdaptiveCMAES", "description": "Implements a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) variant with a dynamically adjusted step size and restarts to escape local optima, enhancing exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=1.0, restart_strategy=\"IPOP\"):\n        \"\"\"\n        Initialize the Adaptive CMA-ES optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size. If None, it's set to 4 + int(3 * np.log(dim)).\n            initial_step_size (float): Initial step size for the covariance matrix adaptation.\n            restart_strategy (str): Strategy for restarting the algorithm (\"IPOP\" for Increasing Population Size, None for no restart).\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_step_size = initial_step_size\n        self.restart_strategy = restart_strategy\n        self.mu = self.pop_size // 2  # Number of parents\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_m = 1  # Learning rate for the mean\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)  # Learning rate for step size\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)  # Learning rate for covariance matrix\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma  # Damping for step size\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_x = None\n        self.mean = None\n        self.sigma = None\n        self.C = None\n        self.pc = None\n        self.psigma = None\n        self.D = None\n        self.B = None\n        self.lb = None\n        self.ub = None\n        self.generation = 0\n        self.restart_factor = 2  # Factor by which to increase pop size on restart\n        self.original_pop_size = self.pop_size # Store initial pop size for restarts\n\n\n    def initialize(self, func):\n        \"\"\"\n        Initialize the CMA-ES parameters.\n        \"\"\"\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.sigma = self.initial_step_size\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.psigma = np.zeros(self.dim)  # Evolution path for sigma\n        self.D = np.ones(self.dim)  # Eigenvalues of C\n        self.B = np.eye(self.dim)  # Eigenvectors of C\n\n    def sample_population(self):\n        \"\"\"\n        Sample a new population from the multivariate normal distribution.\n        \"\"\"\n        z = np.random.randn(self.pop_size, self.dim)\n        y = self.sigma * (self.B @ (self.D * z.T)).T\n        x = self.mean + y\n        x = np.clip(x, self.lb, self.ub)\n        return x\n\n    def update(self, func, x):\n        \"\"\"\n        Update the CMA-ES parameters based on the evaluated population.\n        \"\"\"\n        fitness_values = np.array([func(xi) for xi in x])\n        self.eval_count += self.pop_size\n\n        if np.min(fitness_values) < self.best_fitness:\n            self.best_fitness = np.min(fitness_values)\n            self.best_x = x[np.argmin(fitness_values)].copy()\n\n        idx = np.argsort(fitness_values)\n        x_sorted = x[idx]\n\n        # Selection and recombination\n        y = (x_sorted[:self.mu] - self.mean) / self.sigma\n        mean_diff = np.sum(self.weights[:, None] * y, axis=0)\n\n        # Update evolution paths\n        self.psigma = (1 - self.c_sigma) * self.psigma + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (self.B @ mean_diff)\n        hsig = np.linalg.norm(self.psigma) / np.sqrt(1 - (1 - self.c_sigma)**(2 * (self.eval_count // self.pop_size))) / 1.4 > 2 + 4 / (self.dim + 1)\n        self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * mean_diff\n\n        # Update covariance matrix\n        artmp = (x_sorted[:self.mu] - self.mean) / self.sigma\n        self.C = (1 - self.c_c) * self.C + self.c_c * (self.pc[:, None] @ self.pc[None, :]) + self.c_c * (1 - hsig) * self.C  + self.c_c * np.sum([self.weights[i] * (artmp[i][:, None] @ artmp[i][None, :]) for i in range(self.mu)], axis=0)\n\n        # Adapt step size\n        self.sigma *= np.exp((self.c_sigma / self.damps) * (np.linalg.norm(self.psigma) / np.sqrt(self.dim) - 1))\n        self.sigma = max(self.sigma, 1e-10) # prevent sigma from becoming too small\n\n        # Update mean\n        self.mean += self.c_m * self.sigma * mean_diff\n\n        # Eigen-decomposition of C\n        try:\n             self.D, self.B = np.linalg.eigh(self.C)\n             self.D = np.sqrt(np.abs(self.D))\n        except np.linalg.LinAlgError:\n            # Reset covariance matrix if it becomes ill-conditioned\n            self.C = np.eye(self.dim)\n            self.D = np.ones(self.dim)\n            self.B = np.eye(self.dim)\n            self.pc = np.zeros(self.dim)\n\n    def restart(self, func):\n        \"\"\"\n        Restart the algorithm with a larger population size and re-initialize parameters.\n        \"\"\"\n        if self.restart_strategy == \"IPOP\":\n            self.pop_size = int(self.original_pop_size * self.restart_factor) # Increase population size\n            self.mu = self.pop_size // 2\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights /= np.sum(self.weights)\n            self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n            self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n            self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n            self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n            self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n            self.sigma = self.initial_step_size\n            self.C = np.eye(self.dim)  # Covariance matrix\n            self.pc = np.zeros(self.dim)  # Evolution path for C\n            self.psigma = np.zeros(self.dim)  # Evolution path for sigma\n            self.D = np.ones(self.dim)  # Eigenvalues of C\n            self.B = np.eye(self.dim)  # Eigenvectors of C\n            self.restart_factor *= 2  # Increase the restart factor for the next restart\n            print(f\"Restarting with pop size: {self.pop_size}\") # debugging purpose\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function using CMA-ES.\n        \"\"\"\n        self.initialize(func)\n        self.generation = 0\n\n        while self.eval_count < self.budget:\n            x = self.sample_population()\n            self.update(func, x)\n            self.generation += 1\n\n            # Restart strategy: Increase population size\n            if self.restart_strategy == \"IPOP\" and self.eval_count + self.pop_size < self.budget and self.generation % 50 == 0: # restart every 50 generations\n                self.restart(func)\n\n        return self.best_fitness, self.best_x", "configspace": "", "generation": 7, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,) (2,6) .", "error": "", "parent_ids": ["48be7d0b-c263-46aa-b7bb-9ffb970d1fb8"], "operator": null, "metadata": {}}
{"id": "bb870e7d-c317-4277-8644-5495fa85d782", "fitness": 0.7262929747224239, "name": "AdaptiveDEOrthogonal", "description": "Simplified Adaptive Differential Evolution with orthogonal crossover and reduced parameter tuning.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonal:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutation(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        return x_r1 + self.F * (x_r2 - x_r3)\n\n    def orthogonal_crossover(self, v_i, i):\n        u_i = self.pop[i].copy()\n        crossover_points = np.random.rand(self.dim) < self.CR\n        u_i[crossover_points] = v_i[crossover_points]\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutation(i)\n                v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n                u_i = self.orthogonal_crossover(v_i, i)\n                u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)\n                \n                self.selection(func, u_i, i)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDEOrthogonal scored 0.726 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["987815da-65a0-4cf5-bfd9-005dfb8feaed"], "operator": null, "metadata": {"aucs": [0.5494548531949253, 0.898476914968034, 0.6428379372207436, 0.8957812726982399, 0.2771974429160057, 0.9088361594526294, 0.8456250805931735, 0.8712312528784212, 0.7904616599874025, 0.4677505366414587, 0.9463714263752145, 0.9979046083998975, 0.2520861771140491, 0.4869106248694727, 0.9542062450104949, 0.9085023297097644, 0.5871478223768591, 0.923639964886757, 0.8176937854538429, 0.5037433997010932]}}
{"id": "f308851b-34f6-42a2-8ce9-4ebb0aed553b", "fitness": 0.7288131737431011, "name": "AdaptiveDEOrthogonalCauchy", "description": "Adaptive Differential Evolution with improved parameter adaptation using a weighted average of successful parameters and incorporating a Cauchy mutation operator for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonalCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, adaptation_rate=0.1, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.adaptation_rate = adaptation_rate\n        self.cauchy_scale = cauchy_scale\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.success_F = []\n        self.success_CR = []\n        self.memory_F = [F] * 10  # Memory for F values\n        self.memory_CR = [CR] * 10  # Memory for CR values\n        self.memory_idx = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutation(self, i, func):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        \n        # Cauchy mutation with a small probability\n        if np.random.rand() < 0.05:\n             mutation_vector = x_r1 + self.cauchy_scale * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        else:\n            mutation_vector = x_r1 + self.F * (x_r2 - x_r3)\n\n        mutation_vector = np.clip(mutation_vector, func.bounds.lb, func.bounds.ub)\n        return mutation_vector\n\n    def orthogonal_crossover(self, v_i, i):\n        u_i = self.pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.CR:\n                u_i[j] = v_i[j]\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            delta_fitness = self.fitness[i] - f_u_i\n            self.success_F.append(self.F)\n            self.success_CR.append(self.CR)\n\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n        \n\n    def update_parameters(self):\n        # Update F and CR using a weighted average of past successful values\n        if self.success_F:\n            mean_F = np.mean(self.success_F)\n            mean_CR = np.mean(self.success_CR)\n\n            # Update memory with successful values\n            self.memory_F[self.memory_idx] = mean_F\n            self.memory_CR[self.memory_idx] = mean_CR\n            self.memory_idx = (self.memory_idx + 1) % len(self.memory_F)\n\n            # Calculate weighted average\n            self.F = 0.8 * self.F + 0.2 * np.mean(self.memory_F)\n            self.CR = 0.8 * self.CR + 0.2 * np.mean(self.memory_CR)\n\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.CR = np.clip(self.CR, 0.1, 0.9)\n        self.success_F = []\n        self.success_CR = []\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutation(i, func)\n\n                u_i = self.orthogonal_crossover(v_i, i)\n                u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)\n                \n                self.selection(func, u_i, i)\n            self.update_parameters()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDEOrthogonalCauchy scored 0.729 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["987815da-65a0-4cf5-bfd9-005dfb8feaed"], "operator": null, "metadata": {"aucs": [0.44423838315644815, 0.2233192374881009, 0.7332829613625627, 0.9569955353513908, 0.880057101809864, 0.9109056077554588, 0.840382013119251, 0.5207316875202999, 0.8822329362346077, 0.858124577404987, 0.9177379304339884, 0.9938473548757243, 0.2800946105418881, 0.8631455438765363, 0.8077405336672764, 0.9142483901599135, 0.7680743165290334, 0.92033159273179, 0.3398833859026874, 0.5208897749402127]}}
{"id": "3851edf9-6d28-46cf-b331-be9a5dcb85e5", "fitness": 0.401239515472923, "name": "HybridSADE", "description": "Simplified Hybrid PSO-DE with adaptive velocity scaling and reduced DE operations for efficient exploration.", "code": "import numpy as np\n\nclass HybridSADE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        \"\"\"\n        Initialize the Hybrid SADE Optimizer.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.zeros((self.pop_size, self.dim))\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update(self, func):\n        \"\"\"\n        Combined PSO and DE update.\n        \"\"\"\n        # Population spread for velocity scaling\n        velocity_scale = np.std(self.pop, axis=0)\n\n        for i in range(self.pop_size):\n            # PSO-inspired Velocity Update\n            r1 = np.random.rand(self.dim)\n            velocity = (self.velocities[i] +\n                        r1 * (self.global_best_position - self.pop[i])) # Simplified PSO\n\n            # Velocity Scaling\n            velocity = velocity * velocity_scale\n            trial_position = self.pop[i] + velocity\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n\n            # DE Mutation & Crossover - Reduced DE operations\n            if np.random.rand() < self.CR:\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial_position = mutant  # Overwrite trial position with DE result\n\n            # Evaluation\n            f_trial = func(trial_position)\n            self.eval_count += 1\n\n            # Greedy Selection\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_position.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_position.copy()\n\n            self.velocities[i] = velocity # Update velocity\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm HybridSADE scored 0.401 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["45d62270-9ed6-4f46-aab2-b6ecc35384dc"], "operator": null, "metadata": {"aucs": [0.22855880347685165, 0.582409530874186, 0.4248778499642196, 0.2463276732362253, 0.2638073361767388, 0.3912729185957673, 0.369989815662107, 0.4560337154662152, 0.2013756559811345, 0.23542069513068153, 0.2025038856050162, 0.9979679950676242, 0.39080052261506815, 0.4649937242415091, 0.7572990530122772, 0.3747594156310696, 0.3203171559769741, 0.41455723578404835, 0.23148759273667852, 0.47002973422406724]}}
{"id": "c8e53083-a6c0-49bb-922a-ba660fc0ce9b", "fitness": 0.5886525296033449, "name": "AdaptiveDEOrthogonalArchive", "description": "Adaptive Differential Evolution with orthogonal crossover and Archive to enhance diversity, convergence speed and escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonalArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10, F=0.5, CR=0.9, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = F\n        self.CR = CR\n        self.adaptation_rate = adaptation_rate\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.success_F = []\n        self.success_CR = []\n        self.archive = []  # Archive to store inferior solutions\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutation(self, i, func):\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        x_r1, x_r2 = self.pop[idxs]\n        \n        # Select x_r3 from the population or the archive\n        if len(self.archive) > 0 and np.random.rand() < 0.1:  # 10% chance to pick from archive\n            idx_archive = np.random.randint(len(self.archive))\n            x_r3 = self.archive[idx_archive]\n        else:\n            idx_pop = np.random.choice(self.pop_size, 1, replace=False)[0]  # Ensure it's a different index\n            x_r3 = self.pop[idx_pop]\n            while idx_pop == i or idx_pop in idxs:\n                 idx_pop = np.random.choice(self.pop_size, 1, replace=False)[0]\n                 x_r3 = self.pop[idx_pop]\n        \n        v_i = self.pop[i] + self.F * (x_r1 - x_r2)\n        return v_i\n\n    def orthogonal_crossover(self, v_i, i):\n        u_i = self.pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.CR:\n                u_i[j] = v_i[j]\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            delta_fitness = self.fitness[i] - f_u_i\n            self.success_F.append(self.F)\n            self.success_CR.append(self.CR)\n\n            # Update population\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n        else:\n            # Add the replaced individual to the archive (with probability)\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.pop[i].copy())\n            else:\n                if np.random.rand() < 0.2:  # Replace a random element in the archive with the replaced individual (20% chance)\n                    idx_replace = np.random.randint(self.archive_size)\n                    self.archive[idx_replace] = self.pop[i].copy()\n\n    def update_parameters(self):\n        if self.success_F:\n            self.F = np.mean(self.success_F)\n            self.CR = np.mean(self.success_CR)\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.CR = np.clip(self.CR, 0.1, 0.9)\n        self.success_F = []\n        self.success_CR = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutation(i, func)\n                v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n                u_i = self.orthogonal_crossover(v_i, i)\n                u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)\n                \n                self.selection(func, u_i, i)\n            self.update_parameters()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDEOrthogonalArchive scored 0.589 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["987815da-65a0-4cf5-bfd9-005dfb8feaed"], "operator": null, "metadata": {"aucs": [0.18888070967743675, 0.47044820429913436, 0.594178321299982, 0.8216920008312859, 0.5809601579632382, 0.7260881153586513, 0.350790218543681, 0.5359883440796738, 0.6615809406702584, 0.20470715581503007, 0.8904115609475869, 0.999653101518692, 0.6258325075961018, 0.5295919348221332, 0.8937787878918823, 0.6873081170471182, 0.48825881606991894, 0.8162546366103222, 0.19861420791619988, 0.5080327531085685]}}
{"id": "ee11a54b-4c6d-4268-9de2-c4aafabee3ee", "fitness": 0.735783512201384, "name": "HybridSADE", "description": "Simplified Hybrid PSO-DE with adaptive CR and F, velocity clamping, and reduced parameter count for better exploration and exploitation.", "code": "import numpy as np\n\nclass HybridSADE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        \"\"\"\n        Initialize the Hybrid SADE Optimizer.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.CR = 0.9\n        self.inertia_weight = 0.7\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.zeros((self.pop_size, self.dim))\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update(self, func):\n        \"\"\"\n        Combined PSO and DE update with adaptive parameters.\n        \"\"\"\n        v_max = 0.1 * (func.bounds.ub - func.bounds.lb) # Clamp based on problem bounds\n        \n        for i in range(self.pop_size):\n            # PSO Velocity Update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = (self.inertia_weight * self.velocities[i] +\n                        1.5 * r1 * (self.global_best_position - self.pop[i]) +\n                        1.5 * r2 * (self.pop[np.random.randint(self.pop_size)] - self.pop[i])) #Simplified c1 and c2\n\n            # Velocity Clamping\n            velocity = np.clip(velocity, -v_max, v_max)\n            trial_position = self.pop[i] + velocity\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n\n            # DE Mutation & Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            mutant = x_r1 + self.F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            # Adaptive CR\n            current_CR = self.CR * np.random.uniform(0.5, 1.5)\n            current_CR = np.clip(current_CR, 0, 1)\n            trial_vector = np.array([mutant[j] if np.random.rand() < current_CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # Greedy Selection\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n\n            self.velocities[i] = velocity # update the velocity regardless of acceptance\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm HybridSADE scored 0.736 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b22db253-d625-4433-9531-bf25babe9ef7"], "operator": null, "metadata": {"aucs": [0.4459368642160617, 0.41268984767718064, 0.8147103554963155, 0.1723863521587169, 0.879510719284121, 0.8922972819082766, 0.8086699508585108, 0.5449313427016764, 0.8836920421716814, 0.8437491316000938, 0.9470250070696319, 0.9969126424221094, 0.3479656539185203, 0.8698358889763981, 0.9376358835055463, 0.856006728369432, 0.8168920307575137, 0.9270880927460239, 0.7974476261405227, 0.5202868020493481]}}
{"id": "c48e7c0f-bdc7-45b3-84b4-e77ce53d689c", "fitness": 0.6586820742096373, "name": "HybridSADE", "description": "Combines PSO and DE with adaptive parameter control using rank-based selection and population diversity measure.", "code": "import numpy as np\n\nclass HybridSADE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.5, c2=1.5, F=0.5, CR=0.9):\n        \"\"\"\n        Initialize the Hybrid SADE Optimizer.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.inertia_weight = 0.7\n        self.archive = [] # Archive for storing potentially good solutions.\n        self.archive_size = pop_size # Size of the archive\n        self.success_F = []\n        self.success_CR = []\n        self.memory_size = 10 # Memory size for storing successful F and CR values\n        self.memory_F = np.full(self.memory_size, self.F)\n        self.memory_CR = np.full(self.memory_size, self.CR)\n        self.memory_index = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.zeros((self.pop_size, self.dim))  # Initialize velocities to zero\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update(self, func):\n        \"\"\"\n        Combined PSO and DE update with rank-based adaptation.\n        \"\"\"\n\n        # Rank the population based on fitness\n        ranked_indices = np.argsort(self.fitness)\n        ranked_pop = self.pop[ranked_indices]\n\n        # Calculate population spread for adaptive velocity clamping\n        pop_mean = np.mean(self.pop, axis=0)\n        pop_std = np.std(self.pop, axis=0)\n        v_max = pop_std  # Clamp based on population standard deviation\n\n\n        for i in range(self.pop_size):\n\n            # Adaptive F and CR based on memory\n            self.F = np.random.choice(self.memory_F) if self.success_F else 0.5 # if no succesful F values in memory use default\n            self.CR = np.random.choice(self.memory_CR) if self.success_CR else 0.9\n\n            # PSO Velocity Update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = (self.inertia_weight * self.velocities[i] +\n                        self.c1 * r1 * (self.global_best_position - self.pop[i]) +\n                        self.c2 * r2 * (ranked_pop[np.random.randint(self.pop_size // 4)] - self.pop[i])) # guide by top 25%\n\n            # Velocity Clamping\n            velocity = np.clip(velocity, -v_max, v_max)\n            trial_position = self.pop[i] + velocity\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n\n            # DE Mutation & Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            mutant = x_r1 + self.F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            trial_vector = np.array([mutant[j] if np.random.rand() < self.CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # Greedy Selection and Archive Update\n            if f_trial < self.fitness[i]:\n                delta_fitness = abs(f_trial - self.fitness[i]) # track the improvement\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                # store succesful CR and F values\n                self.success_CR.append(self.CR)\n                self.success_F.append(self.F)\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n\n            self.velocities[i] = velocity # update the velocity regardless of acceptance\n\n        # Update memory of successful CR and F values\n        if self.success_CR:\n            self.memory_CR[self.memory_index] = np.mean(self.success_CR)\n            self.memory_F[self.memory_index] = np.mean(self.success_F)\n            self.memory_index = (self.memory_index + 1) % self.memory_size\n\n        self.success_CR = [] # Reset successful values for next generation\n        self.success_F = []\n        # Decay inertia weight\n        self.inertia_weight *= 0.995\n\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm HybridSADE scored 0.659 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b22db253-d625-4433-9531-bf25babe9ef7"], "operator": null, "metadata": {"aucs": [0.2569841052942877, 0.24487197601294575, 0.400031917628174, 0.9553039156319738, 0.890472380950849, 0.7156601683071804, 0.8779146052436944, 0.8942124495115713, 0.8049438657860295, 0.9004752844099753, 0.8948479886573925, 0.9976663139655102, 0.39403705885575824, 0.38342386569308695, 0.7965140327543666, 0.4784481019225647, 0.3680709971456557, 0.6261536137520387, 0.767206557184283, 0.5264022854854087]}}
{"id": "bfc1aef0-c078-44c7-92f0-b872eed66abe", "fitness": 0.6003944133027781, "name": "HybridSADE", "description": "Combines PSO and DE with self-adaptive parameters and a memory-based mechanism to enhance exploration and exploitation capabilities.", "code": "import numpy as np\n\nclass HybridSADE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.5, c2=1.5, F=0.5, CR=0.9, CR_decay=0.99, memory_size=5):\n        \"\"\"\n        Initialize the Hybrid SADE Optimizer.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.CR_decay = CR_decay # Decay factor for CR\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.inertia_weight = 0.7\n        self.inertia_decay = 0.995 # Decay factor for inertia weight\n        self.memory_size = memory_size\n        self.CR_memory = np.ones(memory_size) * CR  # Initialize CR memory\n        self.F_memory = np.ones(memory_size) * F  # Initialize F memory\n        self.memory_index = 0\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.zeros((self.pop_size, self.dim))  # Initialize velocities to zero\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update(self, func):\n        \"\"\"\n        Combined PSO and DE update.\n        \"\"\"\n        # Calculate population spread for adaptive velocity clamping\n        pop_mean = np.mean(self.pop, axis=0)\n        pop_std = np.std(self.pop, axis=0)\n        v_max = pop_std # Clamp based on population standard deviation\n\n        for i in range(self.pop_size):\n            # PSO Velocity Update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = (self.inertia_weight * self.velocities[i] +\n                        self.c1 * r1 * (self.global_best_position - self.pop[i]) +\n                        self.c2 * r2 * (self.pop[np.random.randint(self.pop_size)] - self.pop[i]))\n\n            # Velocity Clamping\n            velocity = np.clip(velocity, -v_max, v_max)\n            trial_position = self.pop[i] + velocity\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n\n            # DE Mutation & Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Adaptive F: Sample from memory with roulette wheel selection\n            probabilities = self.F_memory / np.sum(self.F_memory)\n            selected_memory_index = np.random.choice(self.memory_size, p=probabilities)\n            current_F = self.F_memory[selected_memory_index] + 0.001 * np.random.randn()\n            current_F = np.clip(current_F, 0.1, 1.0)\n            \n            mutant = x_r1 + current_F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            # Self-adaptive CR: Sample from memory and add noise\n            probabilities = self.CR_memory / np.sum(self.CR_memory)\n            selected_memory_index = np.random.choice(self.memory_size, p=probabilities)\n            current_CR = self.CR_memory[selected_memory_index] + 0.1 * np.random.randn()\n            current_CR = np.clip(current_CR, 0, 1)\n            \n            trial_vector = np.array([mutant[j] if np.random.rand() < current_CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # Greedy Selection\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n                    \n                    # Update memory with successful CR and F values\n                    self.CR_memory[self.memory_index] = current_CR\n                    self.F_memory[self.memory_index] = current_F\n                    self.memory_index = (self.memory_index + 1) % self.memory_size\n\n            self.velocities[i] = velocity # update the velocity regardless of acceptance\n        \n        # Decay inertia weight\n        self.inertia_weight *= self.inertia_decay\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm HybridSADE scored 0.600 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b22db253-d625-4433-9531-bf25babe9ef7"], "operator": null, "metadata": {"aucs": [0.16300638687163083, 0.9063254599144425, 0.5944882625093338, 0.32444565653833213, 0.5659243409846009, 0.9300669594172456, 0.8875495651970204, 0.2604164479425566, 0.914422345217033, 0.8638442819202932, 0.9517016251032481, 0.9995881629029766, 0.353561661622802, 0.594571674447911, 0.7602254609940008, 0.30567306684600126, 0.2845819159563311, 0.5725858491975364, 0.27683469263381244, 0.49807444983845517]}}
{"id": "f799bbf0-1fd2-42b9-abf8-ee51ef53db3f", "fitness": 0.7051602609472243, "name": "AdaptiveDECauchyRank", "description": "An adaptive Differential Evolution strategy employing a Cauchy mutation operator and a rank-based selection scheme to improve exploration and convergence.", "code": "import numpy as np\n\nclass AdaptiveDECauchyRank:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.adaptation_rate = adaptation_rate\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.archive = [] # Archive for storing discarded solutions\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def cauchy_mutation(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        cauchy_sample = np.random.standard_cauchy(size=self.dim)\n        return x_r1 + self.F * cauchy_sample * (x_r2 - x_r3)\n\n    def crossover(self, v_i, i):\n        u_i = self.pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.CR:\n                u_i[j] = v_i[j]\n        return u_i\n\n    def rank_based_selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            # Replace the individual with the trial vector if it's better\n            self.archive.append(self.pop[i].copy()) # Store the discarded solution\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n        else:\n            # Trial vector is not better, store it in the archive with a small probability\n            if np.random.rand() < 0.1:\n                self.archive.append(u_i.copy())\n\n    def update_parameters(self):\n        # Adaptive F and CR\n        self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 0.9)\n        self.CR = np.clip(np.random.normal(0.9, 0.1), 0.1, 0.9)\n\n        # Archive handling (optional): Keep archive size limited\n        if len(self.archive) > self.pop_size * 2:\n            self.archive = self.archive[-self.pop_size*2:]\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.cauchy_mutation(i)\n                v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n                u_i = self.crossover(v_i, i)\n                u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)\n                \n                self.rank_based_selection(func, u_i, i)\n            self.update_parameters()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDECauchyRank scored 0.705 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["987815da-65a0-4cf5-bfd9-005dfb8feaed"], "operator": null, "metadata": {"aucs": [0.20147260359476826, 0.7190072483585566, 0.7018539271891555, 0.8806846597567927, 0.7844429266882651, 0.8285327815321295, 0.6585520902371985, 0.6949069079218613, 0.7768232385284457, 0.7716989192272113, 0.7783394821075512, 0.9920190967249697, 0.2911465591888662, 0.7783245481954599, 0.8388116606850116, 0.8426562671407607, 0.56898135769837, 0.8299343542629944, 0.663285151977294, 0.5017314379288266]}}
{"id": "274f7c53-2d20-41ac-a4c2-7e6da9528d3d", "fitness": 0.2922385312011121, "name": "AdaptiveHybridPSODECauchy", "description": "An adaptive PSO-DE hybrid with a Cauchy mutation operator for enhanced exploration and a selection mechanism based on both fitness and diversity.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODECauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.5, c2=1.5, F=0.5, CR=0.9):\n        \"\"\"\n        Initialize the Adaptive Hybrid PSO-DE Optimizer with Cauchy mutation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.inertia_weight = 0.7\n        self.diversity_threshold = 0.01  # Threshold for population diversity\n        self.cauchy_scale = 0.1  # Scale parameter for Cauchy mutation\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and velocities.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.zeros((self.pop_size, self.dim))\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def cauchy_mutation(self, x):\n        \"\"\"\n        Apply Cauchy mutation to a vector.\n        \"\"\"\n        mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n        mutated_x = x + mutation\n        return mutated_x\n\n    def calculate_diversity(self):\n        \"\"\"\n        Calculate the diversity of the population (average distance from centroid).\n        \"\"\"\n        centroid = np.mean(self.pop, axis=0)\n        distances = np.linalg.norm(self.pop - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def update(self, func):\n        \"\"\"\n        Combined PSO and DE update with adaptive strategy and Cauchy mutation.\n        \"\"\"\n        diversity = self.calculate_diversity()\n\n        for i in range(self.pop_size):\n            # PSO Velocity Update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocity = (self.inertia_weight * self.velocities[i] +\n                        self.c1 * r1 * (self.global_best_position - self.pop[i]) +\n                        self.c2 * r2 * (self.pop[np.random.randint(self.pop_size)] - self.pop[i]))\n\n            trial_position = self.pop[i] + velocity\n            trial_position = np.clip(trial_position, func.bounds.lb, func.bounds.ub)\n\n            # DE Mutation & Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            mutant = x_r1 + self.F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            trial_vector = np.array([mutant[j] if np.random.rand() < self.CR or j == j_rand else trial_position[j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Apply Cauchy mutation if diversity is low\n            if diversity < self.diversity_threshold:\n                trial_vector = self.cauchy_mutation(trial_vector)\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # Selection based on fitness and diversity\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n            else:\n                # If the trial vector is not better, try to accept it with a probability\n                # proportional to the diversity.  This encourages exploration when the\n                # population is clustered together.\n                acceptance_prob = diversity\n                if np.random.rand() < acceptance_prob:\n                    self.pop[i] = trial_vector.copy()\n                    self.fitness[i] = f_trial\n\n            self.velocities[i] = velocity\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveHybridPSODECauchy scored 0.292 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b22db253-d625-4433-9531-bf25babe9ef7"], "operator": null, "metadata": {"aucs": [0.11431012031131904, 0.1642056626772015, 0.2678827911275754, 0.23404931605287138, 0.21747495967622177, 0.24677061455759208, 0.24864959392461627, 0.20107800855641278, 0.20724437690275999, 0.17713000133373902, 0.2685377140661419, 0.9971742374589865, 0.24312324538146524, 0.23615328607727848, 0.6286799479566552, 0.2789877772851337, 0.23083052536868798, 0.2676139357053897, 0.15475516708375636, 0.46011934251843756]}}
{"id": "c1c1bb2e-7aa3-48bc-b196-278e1cd652bd", "fitness": -Infinity, "name": "AdaptiveDEOrthogonalArchive", "description": "Adaptive Differential Evolution with orthogonal crossover, archive for promising solutions, and dynamic F/CR adaptation based on archive interactions.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonalArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10, F=0.5, CR=0.9, F_stepsize = 0.1, CR_stepsize = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = F\n        self.CR = CR\n        self.F_stepsize = F_stepsize\n        self.CR_stepsize = CR_stepsize\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.archive = []  # Store promising solutions\n        self.archive_fitness = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutation(self, i, func):\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        x_r1, x_r2 = self.pop[idxs]\n\n        # Use archive if available\n        if len(self.archive) > 0 and np.random.rand() < 0.1:  # 10% chance to use archive\n            idx_archive = np.random.randint(len(self.archive))\n            x_r3 = self.archive[idx_archive]\n        else:\n            idxs_pop = np.random.choice(self.pop_size, 1, replace=False)\n            x_r3 = self.pop[idxs_pop[0]]\n\n        F_adapted = np.clip(self.F + self.F_stepsize * np.random.randn(), 0.1, 1.0) # Adapt F\n        return self.pop[i] + F_adapted * (x_r1 - x_r2)\n\n    def orthogonal_crossover(self, v_i, i):\n        u_i = self.pop[i].copy()\n        CR_adapted = np.clip(self.CR + self.CR_stepsize * np.random.randn(), 0.1, 1.0) # Adapt CR\n        crossover_points = np.random.rand(self.dim) < CR_adapted\n        u_i[crossover_points] = v_i[crossover_points]\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            # Archive update\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.pop[i].copy())\n            else:\n                # Replace worst in archive\n                if self.fitness[i] < np.max(self.fitness):\n                    worst_index = np.argmax(self.fitness)\n                    self.archive[worst_index] = self.pop[i].copy()\n\n\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutation(i, func)\n                v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n                u_i = self.orthogonal_crossover(v_i, i)\n                u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)\n                \n                self.selection(func, u_i, i)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 8, "feedback": "An exception occurred: list assignment index out of range.", "error": "", "parent_ids": ["bb870e7d-c317-4277-8644-5495fa85d782"], "operator": null, "metadata": {}}
{"id": "592fb39a-4ab5-44bb-8b67-d77c45d540d6", "fitness": 0.0, "name": "NeighborhoodAdaptiveDE", "description": "Self-adaptive Differential Evolution with Neighborhood-based mutation and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass NeighborhoodAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, neighborhood_size=3, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.neighborhood_size = neighborhood_size\n        self.restart_prob = restart_prob\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.F_history = []\n        self.CR_history = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def neighborhood_mutation(self, i, func):\n        # Select neighbors\n        neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n        \n        # Ensure the current individual is not in the neighborhood\n        while i in neighbors:\n            neighbors = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n\n        # Select three distinct individuals from the neighborhood\n        if len(neighbors) < 3:\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n        else:\n            x_r1, x_r2, x_r3 = self.pop[neighbors[0]], self.pop[neighbors[1]], self.pop[neighbors[2]]\n\n        mutation_vector = self.pop[i] + self.F * (x_r1 - x_r2)\n        mutation_vector = np.clip(mutation_vector, func.bounds.lb, func.bounds.ub)\n        return mutation_vector\n\n    def crossover(self, v_i, i):\n        u_i = self.pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.CR:\n                u_i[j] = v_i[j]\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n                \n            # Adaptive F and CR\n            self.F = np.random.normal(0.5, 0.1)\n            self.CR = np.random.normal(0.9, 0.1)\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.CR = np.clip(self.CR, 0.1, 0.9)\n            \n            self.F_history.append(self.F)\n            self.CR_history.append(self.CR)\n        \n        # Restart mechanism\n        elif np.random.rand() < self.restart_prob:\n            self.pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n            self.fitness[i] = func(self.pop[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.best_fitness:\n                self.best_fitness = self.fitness[i]\n                self.best_position = self.pop[i].copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.neighborhood_mutation(i, func)\n                u_i = self.crossover(v_i, i)\n                u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)\n                self.selection(func, u_i, i)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 8, "feedback": "The algorithm NeighborhoodAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f308851b-34f6-42a2-8ce9-4ebb0aed553b"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "4c4c6bc5-1616-405e-905d-ce2449c019b7", "fitness": -Infinity, "name": "SOMDE", "description": "An adaptive hybrid algorithm combining Differential Evolution with a self-organizing map (SOM) to guide the search based on fitness landscape topology.", "code": "import numpy as np\nfrom minisom import MiniSom\n\nclass SOMDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, som_grid_size=10, learning_rate=0.5, sigma=0.3, de_mutation_factor=0.5, de_crossover_rate=0.9):\n        \"\"\"\n        Initialize the SOM-DE Optimizer.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.som_grid_size = som_grid_size\n        self.learning_rate = learning_rate\n        self.sigma = sigma\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.som = None\n\n    def initialize_population(self, func):\n        \"\"\"\n        Initialize the population with random positions and evaluate fitness.\n        \"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def initialize_som(self):\n        \"\"\"\n        Initialize the Self-Organizing Map.\n        \"\"\"\n        self.som = MiniSom(self.som_grid_size, self.som_grid_size, self.dim, sigma=self.sigma, learning_rate=self.learning_rate)\n        self.som.random_weights_init(self.pop)  # Initialize with population data\n        self.som.train_random(self.pop, 100)\n\n    def update(self, func):\n        \"\"\"\n        Differential Evolution update guided by the SOM.\n        \"\"\"\n        for i in range(self.pop_size):\n            # 1. Find the Best Matching Unit (BMU) in the SOM for the current individual\n            bmu = self.som.winner(self.pop[i])\n            \n            # 2. Get indices of neighbors around the BMU\n            neighbors = self.get_neighbors(bmu)\n\n            # 3. Select three distinct individuals for DE, one from the neighborhood\n            idxs = np.random.choice(self.pop_size, 2, replace=False) # Select 2 random indices\n            r1, r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n            \n            #Select one random individual from the BMU neighboorhood\n            if len(neighbors) > 0:\n                neighbor_idx = np.random.choice(len(neighbors))\n                r3 = self.pop[neighbors[neighbor_idx]]\n            else:\n                r3 = self.pop[np.random.randint(self.pop_size)]\n            \n            # 4. Differential Evolution Mutation and Crossover\n            mutant = self.pop[i] + self.de_mutation_factor * (r1 - r2)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            trial_vector = np.array([mutant[j] if np.random.rand() < self.de_crossover_rate or j == j_rand else self.pop[i][j] for j in range(self.dim)])\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n            # 5. Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # 6. Greedy Selection\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n                \n                # Update SOM with new best individual\n                self.som.update(self.pop[i], self.som.winner(self.pop[i]), self.learning_rate)\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n\n    def get_neighbors(self, bmu):\n        \"\"\"\n        Get the indices of individuals in the neighborhood of the BMU.\n        \"\"\"\n        neighbors = []\n        bmu_row, bmu_col = bmu\n        for i in range(self.pop_size):\n            winner = self.som.winner(self.pop[i])\n            row, col = winner\n            if abs(row - bmu_row) <= 1 and abs(col - bmu_col) <= 1 and (row, col) != (bmu_row, bmu_col):\n                neighbors.append(i)\n        return neighbors\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n        \"\"\"\n        self.initialize_population(func)\n        self.initialize_som()\n\n        while self.eval_count < self.budget:\n            self.update(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "An exception occurred: No module named 'minisom'.", "error": "", "parent_ids": ["ee11a54b-4c6d-4268-9de2-c4aafabee3ee"], "operator": null, "metadata": {}}
{"id": "5aef0820-9368-4c25-9a18-d6a71ec68189", "fitness": -Infinity, "name": "AdaptiveDEOrthogonalCauchyArchive", "description": "Adaptive Differential Evolution with orthogonal design for parameter tuning and a Cauchy mutation for exploration, combined with an archive-based strategy and improved parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonalCauchyArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, adaptation_rate=0.1, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.adaptation_rate = adaptation_rate\n        self.archive_size = archive_size\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.archive = []\n        self.success_F = []\n        self.success_CR = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def cauchy_mutation(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        cauchy_sample = np.random.standard_cauchy(size=self.dim)\n        return x_r1 + self.F * cauchy_sample * (x_r2 - x_r3)\n\n    def crossover(self, v_i, i):\n        u_i = self.pop[i].copy()\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                u_i[j] = v_i[j]\n        return u_i\n\n    def orthogonal_design(self, func, i):\n        levels = 3\n        design = np.array([[-1, 0, 1],\n                           [-1, 0, 1],\n                           [0, 1, -1]]) # Example L9 orthogonal array, can be expanded\n        \n        best_u_i = self.pop[i].copy()\n        best_f_u_i = self.fitness[i]\n\n        for k in range(levels):\n            u_i = self.pop[i].copy()\n            for j in range(self.dim):\n                delta = (func.bounds.ub - func.bounds.lb) / (levels - 1)\n                u_i[j] = self.pop[i][j] + design[k % 3, (j % 3)] * delta * 0.1 # Smaller step\n                u_i[j] = np.clip(u_i[j], func.bounds.lb, func.bounds.ub)\n                \n            f_u_i = func(u_i)\n            self.eval_count += 1\n            \n            if f_u_i < best_f_u_i:\n                best_f_u_i = f_u_i\n                best_u_i = u_i.copy()\n        return best_u_i, best_f_u_i\n\n\n    def selection(self, func, u_i, i, F, CR):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            self.success_F.append(F)\n            self.success_CR.append(CR)\n            self.archive.append(self.pop[i].copy())\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n        else:\n            if len(self.archive) < self.archive_size:\n                self.archive.append(u_i.copy())\n            else:\n                idx = np.random.randint(0, len(self.archive))\n                self.archive[idx] = u_i.copy()\n\n    def update_parameters(self):\n        if self.success_F:\n            self.F = np.mean(self.success_F)\n            self.CR = np.mean(self.success_CR)\n        \n        self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 0.9)\n        self.CR = np.clip(np.random.normal(self.CR, 0.1), 0.1, 0.9)\n        \n        self.success_F = []\n        self.success_CR = []\n\n        if len(self.archive) > self.pop_size * 2:\n            self.archive = self.archive[-self.pop_size*2:]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                F = np.clip(np.random.normal(0.5, 0.1), 0.1, 0.9)\n                CR = np.clip(np.random.normal(0.9, 0.1), 0.1, 0.9)\n\n                v_i = self.cauchy_mutation(i)\n                v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n                u_i = self.crossover(v_i, i)\n                u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)\n\n                u_i_ortho, f_u_i_ortho = self.orthogonal_design(func, i)\n                if f_u_i_ortho < func(u_i):\n                    u_i = u_i_ortho\n                \n                self.selection(func, u_i, i, F, CR)\n            self.update_parameters()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 8, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["f799bbf0-1fd2-42b9-abf8-ee51ef53db3f"], "operator": null, "metadata": {}}
{"id": "92a3ab47-0b3b-4f6b-87da-f9916aa824f9", "fitness": 0.6544767240478834, "name": "AdaptiveDEOrthogonalCauchy", "description": "Simplified Adaptive Differential Evolution with orthogonal crossover, Cauchy mutation, and memory-based parameter adaptation for robust exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonalCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=20, adaptation_rate=0.1, cauchy_scale=0.1, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.adaptation_rate = adaptation_rate\n        self.cauchy_scale = cauchy_scale\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.memory_F = [0.5] * memory_size  # Memory for F values\n        self.memory_CR = [0.9] * memory_size  # Memory for CR values\n        self.memory_idx = 0\n        self.F = 0.5\n        self.CR = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutation(self, i, func):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        \n        # Cauchy mutation with a small probability\n        if np.random.rand() < 0.05:\n             mutation_vector = x_r1 + self.cauchy_scale * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        else:\n            mutation_vector = x_r1 + self.F * (x_r2 - x_r3)\n\n        mutation_vector = np.clip(mutation_vector, func.bounds.lb, func.bounds.ub)\n        return mutation_vector\n\n    def orthogonal_crossover(self, v_i, i):\n        u_i = self.pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.CR:\n                u_i[j] = v_i[j]\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n\n    def update_parameters(self):\n        # Update F and CR using a weighted average of past values\n        self.memory_F[self.memory_idx] = self.F\n        self.memory_CR[self.memory_idx] = self.CR\n        self.memory_idx = (self.memory_idx + 1) % len(self.memory_F)\n\n        self.F = np.clip(np.mean(self.memory_F) + self.adaptation_rate * np.random.normal(0, 1), 0.1, 0.9)\n        self.CR = np.clip(np.mean(self.memory_CR) + self.adaptation_rate * np.random.normal(0, 1), 0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutation(i, func)\n                u_i = self.orthogonal_crossover(v_i, i)\n                u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)                \n                self.selection(func, u_i, i)\n            self.update_parameters()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDEOrthogonalCauchy scored 0.654 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f308851b-34f6-42a2-8ce9-4ebb0aed553b"], "operator": null, "metadata": {"aucs": [0.27228394087077823, 0.26785399283562306, 0.28555630317395886, 0.9321134785244224, 0.8633205875677332, 0.6058005854420114, 0.8572354346783092, 0.5139019229699486, 0.8369135283144944, 0.680995521848449, 0.8587267157068047, 0.9970972330587203, 0.4514119737851281, 0.8204028115935653, 0.9072787818599796, 0.7400106018527612, 0.34175045429316364, 0.8535672127266842, 0.49506128399398386, 0.5082521158611473]}}
{"id": "fd2c50a7-857c-4cb5-b4d8-3e216cee9f24", "fitness": 0.6811017495867382, "name": "AdaptiveDECauchyRank", "description": "Simplified Adaptive Differential Evolution with Cauchy mutation and rank-based selection, focusing on parameter adaptation and archive utilization for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDECauchyRank:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, archive_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.archive_rate = archive_rate\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.archive = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def cauchy_mutation(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        cauchy_sample = np.random.standard_cauchy(size=self.dim)\n        return x_r1 + self.F * cauchy_sample * (x_r2 - x_r3)\n\n    def crossover(self, v_i, i):\n        u_i = self.pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.CR:\n                u_i[j] = v_i[j]\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            if len(self.archive) < self.pop_size * 2:\n                self.archive.append(self.pop[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, len(self.archive))\n                self.archive[idx_to_replace] = self.pop[i].copy()\n                \n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n        elif np.random.rand() < self.archive_rate:\n            if len(self.archive) < self.pop_size * 2:\n                self.archive.append(u_i.copy())\n            else:\n                idx_to_replace = np.random.randint(0, len(self.archive))\n                self.archive[idx_to_replace] = u_i.copy()\n                \n    def update_parameters(self):\n        self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 0.9)\n        self.CR = np.clip(np.random.normal(0.9, 0.1), 0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.cauchy_mutation(i)\n                v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n                u_i = self.crossover(v_i, i)\n                u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)\n                self.selection(func, u_i, i)\n            self.update_parameters()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDECauchyRank scored 0.681 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f799bbf0-1fd2-42b9-abf8-ee51ef53db3f"], "operator": null, "metadata": {"aucs": [0.2139323191052186, 0.5788380347979275, 0.7021488051135902, 0.8727155328473748, 0.7729864468632943, 0.8003291633590333, 0.6335305336227892, 0.7159360358025226, 0.7455309538752662, 0.7808449114754371, 0.8543317441315351, 0.9973270153337557, 0.24266799562690522, 0.7476640878365256, 0.8483468862208017, 0.8278707805576953, 0.6607199775713097, 0.8622993754761388, 0.23675086976485604, 0.5272635223527844]}}
{"id": "6abbe250-3c78-4f4d-b5ce-47eed0df0862", "fitness": 0.8118225976101032, "name": "AdaptiveDEOrthogonalCauchy", "description": "Simplified Adaptive Differential Evolution with adaptive F and CR, orthogonal crossover, and a small Cauchy perturbation for enhanced exploration around the best solution.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonalCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, cauchy_scale=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.success_F = []\n        self.success_CR = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def mutation(self, i, func):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        mutation_vector = x_r1 + self.F * (x_r2 - x_r3)\n\n        # Cauchy perturbation near the best solution\n        mutation_vector += self.cauchy_scale * np.random.standard_cauchy(size=self.dim) * (self.best_position - self.pop[i])\n        \n        mutation_vector = np.clip(mutation_vector, func.bounds.lb, func.bounds.ub)\n        return mutation_vector\n\n    def orthogonal_crossover(self, v_i, i):\n        u_i = self.pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.CR:\n                u_i[j] = v_i[j]\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            self.success_F.append(self.F)\n            self.success_CR.append(self.CR)\n\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n\n\n    def update_parameters(self):\n        if self.success_F:\n            self.F = 0.8 * self.F + 0.2 * np.mean(self.success_F)\n            self.CR = 0.8 * self.CR + 0.2 * np.mean(self.success_CR)\n\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.CR = np.clip(self.CR, 0.1, 0.9)\n        self.success_F = []\n        self.success_CR = []\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutation(i, func)\n                u_i = self.orthogonal_crossover(v_i, i)\n                u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)                \n                self.selection(func, u_i, i)\n            self.update_parameters()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDEOrthogonalCauchy scored 0.812 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f308851b-34f6-42a2-8ce9-4ebb0aed553b"], "operator": null, "metadata": {"aucs": [0.4488915059812565, 0.8652781010594652, 0.7622936929031344, 0.953968372164209, 0.8911610156942859, 0.9109301432970347, 0.8606966146220654, 0.8744021345197681, 0.885349584017965, 0.8593049688323581, 0.9461468329606828, 0.9928928828959188, 0.3251906830223289, 0.8839938078778017, 0.9455972524526356, 0.9190132881631194, 0.8581987327373992, 0.942097882930384, 0.5824383650159874, 0.528606091054263]}}
{"id": "5ccd4d4e-60e5-4ca4-96cd-f9f28fefa085", "fitness": 0.608950410271255, "name": "PeriodicRestartDE", "description": "Differential Evolution with a periodic restart mechanism and self-adaptive parameters for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass PeriodicRestartDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, restart_period=500, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.restart_period = restart_period\n        self.adaptation_rate = adaptation_rate\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.generation = 0\n        self.archive = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n        self.archive = []\n\n    def mutation(self, i, func):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        mutation_vector = x_r1 + self.F * (x_r2 - x_r3)\n        mutation_vector = np.clip(mutation_vector, func.bounds.lb, func.bounds.ub)\n        return mutation_vector\n\n    def crossover(self, v_i, i):\n        u_i = self.pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.CR:\n                u_i[j] = v_i[j]\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            self.archive.append((self.pop[i].copy(), self.fitness[i]))\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n        else:\n            # Store the parent if the offspring is not better\n            self.archive.append((self.pop[i].copy(), self.fitness[i]))\n\n    def adapt_parameters(self):\n        # Self-adaptive F and CR\n        self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 0.9)\n        self.CR = np.clip(np.random.normal(self.CR, 0.1), 0.1, 0.9)\n\n    def restart_population(self, func):\n        # Restart strategy: Re-initialize population from archive if available, else randomly.\n        if len(self.archive) >= self.pop_size:\n            # Sample from the archive\n            indices = np.random.choice(len(self.archive), self.pop_size, replace=False)\n            self.pop = np.array([self.archive[i][0] for i in indices])\n            self.fitness = np.array([self.archive[i][1] for i in indices])\n        else:\n            # Re-initialize randomly\n            self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.pop])\n            self.eval_count += self.pop_size-len(self.archive) if len(self.archive)<self.pop_size else 0\n\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n        self.archive = [] # Clear the archive after restart\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutation(i, func)\n                u_i = self.crossover(v_i, i)\n                u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)\n                self.selection(func, u_i, i)\n\n            self.adapt_parameters()\n            self.generation += 1\n\n            if self.generation % (self.restart_period // self.pop_size) == 0:\n                self.restart_population(func)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 8, "feedback": "The algorithm PeriodicRestartDE scored 0.609 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f308851b-34f6-42a2-8ce9-4ebb0aed553b"], "operator": null, "metadata": {"aucs": [0.2159719596657016, 0.6374403591506258, 0.5167536677363527, 0.9207266734001047, 0.640855831164356, 0.6847530415993619, 0.33975154096161586, 0.6961771123901093, 0.6309861027676795, 0.2426943594845994, 0.9146340431348726, 0.9965331171063614, 0.2853138160309939, 0.6360353588321025, 0.8969808128086338, 0.7879905325447792, 0.5411977117705773, 0.866900754210961, 0.21562990642026447, 0.5116815042450436]}}
{"id": "e8890d93-397e-4301-8c68-4ed57486c166", "fitness": 0.5103027849939694, "name": "HybridSADE", "description": "Simplified Hybrid DE-PSO with self-adaptive parameters and reduced control parameters for faster convergence.", "code": "import numpy as np\n\nclass HybridSADE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.CR = 0.9\n        self.inertia_weight = 0.7\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.global_best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update(self, func):\n        for i in range(self.pop_size):\n            # DE Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            mutant = x_r1 + self.F * (x_r2 - x_r3)\n            mutant = np.clip(mutant, self.lb, self.ub)\n\n            # PSO-inspired update\n            r1 = np.random.rand(self.dim)\n            trial_vector = mutant + r1 * (self.global_best_position - mutant)\n            trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            crossover_mask = np.random.rand(self.dim) < self.CR\n            trial_vector[crossover_mask] = mutant[crossover_mask]\n            trial_vector[j_rand] = mutant[j_rand]  # Ensure at least one component changes\n            trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n            # Evaluation\n            f_trial = func(trial_vector)\n            self.eval_count += 1\n\n            # Greedy Selection\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector.copy()\n                self.fitness[i] = f_trial\n\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = trial_vector.copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.update(func)\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm HybridSADE scored 0.510 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ee11a54b-4c6d-4268-9de2-c4aafabee3ee"], "operator": null, "metadata": {"aucs": [0.2585996569195472, 0.3406003208668307, 0.35045566710356457, 0.9680653304328263, 0.25832794427451444, 0.4931127320331976, 0.5630574638856454, 0.4773234069398695, 0.7289935882419138, 0.7333285725628363, 0.431570699806781, 0.9952211967062616, 0.2510258270062815, 0.5557349025402218, 0.7080938855606584, 0.4133419103450703, 0.41274527378521264, 0.5623001864024417, 0.1988610674067982, 0.5052960670589166]}}
{"id": "f5c7d097-b01e-4dd3-a855-dc0f6b1db981", "fitness": 0.6648166717450736, "name": "AdaptiveDEMomentumCauchy", "description": "Adaptive Differential Evolution with momentum-based parameter adaptation, Cauchy mutation, and a dynamic population size adjustment strategy for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDEMomentumCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, adaptation_rate=0.1, cauchy_scale=0.1, pop_size_adaptation_frequency=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.adaptation_rate = adaptation_rate\n        self.cauchy_scale = cauchy_scale\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.success_F = []\n        self.success_CR = []\n        self.memory_F = [F] * 10  # Memory for F values\n        self.memory_CR = [CR] * 10  # Memory for CR values\n        self.memory_idx = 0\n        self.F_momentum = 0.0\n        self.CR_momentum = 0.0\n        self.momentum_beta = 0.9\n        self.pop_size_adaptation_frequency = pop_size_adaptation_frequency\n        self.pop_size_history = []\n        self.min_pop_size = 10\n        self.max_pop_size = 50\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n        self.pop_size_history.append(self.pop_size)\n\n    def mutation(self, i, func):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        \n        # Cauchy mutation with a small probability\n        if np.random.rand() < 0.05:\n             mutation_vector = x_r1 + self.cauchy_scale * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        else:\n            mutation_vector = x_r1 + self.F * (x_r2 - x_r3)\n\n        mutation_vector = np.clip(mutation_vector, func.bounds.lb, func.bounds.ub)\n        return mutation_vector\n\n    def orthogonal_crossover(self, v_i, i):\n        u_i = self.pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.CR:\n                u_i[j] = v_i[j]\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            delta_fitness = self.fitness[i] - f_u_i\n            self.success_F.append(self.F)\n            self.success_CR.append(self.CR)\n\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n        \n\n    def update_parameters(self):\n        # Update F and CR using a weighted average of past successful values\n        if self.success_F:\n            mean_F = np.mean(self.success_F)\n            mean_CR = np.mean(self.success_CR)\n\n            # Update memory with successful values\n            self.memory_F[self.memory_idx] = mean_F\n            self.memory_CR[self.memory_idx] = mean_CR\n            self.memory_idx = (self.memory_idx + 1) % len(self.memory_F)\n\n            # Calculate weighted average with momentum\n            self.F_momentum = self.momentum_beta * self.F_momentum + (1 - self.momentum_beta) * np.mean(self.memory_F)\n            self.CR_momentum = self.momentum_beta * self.CR_momentum + (1 - self.momentum_beta) * np.mean(self.memory_CR)\n            \n            self.F = 0.8 * self.F + 0.2 * self.F_momentum\n            self.CR = 0.8 * self.CR + 0.2 * self.CR_momentum\n\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.CR = np.clip(self.CR, 0.1, 0.9)\n        self.success_F = []\n        self.success_CR = []\n\n    def adjust_population_size(self):\n        if len(self.pop_size_history) < self.pop_size_adaptation_frequency:\n            return\n\n        recent_fitness = [np.min(self.fitness)]\n        if len(self.pop_size_history) > 1:\n            recent_fitness = [np.min(self.fitness) for _ in range(self.pop_size_adaptation_frequency)]\n\n        improvement = False\n        if len(self.pop_size_history) > self.pop_size_adaptation_frequency:\n            \n            old_pop_size = self.pop_size_history[-self.pop_size_adaptation_frequency-1]\n            past_fitness = self.best_fitness\n            if self.best_fitness < past_fitness:\n                improvement = True\n        else:\n            past_fitness = self.best_fitness\n            if self.best_fitness < past_fitness:\n                improvement = True\n\n        if improvement:\n            self.pop_size = min(self.pop_size + 2, self.max_pop_size)  # Increase pop size\n        else:\n            self.pop_size = max(self.pop_size - 2, self.min_pop_size)  # Decrease pop size\n            \n        self.pop_size_history.append(self.pop_size)\n        # Reinitialize population with the new size\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutation(i, func)\n\n                u_i = self.orthogonal_crossover(v_i, i)\n                u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)\n                \n                self.selection(func, u_i, i)\n            self.update_parameters()\n            \n            if self.eval_count // self.pop_size_adaptation_frequency > len(self.pop_size_history):\n                self.adjust_population_size()\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDEMomentumCauchy scored 0.665 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f308851b-34f6-42a2-8ce9-4ebb0aed553b"], "operator": null, "metadata": {"aucs": [0.18642585572948633, 0.6612271000044386, 0.5811613894524309, 0.9146923519663749, 0.8521142624319928, 0.8923175965053302, 0.8349606952780553, 0.6674612586692659, 0.43689808461204616, 0.6939783550811804, 0.5349465457181066, 0.996621362958117, 0.31210811842669295, 0.8045391996220612, 0.786734714895628, 0.87986254298524, 0.7239698072195544, 0.7803750311401891, 0.23856122691562565, 0.5173779352896585]}}
{"id": "3632d329-3b45-434a-90bf-bc5dc4841651", "fitness": 0.0, "name": "AdaptiveDEPopulationRestartCauchy", "description": "Adaptive Differential Evolution with a dynamically adjusted population size and a Cauchy mutation, incorporating a restart mechanism when stagnation is detected.", "code": "import numpy as np\n\nclass AdaptiveDEPopulationRestartCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size_init=20, F=0.5, CR=0.9, stagnation_threshold=500, pop_size_adjust_freq=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.pop_size_adjust_freq = pop_size_adjust_freq\n        self.pop_sizes = [pop_size_init]\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n        self.last_best_fitness = self.best_fitness # For stagnation detection\n\n    def mutation(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        # Cauchy mutation\n        mutation_vector = x_r1 + self.F * (x_r2 - x_r3) + 0.01 * np.random.standard_cauchy(size=self.dim) \n        return mutation_vector\n\n    def crossover(self, v_i, i):\n        u_i = self.pop[i].copy()\n        crossover_points = np.random.rand(self.dim) < self.CR\n        u_i[crossover_points] = v_i[crossover_points]\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n                self.stagnation_counter = 0 # Reset stagnation counter\n        else:\n            self.stagnation_counter +=1\n\n    def adjust_population_size(self):\n        if self.stagnation_counter > self.stagnation_threshold:\n            # Reduce population size if stagnating\n            new_pop_size = max(5, int(self.pop_size * 0.75))\n            print(f\"Stagnation detected. Reducing population size from {self.pop_size} to {new_pop_size}\")\n            self.pop_size = new_pop_size\n            self.pop_sizes.append(self.pop_size)\n            self.stagnation_counter = 0 #reset stagnation counter\n            return True\n        return False\n\n    def restart_population(self, func):\n         print(\"Restarting Population\")\n         self.initialize_population(func)\n         self.stagnation_counter = 0\n         self.last_best_fitness = self.best_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.mutation(i)\n                v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n\n                u_i = self.crossover(v_i, i)\n                u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)\n                \n                self.selection(func, u_i, i)\n\n            if self.eval_count % self.pop_size_adjust_freq == 0:\n                if self.adjust_population_size():\n                    self.restart_population(func)\n                elif abs(self.best_fitness - self.last_best_fitness) < 1e-8 and self.stagnation_counter > self.stagnation_threshold:\n                    self.restart_population(func) #perform a restart after stagnation\n                self.last_best_fitness = self.best_fitness\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDEPopulationRestartCauchy scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["bb870e7d-c317-4277-8644-5495fa85d782"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "825eb643-0d01-42ad-9863-417db03e800f", "fitness": 0.688670949973709, "name": "AdaptiveDECauchyRankSimple", "description": "Simplified Adaptive Differential Evolution with Cauchy mutation and probabilistic archiving, focusing on reducing complexity and parameter count while maintaining exploration.", "code": "import numpy as np\n\nclass AdaptiveDECauchyRankSimple:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, archive_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.archive_prob = archive_prob\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.archive = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n\n    def cauchy_mutation(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        cauchy_sample = np.random.standard_cauchy(size=self.dim)\n        return x_r1 + self.F * cauchy_sample * (x_r2 - x_r3)\n\n    def crossover(self, v_i, i):\n        u_i = self.pop[i].copy()\n        mask = np.random.rand(self.dim) < self.CR\n        u_i[mask] = v_i[mask]\n        return u_i\n\n    def selection(self, func, u_i, i):\n        f_u_i = func(u_i)\n        self.eval_count += 1\n\n        if f_u_i < self.fitness[i]:\n            if np.random.rand() < self.archive_prob:\n                self.archive.append(self.pop[i].copy())\n            self.fitness[i] = f_u_i\n            self.pop[i] = u_i.copy()\n\n            if f_u_i < self.best_fitness:\n                self.best_fitness = f_u_i\n                self.best_position = u_i.copy()\n        elif np.random.rand() < self.archive_prob:\n            self.archive.append(u_i.copy())\n\n    def update_parameters(self):\n        self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 0.9)\n        self.CR = np.clip(np.random.normal(0.9, 0.1), 0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                v_i = self.cauchy_mutation(i)\n                v_i = np.clip(v_i, func.bounds.lb, func.bounds.ub)\n                u_i = self.crossover(v_i, i)\n                u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)\n                self.selection(func, u_i, i)\n            self.update_parameters()\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDECauchyRankSimple scored 0.689 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f799bbf0-1fd2-42b9-abf8-ee51ef53db3f"], "operator": null, "metadata": {"aucs": [0.3233489603803946, 0.6432779938460963, 0.7135934750303106, 0.8849819580166991, 0.8177462023135057, 0.8105841177857139, 0.6832351253085549, 0.7311298764812806, 0.7809793116319679, 0.7361603828447882, 0.8449519891673123, 0.9947547689143098, 0.27361449844120156, 0.7300504657035596, 0.7707825956166879, 0.8428579950262416, 0.5506457122553206, 0.8777174804442501, 0.24914346935333564, 0.5138626209126507]}}
