{"id": "f01c7ac7-3342-441e-818b-2c2ccbb8fe7e", "fitness": 0.34780138855396886, "name": "AdaptiveDE", "description": "An adaptive differential evolution strategy that adjusts mutation and crossover rates based on population diversity and fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        \"\"\"\n        Initialize the Adaptive Differential Evolution optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            F (float): Initial mutation factor.\n            CR (float): Initial crossover rate.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, pop, F):\n        \"\"\"Perform mutation operation.\"\"\"\n        mutated_pop = np.zeros_like(pop)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = pop[idxs]\n            mutated_pop[i] = x_r1 + F * (x_r2 - x_r3)\n        return mutated_pop\n\n    def crossover(self, pop, mutated_pop, CR):\n        \"\"\"Perform crossover operation.\"\"\"\n        crossed_pop = np.zeros_like(pop)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < CR:\n                    crossed_pop[i, j] = mutated_pop[i, j]\n                else:\n                    crossed_pop[i, j] = pop[i, j]\n        return crossed_pop\n\n    def ensure_bounds(self, pop, lb, ub):\n        \"\"\"Ensure the population stays within the bounds.\"\"\"\n        pop = np.clip(pop, lb, ub)\n        return pop\n\n    def update_params(self, fitness):\n        \"\"\"Update mutation factor and crossover rate based on fitness improvement.\"\"\"\n        delta_fitness = np.mean(self.fitness) - np.mean(fitness)\n        if delta_fitness > 0:\n            self.F = max(0.1, self.F * 0.9)  # Reduce F if improvement\n            self.CR = min(0.99, self.CR * 1.1)  # Increase CR if improvement\n        else:\n            self.F = min(0.9, self.F * 1.1)  # Increase F if no improvement\n            self.CR = max(0.1, self.CR * 0.9)  # Reduce CR if no improvement\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Adaptive Differential Evolution.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            F = self.F\n            CR = self.CR\n\n            mutated_pop = self.mutate(self.pop, F)\n            mutated_pop = self.ensure_bounds(mutated_pop, func.bounds.lb, func.bounds.ub)\n            crossed_pop = self.crossover(self.pop, mutated_pop, CR)\n            crossed_pop = self.ensure_bounds(crossed_pop, func.bounds.lb, func.bounds.ub)\n\n            new_fitness = np.array([func(x) for x in crossed_pop])\n            self.eval_count += self.pop_size\n\n            improved_indices = new_fitness < self.fitness\n            self.pop[improved_indices] = crossed_pop[improved_indices]\n            self.fitness[improved_indices] = new_fitness[improved_indices]\n\n            # Update the best solution found so far\n            current_best_index = np.argmin(self.fitness)\n            if self.fitness[current_best_index] < self.f_opt:\n                self.f_opt = self.fitness[current_best_index]\n                self.x_opt = self.pop[current_best_index]\n            \n            self.update_params(self.fitness)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.348 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.14442800308283965, 0.21149284872380592, 0.32295687179756183, 0.3028098017158538, 0.25964029028956814, 0.36597414776997306, 0.2849651612087827, 0.3085985527032502, 0.2608259147070897, 0.21796216813478386, 0.2566738027190696, 0.9924680112809287, 0.25261576435657296, 0.27926448159181905, 0.6912194323007141, 0.38834138622829084, 0.3136147497185009, 0.44212846908271464, 0.17844619908111548, 0.4816017145861424]}}
{"id": "abea0991-2535-459e-a3e3-1b41aca82e6f", "fitness": 0.7081444051115964, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with archiving and stochastic ranking for constraint handling.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.archive_size = archive_size\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = []\n        self.archive_fitness = []\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                if len(self.archive) > 0:\n                  all_individuals = np.concatenate((self.pop, self.archive))\n                  idx = np.random.choice(range(len(all_individuals)), size=3, replace=False)\n                  x1, x2, x3 = all_individuals[idx[0]], all_individuals[idx[1]], all_individuals[idx[2]]\n\n                else:\n                  idx = np.random.choice(candidates, size=3, replace=False)\n                  x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                \n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.archive.append(self.pop[i])\n                    self.archive_fitness.append(self.fitness[i])\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                        self.archive_fitness.pop(0)\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                  break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.708 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.35757698317705167, 0.685674433510171, 0.6814135118884058, 0.8907240640818057, 0.7433522046895512, 0.7980732999693186, 0.6413567328225648, 0.6561083250222062, 0.7685431069810594, 0.6800770656489472, 0.8708118310896682, 0.9930477406452741, 0.7036852156361764, 0.7409868270604596, 0.9255243790680366, 0.7719474178689815, 0.6455447648692916, 0.8608255518723332, 0.22192002373403363, 0.5256946225965922]}}
{"id": "21b574e2-c479-487d-ac5b-9bc2a5020072", "fitness": 0.6750051234156842, "name": "HybridPSO_DE", "description": "Population-based algorithm that combines particle swarm optimization principles with differential evolution mutation and crossover operators for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.cr = cr # Crossover rate\n        self.f = f   # Mutation factor\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        global_best_idx = np.argmin(pbest_fitness)\n        global_best_pos = pbest_pop[global_best_idx].copy()\n        global_best_fitness = pbest_fitness[global_best_idx]\n        \n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity (PSO component)\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                                self.c2 * np.random.rand(self.dim) * (global_best_pos - pop[i])\n                \n                # Mutation (DE component)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = pop[idxs[0]], pop[idxs[1]], pop[idxs[2]]\n                mutant = x1 + self.f * (x2 - x3)\n                \n                # Crossover (DE component)\n                trial = pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                # Ensure trial vector stays within bounds\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                self.budget -= 1\n                \n                # Selection (DE component)\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial.copy()\n                    fitness[i] = trial_fitness\n                    \n                    # Update personal best\n                    if trial_fitness < pbest_fitness[i]:\n                        pbest_pop[i] = trial.copy()\n                        pbest_fitness[i] = trial_fitness\n                        \n                        # Update global best\n                        if trial_fitness < global_best_fitness:\n                            global_best_pos = trial.copy()\n                            global_best_fitness = trial_fitness\n            \n        return global_best_fitness, global_best_pos", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE scored 0.675 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.22322155548177602, 0.5802658587344828, 0.7174540676346213, 0.894893639236277, 0.7516990059321162, 0.8180620116551909, 0.6782109875301165, 0.6775607236837482, 0.8069104000384999, 0.7087363629635388, 0.8633277848198558, 0.9944915450348089, 0.43465050998956134, 0.5401559393099438, 0.6688610593448245, 0.8343429424286342, 0.5791608704819871, 0.8716260248005554, 0.30350395928321994, 0.5529672199299278]}}
{"id": "f074407d-65e4-49c9-91ff-6bd706984e39", "fitness": 0.38057551030016884, "name": "HybridPSO_DE", "description": "A population-based algorithm that combines aspects of particle swarm optimization and differential evolution with a focus on exploration and exploitation balance through dynamic parameter adaptation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.personal_best_fitness = None\n        self.personal_best_position = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (func.bounds.ub - func.bounds.lb) / 2 # Initialize velocities within a reasonable range\n\n        self.personal_best_fitness = np.copy(self.fitness)\n        self.personal_best_position = np.copy(self.pop)\n\n        best_idx = np.argmin(self.fitness)\n        self.best_fitness = self.fitness[best_idx]\n        self.best_position = self.pop[best_idx]\n\n\n    def update_particle(self, i, w, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n\n        self.velocities[i] = w * self.velocities[i] + \\\n                             self.c1 * r1 * (self.personal_best_position[i] - self.pop[i]) + \\\n                             self.c2 * r2 * (self.best_position - self.pop[i])\n\n        # Velocity clamping - important for stability\n        v_max = (func.bounds.ub - func.bounds.lb) / 2\n        self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n        self.pop[i] += self.velocities[i]\n        self.pop[i] = np.clip(self.pop[i], func.bounds.lb, func.bounds.ub) # Keep particles within bounds\n\n        f = func(self.pop[i])\n        self.eval_count += 1\n\n        if f < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f\n            self.personal_best_position[i] = self.pop[i].copy()\n\n            if f < self.best_fitness:\n                self.best_fitness = f\n                self.best_position = self.pop[i].copy()\n\n\n\n    def differential_evolution_mutation(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        while i in idxs:\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.pop[idxs]\n\n        v = x1 + self.F * (x2 - x3)\n        return v\n\n\n    def differential_evolution_crossover(self, i, mutant):\n        trial_vector = np.copy(self.pop[i])\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial_vector[j] = mutant[j]\n        return trial_vector\n    def update_de(self, i, func):\n\n        mutant = self.differential_evolution_mutation(i)\n        trial_vector = self.differential_evolution_crossover(i, mutant)\n\n        trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n        f_trial = func(trial_vector)\n        self.eval_count += 1\n\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.pop[i] = trial_vector.copy()\n            if f_trial < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_trial\n                self.personal_best_position[i] = self.pop[i].copy()\n            if f_trial < self.best_fitness:\n                self.best_fitness = f_trial\n                self.best_position = self.pop[i].copy()\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5: # Choose between PSO and DE\n                    self.update_particle(i, w, func)\n                else:\n                    self.update_de(i, func)\n\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE scored 0.381 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1615815179346075, 0.26431232113885283, 0.3572264624561279, 0.5400065835363076, 0.254008170606432, 0.41024078919413054, 0.29033306249701607, 0.32429160745236296, 0.3045646639363475, 0.2933469069978427, 0.4200357702448084, 0.9978670022524001, 0.28804609905969847, 0.262910127205807, 0.6390144165374472, 0.4108318808967303, 0.3123950213871941, 0.4196210327367066, 0.17506013900368866, 0.48581663092886906]}}
{"id": "bf57147c-3f91-4071-8a2d-7c1990f4e82a", "fitness": 0.3458319439898515, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive mutation factor and crossover rate based on fitness improvements.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()  # Use copy to avoid modification\n\n    def mutate(self, pop, F):\n        idxs = np.random.randint(0, self.pop_size, size=(self.pop_size, 3))\n        x_r1 = pop[idxs[:, 0]]\n        x_r2 = pop[idxs[:, 1]]\n        x_r3 = pop[idxs[:, 2]]\n        return x_r1 + F * (x_r2 - x_r3)\n\n    def crossover(self, pop, mutated_pop, CR):\n        cross_mask = np.random.rand(self.pop_size, self.dim) < CR\n        return np.where(cross_mask, mutated_pop, pop)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        while self.eval_count < self.budget:\n            mutated_pop = self.mutate(self.pop, self.F)\n            mutated_pop = np.clip(mutated_pop, lb, ub)\n            crossed_pop = self.crossover(self.pop, mutated_pop, self.CR)\n\n            new_fitness = np.array([func(x) for x in crossed_pop])\n            self.eval_count += self.pop_size\n\n            improved_indices = new_fitness < self.fitness\n            self.pop[improved_indices] = crossed_pop[improved_indices]\n            self.fitness[improved_indices] = new_fitness[improved_indices]\n\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.pop[best_index].copy() # Use copy\n\n            # Adaptive F and CR\n            if np.mean(new_fitness) < np.mean(self.fitness):\n                self.F = max(0.1, self.F * 0.9)\n                self.CR = min(0.9, self.CR * 1.1)\n            else:\n                self.F = min(0.9, self.F * 1.1)\n                self.CR = max(0.1, self.CR * 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.346 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f01c7ac7-3342-441e-818b-2c2ccbb8fe7e"], "operator": null, "metadata": {"aucs": [0.1550063486088551, 0.19129856646884802, 0.32660377278162755, 0.3029593326608837, 0.2695168564029865, 0.35864534365001366, 0.28129223445887097, 0.28912918745163907, 0.2656674703256712, 0.17901156903557347, 0.29518131854445295, 0.988058548900168, 0.2823225183976217, 0.3113224209167269, 0.6722846195071461, 0.37383524999276563, 0.29616700825624076, 0.4090886326089084, 0.18441478817188206, 0.48483309265614993]}}
{"id": "ea15ceeb-e891-4196-ac4e-266b145f2bbf", "fitness": 0.749412087885157, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with reduced complexity and parameter tuning.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                  break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.749 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["abea0991-2535-459e-a3e3-1b41aca82e6f"], "operator": null, "metadata": {"aucs": [0.3806890727082769, 0.7516582970727483, 0.7243432543649498, 0.9131207367831962, 0.8122138068001249, 0.8401401947773034, 0.6859785725137624, 0.753648658488214, 0.809772471631756, 0.7124735859235936, 0.8953857279733564, 0.9978335353775117, 0.7353246030661189, 0.7789219561181376, 0.913209973225798, 0.8101913352392891, 0.7010799061277099, 0.8574105435366081, 0.27092949203907124, 0.6439160339356134]}}
{"id": "534dcd03-d95a-4aff-8f00-f0f1e8ff71cd", "fitness": 0.678145448681788, "name": "HybridPSO_DE", "description": "Simplified Hybrid PSO-DE algorithm with adaptive parameter control and focused exploration.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, w_init=0.9, w_end=0.4, c=0.1, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c = c\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n\n    def update(self, i, w, func):\n        # PSO update with simplified velocity (no explicit velocity)\n        r1 = np.random.rand(self.dim)\n        new_pos = self.pop[i] + w * (self.best_position - self.pop[i]) + self.c * r1 * (self.best_position - self.pop[i])\n        \n        # DE update\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.pop[idxs]\n        mutant = x1 + self.F * (x2 - x3)\n        \n        # Crossover\n        trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant, self.pop[i])\n        \n        # Clip and evaluate\n        trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n        f_trial = func(trial_vector)\n        self.eval_count += 1\n        \n        #Greedy selection\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.pop[i] = trial_vector.copy()\n            if f_trial < self.best_fitness:\n                self.best_fitness = f_trial\n                self.best_position = trial_vector.copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n            for i in range(self.pop_size):\n                self.update(i, w, func)\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DE scored 0.678 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f074407d-65e4-49c9-91ff-6bd706984e39"], "operator": null, "metadata": {"aucs": [0.2501957513201658, 0.5532462865189076, 0.6429473783031201, 0.8645814567142649, 0.7559976476968006, 0.8074859099032317, 0.6812501643693926, 0.6580523181393586, 0.7545396887696825, 0.7165836972205923, 0.8440994340664657, 0.9967900784662285, 0.39090342423581337, 0.7197042757807159, 0.9191841003146609, 0.8163082403951771, 0.5859476043352845, 0.8349796266795122, 0.2590066676950967, 0.511105222711288]}}
{"id": "b95e9568-9fe2-420d-985e-4e40bf0e3eb3", "fitness": 0.2587230771932722, "name": "HybridPSO_DE", "description": "Simplified Hybrid PSO-DE algorithm with adaptive parameter control based on remaining budget and velocity clamping for improved stability.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=2.0, c2=2.0, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.eval_count = 0\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (self.ub - self.lb) / 2\n\n        best_idx = np.argmin(self.fitness)\n        self.best_fitness = self.fitness[best_idx]\n        self.best_position = self.pop[best_idx]\n\n\n    def update_particle(self, i, w, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n\n        self.velocities[i] = w * self.velocities[i] + \\\n                             self.c1 * r1 * (self.pop[i] - self.best_position) + \\\n                             self.c2 * r2 * (self.pop[i] - self.pop[np.random.randint(self.pop_size)])\n\n        v_max = (self.ub - self.lb) / 2\n        self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n        self.pop[i] += self.velocities[i]\n        self.pop[i] = np.clip(self.pop[i], self.lb, self.ub)\n\n        f = func(self.pop[i])\n        self.eval_count += 1\n\n        if f < self.best_fitness:\n            self.best_fitness = f\n            self.best_position = self.pop[i].copy()\n\n\n    def differential_evolution_mutation(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.pop[idxs]\n\n        v = x1 + self.F * (x2 - x3)\n        return v\n\n\n    def differential_evolution_crossover(self, i, mutant):\n        trial_vector = np.copy(self.pop[i])\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial_vector[j] = mutant[j]\n        return trial_vector\n    def update_de(self, i, func):\n\n        mutant = self.differential_evolution_mutation(i)\n        trial_vector = self.differential_evolution_crossover(i, mutant)\n\n        trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n        f_trial = func(trial_vector)\n        self.eval_count += 1\n\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.pop[i] = trial_vector.copy()\n\n            if f_trial < self.best_fitness:\n                self.best_fitness = f_trial\n                self.best_position = self.pop[i].copy()\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            remaining_budget = self.budget - self.eval_count\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n            \n            F = 0.5 + 0.3 * np.sin(2 * np.pi * self.eval_count / self.budget)\n            CR = 0.7 + 0.2 * np.cos(2 * np.pi * self.eval_count / self.budget)\n\n\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    self.update_particle(i, w, func)\n                else:\n                    self.F = F\n                    self.CR = CR\n                    self.update_de(i, func)\n\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DE scored 0.259 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f074407d-65e4-49c9-91ff-6bd706984e39"], "operator": null, "metadata": {"aucs": [0.09137828964179695, 0.15893413178056814, 0.24821646632573713, 0.18610773258100155, 0.18234501127761893, 0.1830432559998305, 0.23279711092289057, 0.1941861903122467, 0.16846160550557432, 0.13476264748730593, 0.18361332120575868, 0.9999108698828387, 0.2135803965164591, 0.21689747543967353, 0.5565991373172284, 0.2416083070632149, 0.1834426003749362, 0.22058398348358454, 0.1271092151695279, 0.45088379557765135]}}
{"id": "5435b791-2379-4bd2-8ca8-3ec2f45fb8eb", "fitness": 0.699281209782554, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution by removing the archive and focusing on parameter adaptation based on success rate.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, F_adapt=0.1, Cr_adapt=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.F_adapt = F_adapt\n        self.Cr_adapt = Cr_adapt\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.success_F = []\n        self.success_Cr = []\n        self.successful_mutations = 0\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n                    self.successful_mutations += 1\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                #Adapt F and Cr\n                if self.successful_mutations > 5 and self.evals % self.pop_size == 0:\n                    self.F = 0.9 * self.F + 0.1 * np.mean(self.success_F) if len(self.success_F) > 0 else self.F\n                    self.Cr = 0.9 * self.Cr + 0.1 * np.mean(self.success_Cr) if len(self.success_Cr) > 0 else self.Cr\n                    self.F = np.clip(self.F, 0.1, 0.9)\n                    self.Cr = np.clip(self.Cr, 0.1, 0.9)\n                    self.success_F = []\n                    self.success_Cr = []\n                    self.successful_mutations = 0\n\n                if self.evals >= self.budget:\n                  break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.699 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["abea0991-2535-459e-a3e3-1b41aca82e6f"], "operator": null, "metadata": {"aucs": [0.31586343235486336, 0.6834180925772472, 0.6544311625678179, 0.8782157411838677, 0.7448270318401934, 0.7711992641684358, 0.677364713591021, 0.6484057300605317, 0.7545043180198922, 0.700745880274279, 0.8644819661919969, 0.9984440261494668, 0.6439906986306934, 0.7107911920795027, 0.907609315977893, 0.7617457128998871, 0.6163138571786908, 0.8441290475898109, 0.28468779482297046, 0.524455217492021]}}
{"id": "b4d6b64d-4120-4ae2-b137-97e9a5731599", "fitness": 0.5340968373143274, "name": "HybridPSO_DE", "description": "Simplified hybrid PSO-DE, adaptively switching between PSO and DE updates with reduced complexity and parameter tuning.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n\n\n    def pso_update(self, i, func):\n        w = 0.7  # Inertia weight\n        c1 = 1.5 # Cognitive coefficient\n        c2 = 1.5 # Social coefficient\n        \n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        \n        velocity = w * (self.pop[i] - self.pop[i]) + c1 * r1 * (self.pop[np.argmin(self.fitness)] - self.pop[i]) + c2 * r2 * (self.best_position - self.pop[i])  #Simplified Velocity Calculation\n        self.pop[i] += velocity\n\n        self.pop[i] = np.clip(self.pop[i], func.bounds.lb, func.bounds.ub)\n\n        f = func(self.pop[i])\n        self.eval_count += 1\n\n        if f < self.fitness[i]:\n            self.fitness[i] = f\n            if f < self.best_fitness:\n                self.best_fitness = f\n                self.best_position = self.pop[i].copy()\n\n    def de_update(self, i, func):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.pop[idxs]\n        F = 0.5 # Mutation factor\n        CR = 0.7 # Crossover rate\n        \n        mutant = x1 + F * (x2 - x3)\n        trial_vector = np.copy(self.pop[i])\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < CR or j == j_rand:\n                trial_vector[j] = mutant[j]\n        \n        trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n        \n        f_trial = func(trial_vector)\n        self.eval_count += 1\n        \n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.pop[i] = trial_vector.copy()\n            if f_trial < self.best_fitness:\n                self.best_fitness = f_trial\n                self.best_position = self.pop[i].copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    self.pso_update(i, func)\n                else:\n                    self.de_update(i, func)\n        \n        return self.best_fitness, self.best_position", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DE scored 0.534 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f074407d-65e4-49c9-91ff-6bd706984e39"], "operator": null, "metadata": {"aucs": [0.1297718118542993, 0.17564871437523177, 0.8810311065681483, 0.9518457206875036, 0.2744967113266237, 0.8907851400849663, 0.3300487466645895, 0.503971991865511, 0.8813022088227301, 0.23613656456674592, 0.9347518919476507, 0.996256766683497, 0.2523295449564339, 0.2544137809165702, 0.5859127153686561, 0.3889896145624445, 0.3886638115228114, 0.9185511749254271, 0.2251922559120737, 0.4818364726746349]}}
{"id": "e1cc2031-7f91-41a5-9f99-ce1d2577a113", "fitness": 0.619589687380616, "name": "HybridPSO_DE", "description": "Simplified Hybrid PSO-DE, balancing exploration and exploitation with dynamic inertia and adaptive component selection, reducing complexity and parameter count.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c=2.0, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c = c  # Combined acceleration coefficient\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_idx = np.argmin(self.fitness)\n        self.best_fitness = self.fitness[self.best_idx]\n        self.best_position = self.pop[self.best_idx].copy()\n\n\n    def update_particle(self, i, w, func):\n        r1 = np.random.rand(self.dim)\n        \n        velocity = w * (self.pop[i] - self.pop[i]) + \\\n                             self.c * r1 * (self.best_position - self.pop[i])\n\n        self.pop[i] += velocity\n        self.pop[i] = np.clip(self.pop[i], func.bounds.lb, func.bounds.ub)\n\n        f = func(self.pop[i])\n        self.eval_count += 1\n\n        if f < self.fitness[i]:\n            self.fitness[i] = f\n            if f < self.best_fitness:\n                self.best_fitness = f\n                self.best_position = self.pop[i].copy()\n\n\n    def differential_evolution_mutation(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        while i in idxs:\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.pop[idxs]\n        v = x1 + self.F * (x2 - x3)\n        return v\n\n\n    def differential_evolution_crossover(self, i, mutant):\n        trial_vector = np.copy(self.pop[i])\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial_vector[j] = mutant[j]\n        return trial_vector\n\n    def update_de(self, i, func):\n        mutant = self.differential_evolution_mutation(i)\n        trial_vector = self.differential_evolution_crossover(i, mutant)\n        trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n        f_trial = func(trial_vector)\n        self.eval_count += 1\n\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.pop[i] = trial_vector.copy()\n            if f_trial < self.best_fitness:\n                self.best_fitness = f_trial\n                self.best_position = self.pop[i].copy()\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    self.update_particle(i, w, func)\n                else:\n                    self.update_de(i, func)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DE scored 0.620 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f074407d-65e4-49c9-91ff-6bd706984e39"], "operator": null, "metadata": {"aucs": [0.1110954920280659, 0.2031908485606696, 0.9007608012542618, 0.9570153619918459, 0.9091261819091125, 0.924213355922718, 0.32116741191515874, 0.5731432153927405, 0.9065220362084664, 0.2457833717940986, 0.9242956086914977, 0.9957013414492403, 0.34269727482363044, 0.3984548389122967, 0.7439541762568055, 0.9175602935803665, 0.3259434340674201, 0.9295789170885385, 0.21978288400055945, 0.5418069017648273]}}
{"id": "27c3d172-e021-462f-8ff9-a6f02ad3c334", "fitness": 0.541008157691712, "name": "HybridPSO_DE", "description": "Simplified hybrid PSO-DE algorithm with adaptive strategy selection and reduced parameter set for better performance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, F=0.6, CR=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (func.bounds.ub - func.bounds.lb) / 2\n\n        self.best_idx = np.argmin(self.fitness)\n        self.best_fitness = self.fitness[self.best_idx]\n        self.best_position = self.pop[self.best_idx].copy()\n\n    def pso_update(self, i, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n\n        self.velocities[i] = self.w * self.velocities[i] + \\\n                             self.c1 * r1 * (self.pop[i] - self.pop[i]) + \\\n                             self.c2 * r2 * (self.best_position - self.pop[i])\n\n        self.velocities[i] = np.clip(self.velocities[i], -(func.bounds.ub - func.bounds.lb) / 2, (func.bounds.ub - func.bounds.lb) / 2)\n\n        new_pos = self.pop[i] + self.velocities[i]\n        new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n        f = func(new_pos)\n        self.eval_count += 1\n\n        if f < self.fitness[i]:\n            self.fitness[i] = f\n            self.pop[i] = new_pos.copy()\n\n            if f < self.best_fitness:\n                self.best_fitness = f\n                self.best_position = new_pos.copy()\n\n    def de_update(self, i, func):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        while i in idxs:\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.pop[idxs]\n\n        mutant = x1 + self.F * (x2 - x3)\n        \n        j_rand = np.random.randint(self.dim)\n        trial_vector = np.copy(self.pop[i])\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial_vector[j] = mutant[j]\n\n        trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n        f_trial = func(trial_vector)\n        self.eval_count += 1\n\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.pop[i] = trial_vector.copy()\n            if f_trial < self.best_fitness:\n                self.best_fitness = f_trial\n                self.best_position = trial_vector.copy()\n    \n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    self.pso_update(i, func)\n                else:\n                    self.de_update(i, func)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DE scored 0.541 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f074407d-65e4-49c9-91ff-6bd706984e39"], "operator": null, "metadata": {"aucs": [0.1967027864258597, 0.3673274402300273, 0.460427045243085, 0.7957647042086227, 0.5361109534741112, 0.6680830116764829, 0.35576570128653473, 0.4317610412692272, 0.5007742372497779, 0.4790149955636094, 0.7416282969414916, 0.9991703500108197, 0.3631989771082801, 0.5247753393464547, 0.8610931703076142, 0.6424217180412717, 0.4069601540135577, 0.73834247692166, 0.2550400279478756, 0.49580072656787266]}}
{"id": "fd38e565-1cc9-4f1a-b7fe-f32e2d6dc541", "fitness": 0.724692051635232, "name": "HybridPSO_DE", "description": "A simplified hybrid PSO-DE algorithm with adaptive component selection and parameter control for exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c=2.0, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c = c\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n\n    def pso_update(self, i, w, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n\n        velocity = w * (self.pop[i] - self.pop[i]) + self.c * r1 * (self.pop[i] - self.pop[i]) + self.c * r2 * (self.best_position - self.pop[i]) #Simplified velocity update\n        new_pos = self.pop[i] + velocity\n        new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n        f = func(new_pos)\n        self.eval_count += 1\n\n        if f < self.fitness[i]:\n            self.fitness[i] = f\n            self.pop[i] = new_pos.copy()\n\n            if f < self.best_fitness:\n                self.best_fitness = f\n                self.best_position = new_pos.copy()\n\n    def de_update(self, i, func):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.pop[idxs]\n        mutant = x1 + self.F * (x2 - x3)\n        \n        j_rand = np.random.randint(self.dim)\n        trial_vector = np.copy(self.pop[i])\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial_vector[j] = mutant[j]\n        \n        trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n        f_trial = func(trial_vector)\n        self.eval_count += 1\n        \n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.pop[i] = trial_vector.copy()\n\n            if f_trial < self.best_fitness:\n                self.best_fitness = f_trial\n                self.best_position = trial_vector.copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            w = self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    self.pso_update(i, w, func)\n                else:\n                    self.de_update(i, func)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DE scored 0.725 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f074407d-65e4-49c9-91ff-6bd706984e39"], "operator": null, "metadata": {"aucs": [0.3624024192068436, 0.8021804251010176, 0.8215895956585996, 0.2630200707305649, 0.8780383257786027, 0.9208619941026258, 0.84085369122426, 0.7662821898934455, 0.8854613645122253, 0.8818328850820205, 0.9255852930941293, 0.9991097508245462, 0.31961088989209685, 0.36958007167823226, 0.9425482730165667, 0.9236121715748673, 0.8282132171471388, 0.9323600842333298, 0.3406775674405732, 0.4900207525129532]}}
{"id": "f2f3e0e6-6a75-43ae-8661-778b4121d5ca", "fitness": 0.6774489476650432, "name": "AdaptiveDE", "description": "Simplified adaptive differential evolution with self-adaptive mutation factor and crossover rate based on successful updates.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                mutated = x_r1 + self.F * (x_r2 - x_r3)\n                mutated = np.clip(mutated, func.bounds.lb, func.bounds.ub)\n\n                crossed = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        crossed[j] = mutated[j]\n                    else:\n                        crossed[j] = self.pop[i, j]\n\n                f_new = func(crossed)\n                self.eval_count += 1\n\n                if f_new < self.fitness[i]:\n                    self.pop[i] = crossed\n                    self.fitness[i] = f_new\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = crossed\n                    self.F = np.random.normal(0.5, 0.1)\n                    self.CR = np.random.normal(0.9, 0.1)\n                \n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n                \n                if self.eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.677 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f01c7ac7-3342-441e-818b-2c2ccbb8fe7e"], "operator": null, "metadata": {"aucs": [0.2627883412996398, 0.6131771212691457, 0.6583888742837253, 0.8487390463647, 0.745517567580414, 0.7947580253701665, 0.6342796203039227, 0.6305897889713028, 0.7056556297109297, 0.6509592778639132, 0.8492989892289489, 0.9921865473634033, 0.515234210673343, 0.715258817228595, 0.9078280981067585, 0.7693115594246837, 0.5472666095771543, 0.829971998570855, 0.22530790685909308, 0.6524609232501707]}}
{"id": "84ebb88d-905c-43b5-903c-4afd6608d338", "fitness": 0.6978721734234321, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a focus on reducing complexity and improving efficiency by streamlining the mutation and selection phases, and removing the archive.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                  break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.698 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["abea0991-2535-459e-a3e3-1b41aca82e6f"], "operator": null, "metadata": {"aucs": [0.26595394511220527, 0.6847149496880718, 0.6799279114437355, 0.8792236845536878, 0.745325435627844, 0.778372805082036, 0.6333922743247413, 0.6524719393099434, 0.7383905887954678, 0.7061311379897373, 0.8725681128702452, 0.9982901251718764, 0.6804098558801462, 0.6930408768866607, 0.8970299145304315, 0.7901655605565783, 0.635147063671852, 0.8613110945824024, 0.24353543048867077, 0.5220407619023073]}}
{"id": "ddb20cdf-f96e-4b61-a8de-cf3094a910d9", "fitness": 0.6766949374895942, "name": "HybridPSO_DE", "description": "Simplified Hybrid PSO-DE by removing the velocity update and using only DE mutation/crossover, focusing on efficient exploration and exploitation within bounds.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = cr # Crossover rate\n        self.f = f   # Mutation factor\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Initialize best position and fitness\n        best_idx = np.argmin(fitness)\n        best_pos = pop[best_idx].copy()\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (DE component)\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = pop[idxs[0]], pop[idxs[1]], pop[idxs[2]]\n                mutant = x1 + self.f * (x2 - x3)\n                \n                # Crossover (DE component)\n                trial = pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                # Ensure trial vector stays within bounds\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                self.budget -= 1\n                \n                # Selection (DE component)\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial.copy()\n                    fitness[i] = trial_fitness\n                    \n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_pos = trial.copy()\n                        best_fitness = trial_fitness\n            \n        return best_fitness, best_pos", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DE scored 0.677 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["21b574e2-c479-487d-ac5b-9bc2a5020072"], "operator": null, "metadata": {"aucs": [0.23967949280701117, 0.39672767393990327, 0.7387594546009635, 0.8676301626155123, 0.775183186759044, 0.8086886643755213, 0.6023786958103372, 0.694495957872594, 0.7360770391648629, 0.7346451161075902, 0.8711748219717559, 0.995944661482546, 0.40256873890213496, 0.7361861523001261, 0.910431230969794, 0.8096940619483626, 0.6046749786856145, 0.8547302802638039, 0.22927864988535018, 0.524949729329058]}}
{"id": "5c72e8d7-d090-4568-b8cf-ca17f9c27a05", "fitness": 0.42883429364030584, "name": "HybridPSO_DE", "description": "Simplified hybrid PSO-DE algorithm with self-adaptive parameter tuning for exploration-exploitation balance and reduced function evaluations.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=40):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.eval_count = 0\n        self.w = 0.7  # Inertia weight for PSO\n        self.c = 1.5  # Cognitive and social coefficients for PSO\n        self.F = 0.6  # Mutation factor for DE\n        self.CR = 0.8 # Crossover rate for DE\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n\n    def pso_update(self, i, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n\n        velocity = self.w * (self.pop[i] - self.pop[i]) + self.c * r1 * (self.best_position - self.pop[i]) + self.c * r2 * (self.best_position - self.pop[i])  # Simplified velocity update, more emphasis on best_position\n        new_pos = self.pop[i] + velocity\n        new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n\n        f = func(new_pos)\n        self.eval_count += 1\n\n        if f < self.fitness[i]:\n            self.fitness[i] = f\n            self.pop[i] = new_pos.copy()\n\n            if f < self.best_fitness:\n                self.best_fitness = f\n                self.best_position = new_pos.copy()\n\n    def de_update(self, i, func):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.pop[idxs]\n        mutant = x1 + self.F * (x2 - x3)\n\n        j_rand = np.random.randint(self.dim)\n        trial_vector = np.copy(self.pop[i])\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial_vector[j] = mutant[j]\n\n        trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n        f_trial = func(trial_vector)\n        self.eval_count += 1\n\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.pop[i] = trial_vector.copy()\n\n            if f_trial < self.best_fitness:\n                self.best_fitness = f_trial\n                self.best_position = trial_vector.copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive strategy: favor PSO early, DE later\n            if self.eval_count / self.budget < 0.6:\n                for i in range(self.pop_size):\n                    self.pso_update(i, func)\n            else:\n                for i in range(self.pop_size):\n                    self.de_update(i, func)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSO_DE scored 0.429 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["fd38e565-1cc9-4f1a-b7fe-f32e2d6dc541"], "operator": null, "metadata": {"aucs": [0.19379256148770485, 0.24949786854665357, 0.8917361429924918, 0.17261082808017714, 0.17979212622079066, 0.2842507550879858, 0.25019376060037934, 0.5287497498784675, 0.9250049800538493, 0.22910678824952913, 0.20730518627710204, 0.995059957002027, 0.3353985804620925, 0.25445510421781237, 0.7377750907768823, 0.3568361016583047, 0.8418876171735001, 0.2908861695117265, 0.15975030879161334, 0.4925961957370275]}}
{"id": "03bed4a2-61a7-43c0-bb13-de42f2011f3a", "fitness": 0.653670345638823, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and focus on exploitation by reducing population diversity through a smaller population size and increased crossover rate.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                \n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                  break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.654 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ea15ceeb-e891-4196-ac4e-266b145f2bbf"], "operator": null, "metadata": {"aucs": [0.3207497801361726, 0.39369172604494074, 0.6423171291063985, 0.9363524699798684, 0.8945531537926433, 0.9184456469898296, 0.8632095570356736, 0.3547293011529078, 0.8481300216987465, 0.47272650762349566, 0.9484426039358007, 0.9983512807713736, 0.30534117623899937, 0.8546980908282806, 0.5848375358866345, 0.3599663013812001, 0.761686703276789, 0.7689918632684776, 0.30993323741335177, 0.5362528262148757]}}
{"id": "ef0a3156-5e4a-496f-b872-a83df076e549", "fitness": 0.7038354906866734, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters F and Cr based on a success rate, and reduced memory usage.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        \n        success_F = []\n        success_Cr = []\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    success_F.append(self.F)\n                    success_Cr.append(self.Cr)\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n            #Adapt F and Cr after each generation\n            if success_F and self.evals >= self.pop_size:\n                self.F = 0.9 * self.F + 0.1 * np.mean(success_F)\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.Cr = 0.9 * self.Cr + 0.1 * np.mean(success_Cr)\n                self.Cr = np.clip(self.Cr, 0.1, 0.9)\n                success_F = []\n                success_Cr = []\n\n            if self.evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.704 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5435b791-2379-4bd2-8ca8-3ec2f45fb8eb"], "operator": null, "metadata": {"aucs": [0.36579743973598566, 0.6512410838697511, 0.7014933108950664, 0.877057804074569, 0.7670664610016189, 0.7836371494695314, 0.6505580287974337, 0.6592342949407362, 0.7470626178724702, 0.7019716588072252, 0.8289316471979193, 0.9945064382497609, 0.6813944105475487, 0.7320882661037206, 0.937476381435873, 0.7800509112719612, 0.6155467229289073, 0.8425711151379701, 0.25243803847499213, 0.5065860329204261]}}
{"id": "c47312bb-1167-4662-9469-9ecfa0deabd5", "fitness": 0.7071660369580833, "name": "AdaptiveDE", "description": "Simplified Differential Evolution with dynamic F and Cr adaptation based on population diversity and success history.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, F_adapt=True, Cr_adapt=True):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.F_adapt = F_adapt\n        self.Cr_adapt = Cr_adapt\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.success_history_F = []\n        self.success_history_Cr = []\n\n\n        while self.evals < self.budget:\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_history_F.append(self.F)\n                    self.success_history_Cr.append(self.Cr)\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                  break\n            \n            #Adapt F and Cr\n            if self.F_adapt and self.success_history_F:\n                self.F = np.clip(np.mean(self.success_history_F), 0.1, 0.9)\n                self.success_history_F = []\n            if self.Cr_adapt and self.success_history_Cr:\n                self.Cr = np.clip(np.mean(self.success_history_Cr), 0.1, 0.9)\n                self.success_history_Cr = []\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.707 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["84ebb88d-905c-43b5-903c-4afd6608d338"], "operator": null, "metadata": {"aucs": [0.24839773176550606, 0.6890710847762274, 0.6777121681815302, 0.8941858886973096, 0.743744031383858, 0.7665676269594538, 0.6570072616079696, 0.6582374873895775, 0.740903062026941, 0.6635045098965058, 0.8666702589589117, 0.9816356627512053, 0.6541224251236359, 0.6995068217720508, 0.9124919363256493, 0.7834635548258237, 0.6175764249451419, 0.8411990487076274, 0.5227131231737897, 0.5246106298929518]}}
{"id": "d611878a-0a68-4614-a3b5-352644273818", "fitness": 0.5845430446635044, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters, focusing on minimal complexity and efficient adaptation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                    self.F = 0.9 * self.F + 0.1 * np.random.rand()  # Adapt F\n                    self.Cr = 0.9 * self.Cr + 0.1 * np.random.rand() # Adapt Cr\n                    self.F = np.clip(self.F, 0.1, 0.9)\n                    self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n                if self.evals >= self.budget:\n                  break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.585 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5435b791-2379-4bd2-8ca8-3ec2f45fb8eb"], "operator": null, "metadata": {"aucs": [0.20894746297526778, 0.2875400241801336, 0.5645961622849116, 0.8242294660348409, 0.6568164769457475, 0.7147019136473798, 0.5085552555707855, 0.5470090756566801, 0.677505149964845, 0.4619455076197264, 0.6773210397241824, 0.9902306839784222, 0.3258948680304449, 0.5770635953333143, 0.8490081577959272, 0.7448220991747299, 0.4844484614411103, 0.8044534104006786, 0.2769810481229049, 0.5087910343880544]}}
{"id": "c0d125c4-189c-45b6-ad97-72fb793eeb16", "fitness": 0.5296039438949299, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on population diversity and success history.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.F_memory = [F] * 10\n        self.Cr_memory = [Cr] * 10\n        self.memory_idx = 0\n\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            successful_F = []\n            successful_Cr = []\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    successful_F.append(self.F)\n                    successful_Cr.append(self.Cr)\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr\n            if successful_F:\n                self.F = np.mean(successful_F)\n                self.Cr = np.mean(successful_Cr)\n                self.F = 0.1 + 0.9 * self.F # ensure F is not too small\n                self.Cr = np.clip(self.Cr, 0, 1) #ensure Cr is in [0,1]\n            else:\n                self.F = 0.5 #reset to default value\n                self.Cr = 0.9 #reset to default value\n\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.Cr = np.clip(self.Cr, 0.0, 1.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.530 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ea15ceeb-e891-4196-ac4e-266b145f2bbf"], "operator": null, "metadata": {"aucs": [0.22993286356975973, 0.45945590989174256, 0.4203162729208315, 0.7508377497086183, 0.5028334505945498, 0.5859033144122884, 0.39331756954519825, 0.4232094040180321, 0.4845769144033101, 0.4486347728484381, 0.7236463103853245, 0.9997370285760596, 0.4510923628937411, 0.4626269622138348, 0.8697660534611733, 0.5642916698969835, 0.4231394660158301, 0.6265008814723523, 0.24782642591246817, 0.5244334951580626]}}
{"id": "8e70e441-3bfb-4b77-942a-0155c01b691f", "fitness": 0.3954659503621091, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified mutation, crossover, and parameter adaptation based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9, F_adapt=True, Cr_adapt=True):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.F_adapt = F_adapt\n        self.Cr_adapt = Cr_adapt\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Adaptive F and Cr based on population diversity\n            if self.F_adapt:\n                self.F = 0.5 * (1 + np.std(self.fitness) / (np.mean(self.fitness) + 1e-8))\n            if self.Cr_adapt:\n                self.Cr = 0.1 + 0.8 * np.exp(-16 * np.std(self.fitness) / (np.max(self.fitness) - np.min(self.fitness) + 1e-8))\n                self.Cr = np.clip(self.Cr, 0.0, 1.0)\n\n\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                u[mask] = v[mask]\n                \n                # Ensure at least one element is different\n                if not np.any(mask):\n                    j_rand = np.random.randint(self.dim)\n                    u[j_rand] = v[j_rand]\n\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                  break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.395 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ea15ceeb-e891-4196-ac4e-266b145f2bbf"], "operator": null, "metadata": {"aucs": [0.1675176177526857, 0.2354409804899369, 0.39322300387872466, 0.2828036128352137, 0.3359621748368846, 0.4639417261170433, 0.3292098405813374, 0.3751672360428344, 0.3139813212028346, 0.2139777868785694, 0.3366077101024716, 0.9984509412036606, 0.288086165028565, 0.3028643793198095, 0.7823100330203522, 0.5992655336650394, 0.31310964957150145, 0.49763770934130047, 0.19448301607556917, 0.4852785692978461]}}
{"id": "be07fd46-19e3-4891-b66a-d0bdf7770513", "fitness": 0.41334402522534636, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified mutation and parameter adaptation based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.archive_factor = 0.1 #introduce an archive to improve diversity and avoid getting trapped in local minima\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.archive_size = int(self.pop_size * self.archive_factor)\n        self.archive = np.empty((self.archive_size, self.dim))\n        self.archive_fitness = np.full(self.archive_size, np.inf) # Initialize with a high value\n        archive_idx = 0\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation (simplified: use only two random individuals)\n                idx = np.random.choice(self.pop_size, size=2, replace=False)\n                x1, x2 = self.pop[idx[0]], self.pop[idx[1]]\n                \n                # Use archive if available\n                if len(self.archive) > 0 and np.random.rand() < 0.1: #Small probability for using the archive.\n                    arch_idx = np.random.randint(len(self.archive))\n                    x3 = self.archive[arch_idx]\n                    v = self.pop[i] + self.F * (x1 - x2)+ self.F*(x3-self.pop[i])  #exploit from the archive\n\n                else:\n                    v = self.pop[i] + self.F * (x1 - x2)\n                    \n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    #Archive update\n                    if f_u < self.archive_fitness.max():  # Only add if better than the worst in the archive\n                        max_index = np.argmax(self.archive_fitness)\n                        self.archive[max_index] = self.pop[i]\n                        self.archive_fitness[max_index] = self.fitness[i]\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                  break\n            \n            # Parameter adaptation (simple adaptation based on population diversity)\n            if np.std(self.fitness) < 1e-3:  # If population is too uniform, increase exploration\n                self.F = min(self.F * 1.1, 1.0)\n                self.Cr = max(self.Cr * 0.9, 0.1)\n            else:  # Otherwise, focus on exploitation\n                self.F = max(self.F * 0.9, 0.1)\n                self.Cr = min(self.Cr * 1.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.413 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["84ebb88d-905c-43b5-903c-4afd6608d338"], "operator": null, "metadata": {"aucs": [0.11709235472824397, 0.3375384104502035, 0.4181765116972872, 0.5308288152155742, 0.29448106727493106, 0.4316069390802201, 0.2841701049530796, 0.3293457556328069, 0.3127239140850634, 0.22186084366825876, 0.5870054860544953, 0.9912974852831654, 0.4341033739298217, 0.28943237368801356, 0.7766233736623686, 0.37887858486162873, 0.3351865347856413, 0.5290470743227963, 0.18280525740806974, 0.48467624372525775]}}
{"id": "ddfbcd26-0b87-4172-bd42-54d5558a9432", "fitness": 0.7283191096395855, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters and reduced population diversity maintenance.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.F_memory = np.full(self.pop_size, self.F)\n        self.Cr_memory = np.full(self.pop_size, self.Cr)\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                self.F = self.F_memory[i] + 0.1 * np.random.normal()\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.Cr = self.Cr_memory[i] + 0.1 * np.random.normal()\n                self.Cr = np.clip(self.Cr, 0.1, 1.0)\n                \n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    self.F_memory[i] = self.F  # Store successful F\n                    self.Cr_memory[i] = self.Cr # Store successful CR\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                  break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.728 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ea15ceeb-e891-4196-ac4e-266b145f2bbf"], "operator": null, "metadata": {"aucs": [0.32706003098680425, 0.7830183855105547, 0.6263144476361421, 0.8872530214265973, 0.8064329786487219, 0.8112076568531517, 0.6897085428583949, 0.6442437442956847, 0.76212166938682, 0.739400872456436, 0.8762308026342194, 0.9937156478896403, 0.6816356294277197, 0.712329029715917, 0.8880342601935967, 0.8479258503176292, 0.6168452584523281, 0.8622375478970288, 0.4799597247295988, 0.530707091474725]}}
{"id": "6276eca8-1a4e-4d1e-9749-71bf531fdb2f", "fitness": 0.3163339339531325, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on exponentially weighted averages and a rank-based selection to improve convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.F_mem = [F] * 5  # Memory for F adaptation\n        self.Cr_mem = [Cr] * 5 # Memory for Cr adaptation\n        self.mem_idx = 0\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        \n        while self.evals < self.budget:\n            ranked_indices = np.argsort(self.fitness)\n            \n            for i in range(self.pop_size):\n                # Mutation\n                donor_idx = np.random.choice(ranked_indices[:min(5, self.pop_size)], size=3, replace=False) # Rank-based selection\n                x1, x2, x3 = self.pop[donor_idx[0]], self.pop[donor_idx[1]], self.pop[donor_idx[2]]\n\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                #Adapt F and Cr using exponential weighted average\n                w = np.exp(np.linspace(0, -5, 5))\n                w /= w.sum()\n              \n                self.F = 0.8 * self.F + 0.2 * np.mean(self.F_mem) \n                self.Cr = 0.8 * self.Cr + 0.2 * np.mean(self.Cr_mem) \n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.Cr = np.clip(self.Cr, 0.1, 0.9)\n                \n                self.F_mem[self.mem_idx] = self.F\n                self.Cr_mem[self.mem_idx] = self.Cr\n                self.mem_idx = (self.mem_idx + 1) % 5\n                \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.316 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5435b791-2379-4bd2-8ca8-3ec2f45fb8eb"], "operator": null, "metadata": {"aucs": [0.09948702175428459, 0.34073659542158774, 0.2839682460168076, 0.25690558219591997, 0.25466701153473026, 0.37147375632434354, 0.28731423439037473, 0.31107147698430127, 0.5153740348184992, 0.1395923141171932, 0.2727778977339692, 0.997192064110993, 0.2571242014499794, 0.25680153671120665, 0.17627881722045458, 0.31697747570895385, 0.2528669383963289, 0.2267841956310812, 0.21134918115034496, 0.49793609739129574]}}
{"id": "345cc939-9a80-4049-a681-b4478b76ff67", "fitness": 0.5347461548137747, "name": "AdaptiveDE", "description": "Simplified Differential Evolution with adaptive scaling factor and crossover rate based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Adaptive F and Cr\n            if np.std(self.fitness) > 0:\n                self.F = 0.5 + 0.3 * np.random.rand() # Adaptive F\n                self.Cr = 0.1 + 0.8 * np.random.rand()  # Adaptive Cr\n\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                  break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.535 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["84ebb88d-905c-43b5-903c-4afd6608d338"], "operator": null, "metadata": {"aucs": [0.17875941412917395, 0.2880496636224472, 0.47539982798913494, 0.7591587824888808, 0.5447957632005866, 0.6854136629208347, 0.4024813334346443, 0.48074754163097677, 0.5524342068860859, 0.46774888958113603, 0.6765623022603715, 0.9984187992978579, 0.28977735686037154, 0.5000282574662228, 0.8299640911145418, 0.6915304035377263, 0.42892246258849753, 0.7327723802308008, 0.2097586623361265, 0.5021992946990765]}}
{"id": "08194c5c-6f5b-489b-9081-a5a386373ba5", "fitness": 0.6973177934324786, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters and reduced memory usage by directly updating F and Cr based on recent success.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.success_F = []\n        self.success_Cr = []\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        \n                #Adapt F and Cr online based on recent successes\n                if len(self.success_F) > 5 and self.evals % self.pop_size == 0:\n                    self.F = 0.8 * self.F + 0.2 * np.mean(self.success_F)\n                    self.Cr = 0.8 * self.Cr + 0.2 * np.mean(self.success_Cr)\n                    self.F = np.clip(self.F, 0.1, 0.9)\n                    self.Cr = np.clip(self.Cr, 0.1, 0.9)\n                    self.success_F = []\n                    self.success_Cr = []\n\n                if self.evals >= self.budget:\n                  break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.697 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5435b791-2379-4bd2-8ca8-3ec2f45fb8eb"], "operator": null, "metadata": {"aucs": [0.2765067605947432, 0.6748179227246374, 0.6675945670417323, 0.8660897511403354, 0.7411989603834697, 0.8035210613107773, 0.6448780832109464, 0.6665913509200008, 0.7513101326089446, 0.6927807414473435, 0.8584028176177175, 0.9975257662936472, 0.6323957136189644, 0.7201970171977052, 0.9173011109127915, 0.7645489384205294, 0.631488612884528, 0.8292317224749457, 0.23824770260781825, 0.5717271352379925]}}
{"id": "5b935556-9e85-4ebd-8a71-48c88248db8a", "fitness": 0.0, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with per-vector, direct adaptation of F and CR based on success, and reduced diversity maintenance by occasionally perturbing best solution.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9, perturb_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.F_memory = np.full(self.pop_size, self.F)\n        self.Cr_memory = np.full(self.pop_size, self.Cr)\n        self.perturb_rate = perturb_rate\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                \n                # Parameter adaptation (direct update)\n                F = self.F_memory[i] + 0.1 * np.random.normal()\n                F = np.clip(F, 0.1, 1.0)\n                Cr = self.Cr_memory[i] + 0.1 * np.random.normal()\n                Cr = np.clip(Cr, 0.1, 1.0)\n                \n                v = x1 + F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    self.F_memory[i] = F  # Store successful F\n                    self.Cr_memory[i] = Cr # Store successful CR\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n            # Perturb the best solution occasionally to increase diversity\n            if np.random.rand() < self.perturb_rate:\n                idx = np.argmin(self.fitness)\n                self.pop[idx] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                self.fitness[idx] = func(self.pop[idx])\n                self.evals += 1\n\n                if self.fitness[idx] < self.f_opt:\n                    self.f_opt = self.fitness[idx]\n                    self.x_opt = self.pop[idx]\n\n            if self.evals >= self.budget:\n                break\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ddfbcd26-0b87-4172-bd42-54d5558a9432"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "e04f3c6f-052e-425d-a484-c6ed885da073", "fitness": 0.7116734568405205, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive F and Cr based on exponential moving averages and aggressive updates only upon successful improvements, further reducing complexity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, alpha_F=0.1, alpha_Cr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.alpha_F = alpha_F\n        self.alpha_Cr = alpha_Cr\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Update F and Cr using exponential moving average\n                    self.F = (1 - self.alpha_F) * self.F + self.alpha_F * self.F # Keep the same F\n                    self.Cr = (1 - self.alpha_Cr) * self.Cr + self.alpha_Cr * self.Cr # Keep the same Cr\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.712 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c47312bb-1167-4662-9469-9ecfa0deabd5"], "operator": null, "metadata": {"aucs": [0.3542494156468019, 0.6464421337738468, 0.6662412846076429, 0.885830004299969, 0.7485443480743547, 0.7696600256525975, 0.6233074670288976, 0.6688116845948411, 0.7325376092490028, 0.7183650705674173, 0.8744202644844231, 0.9961211960380185, 0.6601407331360729, 0.7526832014369214, 0.9190554565802436, 0.782856024051932, 0.6487758497517474, 0.8478785068501287, 0.41420908868333295, 0.5233397723022185]}}
{"id": "e6c2dec3-43f4-4a9f-896e-299424a74b97", "fitness": 0.5987091092977701, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a single set of self-adaptive parameters (F and Cr) for the whole population, and clipped parameter updates, focusing on efficiency.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Parameter adaptation (global)\n            self.F = np.clip(self.F + 0.1 * np.random.normal(), 0.1, 1.0)\n            self.Cr = np.clip(self.Cr + 0.1 * np.random.normal(), 0.1, 1.0)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                  break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.599 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ddfbcd26-0b87-4172-bd42-54d5558a9432"], "operator": null, "metadata": {"aucs": [0.22397937691445247, 0.43952113811820503, 0.3940330230550154, 0.9011330943590999, 0.6799963555457562, 0.6280360209460341, 0.6300569227560748, 0.6215220278022143, 0.6533708633889366, 0.4020085220564741, 0.8121955301761101, 0.9953607173539464, 0.6014931259947995, 0.6674865461985131, 0.7085296196158913, 0.7434940356702215, 0.38195894218507265, 0.7566032856745427, 0.2147400421582658, 0.518662995985778]}}
{"id": "309a0c82-50e5-497f-afd0-a1410693ac94", "fitness": 0.5858765067516326, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and reduced memory footprint, focusing on immediate success for parameter updates.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr immediately upon success\n                    self.F = 0.8 * self.F + 0.2 * np.random.rand() # Simplified F adaptation\n                    self.Cr = 0.8 * self.Cr + 0.2 * np.random.rand() # Simplified Cr adaptation\n                    self.F = np.clip(self.F, 0.1, 0.9)\n                    self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                  break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.586 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["08194c5c-6f5b-489b-9081-a5a386373ba5"], "operator": null, "metadata": {"aucs": [0.20253331757978166, 0.3111460028787868, 0.5593284911405898, 0.7895732944760537, 0.6589322149560839, 0.7453135123001025, 0.5500218514564253, 0.5503020799827825, 0.6479594252129244, 0.5207080904866964, 0.7622095112862933, 0.9933794956244549, 0.28679515594294014, 0.5569263059871927, 0.8473988846269485, 0.7484122792427303, 0.46952344075191976, 0.7949177750590649, 0.20140646012174634, 0.5207425459191352]}}
{"id": "b1159159-076f-4ac5-ad78-b7475b967b9c", "fitness": 0.6981730692060798, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a single success history for both F and Cr, prioritizing recent successful parameter combinations.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, success_rate_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.success_rate_memory = success_rate_memory\n        self.success_history = []\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_history.append((self.F, self.Cr))\n                    if len(self.success_history) > self.success_rate_memory:\n                        self.success_history.pop(0)\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr\n            if self.success_history:\n                recent_successes = self.success_history[-min(len(self.success_history), self.success_rate_memory):]\n                avg_F = np.mean([F for F, Cr in recent_successes])\n                avg_Cr = np.mean([Cr for F, Cr in recent_successes])\n                \n                self.F = np.clip(avg_F, 0.1, 0.9)\n                self.Cr = np.clip(avg_Cr, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.698 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c47312bb-1167-4662-9469-9ecfa0deabd5"], "operator": null, "metadata": {"aucs": [0.33876046232911416, 0.6908614302059504, 0.654467922684107, 0.8916661505145422, 0.7169184782113763, 0.7857535456607366, 0.610982875108292, 0.6715980786032778, 0.7402826918192531, 0.7343443239592726, 0.8272602087082414, 0.9943565427286573, 0.6708568825724568, 0.7056567723239122, 0.8664419203146729, 0.755609982428577, 0.6221883674321188, 0.8402880360975971, 0.3250143875529269, 0.5201523248665137]}}
{"id": "4aa81b43-7663-4ddc-9ed7-4162d183f45e", "fitness": 0.5819881632156951, "name": "AdaptiveDE", "description": "Simplified Differential Evolution with adaptive F and Cr parameters based on recent success, directly updating them without history storage for faster adaptation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                    # Adapt F and Cr immediately upon success\n                    self.F = 0.9 * self.F + 0.1 * np.random.rand()\n                    self.Cr = 0.9 * self.Cr + 0.1 * np.random.rand()\n                    self.F = np.clip(self.F, 0.1, 0.9)\n                    self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.582 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c47312bb-1167-4662-9469-9ecfa0deabd5"], "operator": null, "metadata": {"aucs": [0.1985969974498064, 0.34203494266452394, 0.5328731952697017, 0.8008015434661424, 0.6757241396660134, 0.7267745241304688, 0.4780135533640988, 0.5437632128705876, 0.6500432604787232, 0.5270923638938806, 0.7357512888822293, 0.9986295568982336, 0.2695179118758616, 0.5738303127094813, 0.839280445253629, 0.7239739411482015, 0.5202425854306779, 0.7925504643418853, 0.19668000484742376, 0.5135890196723332]}}
{"id": "cc53956d-3c80-4df2-8da7-d17c8c43c5b3", "fitness": 0.5888645408240193, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with reduced parameter adaptation frequency and focused population updates, leveraging best-so-far information.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9, adapt_freq=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.adapt_freq = adapt_freq # Reduced adaptation frequency\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.evals = 0\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Parameter adaptation (less frequent)\n                if np.random.rand() < self.adapt_freq:\n                    F = self.F + 0.1 * np.random.normal()\n                    F = np.clip(F, 0.1, 1.0)\n                    Cr = self.Cr + 0.1 * np.random.normal()\n                    Cr = np.clip(Cr, 0.1, 1.0)\n                else:\n                    F = self.F\n                    Cr = self.Cr\n                \n                # Mutation using best solution\n                idx = np.random.choice(self.pop_size, size=2, replace=False)\n                x1, x2 = self.pop[idx[0]], self.pop[idx[1]]\n                v = self.x_opt + F * (x1 - x2)  # Use x_opt for mutation\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                  break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.589 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ddfbcd26-0b87-4172-bd42-54d5558a9432"], "operator": null, "metadata": {"aucs": [0.35453819834903044, 0.22406021922493424, 0.9200157555174444, 0.9764433527643352, 0.2703179405122911, 0.23564424662882477, 0.28407156731226946, 0.7227658419908285, 0.3359464667484142, 0.9425163316362745, 0.9731890985453032, 0.996452269630021, 0.2604948968013948, 0.4203104799725442, 0.9771717580293996, 0.3351499059576343, 0.8784986823031863, 0.9594237790012394, 0.2385890893286261, 0.47169093622639013]}}
{"id": "4c3b1982-7363-44cb-b5a8-afefd4c5b8a0", "fitness": 0.5602168111957001, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with success-history based parameter adaptation and reduced population diversity enhancement using a perturbing vector.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.success_F = []\n        self.success_Cr = []\n\n\n        while self.evals < self.budget:\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, size=3, replace=False)\n                a, b, c = self.pop[idxs]\n                mutant = a + self.F * (b - c)\n\n                # Perturbing vector for diversity enhancement.\n                perturb = np.random.normal(0, 0.01, self.dim)\n                mutant = np.clip(mutant + perturb, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.Cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if self.evals >= self.budget:\n                    break\n            \n            #Adapt F and Cr based on success\n            if self.success_F:\n                self.F = 0.9 * np.mean(self.success_F) + 0.1 * self.F\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.success_F = []\n\n            if self.success_Cr:\n                self.Cr = 0.9 * np.mean(self.success_Cr) + 0.1 * self.Cr\n                self.Cr = np.clip(self.Cr, 0.1, 0.9)\n                self.success_Cr = []\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.560 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c47312bb-1167-4662-9469-9ecfa0deabd5"], "operator": null, "metadata": {"aucs": [0.2242777875637001, 0.5214360709894088, 0.5024103954449594, 0.8804100698706748, 0.488007223640762, 0.5923731888594284, 0.3709124165951734, 0.4380165557237067, 0.4978115349131629, 0.4074429389318054, 0.86120593157891, 0.996563230219237, 0.3983832887643327, 0.5228394495342004, 0.9246040193456287, 0.5741688644022216, 0.4528195147032027, 0.7060405597077795, 0.32594506034600035, 0.5186681227797052]}}
{"id": "3eedcc49-7435-4ccc-8de4-d98d71005098", "fitness": 0.7078727499282823, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive F and Cr based on success, combined with a simple population diversity check to trigger parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.success_F = []\n        self.success_Cr = []\n        self.diversity_threshold = 0.01  # Adjust as needed\n\n        while self.evals < self.budget:\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                mask = np.random.rand(self.dim) < self.Cr\n                u[mask] = v[mask]\n                u[j_rand] = v[j_rand]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                if self.evals >= self.budget:\n                    break\n            \n            # Adapt F and Cr based on success and diversity\n            if len(self.success_F) > 0 and self.population_diversity() > self.diversity_threshold:\n                self.F = np.clip(np.mean(self.success_F), 0.1, 0.9)\n                self.Cr = np.clip(np.mean(self.success_Cr), 0.1, 0.9)\n                self.success_F = []\n                self.success_Cr = []\n\n        return self.f_opt, self.x_opt\n\n    def population_diversity(self):\n        \"\"\"Calculates a simple measure of population diversity.\"\"\"\n        return np.std(self.pop)", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.708 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c47312bb-1167-4662-9469-9ecfa0deabd5"], "operator": null, "metadata": {"aucs": [0.32119299300393855, 0.6726827866631956, 0.6986238238439788, 0.8483402950275398, 0.7552334926159641, 0.7903155783940504, 0.6707512927681705, 0.6698205931017207, 0.742602639151833, 0.718651097886805, 0.8607820475451204, 0.9988744395434477, 0.6654311132784342, 0.7366070157101899, 0.9119229675962841, 0.7758574634256029, 0.6223277259835137, 0.8352929873380702, 0.2934064776363441, 0.5687381680514425]}}
{"id": "9b4bb490-8545-4f71-8347-fc597596d2d2", "fitness": 0.582577917226719, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with individual learning rates, simplified parameter adaptation, and jittering to enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.F_memory = np.full(self.pop_size, self.F)\n        self.Cr_memory = np.full(self.pop_size, self.Cr)\n        self.lr = 0.1 # Individual learning rate for F and Cr\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Parameter adaptation with individual learning rate\n                self.F = self.F_memory[i] + self.lr * np.random.normal()\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.Cr = self.Cr_memory[i] + self.lr * np.random.normal()\n                self.Cr = np.clip(self.Cr, 0.1, 1.0)\n                \n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n\n                #Jittering to enhance exploration\n                v += np.random.normal(0, 0.01, self.dim)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    self.F_memory[i] = self.F  # Store successful F\n                    self.Cr_memory[i] = self.Cr # Store successful CR\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                  break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.583 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ddfbcd26-0b87-4172-bd42-54d5558a9432"], "operator": null, "metadata": {"aucs": [0.2726217719396409, 0.6015236096573164, 0.5286525230871464, 0.884718153075521, 0.5502888931460286, 0.6232759565442126, 0.4352292958859718, 0.486685067863768, 0.5440448300395534, 0.4990169480729266, 0.8616152660254638, 0.9976824148760568, 0.3721499602035514, 0.5210021447544648, 0.9081237051794105, 0.634092990969924, 0.4565695030276814, 0.7225925995988696, 0.23686730642121112, 0.5148054041656639]}}
{"id": "5175fabc-4674-4b2e-8cd6-ecc24154c373", "fitness": 0.5986034889810588, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified F and Cr adaptation based on a running average and reduced population diversity update.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n            #Adapt F and Cr online based on population update\n            self.F = 0.9 * self.F + 0.1 * np.random.rand() #Simple running average for F\n            self.Cr = 0.9 * self.Cr + 0.1 * np.random.rand() #Simple running average for Cr\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.599 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["08194c5c-6f5b-489b-9081-a5a386373ba5"], "operator": null, "metadata": {"aucs": [0.18862790636913385, 0.4394210434952749, 0.587693868455855, 0.8466221096323179, 0.6752057319369673, 0.7597977167569591, 0.45950846457037575, 0.5744125138880576, 0.6257533861937763, 0.6138944857637786, 0.7350355523985704, 0.9834732741841234, 0.27420594144607047, 0.6104170736661257, 0.8272759287592846, 0.7550401344248081, 0.46359766460917107, 0.8070596203417946, 0.23652444582526178, 0.508502916903468]}}
{"id": "45f85f67-6119-4dba-a1e4-271efac3fbe9", "fitness": 0.6844741417408623, "name": "AdaptiveDE", "description": "Simplified Differential Evolution with self-adaptive F and Cr based on a decaying average, with population diversity control through periodic re-initialization.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1, reinit_prob=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n        self.reinit_prob = reinit_prob\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr using decaying average\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * self.F  #No change to F\n                    self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * self.Cr #No change to Cr\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                # Re-initialize individual with small probability\n                if np.random.rand() < self.reinit_prob:\n                    self.pop[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                    self.fitness[i] = func(self.pop[i])\n                    self.evals += 1\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.pop[i]\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.684 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c47312bb-1167-4662-9469-9ecfa0deabd5"], "operator": null, "metadata": {"aucs": [0.2858887063753951, 0.6383743386454029, 0.6755885594150918, 0.8454881470766382, 0.7351740878411275, 0.7709668922887446, 0.6159307106436787, 0.6407778658006714, 0.743272014755986, 0.6792378406155819, 0.8474283603596523, 0.9917610947768082, 0.6278740829718625, 0.6882431583646096, 0.9206573064570053, 0.7802357727626933, 0.6076656822586737, 0.818176423495656, 0.2705045490901452, 0.5062372408218226]}}
{"id": "bdc8455b-5e43-48ef-93b7-c25a538669ab", "fitness": 0.0, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and a focused restart strategy based on fitness.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr simply by setting them to random values within a reasonable range\n                    self.F = np.random.uniform(0.3, 0.9)\n                    self.Cr = np.random.uniform(0.1, 1.0)\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                # Focused restart: replace worst individual if no improvement after some iterations\n                if np.random.rand() < self.restart_prob:\n                    worst_idx = np.argmax(self.fitness)\n                    self.pop[worst_idx] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                    self.fitness[worst_idx] = func(self.pop[worst_idx])\n                    self.evals += 1\n                    if self.fitness[worst_idx] < self.f_opt:\n                        self.f_opt = self.fitness[worst_idx]\n                        self.x_opt = self.pop[worst_idx]\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["45f85f67-6119-4dba-a1e4-271efac3fbe9"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "c5895dfa-76f3-4b2d-a04a-bb70797c14db", "fitness": 0.0, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive F and Cr based on success, using a weighted average for parameter adaptation and incorporating a local search step for intensification.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.success_F = []\n        self.success_Cr = []\n        self.F_memory = [self.F] * 5  # Store recent F values\n        self.Cr_memory = [self.Cr] * 5  # Store recent Cr values\n        self.memory_idx = 0\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                mask = np.random.rand(self.dim) < self.Cr\n                u[mask] = v[mask]\n                u[j_rand] = v[j_rand]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n            \n            # Local Search\n            if np.random.rand() < self.local_search_prob:\n                idx = np.random.randint(self.pop_size)\n                x_local = np.clip(self.pop[idx] + np.random.normal(0, 0.05, self.dim), self.lb, self.ub)\n                f_local = func(x_local)\n                self.evals += 1\n                if f_local < self.fitness[idx]:\n                    self.pop[idx] = x_local\n                    self.fitness[idx] = f_local\n                    if f_local < self.f_opt:\n                        self.f_opt = f_local\n                        self.x_opt = x_local\n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr based on success using weighted average\n            if len(self.success_F) > 0:\n                avg_F = np.mean(self.success_F)\n                avg_Cr = np.mean(self.success_Cr)\n\n                # Weighted average with memory\n                self.F_memory[self.memory_idx] = avg_F\n                self.Cr_memory[self.memory_idx] = avg_Cr\n                self.memory_idx = (self.memory_idx + 1) % 5\n\n                self.F = np.clip(np.mean(self.F_memory), 0.1, 0.9)\n                self.Cr = np.clip(np.mean(self.Cr_memory), 0.1, 0.9)\n\n                self.success_F = []\n                self.success_Cr = []\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3eedcc49-7435-4ccc-8de4-d98d71005098"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "2ae6d70b-c5f2-40fa-ba4c-e4655a126944", "fitness": 0.0, "name": "AdaptiveDE", "description": "Simplified Differential Evolution with adaptive F and Cr based on successful mutations, combined with population reduction to focus search.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1, reduction_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n        self.reduction_factor = reduction_factor # Introduce reduction factor\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        successful_F = []\n        successful_Cr = []\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n\n                # Sample F and Cr\n                F = np.random.normal(self.F, 0.1)\n                F = np.clip(F, 0.1, 1.0)\n                Cr = np.random.normal(self.Cr, 0.1)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                v = x1 + F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    successful_F.append(F)\n                    successful_Cr.append(Cr)\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n            \n            # Adapt F and Cr using successful values\n            if successful_F:\n                self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * np.mean(successful_F)\n                self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * np.mean(successful_Cr)\n                successful_F = []\n                successful_Cr = []\n            \n            # Population reduction\n            if self.evals < self.budget * 0.8:\n                sorted_indices = np.argsort(self.fitness)\n                new_pop_size = int(self.pop_size * self.reduction_factor)\n                self.pop = self.pop[sorted_indices[:new_pop_size]]\n                self.fitness = self.fitness[sorted_indices[:new_pop_size]]\n                self.pop_size = new_pop_size\n\n                # Refill population with random individuals\n                num_to_refill = 50 - new_pop_size\n                new_individuals = np.random.uniform(self.lb, self.ub, size=(num_to_refill, self.dim))\n                new_fitness = np.array([func(x) for x in new_individuals])\n                self.evals += num_to_refill\n\n                self.pop = np.concatenate((self.pop, new_individuals), axis=0)\n                self.fitness = np.concatenate((self.fitness, new_fitness))\n                self.pop_size = 50\n\n                best_index = np.argmin(self.fitness)\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.pop[best_index]\n                \n            if self.evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["45f85f67-6119-4dba-a1e4-271efac3fbe9"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "adccd15b-cb8a-4fd9-ab57-992fc472f42d", "fitness": 0.7009826296778136, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on recent success and reduced complexity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, success_history_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.success_F = []\n        self.success_Cr = []\n        self.success_history_size = success_history_size\n\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                u[mask] = v[mask]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n                    if len(self.success_F) > self.success_history_size:\n                        self.success_F.pop(0)\n                        self.success_Cr.pop(0)\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                if self.evals >= self.budget:\n                    break\n            \n            # Adapt F and Cr based on recent success\n            if self.success_F:\n                self.F = np.clip(np.mean(self.success_F), 0.1, 0.9)\n                self.Cr = np.clip(np.mean(self.success_Cr), 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.701 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3eedcc49-7435-4ccc-8de4-d98d71005098"], "operator": null, "metadata": {"aucs": [0.2973654910854834, 0.5948443192107395, 0.7036439781735719, 0.864697994130768, 0.7349279058473026, 0.7718447797449834, 0.6311993611070787, 0.6507956787832758, 0.7402952609893538, 0.6577332598922372, 0.8803414021734071, 0.9989452661202625, 0.629237390495748, 0.7438363701227111, 0.9134608944021394, 0.7879913598298117, 0.6624204244501225, 0.8369797553714196, 0.3889440631287584, 0.5301476384970985]}}
{"id": "42159dc2-4692-4918-ba03-d704624f5a46", "fitness": 0.5823061737221499, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified self-adaptation of F and Cr based on exponential moving averages, aggressively updated only upon successful improvements, and further simplified parameter update and selection.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, alpha=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.alpha = alpha\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                mask = np.random.rand(self.dim) < self.Cr\n                mask[j_rand] = True  # Ensure at least one component changes\n                u[mask] = v[mask]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Update F and Cr using exponential moving average only on improvement\n                    self.F = (1 - self.alpha) * self.F + self.alpha * 0.5  # Simplified F update\n                    self.Cr = (1 - self.alpha) * self.Cr + self.alpha * np.random.rand() # Simplified Cr update\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.582 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e04f3c6f-052e-425d-a484-c6ed885da073"], "operator": null, "metadata": {"aucs": [0.19491993778091932, 0.295661898773948, 0.5568128260069358, 0.7804419694559186, 0.6562504300848657, 0.7364436520154063, 0.48307748363113445, 0.5510759892203111, 0.6781620647581978, 0.5589634498190361, 0.7156545341637467, 0.999165205786896, 0.2773427079082158, 0.5894813916294777, 0.8328352634983229, 0.754350702596043, 0.4418193436547283, 0.7830842033922699, 0.2551096259506891, 0.5054707943159344]}}
{"id": "b92e7f3b-d27b-48d1-9821-060962d80618", "fitness": 0.7132566088453531, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with separate success histories for F and Cr, and a decaying average for adaptation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, success_rate_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.success_rate_memory = success_rate_memory\n        self.F_history = []\n        self.Cr_history = []\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.F_history.append(self.F)\n                    self.Cr_history.append(self.Cr)\n                    if len(self.F_history) > self.success_rate_memory:\n                        self.F_history.pop(0)\n                        self.Cr_history.pop(0)\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr\n            if self.F_history:\n                self.F = 0.9 * self.F + 0.1 * np.mean(self.F_history)\n                self.Cr = 0.9 * self.Cr + 0.1 * np.mean(self.Cr_history)\n\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.713 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b1159159-076f-4ac5-ad78-b7475b967b9c"], "operator": null, "metadata": {"aucs": [0.328830056017426, 0.680532608240281, 0.6630028328536194, 0.8630810144425822, 0.7535485392882915, 0.8057469833482757, 0.63072946841371, 0.6429321216998851, 0.7405734971532361, 0.704407380339573, 0.8723798819060573, 0.9844292019946805, 0.6292989493595567, 0.7151151309221742, 0.9129152731254797, 0.7940377978622776, 0.6104812214863587, 0.8323551098754816, 0.5779075245417696, 0.5228275840363468]}}
{"id": "272a8111-c038-44ba-9bbb-d71cf5020850", "fitness": 0.624047017923931, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive F and Cr based on exponential moving averages and aggressive updates only upon successful improvements, combined with a scaling factor for differential variation to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, alpha_F=0.1, alpha_Cr=0.1, scaling_factor=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.alpha_F = alpha_F\n        self.alpha_Cr = alpha_Cr\n        self.scaling_factor = scaling_factor  # Scaling factor for differential variation\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.scaling_factor * self.F * (x2 - x3)  # Applying scaling factor\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Update F and Cr using exponential moving average. Use current values of F and Cr to update them instead of keeping them the same.\n                    self.F = (1 - self.alpha_F) * self.F + self.alpha_F * np.random.rand()\n                    self.Cr = (1 - self.alpha_Cr) * self.Cr + self.alpha_Cr * np.random.rand()\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.624 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e04f3c6f-052e-425d-a484-c6ed885da073"], "operator": null, "metadata": {"aucs": [0.2164478735530656, 0.399944691359692, 0.6199794476950558, 0.8465688955357251, 0.7280220761542517, 0.7789898723730159, 0.6078330440915285, 0.5774088830270053, 0.7033906731070838, 0.6245461897490414, 0.7703615378982636, 0.9966409166213764, 0.3105121084073388, 0.6607965421722328, 0.8482859477740042, 0.7883196338508606, 0.48473452337993295, 0.8115237459617173, 0.19698444834120798, 0.5096493074262238]}}
{"id": "c5c024b9-eebd-408d-b082-6166ca374e0e", "fitness": 0.7034007871098914, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a single success history for F and Cr, prioritizing recent successful parameter combinations and using a simplified parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, success_rate_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.success_rate_memory = success_rate_memory\n        self.success_history_F = []\n        self.success_history_Cr = []\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_history_F.append(self.F)\n                    self.success_history_Cr.append(self.Cr)\n                    if len(self.success_history_F) > self.success_rate_memory:\n                        self.success_history_F.pop(0)\n                        self.success_history_Cr.pop(0)\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr\n            if self.success_history_F:\n                self.F = np.clip(np.mean(self.success_history_F), 0.1, 0.9)\n                self.Cr = np.clip(np.mean(self.success_history_Cr), 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.703 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b1159159-076f-4ac5-ad78-b7475b967b9c"], "operator": null, "metadata": {"aucs": [0.2798453350109845, 0.6854371045125897, 0.6970212883308893, 0.8996699767926939, 0.7530127103761741, 0.7846691300643209, 0.651447094858929, 0.6538834602244821, 0.7652782197559705, 0.6998942928087519, 0.8614299185920167, 0.99891707589019, 0.6497093271964645, 0.7462559782883428, 0.9358508408370978, 0.7912392924420408, 0.6131470120581056, 0.857184583182359, 0.2196203780834679, 0.5245027228919585]}}
{"id": "8f41c2e9-231a-44a3-9533-1128b842c83f", "fitness": 0.5149088815916841, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and focused population diversity via targeted restarts of underperforming individuals.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1, restart_prob=0.05, quantile=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n        self.restart_prob = restart_prob\n        self.quantile = quantile # Quantile for identifying underperforming individuals\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr (Simplified: direct update based on success)\n                    self.F = 0.9 * self.F + 0.1 * np.random.rand()\n                    self.Cr = 0.9 * self.Cr + 0.1 * np.random.rand()\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Restart underperforming individuals\n            if self.evals < self.budget:\n                restart_threshold = np.quantile(self.fitness, self.quantile)\n                for i in range(self.pop_size):\n                    if self.fitness[i] > restart_threshold and np.random.rand() < self.restart_prob:\n                        self.pop[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                        self.fitness[i] = func(self.pop[i])\n                        self.evals += 1\n                        if self.fitness[i] < self.f_opt:\n                            self.f_opt = self.fitness[i]\n                            self.x_opt = self.pop[i]\n                        if self.evals >= self.budget:\n                            break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.515 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["45f85f67-6119-4dba-a1e4-271efac3fbe9"], "operator": null, "metadata": {"aucs": [0.19984288743231038, 0.30145491073321884, 0.4702057642030413, 0.7079144385966534, 0.5167843051857952, 0.6215374391350845, 0.39307355041120495, 0.43030344660167197, 0.5816971935914983, 0.38634151932796634, 0.6574529724802761, 0.998054104211242, 0.2776747723511799, 0.50493305508253, 0.7789505939164294, 0.6419159141856388, 0.3992569061970982, 0.7182596292070129, 0.20995380963694288, 0.5025704193468887]}}
{"id": "3b5992bb-9166-4d55-a64a-0ee40cafbd04", "fitness": 0.36058879160888246, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with success-based parameter adaptation and population reduction for faster convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1, reduction_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n        self.reduction_factor = reduction_factor\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        successful_F = []\n        successful_Cr = []\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    successful_F.append(self.F)\n                    successful_Cr.append(self.Cr)\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                    \n                    if len(successful_F) > 0:\n                        self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * np.mean(successful_F) if len(successful_F) > 0 else self.F\n                        self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * np.mean(successful_Cr) if len(successful_Cr) > 0 else self.Cr\n\n                if self.evals >= self.budget:\n                    break\n\n            # Population reduction\n            if self.pop_size > 10 and self.evals < self.budget * 0.75: # Reduce only if budget allows\n                sorted_indices = np.argsort(self.fitness)[::-1]\n                num_to_reduce = max(1, int(self.pop_size * (1 - self.reduction_factor)))\n                indices_to_keep = sorted_indices[:-num_to_reduce]\n                \n                self.pop = self.pop[indices_to_keep]\n                self.fitness = self.fitness[indices_to_keep]\n                self.pop_size = self.pop.shape[0]\n                \n                if self.x_opt not in self.pop:\n                    best_index = np.argmin(self.fitness)\n                    self.x_opt = self.pop[best_index]\n                    self.f_opt = self.fitness[best_index]\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.361 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["45f85f67-6119-4dba-a1e4-271efac3fbe9"], "operator": null, "metadata": {"aucs": [0.18328853327011563, 0.20129383878877827, 0.25396692371590923, 0.24478373263375008, 0.2488783205933377, 0.29137033820883473, 0.3431752268226341, 0.328307189041637, 0.25616156296511894, 0.47990185323411716, 0.36179604785953134, 0.9994776776731913, 0.3355737654299228, 0.4129794291649961, 0.5522138485560378, 0.31163965584405795, 0.2781663010119958, 0.42887010837385264, 0.20203575889979197, 0.4978957200900387]}}
{"id": "f8162138-f01a-4625-8abe-29b5bd168044", "fitness": -Infinity, "name": "AdaptiveDE", "description": "Simplified Differential Evolution with adaptive F and Cr based on successful mutations and archive usage to enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.archive = []\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                if len(self.archive) > 0:\n                    arch_idx = np.random.randint(len(self.archive))\n                    candidates.append(self.archive[arch_idx])\n\n                idx = np.random.choice(len(candidates), size=3, replace=False)\n                if candidates[idx[0]] in range(self.pop_size):\n                    x1 = self.pop[candidates[idx[0]]]\n                else:\n                    x1 = candidates[idx[0]]\n                if candidates[idx[1]] in range(self.pop_size):\n                    x2 = self.pop[candidates[idx[1]]]\n                else:\n                    x2 = candidates[idx[1]]\n                if candidates[idx[2]] in range(self.pop_size):\n                    x3 = self.pop[candidates[idx[2]]]\n                else:\n                    x3 = candidates[idx[2]]\n\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr (Simplified) - can be further tuned\n                    self.F = np.random.normal(0.5, 0.1)\n                    self.F = np.clip(self.F, 0.1, 1.0)\n                    self.Cr = np.random.normal(0.9, 0.1)\n                    self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n                    # Update population and archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i].copy())\n                    else:\n                        replace_idx = np.random.randint(self.archive_size)\n                        self.archive[replace_idx] = self.pop[i].copy()\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["45f85f67-6119-4dba-a1e4-271efac3fbe9"], "operator": null, "metadata": {}}
{"id": "1e8711a3-a07a-437e-9d33-b6d32a3691d9", "fitness": 0.6644939571858333, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on successful updates, using a single learning rate for F and Cr, and reduced function evaluations by skipping re-evaluation after re-initialization.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1, reinit_prob=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n        self.reinit_prob = reinit_prob\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr using a single learning rate\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.5  #Simplified F adaptation\n                    self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * 0.9 #Simplified Cr adaptation\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                # Re-initialize individual with small probability\n                if np.random.rand() < self.reinit_prob:\n                    self.pop[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                    #self.fitness[i] = func(self.pop[i]) # Skip re-evaluation immediately\n                    #self.evals += 1  # No need to increment evals here, as the fitness isn't re-evaluated immediately\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.664 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["45f85f67-6119-4dba-a1e4-271efac3fbe9"], "operator": null, "metadata": {"aucs": [0.21747601409519834, 0.6499994900326809, 0.6333521917034801, 0.8671663239886677, 0.7181626147856721, 0.748684616669709, 0.5425474306362454, 0.6070289036176715, 0.6917385614302021, 0.6211597138445997, 0.8528157207733846, 0.9944820326425654, 0.6457891129772659, 0.6826866570573359, 0.9113399941474408, 0.74226855581164, 0.6022219225249474, 0.829488399824138, 0.23180031498013798, 0.49967057217368316]}}
{"id": "a74064b5-a6a1-4fc9-afed-b26758fb0242", "fitness": 0.48635048634250627, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified adaptation of F and Cr based on recent successful values and optional population re-initialization.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, success_rate_memory=10, restart_prob=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.success_rate_memory = success_rate_memory\n        self.F_history = []\n        self.Cr_history = []\n        self.restart_prob = restart_prob  # Probability of re-initializing a random individual\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.F_history.append(self.F)\n                    self.Cr_history.append(self.Cr)\n                    if len(self.F_history) > self.success_rate_memory:\n                        self.F_history.pop(0)\n                        self.Cr_history.pop(0)\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Optional: Re-initialize individual with small probability\n                    if np.random.rand() < self.restart_prob:\n                        self.pop[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                        self.fitness[i] = func(self.pop[i])\n                        self.evals += 1 \n                        if self.fitness[i] < self.f_opt:\n                            self.f_opt = self.fitness[i]\n                            self.x_opt = self.pop[i]\n\n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr using a moving average\n            if self.F_history:\n                self.F = np.mean(self.F_history[-self.success_rate_memory:])\n                self.Cr = np.mean(self.Cr_history[-self.success_rate_memory:])\n\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.486 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b92e7f3b-d27b-48d1-9821-060962d80618"], "operator": null, "metadata": {"aucs": [0.28703597341593223, 0.6081956204577792, 0.6598072288450383, 0.8767136089937816, 0]}}
{"id": "9914c7e9-e067-48e6-9756-87cff02e8c17", "fitness": 0.5488722355254503, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on successful updates, using a single learning rate for F and Cr, and a restart mechanism for exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr using a single learning rate\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.5\n                    self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * 0.9\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                # Restart mechanism for exploration\n                if np.random.rand() < self.restart_prob:\n                    self.pop[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                    self.fitness[i] = func(self.pop[i])\n                    self.evals += 1\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.pop[i]\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.549 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1e8711a3-a07a-437e-9d33-b6d32a3691d9"], "operator": null, "metadata": {"aucs": [0.2135113438335945, 0.49573120436415496, 0.5397516634347198, 0.7855930983230601, 0.6138406263740125, 0.6495931843714857, 0.41655452367173407, 0.5019218221233117, 0.5872616149176166, 0.5660344767971053, 0.8013640314169919, 0.9993917108336747, 0.5136619968948405, 0]}}
{"id": "3626f421-0cbe-49cf-a4eb-051cfced472a", "fitness": 0.6883734094185986, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on successful updates, using a single learning rate and reduced memory footprint by averaging F/Cr values instead of storing the full history.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.success_count = 0\n        self.F_sum = 0.0\n        self.Cr_sum = 0.0\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                u[mask] = v[mask]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_count += 1\n                    self.F_sum += self.F\n                    self.Cr_sum += self.Cr\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                if self.evals >= self.budget:\n                    break\n            \n            # Adapt F and Cr based on recent success\n            if self.success_count > 0:\n                self.F = np.clip(self.F_sum / self.success_count, 0.1, 0.9)\n                self.Cr = np.clip(self.Cr_sum / self.success_count, 0.1, 0.9)\n                self.success_count = 0\n                self.F_sum = 0.0\n                self.Cr_sum = 0.0\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.688 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["adccd15b-cb8a-4fd9-ab57-992fc472f42d"], "operator": null, "metadata": {"aucs": [0.3801825895334193, 0.5674561536361211, 0.6762515090033072, 0.8874448576772548, 0.7613699836463951, 0.774087123663359, 0.6220539861239494, 0.630996536419689, 0.724940604443706, 0.6584352739289312, 0.8359329044682065, 0.9995041170969486, 0.6329823977141751, 0.7246653251713389, 0.9055898400996568, 0.7762948563501197, 0.5711858321437208, 0.8511724083614863, 0.23909333077692219, 0.5478285581132627]}}
{"id": "d313bca2-6b9c-44b1-8b93-d40f87de6984", "fitness": 0.7057604725318097, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on successful updates using exponentially weighted moving averages for F and Cr to prioritize recent successes.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, ewma_alpha=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.ewma_alpha = ewma_alpha\n        self.success_F = []\n        self.success_Cr = []\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr using EWMA\n            if self.success_F:\n                self.F = (1 - self.ewma_alpha) * self.F + self.ewma_alpha * np.mean(self.success_F)\n                self.Cr = (1 - self.ewma_alpha) * self.Cr + self.ewma_alpha * np.mean(self.success_Cr)\n\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.Cr = np.clip(self.Cr, 0.1, 0.9)\n                self.success_F = []\n                self.success_Cr = []\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.706 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b92e7f3b-d27b-48d1-9821-060962d80618"], "operator": null, "metadata": {"aucs": [0.36975729580614447, 0.6642909766558296, 0.6671215128429342, 0.8675388767235894, 0.7495857896730631, 0.7642388462485037, 0.6095041733956419, 0.6520496278000765, 0.7373721260515314, 0.7428917785474929, 0.8701145459941223, 0.9983792235342921, 0.6679353619306615, 0.7185393113786762, 0.91344786732197, 0.7729191763441138, 0.6312057938122699, 0.8362234384398347, 0.28014074073657624, 0.6019529873988732]}}
{"id": "219d6383-4cfe-428f-b0a9-bb1d6d287aa1", "fitness": 0.6826989100251227, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified adaptation and population-wide update checks for faster convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1, reinit_prob=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n        self.reinit_prob = reinit_prob\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    # Adapt F and Cr only if there's an improvement\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.5\n                    self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * 0.9\n\n\n                # Re-initialize individual with small probability\n                if np.random.rand() < self.reinit_prob:\n                    self.pop[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                    f_u = func(self.pop[i])\n                    self.fitness[i] = f_u\n                    self.evals +=1\n\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.pop[i]\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.683 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1e8711a3-a07a-437e-9d33-b6d32a3691d9"], "operator": null, "metadata": {"aucs": [0.3135307627612953, 0.6761762409702494, 0.6871386936428052, 0.8755631196479271, 0.7199287056807337, 0.7664904726070977, 0.5703899106196906, 0.6126276008251665, 0.7284556374734292, 0.6593423334249603, 0.8445627506875923, 0.9983805499474644, 0.6330584155319883, 0.7125191269467372, 0.9126285783177923, 0.7747466410875355, 0.5871864867901243, 0.8444920030275663, 0.21630119785476143, 0.5204589726575366]}}
{"id": "526a5d44-80a5-45da-a62a-0ebe8d46b27d", "fitness": 0.6914564021156423, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with improved parameter adaptation using weighted averages based on fitness improvement, and reduced complexity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, success_history_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.success_F = []\n        self.success_Cr = []\n        self.success_history_size = success_history_size\n        self.epsilon = 1e-8\n\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                mask = np.random.rand(self.dim) < self.Cr\n                u[mask] = v[mask]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    delta_f = self.fitness[i] - f_u\n                    self.success_F.append((self.F, delta_f))\n                    self.success_Cr.append((self.Cr, delta_f))\n                    if len(self.success_F) > self.success_history_size:\n                        self.success_F.pop(0)\n                        self.success_Cr.pop(0)\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                if self.evals >= self.budget:\n                    break\n            \n            # Adapt F and Cr based on recent success, weighting by improvement\n            if self.success_F:\n                sum_weights_F = np.sum([w for _, w in self.success_F])\n                F_sum = np.sum([F * w for F, w in self.success_F])\n                self.F = np.clip(F_sum / (sum_weights_F + self.epsilon), 0.1, 0.9)\n\n                sum_weights_Cr = np.sum([w for _, w in self.success_Cr])\n                Cr_sum = np.sum([Cr * w for Cr, w in self.success_Cr])\n                self.Cr = np.clip(Cr_sum / (sum_weights_Cr + self.epsilon), 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.691 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["adccd15b-cb8a-4fd9-ab57-992fc472f42d"], "operator": null, "metadata": {"aucs": [0.26439595035351926, 0.6237774283712711, 0.6871772803830802, 0.8785978279401192, 0.7318707793361936, 0.7889016138606003, 0.5983571334643645, 0.6681295488587937, 0.7411926965748696, 0.6906903994460586, 0.8549241207693835, 0.9977463492924097, 0.6153944126408291, 0.7075404916653049, 0.9190458677643258, 0.7832831448163042, 0.6042560042888627, 0.8460169662222958, 0.3086396393398312, 0.519190386924429]}}
{"id": "7138a7ac-cc7c-4085-85d7-3bce4fa7eba1", "fitness": 0.7107584296756911, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive F and Cr based on success history and reduced parameter tuning.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.learning_rate = learning_rate\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.success_F = []\n        self.success_Cr = []\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr using a simple running average\n            if self.success_F:\n                mean_F = np.mean(self.success_F)\n                self.F = (1 - self.learning_rate) * self.F + self.learning_rate * mean_F\n                self.F = np.clip(self.F, 0.1, 0.9)\n\n                mean_Cr = np.mean(self.success_Cr)\n                self.Cr = (1 - self.learning_rate) * self.Cr + self.learning_rate * mean_Cr\n                self.Cr = np.clip(self.Cr, 0.1, 0.9)\n                \n                self.success_F = []\n                self.success_Cr = []\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.711 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c5c024b9-eebd-408d-b082-6166ca374e0e"], "operator": null, "metadata": {"aucs": [0.33623763976994325, 0.6735211421531921, 0.7002622291199605, 0.8762810226267687, 0.7512557669853066, 0.7947626021334455, 0.6532812393599235, 0.6781356508850169, 0.7560731371921396, 0.7011427905044878, 0.8553654983358965, 0.9993199120261858, 0.6518316598039364, 0.7130597040371334, 0.9316261688803901, 0.7916574286874388, 0.6383701298371826, 0.8407399464282168, 0.32242048492582975, 0.5498244398214281]}}
{"id": "e4deafb1-6c84-40ee-85bd-be367e6efc21", "fitness": 0.6053080858655047, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters F and Cr and population size reduction.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1, pop_decay_rate=0.001):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n        self.pop_decay_rate = pop_decay_rate #rate at which the population size is reduced over time\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr using self-adaptive approach\n                    self.F = np.clip(self.F + self.adapt_rate * (np.random.rand() - 0.5), 0.1, 0.9) #Self-adaptive F\n                    self.Cr = np.clip(self.Cr + self.adapt_rate * (np.random.rand() - 0.5), 0.1, 0.9) #Self-adaptive Cr\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n            \n            #Reduce pop_size over time, but ensure it doesn't go below 10\n            self.pop_size = max(10, int(self.pop_size * (1 - self.pop_decay_rate)))\n\n            if self.evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.605 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1e8711a3-a07a-437e-9d33-b6d32a3691d9"], "operator": null, "metadata": {"aucs": [0.23426763501678227, 0.27197152524439494, 0.43492424504230254, 0.8988086887546313, 0.8465685006868505, 0.8662956083633946, 0.5629174990506957, 0.7080659992454252, 0.6726094752276679, 0.2086715204518137, 0.8674932541156248, 0.9894282938918204, 0.36171492678801465, 0.7824710215302815, 0.8819014757879075, 0.6524696583259907, 0.5931898755026457, 0.4663199113375557, 0.30777974037441813, 0.49829286257187855]}}
{"id": "82107e43-8cb1-43a1-a63d-d6f7546f3342", "fitness": 0.7014747344935424, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a single success history and adaptive population size based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, success_rate_memory=10, stagnation_threshold=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.success_rate_memory = success_rate_memory\n        self.success_history_F = []\n        self.success_history_Cr = []\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_history_F.append(self.F)\n                    self.success_history_Cr.append(self.Cr)\n                    if len(self.success_history_F) > self.success_rate_memory:\n                        self.success_history_F.pop(0)\n                        self.success_history_Cr.pop(0)\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n            \n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                self.best_fitness_history.pop(0)\n                if np.std(self.best_fitness_history) < 1e-8:\n                    # Stagnation detected, increase population size\n                    self.pop_size = int(self.pop_size * 1.2)  # Increase by 20%\n                    self.pop_size = min(self.pop_size, 200)  # Limit population size\n                    new_pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size - len(self.pop), self.dim))\n                    self.pop = np.vstack((self.pop, new_pop))\n                    self.fitness = np.array([func(x) for x in self.pop])\n                    \n                    # Reset adaptation parameters\n                    self.F = 0.5\n                    self.Cr = 0.9\n                    self.success_history_F = []\n                    self.success_history_Cr = []\n                    \n            # Adapt F and Cr\n            if self.success_history_F:\n                self.F = np.clip(np.mean(self.success_history_F), 0.1, 0.9)\n                self.Cr = np.clip(np.mean(self.success_history_Cr), 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.701 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c5c024b9-eebd-408d-b082-6166ca374e0e"], "operator": null, "metadata": {"aucs": [0.32066792847272574, 0.7174871392652372, 0.6894303411378434, 0.8677343218802707, 0.756146510105589, 0.7893972175880162, 0.6531032640832166, 0.7008971371782964, 0.7052191271852372, 0.6749313492456881, 0.8615087718443297, 0.9945224464694813, 0.6716484488626384, 0.7436630871723104, 0.89883094951253, 0.7768051925748578, 0.6000814498693678, 0.8406759357995968, 0.2544165914744112, 0.5123274801492039]}}
{"id": "abfa0abb-3f97-43de-b0bb-e34aa78b7e58", "fitness": 0.5369163974292299, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a single success history and adaptive population size reduction.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, success_rate_memory=10, pop_decay_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.success_rate_memory = success_rate_memory\n        self.success_history_F = []\n        self.success_history_Cr = []\n        self.pop_decay_rate = pop_decay_rate\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_history_F.append(self.F)\n                    self.success_history_Cr.append(self.Cr)\n                    if len(self.success_history_F) > self.success_rate_memory:\n                        self.success_history_F.pop(0)\n                        self.success_history_Cr.pop(0)\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr\n            if self.success_history_F:\n                self.F = np.clip(np.mean(self.success_history_F), 0.1, 0.9)\n                self.Cr = np.clip(np.mean(self.success_history_Cr), 0.1, 0.9)\n\n            # Adapt population size\n            self.pop_size = max(int(self.pop_size * (1 - self.pop_decay_rate)), 10)\n            if self.pop.shape[0] > self.pop_size:\n                idx_to_keep = np.argsort(self.fitness)[:self.pop_size]\n                self.pop = self.pop[idx_to_keep]\n                self.fitness = self.fitness[idx_to_keep]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.537 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c5c024b9-eebd-408d-b082-6166ca374e0e"], "operator": null, "metadata": {"aucs": [0.32842557533549854, 0.44127044919004166, 0.44846496530720836, 0.5046937456443885, 0.5353794591028764, 0.5531777811661327, 0.446569988598441, 0.43283340029786876, 0.40864005932702185, 0.23478671192151201, 0.9168787977009683, 0.9946612218776036, 0.38411094163890924, 0.4793189705410891, 0.7385332513358851, 0.7732550518797392, 0.5429186052132371, 0.7565572665901124, 0.2932828933463191, 0.5245688125697472]}}
{"id": "ff659d53-4bef-4d08-a59d-5ed47795519e", "fitness": 0.6986482485714548, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on a single success history, prioritizing recent successful parameter combinations through exponential moving averages.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, success_rate_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.success_rate_memory = success_rate_memory\n        self.success_history = []\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_history.append((self.F, self.Cr))\n                    if len(self.success_history) > self.success_rate_memory:\n                        self.success_history.pop(0)\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr using exponential moving averages\n            if self.success_history:\n                F_vals, Cr_vals = zip(*self.success_history)\n                self.F = 0.9 * self.F + 0.1 * np.mean(F_vals)\n                self.Cr = 0.9 * self.Cr + 0.1 * np.mean(Cr_vals)\n\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.699 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b92e7f3b-d27b-48d1-9821-060962d80618"], "operator": null, "metadata": {"aucs": [0.3401003031564198, 0.6588831571163984, 0.6562038550255032, 0.8772041754663574, 0.7474801423408177, 0.7985159063718084, 0.6417283519771205, 0.6609989321938377, 0.7384335501248848, 0.7336309063173159, 0.8570476691276514, 1.0, 0.6434400482912805, 0.6966001599169387, 0.9132807316806668, 0.7974437057358238, 0.6118827054829699, 0.836639208788329, 0.2409359576892418, 0.5225155046257309]}}
{"id": "89aee077-74ee-41f2-9996-8197f4e57316", "fitness": 0.6600028870188129, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on successful updates, using a single learning rate for F and Cr, reduced function evaluations by skipping re-evaluation after re-initialization, and adjusting F and Cr towards optimal values (0.5 and 0.9, respectively).", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1, reinit_prob=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n        self.reinit_prob = reinit_prob\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr using a single learning rate, moving towards 0.5 and 0.9\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.5\n                    self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * 0.9\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                # Re-initialize individual with small probability\n                if np.random.rand() < self.reinit_prob:\n                    self.pop[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.660 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1e8711a3-a07a-437e-9d33-b6d32a3691d9"], "operator": null, "metadata": {"aucs": [0.24721219978506292, 0.5628339867833927, 0.6164205125175715, 0.8695643053830348, 0.7164943094529085, 0.7616020028398196, 0.5771937128995634, 0.6405721335765701, 0.7161542252905659, 0.6085860733154561, 0.8377499459261499, 0.9915405469063313, 0.6020574962237528, 0.692673851963701, 0.9123679637973757, 0.7666065128484464, 0.5607972665886997, 0.8295012027107407, 0.1863115149963881, 0.5038179765707271]}}
{"id": "18c30bf2-21da-4b91-97b2-622bb0935281", "fitness": 0.22539048184733765, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on successful updates, and population size adjusted based on stagnation, further simplified by removing success history and directly adapting F and Cr based on recent improvements.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, stagnation_threshold=1000, stagnation_tolerance=1e-8, pop_size_max=200):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_tolerance = stagnation_tolerance\n        self.pop_size_max = pop_size_max\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.best_fitness_history.append(self.f_opt)\n        self.last_improvement = 0  # Track when the last improvement happened\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adaptation based on improvement\n                    delta_f = self.fitness[i] - f_u\n                    self.F = 0.9 * self.F + 0.1 * (0.5 + 0.5 * np.exp(delta_f))\n                    self.Cr = 0.9 * self.Cr + 0.1 * (np.random.rand())\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        self.last_improvement = self.evals\n                \n                if self.evals >= self.budget:\n                    break\n            \n            self.best_fitness_history.append(self.f_opt)\n\n            # Stagnation check and population size adjustment\n            if self.evals - self.last_improvement > self.stagnation_threshold:\n                if len(self.best_fitness_history) > self.stagnation_threshold:\n                    self.best_fitness_history.pop(0)\n\n                if np.std(self.best_fitness_history) < self.stagnation_tolerance:\n                    # Stagnation detected, increase population size\n                    new_pop_size = int(self.pop_size * 1.2)\n                    new_pop_size = min(new_pop_size, self.pop_size_max)\n\n                    if new_pop_size > self.pop_size:\n                        new_individuals = np.random.uniform(self.lb, self.ub, size=(new_pop_size - self.pop_size, self.dim))\n                        self.pop = np.vstack((self.pop, new_individuals))\n                        new_fitness = np.array([func(x) for x in new_individuals])\n                        self.fitness = np.concatenate((self.fitness, new_fitness))\n                        self.pop_size = new_pop_size\n                        self.evals += len(new_fitness)\n\n                    # Reset adaptation parameters\n                    self.F = 0.5\n                    self.Cr = 0.9\n                    self.best_fitness_history = [] # Reset history\n                    self.last_improvement = self.evals # Reset last improvement\n                    self.best_fitness_history.append(self.f_opt)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.225 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["82107e43-8cb1-43a1-a63d-d6f7546f3342"], "operator": null, "metadata": {"aucs": [0.1109236106034408, 0.1549273166980214, 0.3593276730953249, 0.31441550154426645, 0.20674459147877422, 0.4064737796426108, 0.24150250206348656, 0.2570743697426978, 0.17502844479681157, 0.17535751735417437, 0.30291047514844327, 0]}}
{"id": "8eb126ff-afab-4dcd-9850-dac2ea49f79d", "fitness": 0.7131033896238316, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on a single success history using a leaky integrator for F and Cr adaptation, combined with a simple bound constraint handling.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Simple bound handling\n                u = np.clip(u, self.lb, self.ub)\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr using leaky integration\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.9 #Simplified F update\n                    self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * 0.9 #Simplified Cr update\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Adapt F and Cr when the trial vector is not better\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.1 # if not improving, reduce F\n                \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.713 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ff659d53-4bef-4d08-a59d-5ed47795519e"], "operator": null, "metadata": {"aucs": [0.2522253204522191, 0.7959622346967753, 0.71871893630163, 0.8640891130491333, 0.7972075829878742, 0.8088245912492424, 0.716220779669547, 0.7175136180543282, 0.7856470699162756, 0.7543599757915962, 0.897403341973924, 0.9881560839431527, 0.349469575331085, 0.7875977930563047, 0.9174644525121198, 0.806853059184187, 0.7001225333605856, 0.8649652998117343, 0.2371637773048012, 0.5021026538301154]}}
{"id": "7943b019-ae13-4255-9b90-6e29de7d8d07", "fitness": 0.7087127713683579, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using exponentially weighted moving averages and reduced memory for success history.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, success_rate_memory=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.success_rate_memory = success_rate_memory\n        self.success_history = []\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_history.append((self.F, self.Cr))\n                    if len(self.success_history) > self.success_rate_memory:\n                        self.success_history.pop(0)\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr using exponential moving averages\n            if self.success_history:\n                F_vals, Cr_vals = zip(*self.success_history)\n                self.F = 0.8 * self.F + 0.2 * np.mean(F_vals)\n                self.Cr = 0.8 * self.Cr + 0.2 * np.mean(Cr_vals)\n\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.709 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ff659d53-4bef-4d08-a59d-5ed47795519e"], "operator": null, "metadata": {"aucs": [0.2939675703933332, 0.677178529752904, 0.6665910861229998, 0.8549827672311078, 0.753115536945615, 0.786299347781413, 0.6188268067527531, 0.6400195857879566, 0.7318078782093373, 0.6971707586072782, 0.8576413808017599, 0.9990101496970041, 0.6496924846687284, 0.7168379213285306, 0.92173790874976, 0.7941427060320816, 0.6048320265118707, 0.8530639662852632, 0.5463657501400615, 0.5109712655673982]}}
{"id": "240c8a0b-3518-4b0b-9a6b-d749747deb4e", "fitness": 0.698866753821674, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a single success history and truncated mean for parameter updates.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, success_rate_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.success_rate_memory = success_rate_memory\n        self.success_history_F = []\n        self.success_history_Cr = []\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_history_F.append(self.F)\n                    self.success_history_Cr.append(self.Cr)\n                    if len(self.success_history_F) > self.success_rate_memory:\n                        self.success_history_F.pop(0)\n                        self.success_history_Cr.pop(0)\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr using truncated mean\n            if self.success_history_F:\n                self.F = np.mean(sorted(self.success_history_F)[len(self.success_history_F) // 4:])\n                self.Cr = np.mean(sorted(self.success_history_Cr)[len(self.success_history_Cr) // 4:])\n\n\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.699 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ff659d53-4bef-4d08-a59d-5ed47795519e"], "operator": null, "metadata": {"aucs": [0.34296473729752697, 0.6612840025874809, 0.6922718671087245, 0.8814197627198211, 0.746832982814172, 0.7865240311766155, 0.6651299648205342, 0.6259233525300459, 0.7123359455933764, 0.6920010101034832, 0.8565378341572161, 0.987487257983079, 0.643045293065351, 0.7409297908304951, 0.9022775274334913, 0.7883023415636311, 0.602282325789772, 0.8434003010449675, 0.28154787386208135, 0.5248368739516145]}}
{"id": "dc765bc3-1d45-4ac6-8269-a8b6986e7ee1", "fitness": 0.6951703623152726, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using exponentially weighted moving averages for F and Cr, clipped mutation, and reduced parameter tuning.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.learning_rate = learning_rate\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.success_F = []\n        self.success_Cr = []\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)  # Clip mutation result\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr using exponentially weighted moving averages\n            if self.success_F:\n                self.F = (1 - self.learning_rate) * self.F + self.learning_rate * np.mean(self.success_F)\n                self.Cr = (1 - self.learning_rate) * self.Cr + self.learning_rate * np.mean(self.success_Cr)\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n                self.success_F = []\n                self.success_Cr = []\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.695 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7138a7ac-cc7c-4085-85d7-3bce4fa7eba1"], "operator": null, "metadata": {"aucs": [0.280434534717387, 0.63087042383806, 0.6839034181105661, 0.8653354600919216, 0.7305254575126174, 0.7825166049098106, 0.6340633601969068, 0.6336492181750171, 0.7157640535674861, 0.69456608085238, 0.8798996701205833, 0.9945539122387358, 0.6434370144686792, 0.732319577447367, 0.9145772229000575, 0.7743151790402708, 0.608865446315251, 0.8285728193733645, 0.22181146324580525, 0.6534263291831843]}}
{"id": "9b477cf6-7399-4148-8cb6-2609e24185b4", "fitness": 0.6996071730927735, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with adaptive F and Cr using a memory of successful values and simplified update rules.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.memory_size = memory_size\n        self.F_memory = np.full(memory_size, F_init)\n        self.Cr_memory = np.full(memory_size, Cr_init)\n        self.memory_idx = 0\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Update memory\n                    self.F_memory[self.memory_idx] = self.F\n                    self.Cr_memory[self.memory_idx] = self.Cr\n                    self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr - Simplified: Randomly pick from memory\n            self.F = np.random.choice(self.F_memory)\n            self.Cr = np.random.choice(self.Cr_memory)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.700 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7138a7ac-cc7c-4085-85d7-3bce4fa7eba1"], "operator": null, "metadata": {"aucs": [0.30319170525188244, 0.6648182389586788, 0.6817476850466095, 0.870293832116612, 0.7462362607804304, 0.791134890148911, 0.6210149400992367, 0.6723251225795135, 0.7407185838344894, 0.6714644524849971, 0.8600558391593213, 0.9980998407202761, 0.6488377474247401, 0.7238484562583878, 0.9125769173721237, 0.7867595181219972, 0.6243398450658497, 0.8336340648745391, 0.2227709397023867, 0.618274581854487]}}
{"id": "caedf63a-0a28-4c05-86f7-d23163d7f91b", "fitness": 0.7139068085103494, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with mirrored sampling for mutation and adaptive learning rate.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.learning_rate = learning_rate\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.success_F = []\n        self.success_Cr = []\n\n        while self.evals < self.budget:\n            # Adjust learning rate based on stagnation\n            if len(self.success_F) == 0:\n                self.learning_rate = min(self.learning_rate * 1.1, 0.5)  # Increase learning rate if no recent success\n            else:\n                self.learning_rate = max(self.learning_rate * 0.9, 0.01)  # Decrease if there is success\n                \n            for i in range(self.pop_size):\n                # Mutation with mirrored sampling\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                \n                # Mirroring boundary handling\n                v = np.where(v < self.lb, 2 * self.lb - v, v)\n                v = np.where(v > self.ub, 2 * self.ub - v, v)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr using a simple running average\n            if self.success_F:\n                self.F = (1 - self.learning_rate) * self.F + self.learning_rate * np.mean(self.success_F)\n                self.F = np.clip(self.F, 0.1, 0.9)\n\n                self.Cr = (1 - self.learning_rate) * self.Cr + self.learning_rate * np.mean(self.success_Cr)\n                self.Cr = np.clip(self.Cr, 0.1, 0.9)\n                \n                self.success_F = []\n                self.success_Cr = []\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.714 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7138a7ac-cc7c-4085-85d7-3bce4fa7eba1"], "operator": null, "metadata": {"aucs": [0.3410561064965624, 0.7057554977378735, 0.6061356314847874, 0.8594517801244076, 0.7146392402841288, 0.8047399676076531, 0.6397483737423422, 0.6741373330598671, 0.7537644222375697, 0.643500826516318, 0.8688419164045379, 0.995781708247884, 0.6132558414694123, 0.7457922090203275, 0.9299255445793333, 0.787988953485858, 0.6012892370257725, 0.8439242429463011, 0.559622801072692, 0.5887845366633588]}}
{"id": "7b40e5fa-2b46-4382-be4a-8f503ae3b8d2", "fitness": 0.70882601938999, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with adaptive F and Cr based on exponentially weighted moving averages of successful values, and simplified parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.learning_rate = learning_rate\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.success_F = []\n        self.success_Cr = []\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    if self.success_F:\n                      self.F = (1 - self.learning_rate) * self.F + self.learning_rate * np.mean(self.success_F)\n                      self.Cr = (1 - self.learning_rate) * self.Cr + self.learning_rate * np.mean(self.success_Cr)\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n            self.success_F = []\n            self.success_Cr = []\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.709 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7138a7ac-cc7c-4085-85d7-3bce4fa7eba1"], "operator": null, "metadata": {"aucs": [0.31074777314782864, 0.6701588179550262, 0.6897602077417064, 0.8640453491754292, 0.7505357368534786, 0.7937520628536826, 0.6055923398160388, 0.6672023556410887, 0.7542062017140494, 0.7057241938883226, 0.8616410451629515, 0.9874562441598725, 0.6813596270703663, 0.7422728522262478, 0.918225954648901, 0.7725660681513197, 0.6017192425551998, 0.8490256365060638, 0.2792136358134918, 0.6713150427187347]}}
{"id": "f7d2acad-305f-482e-9a7c-a3c2314381eb", "fitness": 0.6951663578780716, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with success-history adaptation and dynamic population size adjustment based on stagnation, using a moving average to smooth fitness changes and a simplified parameter update.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, success_rate_memory=10, stagnation_threshold=1000, stagnation_fitness_window=30):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.success_rate_memory = success_rate_memory\n        self.success_history_F = []\n        self.success_history_Cr = []\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.stagnation_fitness_window = stagnation_fitness_window\n        self.fitness_history = []\n\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.best_fitness_history.append(self.f_opt)\n        self.fitness_history.append(self.f_opt)\n\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_history_F.append(self.F)\n                    self.success_history_Cr.append(self.Cr)\n                    if len(self.success_history_F) > self.success_rate_memory:\n                        self.success_history_F.pop(0)\n                        self.success_history_Cr.pop(0)\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n            \n            self.fitness_history.append(self.f_opt)\n            if len(self.fitness_history) > self.stagnation_fitness_window:\n                self.fitness_history.pop(0)\n\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                self.best_fitness_history.pop(0)\n                # Use moving average to detect stagnation\n                if np.std(self.fitness_history) < 1e-8:\n                    # Stagnation detected, increase population size\n                    self.pop_size = int(self.pop_size * 1.1)  # Increase by 10%\n                    self.pop_size = min(self.pop_size, 150)  # Limit population size\n                    new_pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size - len(self.pop), self.dim))\n                    self.pop = np.vstack((self.pop, new_pop))\n                    self.fitness = np.array([func(x) for x in self.pop])\n                    \n                    # Reset adaptation parameters - Simplified\n                    self.F = 0.5\n                    self.Cr = 0.9\n                    self.success_history_F = []\n                    self.success_history_Cr = []\n                    self.fitness_history = [self.f_opt] * self.stagnation_fitness_window  # Reset fitness history\n\n\n            # Adapt F and Cr - Simplified\n            if self.success_history_F:\n                self.F = 0.9 * self.F + 0.1 * np.mean(self.success_history_F)  # Exponential smoothing\n                self.Cr = 0.9 * self.Cr + 0.1 * np.mean(self.success_history_Cr)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.695 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["82107e43-8cb1-43a1-a63d-d6f7546f3342"], "operator": null, "metadata": {"aucs": [0.29215132763489315, 0.6424340061243636, 0.6648843874649197, 0.8546168904186187, 0.7275223207250705, 0.78421621873755, 0.6632840426031361, 0.6994714413837727, 0.7477017942538768, 0.6938668896192228, 0.8400707510331155, 0.9984887138453294, 0.6687422912580157, 0.7276454214612451, 0.8929347243398349, 0.8023308345616342, 0.6254008885405307, 0.827787870570436, 0.2239565240005098, 0.5258198189853558]}}
{"id": "93f800b1-cda1-4c2a-be4c-d03f0aadf05f", "fitness": 0.6939133958071653, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using weighted averages and population size adjustment based on stagnation, further enhanced by perturbing the best solution to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, success_rate_memory=10, stagnation_threshold=1000, stagnation_fitness_diff=1e-8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.success_rate_memory = success_rate_memory\n        self.success_history_F = []\n        self.success_history_Cr = []\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.stagnation_fitness_diff = stagnation_fitness_diff #Small fitness difference to detect stagnation\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_history_F.append(self.F)\n                    self.success_history_Cr.append(self.Cr)\n                    if len(self.success_history_F) > self.success_rate_memory:\n                        self.success_history_F.pop(0)\n                        self.success_history_Cr.pop(0)\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n            \n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                self.best_fitness_history.pop(0)\n                if np.std(self.best_fitness_history) < self.stagnation_fitness_diff: #Use a user defined tolerance\n\n                    #Stagnation detected, perturb best solution\n                    mutation_indices = np.random.choice(self.dim, size=int(self.dim*0.1), replace=False) #Only perturb 10% of dimensions\n                    self.x_opt[mutation_indices] = np.random.uniform(self.lb, self.ub, size=len(mutation_indices))\n                    f_opt_new = func(self.x_opt)\n                    self.evals+=1\n                    if f_opt_new < self.f_opt:\n                         self.f_opt = f_opt_new\n\n                    # Stagnation detected, increase population size\n                    self.pop_size = int(self.pop_size * 1.2)  # Increase by 20%\n                    self.pop_size = min(self.pop_size, 200)  # Limit population size\n                    new_pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size - len(self.pop), self.dim))\n                    self.pop = np.vstack((self.pop, new_pop))\n                    self.fitness = np.array([func(x) for x in self.pop])\n                    self.evals += (self.pop_size - len(self.pop)) #Update evaluation count\n\n\n                    # Reset adaptation parameters\n                    self.F = 0.5\n                    self.Cr = 0.9\n                    self.success_history_F = []\n                    self.success_history_Cr = []\n                    \n            # Adapt F and Cr using weighted averages\n            if self.success_history_F:\n                weights = np.arange(1, len(self.success_history_F) + 1)\n                weights = weights / np.sum(weights)\n                self.F = np.clip(np.average(self.success_history_F, weights=weights), 0.1, 0.9)\n                self.Cr = np.clip(np.average(self.success_history_Cr, weights=weights), 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.694 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["82107e43-8cb1-43a1-a63d-d6f7546f3342"], "operator": null, "metadata": {"aucs": [0.24305675323585518, 0.6711949486447855, 0.6881386327409091, 0.8679769169792282, 0.7445252442510688, 0.7970399243502142, 0.6183431980461025, 0.6487094324718555, 0.7429291732979109, 0.7459544515979984, 0.8557254056565936, 0.9981807382526247, 0.6269706946897571, 0.7051027630389057, 0.8820936654450631, 0.7917550164057284, 0.6671404219331599, 0.821508063175068, 0.2507317225567929, 0.5111907493736845]}}
{"id": "2ecdb9a5-5192-4d95-89e5-7dc29178f305", "fitness": 0.0, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a self-adaptive population size and parameter adaptation based on a single, dynamically updated success history.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, F_init=0.5, Cr_init=0.9, ewma_alpha=0.2, pop_size_reduction_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.pop_size_init = pop_size_init\n        self.F = F_init\n        self.Cr = Cr_init\n        self.ewma_alpha = ewma_alpha\n        self.success_F = F_init\n        self.success_Cr = Cr_init\n        self.pop_size_reduction_factor = pop_size_reduction_factor\n        self.stagnation_counter = 0\n        self.max_stagnation = 20\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.best_fitness_history = [self.f_opt]\n\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    \n                    self.success_F = (1 - self.ewma_alpha) * self.success_F + self.ewma_alpha * self.F\n                    self.success_Cr = (1 - self.ewma_alpha) * self.success_Cr + self.ewma_alpha * self.Cr\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        self.stagnation_counter = 0\n                    else:\n                         self.stagnation_counter += 1\n                else:\n                    self.stagnation_counter += 1\n\n\n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr using EWMA\n            self.F = np.clip(self.success_F, 0.1, 0.9)\n            self.Cr = np.clip(self.success_Cr, 0.1, 0.9)\n\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > 1:\n                if self.best_fitness_history[-1] >= self.best_fitness_history[-2]:\n                    self.stagnation_counter +=1\n                else:\n                    self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.max_stagnation and self.pop_size > 10:\n                self.pop_size = int(self.pop_size * self.pop_size_reduction_factor)\n                self.pop_size = max(10, self.pop_size)\n                self.pop = self.pop[np.argsort(self.fitness)[:self.pop_size]]\n                self.fitness = self.fitness[np.argsort(self.fitness)[:self.pop_size]]\n                \n                new_pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size_init - self.pop_size, self.dim))\n                new_fitness = np.array([func(x) for x in new_pop])\n                self.evals += (self.pop_size_init - self.pop_size)\n                \n                self.pop = np.concatenate((self.pop, new_pop))\n                self.fitness = np.concatenate((self.fitness, new_fitness))\n                self.pop_size = self.pop_size_init\n                self.stagnation_counter = 0\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d313bca2-6b9c-44b1-8b93-d40f87de6984"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "83874336-bc17-4474-9a1c-8f011b2d2380", "fitness": 0.6994675542471256, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and reduced memory using a single EWMA for both F and Cr based on success history and improved exploration through population diversity maintenance.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, ewma_alpha=0.2, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.ewma_alpha = ewma_alpha\n        self.success_values = []\n        self.diversity_threshold = diversity_threshold  # Threshold for population diversity\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_values.append((self.F, self.Cr))\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr using EWMA\n            if self.success_values:\n                F_vals, Cr_vals = zip(*self.success_values)\n                self.F = (1 - self.ewma_alpha) * self.F + self.ewma_alpha * np.mean(F_vals)\n                self.Cr = (1 - self.ewma_alpha) * self.Cr + self.ewma_alpha * np.mean(Cr_vals)\n\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.Cr = np.clip(self.Cr, 0.1, 0.9)\n                self.success_values = []\n\n            # Diversity maintenance (optional, but potentially helpful)\n            if np.std(self.pop) < self.diversity_threshold:\n                self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.evals += self.pop_size  # Account for new evaluations\n                \n                best_idx = np.argmin(self.fitness)\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.pop[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.699 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d313bca2-6b9c-44b1-8b93-d40f87de6984"], "operator": null, "metadata": {"aucs": [0.28923363041024563, 0.6500918412341103, 0.6720989065800338, 0.8707716380585102, 0.7352105723761064, 0.7929672573315543, 0.6528708525503975, 0.6444724900351999, 0.7402344730324756, 0.6985007539657384, 0.8226614136536374, 0.9998212869644876, 0.6988278683629637, 0.7168300777156668, 0.9178558340012404, 0.7812319706409665, 0.6174623791498262, 0.8543680047631873, 0.25190251969843935, 0.581937314417722]}}
{"id": "a6316b47-1d46-41c4-8173-681fccd7b10a", "fitness": -Infinity, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive F and Cr using a single memory entry, and mirrored sampling for mutation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.success_F = None\n        self.success_Cr = None\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation with mirrored sampling\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n\n                # Boundary handling (mirroring)\n                mask_lower = v < self.lb\n                mask_upper = v > self.ub\n                v[mask_lower] = self.lb + (self.lb - v[mask_lower])\n                v[mask_upper] = self.ub - (v[mask_upper] - self.ub)\n                \n                v = np.clip(v, self.lb, self.ub)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr using success values\n                    if self.success_F is not None:\n                        self.F = 0.8 * self.F + 0.2 * self.success_F\n                        self.Cr = 0.8 * self.Cr + 0.2 * self.success_Cr\n                    self.success_F = self.F\n                    self.success_Cr = self.Cr\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n        \n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,) (0,) .", "error": "", "parent_ids": ["7943b019-ae13-4255-9b90-6e29de7d8d07"], "operator": null, "metadata": {}}
{"id": "66cac08f-2fdb-46de-adaf-b0ac5c51e150", "fitness": 0.0, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using exponentially weighted moving averages and adaptive population size.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F_init=0.5, Cr_init=0.9, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(4 + 3 * np.log(dim))  # Adaptive pop size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.learning_rate = learning_rate\n        self.min_pop_size = 4\n        self.max_pop_size = 100\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.archive_F = []\n        self.archive_Cr = []\n        \n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.archive_F.append(self.F)\n                    self.archive_Cr.append(self.Cr)\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            if self.archive_F:\n                self.F = (1 - self.learning_rate) * self.F + self.learning_rate * np.mean(np.clip(self.archive_F, 0.1, 0.9))\n                self.Cr = (1 - self.learning_rate) * self.Cr + self.learning_rate * np.mean(np.clip(self.archive_Cr, 0.1, 0.9))\n            \n            self.archive_F = []\n            self.archive_Cr = []\n\n            # Adaptive population size adjustment (simplified)\n            if self.evals < self.budget / 2:\n                self.pop_size = min(self.max_pop_size, int(self.pop_size * 1.05))\n            else:\n                self.pop_size = max(self.min_pop_size, int(self.pop_size * 0.95))\n\n            if self.pop_size != self.pop.shape[0]:\n                new_pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                new_fitness = np.array([func(x) for x in new_pop])\n                self.evals += self.pop_size - self.pop.shape[0]\n                \n                if self.pop_size > self.pop.shape[0]:\n                    self.pop = np.vstack((self.pop, new_pop[self.pop.shape[0]:self.pop_size]))\n                    self.fitness = np.concatenate((self.fitness, new_fitness[self.pop.shape[0]:self.pop_size]))\n                else:\n                    self.pop = self.pop[:self.pop_size]\n                    self.fitness = self.fitness[:self.pop_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7b40e5fa-2b46-4382-be4a-8f503ae3b8d2"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "b99e604d-cfac-4384-9589-f2fa9a0565e2", "fitness": 0.700955999725135, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with mirrored sampling, simplified learning rate, and clipping of mutated vectors for better exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        \n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation with mirrored sampling\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                \n                # Clipping to boundaries\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.701 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["caedf63a-0a28-4c05-86f7-d23163d7f91b"], "operator": null, "metadata": {"aucs": [0.2753923844188143, 0.6950121389052152, 0.6925211306993166, 0.8687046990334863, 0.7542573314961324, 0.754593021909125, 0.632453990999732, 0.6601984176351638, 0.7431098862696431, 0.7064292806657715, 0.8794085359528203, 0.9992794592136168, 0.6696783408000225, 0.7137261941298181, 0.9133447428537718, 0.7626590259637049, 0.5792374421136595, 0.8420579544293425, 0.2920181101676319, 0.5850379068459098]}}
{"id": "3e189834-8868-4baf-b07a-1dd8e620a934", "fitness": 0.6947880507878812, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive F and Cr using a single success history for faster adaptation and reduced complexity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.learning_rate = learning_rate\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.last_success_F = None\n        self.last_success_Cr = None\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    if self.last_success_F is not None:\n                        self.F = (1 - self.learning_rate) * self.F + self.learning_rate * self.last_success_F\n                        self.Cr = (1 - self.learning_rate) * self.Cr + self.learning_rate * self.last_success_Cr\n\n                    self.last_success_F = self.F\n                    self.last_success_Cr = self.Cr\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.695 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7b40e5fa-2b46-4382-be4a-8f503ae3b8d2"], "operator": null, "metadata": {"aucs": [0.31258217869375227, 0.6639213742725045, 0.6512564672663765, 0.8798009855995343, 0.7666181795603573, 0.7911110972587436, 0.5997956003398666, 0.6522594293839603, 0.7165915155127347, 0.6802303614288729, 0.8644548729586252, 0.994319484613032, 0.6605824888398648, 0.7108657451789564, 0.9149942248609556, 0.7897596044429781, 0.6413156200257866, 0.8523362962217884, 0.22937929934490853, 0.523586189954025]}}
{"id": "d5de8052-60c5-434e-8051-f4db43b6b415", "fitness": 0.7271354262935478, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a single success history and population diversity enhancement through random re-initialization of stagnant individuals.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1, stagnation_threshold=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n        self.stagnation_threshold = stagnation_threshold  # Threshold for stagnation\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.stagnation_counter = np.zeros(self.pop_size)  # Counter for each individual\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Simple bound handling\n                u = np.clip(u, self.lb, self.ub)\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr using leaky integration, simplified\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.9\n                    self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * 0.9\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    self.stagnation_counter[i] = 0  # Reset stagnation counter\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Adapt F and Cr when the trial vector is not better\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.1\n                    self.stagnation_counter[i] += 1  # Increment stagnation counter\n\n                # Stagnation check and re-initialization\n                if self.stagnation_counter[i] > self.stagnation_threshold:\n                    self.pop[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                    self.fitness[i] = func(self.pop[i])\n                    self.evals += 1\n                    self.stagnation_counter[i] = 0  # Reset stagnation counter\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.pop[i]\n                \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.727 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8eb126ff-afab-4dcd-9850-dac2ea49f79d"], "operator": null, "metadata": {"aucs": [0.42882936056104726, 0.772707074076312, 0.7060238246959005, 0.8960148396003934, 0.7505643620938209, 0.8284069546556851, 0.717635205497968, 0.7159257827802229, 0.7900017365369824, 0.37302924280008687, 0.8789126131147307, 0.9937005177037826, 0.37946635002616014, 0.7892339746116945, 0.9250132746942925, 0.8189805790825652, 0.6980486834767903, 0.8675682475732703, 0.6848060222765012, 0.5278398800127493]}}
{"id": "77fa1762-e1a6-403b-a9c9-06e4b93e58a8", "fitness": 0.6102819274680209, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive F and Cr parameters using moving averages and reduced complexity by removing success history.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, learning_rate=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.learning_rate = learning_rate\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.F_mean = self.F\n        self.Cr_mean = self.Cr\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr using moving averages\n                    self.F_mean = (1 - self.learning_rate) * self.F_mean + self.learning_rate * self.F\n                    self.Cr_mean = (1 - self.learning_rate) * self.Cr_mean + self.learning_rate * self.Cr\n                    self.F = np.clip(np.random.normal(self.F_mean, 0.1), 0.1, 0.9)\n                    self.Cr = np.clip(np.random.normal(self.Cr_mean, 0.1), 0.1, 0.9)\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.610 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7943b019-ae13-4255-9b90-6e29de7d8d07"], "operator": null, "metadata": {"aucs": [0.26718347348289206, 0.25258866810959757, 0.5785634841631732, 0.8223211374559186, 0.6004505115372971, 0.750697305165601, 0.6046561740731657, 0.5941382009657522, 0.7307631662427093, 0.44765529034274365, 0.8123966471254174, 0.9950128127241281, 0.33294513566390194, 0.5047942917681547, 0.8300492118376651, 0.7574953380241357, 0.42648738481245385, 0.7463132016797722, 0.6024123573909359, 0.5487147567950015]}}
{"id": "d20832ac-ea59-49c6-a385-c192b2e27c33", "fitness": 0.7287649118566478, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a leaky integrator, self-adaptive population size reduction, and mirrored boundary reflection.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1, pop_reduction_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.pop_size_init = pop_size_init\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n        self.pop_reduction_rate = pop_reduction_rate\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Mirrored boundary reflection\n                u = np.where(u < self.lb, 2 * self.lb - u, u)\n                u = np.where(u > self.ub, 2 * self.ub - u, u)\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr using leaky integration\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.9\n                    self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * 0.9\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Adapt F and Cr when the trial vector is not better\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.1\n                \n                if self.evals >= self.budget:\n                    break\n            \n            # Population size reduction\n            if self.evals > self.budget * 0.5 and self.pop_size > 10: # start reducing after half budget\n                new_pop_size = int(self.pop_size * (1 - self.pop_reduction_rate))\n                if new_pop_size < 10:\n                    new_pop_size = 10\n                \n                # Keep the best individuals\n                idx = np.argsort(self.fitness)[:new_pop_size]\n                self.pop = self.pop[idx]\n                self.fitness = self.fitness[idx]\n                self.pop_size = new_pop_size\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.729 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8eb126ff-afab-4dcd-9850-dac2ea49f79d"], "operator": null, "metadata": {"aucs": [0.3401636645562649, 0.7873267906607555, 0.6100480627607956, 0.8933132521914151, 0.7894128640248035, 0.8140281921761383, 0.7318350155652202, 0.7113110348143963, 0.7662116861506635, 0.75598142000625, 0.8759272081564391, 0.9998346160319692, 0.3154064847838738, 0.779558371105113, 0.9112251800633868, 0.7987950090434497, 0.6513127881003382, 0.8638745710977833, 0.6604829650665476, 0.5192490607773558]}}
{"id": "d920f05f-4895-44c8-961a-cc8b697c6741", "fitness": 0.42490347478492263, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation, mirroring, and dynamic population size adjustment based on success.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, learning_rate=0.1, pop_size_reduction_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.learning_rate = learning_rate\n        self.pop_size_reduction_factor = pop_size_reduction_factor\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.success_F = []\n        self.success_Cr = []\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation with mirrored sampling\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                \n                # Mirroring boundary handling\n                v = np.where(v < self.lb, 2 * self.lb - v, v)\n                v = np.where(v > self.ub, 2 * self.ub - v, v)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr using a simple running average\n            if self.success_F:\n                self.F = (1 - self.learning_rate) * self.F + self.learning_rate * np.mean(self.success_F)\n                self.F = np.clip(self.F, 0.1, 0.9)\n\n                self.Cr = (1 - self.learning_rate) * self.Cr + self.learning_rate * np.mean(self.success_Cr)\n                self.Cr = np.clip(self.Cr, 0.1, 0.9)\n                \n                # Dynamically reduce population size if successful\n                if len(self.success_F) > self.pop_size * 0.2:\n                    self.pop_size = int(self.pop_size * self.pop_size_reduction_factor)\n                    self.pop_size = max(10, self.pop_size)  # Ensure minimum population size\n                    \n                    # Truncate population if pop_size decreased\n                    if self.pop.shape[0] > self.pop_size:\n                        idx = np.argsort(self.fitness)[:self.pop_size]\n                        self.pop = self.pop[idx]\n                        self.fitness = self.fitness[idx]\n\n                self.success_F = []\n                self.success_Cr = []\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.425 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["caedf63a-0a28-4c05-86f7-d23163d7f91b"], "operator": null, "metadata": {"aucs": [0.24212476708565844, 0.3724540173806533, 0.34592927918529726, 0.42172714228162567, 0.36562639365118177, 0.4266027492603641, 0.2939500524438734, 0.4049006491124312, 0.37890697226809833, 0.21398885695542025, 0.5300490344625126, 0.9922595067378752, 0.2794486375736219, 0.7028239455511852, 0.6766690410058408, 0.3551417138255287, 0.2840358366889648, 0.43449917674393956, 0.27255204174652237, 0.5043796817378577]}}
{"id": "e7c4c662-3049-4a3b-8c7e-6da8d7679119", "fitness": 0.42086028993016233, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using exponentially weighted moving averages and reduced memory for success history and a simplified mutation strategy.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.learning_rate = learning_rate\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.success_F = []\n        self.success_Cr = []\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = self.pop[i] + self.F * (x2 - x3)  # Simplified mutation\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    if self.success_F:\n                      self.F = (1 - self.learning_rate) * self.F + self.learning_rate * np.mean(self.success_F[-5:])  # Limited memory\n                      self.Cr = (1 - self.learning_rate) * self.Cr + self.learning_rate * np.mean(self.success_Cr[-5:])  # Limited memory\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.421 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7b40e5fa-2b46-4382-be4a-8f503ae3b8d2"], "operator": null, "metadata": {"aucs": [0.16169567933070572, 0.30172027703388915, 0.3901556479094198, 0.4917764234972989, 0.3125927504871706, 0.45442727385745263, 0.29453601057219114, 0.35769113450735146, 0.3341026847152241, 0.2267441223500074, 0.6405198860307812, 0.9934773706185024, 0.38908261995384485, 0.30962290341461174, 0.7805821369192855, 0.44639033896541624, 0.3336592173086924, 0.5386232617207982, 0.17336271815414206, 0.4864433412564615]}}
{"id": "b72e7495-5122-47eb-ac69-43441223ddd8", "fitness": 0.637610764810403, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive F and Cr using a single success memory and reduced parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.memory_F = 0.5\n        self.memory_Cr = 0.9\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                F = np.random.normal(self.memory_F, 0.1)\n                F = np.clip(F, 0.1, 0.9)\n                v = x1 + F * (x2 - x3)\n\n                # Boundary handling (clip)\n                v = np.clip(v, self.lb, self.ub)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                Cr = np.random.normal(self.memory_Cr, 0.1)\n                Cr = np.clip(Cr, 0.1, 0.9)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.memory_F = F\n                    self.memory_Cr = Cr\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.638 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["caedf63a-0a28-4c05-86f7-d23163d7f91b"], "operator": null, "metadata": {"aucs": [0.2521733192958101, 0.47666379427922234, 0.5176410698327434, 0.8233638081220973, 0.731794843593164, 0.7171904699298082, 0.687180470772407, 0.5662658274498636, 0.6973203947992512, 0.6624499481336565, 0.7715447210756254, 0.9954196224662852, 0.446049491276594, 0.6701393265397593, 0.8632643037937873, 0.7634499257955246, 0.5372110575005187, 0.8228718557608508, 0.23241545227691862, 0.5178055935141761]}}
{"id": "e58fe8c9-52a3-4692-94ba-e5565c4be5f4", "fitness": 0.6747276170594219, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with mirrored sampling and self-adaptive learning rate adjustment based on success ratio.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.success_count = 0\n        self.learning_rate = 0.1\n\n        while self.evals < self.budget:\n            # Adjust learning rate based on success ratio\n            success_ratio = self.success_count / self.pop_size if self.pop_size > 0 else 0\n            if success_ratio < 0.2:\n                self.learning_rate = min(self.learning_rate * 1.1, 0.5)  # Increase learning rate if low success\n            else:\n                self.learning_rate = max(self.learning_rate * 0.9, 0.01)  # Decrease if high success\n            \n            self.success_count = 0\n            for i in range(self.pop_size):\n                # Mutation with mirrored sampling\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n                \n                # Mirroring boundary handling\n                v = np.where(v < self.lb, 2 * self.lb - v, v)\n                v = np.where(v > self.ub, 2 * self.ub - v, v)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.success_count += 1\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Adapt F and Cr - simplified adaptation\n            self.F = np.clip(self.F + self.learning_rate * np.random.normal(0, 0.1), 0.1, 0.9)\n            self.Cr = np.clip(self.Cr + self.learning_rate * np.random.normal(0, 0.1), 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.675 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["caedf63a-0a28-4c05-86f7-d23163d7f91b"], "operator": null, "metadata": {"aucs": [0.289338265352835, 0.5790278307817038, 0.6393562489380051, 0.8815077788963813, 0.7420382353344512, 0.7859162988708872, 0.6070586028658467, 0.584115633793495, 0.7037065224288731, 0.583073549656147, 0.8493539189474535, 0.999708301440111, 0.6324436374325302, 0.7147438400621149, 0.9129193596747636, 0.7839539023125923, 0.6095441924618263, 0.8579056220617711, 0.2194702179542507, 0.5193703819223963]}}
{"id": "04856490-d821-4ab5-abfa-c6576a9219b1", "fitness": 0.74182240696627, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with a simplified F and Cr update and focused perturbation strategy.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation with focused perturbation\n                idx = np.random.choice(self.pop_size, size=2, replace=False)\n                x1, x2 = self.pop[idx[0]], self.pop[idx[1]]\n                \n                # Focused perturbation: perturb only around the best solution\n                v = self.x_opt + self.F * (x1 - x2)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Simple bound handling\n                u = np.clip(u, self.lb, self.ub)\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr using leaky integration - simplified\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.5\n                    self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * 0.9\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                                        \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.742 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8eb126ff-afab-4dcd-9850-dac2ea49f79d"], "operator": null, "metadata": {"aucs": [0.4498509478696615, 0.9249054273640835, 0.9264051303574324, 0.9623827891248448, 0.283587962295366, 0.9425479809646579, 0.9181680195370394, 0.9185913449676879, 0.17080986537046028, 0.9216669562645032, 0.9666029901979539, 0.9994073139072491, 0.9019261367158891, 0.2998629035288425, 0.7416095861242492, 0.9354966804317347, 0.9063410946807597, 0.9579253792115315, 0.199398446959846, 0.5089611834516082]}}
{"id": "9b232423-5d21-4cb1-ba50-63d8e7780172", "fitness": -Infinity, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with improved parameter adaptation using a leaky integrator, mirroring, and boundary clipping.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, F_decay=0.99, Cr_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.F_decay = F_decay\n        self.Cr_decay = Cr_decay\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        \n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation with mirrored sampling\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n\n                # Mirroring if out of bounds\n                for j in range(self.dim):\n                    if v[j] < self.lb:\n                        v[j] = 2 * self.lb - v[j]\n                    elif v[j] > self.ub:\n                        v[j] = 2 * self.ub - v[j]\n                \n                v = np.clip(v, self.lb, self.ub) #Redundant after mirroring but safe\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                # Adaptive F and Cr (Leaky Integrator)\n                if np.random.rand() < 0.1:  # Small probability to adapt F and Cr\n                   self.F = self.F * self.F_decay + 0.1 * np.random.rand()\n                   self.Cr = self.Cr * self.Cr_decay + 0.1 * np.random.rand()\n                \n                self.F = np.clip(self.F, 0.1, 0.9) # Keep F in a reasonable range\n                self.Cr = np.clip(self.Cr, 0.1, 0.9) # Keep Cr in a reasonable range\n                \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["b99e604d-cfac-4384-9589-f2fa9a0565e2"], "operator": null, "metadata": {}}
{"id": "d3558c5d-684e-4afe-9063-2856137379e8", "fitness": 0.5513533120171836, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with decaying exploration and exploitation trade-off using linearly decreasing F and Cr.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.9, Cr_init=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_init = F_init\n        self.Cr_init = Cr_init\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        \n        while self.evals < self.budget:\n            # Linearly decrease F and Cr to shift from exploration to exploitation\n            F = self.F_init * (1 - self.evals / self.budget)\n            Cr = self.Cr_init * (1 - self.evals / self.budget)\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + F * (x2 - x3)\n                v = np.clip(v, self.lb, self.ub)  # Clipping\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.551 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b99e604d-cfac-4384-9589-f2fa9a0565e2"], "operator": null, "metadata": {"aucs": [0.18065698839955346, 0.25847181765964744, 0.4962343277808673, 0.7647793996667114, 0.6261353232319233, 0.6770211833959833, 0.46651607751538426, 0.4825528273691624, 0.5697602843434493, 0.5531778067003471, 0.7576569893711429, 0.9989550471688358, 0.3043109455323927, 0.534734975512202, 0.8152304263511057, 0.6701932525185649, 0.4104913297644428, 0.7568305775784402, 0.19651533995457204, 0.5068413205289426]}}
{"id": "a6b19796-21b1-495d-85da-3b41cada36f8", "fitness": 0.6119980828620364, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with reduced parameter set, greedy F adaptation, and per-dimension mirrored sampling for improved exploration around boundaries.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.Cr = Cr\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        \n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation with per-dimension mirrored sampling and greedy F adaptation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                \n                # Adaptive F: If x2 is better than x3, increase F; otherwise, decrease it\n                F = 0.5 + 0.3 * (self.fitness[idx[2]] > self.fitness[idx[1]]) \n\n                v = x1 + F * (x2 - x3)\n                \n                # Clipping to boundaries\n                v = np.clip(v, self.lb, self.ub)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.612 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b99e604d-cfac-4384-9589-f2fa9a0565e2"], "operator": null, "metadata": {"aucs": [0.20937725063439683, 0.5001601116426126, 0.5858247113946466, 0.8343987569244719, 0.6540371438677761, 0.7279846001663901, 0.5302977904392301, 0.5440513287744284, 0.639720025659551, 0.5239094173469565, 0.8153329311576346, 0.9942168952943097, 0.5104049355836566, 0.5489521526908627, 0.9167310158710763, 0.6993821161079659, 0.4989559958965375, 0.778778595586077, 0.20841527495245438, 0.5190306072496925]}}
{"id": "b9b36023-05f0-44d3-addb-ba9a53a63120", "fitness": 0.7526635015701337, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and probabilistic re-initialization based on stagnation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1, stagnation_threshold=10, reinit_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n        self.stagnation_threshold = stagnation_threshold\n        self.reinit_prob = reinit_prob  # Probability of re-initialization\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.stagnation_counter = np.zeros(self.pop_size)\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Simple bound handling\n                u = np.clip(u, self.lb, self.ub)\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr using leaky integration\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.9\n                    self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * 0.9\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    self.stagnation_counter[i] = 0\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Adapt F and Cr when the trial vector is not better\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.1\n                    self.stagnation_counter[i] += 1\n\n                # Probabilistic Re-initialization\n                if self.stagnation_counter[i] > self.stagnation_threshold:\n                    if np.random.rand() < self.reinit_prob:\n                        self.pop[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                        self.fitness[i] = func(self.pop[i])\n                        self.evals += 1\n                        self.stagnation_counter[i] = 0\n                        if self.fitness[i] < self.f_opt:\n                            self.f_opt = self.fitness[i]\n                            self.x_opt = self.pop[i]\n                    else:\n                        self.stagnation_counter[i] = 0  # Reset even if not re-initialized\n                \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.753 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d5de8052-60c5-434e-8051-f4db43b6b415"], "operator": null, "metadata": {"aucs": [0.46758447607219655, 0.7529625664449676, 0.5966918953448006, 0.882915241513335, 0.7854722475795409, 0.8081892118302993, 0.7282410977231446, 0.7284211887509984, 0.7765587417170702, 0.7628445484248674, 0.8691914275345431, 0.9900550774584597, 0.5988265512234958, 0.786709753150314, 0.9153218890475904, 0.792651066230356, 0.7186467173686275, 0.8674199698122602, 0.7038410848890699, 0.5207252792867361]}}
{"id": "071dec6b-077a-4ece-a5ac-5ecbc894f29b", "fitness": 0.570311092867525, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with per-dimension learning rates and scaled difference vectors for better exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = np.full(dim, F_init)  # Per-dimension F\n        self.Cr = np.full(dim, Cr_init)  # Per-dimension Cr\n        self.adapt_rate = adapt_rate\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n\n                # Scale difference vector by bounds\n                diff = (x2 - x3) \n                v = x1 + self.F * diff\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr[j] or j == j_rand:\n                        u[j] = v[j]\n\n                # Bound handling\n                u = np.clip(u, self.lb, self.ub)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr (per dimension)\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.9\n                    self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * 0.9\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Adapt F and Cr (per dimension) when the trial vector is not better\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.1\n                    self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * 0.1\n                \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.570 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d5de8052-60c5-434e-8051-f4db43b6b415"], "operator": null, "metadata": {"aucs": [0.16812317445861336, 0.2424321412878323, 0.5904826216667645, 0.7920537062269893, 0.7040262538372607, 0.7273697401363215, 0.5666152402237457, 0.5530500595106698, 0.6889819116114642, 0.39053470480345154, 0.516849919495997, 0.9992161650353331, 0.2743314403263385, 0.6206679659727765, 0.7751132152645408, 0.7725095389989358, 0.4518565774913672, 0.8179958437051964, 0.2531444338905351, 0.5008672034063673]}}
{"id": "31892518-2bd4-4cf9-bd84-9cc190d116db", "fitness": 0.7089271368016721, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a leaky integrator and success-history based parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1, hist_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n        self.hist_size = hist_size\n        self.F_hist = np.full(hist_size, F_init)\n        self.Cr_hist = np.full(hist_size, Cr_init)\n        self.hist_idx = 0\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                F = self.F_hist[np.random.randint(self.hist_size)]\n                v = x1 + F * (x2 - x3)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                Cr = self.Cr_hist[np.random.randint(self.hist_size)]\n                for j in range(self.dim):\n                    if np.random.rand() < Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Boundary handling (SAT)\n                u = np.clip(u, self.lb, self.ub)\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Update success history\n                    self.F_hist[self.hist_idx] = F\n                    self.Cr_hist[self.hist_idx] = Cr\n                    self.hist_idx = (self.hist_idx + 1) % self.hist_size\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.709 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d20832ac-ea59-49c6-a385-c192b2e27c33"], "operator": null, "metadata": {"aucs": [0.32107457272768947, 0.6680560204814714, 0.6813879430931211, 0.8621736861723756, 0.7555713165804714, 0.7914340398141897, 0.6350984262563605, 0.6878696233870358, 0.7443853797796339, 0.6690996897722346, 0.8831609057478017, 0.9991189735917411, 0.644269695549538, 0.7103015932685601, 0.9182719360728109, 0.777576206404729, 0.6636655105091009, 0.8207124176510726, 0.4287923232174198, 0.5165224759560811]}}
{"id": "86fe05e2-1bdc-401c-9657-61a828f25130", "fitness": 0.7029927992629388, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a success-history based adaptation and population diversity enhancement.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, memory_size=10, F_init=0.5, Cr_init=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.memory_size = memory_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.F_memory = np.full(memory_size, F_init)\n        self.Cr_memory = np.full(memory_size, Cr_init)\n        self.memory_idx = 0\n        self.success_F = []\n        self.success_Cr = []\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                self.F = self.F_memory[np.random.randint(self.memory_size)]\n                self.Cr = self.Cr_memory[np.random.randint(self.memory_size)]\n\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Boundary handling (clip)\n                u = np.clip(u, self.lb, self.ub)\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Update memory with successful parameters\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n            # Memory update\n            if self.success_F:\n                self.F_memory[self.memory_idx] = np.mean(self.success_F)\n                self.Cr_memory[self.memory_idx] = np.mean(self.success_Cr)\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n                self.success_F = []\n                self.success_Cr = []\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.703 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d20832ac-ea59-49c6-a385-c192b2e27c33"], "operator": null, "metadata": {"aucs": [0.3344584515570629, 0.6488106319729061, 0.652378680160973, 0.8682717763021504, 0.7482249761180897, 0.787996451835026, 0.6087830346843839, 0.6705502093599398, 0.7359848675999203, 0.6737377310118015, 0.8618371128267825, 0.9984714314302187, 0.6775685033922522, 0.7271619430521524, 0.908084470627682, 0.7816443489367495, 0.641775027414907, 0.8368710277774425, 0.3578089521476041, 0.539436357050731]}}
{"id": "fb1480b5-94f5-4ab9-aa62-70c2029ede74", "fitness": 0.7490352548100274, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation, mirrored boundary reflection and improved stagnation handling with local search.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1, stagnation_threshold=10, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n        self.stagnation_threshold = stagnation_threshold\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        self.stagnation_counter = np.zeros(self.pop_size)\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Mirrored boundary handling\n                u = np.where(u < self.lb, 2 * self.lb - u, u)\n                u = np.where(u > self.ub, 2 * self.ub - u, u)\n\n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Adapt F and Cr \n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.9\n                    self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * 0.9\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    self.stagnation_counter[i] = 0\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Adapt F and Cr when the trial vector is not better\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * 0.1\n                    self.stagnation_counter[i] += 1\n\n                # Stagnation check and re-initialization/local search\n                if self.stagnation_counter[i] > self.stagnation_threshold:\n                    if np.random.rand() < self.local_search_prob:\n                        # Perform local search around the current individual\n                        sigma = 0.1 * (self.ub - self.lb)  # Scale for local search\n                        u_local = self.pop[i] + np.random.normal(0, sigma, size=self.dim)\n                        u_local = np.clip(u_local, self.lb, self.ub)\n                        f_local = func(u_local)\n                        self.evals += 1\n\n                        if f_local < self.fitness[i]:\n                            self.pop[i] = u_local\n                            self.fitness[i] = f_local\n                            if f_local < self.f_opt:\n                                self.f_opt = f_local\n                                self.x_opt = u_local\n                    else:\n                        # Re-initialize if local search is not performed\n                        self.pop[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                        self.fitness[i] = func(self.pop[i])\n                        self.evals += 1\n                        if self.fitness[i] < self.f_opt:\n                            self.f_opt = self.fitness[i]\n                            self.x_opt = self.pop[i]\n                    self.stagnation_counter[i] = 0\n                \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.749 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d5de8052-60c5-434e-8051-f4db43b6b415"], "operator": null, "metadata": {"aucs": [0.5244007753768809, 0.464486022823112, 0.7073284728051739, 0.8919548035432822, 0.7786806408389645, 0.7953469115400007, 0.7281753432128988, 0.6975807422086696, 0.7802377702512138, 0.7360592521751481, 0.8995690939582844, 0.9969406424317503, 0.7331319655362828, 0.7881388999262305, 0.9304838306891904, 0.8246581812870815, 0.6882847733911497, 0.8582336841183938, 0.6415505616134369, 0.5154627284734014]}}
{"id": "5e686b71-4590-475f-85b8-a0adb3630019", "fitness": 0.6805536509182067, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with rank-based mutation, boundary reflection, and dynamic learning rate, focusing on exploitation near the best solutions.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.lr = lr # Learning Rate for F and Cr adaptation\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        \n        while self.evals < self.budget:\n            # Sort population by fitness\n            ranked_indices = np.argsort(self.fitness)\n            self.pop = self.pop[ranked_indices]\n            self.fitness = self.fitness[ranked_indices]\n\n            for i in range(self.pop_size):\n                # Rank-based Mutation (focusing on better individuals)\n                idx = np.random.choice(min(self.pop_size, 10), size=3, replace=False) # Bias towards better solutions\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                \n                v = x1 + self.F * (x2 - x3)\n                \n                # Boundary Reflection\n                v = np.where(v < self.lb, 2 * self.lb - v, v)\n                v = np.where(v > self.ub, 2 * self.ub - v, v)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Update F and Cr based on success (simplified)\n                    delta_f = self.fitness[i] - f_u\n                    self.F = self.F + self.lr * delta_f * (1 - self.F) # Adjust F towards 1 if improvement is high\n                    self.Cr = self.Cr + self.lr * delta_f * (1 - self.Cr) # Adjust Cr towards 1 if improvement is high\n\n                    self.F = np.clip(self.F, 0.1, 0.9) # Keep F within reasonable bounds\n                    self.Cr = np.clip(self.Cr, 0.1, 0.9) # Keep Cr within reasonable bounds\n\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.681 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b99e604d-cfac-4384-9589-f2fa9a0565e2"], "operator": null, "metadata": {"aucs": [0.25489645760532853, 0.382845511853392, 0.7566197873618199, 0.9408700202103608, 0.8297115163087676, 0.878467146892481, 0.8236497938210781, 0.7019467272529643, 0.8592579960468194, 0.20735481969395253, 0.9289625223104804, 0.9968133339487631, 0.33907570440017054, 0.37891491756754714, 0.9209079182238111, 0.8922449571982577, 0.816676105976669, 0.9267571384757173, 0.2735946983786395, 0.5015059448371157]}}
{"id": "e5839688-3316-4be3-8d07-1b2cf7b4cf3e", "fitness": 0.42462459253034035, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using success history, population size reduction, and a Cauchy mutation operator for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1, pop_reduction_rate=0.05, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.pop_size_init = pop_size_init\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n        self.pop_reduction_rate = pop_reduction_rate\n        self.cauchy_scale = cauchy_scale\n        self.success_F = []\n        self.success_Cr = []\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Parameter Adaptation\n                F = np.random.normal(self.F, 0.1)\n                F = np.clip(F, 0.1, 1.0)  # Clip to ensure reasonable values\n                Cr = np.random.normal(self.Cr, 0.1)\n                Cr = np.clip(Cr, 0.1, 1.0)\n\n                # Mutation (Cauchy)\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + F * (x2 - x3) + self.cauchy_scale * np.random.standard_cauchy(size=self.dim) # Cauchy mutation\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Boundary Handling (clip)\n                u = np.clip(u, self.lb, self.ub)\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        self.success_F.append(F)\n                        self.success_Cr.append(Cr)\n\n                    # Simplified F/Cr update using success history\n                    if len(self.success_F) > 10:\n                        self.success_F = self.success_F[-10:]\n                        self.success_Cr = self.success_Cr[-10:]\n                        self.F = np.mean(self.success_F)\n                        self.Cr = np.mean(self.success_Cr)\n\n                if self.evals >= self.budget:\n                    break\n            \n            # Population size reduction\n            if self.evals > self.budget * 0.5 and self.pop_size > 10: # start reducing after half budget\n                new_pop_size = int(self.pop_size * (1 - self.pop_reduction_rate))\n                if new_pop_size < 10:\n                    new_pop_size = 10\n                \n                # Keep the best individuals\n                idx = np.argsort(self.fitness)[:new_pop_size]\n                self.pop = self.pop[idx]\n                self.fitness = self.fitness[idx]\n                self.pop_size = new_pop_size\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.425 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d20832ac-ea59-49c6-a385-c192b2e27c33"], "operator": null, "metadata": {"aucs": [0.18618086792120392, 0.3254968144252671, 0.4028180559380349, 0.679088687594605, 0.3296177837407228, 0.4140706170520657, 0.3012420689828228, 0.3561883698231566, 0.3344726920875085, 0.2624279080940636, 0.4954175545929862, 0.9986161400558844, 0.28191464919830866, 0.3379440900906472, 0.7831813861081098, 0.4105534059911782, 0.3445875245540535, 0.519150865352541, 0.22855476395457341, 0.5009676050490748]}}
{"id": "a529a9f1-f26e-41bc-8cee-954198703d0b", "fitness": 0.6959502813509865, "name": "AdaptiveDE", "description": "Simplified Adaptive DE with self-adaptive mutation factor, mirrored sampling, boundary handling, and reduced parameter tuning.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5  # Fixed mutation factor\n        self.Cr = 0.9 # Fixed crossover rate\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n        \n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation with mirrored sampling\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                \n                # Adaptive F:  F is drawn from a normal distribution\n                F = np.random.normal(self.F, 0.1)\n                F = np.clip(F, 0.1, 1.0) #clip the value between 0.1 and 1.0\n                v = x1 + F * (x2 - x3)\n                \n                # Boundary handling: Reflect at boundaries\n                v = np.where(v < self.lb, 2 * self.lb - v, v)\n                v = np.where(v > self.ub, 2 * self.ub - v, v)\n                \n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.696 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b99e604d-cfac-4384-9589-f2fa9a0565e2"], "operator": null, "metadata": {"aucs": [0.32071137678612427, 0.6714605400554995, 0.7038465421600303, 0.8792598682152142, 0.7503311905480876, 0.7866163264235937, 0.626462510025954, 0.6799858482926411, 0.7176341400403592, 0.6788599974661483, 0.8724169436646463, 0.9859247677917444, 0.6307679322958968, 0.7339604763441506, 0.8155902799523458, 0.7443717797537228, 0.5968233893063424, 0.8489156183396581, 0.3493071988426786, 0.5257589007148906]}}
{"id": "26950f70-2205-4947-adf9-1b827db2df01", "fitness": 0.7102511285661295, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with momentum-based parameter adaptation and enhanced boundary handling using reflecting bounds.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, Cr_init=0.9, adapt_rate=0.1, momentum=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.Cr = Cr_init\n        self.adapt_rate = adapt_rate\n        self.momentum = momentum\n        self.F_velocity = 0.0\n        self.Cr_velocity = 0.0\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idx = np.random.choice(self.pop_size, size=3, replace=False)\n                x1, x2, x3 = self.pop[idx[0]], self.pop[idx[1]], self.pop[idx[2]]\n                v = x1 + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Reflecting Bounds\n                u = np.where(u < self.lb, 2 * self.lb - u, u)\n                u = np.where(u > self.ub, 2 * self.ub - u, u)\n                \n                # Selection\n                f_u = func(u)\n                self.evals += 1\n\n                if f_u < self.fitness[i]:\n                    # Momentum-based adaptation\n                    delta_F = 0.5 - self.F\n                    delta_Cr = 0.9 - self.Cr\n\n                    self.F_velocity = self.momentum * self.F_velocity + (1 - self.momentum) * delta_F\n                    self.Cr_velocity = self.momentum * self.Cr_velocity + (1 - self.momentum) * delta_Cr\n\n                    self.F += self.adapt_rate * self.F_velocity\n                    self.Cr += self.adapt_rate * self.Cr_velocity\n                    \n                    self.F = np.clip(self.F, 0.1, 0.9)\n                    self.Cr = np.clip(self.Cr, 0.1, 0.9)\n                    \n                    self.pop[i] = u\n                    self.fitness[i] = f_u\n                    \n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                                        \n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.710 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["04856490-d821-4ab5-abfa-c6576a9219b1"], "operator": null, "metadata": {"aucs": [0.323326112483595, 0.680639507318565, 0.682647000860716, 0.8785938861708941, 0.7674521429585035, 0.7801767924995009, 0.6412837279572376, 0.6753496015900441, 0.7309202674156191, 0.7093005318625856, 0.8814885190054972, 0.9984829544562315, 0.6862267806531351, 0.7182621705487793, 0.9304469883287252, 0.7855740802802069, 0.6537293523179275, 0.8435823825493138, 0.30989039475007996, 0.5276493773154314]}}
