{"id": "e661735d-7070-4a9f-81a2-ddb291e0c76e", "fitness": 0.0, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with shrinking population and archive.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Crossover rate\n        self.CR = 0.7 # Mutation factor\n        self.shrink_factor = 0.99 # Shrink population by this factor each time the budget is significantly decreased.\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize population and archive\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))\n        archive_fitness = np.array([func(x) for x in archive])\n        self.budget -= self.archive_size\n        \n        # Update optimal solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size + self.archive_size, 3, replace=False)\n                \n                if indices[0] < self.pop_size:\n                  x1 = population[indices[0]]\n                else:\n                  x1 = archive[indices[0] - self.pop_size]\n\n                if indices[1] < self.pop_size:\n                  x2 = population[indices[1]]\n                else:\n                  x2 = archive[indices[1] - self.pop_size]\n                \n                if indices[2] < self.pop_size:\n                  x3 = population[indices[2]]\n                else:\n                  x3 = archive[indices[2] - self.pop_size]\n                  \n                mutant = population[i] + self.F * (x2 - x3)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub) # check bounds\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                \n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    #Update archive\n                    worst_archive_index = np.argmax(archive_fitness)\n                    if f < archive_fitness[worst_archive_index]:\n                        archive_fitness[worst_archive_index] = f\n                        archive[worst_archive_index] = trial.copy()\n                \n                # Update optimal solution\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = trial.copy()\n\n            #Shrink population if budget is significantly decreased\n            if self.budget < self.budget * 0.5:\n                self.pop_size = int(self.pop_size * self.shrink_factor)\n                self.pop_size = max(int(5), self.pop_size) #minimum population size\n                \n                #Reduce the population size of existing population\n                indices = np.argsort(fitness)[:self.pop_size]\n                population = population[indices]\n                fitness = fitness[indices]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}}
{"id": "7e1649fa-cad5-433f-9f48-2787c8ca578e", "fitness": -Infinity, "name": "CMAES", "description": "Covariance matrix adaptation evolution strategy with adaptive step size control and restart mechanism.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=None, c_cov=None, c_mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n\n        self.cs = cs\n        self.damp = damp if damp is not None else 1 + 2 * np.max([0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1]) + self.cs\n        self.c_cov = c_cov if c_cov is not None else 2 / ((self.dim + np.sqrt(2))**2)\n        self.c_mu = c_mu if c_mu is not None else min(1, self.mu / sum(range(1, self.mu + 1)))\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize mean and covariance matrix\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = 0.3  # Initial step size\n        C = np.eye(self.dim)  # Initial covariance matrix\n\n        # Evolution path\n        p_sigma = np.zeros(self.dim)\n        p_c = np.zeros(self.dim)\n\n        # Evolution loop\n        evals = 0\n        while evals < self.budget:\n            # Sample population\n            Z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            try:\n                A = np.linalg.cholesky(C)\n                X = mean[:, np.newaxis] + sigma * A @ Z\n            except np.linalg.LinAlgError:\n                # If C is not positive definite, add a small identity matrix\n                C += 1e-6 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                X = mean[:, np.newaxis] + sigma * A @ Z\n            \n            # Ensure the solutions are within the bounds\n            X = np.clip(X, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            fitness = np.array([func(x) for x in X.T])\n            evals += self.popsize\n\n            # Sort population\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            X = X[:, idx]\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = X[:, 0]\n\n            # Update mean\n            mean_old = mean.copy()\n            mean = np.mean(X[:, :self.mu], axis=1)\n\n            # Update evolution paths\n            y = (mean - mean_old) / sigma\n            p_sigma = (1 - self.cs) * p_sigma + np.sqrt(self.cs * (2 - self.cs) * self.mu) * A @ (mean - mean_old) / sigma\n            hsig = np.linalg.norm(p_sigma) / np.sqrt(1 - (1 - self.cs)**(2 * evals / self.popsize)) / 1.4 > 1 + 2 / (self.dim + 1)\n            p_c = (1 - self.c_cov) * p_c + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * self.mu) * (mean - mean_old) / sigma\n\n            # Update covariance matrix\n            C = (1 - self.c_cov) * C + self.c_cov / self.mu * p_c[:, np.newaxis] @ p_c[np.newaxis, :]\n            for i in range(self.mu):\n                C += self.c_mu * (X[:, i] - mean_old)[:, np.newaxis] @ (X[:, i] - mean_old)[np.newaxis, :] / sigma**2\n\n            # Update step size\n            sigma *= np.exp((self.cs / self.damp) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n            \n            if np.isinf(self.f_opt) or np.isnan(self.f_opt): #Restart Mechanism\n                mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                sigma = 0.3\n                C = np.eye(self.dim)\n                p_sigma = np.zeros(self.dim)\n                p_c = np.zeros(self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "60db4901-fe9c-4338-99d8-c22fdb5d1c4e", "fitness": 0.0, "name": "AdaptiveDE", "description": "An adaptive differential evolution strategy that adjusts its parameters based on the success of previous generations, incorporating a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, restart_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.Cr = Cr  # Crossover probability\n        self.restart_factor = restart_factor # Probability of restart\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n        \n    def adapt_parameters(self):\n        # Adaptive F: Increase if stagnation is detected, decrease if progress is good\n        if np.std(self.fitness) < 1e-6:  # Stagnation\n            self.F = min(self.F * 1.2, 1.0)\n        else:\n            self.F = max(self.F * 0.9, 0.1)\n\n        # Adaptive Cr: Increase if the population diversity is low, decrease otherwise\n        if len(np.unique(self.fitness)) < self.pop_size * 0.2:  # Low diversity\n            self.Cr = min(self.Cr * 1.1, 1.0)\n        else:\n            self.Cr = max(self.Cr * 0.9, 0.05)\n\n\n    def restart_population(self, func):\n         # Restart a portion of the population to encourage exploration\n        num_restart = int(self.restart_factor * self.pop_size)\n        restart_indices = np.random.choice(self.pop_size, num_restart, replace=False)\n        self.pop[restart_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_restart, self.dim))\n        self.fitness[restart_indices] = np.array([func(x) for x in self.pop[restart_indices]])\n        self.eval_count += num_restart\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n            # Periodically restart the population\n            if self.eval_count % (self.budget // 10) == 0:\n                self.restart_population(func)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}}
{"id": "50e79e06-c27b-4a16-af01-e335fb5a9b98", "fitness": 0.26773244029574184, "name": "CMABiasedRepair", "description": "Covariance Matrix Adaptation Evolution Strategy with Biased sampling and Repair Mechanism.", "code": "import numpy as np\n\nclass CMABiasedRepair:\n    def __init__(self, budget=10000, dim=10, mu_ratio=0.25, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(mu_ratio * budget)  # Number of parents\n        self.sigma0 = sigma0  # Initial step size\n        self.C = np.eye(dim)  # Covariance matrix\n        self.pc = np.zeros(dim)  # Evolution path for C\n        self.ps = np.zeros(dim)  # Evolution path for sigma\n        self.chiN = dim**0.5 * (1 - (1/(4*dim)) + 1/(21*dim**2)) # Expectation of ||N(0,I)||\n\n        self.c_sigma = (self.mu / budget) ** 0.5\n        self.c_c = (4 + self.mu/dim) / (dim + 4 + 2*self.mu/dim)\n        self.c_1 = 2 / ((dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu-1) / ((dim + 2)**2 + self.mu))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu-1)/(dim+1)) - 1) + self.c_sigma\n        self.mu = int(budget/10)\n        self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.m = (func.bounds.ub + func.bounds.lb) / 2 * np.ones(self.dim) \n        self.sigma = self.sigma0\n        \n        used_budget = 0\n        while used_budget < self.budget:\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.mu)\n            x = self.m + self.sigma * z\n            \n            # Repair mechanism: Clip values to stay within bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            used_budget += self.mu\n            if used_budget > self.budget:\n                f = f[:self.mu - (used_budget - self.budget)]\n                x = x[:self.mu - (used_budget - self.budget)]\n                used_budget = self.budget\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_sorted = x[idx]\n            z_sorted = z[idx]\n\n            # Update CMA-ES parameters\n            self.m = np.sum(self.weights[:, None] * x_sorted[:self.mu], axis=0)\n            zmean = np.sum(self.weights[:, None] * z_sorted[:self.mu], axis=0)\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * zmean\n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * (used_budget / self.mu))) / self.chiN < 1.4 + 2 / (self.dim + 1)\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (self.m - self.m) / self.sigma\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :]) + self.c_mu * np.sum(self.weights[:, None, None] * (z_sorted[:self.mu, :, None] @ z_sorted[:self.mu, None, :]), axis=0)\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                self.C = np.linalg.cholesky(self.C)\n                self.C = self.C @ self.C.T\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)  # Reset covariance matrix if not positive definite\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CMABiasedRepair scored 0.268 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.11154486513108641, 0.23520834109176436, 0.35326942169575803, 0.1899459314560924, 0.2007044698967274, 0.22515575476500094, 0.24003005292608948, 0.23947212013965213, 0.22353997466225173, 0.1637661661440437, 0.2782919738123526, 0.6768765781111749, 0.26950721991237403, 0.1904211175014887, 0.41831472623174293, 0.2885241158074595, 0.24152353704601215, 0.25106887496565244, 0.1795314424372354, 0.3779521221808786]}}
{"id": "e3baa148-f48b-406b-bc78-6f56c71875a4", "fitness": -Infinity, "name": "CMAES", "description": "Covariance Matrix Adaptation Evolution Strategy with simplified updates and a robust Cholesky decomposition to prevent errors.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=None, c_cov=None, c_mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n\n        self.cs = cs\n        self.damp = damp if damp is not None else 1 + 2 * np.max([0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1]) + self.cs\n        self.c_cov = c_cov if c_cov is not None else 2 / ((self.dim + np.sqrt(2))**2)\n        self.c_mu = c_mu if c_mu is not None else min(1, self.mu / sum(range(1, self.mu + 1)))\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize mean and covariance matrix\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = 0.3  # Initial step size\n        C = np.eye(self.dim)  # Initial covariance matrix\n\n        # Evolution path\n        p_sigma = np.zeros(self.dim)\n        p_c = np.zeros(self.dim)\n\n        # Evolution loop\n        evals = 0\n        while evals < self.budget:\n            # Sample population\n            Z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            try:\n                A = np.linalg.cholesky(C)\n                X = mean[:, np.newaxis] + sigma * A @ Z\n            except np.linalg.LinAlgError:\n                # If C is not positive definite, add a small identity matrix\n                C += 1e-6 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                X = mean[:, np.newaxis] + sigma * A @ Z\n            \n            # Ensure the solutions are within the bounds\n            X = np.clip(X, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            fitness = np.array([func(x) for x in X.T])\n            evals += self.popsize\n\n            # Sort population\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            X = X[:, idx]\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = X[:, 0]\n\n            # Update mean\n            mean_old = mean.copy()\n            mean = np.mean(X[:, :self.mu], axis=1)\n\n            # Update evolution paths\n            y = (mean - mean_old) / sigma\n            p_sigma = (1 - self.cs) * p_sigma + np.sqrt(self.cs * (2 - self.cs) * self.mu) * y\n            hsig = np.linalg.norm(p_sigma) / np.sqrt(1 - (1 - self.cs)**(2 * evals / self.popsize)) / 1.4 > 1 + 2 / (self.dim + 1)\n            p_c = (1 - self.c_cov) * p_c + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * self.mu) * y\n\n            # Update covariance matrix\n            C = (1 - self.c_cov) * C + self.c_cov / self.mu * p_c[:, np.newaxis] @ p_c[np.newaxis, :]\n            C += self.c_mu * np.sum([(X[:, i] - mean_old)[:, np.newaxis] @ (X[:, i] - mean_old)[np.newaxis, :] / sigma**2 for i in range(self.mu)], axis=0)\n\n            # Update step size\n            sigma *= np.exp((self.cs / self.damp) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n            \n            if np.isinf(self.f_opt) or np.isnan(self.f_opt): #Restart Mechanism\n                mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                sigma = 0.3\n                C = np.eye(self.dim)\n                p_sigma = np.zeros(self.dim)\n                p_c = np.zeros(self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["7e1649fa-cad5-433f-9f48-2787c8ca578e"], "operator": null, "metadata": {}}
{"id": "516935f4-7af1-4250-81e3-53897ebb8513", "fitness": 0.0, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with dynamic parameter adaptation based on population diversity and stagnation detection, and a restart mechanism.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, restart_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.restart_factor = restart_factor\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.update_best()\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                self.update_best()\n\n    def adapt_parameters(self):\n        if np.std(self.fitness) < 1e-6:\n            self.F = min(self.F * 1.1, 1.0)\n        else:\n            self.F = max(self.F * 0.9, 0.1)\n\n        if len(np.unique(self.fitness)) < self.pop_size * 0.2:\n            self.Cr = min(self.Cr * 1.1, 1.0)\n        else:\n            self.Cr = max(self.Cr * 0.9, 0.05)\n\n    def restart_population(self, func):\n        num_restart = int(self.restart_factor * self.pop_size)\n        restart_indices = np.random.choice(self.pop_size, num_restart, replace=False)\n        self.pop[restart_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_restart, self.dim))\n        self.fitness[restart_indices] = np.array([func(x) for x in self.pop[restart_indices]])\n        self.eval_count += num_restart\n        self.update_best()\n\n    def update_best(self):\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n            if self.eval_count % (self.budget // 10) == 0:\n                self.restart_population(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["60db4901-fe9c-4338-99d8-c22fdb5d1c4e"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "052fe1d7-e6eb-4561-8966-0793f977207a", "fitness": 0.0, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with an archive, dynamically adjusted crossover rate, and population shrinking.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Mutation factor\n        self.CR = 0.7 # Initial Crossover rate\n        self.shrink_factor = 0.99 # Shrink population by this factor\n        self.min_pop_size = 5\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize population and archive\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))\n        archive_fitness = np.array([func(x) for x in archive])\n        self.budget -= self.archive_size\n        \n        # Update optimal solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size + self.archive_size, 3, replace=False)\n                \n                x1 = population[indices[0] % self.pop_size] if indices[0] < self.pop_size else archive[indices[0] - self.pop_size]\n                x2 = population[indices[1] % self.pop_size] if indices[1] < self.pop_size else archive[indices[1] - self.pop_size]\n                x3 = population[indices[2] % self.pop_size] if indices[2] < self.pop_size else archive[indices[2] - self.pop_size]\n                  \n                mutant = population[i] + self.F * (x2 - x3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover - Adapt CR based on current fitness\n                self.CR = 0.7 + 0.2 * np.exp(-np.abs(fitness[i] - self.f_opt))\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                \n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    #Update archive\n                    worst_archive_index = np.argmax(archive_fitness)\n                    if f < archive_fitness[worst_archive_index]:\n                        archive_fitness[worst_archive_index] = f\n                        archive[worst_archive_index] = trial.copy()\n                \n                # Update optimal solution\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = trial.copy()\n\n            #Shrink population if budget is significantly decreased\n            if self.budget < 0.5 * self.budget:\n                self.pop_size = int(self.pop_size * self.shrink_factor)\n                self.pop_size = max(self.min_pop_size, self.pop_size)\n                \n                #Reduce the population size of existing population\n                indices = np.argsort(fitness)[:self.pop_size]\n                population = population[indices]\n                fitness = fitness[indices]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e661735d-7070-4a9f-81a2-ddb291e0c76e"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "61521e55-967c-4453-b8ff-705a8bd84aa0", "fitness": 0.0, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with adaptive F and Cr, and periodic population restarts.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, restart_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.restart_factor = restart_factor\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        if np.std(self.fitness) < 1e-6:\n            self.F = min(self.F * 1.1, 0.9)\n            self.Cr = min(self.Cr * 1.1, 0.9)\n        else:\n            self.F = max(self.F * 0.9, 0.1)\n            self.Cr = max(self.Cr * 0.9, 0.1)\n\n    def restart_population(self, func):\n        num_restart = int(self.restart_factor * self.pop_size)\n        restart_indices = np.random.choice(self.pop_size, num_restart, replace=False)\n        self.pop[restart_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_restart, self.dim))\n        self.fitness[restart_indices] = np.array([func(x) for x in self.pop[restart_indices]])\n        self.eval_count += num_restart\n        best_index = np.argmin(self.fitness)\n        self.f_opt = min(self.f_opt, self.fitness[best_index])\n        self.x_opt = self.pop[best_index]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n            if self.eval_count % (self.budget // 10) == 0:\n                self.restart_population(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["60db4901-fe9c-4338-99d8-c22fdb5d1c4e"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "e327c26a-b67b-4a94-aa4e-af29aa6793cd", "fitness": -Infinity, "name": "CMAES", "description": "CMA-ES with simplified update rules, bound correction, and restart mechanism.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=None, c_cov=None, c_mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n\n        self.cs = cs\n        self.damp = damp if damp is not None else 1 + 2 * np.max([0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1]) + self.cs\n        self.c_cov = c_cov if c_cov is not None else 2 / ((self.dim + np.sqrt(2))**2)\n        self.c_mu = c_mu if c_mu is not None else min(1, self.mu / sum(range(1, self.mu + 1)))\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize mean and covariance matrix\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = 0.3  # Initial step size\n        C = np.eye(self.dim)  # Initial covariance matrix\n\n        # Evolution path\n        p_sigma = np.zeros(self.dim)\n        p_c = np.zeros(self.dim)\n\n        # Evolution loop\n        evals = 0\n        while evals < self.budget:\n            # Sample population\n            Z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            try:\n                A = np.linalg.cholesky(C)\n                X = mean[:, np.newaxis] + sigma * A @ Z\n            except np.linalg.LinAlgError:\n                # If C is not positive definite, add a small identity matrix\n                C += 1e-6 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                X = mean[:, np.newaxis] + sigma * A @ Z\n            \n            # Ensure the solutions are within the bounds\n            X = np.clip(X, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            fitness = np.array([func(X[:, i]) for i in range(self.popsize)])\n            evals += self.popsize\n\n            # Sort population\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            X = X[:, idx]\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = X[:, 0].copy()\n\n            # Update mean\n            mean_old = mean.copy()\n            mean = np.mean(X[:, :self.mu], axis=1)\n\n            # Update evolution paths\n            y = (mean - mean_old) / sigma\n            p_sigma = (1 - self.cs) * p_sigma + np.sqrt(self.cs * (2 - self.cs) * self.mu) * y\n            hsig = np.linalg.norm(p_sigma) / np.sqrt(1 - (1 - self.cs)**(2 * evals / self.popsize)) / 1.4 > 1 + 2 / (self.dim + 1)\n            p_c = (1 - self.c_cov) * p_c + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * self.mu) * y\n\n            # Update covariance matrix\n            C = (1 - self.c_cov) * C + self.c_cov / self.mu * p_c[:, np.newaxis] @ p_c[np.newaxis, :]\n            C += self.c_mu * np.mean([(X[:, i] - mean_old)[:, np.newaxis] @ (X[:, i] - mean_old)[np.newaxis, :] for i in range(self.mu)], axis=0) / sigma**2\n\n            # Update step size\n            sigma *= np.exp((self.cs / self.damp) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n            \n            if np.isinf(self.f_opt) or np.isnan(self.f_opt): #Restart Mechanism\n                mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                sigma = 0.3\n                C = np.eye(self.dim)\n                p_sigma = np.zeros(self.dim)\n                p_c = np.zeros(self.dim)\n\n            if evals >= self.budget:\n                break\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["7e1649fa-cad5-433f-9f48-2787c8ca578e"], "operator": null, "metadata": {}}
{"id": "915db845-c96c-48bb-9444-9a419a596125", "fitness": -Infinity, "name": "CMAES", "description": "Covariance matrix adaptation evolution strategy with simplified updates and a robust handling of covariance matrix decomposition.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=None, c_cov=None, c_mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n\n        self.cs = cs\n        self.damp = damp if damp is not None else 1 + 2 * np.max([0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1]) + self.cs\n        self.c_cov = c_cov if c_cov is not None else 2 / ((self.dim + np.sqrt(2))**2)\n        self.c_mu = c_mu if c_mu is not None else min(1, self.mu / sum(range(1, self.mu + 1)))\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize mean and covariance matrix\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = 0.3  # Initial step size\n        C = np.eye(self.dim)  # Initial covariance matrix\n\n        # Evolution path\n        p_sigma = np.zeros(self.dim)\n        p_c = np.zeros(self.dim)\n\n        # Evolution loop\n        evals = 0\n        while evals < self.budget:\n            # Sample population\n            Z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            try:\n                A = np.linalg.cholesky(C)\n                X = mean[:, np.newaxis] + sigma * A @ Z\n            except np.linalg.LinAlgError:\n                # If C is not positive definite, add a small identity matrix\n                C += 1e-6 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                X = mean[:, np.newaxis] + sigma * A @ Z\n            \n            # Ensure the solutions are within the bounds\n            X = np.clip(X, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            fitness = np.array([func(x) for x in X.T])\n            evals += self.popsize\n\n            # Sort population\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            X = X[:, idx]\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = X[:, 0].copy()\n\n            # Update mean\n            mean_old = mean.copy()\n            mean = np.mean(X[:, :self.mu], axis=1)\n\n            # Update evolution paths\n            y = (mean - mean_old) / sigma\n            p_sigma = (1 - self.cs) * p_sigma + np.sqrt(self.cs * (2 - self.cs) * self.mu) * A @ y\n            hsig = np.linalg.norm(p_sigma) / np.sqrt(1 - (1 - self.cs)**(2 * evals / self.popsize)) / 1.4 < 1 + 2 / (self.dim + 1)\n            \n            p_c = (1 - self.c_cov) * p_c + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * self.mu) * y\n\n            # Update covariance matrix\n            C = (1 - self.c_cov) * C + self.c_cov / self.mu * p_c[:, np.newaxis] @ p_c[np.newaxis, :]\n            C += self.c_mu * np.sum([w * ((X[:, i] - mean_old)[:, np.newaxis] @ (X[:, i] - mean_old)[np.newaxis, :]) / sigma**2\n                                     for i, w in enumerate(np.ones(self.mu)/self.mu)], axis=0) #Simplified update with equal weights\n\n            # Update step size\n            sigma *= np.exp((self.cs / self.damp) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n            \n            if np.isinf(self.f_opt) or np.isnan(self.f_opt): #Restart Mechanism\n                mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                sigma = 0.3\n                C = np.eye(self.dim)\n                p_sigma = np.zeros(self.dim)\n                p_c = np.zeros(self.dim)\n            \n            if evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["7e1649fa-cad5-433f-9f48-2787c8ca578e"], "operator": null, "metadata": {}}
{"id": "f6aa30b1-5792-4331-8466-e58a56d3bfe4", "fitness": 0.0, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with parameter adaptation based on population diversity and stagnation, and periodic restarts.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, restart_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.Cr = Cr  # Crossover probability\n        self.restart_factor = restart_factor # Probability of restart\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n        \n    def adapt_parameters(self):\n        # Adaptive F: Increase if stagnation is detected, decrease if progress is good\n        if np.std(self.fitness) < 1e-6:  # Stagnation\n            self.F = min(self.F * 1.1, 1.0)\n        else:\n            self.F = max(self.F * 0.9, 0.1)\n\n        # Adaptive Cr: Increase if the population diversity is low, decrease otherwise\n        if len(np.unique(self.fitness)) < self.pop_size * 0.2:  # Low diversity\n            self.Cr = min(self.Cr * 1.1, 1.0)\n        else:\n            self.Cr = max(self.Cr * 0.9, 0.05)\n\n\n    def restart_population(self, func):\n         # Restart a portion of the population to encourage exploration\n        num_restart = int(self.restart_factor * self.pop_size)\n        restart_indices = np.random.choice(self.pop_size, num_restart, replace=False)\n        self.pop[restart_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_restart, self.dim))\n        self.fitness[restart_indices] = np.array([func(x) for x in self.pop[restart_indices]])\n        self.eval_count += num_restart\n\n        best_index = np.argmin(self.fitness[restart_indices])\n        if self.fitness[restart_indices][best_index] < self.f_opt:\n            self.f_opt = self.fitness[restart_indices][best_index]\n            self.x_opt = self.pop[restart_indices][best_index]\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n            # Periodically restart the population\n            if self.eval_count % (self.budget // 10) == 0:\n                self.restart_population(func)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["60db4901-fe9c-4338-99d8-c22fdb5d1c4e"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "51a01f27-ef60-4c5e-89bb-a30215f91b50", "fitness": 0.26992789887226165, "name": "CMASimpleRepair", "description": "Simplified CMA-ES with adaptive step size, covariance matrix update, and a repair mechanism to ensure solutions stay within bounds, focusing on efficiency and stability.", "code": "import numpy as np\n\nclass CMASimpleRepair:\n    def __init__(self, budget=10000, dim=10, mu_ratio=0.25, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(mu_ratio * budget)  # Number of parents\n        self.sigma0 = sigma0  # Initial step size\n        self.C = np.eye(dim)  # Covariance matrix\n        self.ps = np.zeros(dim)  # Evolution path for sigma\n        self.chiN = dim**0.5 * (1 - (1/(4*dim)) + 1/(21*dim**2)) # Expectation of ||N(0,I)||\n\n        self.c_sigma = (self.mu / budget) ** 0.5\n        self.c_1 = 2 / ((dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu-1) / ((dim + 2)**2 + self.mu))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu-1)/(dim+1)) - 1) + self.c_sigma\n        self.mu = int(budget/10)\n        self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.m = (func.bounds.ub + func.bounds.lb) / 2 * np.ones(self.dim)\n        self.sigma = self.sigma0\n        \n        used_budget = 0\n        while used_budget < self.budget:\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.mu)\n            x = self.m + self.sigma * z\n            \n            # Repair mechanism: Clip values to stay within bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            used_budget += self.mu\n            if used_budget > self.budget:\n                f = f[:self.mu - (used_budget - self.budget)]\n                x = x[:self.mu - (used_budget - self.budget)]\n                used_budget = self.budget\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_sorted = x[idx]\n            z_sorted = z[idx]\n\n            # Update CMA-ES parameters - simplified\n            self.m = np.sum(self.weights[:, None] * x_sorted[:self.mu], axis=0)\n            zmean = np.sum(self.weights[:, None] * z_sorted[:self.mu], axis=0)\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * zmean\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * np.outer(self.ps, self.ps) + self.c_mu * np.sum(self.weights[:, None, None] * (z_sorted[:self.mu, :, None] @ z_sorted[:self.mu, None, :]), axis=0)\n\n            # Ensure C remains symmetric\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n\n            # Handle potential numerical instability\n            try:\n                np.linalg.cholesky(self.C)  # Check if positive definite\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)  # Reset if not positive definite\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm CMASimpleRepair scored 0.270 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["50e79e06-c27b-4a16-af01-e335fb5a9b98"], "operator": null, "metadata": {"aucs": [0.11308446445798126, 0.22334559886599326, 0.34356218238748903, 0.19388192342471788, 0.19320671142164825, 0.21687023898680613, 0.24141038752100386, 0.239157427753378, 0.21103746333981577, 0.16185937121177085, 0.27566542077885825, 0.738792066086825, 0.27039881273743105, 0.20190317937547675, 0.44428191014820695, 0.2905601779209295, 0.23564091532477538, 0.23806420556200114, 0.17619227005263216, 0.38964325008749334]}}
{"id": "06b0c8e6-cce4-4324-b171-f214a5e7496a", "fitness": 0.2695621315441888, "name": "CMASimpleRepair", "description": "Simplified CMA-ES with clipping repair and dynamic population size, focusing on efficiency and robustness.", "code": "import numpy as np\n\nclass CMASimpleRepair:\n    def __init__(self, budget=10000, dim=10, mu_ratio=0.1, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(mu_ratio * budget)  # Population size\n        self.sigma0 = sigma0  # Initial step size\n        self.m = None  # Mean of the search distribution\n        self.C = np.eye(dim)  # Covariance matrix\n        self.pc = np.zeros(dim)  # Evolution path for C\n        self.ps = np.zeros(dim)  # Evolution path for sigma\n        self.chiN = dim**0.5 * (1 - (1/(4*dim)) + 1/(21*dim**2))\n\n        self.c_sigma = (self.mu / budget) ** 0.5\n        self.c_c = (4 + self.mu/dim) / (dim + 4 + 2*self.mu/dim)\n        self.c_1 = 2 / ((dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu-1) / ((dim + 2)**2 + self.mu))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu-1)/(dim+1)) - 1) + self.c_sigma\n\n        self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.m = (func.bounds.ub + func.bounds.lb) / 2 * np.ones(self.dim)\n        self.sigma = self.sigma0\n        used_budget = 0\n\n        while used_budget < self.budget:\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.mu)\n            x = self.m + self.sigma * z\n\n            # Repair mechanism: Clip values to stay within bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.mu\n            if used_budget > self.budget:\n                f = f[:self.mu - (used_budget - self.budget)]\n                x = x[:self.mu - (used_budget - self.budget)]\n                used_budget = self.budget\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_sorted = x[idx]\n            z_sorted = z[idx]\n\n            # Update CMA-ES parameters\n            m_new = np.sum(self.weights[:, None] * x_sorted[:self.mu], axis=0)\n            zmean = np.sum(self.weights[:, None] * z_sorted[:self.mu], axis=0)\n\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * zmean\n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * (used_budget / self.mu))) / self.chiN < 1.4 + 2 / (self.dim + 1)\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (m_new - self.m) / self.sigma\n\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :]) + self.c_mu * np.sum(self.weights[:, None, None] * (z_sorted[:self.mu, :, None] @ z_sorted[:self.mu, None, :]), axis=0)\n\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Ensure covariance matrix remains positive definite\n            try:\n                L = np.linalg.cholesky(self.C)\n                self.C = np.dot(L, L.T)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            self.m = m_new #Update mean at the end\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm CMASimpleRepair scored 0.270 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["50e79e06-c27b-4a16-af01-e335fb5a9b98"], "operator": null, "metadata": {"aucs": [0.10668290072552522, 0.21787566324376006, 0.34669104603364354, 0.190779251192446, 0.19824177702648837, 0.22859137522505812, 0.2364662681922337, 0.2434486797800789, 0.22744994523702056, 0.16014199723205524, 0.2480865959507531, 0.7446072667156882, 0.2693078718812, 0.19245541401830846, 0.4262486974313411, 0.28988808216830697, 0.23504651028557766, 0.25115281122840194, 0.17397685285587705, 0.40410362446001136]}}
{"id": "21eb9444-6599-4e70-a072-1139f7061fd3", "fitness": 0.3751396759732505, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with periodic parameter adaptation and a repair mechanism to handle boundary violations.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5\n        self.CR = 0.7\n        self.period = 100\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index].copy()\n\n        generation = 0\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n                mutant = population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Repair: clip to bounds instead of random replacement\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                \n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n            \n            # Parameter adaptation\n            if generation % self.period == 0:\n                self.F = np.random.uniform(0.3, 0.9)\n                self.CR = np.random.uniform(0.2, 0.8)\n            generation += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.375 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e661735d-7070-4a9f-81a2-ddb291e0c76e"], "operator": null, "metadata": {"aucs": [0.1551062065812685, 0.25361678279777644, 0.3639449573810317, 0.3547552846783325, 0.28830047981583595, 0.4025505299890214, 0.29403572075786466, 0.3226198568628603, 0.2949498143446536, 0.22325446402267157, 0.37179840121983077, 0.9913552179995629, 0.27569643194349813, 0.2785545190527471, 0.7225128104819181, 0.417761777447039, 0.3377339903419425, 0.47745786957297787, 0.19313868938799494, 0.4836497147861817]}}
{"id": "30d4b9c4-b553-4ef4-9e6f-52bf63c5bf74", "fitness": 0.0, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified mutation and probabilistic population shrinking.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=20, F=0.5, CR=0.7, shrink_factor=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.shrink_factor = shrink_factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize archive\n        archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))\n        archive_fitness = np.array([func(x) for x in archive])\n        self.budget -= self.archive_size\n\n        # Update optimal solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Mutation: select three distinct individuals\n                idxs = np.random.choice(self.pop_size + self.archive_size, 3, replace=False)\n                a = population[idxs[0] % self.pop_size] if idxs[0] < self.pop_size else archive[idxs[0] - self.pop_size]\n                b = population[idxs[1] % self.pop_size] if idxs[1] < self.pop_size else archive[idxs[1] - self.pop_size]\n                c = population[idxs[2] % self.pop_size] if idxs[2] < self.pop_size else archive[idxs[2] - self.pop_size]\n                \n                mutant = population[i] + self.F * (b - c)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    # Update archive\n                    max_archive_index = np.argmax(archive_fitness)\n                    if f < archive_fitness[max_archive_index]:\n                        archive_fitness[max_archive_index] = f\n                        archive[max_archive_index] = trial.copy()\n\n                    # Update optimal solution\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n            \n            #Probabilistic shrinking\n            if np.random.rand() < 0.1 and self.pop_size > 5:\n              self.pop_size = int(self.pop_size * self.shrink_factor)\n              indices = np.argsort(fitness)[:self.pop_size]\n              population = population[indices]\n              fitness = fitness[indices]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e661735d-7070-4a9f-81a2-ddb291e0c76e"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "12d53c98-abb9-48ba-af7f-e7e8408afc31", "fitness": 0.4961422529424785, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with dynamic F and Cr, focusing on parameter adaptation and reduced complexity for faster convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.Cr = Cr  # Crossover probability\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n        \n    def adapt_parameters(self):\n        # Adaptive F: Increase if stagnation is detected, decrease if progress is good\n        if np.std(self.fitness) < 1e-6:  # Stagnation\n            self.F = min(self.F * 1.1, 0.9)\n        else:\n            self.F = max(self.F * 0.9, 0.1)\n\n        # Adaptive Cr: Increase if the population diversity is low, decrease otherwise\n        if len(np.unique(self.fitness)) < self.pop_size * 0.2:  # Low diversity\n            self.Cr = min(self.Cr * 1.1, 0.9)\n        else:\n            self.Cr = max(self.Cr * 0.9, 0.1)\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.496 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["60db4901-fe9c-4338-99d8-c22fdb5d1c4e"], "operator": null, "metadata": {"aucs": [0.1866208267800008, 0.31066466638294665, 0.389026044555424, 0.7644181415110208, 0.3644445709859987, 0.6770283763165024, 0.39855867414891866, 0.47058729470436567, 0.6018577183461363, 0.2987420105868933, 0.3066392169604355, 0.9982558404281329, 0.3062116683813705, 0.41449399484031124, 0.7304355350406093, 0.7917346868765553, 0.4628199502408863, 0.6940715660468253, 0.2517483211499142, 0.5044859545663224]}}
{"id": "041985cb-1f74-412a-a288-311a2219835d", "fitness": -Infinity, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and a probability-based repair mechanism for constraint handling.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5\n        self.CR = 0.7\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n                mutant = population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Repair: Probability-based repair\n                repair_needed = (trial < func.bounds.lb) | (trial > func.bounds.ub)\n                trial[repair_needed] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=np.sum(repair_needed))\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                \n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n            \n            # Parameter adaptation - Simplification: Adapt F and CR based on population diversity\n            if np.std(fitness) > 0:\n                self.F = 0.5 + 0.3 * np.random.normal()\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.CR = 0.7 + 0.2 * np.random.normal()\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: Output size (1,) is not compatible with broadcast dimensions of inputs (2,)..", "error": "", "parent_ids": ["21eb9444-6599-4e70-a072-1139f7061fd3"], "operator": null, "metadata": {}}
{"id": "b2c6e7a0-6e7e-48fb-9170-6cc557b0ee0d", "fitness": -Infinity, "name": "CMASimpleRepair", "description": "Simplified CMA-ES with rank-one covariance matrix update, step-size adaptation, and bound handling for efficient optimization.", "code": "import numpy as np\n\nclass CMASimpleRepair:\n    def __init__(self, budget=10000, dim=10, mu_ratio=0.25, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(mu_ratio * budget)  # Number of parents\n        self.sigma0 = sigma0  # Initial step size\n        self.C = np.eye(dim)  # Covariance matrix\n        self.ps = np.zeros(dim)  # Evolution path for sigma\n        self.chiN = dim**0.5 * (1 - (1/(4*dim)) + 1/(21*dim**2)) # Expectation of ||N(0,I)||\n\n        self.c_sigma = (self.mu / budget) ** 0.5\n        self.c_1 = 2 / ((dim + 1.3)**2 + self.mu)\n        self.mu = int(budget/10)\n        self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.m = (func.bounds.ub + func.bounds.lb) / 2 * np.ones(self.dim)\n        self.sigma = self.sigma0\n        \n        used_budget = 0\n        while used_budget < self.budget:\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.mu)\n            x = self.m + self.sigma * z\n            \n            # Repair mechanism: Clip values to stay within bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            used_budget += self.mu\n            if used_budget > self.budget:\n                f = f[:self.mu - (used_budget - self.budget)]\n                x = x[:self.mu - (used_budget - self.budget)]\n                used_budget = self.budget\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_sorted = x[idx]\n            z_sorted = z[idx]\n\n            # Update CMA-ES parameters - simplified\n            self.m = np.sum(self.weights[:, None] * x_sorted[:self.mu], axis=0)\n            zmean = np.sum(self.weights[:, None] * z_sorted[:self.mu], axis=0)\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * zmean\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.C = (1 - self.c_1) * self.C + self.c_1 * np.outer(self.ps, self.ps) # Rank-one update, removed mueff\n\n            # Ensure C remains symmetric\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n\n            # Handle potential numerical instability\n            try:\n                np.linalg.cholesky(self.C)  # Check if positive definite\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)  # Reset if not positive definite\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: 'CMASimpleRepair' object has no attribute 'd_sigma'.", "error": "", "parent_ids": ["51a01f27-ef60-4c5e-89bb-a30215f91b50"], "operator": null, "metadata": {}}
{"id": "ef107f51-01de-4b9f-b74f-99aa429068bf", "fitness": 0.2247804769414261, "name": "CMASimpleRankOne", "description": "Simplified CMA-ES with rank-one update, dynamic population size, and a novel rescaling to improve exploration and exploitation.", "code": "import numpy as np\n\nclass CMASimpleRankOne:\n    def __init__(self, budget=10000, dim=10, mu_ratio=0.1, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(mu_ratio * budget)  # Population size\n        self.sigma0 = sigma0  # Initial step size\n        self.m = None  # Mean of the search distribution\n        self.C = np.eye(dim)  # Covariance matrix\n        self.pc = np.zeros(dim)  # Evolution path for C\n        self.sigma = sigma0\n\n        self.c_c = 2 / (dim + 2)\n        self.c_1 = 2 / ((dim + 1.3)**2)\n        self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.m = (func.bounds.ub + func.bounds.lb) / 2 * np.ones(self.dim)\n        used_budget = 0\n\n        while used_budget < self.budget:\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.mu)\n            x = self.m + self.sigma * z\n\n            # Repair mechanism: Clip values to stay within bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.mu\n            if used_budget > self.budget:\n                f = f[:self.mu - (used_budget - self.budget)]\n                x = x[:self.mu - (used_budget - self.budget)]\n                used_budget = self.budget\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_sorted = x[idx]\n            z_sorted = z[idx]\n\n            # Update CMA-ES parameters\n            m_new = np.sum(self.weights[:, None] * x_sorted[:self.mu], axis=0)\n            zmean = np.sum(self.weights[:, None] * z_sorted[:self.mu], axis=0)\n\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * zmean\n\n            self.C = (1 - self.c_1) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n\n            self.sigma *= np.exp(0.5 * (np.linalg.norm(self.pc)**2 - self.dim) / self.dim)\n\n            self.m = m_new #Update mean at the end\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm CMASimpleRankOne scored 0.225 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["06b0c8e6-cce4-4324-b171-f214a5e7496a"], "operator": null, "metadata": {"aucs": [0.06779019762665361, 0.1588924574840297, 0.2996448203941354, 0.12213883577240525, 0.11411376916935223, 0.1467577489446692, 0.18237135247864866, 0.14726901551632166, 0.1514664549458734, 0.1382351481820413, 0.15479882050744687, 0.9166277332993812, 0.25535076793645783, 0.13476599073323536, 0.49333291039429905, 0.23348610558033256, 0.1424234384212134, 0.15677052465756147, 0.1390762426000678, 0.3402972041843959]}}
{"id": "fe76ea28-6520-4d45-bf2e-503058638f37", "fitness": 0.22127408753390232, "name": "CMASimpleRankOne", "description": "Simplified CMA-ES with rank-one update, clipping repair, and dynamic sigma adaptation based on objective rank for improved efficiency and robustness.", "code": "import numpy as np\n\nclass CMASimpleRankOne:\n    def __init__(self, budget=10000, dim=10, mu_ratio=0.1, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(mu_ratio * budget)  # Population size\n        self.sigma0 = sigma0  # Initial step size\n        self.m = None  # Mean of the search distribution\n        self.C = np.eye(dim)  # Covariance matrix\n        self.pc = np.zeros(dim)  # Evolution path for C\n        self.ps = np.zeros(dim)  # Evolution path for sigma\n        self.chiN = dim**0.5 * (1 - (1/(4*dim)) + 1/(21*dim**2))\n\n        self.c_sigma = (self.mu / budget) ** 0.5\n        self.c_c = (4 + self.mu/dim) / (dim + 4 + 2*self.mu/dim)\n        self.c_1 = 2 / ((dim + 1.3)**2 + self.mu)\n\n        self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.m = (func.bounds.ub + func.bounds.lb) / 2 * np.ones(self.dim)\n        self.sigma = self.sigma0\n        used_budget = 0\n\n        while used_budget < self.budget:\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.mu)\n            x = self.m + self.sigma * z\n\n            # Repair mechanism: Clip values to stay within bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.mu\n            if used_budget > self.budget:\n                f = f[:self.mu - (used_budget - self.budget)]\n                x = x[:self.mu - (used_budget - self.budget)]\n                used_budget = self.budget\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_sorted = x[idx]\n            z_sorted = z[idx]\n\n            # Update CMA-ES parameters\n            m_new = np.sum(self.weights[:, None] * x_sorted[:self.mu], axis=0)\n            zmean = np.sum(self.weights[:, None] * z_sorted[:self.mu], axis=0)\n\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * zmean\n\n            self.C = (1 - self.c_1) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n\n            rank_based_sigma = np.sum(self.weights * f[idx])\n            self.sigma *= np.exp(0.1 * (rank_based_sigma - np.mean(f)) / np.std(f))\n\n            # Ensure covariance matrix remains positive definite\n            try:\n                L = np.linalg.cholesky(self.C)\n                self.C = np.dot(L, L.T)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            self.m = m_new #Update mean at the end\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm CMASimpleRankOne scored 0.221 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["06b0c8e6-cce4-4324-b171-f214a5e7496a"], "operator": null, "metadata": {"aucs": [0.10391495825894603, 0.1911880569494514, 0.3382240713859149, 0.1513123023650933, 0.17600844971803364, 0.18418918812488527, 0.23124522363324262, 0.22151915765451957, 0.21637521364337475, 0.1516728167919691, 0.2238291168525468, 0.44626342671076014, 0.2558268940208269, 0.17719566606263748, 0.20961393802579553, 0.2535854848405438, 0.2140510179338948, 0.1828761990397073, 0.1492495048388377, 0.3473410638270653]}}
{"id": "b769b496-7a89-4e6b-9534-68f131e82c9f", "fitness": 0.2586680758111314, "name": "CMASimpleRepair", "description": "Simplified CMA-ES with rank-one covariance update and active update mechanism for faster convergence and better exploration.", "code": "import numpy as np\n\nclass CMASimpleRepair:\n    def __init__(self, budget=10000, dim=10, mu_ratio=0.25, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(mu_ratio * budget)  # Number of parents\n        self.sigma0 = sigma0  # Initial step size\n        self.C = np.eye(dim)  # Covariance matrix\n        self.ps = np.zeros(dim)  # Evolution path for sigma\n        self.pc = np.zeros(dim)\n        self.chiN = dim**0.5 * (1 - (1/(4*dim)) + 1/(21*dim**2)) # Expectation of ||N(0,I)||\n\n        self.c_sigma = (self.mu / budget) ** 0.5\n        self.c_1 = 2 / ((dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu-1) / ((dim + 2)**2 + self.mu))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu-1)/(dim+1)) - 1) + self.c_sigma\n        self.mu = int(budget/10)\n        self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_c = 4 / (dim + 4)\n        self.c_cov = 2 / (dim**0.5 * 2 +1)\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.m = (func.bounds.ub + func.bounds.lb) / 2 * np.ones(self.dim)\n        self.sigma = self.sigma0\n        \n        used_budget = 0\n        while used_budget < self.budget:\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.mu)\n            x = self.m + self.sigma * z\n            \n            # Repair mechanism: Clip values to stay within bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            used_budget += self.mu\n            if used_budget > self.budget:\n                f = f[:self.mu - (used_budget - self.budget)]\n                x = x[:self.mu - (used_budget - self.budget)]\n                used_budget = self.budget\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_sorted = x[idx]\n            z_sorted = z[idx]\n\n            # Update CMA-ES parameters - simplified\n            m_old = self.m\n            self.m = np.sum(self.weights[:, None] * x_sorted[:self.mu], axis=0)\n            zmean = np.sum(self.weights[:, None] * z_sorted[:self.mu], axis=0)\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * zmean\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2-self.c_c) * self.mueff) * (self.m - m_old) / self.sigma\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            \n            # Rank-one update\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * np.outer(self.pc, self.pc)\n            \n\n            # Ensure C remains symmetric\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n\n            # Handle potential numerical instability\n            try:\n                np.linalg.cholesky(self.C)  # Check if positive definite\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)  # Reset if not positive definite\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm CMASimpleRepair scored 0.259 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["51a01f27-ef60-4c5e-89bb-a30215f91b50"], "operator": null, "metadata": {"aucs": [0.09709891361734413, 0.17807959607243318, 0.3050576244736819, 0.16347919437924885, 0.17031553238035757, 0.20476988759388137, 0.25723161841650466, 0.22833925103684594, 0.22146592353098937, 0.16186125743275281, 0.24977636707216788, 0.8578810433920295, 0.25546527124285234, 0.18939274100405623, 0.418755110565296, 0.2480712793417661, 0.21700418715662084, 0.20031000277959055, 0.13759173951919712, 0.41141497521501047]}}
{"id": "76adbca5-03b1-4880-b260-78d015b4e3f9", "fitness": 0.20391377732865484, "name": "CMASimpleReflect", "description": "Simplified CMA-ES with a rank-one update for the covariance matrix and adaptive step size control, enhanced with a reflection mechanism for boundary handling and simplified parameter updates.", "code": "import numpy as np\n\nclass CMASimpleReflect:\n    def __init__(self, budget=10000, dim=10, mu_ratio=0.2, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(mu_ratio * budget)  # Population size\n        self.sigma0 = sigma0  # Initial step size\n        self.m = None  # Mean of the search distribution\n        self.C = np.eye(dim)  # Covariance matrix\n        self.pc = np.zeros(dim)  # Evolution path for C\n        self.ps = np.zeros(dim)  # Evolution path for sigma\n        self.chiN = dim**0.5 * (1 - (1/(4*dim)) + 1/(21*dim**2))\n\n        self.c_sigma = (self.mu / budget) ** 0.5\n        self.c_c = (4 + self.mu/dim) / (dim + 4 + 2*self.mu/dim)\n        self.c_1 = 2 / ((dim + 1.3)**2 + self.mu)\n\n        self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff-1)/(dim+1)) - 1) + self.c_sigma\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.m = (func.bounds.ub + func.bounds.lb) / 2 * np.ones(self.dim)\n        self.sigma = self.sigma0\n        used_budget = 0\n\n        while used_budget < self.budget:\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.mu)\n            x = self.m + self.sigma * z\n\n            # Repair mechanism: Reflect values to stay within bounds\n            for i in range(self.mu):\n                for j in range(self.dim):\n                    if x[i, j] < func.bounds.lb[j]:\n                        x[i, j] = 2 * func.bounds.lb[j] - x[i, j]\n                    if x[i, j] > func.bounds.ub[j]:\n                        x[i, j] = 2 * func.bounds.ub[j] - x[i, j]\n                        \n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.mu\n            if used_budget > self.budget:\n                f = f[:self.mu - (used_budget - self.budget)]\n                x = x[:self.mu - (used_budget - self.budget)]\n                used_budget = self.budget\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_sorted = x[idx]\n            z_sorted = z[idx]\n\n            # Update CMA-ES parameters\n            m_new = np.sum(self.weights[:, None] * x_sorted[:self.mu], axis=0)\n            zmean = np.sum(self.weights[:, None] * z_sorted[:self.mu], axis=0)\n\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * zmean\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * (used_budget / self.mu))) / self.chiN) < (1.4 + 2 / (self.dim + 1))\n\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * zmean #Simplified pc update\n\n            self.C = (1 - self.c_1) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :]) #Rank-one update\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n\n            # Ensure covariance matrix remains positive definite (simplified)\n            if np.any(np.isnan(self.C)):\n                 self.C = np.eye(self.dim)\n\n\n            self.m = m_new #Update mean at the end\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm CMASimpleReflect scored 0.204 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["06b0c8e6-cce4-4324-b171-f214a5e7496a"], "operator": null, "metadata": {"aucs": [0.09214254178973091, 0.18413056156200447, 0.31838638367806504, 0.14842171594645093, 0.15400252191911246, 0.17110581618882148, 0.2055782188797569, 0.19209096438486317, 0.18245382103376773, 0.14872100779515096, 0.17869184124085935, 0.42818979700762116, 0.255209555996348, 0.15647137811973677, 0.15861920430344179, 0.2608864088935431, 0.2118557801357389, 0.177288464522797, 0.15681124769070265, 0.29721831548458444]}}
{"id": "d62a53f5-a751-42f4-a7dc-298a75b0e680", "fitness": 0.5672539639107331, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with dynamic F and CR, focusing on parameter adaptation and reduced complexity for faster convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5\n        self.CR = 0.7\n        self.period = 100\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index].copy()\n\n        generation = 0\n        while self.budget > 0:\n            # Parameter adaptation\n            if generation % self.period == 0:\n                self.F = np.random.uniform(0.3, 0.9)\n                self.CR = np.random.uniform(0.2, 0.8)\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n                mutant = x1 + self.F * (x2 - x3)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Repair: clip to bounds\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                \n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n            \n            generation += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.567 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["21eb9444-6599-4e70-a072-1139f7061fd3"], "operator": null, "metadata": {"aucs": [0.20132907029662805, 0.5604005902607707, 0.5280470757597919, 0.7198252273372373, 0.4604482538566601, 0.7690053115093052, 0.44933992040339954, 0.46999011437814475, 0.5434963857148344, 0.6875292685569843, 0.7014167983759856, 0.9989005100887315, 0.2886624637057783, 0.4369957974709825, 0.8319131377210058, 0.77328040681269, 0.3832990562423071, 0.8214449339078809, 0.22010725851892043, 0.4996476972966233]}}
{"id": "4023eaed-b036-4131-8a88-a14700b7e965", "fitness": 0.7286078206031339, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters and reduced population size for improved efficiency.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=25, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.Cr = Cr  # Crossover probability\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n        \n    def adapt_parameters(self):\n        # Self-adaptive F and Cr\n        self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 0.9)\n        self.Cr = np.clip(np.random.normal(0.9, 0.2), 0.1, 0.9)\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.729 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["12d53c98-abb9-48ba-af7f-e7e8408afc31"], "operator": null, "metadata": {"aucs": [0.255894199622957, 0.790571496093233, 0.5713392741697687, 0.9380471883384973, 0.8765714112013596, 0.8825252361656802, 0.8364092609877181, 0.8069178308371854, 0.8293047808417723, 0.2102613742389804, 0.9342504498422856, 0.9957465589764999, 0.422632741434425, 0.8349710250769635, 0.9309952683373496, 0.8975983636760669, 0.7562079007769238, 0.9230105641813853, 0.3542366541851558, 0.524664833078472]}}
{"id": "04b735a8-f234-4090-ae70-99d5ab38e4af", "fitness": 0.5837289685787971, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters and reduced function evaluations by evaluating only when crossover occurs.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.Cr = Cr  # Crossover probability\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            trial_changed = False\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n                    trial_changed = True\n\n            # Selection: Evaluate only if crossover happened\n            if trial_changed:\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n        \n    def adapt_parameters(self):\n        # Self-adaptive F\n        self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 0.9)\n\n        # Self-adaptive Cr\n        self.Cr = np.clip(np.random.normal(self.Cr, 0.1), 0.1, 0.9)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.584 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["12d53c98-abb9-48ba-af7f-e7e8408afc31"], "operator": null, "metadata": {"aucs": [0.23036339887162538, 0.3322060110155969, 0.4943861862909015, 0.8006357190709134, 0.7704234109769673, 0.7641369956059905, 0.3360009025638415, 0.4891160709972795, 0.5521940697501371, 0.39999816006977873, 0.8079956375834634, 0.9921526752109917, 0.35142634444095, 0.6311125773126245, 0.8703683655308547, 0.7849779364995537, 0.5534385783677411, 0.7463354022858745, 0.2377673037042155, 0.5295436254266399]}}
{"id": "96adf729-7070-4a3c-a5ed-8ff5fedce3eb", "fitness": 0.6983162907117535, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters F and Cr based on success history and population diversity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.Cr = Cr  # Crossover probability\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_F = []\n        self.success_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.success_F.append(self.F)\n                self.success_Cr.append(self.Cr)\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n        \n    def adapt_parameters(self):\n        # Adaptive F: Use mean of successful F values, or random if none\n        if self.success_F:\n            self.F = np.clip(np.mean(self.success_F), 0.1, 0.9)\n        else:\n            self.F = np.random.uniform(0.1, 0.9)\n        self.success_F = []\n\n        # Adaptive Cr: Use mean of successful Cr values, or random if none\n        if self.success_Cr:\n            self.Cr = np.clip(np.mean(self.success_Cr), 0.1, 0.9)\n        else:\n            self.Cr = np.random.uniform(0.1, 0.9)\n        self.success_Cr = []\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE scored 0.698 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["12d53c98-abb9-48ba-af7f-e7e8408afc31"], "operator": null, "metadata": {"aucs": [0.3184326755954381, 0.6572199462546251, 0.7047137682033832, 0.8569617451124323, 0.7513629979740336, 0.7919690587968684, 0.6154326369053995, 0.6154216473819775, 0.7494604549240877, 0.7002276691827931, 0.868127996788386, 0.9912743973273929, 0.6754076391069757, 0.715907728879091, 0.9256491789817375, 0.8040912476124207, 0.6180652771531846, 0.8458589940898085, 0.24087441931054998, 0.5198663346544834]}}
{"id": "551fb81e-c478-4878-98a8-d26607eba543", "fitness": -Infinity, "name": "CMASimpleMirror", "description": "Simplified CMA-ES with rank-one covariance update, adaptive step size, and bound management via mirroring to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass CMASimpleMirror:\n    def __init__(self, budget=10000, dim=10, mu_ratio=0.25, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(mu_ratio * budget)\n        self.sigma0 = sigma0\n        self.m = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.C = np.eye(dim)\n        self.c_sigma = (self.mu / budget) ** 0.5\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu-1)/(dim+1)) - 1) + self.c_sigma\n        self.c_1 = 1 / ((dim + 1.3)**2 + self.mu) #Simplified rank-one update\n        self.chiN = dim**0.5 * (1 - (1/(4*dim)) + 1/(21*dim**2))\n        self.mueff = self.mu\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.m = (ub + lb) / 2 * np.ones(self.dim)\n        self.sigma = self.sigma0\n        used_budget = 0\n\n        while used_budget < self.budget:\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.mu)\n            x = self.m + self.sigma * z\n\n            # Mirroring boundary handling\n            for i in range(self.mu):\n                for j in range(self.dim):\n                    if x[i, j] < lb:\n                        x[i, j] = 2 * lb - x[i, j]\n                    elif x[i, j] > ub:\n                        x[i, j] = 2 * ub - x[i, j]\n            x = np.clip(x, lb, ub)  # Ensure clipping after mirroring\n\n            f = np.array([func(xi) for xi in x])\n            used_budget += self.mu\n            if used_budget > self.budget:\n                f = f[:self.mu - (used_budget - self.budget)]\n                x = x[:self.mu - (used_budget - self.budget)]\n                used_budget = self.budget\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_sorted = x[idx]\n            z_sorted = z[idx]\n\n            # Simplified CMA-ES updates\n            self.m = np.mean(x_sorted[:self.mu], axis=0)\n            zmean = np.mean(z_sorted[:self.mu], axis=0)\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.C = (1 - self.c_1) * self.C + self.c_1 * np.outer(self.ps, self.ps)\n\n            # Ensure C remains symmetric and positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["51a01f27-ef60-4c5e-89bb-a30215f91b50"], "operator": null, "metadata": {}}
{"id": "d8ca417b-5815-49cb-8b3e-88fdce8ba23c", "fitness": 0.234711444821819, "name": "CMASimpleRepair", "description": "Simplified CMA-ES with rank-one updates and dynamic population size, focusing on efficiency and robustness using fewer parameters and memory.", "code": "import numpy as np\n\nclass CMASimpleRepair:\n    def __init__(self, budget=10000, dim=10, mu_ratio=0.1, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(mu_ratio * budget)  # Number of parents\n        self.sigma0 = sigma0  # Initial step size\n        self.C = np.eye(dim)  # Covariance matrix\n        self.ps = np.zeros(dim)  # Evolution path for sigma\n        self.chiN = dim**0.5 * (1 - (1/(4*dim)) + 1/(21*dim**2)) # Expectation of ||N(0,I)||\n\n        self.c_sigma = (self.mu / budget) ** 0.5\n        self.c_1 = 2 / ((dim + 1.3)**2 + self.mu) # Simplified c_1\n        self.mu = int(budget/10) # Number of points for recombination\n        self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.m = (func.bounds.ub + func.bounds.lb) / 2 * np.ones(self.dim)\n        self.sigma = self.sigma0\n        \n        used_budget = 0\n        while used_budget < self.budget:\n            z = np.random.normal(0, 1, size=(self.mu, self.dim))\n            x = self.m + self.sigma * z\n            \n            # Repair mechanism: Clip values to stay within bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            used_budget += self.mu\n            if used_budget > self.budget:\n                f = f[:self.mu - (used_budget - self.budget)]\n                x = x[:self.mu - (used_budget - self.budget)]\n                z = z[:self.mu - (used_budget - self.budget)]\n                used_budget = self.budget\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_sorted = x[idx]\n            z_sorted = z[idx]\n\n            # Update CMA-ES parameters - simplified\n            self.m = np.sum(self.weights[:, None] * x_sorted[:self.mu], axis=0)\n            zmean = np.sum(self.weights[:, None] * z_sorted[:self.mu], axis=0)\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * zmean\n            self.sigma *= np.exp((self.c_sigma / self.chiN) * (np.linalg.norm(self.ps)**2 / self.dim - 1)) # Simplified sigma update\n            self.C = (1 - self.c_1) * self.C + self.c_1 * np.outer(self.ps, self.ps) # Rank-one update\n\n            # Ensure C remains symmetric\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n\n            # Handle potential numerical instability\n            try:\n                np.linalg.cholesky(self.C)  # Check if positive definite\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)  # Reset if not positive definite\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm CMASimpleRepair scored 0.235 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["51a01f27-ef60-4c5e-89bb-a30215f91b50"], "operator": null, "metadata": {"aucs": [0.06657903353203942, 0.17850570069682203, 0.2971144090831094, 0.1428831009967706, 0.12850138610717188, 0.1797062876993496, 0.1785031011770326, 0.1458576781152613, 0.1520139148858063, 0.1475596178354719, 0.1821108766167011, 0.9163471669853891, 0.2601719991969704, 0.1449343308322364, 0.4972527459897881, 0.2240707976042583, 0.154326316211431, 0.16654621789449886, 0.1461804230019903, 0.38506379197428164]}}
{"id": "3ee21df4-83d5-4621-8359-380b83101203", "fitness": 0.6033395504254683, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and vectorized operations for efficiency.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5\n        self.CR = 0.7\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            # Mutation\n            indices = np.random.randint(0, self.pop_size, size=(self.pop_size, 3))\n            x1, x2, x3 = population[indices[:, 0]], population[indices[:, 1]], population[indices[:, 2]]\n            mutant = x1 + self.F * (x2 - x3)\n\n            # Crossover\n            cross_points = np.random.rand(self.pop_size, self.dim) < self.CR\n            trial = np.where(cross_points, mutant, population)\n\n            # Repair: clip to bounds\n            trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n            # Selection\n            f = np.array([func(x) for x in trial])\n            self.budget -= self.pop_size\n\n            improved = f < fitness\n            fitness[improved] = f[improved]\n            population[improved] = trial[improved]\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.603 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d62a53f5-a751-42f4-a7dc-298a75b0e680"], "operator": null, "metadata": {"aucs": [0.21255217970890317, 0.41394756531894716, 0.5422239720009974, 0.7731831275521279, 0.6729622417077821, 0.7251934112607319, 0.5353953112749832, 0.5644512275565416, 0.6570494682970647, 0.6268047218188311, 0.8021567624271697, 0.9919059677765238, 0.35519930384902954, 0.6096852107969069, 0.8521910598407954, 0.725514578901638, 0.4818685961518028, 0.7974063379639058, 0.21246574462034185, 0.514634219684342]}}
{"id": "654b7e18-cb5a-4f94-b034-22e7b63717a8", "fitness": 0.7193312878805271, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and a focus on local search around the best solution.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=25, F=0.5, Cr=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        if np.random.rand() < 0.1:\n            self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 0.9)\n        if np.random.rand() < 0.1:\n            self.Cr = np.clip(np.random.normal(0.7, 0.2), 0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.719 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["04b735a8-f234-4090-ae70-99d5ab38e4af"], "operator": null, "metadata": {"aucs": [0.2743871173809729, 0.7258867842666625, 0.7433566209439766, 0.8994243971038317, 0.25721041030986613, 0.8805647419955838, 0.8449281209661107, 0.4152719263702621, 0.8409821729357132, 0.7990835706634575, 0.8225114885697922, 0.9966982036998947, 0.4569000095195924, 0.8306903986045091, 0.9401235136585665, 0.8452561540088241, 0.6817852843081396, 0.8824548874743308, 0.7225661590595701, 0.5265437957708853]}}
{"id": "c6b114b4-cd77-4d20-8d71-9a9b2d73a29d", "fitness": 0.6107809190334643, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and conditional evaluation for efficiency.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 0.9)\n        self.Cr = np.clip(np.random.normal(self.Cr, 0.1), 0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.611 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["04b735a8-f234-4090-ae70-99d5ab38e4af"], "operator": null, "metadata": {"aucs": [0.21303567473383878, 0.631146154078353, 0.509503432253456, 0.8080307185441411, 0.7309233257024371, 0.6440181958803144, 0.6233718359047382, 0.5334374732819316, 0.6935556092581868, 0.7354461888249071, 0.7563224522031734, 0.9915313518355345, 0.3725784223427512, 0.614899211218888, 0.7459275758618109, 0.71630799660604, 0.39360647476396693, 0.785474908747509, 0.21151806300964682, 0.5049833156176615]}}
{"id": "b035b22e-e58f-413a-8390-57ea99190865", "fitness": 0.7046388244005322, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on exponential moving averages of successful F and Cr values.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, adapt_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.Cr = Cr  # Crossover probability\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.adapt_rate = adapt_rate  # Learning rate for adaptation\n        self.success_F = []\n        self.success_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                if self.success_F:\n                    self.F = (1 - self.adapt_rate) * self.F + self.adapt_rate * self.F\n                    self.Cr = (1 - self.adapt_rate) * self.Cr + self.adapt_rate * self.Cr\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.705 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["96adf729-7070-4a3c-a5ed-8ff5fedce3eb"], "operator": null, "metadata": {"aucs": [0.3513519304483067, 0.6783399173203888, 0.6970066467641562, 0.88273757769741, 0.7598624812911358, 0.7717395469094697, 0.6374275902921994, 0.640138997432019, 0.7519396901145422, 0.6641978257587846, 0.8587949387384164, 0.9995282116942004, 0.663448935073516, 0.7245465867940766, 0.8883766346783364, 0.7962768929130939, 0.6471360544762341, 0.8598800732081835, 0.2952016730300474, 0.5248442833761282]}}
{"id": "d5344c01-f89f-4d7f-85c4-0512e88bee0b", "fitness": 0.7832289638021511, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on success history and a dynamically adjusted population size.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)  # Population size scaling with dimension\n        self.F = 0.5  # Initial differential weight\n        self.Cr = 0.9  # Initial crossover probability\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_F = []\n        self.success_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.success_F.append(self.F)\n                self.success_Cr.append(self.Cr)\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        if self.success_F:\n            self.F = np.mean(self.success_F)\n            self.F = 0.1 + 0.8 * self.F  # Scale F to [0.1, 0.9]\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.success_F = []\n        \n        if self.success_Cr:\n            self.Cr = np.mean(self.success_Cr)\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n            self.success_Cr = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.783 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["96adf729-7070-4a3c-a5ed-8ff5fedce3eb"], "operator": null, "metadata": {"aucs": [0.6699568634263561, 0.8492274770022329, 0.8164252953419497, 0.9302481505940554, 0.8603625279282944, 0.8909600454764227, 0.3709856795434736, 0.8346141189242268, 0.8613710815741509, 0.7940683142641659, 0.9379570638570826, 0.9971513401296289, 0.2975916686759612, 0.8576755568688157, 0.9515438056576448, 0.8955401425451808, 0.8139573763792655, 0.9071342813080641, 0.6043459088685639, 0.5234625776774865]}}
{"id": "238092b8-e6eb-431b-b55f-8566dd9b8ad7", "fitness": 0.7058299447659445, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on a moving average of successful F and Cr values.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, history_length=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.Cr = Cr  # Crossover probability\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_F = []\n        self.success_Cr = []\n        self.history_length = history_length\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.success_F.append(self.F)\n                self.success_Cr.append(self.Cr)\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n        \n    def adapt_parameters(self):\n        # Adaptive F: Use moving average of successful F values\n        if self.success_F:\n            self.F = np.clip(np.mean(self.success_F[-self.history_length:]), 0.1, 0.9)\n\n        # Adaptive Cr: Use moving average of successful Cr values\n        if self.success_Cr:\n            self.Cr = np.clip(np.mean(self.success_Cr[-self.history_length:]), 0.1, 0.9)\n\n        self.success_F = []\n        self.success_Cr = []\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.706 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["96adf729-7070-4a3c-a5ed-8ff5fedce3eb"], "operator": null, "metadata": {"aucs": [0.3443056852858325, 0.6723123448390962, 0.7019430344340098, 0.8879468480195927, 0.7665790764935022, 0.793454654245831, 0.648100796362034, 0.6888991738682919, 0.7333821413097913, 0.6408877510263775, 0.8653613808348022, 0.9931696688400045, 0.6595669824391395, 0.7055390029564331, 0.9171064957901954, 0.7813374843187196, 0.661266087557568, 0.8398233555437197, 0.29487407938164767, 0.5207428517723004]}}
{"id": "8ae27fea-a31b-4570-b4a7-40bd031dbfb3", "fitness": 0.6290073454385933, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on successful mutations and a focus on exploitation by reducing diversity through adjusted F and CR parameters.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5\n        self.CR = 0.7\n        self.success_F = []\n        self.success_CR = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n                mutant = x1 + self.F * (x2 - x3)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Repair: clip to bounds\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                \n                if f < fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n\n            # Adapt F and CR based on success history\n            if self.success_F:\n                self.F = np.clip(np.mean(self.success_F), 0.3, 0.9)\n                self.CR = np.clip(np.mean(self.success_CR), 0.2, 0.8)\n                self.success_F = []\n                self.success_CR = []\n            else:\n                # If no success, reduce exploration\n                self.F *= 0.9\n                self.CR *= 0.9\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.629 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d62a53f5-a751-42f4-a7dc-298a75b0e680"], "operator": null, "metadata": {"aucs": [0.22281765327066094, 0.4588422195219818, 0.5963645703920619, 0.8526785969469307, 0.711370536169758, 0.7520236257995407, 0.5709672942928523, 0.5983614159652781, 0.6767478276996963, 0.6031912305939917, 0.7775151256085985, 0.9987046831388633, 0.30535279982031194, 0.6213834781630003, 0.8773005752603391, 0.7639632608768328, 0.5088402147530721, 0.7992538472784937, 0.38256784160783686, 0.5019001116117657]}}
{"id": "b9c6cd68-ea87-4891-a6a3-d11870785c7f", "fitness": 0.21191925634388645, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on fitness improvement and reduced memory usage by eliminating explicit population storage.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=5): # Reduced pop_size for efficiency\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n            #Adapt F and Cr based on best fitness improvement\n            if self.eval_count < self.budget:\n              delta_f = self.f_opt - np.min(fitness)\n              if delta_f < 0: #improvement, change parameters\n                  self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 0.9)\n                  self.Cr = np.clip(np.random.normal(self.Cr, 0.1), 0.1, 0.9)\n              else:\n                  self.F = np.clip(np.random.normal(self.F, 0.05), 0.1, 0.9)\n                  self.Cr = np.clip(np.random.normal(self.Cr, 0.05), 0.1, 0.9)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.212 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4023eaed-b036-4131-8a88-a14700b7e965"], "operator": null, "metadata": {"aucs": [0.19104372767688205, 0.19279463422076792, 0.3157494751127512, 0.289174763159624, 0.1289368422387912, 0.18681950984767992, 0.2150415583128682, 0.20391386044146997, 0.24485522497882029, 0.14349761924036608, 0.1289824639458118, 0.22125420878873725, 0.27712370983460644, 0.25659960720876407, 0.1452358399171686, 0.31658514010922156, 0.20889936507580564, 0.16979623573260505, 0.18979816503953062, 0.2122831759954571]}}
{"id": "ae0bece7-63ca-4f27-a208-ac8ccbca8d17", "fitness": 0.7729633138846228, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a learning rate and a smaller population.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=25, F=0.5, Cr=0.9, lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lr = lr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.archive_F = []\n        self.archive_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.archive_F.append(self.F)\n                self.archive_Cr.append(self.Cr)\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        if self.archive_F:\n            mean_F = np.mean(self.archive_F)\n            self.F = (1 - self.lr) * self.F + self.lr * mean_F\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.archive_F = []\n\n        if self.archive_Cr:\n            mean_Cr = np.mean(self.archive_Cr)\n            self.Cr = (1 - self.lr) * self.Cr + self.lr * mean_Cr\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n            self.archive_Cr = []\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.773 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["96adf729-7070-4a3c-a5ed-8ff5fedce3eb"], "operator": null, "metadata": {"aucs": [0.6089650723931777, 0.833804378692371, 0.6405331723368797, 0.9352440431205266, 0.8132096818784884, 0.8820967775292217, 0.58895664200292, 0.819873654856788, 0.8769813359225357, 0.8278275498784098, 0.9082145529600738, 0.9987660769238751, 0.5034564024156629, 0.8576367321641936, 0.9550993289975873, 0.8794030590914366, 0.7720514517312187, 0.9055396153784947, 0.3156970857751471, 0.5359096636434486]}}
{"id": "a1eec532-0bb7-41f0-8df3-b03dea1b8824", "fitness": 0.5905592626023507, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on fitness improvement and aggressive population reduction.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.Cr = Cr  # Crossover probability\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history_F = []\n        self.success_history_CR = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.success_history_F.append(self.F)\n                self.success_history_CR.append(self.Cr)\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n        \n    def adapt_parameters(self):\n        # Adapt F and Cr based on success history\n        if self.success_history_F:\n            self.F = np.mean(self.success_history_F)\n            self.Cr = np.mean(self.success_history_CR)\n        \n        self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 0.9)\n        self.Cr = np.clip(np.random.normal(self.Cr, 0.1), 0.1, 0.9)\n\n        self.success_history_F = []\n        self.success_history_CR = []\n            \n    def reduce_population(self):\n        if self.eval_count > self.budget * 0.5 and self.pop_size > 10:\n             self.pop_size = max(10, int(self.pop_size * 0.75))\n             best_indices = np.argsort(self.fitness)[:self.pop_size]\n             self.pop = self.pop[best_indices]\n             self.fitness = self.fitness[best_indices]\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n            self.reduce_population()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.591 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4023eaed-b036-4131-8a88-a14700b7e965"], "operator": null, "metadata": {"aucs": [0.21428924198493537, 0.30549309554269877, 0.5250664742275251, 0.7763430131924698, 0.6675554086453843, 0.7920788384008873, 0.5362866940288744, 0.6056776033459164, 0.7408924933940104, 0.40655753995873667, 0.6819063630551592, 0.9996651759491378, 0.3119544952675055, 0.7279609110237053, 0.7031036207787015, 0.7546281161650246, 0.5027541131139059, 0.8201385311778686, 0.23029347849625748, 0.508540044298311]}}
{"id": "e7db5c28-cc44-43d7-a0c9-a9b2464db9f0", "fitness": 0.6511677086153738, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified adaptation and reduced evaluations by evaluating only changed individuals, focusing on successful parameter settings.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_F = []\n        self.success_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            trial_changed = False\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n                    trial_changed = True\n\n            if trial_changed:\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        if self.success_F:\n            self.F = np.mean(self.success_F)\n            self.Cr = np.mean(self.success_Cr)\n\n            self.success_F = []\n            self.success_Cr = []\n\n        self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 0.9)\n        self.Cr = np.clip(np.random.normal(self.Cr, 0.1), 0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.651 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["04b735a8-f234-4090-ae70-99d5ab38e4af"], "operator": null, "metadata": {"aucs": [0.19646703136673327, 0.5231742061825455, 0.6258608404772275, 0.9020754802591257, 0.7617295026195247, 0.5708165778328704, 0.44478057357442613, 0.6793078089436819, 0.7132886279805937, 0.6979998108654563, 0.8575794013193961, 0.9958974268210781, 0.329586166065888, 0.7148975549666129, 0.8454649076828039, 0.8397160789320616, 0.6907064055627199, 0.8549776836864439, 0.26272217010594934, 0.5163059170623385]}}
{"id": "831e0b52-8647-4552-91a8-18cc63783c3d", "fitness": 0.6172437856249948, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on population improvement and reduced population size.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.Cr = Cr  # Crossover probability\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_F = []\n        self.success_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False, p=None) #remove p\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.success_F.append(self.F)\n                self.success_Cr.append(self.Cr)\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n        \n    def adapt_parameters(self):\n         # Simplified parameter adaptation using success history\n        if self.success_F:\n            self.F = np.mean(self.success_F)\n            self.Cr = np.mean(self.success_Cr)\n            self.success_F = []\n            self.success_Cr = []\n\n        # Add stochasticity to prevent stagnation, clip to bounds\n        self.F = np.clip(self.F * (1 + 0.1 * np.random.normal(0, 1)), 0.1, 0.9)\n        self.Cr = np.clip(self.Cr * (1 + 0.1 * np.random.normal(0, 1)), 0.1, 0.9)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.617 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4023eaed-b036-4131-8a88-a14700b7e965"], "operator": null, "metadata": {"aucs": [0.41519445264815547, 0.46389482345866007, 0.3421777282324301, 0.8224307602665082, 0.7371602578752181, 0.6769616462611903, 0.7873135494945358, 0.43925195867983535, 0.7372601920391648, 0.5770998452687873, 0.3356652744148019, 0.9953378585097729, 0.424386163231797, 0.8274453374334528, 0.8814078028154139, 0.8759640852976247, 0.2504198836634344, 0.931207059683054, 0.30890368991005845, 0.5153933433160013]}}
{"id": "fe672793-445e-44dd-b110-f9c8a98c41a0", "fitness": -Infinity, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a memory of successful parameters and population size adaptation based on stagnation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.memory_size = memory_size\n        self.F_memory = np.full(memory_size, 0.5)\n        self.Cr_memory = np.full(memory_size, 0.9)\n        self.memory_idx = 0\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 50  # Number of iterations without improvement\n        self.pop_size_min = int(2 * dim)\n        self.pop_size_max = int(10 * dim)\n        self.best_fitness_history = []\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n        self.best_fitness_history.append(self.f_opt)\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Parameter Adaptation: Sample F and Cr from memory\n            self.F = self.F_memory[np.random.randint(self.memory_size)]\n            self.Cr = self.Cr_memory[np.random.randint(self.memory_size)]\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                # Update memory with successful parameters\n                self.F_memory[self.memory_idx] = self.F\n                self.Cr_memory[self.memory_idx] = self.Cr\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n    \n    def adjust_population_size(self):\n        if len(self.best_fitness_history) > self.stagnation_threshold:\n            if self.best_fitness_history[-1] == self.best_fitness_history[-self.stagnation_threshold]:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        if self.stagnation_counter > self.stagnation_threshold:\n            self.pop_size = max(self.pop_size_min, int(self.pop_size * 0.8))\n            self.stagnation_counter = 0  # Reset counter\n        elif self.eval_count > self.budget * 0.75 and self.pop_size < self.pop_size_max:\n            self.pop_size = min(self.pop_size_max, int(self.pop_size * 1.2))\n        \n        self.pop_size = int(self.pop_size) # Ensure integer\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            \n            current_best_fitness = np.min(self.fitness)\n            if current_best_fitness < self.f_opt:\n              self.f_opt = current_best_fitness\n              self.x_opt = self.pop[np.argmin(self.fitness)]\n            self.best_fitness_history.append(self.f_opt)\n\n            self.adjust_population_size()\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occurred: index 10 is out of bounds for axis 0 with size 10.", "error": "", "parent_ids": ["d5344c01-f89f-4d7f-85c4-0512e88bee0b"], "operator": null, "metadata": {}}
{"id": "e364be06-e77d-43c0-a226-c598aca90f78", "fitness": 0.5817802144567944, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and intensified local search around the best solution, reducing population diversity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15, F=0.5, Cr=0.7, local_rate=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.local_rate = local_rate # Probability of local search\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Local search with a certain probability\n            if np.random.rand() < self.local_rate:\n                x_mutated = self.x_opt + np.random.normal(0, 0.05, self.dim)  # Smaller step size for local search\n            else:\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        if np.random.rand() < 0.1:\n            self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 0.9)\n        if np.random.rand() < 0.1:\n            self.Cr = np.clip(np.random.normal(0.7, 0.2), 0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.582 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["654b7e18-cb5a-4f94-b034-22e7b63717a8"], "operator": null, "metadata": {"aucs": [0.2892732650341665, 0.23083807691547387, 0.8511809057490685, 0.1745591854955777, 0.2786102558346859, 0.9186253281919523, 0.8025991014282963, 0.47778541944713726, 0.9056017020497695, 0.18324102422168376, 0.9115189742889666, 0.9957446962752081, 0.2596466933766297, 0.3228120148260084, 0.9077351604709541, 0.9162920801696097, 0.573417581760362, 0.9171747649769467, 0.23266458080058472, 0.4862834778228068]}}
{"id": "12365b95-3c21-4a8a-bc7d-12c49ca34421", "fitness": 0.44591701822058133, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and focused local search around the best solution, using a smaller, dynamically adjusted population size.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=10, F=0.5, Cr=0.7, local_rate=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.local_rate = local_rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            \n            if np.random.rand() < self.local_rate:\n                x_r1 = self.x_opt  # Local search around the best\n            \n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            crossover_mask = np.random.rand(self.dim) < self.Cr\n            x_trial[crossover_mask] = x_mutated[crossover_mask]\n\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        if np.random.rand() < 0.1:\n            self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 0.9)\n        if np.random.rand() < 0.1:\n            self.Cr = np.clip(np.random.normal(0.7, 0.2), 0.1, 0.9)\n        \n        #Dynamically adjust population size\n        if self.eval_count > self.budget * 0.75 and self.pop_size > 5:\n            self.pop_size = max(5, int(self.pop_size * 0.9))  # Reduce pop size late in the search\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.446 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["654b7e18-cb5a-4f94-b034-22e7b63717a8"], "operator": null, "metadata": {"aucs": [0.2993177891210972, 0.2051842193647001, 0.33567918264245966, 0.9490341113166265, 0.7816197822540685, 0.5157549095696273, 0.32915949589733107, 0.21740503488495533, 0.3186922401447111, 0.2215024109441901, 0.18814770941678038, 0.996501063800321, 0.29432178383035423, 0.3068482178853884, 0.6503208996659275, 0.33514406423712917, 0.31983867338189753, 0.9456584784473577, 0.22238103952370225, 0.48582925808300315]}}
{"id": "d489b1ee-b85d-4279-8361-cefce8deda7f", "fitness": 0.5589261720296933, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with a simplified parameter adaptation and local search intensification around the best solution using smaller steps.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, local_rate=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.local_rate = local_rate  # Probability of local search\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            if np.random.rand() < self.local_rate: # Local search around best\n                 x_trial = self.x_opt + np.random.normal(0, 0.05, self.dim) # smaller steps\n                 x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n            else:    \n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        if np.random.rand() < 0.1:\n            self.F = np.clip(np.random.normal(0.5, 0.2), 0.1, 0.9)\n        if np.random.rand() < 0.1:\n            self.Cr = np.clip(np.random.normal(0.7, 0.15), 0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.559 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["654b7e18-cb5a-4f94-b034-22e7b63717a8"], "operator": null, "metadata": {"aucs": [0.3186421761617867, 0.19909339840169638, 0.7128240157001999, 0.9147129999867811, 0.8845902799875731, 0.8792864013259406, 0.28123662677241923, 0.7106139656097181, 0.2649736327478991, 0.19673706615644404, 0.943067036717575, 0.9990307263695835, 0.2407309550893867, 0.25572301466214675, 0.9237190710701499, 0.33530826084307674, 0.41230322777997586, 0.9509811327317876, 0.23989865257732368, 0.515050799902403]}}
{"id": "6deff661-c71a-4972-9622-f7de770feab4", "fitness": 0.7454296101539736, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters F and Cr, and reduced complexity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Self-adaptive F and Cr\n            if f_trial < self.fitness[i]:\n                self.F = np.random.normal(0.5, 0.1)\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.Cr = np.random.normal(0.9, 0.1)\n                self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.745 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ae0bece7-63ca-4f27-a208-ac8ccbca8d17"], "operator": null, "metadata": {"aucs": [0.2631220976135298, 0.26081021431382356, 0.8797297478507581, 0.955987134113092, 0.897275159545479, 0.8989954356147126, 0.8531493822295952, 0.8769612989766047, 0.8379230164406918, 0.8635924134143604, 0.9501806918417455, 0.9934034272527767, 0.44697015659453243, 0.8749738978673905, 0.7497201169391128, 0.9063364210534136, 0.3678463490974957, 0.9222926394613414, 0.5790285652022933, 0.5302940376567228]}}
{"id": "c9b5d431-c376-49cf-815d-9c3076992cf9", "fitness": 0.5441637143802922, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with a simplified parameter adaptation and focused local search around the best solution using a smaller population and adaptive F/Cr based on best solution proximity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, local_search_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.local_search_prob = local_search_prob\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            \n            # Local search around best\n            if np.random.rand() < self.local_search_prob:\n                x_r1 = self.x_opt\n\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        # Adapt F and Cr based on proximity to the best solution\n        if np.linalg.norm(self.pop[np.argmin(self.fitness)] - self.x_opt) < 0.1:\n           self.F = np.clip(np.random.normal(0.4, 0.1), 0.1, 0.9)\n           self.Cr = np.clip(np.random.normal(0.8, 0.1), 0.1, 0.9)\n        else:\n           self.F = np.clip(np.random.normal(0.5, 0.2), 0.1, 0.9)\n           self.Cr = np.clip(np.random.normal(0.7, 0.2), 0.1, 0.9)\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.544 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["654b7e18-cb5a-4f94-b034-22e7b63717a8"], "operator": null, "metadata": {"aucs": [0.32152502992605236, 0.23874434034766423, 0.447047969502543, 0.9622807574950675, 0.34891433999553734, 0.289548504530697, 0.3766734455840286, 0.8810174611874548, 0.819297888129501, 0.2196230549311976, 0.5379350126791396, 0.998837223369291, 0.3153809365755401, 0.3270598106526118, 0.7329559869129478, 0.4815982551117889, 0.3036079951177024, 0.9586912521598646, 0.8435056478940783, 0.47902937550313507]}}
{"id": "4fe6dd10-a14a-44fb-b6a7-e1e70ddd53d3", "fitness": 0.7901364324027729, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a fixed population size and adaptive F and Cr based on a moving average of successful values.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.memory_F = []\n        self.memory_Cr = []\n        self.memory_size = 10  # Size of the moving average memory\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.memory_F.append(self.F)\n                self.memory_Cr.append(self.Cr)\n                if len(self.memory_F) > self.memory_size:\n                    self.memory_F.pop(0)\n                    self.memory_Cr.pop(0)\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        if self.memory_F:\n            self.F = np.mean(self.memory_F)\n            self.F = np.clip(self.F, 0.1, 0.9)\n        \n        if self.memory_Cr:\n            self.Cr = np.mean(self.memory_Cr)\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.790 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d5344c01-f89f-4d7f-85c4-0512e88bee0b"], "operator": null, "metadata": {"aucs": [0.5864797493865544, 0.45976420790796435, 0.8553975115269133, 0.936567999280834, 0.8518572619237621, 0.8659812305611405, 0.8215621010537282, 0.836620246166462, 0.8550338345558082, 0.8261953540338854, 0.9379048157092686, 0.9967819792989454, 0.8395213051739049, 0.8651548642986019, 0.8846707459785366, 0.89166946363658, 0.7787838695951798, 0.9181220458016015, 0.258735692773147, 0.5359243693926397]}}
{"id": "6f8fa36d-86a2-42b4-af19-053fda37f132", "fitness": 0.7075539262688613, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters and reduced complexity for faster convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lr = lr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_F = []\n        self.success_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.success_F.append(self.F)\n                self.success_Cr.append(self.Cr)\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        if self.success_F:\n            self.F = np.mean(self.success_F)\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.success_F = []\n\n        if self.success_Cr:\n            self.Cr = np.mean(self.success_Cr)\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n            self.success_Cr = []\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.708 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ae0bece7-63ca-4f27-a208-ac8ccbca8d17"], "operator": null, "metadata": {"aucs": [0.38088737415504414, 0.915520947929216, 0.49142533613617156, 0.9448323348976697, 0.8738412174712322, 0.8743951012755172, 0.3464523317035181, 0.439920350674075, 0.8978789079644066, 0.8656451642963304, 0.9375117328500471, 0.9960488288800977, 0.33037988225177073, 0.8917448040945393, 0.6978605679433567, 0.9060268982100194, 0.6721427034536047, 0.9365442664709668, 0.22214197198891195, 0.5298778027307294]}}
{"id": "110a2e29-f91b-4340-ad6f-554bf270536c", "fitness": 0.45742929817998323, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with dynamic F/Cr adaptation and local search intensification around the best solution.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, local_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.local_rate = local_rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            crossover_points = np.random.rand(self.dim) < self.Cr\n            x_trial[crossover_points] = x_mutated[crossover_points]\n\n            # Local search around best\n            if np.random.rand() < self.local_rate:\n                x_trial = self.x_opt + 0.01 * np.random.randn(self.dim)\n                x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n            \n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        self.F = 0.5 + 0.3 * np.random.randn()\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = 0.7 + 0.2 * np.random.randn()\n        self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.457 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["654b7e18-cb5a-4f94-b034-22e7b63717a8"], "operator": null, "metadata": {"aucs": [0.16829426405298598, 0.2751826034800301, 0.6435186752516917, 0.24744875019912538, 0.24373872424955811, 0.8228515374959289, 0.3240025235593328, 0.25086811270286236, 0.3460022624987784, 0.2076071005834672, 0.3447433752089202, 0.9923633465408107, 0.24593881006657636, 0.7854387251885633, 0.8449358591442006, 0.3620973090189493, 0.4532894634861798, 0.9108823977127671, 0.18463890069901423, 0.4947432224599225]}}
{"id": "cb169ad3-c7cf-45d2-81ee-f6ab29a6411f", "fitness": 0.7034280322604591, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with individual learning rates for F and Cr, and a moving average of successful values.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, history_length=10, F_lr=0.1, Cr_lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = np.full(pop_size, F)  # Individual F values\n        self.Cr = np.full(pop_size, Cr)  # Individual Cr values\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_F = [[] for _ in range(pop_size)]  # Track success for each individual\n        self.success_Cr = [[] for _ in range(pop_size)]\n        self.history_length = history_length\n        self.F_lr = F_lr # Learning rate for F\n        self.Cr_lr = Cr_lr # Learning rate for Cr\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F[i] * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr[i] or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.success_F[i].append(self.F[i])\n                self.success_Cr[i].append(self.Cr[i])\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n        \n    def adapt_parameters(self):\n        for i in range(self.pop_size):\n            # Adaptive F: Use moving average of successful F values\n            if self.success_F[i]:\n                avg_F = np.mean(self.success_F[i][-self.history_length:])\n                self.F[i] += self.F_lr * (avg_F - self.F[i])\n                self.F[i] = np.clip(self.F[i], 0.1, 0.9)\n\n            # Adaptive Cr: Use moving average of successful Cr values\n            if self.success_Cr[i]:\n                avg_Cr = np.mean(self.success_Cr[i][-self.history_length:])\n                self.Cr[i] += self.Cr_lr * (avg_Cr - self.Cr[i])\n                self.Cr[i] = np.clip(self.Cr[i], 0.1, 0.9)\n\n        self.success_F = [[] for _ in range(self.pop_size)]  # Reset success lists\n        self.success_Cr = [[] for _ in range(self.pop_size)]\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.703 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["238092b8-e6eb-431b-b55f-8566dd9b8ad7"], "operator": null, "metadata": {"aucs": [0.292769034179578, 0.6497303326807955, 0.6767846427338005, 0.8511938022240976, 0.751091129926302, 0.7794396918064178, 0.6317847133367522, 0.6577142102816069, 0.7263477066397493, 0.7053580379598237, 0.8833412369562804, 0.9974491512122994, 0.6509823193831134, 0.7327723718332273, 0.9223256944286676, 0.7849404228799528, 0.6043147925464958, 0.8428847431407376, 0.3162434135917924, 0.6110931974676925]}}
{"id": "ebbedbe0-9a3f-4680-bd12-004fd159e920", "fitness": 0.5518483095389504, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters and a reduced population size for faster convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.memory_F = []\n        self.memory_Cr = []\n        self.memory_size = 10\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.memory_F.append(self.F)\n                self.memory_Cr.append(self.Cr)\n                if len(self.memory_F) > self.memory_size:\n                    self.memory_F.pop(0)\n                    self.memory_Cr.pop(0)\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        if self.memory_F:\n            self.F = np.mean(self.memory_F)\n            self.F = np.clip(self.F, 0.1, 0.9)\n        \n        if self.memory_Cr:\n            self.Cr = np.mean(self.memory_Cr)\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.552 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d5344c01-f89f-4d7f-85c4-0512e88bee0b"], "operator": null, "metadata": {"aucs": [0.396025162079238, 0.29776105328950353, 0.5897564044680829, 0.971357663108977, 0.7542846183269757, 0.442275030943335, 0.46172963543333767, 0.5666226625460937, 0.5429338510327891, 0.2108472329673482, 0.9414351716730823, 0.994979542714814, 0.2657100802724728, 0.34808243594586297, 0.7127538431501907, 0.8836879435672287, 0.37177423803806886, 0.3837652555796892, 0.3809429006648035, 0.5202414649771121]}}
{"id": "c08ef62e-465a-45a5-ba7c-1f81d3055bba", "fitness": 0.7357379103909395, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using weighted averages of successful F and Cr values and a small population size.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.learning_rate = learning_rate\n        self.archive = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                # Update F and Cr using a weighted average\n                self.F = (1 - self.learning_rate) * self.F + self.learning_rate * self.F  # Keep F constant in this version\n                self.Cr = (1 - self.learning_rate) * self.Cr + self.learning_rate * np.random.rand() # Use a random value for Cr\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.736 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["238092b8-e6eb-431b-b55f-8566dd9b8ad7"], "operator": null, "metadata": {"aucs": [0.22920587950676508, 0.7244149906262719, 0.7651005091745146, 0.9203967556605969, 0.849291453422071, 0.8920332415709175, 0.788577444308982, 0.8088633129468514, 0.8495675525422965, 0.8312765950713066, 0.8653264332786188, 0.9971547214999444, 0.34290697111963075, 0.8431102549555524, 0.735328931384665, 0.896596162834892, 0.6998969491939122, 0.8437342777308536, 0.3167545776353411, 0.5152211933548088]}}
{"id": "ae6dd43e-96e2-4212-a1fb-bf1ed3b8854d", "fitness": -Infinity, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a mirrored archive to enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, archive_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.archive = []\n        self.archive_size = archive_size\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x)] for x in self.pop)\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation using archive\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x_r1, x_r2 = self.pop[idxs]\n\n            if len(self.archive) > 0 and np.random.rand() < 0.1:\n                x_r3 = self.archive[np.random.randint(len(self.archive))]\n            else:\n                x_r3 = self.pop[np.random.choice(self.pop_size)]\n\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.pop[i].copy())\n                else:\n                    self.archive[np.random.randint(self.archive_size)] = self.pop[i].copy()\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occurred: too many indices for array: array is 0-dimensional, but 1 were indexed.", "error": "", "parent_ids": ["c08ef62e-465a-45a5-ba7c-1f81d3055bba"], "operator": null, "metadata": {}}
{"id": "2b22a15c-bc23-4471-bc66-3aa801deb773", "fitness": -Infinity, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters F and Cr, and a mirrored boundary handling strategy.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.learning_rate = learning_rate\n        self.archive = []\n        self.success_F = []\n        self.success_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            F = np.random.normal(self.F, 0.1)\n            F = np.clip(F, 0.0, 1.0)\n            x_mutated = x_r1 + F * (x_r2 - x_r3)\n\n            # Boundary Handling: Mirrored\n            lower_bounds = func.bounds.lb\n            upper_bounds = func.bounds.ub\n\n            for j in range(self.dim):\n                if x_mutated[j] < lower_bounds:\n                    x_mutated[j] = lower_bounds + (lower_bounds - x_mutated[j])\n                elif x_mutated[j] > upper_bounds:\n                    x_mutated[j] = upper_bounds - (x_mutated[j] - upper_bounds)\n            \n            # Crossover\n            x_trial = self.pop[i].copy()\n            Cr = np.random.normal(self.Cr, 0.1)\n            Cr = np.clip(Cr, 0.0, 1.0)\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.success_F.append(F)\n                self.success_Cr.append(Cr)\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Update F and Cr adaptively after each generation.\n            if len(self.success_F) > 0:\n                self.F = np.mean(self.success_F)\n                self.Cr = np.mean(self.success_Cr)\n                self.success_F = []\n                self.success_Cr = []\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["c08ef62e-465a-45a5-ba7c-1f81d3055bba"], "operator": null, "metadata": {}}
{"id": "22243e04-e667-49bf-b962-3aea7b6d3d85", "fitness": -Infinity, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on successful parameter values and a dynamically adjusted population size.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_F = []\n        self.success_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.success_F.append(self.F)\n                self.success_Cr.append(self.Cr)\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        if self.success_F:\n            self.F = np.mean(self.success_F)\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.success_F = []\n        else:\n            self.F = 0.5  # Reset F if no success\n\n        if self.success_Cr:\n            self.Cr = np.mean(self.success_Cr)\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n            self.success_Cr = []\n        else:\n            self.Cr = 0.9  # Reset Cr if no success\n\n        # Adjust population size (simplified)\n        if self.eval_count < self.budget // 2 and len(self.success_F) > self.pop_size // 5:\n            self.pop_size = int(self.pop_size * 1.1)\n            self.pop_size = min(self.pop_size, self.budget)\n            \n        elif self.eval_count > self.budget // 2 and len(self.success_F) < self.pop_size // 10:\n            self.pop_size = int(self.pop_size * 0.9)\n            self.pop_size = max(self.pop_size, self.dim + 1)\n\n        self.pop_size = int(self.pop_size)\n        \n\n    def __call__(self, func):\n        self.pop_size = int(self.pop_size)\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            if self.pop_size != self.pop.shape[0] and self.eval_count < self.budget:\n                # Resize population if needed\n                new_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - self.pop.shape[0], self.dim))\n                new_fitness = np.array([func(x) for x in new_pop])\n                self.eval_count += new_pop.shape[0]\n                \n                self.pop = np.concatenate([self.pop, new_pop]) if new_pop.shape[0] > 0 else self.pop\n                self.fitness = np.concatenate([self.fitness, new_fitness]) if new_pop.shape[0] > 0 else self.fitness\n\n            self.evolve(func)\n            self.adapt_parameters()\n            \n            best_index = np.argmin(self.fitness)\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occurred: negative dimensions are not allowed.", "error": "", "parent_ids": ["4fe6dd10-a14a-44fb-b6a7-e1e70ddd53d3"], "operator": null, "metadata": {}}
{"id": "0c777939-7454-4dd7-8889-c452b77fa408", "fitness": 0.17593836026225468, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified self-adaptation of F and Cr based on successful updates, and population restart.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, restart_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.restart_prob = restart_prob\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n                # Simplified self-adaptive F and Cr\n                self.F = 0.9 * self.F + 0.1 * np.random.uniform(0.1, 0.9)\n                self.Cr = 0.9 * self.Cr + 0.1 * np.random.uniform(0.1, 0.9)\n\n        # Population restart\n        if np.random.rand() < self.restart_prob:\n            self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.pop])\n            self.eval_count += self.pop_size\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.pop[best_index]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.176 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6deff661-c71a-4972-9622-f7de770feab4"], "operator": null, "metadata": {"aucs": [0.14317738321137063, 0.21107516369108603, 0.34950089414656205, 0]}}
{"id": "815e29ed-70d4-4016-bccf-f616a5f12bc3", "fitness": 0.48443852554407485, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and periodic population reset.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, reset_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.reset_prob = reset_prob\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def maybe_reset_population(self, func):\n        if np.random.rand() < self.reset_prob:\n            self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.pop])\n            self.eval_count += self.pop_size\n            best_index = np.argmin(self.fitness)\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.maybe_reset_population(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.484 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6f8fa36d-86a2-42b4-af19-053fda37f132"], "operator": null, "metadata": {"aucs": [0.2510659269550627, 0.3104833900279216, 0.4815888771111386, 0.7271355232886852, 0.3685643022997602, 0.5572964902697473, 0.40504195486674077, 0.3936170115931432, 0.44333773664374676, 0.30709551819137015, 0.8014339375328606, 0.9988421560708152, 0.3535899380847235, 0.45346747712121827, 0.7569408428055411, 0.6259538513867975, 0]}}
{"id": "74fae8ce-d827-4eec-abec-09568498254a", "fitness": 0.6395239188481436, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and reduced population diversity using a single randomly chosen parent.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x_r1, x_r2 = self.pop[idxs]\n            \n            # Simplified mutation: only use two parents\n            x_mutated = self.pop[i] + self.F * (x_r1 - x_r2)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Simplified self-adaptive F and Cr (reset instead of normal distribution)\n            if f_trial < self.fitness[i]:\n                self.F = 0.5\n                self.Cr = 0.9\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.640 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6deff661-c71a-4972-9622-f7de770feab4"], "operator": null, "metadata": {"aucs": [0.22658474977727905, 0.3645743929946984, 0.7173556381052919, 0.8859633241761202, 0.6868801668620597, 0.827253843911684, 0.3967953228685882, 0.6755765501109106, 0.7621806847581977, 0.2166741992343456, 0.888280805234255, 0.9879701749553189, 0.7925274890638645, 0.49961053498100605, 0.9041765426965491, 0.8073818440932796, 0.5824015251970971, 0.8705069704817828, 0.2014350063829301, 0.49634861107761286]}}
{"id": "a8dc5594-892b-431a-8b03-e2dfec258c98", "fitness": 0.7837546247102869, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive crossover rate (Cr) and fixed mutation factor (F) using a smaller population size for faster convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15, F=0.5, Cr=0.9, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.learning_rate = learning_rate\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                # Update Cr using a weighted average of a random value\n                self.Cr = (1 - self.learning_rate) * self.Cr + self.learning_rate * np.random.rand()\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.784 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c08ef62e-465a-45a5-ba7c-1f81d3055bba"], "operator": null, "metadata": {"aucs": [0.35381666400334444, 0.7711904817148798, 0.6859555548652769, 0.9399487403499746, 0.8748055496602078, 0.9258957847787216, 0.8257941389148605, 0.8393478564193888, 0.8847609352038414, 0.773765225440072, 0.9171435486842011, 0.9942264913339742, 0.27395570080117704, 0.8022161297247923, 0.9487824134865552, 0.9168389059273468, 0.7641162152028175, 0.9337362688777637, 0.7311469888411506, 0.5176488999753928]}}
{"id": "6f3c2872-ff89-4c21-a749-9c18cdf9cdd5", "fitness": 0.3346301587682789, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation, reduced memory, and periodic population refreshment to enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, refresh_rate=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.refresh_rate = refresh_rate # Rate to refresh population\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_F = []\n        self.success_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.success_F.append(self.F)\n                self.success_Cr.append(self.Cr)\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        if self.success_F:\n            self.F = 0.9 * self.F + 0.1 * np.mean(self.success_F)  # Moving average\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.success_F = []\n\n        if self.success_Cr:\n            self.Cr = 0.9 * self.Cr + 0.1 * np.mean(self.success_Cr) # Moving average\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n            self.success_Cr = []\n\n    def refresh_population(self, func):\n        # Replace a fraction of the population with new random individuals.\n        num_refresh = int(self.refresh_rate * self.pop_size)\n        idx_to_refresh = np.random.choice(self.pop_size, num_refresh, replace=False)\n        self.pop[idx_to_refresh] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_refresh, self.dim))\n        self.fitness[idx_to_refresh] = [func(x) for x in self.pop[idx_to_refresh]]\n        self.eval_count += num_refresh\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n            if self.eval_count < self.budget: # Ensure refresh does not exceed budget.\n                self.refresh_population(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.335 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6f8fa36d-86a2-42b4-af19-053fda37f132"], "operator": null, "metadata": {"aucs": [0.1505890410427615, 0.2297564288387618, 0.3145681356518858, 0.3170995726127931, 0.27855843970589966, 0.2899797184546996, 0.2754185997909202, 0.2685106341848782, 0.247703241542369, 0.1831877986923508, 0.3091398263161834, 0.9998377152670898, 0.27364138992698617, 0.29756680347536546, 0.6657976052993158, 0.3196856630593464, 0.2692900588512279, 0.3459175719254416, 0.18963602658487466, 0.46671890414242767]}}
{"id": "46dede49-4b5a-466f-ac67-056261ffc9da", "fitness": 0.7755091543040133, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on successful parameter values and a Cauchy mutation operator for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.successful_F = []\n        self.successful_Cr = []\n        self.p = 0.1  # Probability for Cauchy mutation\n        self.memory_size = 5\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Cauchy mutation with probability p\n            if np.random.rand() < self.p:\n                cauchy_values = np.random.standard_cauchy(size=self.dim) * 0.1  # Scale Cauchy values\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3) + cauchy_values\n            else:\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                \n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.successful_F.append(self.F)\n                self.successful_Cr.append(self.Cr)\n\n                # Keep only the last 'memory_size' successful values\n                if len(self.successful_F) > self.memory_size:\n                    self.successful_F.pop(0)\n                    self.successful_Cr.pop(0)\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        if self.successful_F:\n            self.F = np.median(self.successful_F)\n            self.F = np.clip(self.F, 0.1, 0.9)\n        \n        if self.successful_Cr:\n            self.Cr = np.median(self.successful_Cr)\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.776 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4fe6dd10-a14a-44fb-b6a7-e1e70ddd53d3"], "operator": null, "metadata": {"aucs": [0.574385786598849, 0.8273486027773174, 0.8191602639239258, 0.9213682214240001, 0.8698507438476114, 0.8714840551627896, 0.7946215459858601, 0.8191794243806655, 0.8312916481882768, 0.8394903390593403, 0.9149794650283437, 0.9909488405697057, 0.42318461259348583, 0.8569878555056387, 0.8080431404820114, 0.8829838037852538, 0.6891359828564211, 0.910550090041064, 0.3503570903613711, 0.5148315735083385]}}
{"id": "5a609046-dd13-45a7-b99d-4c9fc8e6aa47", "fitness": 0.6350666515415412, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with even more aggressively self-adaptive F and Cr parameters and a dynamically adjusted population size based on budget.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget, dim * pop_factor) # Dynamic population size\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_F = []\n        self.success_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.success_F.append(self.F)\n                self.success_Cr.append(self.Cr)\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n            # Aggressive Self-adaptive F and Cr with averaging\n            if self.success_F:\n                self.F = np.mean(self.success_F)\n                self.Cr = np.mean(self.success_Cr)\n            else:\n                self.F = np.random.uniform(0.1, 0.9)\n                self.Cr = np.random.uniform(0.1, 0.9)\n\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.635 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6deff661-c71a-4972-9622-f7de770feab4"], "operator": null, "metadata": {"aucs": [0.2570350296362979, 0.38340478397871125, 0.815559365581113, 0.833628939314941, 0.6046049365516986, 0.35879499278839766, 0.6053116438914441, 0.46695068625888403, 0.8634388943470264, 0.44518350621625846, 0.9222056436702479, 0.9947197983307741, 0.25375416867951495, 0.8366186713725627, 0.7391055627690288, 0.8942873155174823, 0.4766524873791641, 0.9230877422585937, 0.23858871276316773, 0.7884001495255168]}}
{"id": "52c62e0c-31cf-486b-b0e1-c8ad6361b6ec", "fitness": 0.7534527598478965, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with reduced memory by directly adapting F and Cr without storing successful values.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lr = lr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_count = 0\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.success_count += 1\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        if self.success_count > 0:\n            self.F = 0.9 * self.F + 0.1 * np.random.uniform(0.1, 0.9)\n            self.Cr = 0.9 * self.Cr + 0.1 * np.random.uniform(0.1, 0.9)\n            self.success_count = 0\n        else:\n            self.F = 0.9 * self.F + 0.1 * np.random.uniform(0.1, 0.9)\n            self.Cr = 0.9 * self.Cr + 0.1 * np.random.uniform(0.1, 0.9)\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.753 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6f8fa36d-86a2-42b4-af19-053fda37f132"], "operator": null, "metadata": {"aucs": [0.25914035295504045, 0.5850525377020495, 0.8200843126762631, 0.9332329166998655, 0.8704540050464659, 0.8973662565521985, 0.8273096321855078, 0.8041447643424195, 0.8576387572361397, 0.801429640356514, 0.9022184198512797, 0.9876993719506264, 0.3689843935728717, 0.753752320023555, 0.9351541993562643, 0.8874402871640957, 0.6933101913896278, 0.92403993338744, 0.3425650490405958, 0.6180378554691088]}}
{"id": "b235a613-f860-4761-8d8c-60a459314e73", "fitness": 0.3864670357003438, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a decay factor for F and Cr and an archive to prevent premature convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.decay = decay\n        self.archive = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                # Archive successful solutions\n                self.archive.append(self.pop[i].copy())\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    \n                # Decay F and Cr\n                self.F *= self.decay\n                self.Cr *= self.decay\n            else:\n                # If the trial vector is not better, replace it with a vector from the archive if possible\n                if len(self.archive) > 0 and np.random.rand() < 0.1:  # Small chance to replace with archive vector\n                    x_replace = self.archive[np.random.randint(len(self.archive))]\n                    f_replace = func(x_replace)\n                    self.eval_count += 1\n                    if f_replace < self.fitness[i]:\n                        self.fitness[i] = f_replace\n                        self.pop[i] = x_replace\n                        if f_replace < self.f_opt:\n                            self.f_opt = f_replace\n                            self.x_opt = x_replace\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.386 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c08ef62e-465a-45a5-ba7c-1f81d3055bba"], "operator": null, "metadata": {"aucs": [0.15788630747446764, 0.35038092906807694, 0.3116425955290808, 0.4257947393406558, 0.31343743758871445, 0.38967404753575885, 0.30396810372041383, 0.36081184491636664, 0.309251062109164, 0.22932618008536432, 0.549030484650129, 0.9983726759790503, 0.24331533941228056, 0.28456574085097264, 0.5946700069775068, 0.3558104737828347, 0.34361066005882823, 0.46793066602561395, 0.2363840282042191, 0.5034773906973771]}}
{"id": "8f8f2c22-e532-4634-a483-8d7036e58f72", "fitness": 0.23574034055215215, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a single parent difference and a more aggressive parameter reset based on global best.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Simplified mutation: only use one parent difference\n            idx = np.random.randint(self.pop_size)\n            x_r = self.pop[idx]\n            \n            x_mutated = self.pop[i] + self.F * (x_r - self.pop[i])\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Aggressive self-adaptive F and Cr based on global best\n            if f_trial < self.f_opt:\n                self.F = 0.3  # More exploration\n                self.Cr = 0.7  # Balance exploration/exploitation\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.236 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["74fae8ce-d827-4eec-abec-09568498254a"], "operator": null, "metadata": {"aucs": [0.13982026396053227, 0.15493681426108363, 0.3045751407648981, 0.16117202119149898, 0.14919392140881482, 0.16712522834544086, 0.19810617669986963, 0.17816913023973902, 0.1792811823936301, 0.14903728813659767, 0.19633928529224098, 0.9993087780576788, 0.24038795037223604, 0.13213780979854128, 0.13476798390621314, 0.2408362706160947, 0.2246477291881782, 0.1578456887315831, 0.15760973180889792, 0.4495084158692738]}}
{"id": "4c1f9d2c-5066-4543-bbf0-39e82cfa00a2", "fitness": 0.6554903883947263, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and reduced population diversity using a single randomly chosen parent and simplified mutation and crossover.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x_r1, x_r2 = self.pop[idxs]\n            \n            # Simplified mutation: only use two parents\n            x_mutated = self.pop[i] + self.F * (x_r1 - x_r2)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Simplified crossover\n            x_trial = np.where(np.random.rand(self.dim) < self.Cr, x_mutated, self.pop[i])\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.655 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["74fae8ce-d827-4eec-abec-09568498254a"], "operator": null, "metadata": {"aucs": [0.18896219793793378, 0.629031802659419, 0.6923995348602157, 0.8885189378307579, 0.7328766557964148, 0.8235254678111432, 0.3617829329582357, 0.6684457820310143, 0.7691991742043365, 0.19829909416793956, 0.9168111735013991, 0.9955284740890115, 0.7524728363302836, 0.632767573809294, 0.9322824581076263, 0.7917569546848925, 0.5648803154247398, 0.8468641343240164, 0.22414998550913146, 0.4992522818567212]}}
{"id": "8bbfa790-f38d-4cb6-a9a8-ad0003c0493e", "fitness": 0.8033792118574132, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation, Cauchy mutation, and a focus on exploration via wider parameter sampling.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.p = 0.1  # Probability for Cauchy mutation\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Cauchy mutation with probability p\n            if np.random.rand() < self.p:\n                cauchy_values = np.random.standard_cauchy(size=self.dim) * 0.5  # Increased scale\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3) + cauchy_values\n            else:\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                \n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.803 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["46dede49-4b5a-466f-ac67-056261ffc9da"], "operator": null, "metadata": {"aucs": [0.6218622169086039, 0.8581894279468922, 0.7167082964144129, 0.9138221551766953, 0.8537156791214058, 0.8863773200247588, 0.7538564374320118, 0.8035920829480467, 0.8596710592853073, 0.8137786622035121, 0.9160696172375842, 0.9964903592553978, 0.709091924102087, 0.8606670836265091, 0.7144012947333491, 0.871355087764766, 0.7760018594858296, 0.9132285678100271, 0.7354590493308193, 0.4932460563402489]}}
{"id": "61dcba81-7b87-4da8-8d35-6fbe20f191ee", "fitness": 0.5085129301497344, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive crossover rate (Cr) and fixed mutation factor (F), using a smaller population size and resetting Cr to a fixed value if no improvement is found.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        no_improvement_count = 0\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    no_improvement_count = 0 #reset counter\n                else:\n                    no_improvement_count +=1\n            else:\n                no_improvement_count += 1\n\n            if no_improvement_count > self.pop_size:\n                 self.Cr = 0.9 # Reset Cr after a cycle without global improvement\n                 no_improvement_count = 0\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.509 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a8dc5594-892b-431a-8b03-e2dfec258c98"], "operator": null, "metadata": {"aucs": [0.17495665031038876, 0.25691197706106383, 0.37067400113226356, 0.9529705255010117, 0.6147986694199421, 0.8202738418943328, 0.565390353571748, 0.31170556652061143, 0.6253129092011043, 0.20830764280597835, 0.34572704505209917, 0.9976045095716426, 0.4919719035454244, 0.37089963362222134, 0.832364921849325, 0.32897305159770274, 0.39518191954689375, 0.6477863944057888, 0.3562288459663405, 0.5022182404188067]}}
{"id": "3a27d363-d595-4878-bf76-4bc310022583", "fitness": 0.7297864520563031, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adjusting parameters and a focused perturbation strategy for enhanced exploitation and exploration balance.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.memory_size = 5\n        self.successful_F = []\n        self.successful_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_diff = x_r2 - x_r3\n            \n            # Focused Perturbation: Apply DE mutation only to promising dimensions\n            mask = np.random.rand(self.dim) < self.Cr  # Apply crossover mask directly\n            x_mutated = self.pop[i].copy() # Start with a copy of the current individual\n            x_mutated[mask] = x_r1[mask] + self.F * x_diff[mask]  # Apply mutation only where mask is True\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n\n            # Selection\n            f_trial = func(x_mutated)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.successful_F.append(self.F)\n                self.successful_Cr.append(self.Cr)\n\n                # Keep only the last 'memory_size' successful values\n                if len(self.successful_F) > self.memory_size:\n                    self.successful_F.pop(0)\n                    self.successful_Cr.pop(0)\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_mutated\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_mutated\n\n    def adapt_parameters(self):\n         if self.successful_F:\n            self.F = np.mean(self.successful_F)  # Use mean instead of median\n            self.F = np.clip(self.F, 0.1, 0.9)\n         else:\n             self.F = 0.5 # reset to default if no successful F values\n\n         if self.successful_Cr:\n            self.Cr = np.mean(self.successful_Cr)\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n         else:\n             self.Cr = 0.9 # reset to default if no successful Cr values\n             \n         self.successful_F = []\n         self.successful_Cr = [] # Clear successful values after adaptation\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.730 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["46dede49-4b5a-466f-ac67-056261ffc9da"], "operator": null, "metadata": {"aucs": [0.3680312187074889, 0.4400675163389858, 0.8536881522455927, 0.9415402838837679, 0.8626358397687188, 0.8970192746843495, 0.8245528319855142, 0.8121853197935496, 0.8695936399127057, 0.8345372283065065, 0.9227254698996099, 0.9930850674201834, 0.29323426910761585, 0.8655046830585582, 0.7516601021094863, 0.8935922650714911, 0.4095101933284252, 0.923620817661999, 0.31846178206369513, 0.5204830857778187]}}
{"id": "aa3c5448-02d7-4de9-8958-30472bbf6cc2", "fitness": 0.43121256850289047, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with a smaller population size and simplified parameter adaptation based on current best solution, enhancing exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=10, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)  # Select 3 distinct indices\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Mutation using current best\n            x_mutated = self.x_opt + self.F * (x_r1 - x_r2)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    #Adapt F and Cr based on improvement\n                    self.F = np.clip(self.F + 0.1 * np.random.normal(), 0.1, 0.9)\n                    self.Cr = np.clip(self.Cr + 0.1 * np.random.normal(), 0.1, 0.9)\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.431 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["74fae8ce-d827-4eec-abec-09568498254a"], "operator": null, "metadata": {"aucs": [0.08957299015630615, 0.17539394567632227, 0.29966084049457264, 0.9730455329842732, 0.4926416925140725, 0.22537031848200928, 0.3264953632036349, 0.45963022585941393, 0.2489744445456895, 0.553905608413382, 0.6083443905932799, 0.997147989909155, 0.24206936915691435, 0.1758351142862744, 0.9716453423898018, 0.3117828909297622, 0.4945490694559087, 0.290444186939659, 0.19567231293347775, 0.49206974113389923]}}
{"id": "88a81942-18a1-4209-a5ea-ccafc554c9bf", "fitness": 0.7580756053113679, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a single, recent successful parameter value for F and Cr, and a simplified Cauchy mutation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.last_successful_F = None\n        self.last_successful_Cr = None\n        self.p = 0.1  # Probability for Cauchy mutation\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Simplified Cauchy mutation with probability p\n            if np.random.rand() < self.p:\n                cauchy_value = np.random.standard_cauchy(size=1)[0] * 0.1 # Single Cauchy value\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3) + cauchy_value\n            else:\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                \n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.last_successful_F = self.F\n                self.last_successful_Cr = self.Cr\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        if self.last_successful_F is not None:\n            self.F = self.last_successful_F\n            self.F = np.clip(self.F, 0.1, 0.9)\n        \n        if self.last_successful_Cr is not None:\n            self.Cr = self.last_successful_Cr\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.758 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["46dede49-4b5a-466f-ac67-056261ffc9da"], "operator": null, "metadata": {"aucs": [0.5707988646056323, 0.8234004290028736, 0.7949435353365947, 0.922245734119875, 0.8673365250773962, 0.8759286348074062, 0.3428176458946832, 0.8098219383939702, 0.8529007549685208, 0.841313503765138, 0.9285256835994908, 0.9869786093097689, 0.4471567344343508, 0.8401187481762783, 0.9459295207084673, 0.8587316708727484, 0.7917967424894677, 0.9083296288200583, 0.2749126200261137, 0.4775245818185242]}}
{"id": "4fe54346-6d67-4de7-8369-419c1ac4cd72", "fitness": 0.5568465842508294, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with rank-based selection, adaptive F/Cr and a mirrored boundary handling.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.memory_size = 5\n        self.successful_F = []\n        self.successful_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        ranked_indices = np.argsort(self.fitness)\n        elites = self.pop[ranked_indices[:self.pop_size // 5]]  # Top 20% elites\n\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation: Use an elite individual\n            elite = elites[np.random.randint(len(elites))]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x_r1, x_r2 = self.pop[idxs]\n\n            x_mutated = elite + self.F * (x_r1 - x_r2)\n            \n            # Mirrored boundary handling\n            oob = np.logical_or(x_mutated < func.bounds.lb, x_mutated > func.bounds.ub)\n            x_mutated[oob] = 2 * (func.bounds.lb + func.bounds.ub)[oob] - x_mutated[oob]\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.successful_F.append(self.F)\n                self.successful_Cr.append(self.Cr)\n                \n                if len(self.successful_F) > self.memory_size:\n                    self.successful_F.pop(0)\n                    self.successful_Cr.pop(0)\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        if self.successful_F:\n            self.F = np.median(self.successful_F)\n            self.F = np.clip(self.F, 0.1, 0.9)\n        else:\n            self.F = 0.5 # Reset if no success\n\n        if self.successful_Cr:\n            self.Cr = np.median(self.successful_Cr)\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n        else:\n            self.Cr = 0.9 # Reset if no success\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.557 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["46dede49-4b5a-466f-ac67-056261ffc9da"], "operator": null, "metadata": {"aucs": [0.25988122590310636, 0.1936209640130343, 0.46605293197534003, 0.9591158641113783, 0.3457466959708356, 0.8202580581881441, 0.37277092036490045, 0.5781902704723243, 0.6382227304013243, 0.2243988643891145, 0.5087818837865028, 0.9980650906047641, 0.4668260811147874, 0.7680301372535132, 0.9706118758455169, 0.9413496619735346, 0.4143688786448745, 0.40168881713659443, 0.31338216910509187, 0.4955685637619073]}}
{"id": "cf995f0d-117f-4f49-82b0-6d10cc72a660", "fitness": 0.7538810925286803, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation, Cauchy mutation, and jittering for enhanced exploration and reduced stagnation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.p = 0.1  # Probability for Cauchy mutation\n        self.memory_size = 5\n        self.successful_F = []\n        self.successful_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Cauchy mutation with probability p\n            if np.random.rand() < self.p:\n                cauchy_values = np.random.standard_cauchy(size=self.dim) * 0.01  # Scale Cauchy values\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3) + cauchy_values\n            else:\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            \n            # Jittering: Add small random value to F\n            F_jittered = self.F + np.random.normal(0, 0.01)\n            F_jittered = np.clip(F_jittered, 0.1, 0.9)  # Ensure F is within bounds\n            x_mutated = x_r1 + F_jittered * (x_r2 - x_r3)\n\n\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                self.successful_F.append(self.F)\n                self.successful_Cr.append(self.Cr)\n\n                # Keep only the last 'memory_size' successful values\n                if len(self.successful_F) > self.memory_size:\n                    self.successful_F.pop(0)\n                    self.successful_Cr.pop(0)\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n      if self.successful_F:\n          self.F = np.mean(self.successful_F)\n          self.F = np.clip(self.F, 0.1, 0.9)  # Keep F within bounds\n\n      if self.successful_Cr:\n          self.Cr = np.mean(self.successful_Cr)\n          self.Cr = np.clip(self.Cr, 0.1, 0.9)  # Keep Cr within bounds\n\n      self.successful_F = []\n      self.successful_Cr = []\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.754 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["46dede49-4b5a-466f-ac67-056261ffc9da"], "operator": null, "metadata": {"aucs": [0.5082744565784341, 0.8606306493257494, 0.8070950880967288, 0.9309072248459032, 0.842837903241878, 0.8833771343033504, 0.8291806364425361, 0.8152504606733723, 0.5409832861348249, 0.7962141434118593, 0.9377823281012848, 0.9920558687317365, 0.3683641834953507, 0.8651806700886953, 0.7398727383396193, 0.8764022592670089, 0.80186443774381, 0.922596545841527, 0.2647022510462973, 0.49404958486364137]}}
{"id": "9c457a1a-401c-4231-9601-9d0de267d610", "fitness": 0.7853706046825917, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a self-adjusting mutation factor based on population fitness diversity to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Adaptive F: Scale with population fitness diversity\n            F = 0.5 + 0.3 * np.std(self.fitness) / (np.max(self.fitness) - np.min(self.fitness) + 1e-8)\n            F = np.clip(F, 0.1, 0.9)\n\n            x_mutated = x_r1 + F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.785 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["52c62e0c-31cf-486b-b0e1-c8ad6361b6ec"], "operator": null, "metadata": {"aucs": [0.3242183945529601, 0.8357194689614402, 0.8556196504250995, 0.9376909118931492, 0.8759652131182764, 0.8951766854352505, 0.8353564642155124, 0.8134858297357728, 0.876911703584494, 0.8410508725870935, 0.9361154250471716, 0.9979751326967168, 0.4532598035110742, 0.8556007330263424, 0.9118837092927806, 0.9060591484253445, 0.8509821929255241, 0.9192693637932989, 0.26054044062049075, 0.5245309498040414]}}
{"id": "49b23ce3-2c9e-4970-b638-46bdd7d119a8", "fitness": 0.5736577824324958, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and a dynamic mutation factor based on population fitness diversity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15, Cr=0.9, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.learning_rate = learning_rate\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        # Calculate population diversity\n        diversity = np.std(self.fitness)\n\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Dynamic Mutation Factor\n            F = 0.2 + 0.8 * np.exp(-30 * diversity)  # Adjust F based on diversity\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                # Update Cr using a weighted average of a random value\n                self.Cr = (1 - self.learning_rate) * self.Cr + self.learning_rate * np.random.rand()\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.574 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a8dc5594-892b-431a-8b03-e2dfec258c98"], "operator": null, "metadata": {"aucs": [0.25377851609835944, 0.3877403350587205, 0.7294759737492174, 0.8478371412014167, 0.3169616121137523, 0.839471250206689, 0.7568532126662493, 0.7184953212534742, 0.2458235561149671, 0.20923254503156208, 0.8909322547328774, 0.9927708923323348, 0.2995469094743253, 0.25495175111397106, 0.8757046701293283, 0.879285872051241, 0.2657480395080011, 0.8939018435336771, 0.26721556781882394, 0.5474283844609301]}}
{"id": "229244a0-9174-4d9a-9a90-2ec52a69c03e", "fitness": 0.7396246275327364, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified self-adaptation of Cr and F based on population fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15, F=0.5, Cr=0.9, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.learning_rate = learning_rate\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                # Adaptive F and Cr\n                delta_f = self.fitness[i] - f_trial\n                self.Cr = (1 - self.learning_rate) * self.Cr + self.learning_rate * np.random.rand() * (delta_f > 0)\n                self.F = (1 - self.learning_rate) * self.F + self.learning_rate * np.random.rand() * (delta_f > 0)\n                \n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.740 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a8dc5594-892b-431a-8b03-e2dfec258c98"], "operator": null, "metadata": {"aucs": [0.308011138921371, 0.8017170866480416, 0.6798571639166471, 0.19904970908101727, 0.8670389019259237, 0.8946769896965456, 0.8465158229169496, 0.8192044496091199, 0.8867256993789121, 0.8598569409096818, 0.9143971709832664, 0.9920947287768538, 0.30552470711527113, 0.86225493368945, 0.9510622364336963, 0.9338182789979862, 0.8372429433008213, 0.9314370775627386, 0.40044055718239235, 0.5015660136080391]}}
{"id": "e29f990e-d35d-42f8-8f96-9db23d1e0b50", "fitness": 0.7655635664140397, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a learning rate for F and Cr, and a simplified mutation strategy.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5, lr_F=0.1, lr_Cr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.lr_F = lr_F  # Learning rate for F\n        self.lr_Cr = lr_Cr  # Learning rate for Cr\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)            \n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                # Update F and Cr using a learning rate\n                self.F = self.F + self.lr_F * (0.5 - self.F)  # Move towards 0.5\n                self.Cr = self.Cr + self.lr_Cr * (0.9 - self.Cr)  # Move towards 0.9\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.766 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["88a81942-18a1-4209-a5ea-ccafc554c9bf"], "operator": null, "metadata": {"aucs": [0.40055770282913317, 0.856062382528399, 0.8646173940906091, 0.9501677562051486, 0.8512711119476808, 0.9023792337876178, 0.8352237115098712, 0.8265837057256116, 0.88123363098857, 0.8456804256539661, 0.92652014786309, 0.9908832861650828, 0.4705460845041115, 0.8845192654976894, 0.8434782313012088, 0.8843714408209797, 0.4460595352793315, 0.9078219699774147, 0.23691267076368627, 0.5063816408415909]}}
{"id": "1d0e1856-2abe-46a1-8463-e7ca8b5f6cf1", "fitness": 0.3539947191814054, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation based on mean population fitness change and a simplified mutation strategy.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.previous_mean_fitness = None\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n        self.previous_mean_fitness = np.mean(self.fitness)\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        current_mean_fitness = np.mean(self.fitness)\n        fitness_change = current_mean_fitness - self.previous_mean_fitness\n        self.previous_mean_fitness = current_mean_fitness\n\n        # Adjust F and Cr based on fitness change\n        if fitness_change > 0:  # Stagnation: increase exploration\n            self.F *= 1.1\n            self.Cr *= 0.9\n        else:  # Improvement: increase exploitation\n            self.F *= 0.9\n            self.Cr *= 1.1\n\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.354 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["88a81942-18a1-4209-a5ea-ccafc554c9bf"], "operator": null, "metadata": {"aucs": [0.16460918964382998, 0.24582695595474047, 0.3548053989414086, 0.37960301046856537, 0.23657450137414093, 0.3219111373335479, 0.2841032098017753, 0.253367480903683, 0.28293830226939465, 0.20059623201213228, 0.31384930962597135, 0.9992396194009148, 0.35709996354131823, 0.33345143259614207, 0.6342419422327018, 0.30987599059795445, 0.2763921431385604, 0.4762417416296212, 0.188325661360221, 0.4668411608014851]}}
{"id": "837e6517-4259-4324-98f7-ebbe26d06ad3", "fitness": 0.6328172590463448, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a population-wide learning rate and simplified parameter updates, enhancing both exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.lr = 0.1 # Population-wide learning rate\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                # Adaptive F and Cr based on success\n                self.F += self.lr * (np.random.rand() - 0.5)\n                self.Cr += self.lr * (np.random.rand() - 0.5)\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.Cr = np.clip(self.Cr, 0.1, 0.9)\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.633 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["88a81942-18a1-4209-a5ea-ccafc554c9bf"], "operator": null, "metadata": {"aucs": [0.3457917484803529, 0.3031877007698024, 0.7045654714579414, 0.8561310918931271, 0.7790534131593286, 0.8520694457068394, 0.3235937927349104, 0.7693550741093232, 0.781302196027387, 0.3374040879489565, 0.7890391030001989, 0.9894210084539345, 0.34028707029228555, 0.6172958901325583, 0.9339325448491548, 0.7687903435429628, 0.6001066805331883, 0.7538957374930928, 0.29715823088064186, 0.5139645494609086]}}
{"id": "29b083ca-2c22-4acb-980a-d86e6591cdde", "fitness": 0.7706392043412309, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a reduced Cauchy mutation probability, dynamic F adaptation based on success rate, and population resizing for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.p = 0.05  # Reduced probability for Cauchy mutation\n        self.success_F = []\n        self.success_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Cauchy mutation with probability p\n            if np.random.rand() < self.p:\n                cauchy_values = np.random.standard_cauchy(size=self.dim) * 0.1  # Reduced scale\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3) + cauchy_values\n            else:\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                \n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.success_count += 1\n                self.success_F.append(self.F)\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F based on success rate\n        if self.success_count > 0 and len(self.success_F) > 0:\n            self.F = np.mean(self.success_F)\n            self.success_F = []\n            self.success_count = 0\n\n        # Population size adaptation\n        if self.eval_count > self.budget // 2 and self.pop_size > self.dim * 2:\n            self.pop_size = max(self.dim * 2, int(self.pop_size * 0.95))\n            self.pop = self.pop[:self.pop_size]\n            self.fitness = self.fitness[:self.pop_size]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.771 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8bbfa790-f38d-4cb6-a9a8-ad0003c0493e"], "operator": null, "metadata": {"aucs": [0.5499170094970852, 0.8296367570170267, 0.7946611469632184, 0.93834593946525, 0.8614902721205306, 0.8872788420798774, 0.773561164105734, 0.8302457817031573, 0.8490351912833889, 0.8380410881140452, 0.9138151633529327, 0.9931991392242963, 0.377740825875472, 0.8506551146471892, 0.760114849987348, 0.863355820347558, 0.8014305318437135, 0.9183856093592481, 0.25414830573247316, 0.5277255341050757]}}
{"id": "935a63b9-1c37-4990-9b2a-2c859157fc5f", "fitness": 0.461408810260164, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a focus on exploration and exploitation balance using a time-varying mutation factor and simplified parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.p = 0.1\n        self.F_decay = 0.999\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Time-varying mutation factor\n            F_current = self.F * (1 - self.eval_count / self.budget)\n\n            if np.random.rand() < self.p:\n                cauchy_values = np.random.standard_cauchy(size=self.dim) * 0.01\n                x_mutated = x_r1 + F_current * (x_r2 - x_r3) + cauchy_values\n            else:\n                x_mutated = x_r1 + F_current * (x_r2 - x_r3)\n\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            self.F *= self.F_decay #decay the mutation rate\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.461 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cf995f0d-117f-4f49-82b0-6d10cc72a660"], "operator": null, "metadata": {"aucs": [0.23909839264556332, 0.3879866023262062, 0.4915479021134238, 0.9520048458131851, 0.33540597700410013, 0.600588725315885, 0.3721832842905878, 0.3473157505158586, 0.3347723503483693, 0.26376844901372676, 0.38919563012168135, 0.9991722817678821, 0.2783672373622019, 0.29449694286798733, 0.6889991377143654, 0.4455190371402893, 0.3616913239784634, 0.7147028774543904, 0.236502272400676, 0.4948571850084371]}}
{"id": "47cafdbd-fc85-428a-9330-4c28a1a6b819", "fitness": 0.7939754547147349, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and a mirrored sampling strategy to enhance boundary exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.p = 0.1 # Probability for mirrored sampling\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                \n            # Mirrored sampling with probability p\n            if np.random.rand() < self.p:\n                for j in range(self.dim):\n                    if x_mutated[j] < func.bounds.lb[j]:\n                        x_mutated[j] = func.bounds.lb[j] + (func.bounds.lb[j] - x_mutated[j])\n                    elif x_mutated[j] > func.bounds.ub[j]:\n                        x_mutated[j] = func.bounds.ub[j] - (x_mutated[j] - func.bounds.ub[j])\n            \n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.794 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["88a81942-18a1-4209-a5ea-ccafc554c9bf"], "operator": null, "metadata": {"aucs": [0.6077909495232029, 0.8458445739522134, 0.8372415446472732, 0.9325054324648788, 0.8478718102770657, 0.9074757851694147, 0.8218051980525052, 0.8270113595798949, 0.8611353715096967, 0.83934080160156, 0.938439345144475, 0.9968424823697548, 0.3610129693268459, 0.8329271216086747, 0.9509402116113918, 0.893996608469061, 0.8160287093475543, 0.9170629325720718, 0.3112486599223643, 0.5329872271447971]}}
{"id": "52c3214d-3184-497a-a23c-9a58d2004de5", "fitness": 0.5216148686952258, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with population-based parameter adaptation using the best individual to guide the mutation, and reduced Cauchy mutation probability.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.p = 0.05  # Reduced probability for Cauchy mutation\n        self.memory_size = 5\n        self.successful_F = []\n        self.successful_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation using the best individual\n            best_idx = np.argmin(self.fitness)\n            x_best = self.pop[best_idx]\n\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x_r1, x_r2 = self.pop[idxs]\n\n            # Cauchy mutation with probability p\n            if np.random.rand() < self.p:\n                cauchy_values = np.random.standard_cauchy(size=self.dim) * 0.01  # Scale Cauchy values\n                x_mutated = x_best + self.F * (x_r1 - x_r2) + cauchy_values\n            else:\n                x_mutated = x_best + self.F * (x_r1 - x_r2)\n\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                self.successful_F.append(self.F)\n                self.successful_Cr.append(self.Cr)\n\n                # Keep only the last 'memory_size' successful values\n                if len(self.successful_F) > self.memory_size:\n                    self.successful_F.pop(0)\n                    self.successful_Cr.pop(0)\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n      if self.successful_F:\n          self.F = np.mean(self.successful_F)\n          self.F = np.clip(self.F, 0.1, 0.9)  # Keep F within bounds\n\n      if self.successful_Cr:\n          self.Cr = np.mean(self.successful_Cr)\n          self.Cr = np.clip(self.Cr, 0.1, 0.9)  # Keep Cr within bounds\n\n      self.successful_F = []\n      self.successful_Cr = []\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.522 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cf995f0d-117f-4f49-82b0-6d10cc72a660"], "operator": null, "metadata": {"aucs": [0.17178624093140116, 0.17362454188883425, 0.9315666368717352, 0.1709264481413405, 0.9512783146051419, 0.24349596803827478, 0.3342509357370361, 0.5332925683995828, 0.31324141621765966, 0.18738369167137192, 0.8293695710230421, 0.9990912946906995, 0.2928362110990915, 0.3122705942161855, 0.9831771900066303, 0.9443644075884631, 0.29089520576776606, 0.9602380448129434, 0.3035818511600674, 0.505626241037247]}}
{"id": "c7f4682d-08ae-4eff-9033-8d95c6953481", "fitness": 0.8053953745355127, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a moving average of successful F and Cr values and a more aggressive parameter adaption, enhanced Cauchy mutation and a shrinking exploration range.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.p = 0.1  # Probability for Cauchy mutation\n        self.memory_size = 5\n        self.successful_F = []\n        self.successful_Cr = []\n        self.bounds_scale = 1.0  # Initial exploration range scale\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Cauchy mutation with probability p\n            if np.random.rand() < self.p:\n                cauchy_values = np.random.standard_cauchy(size=self.dim) * 0.05 * self.bounds_scale # Increased Cauchy scale\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3) + cauchy_values\n            else:\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                self.successful_F.append(self.F)\n                self.successful_Cr.append(self.Cr)\n\n                # Keep only the last 'memory_size' successful values\n                if len(self.successful_F) > self.memory_size:\n                    self.successful_F.pop(0)\n                    self.successful_Cr.pop(0)\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        # Update F and Cr using a moving average\n        if self.successful_F:\n            self.F = 0.9 * self.F + 0.1 * np.mean(self.successful_F) # Moving average\n            self.F = np.clip(self.F, 0.1, 0.9)\n\n        if self.successful_Cr:\n            self.Cr = 0.9 * self.Cr + 0.1 * np.mean(self.successful_Cr) # Moving average\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n        self.successful_F = []\n        self.successful_Cr = []\n\n        # Shrink the exploration range\n        self.bounds_scale *= 0.995\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.805 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cf995f0d-117f-4f49-82b0-6d10cc72a660"], "operator": null, "metadata": {"aucs": [0.5334816707959085, 0.8362581503746872, 0.5743880585610593, 0.9310322691707251, 0.8658571809901086, 0.8957962149771675, 0.801797986084324, 0.8216207280031648, 0.8581964101684665, 0.8236912851652951, 0.9469236023848133, 0.9899029321428088, 0.33037440861908607, 0.8732892988737342, 0.9206836330825969, 0.8817555128249717, 0.8144668185749215, 0.9121212245798718, 0.7228735393418111, 0.7733965659947337]}}
{"id": "fd72ca81-a215-4c4d-8fdd-893c72e7c971", "fitness": 0.4111147629173867, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with time-varying parameter adaptation and enhanced exploration through per-dimension Cauchy mutation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.generation = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Per-dimension Cauchy mutation\n            cauchy_values = np.random.standard_cauchy(size=self.dim) * 0.01 * (func.bounds.ub - func.bounds.lb) \n            x_mutated = x_r1 + self.F * (x_r2 - x_r3) + cauchy_values\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        # Time-varying parameter adaptation\n        self.F = 0.5 + 0.4 * (1 - self.generation / (self.budget / self.pop_size))\n        self.Cr = 0.1 + 0.8 * (self.generation / (self.budget / self.pop_size))\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n            self.generation += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.411 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["88a81942-18a1-4209-a5ea-ccafc554c9bf"], "operator": null, "metadata": {"aucs": [0.167432745357306, 0.20008177396230653, 0.3943441166097731, 0.5622628649119552, 0.3332424904061373, 0.4482548036084132, 0.3188725590387236, 0.36160874532506526, 0.3735595973240676, 0.23477115564715245, 0.3829942441511994, 0.9977453951155326, 0.26174313531836246, 0.33555825400097505, 0.7678335584273672, 0.49094187365286657, 0.34230850773682264, 0.5578181870478762, 0.19318224214901636, 0.4977390085568152]}}
{"id": "dcca542f-945c-4096-9ea3-7879d916fa1c", "fitness": 0.5609787577345502, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters F and Cr based on recent successful values, and enhanced exploration through Cauchy mutation and dynamic population size adjustment.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.memory_size = memory_size\n        self.successful_F = []\n        self.successful_Cr = []\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Cauchy mutation\n            cauchy_values = np.random.standard_cauchy(size=self.dim) * 0.01\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3) + cauchy_values\n            x_mutated = np.clip(x_mutated, self.lb, self.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            x_trial = np.clip(x_trial, self.lb, self.ub)\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                self.successful_F.append(self.F)\n                self.successful_Cr.append(self.Cr)\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        if self.successful_F:\n            self.F = np.mean(self.successful_F)\n            self.F = np.clip(self.F, 0.1, 0.9)\n        if self.successful_Cr:\n            self.Cr = np.mean(self.successful_Cr)\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n        self.successful_F = self.successful_F[-self.memory_size:]\n        self.successful_Cr = self.successful_Cr[-self.memory_size:]\n\n        # Dynamic population size adjustment (simplified)\n        if self.eval_count > self.budget * 0.75:\n            self.pop_size = max(int(self.pop_size * 0.95), self.dim + 1) # Reduce pop size\n            \n        elif len(self.successful_F) == 0 and self.eval_count > self.budget * 0.5:\n            self.pop_size = min(int(self.pop_size * 1.05), 10 * self.dim)  # Increase pop size\n\n        self.pop = self.pop[:self.pop_size]  # Truncate or pad population\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n            if self.pop.shape[0] != self.pop_size:\n                self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.eval_count += self.pop_size\n                best_index = np.argmin(self.fitness)\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.pop[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.561 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["cf995f0d-117f-4f49-82b0-6d10cc72a660"], "operator": null, "metadata": {"aucs": [0.22378428154606178, 0.5082471448871199, 0.515868426759134, 0.938284183036016, 0.5093048632525956, 0.5854583515438507, 0.3761369290976667, 0.4467012886820526, 0.49038513160632435, 0.4399527360568215, 0.9256383044068233, 0.9899106517788104, 0.34278030933892045, 0.5046603873595208, 0.9301810020998597, 0.600230740352601, 0.4422376378676317, 0.6928580116434186, 0.22413176508307064, 0.5328230082927061]}}
{"id": "056826dd-1805-4214-a345-652ab3b49c23", "fitness": 0.5444249042818914, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a population-wide best solution guided mutation and self-adjusting parameters, promoting convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.p = 0.1 # Probability for alternative mutation\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation: Using the best solution in the population\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x_r1, x_r2 = self.pop[idxs]\n\n            if np.random.rand() < self.p:\n                x_mutated = self.x_opt + self.F * (x_r1 - x_r2) + 0.01 * np.random.randn(self.dim)\n            else:\n                x_mutated = self.x_opt + self.F * (x_r1 - x_r2)\n            \n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.544 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["88a81942-18a1-4209-a5ea-ccafc554c9bf"], "operator": null, "metadata": {"aucs": [0.14079142586237192, 0.18740546574790928, 0.9086172877865072, 0.9624483524886728, 0.32383228038699663, 0.7776440781793857, 0.3821468986494435, 0.3384980773691836, 0.7899586826275827, 0.19223519483831564, 0.973677553401731, 0.9908507267576252, 0.2833880579645597, 0.3370551411478889, 0.982966382910505, 0.3647889220734716, 0.2559343838677337, 0.9602639516879153, 0.2379951609580223, 0.49800006093200677]}}
{"id": "5bb50007-f65d-4c62-993d-2155a6559d41", "fitness": 0.7532611875243919, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution using a single, recent successful parameter value and probability-based Cauchy mutation to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.last_successful_F = 0.5\n        self.last_successful_Cr = 0.9\n        self.p = 0.1  # Probability for Cauchy mutation\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Cauchy mutation with probability p\n            if np.random.rand() < self.p:\n                x_mutated = x_r1 + self.last_successful_F * (x_r2 - x_r3) + np.random.standard_cauchy(size=self.dim) * 0.01\n            else:\n                x_mutated = x_r1 + self.last_successful_F * (x_r2 - x_r3)\n                \n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.last_successful_Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                self.last_successful_F = self.F # Update F after successful trial\n                self.last_successful_Cr = self.Cr # Update Cr after successful trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.753 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["88a81942-18a1-4209-a5ea-ccafc554c9bf"], "operator": null, "metadata": {"aucs": [0.3091560155203671, 0.31080866796893325, 0.8442643983427868, 0.9484904106208039, 0.8641884911429596, 0.87146774549052, 0.8187422114745605, 0.8256467962725651, 0.8619061460080738, 0.8274592062369384, 0.9221014767850104, 0.9991533300035335, 0.5515025652297354, 0.831611245569694, 0.9360961785571515, 0.842575481876862, 0.803303879161483, 0.9235282325420091, 0.26883016865600506, 0.5043911030278434]}}
{"id": "61a060c7-a7ec-4de2-8e21-184ddadc6194", "fitness": -Infinity, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with mirrored sampling, reduced parameter adaptation, and population resizing.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.p = 0.1 # Probability for mirrored sampling\n        self.lr = 0.1 # Learning rate for F and Cr\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                \n            # Mirrored sampling with probability p\n            if np.random.rand() < self.p:\n                x_mutated = np.where(x_mutated < func.bounds.lb, 2*func.bounds.lb - x_mutated, x_mutated)\n                x_mutated = np.where(x_mutated > func.bounds.ub, 2*func.bounds.ub - x_mutated, x_mutated)\n            \n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                # Update F and Cr (simplified)\n                success_factor = (self.fitness[i] - f_trial) / (abs(self.fitness[i]) + 1e-8) # Avoid division by zero\n                self.F = (1 - self.lr) * self.F + self.lr * 0.5 # Towards 0.5\n                self.Cr = (1 - self.lr) * self.Cr + self.lr * 0.9 # Towards 0.9\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n            # Population resizing (remove worst if population is too big)\n            if self.pop_size > 2 * self.dim and self.eval_count > self.budget // 2:\n                worst_index = np.argmax(self.fitness)\n                self.pop = np.delete(self.pop, worst_index, axis=0)\n                self.fitness = np.delete(self.fitness, worst_index)\n                self.pop_size -= 1\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "An exception occurred: index 5 is out of bounds for axis 0 with size 5.", "error": "", "parent_ids": ["47cafdbd-fc85-428a-9330-4c28a1a6b819"], "operator": null, "metadata": {}}
{"id": "84a689a1-c8af-46b5-b401-8421c08947f3", "fitness": 0.7125817096854987, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters F and Cr, combined with a more aggressive mutation strategy and reduced parameter update frequency for faster convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)            \n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                # Adapt F and Cr only on successful updates\n                self.F = 0.9 * self.F + 0.1 * np.random.rand()  # Adapt F\n                self.Cr = 0.9 * self.Cr + 0.1 * np.random.rand()  # Adapt Cr\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.713 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e29f990e-d35d-42f8-8f96-9db23d1e0b50"], "operator": null, "metadata": {"aucs": [0.21825530419476669, 0.5818975300160536, 0.7362929843352259, 0.8873266141168502, 0.8177271714053964, 0.8737022270927972, 0.73744199191403, 0.7704664301499687, 0.8138251686161424, 0.7374860376327492, 0.8618775770814998, 0.9983000211551692, 0.35089663076697175, 0.7659871739381149, 0.8970545248557428, 0.8528453147193594, 0.6975156503429667, 0.8854040890489603, 0.23727204093267562, 0.5300597113945338]}}
{"id": "4c28e491-b77d-4af0-8d82-d366827daab6", "fitness": 0.8050020057248191, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a moving average for F and Cr updates, and a mirrored sampling strategy to enhance boundary exploration, without population resizing.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.memory_size = memory_size\n        self.F_memory = np.ones(memory_size) * 0.5\n        self.Cr_memory = np.ones(memory_size) * 0.9\n        self.memory_index = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Mirrored sampling to handle boundaries\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                # Update memory with successful F and Cr\n                self.F_memory[self.memory_index] = self.F\n                self.Cr_memory[self.memory_index] = self.Cr\n                self.memory_index = (self.memory_index + 1) % self.memory_size\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr using moving average\n        self.F = np.mean(self.F_memory)\n        self.Cr = np.mean(self.Cr_memory)\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.805 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["29b083ca-2c22-4acb-980a-d86e6591cdde"], "operator": null, "metadata": {"aucs": [0.6009391848174417, 0.842625479880363, 0.6662478606464183, 0.9448601935023112, 0.8793471282433667, 0.8912488407209815, 0.8401717434946924, 0.8400834716255632, 0.862775085728133, 0.8302878389077976, 0.9172844504503972, 0.9983741165070071, 0.33597479526159724, 0.8639458813143563, 0.8351237041010295, 0.9064484082369856, 0.8312648096587854, 0.9207269704514145, 0.7790360447409699, 0.5132741062067694]}}
{"id": "afb9f2ac-5507-4791-b04c-1d06bac911ca", "fitness": 0.8111630619325169, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with mirrored boundary handling and simplified parameter adaptation based on success history, plus jittering to avoid stagnation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5, p=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.p = p  # Probability for mirrored sampling\n        self.successful_F = []\n        self.successful_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n\n            # Jittering to avoid stagnation\n            if np.random.rand() < 0.05:\n                x_mutated += np.random.normal(0, 0.01, size=self.dim)\n            \n            # Mirrored sampling\n            if np.random.rand() < self.p:\n                x_mutated = np.where(x_mutated < func.bounds.lb, func.bounds.lb + (func.bounds.lb - x_mutated), x_mutated)\n                x_mutated = np.where(x_mutated > func.bounds.ub, func.bounds.ub - (x_mutated - func.bounds.ub), x_mutated)\n            \n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.successful_F.append(self.F)\n                self.successful_Cr.append(self.Cr)\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr based on successful values\n        if self.successful_F:\n            self.F = np.mean(self.successful_F)\n            self.Cr = np.mean(self.successful_Cr)\n            self.successful_F = []\n            self.successful_Cr = []\n        else:\n            self.F = 0.5  # Reset if no successful updates\n            self.Cr = 0.9\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.811 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["47cafdbd-fc85-428a-9330-4c28a1a6b819"], "operator": null, "metadata": {"aucs": [0.5720839989880433, 0.8564821625680631, 0.843675895968033, 0.924000579356598, 0.8461778463397596, 0.8888252811127142, 0.800689056467862, 0.6765002965043361, 0.8777441699611941, 0.8399750611043783, 0.9431227381958958, 0.9989718690472015, 0.49229966975508166, 0.869015798075931, 0.9596226431355057, 0.8904354109567776, 0.764445992238981, 0.9190732433649168, 0.7451893955982725, 0.5149301299107916]}}
{"id": "204d3721-741e-4f69-a5d0-5bcfcdb5e71b", "fitness": 0.7280225788846171, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation, a mirrored sampling strategy, and a population diversity mechanism.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5, lr_F=0.1, lr_Cr=0.1, mirror_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.lr_F = lr_F\n        self.lr_Cr = lr_Cr\n        self.mirror_prob = mirror_prob\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)            \n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Mirroring\n            if np.random.rand() < self.mirror_prob:\n                for j in range(self.dim):\n                    if x_mutated[j] < func.bounds.lb[j]:\n                        x_mutated[j] = func.bounds.lb[j] + (func.bounds.lb[j] - x_mutated[j])\n                    elif x_mutated[j] > func.bounds.ub[j]:\n                        x_mutated[j] = func.bounds.ub[j] - (x_mutated[j] - func.bounds.ub[j])\n                    x_mutated[j] = np.clip(x_mutated[j], func.bounds.lb[j], func.bounds.ub[j])\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.F = self.F + self.lr_F * (0.5 - self.F)\n                self.Cr = self.Cr + self.lr_Cr * (0.9 - self.Cr)\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            else:\n                # Diversity mechanism: replace the worst individual with a random one\n                if np.random.rand() < 0.05:  # Small probability to maintain diversity\n                    worst_index = np.argmax(self.fitness)\n                    self.pop[worst_index] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    self.fitness[worst_index] = func(self.pop[worst_index])\n                    self.eval_count += 1\n                    if self.fitness[worst_index] < self.f_opt:\n                        self.f_opt = self.fitness[worst_index]\n                        self.x_opt = self.pop[worst_index]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.728 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e29f990e-d35d-42f8-8f96-9db23d1e0b50"], "operator": null, "metadata": {"aucs": [0.4955182227584496, 0.7903418323596411, 0.4121009876620796, 0.9435339785361805, 0.8756279960554829, 0.878521091580903, 0.8224820977776068, 0.8145570059111128, 0.8547310057595057, 0.801919176347492, 0.9284982359305468, 0.9992622863137732, 0.40907085249739883, 0.8451410913784256, 0.9642516027427838, 0.88485005193799, 0.653049960026832, 0.3248262315729459, 0.3302355747080611, 0.5319322958351301]}}
{"id": "b72b0e6c-add1-4313-9a9a-3f7c773f9dd9", "fitness": 0.6671977759875936, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with mirrored boundary handling, adaptive F based on population fitness variance, and reduced parameter count for efficiency.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.p = 0.1  # Probability for mirrored sampling\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        # Adaptive F based on population fitness variance\n        self.F = 0.5 + 0.3 * np.var(self.fitness)\n\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n\n            # Mirrored sampling and clipping\n            for j in range(self.dim):\n                if x_mutated[j] < func.bounds.lb[j]:\n                    x_mutated[j] = func.bounds.lb[j] + (func.bounds.lb[j] - x_mutated[j])\n                elif x_mutated[j] > func.bounds.ub[j]:\n                    x_mutated[j] = func.bounds.ub[j] - (x_mutated[j] - func.bounds.ub[j])\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.667 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["47cafdbd-fc85-428a-9330-4c28a1a6b819"], "operator": null, "metadata": {"aucs": [0.10093273443421291, 0.20381066881730558, 0.6284365879142455, 0.8907427517464507, 0.8207846582687047, 0.8714309939704998, 0.812487851547127, 0.7609002183620428, 0.8604670708200646, 0.7819970674075515, 0.9008628174586012, 0.9919949735801088, 0.24554766215439405, 0.3208447870829825, 0.8731912972546265, 0.8893632846170201, 0.43415742235783905, 0.909363941521089, 0.549570259873166, 0.49706847056383874]}}
{"id": "9445c099-c768-4ad7-9705-edd62fa68753", "fitness": 0.6988548108560688, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation using a weighted average of successful F and Cr values, combined with a dynamic population size adjustment and a simplified Cauchy mutation strategy.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5, initial_F=0.5, initial_Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.initial_pop_size = self.pop_size\n        self.F = initial_F\n        self.Cr = initial_Cr\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.p = 0.05  # Probability for Cauchy mutation, reduced for simplification\n        self.memory_size = 5\n        self.successful_F = []\n        self.successful_Cr = []\n        self.bounds_scale = 1.0\n        self.min_pop_size = 4  # Minimum population size\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Simplified Cauchy mutation\n            if np.random.rand() < self.p:\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3) + np.random.standard_cauchy(size=self.dim) * 0.01 * self.bounds_scale\n            else:\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                self.successful_F.append(self.F)\n                self.successful_Cr.append(self.Cr)\n                \n                if len(self.successful_F) > self.memory_size:\n                    self.successful_F.pop(0)\n                    self.successful_Cr.pop(0)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def adapt_parameters(self):\n        # Weighted average for F and Cr\n        if self.successful_F:\n            self.F = 0.8 * self.F + 0.2 * np.mean(self.successful_F)\n            self.F = np.clip(self.F, 0.1, 0.9)\n\n        if self.successful_Cr:\n            self.Cr = 0.8 * self.Cr + 0.2 * np.mean(self.successful_Cr)\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n        self.successful_F = []\n        self.successful_Cr = []\n\n        # Dynamic population size adjustment\n        if self.f_opt < np.mean(self.fitness):\n            self.pop_size = min(self.initial_pop_size, self.pop_size + 1)\n        else:\n            self.pop_size = max(self.min_pop_size, self.pop_size - 1)\n\n        self.bounds_scale *= 0.995\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.699 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["c7f4682d-08ae-4eff-9033-8d95c6953481"], "operator": null, "metadata": {"aucs": [0.48915831958909606, 0.21585600927786375, 0.7112586139117452, 0.933925597758573, 0.8750465544534883, 0.8801835090313149, 0.8004677389166499, 0.8207005555383449, 0.8818518815154165, 0.835690003020492, 0.9300835751109692, 0.9930125278795483, 0.29365162236510134, 0.8616015648306155, 0.5831382893192214, 0.3327989942066326, 0.7864171502960462, 0.9150313037509809, 0.3383480010507959, 0.4988744052984807]}}
{"id": "f7f979e6-069b-4a2a-b0ae-34f34b747b44", "fitness": 0.5078595135229758, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive F and Cr, and a reduced population size for faster convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.memory_F = 0.5\n        self.memory_Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)           \n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                \n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                self.memory_F = 0.9 * self.memory_F + 0.1 * self.F\n                self.memory_Cr = 0.9 * self.memory_Cr + 0.1 * self.Cr\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            #Adapt F and Cr\n            self.F = np.clip(np.random.normal(self.memory_F, 0.1), 0.1, 0.9)\n            self.Cr = np.clip(np.random.normal(self.memory_Cr, 0.1), 0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.508 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["29b083ca-2c22-4acb-980a-d86e6591cdde"], "operator": null, "metadata": {"aucs": [0.26551980103438777, 0.32011925617639925, 0.398930603791424, 0.9457584061410736, 0.36326854820422805, 0.31230851948195903, 0.3905950679415181, 0.36726390439435086, 0.4907187668125266, 0.8918141913470871, 0.5321171725343041, 0.9993301641161723, 0.2695931555192692, 0.6032638895960885, 0.7809345559837239, 0.3274910868524674, 0.28427014792016203, 0.8542093743695074, 0.22621745077203237, 0.5334662074708347]}}
{"id": "d28541b1-78a5-41d7-a5f5-381bd928142f", "fitness": 0.7485193475674863, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with mirrored boundary handling and adaptive F/Cr based on success history and a reduced learning rate.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5, lr_F=0.05, lr_Cr=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.lr_F = lr_F\n        self.lr_Cr = lr_Cr\n        self.success_F = []\n        self.success_Cr = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            \n            # Mirrored boundary handling\n            oob = (x_mutated < func.bounds.lb) | (x_mutated > func.bounds.ub)\n            x_mutated[oob] = 2 * func.bounds.lb[oob] - x_mutated[oob] if (x_mutated[oob] < func.bounds.lb[oob]).any() else 2 * func.bounds.ub[oob] - x_mutated[oob]\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.success_F.append(self.F)\n                self.success_Cr.append(self.Cr)\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Adaptive F and Cr\n            if self.success_F:\n                self.F = (1 - self.lr_F) * self.F + self.lr_F * np.mean(self.success_F)\n                self.Cr = (1 - self.lr_Cr) * self.Cr + self.lr_Cr * np.mean(self.success_Cr)\n                self.success_F = []\n                self.success_Cr = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.749 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e29f990e-d35d-42f8-8f96-9db23d1e0b50"], "operator": null, "metadata": {"aucs": [0.47992073740491625, 0.870798505585086, 0.8505949012091507, 0.9353042347219985, 0.8578183802864523, 0.8837094921151617, 0.7985372183284616, 0.5336175614414891, 0.8829547529807713, 0.40706096646534984, 0.937601013448131, 0.9929814866533495, 0.3644503569585128, 0.8623961098035472, 0.9556098196594751, 0.8812644897472637, 0.7674901730054559, 0.9123011106334313, 0.25962822170095246, 0.5363474192007707]}}
{"id": "aff133ee-18f2-4e80-9340-e18f0c286e70", "fitness": 0.7644465651809428, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive F and Cr, and enhanced boundary handling.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Self-adaptive F\n            F = np.random.normal(0.5, 0.3)\n            F = np.clip(F, 0.1, 1.0)\n\n            x_mutated = x_r1 + F * (x_r2 - x_r3)\n\n            # Boundary handling: Reflect if out of bounds\n            out_of_bounds = (x_mutated < func.bounds.lb) | (x_mutated > func.bounds.ub)\n            x_mutated[out_of_bounds] = 2 * func.bounds.lb[out_of_bounds] - x_mutated[out_of_bounds]\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            # Self-adaptive Cr\n            Cr = np.random.normal(0.9, 0.1)\n            Cr = np.clip(Cr, 0.1, 1.0)\n\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.764 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e29f990e-d35d-42f8-8f96-9db23d1e0b50"], "operator": null, "metadata": {"aucs": [0.4843126966064437, 0.8499192694896447, 0.8107570030353706, 0.8976547805534045, 0.8518126874234329, 0.9082055717801455, 0.8053886451160371, 0.8394377961209626, 0.8734242151522184, 0.2697743047129437, 0.8832743883193217, 0.9968538245618533, 0.3201185763547293, 0.8444174314150663, 0.8542900174620859, 0.8939363798919384, 0.6592973578812431, 0.9103640365497907, 0.8206257442836071, 0.5150665769086167]}}
{"id": "c33a0d2c-9a2d-42d8-8a5a-1c13e7b0b2da", "fitness": 0.7850366003260576, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and enhanced exploration using a mirrored sampling strategy with dynamic probability based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.p = 0.1  # Initial probability for mirrored sampling\n        self.p_decay = 0.995  # Decay factor for p\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        # Calculate population diversity (standard deviation along each dimension)\n        diversity = np.std(self.pop, axis=0)\n        # Adjust mirrored sampling probability based on diversity (higher diversity -> lower probability)\n        self.p = 0.1 / (np.mean(diversity) + 1e-8)  # Adding a small constant to avoid division by zero\n        self.p = max(0.01, min(self.p, 0.5))\n\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                \n            # Mirrored sampling with probability p\n            if np.random.rand() < self.p:\n                for j in range(self.dim):\n                    if x_mutated[j] < func.bounds.lb[j]:\n                        x_mutated[j] = func.bounds.lb[j] + (func.bounds.lb[j] - x_mutated[j])\n                    elif x_mutated[j] > func.bounds.ub[j]:\n                        x_mutated[j] = func.bounds.ub[j] - (x_mutated[j] - func.bounds.ub[j])\n            \n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.785 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["47cafdbd-fc85-428a-9330-4c28a1a6b819"], "operator": null, "metadata": {"aucs": [0.4700769770409463, 0.37407873859962537, 0.7509261178955384, 0.9365216232436107, 0.8678105244183894, 0.8969256560958946, 0.8375504478666143, 0.8204903040349227, 0.8636028850299448, 0.833420526457405, 0.9208660419995697, 0.9988437741447374, 0.49088784373549865, 0.8480578570380023, 0.8965862632430458, 0.8937599193001359, 0.7946685359706639, 0.9254615477550782, 0.7640246518960908, 0.5161717707554383]}}
{"id": "52794162-e491-4cc4-a329-24b2df80f3d2", "fitness": 0.8070425025890744, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a reduced Cauchy mutation probability, dynamic F adaptation based on success rate using exponential moving average, and population resizing for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5, lr_F=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_factor * dim)\n        self.F = 0.5\n        self.Cr = 0.9\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.p = 0.05  # Reduced probability for Cauchy mutation\n        self.lr_F = lr_F # Learning rate for F\n        self.success_F_ema = self.F  # Exponential moving average of successful F\n        self.min_pop_size = dim * 2\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Cauchy mutation with probability p\n            if np.random.rand() < self.p:\n                cauchy_values = np.random.standard_cauchy(size=self.dim) * 0.01  # Reduced scale\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3) + cauchy_values\n            else:\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                \n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                # Update F using exponential moving average\n                self.success_F_ema = (1 - self.lr_F) * self.success_F_ema + self.lr_F * self.F\n                self.F = self.success_F_ema  # Use EMA directly\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Population size adaptation\n        if self.eval_count > self.budget // 2 and self.pop_size > self.min_pop_size:\n            self.pop_size = max(self.min_pop_size, int(self.pop_size * 0.95))\n            self.pop = self.pop[:self.pop_size]\n            self.fitness = self.fitness[:self.pop_size]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.807 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["29b083ca-2c22-4acb-980a-d86e6591cdde"], "operator": null, "metadata": {"aucs": [0.5350940747430881, 0.8126171195840821, 0.7101281394846852, 0.9518817390213951, 0.8148406987316748, 0.8805043785915856, 0.8164845863227486, 0.8245963400743401, 0.8638113108727112, 0.8399648047791205, 0.9315594000031774, 0.9971303579354268, 0.45279374248729776, 0.8456546483019892, 0.9487306221852686, 0.8860782473526536, 0.7501936344554836, 0.9075787273990455, 0.7159965109831723, 0.6552109684725423]}}
