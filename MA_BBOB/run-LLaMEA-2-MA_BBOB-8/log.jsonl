{"id": "78cd7fda-1767-4676-a713-60e51177b691", "fitness": 0.0, "name": "AdaptiveVelocitySearch", "description": "Population-based algorithm with velocity-based movement, adaptive step size, and local search refinement.", "code": "import numpy as np\n\nclass AdaptiveVelocitySearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) # Initialize velocities\n        \n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index].copy()\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        adaptive_step_size = 1.0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocities with inertia, cognitive, and social components\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i]))\n\n                # Update position, clip to bounds, reduce step size if out of bounds\n                new_position = population[i] + adaptive_step_size * velocities[i]\n                \n                # Boundary Handling and Step Size Adaptation\n                out_of_bounds = np.logical_or(new_position < func.bounds.lb, new_position > func.bounds.ub)\n                if np.any(out_of_bounds):\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                    adaptive_step_size *= 0.9  # Reduce step size if out of bounds\n\n                # Evaluate fitness of new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n\n            # Local Search around global best (optional refinement)\n            for _ in range(min(self.local_search_iterations, self.budget)):  # Limit iterations by budget\n                perturbation = np.random.normal(0, 0.05, self.dim)  # Small random perturbation\n                local_position = global_best_position + perturbation\n                local_position = np.clip(local_position, func.bounds.lb, func.bounds.ub) # clip to bounds\n\n                local_fitness = func(local_position)\n                self.budget -= 1\n                if local_fitness < global_best_fitness:\n                    global_best_fitness = local_fitness\n                    global_best_position = local_position.copy()\n\n            adaptive_step_size = min(adaptive_step_size * 1.05, 1.0) # increase step size slowly\n\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveVelocitySearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}}
{"id": "083d0c50-785e-4c1e-9ffb-e977d526f766", "fitness": -Infinity, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with a dynamically adjusted population size and mutation strategy based on success rate.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9):\n        \"\"\"\n        Initialize the Adaptive Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The initial population size. If None, it's set to 10*dim.\n            F (float, optional): The initial mutation factor.\n            CR (float, optional): The initial crossover rate.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history_F = []\n        self.success_history_CR = []\n        self.archive = []\n        self.archive_size = int(self.pop_size * 0.2)\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, pop, F):\n        \"\"\"Perform differential mutation.\"\"\"\n        \n        idxs = np.random.randint(0, len(pop), size=(len(pop), 3))\n        \n        \n        v = pop[idxs[:, 0]] + F * (pop[idxs[:, 1]] - pop[idxs[:, 2]])\n        return v\n\n    def crossover(self, pop, mutated, CR):\n        \"\"\"Perform binomial crossover.\"\"\"\n        rand_matrix = np.random.rand(*pop.shape)\n        cross_mask = rand_matrix < CR\n        # Ensure at least one component is crossed over\n        for i in range(len(pop)):\n            j = np.random.randint(self.dim)\n            cross_mask[i, j] = True\n        u = np.where(cross_mask, mutated, pop)\n        return u\n\n    def select(self, func, u):\n        \"\"\"Perform selection based on fitness.\"\"\"\n        fitness_u = np.array([func(x) for x in u])\n        self.eval_count += len(u)\n        \n        improvements = fitness_u < self.fitness\n        \n        successful_F = self.F * np.ones(np.sum(improvements))\n        successful_CR = self.CR * np.ones(np.sum(improvements))\n        \n        self.success_history_F.extend(successful_F)\n        self.success_history_CR.extend(successful_CR)\n        \n        self.pop = np.where(improvements[:, None], u, self.pop)\n        self.fitness = np.where(improvements, fitness_u, self.fitness)\n        \n        for i in np.where(improvements)[0]:\n            self.archive.append(self.pop[i].copy())\n            if len(self.archive) > self.archive_size:\n                self.archive.pop(0)\n        \n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n    def adapt_parameters(self):\n        \"\"\"Adapt F and CR based on success history.\"\"\"\n        if self.success_history_F:\n            self.F = np.median(self.success_history_F)\n            self.CR = np.median(self.success_history_CR)\n            self.success_history_F = []\n            self.success_history_CR = []\n        else:\n            self.F = 0.5  # Revert to default if no success\n            self.CR = 0.9\n\n    def adjust_population_size(self):\n        \"\"\"Dynamically adjust population size based on stagnation.\"\"\"\n        if len(self.archive) == self.archive_size:\n            self.pop_size = int(self.pop_size * 1.1)\n            self.pop_size = min(self.pop_size, 20 * self.dim)  # Limit max population size\n            \n            new_individuals = []\n            for _ in range(self.pop_size - len(self.pop)):\n                idx1 = np.random.randint(0, len(self.pop))\n                idx2 = np.random.randint(0, len(self.archive))\n                new_ind = 0.5 * (self.pop[idx1] + self.archive[idx2])\n                new_individuals.append(new_ind)\n                \n            self.pop = np.vstack((self.pop, np.array(new_individuals)))\n            \n        elif len(self.archive) < self.archive_size * 0.2:\n            self.pop_size = int(self.pop_size * 0.9)\n            self.pop_size = max(self.pop_size, 4 * self.dim)\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Adaptive Differential Evolution.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutated = self.mutate(self.pop, self.F)\n            u = self.crossover(self.pop, mutated, self.CR)\n            \n            # Clip values to respect bounds\n            u = np.clip(u, func.bounds.lb, func.bounds.ub)\n            \n            self.select(func, u)\n            self.adapt_parameters()\n            self.adjust_population_size()\n            \n            if self.pop_size != len(self.pop):\n                self.pop = self.pop[:self.pop_size]\n                self.fitness = self.fitness[:self.pop_size]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "An exception occurred: operands could not be broadcast together with shapes (22,) (20,) .", "error": "", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "1117a898-8a0e-4324-a018-e642a767e37c", "fitness": 0.40204580466936796, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Archive and stochastic ranking for constraint handling.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=100, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = F  # Mutation factor\n        self.CR = CR # Crossover rate\n        self.archive = []\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size  # Decrement budget\n\n        for generation in range(self.budget // self.pop_size):\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size + len(self.archive), 3, replace=False)\n                if indices[0] < self.pop_size:\n                    a = self.population[indices[0]]\n                else:\n                    a = self.archive[indices[0] - self.pop_size]\n                if indices[1] < self.pop_size:\n                    b = self.population[indices[1]]\n                else:\n                    b = self.archive[indices[1] - self.pop_size]\n                if indices[2] < self.pop_size:\n                    c = self.population[indices[2]]\n                else:\n                    c = self.archive[indices[2] - self.pop_size]\n\n                mutant = self.population[i] + self.F * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1  # Decrement budget\n                if f_trial < fitness[i]:\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    self.population[i] = trial\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n        \n        # Final evaluation in case budget remains\n        if self.budget > 0:\n            indices = np.random.choice(self.pop_size, self.budget, replace=True)\n            for i in indices:\n                f = func(self.population[i])\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = self.population[i]\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.402 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.15405017767404827, 0.26734195911488223, 0.3745441578476072, 0.5235362053831514, 0.3158880893203747, 0.4287805799289167, 0.29115020007291303, 0.337183004847843, 0.3071849536388237, 0.18670720500187943, 0.559182527756896, 0.9988224660473661, 0.34406864558333405, 0.3046230570320314, 0.7546245376448848, 0.39178865313563715, 0.3122147709773524, 0.5204918248369861, 0.18407628349118954, 0.4846567940512433]}}
{"id": "d56a74de-00d6-4a05-9b08-dd65fb513bbe", "fitness": 0.4192955829181285, "name": "AdaptiveDE", "description": "An adaptive differential evolution strategy that dynamically adjusts its parameters based on the success rate of generating better solutions.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial scaling factor\n        self.CR = CR  # Initial crossover rate\n        self.F_memory = [self.F] * 10  # Memory for past F values\n        self.CR_memory = [self.CR] * 10 # Memory for past CR values\n        self.memory_index = 0\n\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Update budget after initial population evaluation\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                mutant = population[i] + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1 # Update budget\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if self.budget <= 0:\n                   return self.f_opt, self.x_opt    \n\n\n            # Adaptive Parameter Control (adjust F and CR based on success rate)\n            successful_indices = np.where(fitness < np.mean(fitness))[0]\n            if len(successful_indices) > 0:\n                self.F_memory[self.memory_index] = np.mean(np.abs(np.random.normal(self.F, 0.1, len(successful_indices))))\n                self.CR_memory[self.memory_index] = np.mean(np.random.normal(self.CR, 0.1, len(successful_indices)))\n            else:\n                self.F_memory[self.memory_index] = self.F\n                self.CR_memory[self.memory_index] = self.CR\n            \n            self.F = np.clip(np.mean(self.F_memory), 0.1, 1.0) # ensure F is within reasonable bounds\n            self.CR = np.clip(np.mean(self.CR_memory), 0.1, 1.0) # ensure CR is within reasonable bounds\n            self.memory_index = (self.memory_index + 1) % len(self.F_memory) #cycle through the memory\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.419 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1511783125025724, 0.26931684689014357, 0.3863199460117791, 0.575042291932593, 0.31315564550020036, 0.43908685748846743, 0.2986479912855823, 0.34935678141522564, 0.3247473463931714, 0.19506944814888805, 0.6279547598626458, 0.9968089030411825, 0.38175631475223426, 0.3182759639626651, 0.7845337985021505, 0.42486648526493564, 0.34047435982025387, 0.5431532273131885, 0.1769938768679754, 0.48917250140671453]}}
{"id": "4ca9a516-df03-4fbb-bd35-b100e78d6496", "fitness": -Infinity, "name": "GMMAdaptation", "description": "Population-based algorithm using a Gaussian Mixture Model to adapt the search distribution based on promising solutions.", "code": "import numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nclass GMMAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=None, n_components=None):\n        \"\"\"\n        Initialize the Gaussian Mixture Model Adaptation algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The initial population size. If None, it's set to 10*dim.\n            n_components (int, optional): The number of GMM components. If None, it's set to 5.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.n_components = n_components if n_components is not None else 5\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.gmm = None\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def sample_from_gmm(self, func, n_samples):\n        \"\"\"Sample new individuals from the GMM.\"\"\"\n        if self.gmm is None:\n            # If GMM is not fitted yet, sample randomly\n            new_samples = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(n_samples, self.dim))\n        else:\n            new_samples, _ = self.gmm.sample(n_samples)\n            new_samples = np.clip(new_samples, func.bounds.lb, func.bounds.ub)\n        return new_samples\n\n    def fit_gmm(self):\n        \"\"\"Fit a GMM to the top individuals in the population.\"\"\"\n        top_indices = np.argsort(self.fitness)[:self.pop_size // 2]  # Select top 50%\n        top_individuals = self.pop[top_indices]\n        \n        if len(top_individuals) < self.n_components:\n             self.gmm = None # revert back to random sampling because not enough data\n        else:\n            self.gmm = GaussianMixture(n_components=self.n_components, random_state=0, max_iter=100, covariance_type='full').fit(top_individuals)\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using GMM Adaptation.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.fit_gmm()\n            \n            # Generate new samples\n            n_new_samples = min(self.pop_size, self.budget - self.eval_count)\n            new_samples = self.sample_from_gmm(func, n_new_samples)\n\n            # Evaluate new samples\n            fitness_new = np.array([func(x) for x in new_samples])\n            self.eval_count += n_new_samples\n            \n            # Replace worst individuals in the population\n            worst_indices = np.argsort(self.fitness)[-n_new_samples:]\n            self.pop[worst_indices] = new_samples\n            self.fitness[worst_indices] = fitness_new\n            \n            # Update best solution\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.pop[best_index]\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: name 'GaussianMixture' is not defined.", "error": "", "parent_ids": ["083d0c50-785e-4c1e-9ffb-e977d526f766"], "operator": null, "metadata": {}}
{"id": "654be784-3b1b-4bef-91ee-f0ac2453ff8a", "fitness": 0.0, "name": "LevyCauchySearch", "description": "Exploration-Exploitation Balance using Levy Flights and Cauchy Mutations with adaptive step size control.", "code": "import numpy as np\n\nclass LevyCauchySearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, levy_exponent=1.5, cauchy_scale=0.1, adaptive_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.levy_exponent = levy_exponent\n        self.cauchy_scale = cauchy_scale\n        self.adaptive_rate = adaptive_rate\n\n    def levy_flight(self, size):\n        # Generate Levy flights\n        u = np.random.randn(size)\n        v = np.random.randn(size)\n        step = u / np.power(np.abs(v), (1.0 / self.levy_exponent))\n        return step\n\n    def cauchy_mutation(self, size):\n        # Generate Cauchy mutations\n        return self.cauchy_scale * np.random.standard_cauchy(size=size)\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index].copy()\n\n        adaptive_step_size = 1.0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Exploration using Levy Flights\n                levy_steps = self.levy_flight(self.dim)\n                new_position_levy = population[i] + adaptive_step_size * levy_steps\n                new_position_levy = np.clip(new_position_levy, func.bounds.lb, func.bounds.ub)\n\n                # Exploitation using Cauchy Mutation around the best solution\n                cauchy_steps = self.cauchy_mutation(self.dim)\n                new_position_cauchy = global_best_position + adaptive_step_size * cauchy_steps\n                new_position_cauchy = np.clip(new_position_cauchy, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate both new positions, and choose the better one\n                fitness_levy = func(new_position_levy)\n                self.budget -= 1\n                fitness_cauchy = func(new_position_cauchy)\n                self.budget -= 1\n\n                if fitness_levy < fitness_cauchy:\n                    new_fitness = fitness_levy\n                    new_position = new_position_levy.copy()\n                else:\n                    new_fitness = fitness_cauchy\n                    new_position = new_position_cauchy.copy()\n\n                # Update the population and global best if better\n                if new_fitness < fitness[i]:\n                    population[i] = new_position.copy()\n                    fitness[i] = new_fitness\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n            # Adaptive step size\n            adaptive_step_size *= self.adaptive_rate\n            adaptive_step_size = max(adaptive_step_size, 0.01)  # Minimum step size\n\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm LevyCauchySearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["78cd7fda-1767-4676-a713-60e51177b691"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "66d9c481-6a9f-43eb-879f-db4dd03059be", "fitness": 0.0, "name": "RepulsiveArchiveSearch", "description": "Population-based algorithm utilizing a repulsive force among particles to encourage exploration and a shrinking archive to guide convergence.", "code": "import numpy as np\n\nclass RepulsiveArchiveSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10, repulsion_factor=0.1, convergence_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.repulsion_factor = repulsion_factor\n        self.convergence_factor = convergence_factor\n        self.archive = []\n        self.archive_fitness = []\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Repulsion from other particles\n                repulsion = np.zeros(self.dim)\n                for j in range(self.pop_size):\n                    if i != j:\n                        direction = population[i] - population[j]\n                        distance = np.linalg.norm(direction)\n                        if distance > 0:\n                            repulsion += direction / (distance + 1e-8)  # Avoid division by zero\n\n                # Convergence towards the global best\n                convergence = self.convergence_factor * (global_best_position - population[i])\n\n                # Movement with repulsion and convergence\n                new_position = population[i] + self.repulsion_factor * repulsion + convergence\n\n                # Boundary Handling\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness of new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n\n            # Archive update\n            if len(self.archive) < self.archive_size:\n                self.archive.append(global_best_position.copy())\n                self.archive_fitness.append(global_best_fitness)\n            else:\n                max_archive_fitness_index = np.argmax(self.archive_fitness)\n                if global_best_fitness < self.archive_fitness[max_archive_fitness_index]:\n                    self.archive[max_archive_fitness_index] = global_best_position.copy()\n                    self.archive_fitness[max_archive_fitness_index] = global_best_fitness\n\n            # Shrink archive: remove the worst element of the archive\n            if len(self.archive) > 0:\n                worst_archive_index = np.argmax(self.archive_fitness)\n                if len(self.archive) > min(self.archive_size, self.budget // self.pop_size):\n                    del self.archive[worst_archive_index]\n                    del self.archive_fitness[worst_archive_index]\n\n            # Intensify search around best archive member\n            if len(self.archive) > 0:\n                best_archive_index = np.argmin(self.archive_fitness)\n                archive_position = self.archive[best_archive_index]\n                for _ in range(min(5, self.budget)):\n                    perturbation = np.random.normal(0, 0.01, self.dim)\n                    local_position = archive_position + perturbation\n                    local_position = np.clip(local_position, func.bounds.lb, func.bounds.ub)\n                    local_fitness = func(local_position)\n                    self.budget -= 1\n\n                    if local_fitness < global_best_fitness:\n                        global_best_fitness = local_fitness\n                        global_best_position = local_position.copy()\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm RepulsiveArchiveSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["78cd7fda-1767-4676-a713-60e51177b691"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "288635fe-1571-489b-9340-22b56dd24984", "fitness": -Infinity, "name": "SimplexSearch", "description": "An adaptive population-based algorithm that utilizes a Nelder-Mead simplex to explore the search space around promising solutions, adapting the simplex size based on function evaluation outcomes.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SimplexSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_simplex_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 5 * dim\n        self.initial_simplex_size = initial_simplex_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.simplex_history = []\n        self.bounds = None\n\n    def initialize_population(self, func):\n        self.bounds = func.bounds\n        self.pop = np.random.uniform(self.bounds.lb, self.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def explore_simplex(self, func, x0):\n        \"\"\"\n        Explores the search space around x0 using a Nelder-Mead simplex.\n        \"\"\"\n        initial_simplex = np.random.uniform(x0 - self.initial_simplex_size, x0 + self.initial_simplex_size, size=(self.dim + 1, self.dim))\n\n        # Ensure the simplex vertices are within the bounds\n        initial_simplex = np.clip(initial_simplex, self.bounds.lb, self.bounds.ub)\n        \n        # Initial simplex must contain dim+1 points\n        if initial_simplex.shape != (self.dim + 1, self.dim):\n            initial_simplex = np.random.uniform(self.bounds.lb, self.bounds.ub, size=(self.dim + 1, self.dim))\n            initial_simplex = np.clip(initial_simplex, self.bounds.lb, self.bounds.ub)\n            \n\n        res = minimize(func, x0, method='Nelder-Mead', options={'maxfev': self.budget - self.eval_count},\n                       bounds=func.bounds)\n        \n        self.eval_count += res.nfev\n        \n        return res.fun, res.x\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            # Select the best individual as the starting point for simplex search\n            best_index = np.argmin(self.fitness)\n            x0 = self.pop[best_index].copy()\n            \n            # Explore around the best individual\n            f_simplex, x_simplex = self.explore_simplex(func, x0)\n\n            # Update the population and fitness if simplex search finds a better solution\n            if f_simplex < self.f_opt:\n                self.f_opt = f_simplex\n                self.x_opt = x_simplex\n                \n                # Replace a random individual in the population with the new best\n                replace_index = np.random.randint(self.pop_size)\n                self.pop[replace_index] = x_simplex\n                self.fitness[replace_index] = f_simplex\n            else:\n                # If simplex search did not yield a better solution, explore a random individual to increase diversity.\n                random_index = np.random.randint(self.pop_size)\n                x0_random = self.pop[random_index].copy()\n                f_simplex_random, x_simplex_random = self.explore_simplex(func, x0_random)\n                if f_simplex_random < self.fitness[random_index]:\n                    self.pop[random_index] = x_simplex_random\n                    self.fitness[random_index] = f_simplex_random\n\n            # Adjust simplex size based on success\n            if f_simplex < self.fitness[best_index]:\n                self.initial_simplex_size *= 1.1  # Increase simplex size if successful\n            else:\n                self.initial_simplex_size *= 0.9  # Decrease simplex size if unsuccessful\n            \n            self.initial_simplex_size = np.clip(self.initial_simplex_size, 0.0001, 1.0)  # Keep simplex size within reasonable bounds\n\n\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.pop[best_index]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["083d0c50-785e-4c1e-9ffb-e977d526f766"], "operator": null, "metadata": {}}
{"id": "a3d1da49-8a11-42d8-a9c9-ad2d59c37a95", "fitness": -Infinity, "name": "CMAES", "description": "Covariance Matrix Adaptation Evolution Strategy with mirrored sampling and active covariance update for improved exploration and exploitation.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.3, cs=0.8, damps=None, c_cov_mu=0.1, c_cov_one=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.cs = cs\n        if damps is None:\n            self.damps = 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.cs\n        else:\n            self.damps = damps\n        self.c_cov_mu = c_cov_mu\n        self.c_cov_one = c_cov_one\n        self.c_cov_mu = min(1, self.c_cov_mu * (self.pop_size / 4))\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        B = None\n        D = None\n\n        while self.budget > 0:\n            # Generate and evaluate lambda offspring\n            z = np.random.randn(self.dim, self.pop_size)\n            if B is None or D is None:\n                C = self.C\n            else:\n                C = B @ np.diag(D**2) @ B.T\n\n            try:\n                samples = self.m[:, np.newaxis] + self.sigma * np.sqrt(C) @ z\n            except np.linalg.LinAlgError:\n                # Handle singular matrix\n                samples = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim, self.pop_size))\n\n            samples = np.clip(samples, func.bounds.lb, func.bounds.ub)\n\n            fitness = np.array([func(x) for x in samples.T])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = samples[:, np.argmin(fitness)]\n\n            # Select and recombine\n            idx = np.argsort(fitness)\n            x_mu = samples[:, idx[:self.mu]]\n            self.m = np.sum(x_mu * self.weights, axis=1)\n\n            # Update evolution path\n            z_mu = z[:, idx[:self.mu]] @ self.weights\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * (B @ z_mu)\n            \n            norm_ps = np.linalg.norm(self.ps)\n            c_sigma = (self.cs * (2 - self.cs)) * ((norm_ps**2 / self.dim) - 1)\n            self.sigma *= np.exp(c_sigma / 2)\n\n            self.pc = (1 - self.c_cov_one) * self.pc + np.sqrt(self.c_cov_one * (2 - self.c_cov_one)) * (self.m - (self.m[:, np.newaxis] - self.sigma * B @ z_mu).mean(axis=1))\n\n            # Update covariance matrix\n            self.C = (1 - self.c_cov_mu - self.c_cov_one) * self.C + \\\n                       self.c_cov_one * np.outer(self.pc, self.pc) + \\\n                       self.c_cov_mu * (B @ z[:, idx[:self.mu]] @ np.diag(self.weights) @ z[:, idx[:self.mu]].T @ B.T)\n\n            try:\n                D, B = np.linalg.eigh(self.C)\n            except np.linalg.LinAlgError:\n                #Handle singular matrix by resetting it\n                self.C = np.eye(self.dim)\n                B = None\n                D = None\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["1117a898-8a0e-4324-a018-e642a767e37c"], "operator": null, "metadata": {}}
{"id": "cf4519cd-b620-410d-93f4-078a08aaa11c", "fitness": -Infinity, "name": "AdaptiveCMAES", "description": "Covariance matrix adaptation evolution strategy (CMA-ES) with adaptive population size and dynamic bounds handling.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.pop_size = 4 + int(3 * np.log(self.dim))  # Adaptive population size\n        self.mu = self.pop_size // 2  # Number of parents\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2.0)**2 + self.mueff))\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize variables\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n        sigma = self.initial_sigma\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        C = np.eye(self.dim)\n        B = np.eye(self.dim)  # eigenvectors of C\n        D = np.ones(self.dim)  # eigenvalues of C\n\n        while self.budget > 0:\n            # Generate and evaluate offspring\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            y = B.dot(D * z.T).T\n            x = mean + sigma * y\n            \n            # Dynamic bounds handling\n            out_of_bounds = np.logical_or(x < func.bounds.lb, x > func.bounds.ub)\n            x[out_of_bounds] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=x[out_of_bounds].shape)\n            \n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            if self.budget <= 0:\n                break\n\n            # Sort by fitness\n            indices = np.argsort(fitness)\n            fitness = fitness[indices]\n            x = x[indices]\n\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            mean_old = mean.copy()\n            mean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n            \n            # Update evolution path\n            y_mean = (mean - mean_old) / sigma\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * B.dot(D**-1 * (mean - mean_old) / sigma)\n            hsig = (np.sum(ps**2) / (1 - (1 - self.cs)**(2 * (self.budget // self.pop_size))) / self.dim) < (2 + 4 / (self.dim + 1))\n            pc = (1 - self.cc) * pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * y_mean\n\n            # Update covariance matrix\n            C = (1 - self.c1 - self.cmu) * C + self.c1 * (pc[:, None] @ pc[None, :]) + self.cmu * np.sum(self.weights[:, None, None] * y[:self.mu, :, None] * y[:self.mu, None, :], axis=0)\n\n            # Adapt step size\n            sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n\n            # Eigen-decomposition of C (every lambda/((c1+cmu)/dim/10) evaluations)\n            if self.budget % (self.pop_size * int(1 / (self.c1 + self.cmu) / self.dim / 10)) < self.pop_size:\n                C = np.triu(C) + np.triu(C, 1).T\n                D, B = np.linalg.eigh(C)\n                D = np.sqrt(D)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,) (2,6) .", "error": "", "parent_ids": ["d56a74de-00d6-4a05-9b08-dd65fb513bbe"], "operator": null, "metadata": {}}
{"id": "b48aaa1c-966f-47ba-9879-381174897979", "fitness": -Infinity, "name": "CMAES", "description": "Covariance matrix adaptation evolution strategy with adaptive population sizing and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, mu_factor=0.25, cs=0.08, damps=None, ccov1=None, ccovmu=None, restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.mu_factor = mu_factor\n        self.cs = cs\n\n        self.restarts = restarts\n        self.restart_count = 0\n        self.f_opt = np.Inf\n        self.x_opt = None\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))  # Recommended pop size\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_factor)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n        self.C = np.eye(self.dim)\n        self.invsqrtC = np.eye(self.dim)\n\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        if damps is None:\n            self.damps = 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1))-1) + self.cs\n        else:\n            self.damps = damps\n        \n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = min(1-self.ccov1, 2 * (self.mueff-2+1/self.mueff) / ((self.dim+2)**2 + self.mueff))\n        else:\n            self.ccovmu = ccovmu\n\n    def __call__(self, func):\n\n        while self.budget > 0 and self.restart_count < self.restarts:\n            self.run_cmaes_iteration(func)\n            if self.budget <= 0:\n                return self.f_opt, self.x_opt\n            self.restart_count += 0  # Do not restart\n            if self.restart_count > 0:  # Restart if stuck\n                 # Reset parameters\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.B = np.eye(self.dim)\n                self.D = np.ones(self.dim)\n                self.C = np.eye(self.dim)\n                self.invsqrtC = np.eye(self.dim)\n                self.sigma = 0.5\n\n        return self.f_opt, self.x_opt\n\n    def run_cmaes_iteration(self, func):\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Adapt mean to bounds\n        \n        # Sample population\n        arz = np.random.randn(self.dim, self.pop_size)\n        arx = mean[:, np.newaxis] + self.sigma * (self.B @ (self.D[:, np.newaxis] * arz))\n        arx = np.clip(arx, func.bounds.lb, func.bounds.ub)\n        \n        # Evaluate population\n        fitness = np.array([func(x) for x in arx.T])\n        self.budget -= self.pop_size\n\n        # Sort by fitness\n        aridx = np.argsort(fitness)\n        arfitness = fitness[aridx]\n        arx = arx[:, aridx]\n\n        # Update best solution\n        if arfitness[0] < self.f_opt:\n            self.f_opt = arfitness[0]\n            self.x_opt = arx[:, 0]\n\n        # Update distribution parameters\n        xmean = np.sum(arx[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n        \n        zmean = np.sum(arz[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n\n        self.ps = (1-self.cs) * self.ps + np.sqrt(self.cs*(2-self.cs)*self.mueff) * self.invsqrtC @ zmean\n        hsig = (np.linalg.norm(self.ps)/np.sqrt(1-(1-self.cs)**(2*self.budget/self.pop_size))/self.chiN < 1.4 + 2/(self.dim+1))\n        self.pc = (1-self.ccov1) * self.pc + hsig * np.sqrt(self.ccov1*(2-self.ccov1)*self.mueff) * (xmean - mean) / self.sigma\n\n        artmp = (1/self.sigma) * (arx[:, :self.mu] - mean[:, np.newaxis])\n        self.C = (1-self.ccov1-self.ccovmu+self.ccov1*self.ccovmu*np.sum(self.weights) ) * self.C \\\n            + self.ccov1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) \\\n            + self.ccovmu * artmp @ np.diag(self.weights) @ artmp.T\n\n        self.sigma *= np.exp((self.cs/self.damps)*(np.linalg.norm(self.ps)/self.chiN - 1))\n\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        self.D, self.B = np.linalg.eig(self.C)\n        self.D = np.sqrt(self.D)\n        self.invsqrtC = self.B @ np.diag(self.D**-1) @ self.B.T", "configspace": "", "generation": 1, "feedback": "An exception occurred: operands could not be broadcast together with shapes (2,6) (2,) (2,) .", "error": "", "parent_ids": ["d56a74de-00d6-4a05-9b08-dd65fb513bbe"], "operator": null, "metadata": {}}
{"id": "03250e4e-8cfd-4e23-b6f0-2257ad63e8bf", "fitness": 0.1984456967388713, "name": "AdaptiveDESelfPop", "description": "An adaptive Differential Evolution strategy employing a self-adaptive population size and a tournament-based selection to improve exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDESelfPop:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F=0.5, CR=0.9, min_pop_size=10, max_pop_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.initial_pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.F = F  # Initial scaling factor\n        self.CR = CR  # Initial crossover rate\n        self.F_memory = [self.F] * 10  # Memory for past F values\n        self.CR_memory = [self.CR] * 10 # Memory for past CR values\n        self.memory_index = 0\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Update budget after initial population evaluation\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Population size adjustment\n            if np.random.rand() < 0.1:  # Adjust population size probabilistically\n                success_rate = np.sum(fitness < np.mean(fitness)) / self.pop_size if self.pop_size > 0 else 0\n                \n                if success_rate > 0.3:  # Dynamic Adjustment based on Success\n                  self.pop_size = min(self.max_pop_size, int(self.pop_size * (1 + success_rate)))\n                elif success_rate < 0.1:\n                  self.pop_size = max(self.min_pop_size, int(self.pop_size * (1 - (0.2 - success_rate))))\n\n                #Resample population if size changes\n                old_pop = population\n                old_fitness = fitness\n\n                self.pop_size = int(self.pop_size)\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                #Retain best solutions from previous pop\n                num_retain = min(self.pop_size, self.initial_pop_size) #retain the first initial_pop_size entries.\n                \n                best_indices_old = np.argsort(old_fitness)[:num_retain] \n                \n                population[:num_retain] = old_pop[best_indices_old]\n                fitness[:num_retain] = old_fitness[best_indices_old]\n\n                best_index = np.argmin(fitness)\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                mutant = population[i] + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Tournament Selection\n                opponent_index = np.random.randint(self.pop_size)\n                f_trial = func(trial)\n                self.budget -= 1 # Update budget\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                elif fitness[opponent_index] < fitness[i]: #Tournament selection: trial competes against a random member\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial\n                \n                if self.budget <= 0:\n                   return self.f_opt, self.x_opt    \n\n            # Adaptive Parameter Control (adjust F and CR based on success rate)\n            successful_indices = np.where(fitness < np.mean(fitness))[0]\n            if len(successful_indices) > 0:\n                self.F_memory[self.memory_index] = np.mean(np.abs(np.random.normal(self.F, 0.1, len(successful_indices))))\n                self.CR_memory[self.memory_index] = np.mean(np.random.normal(self.CR, 0.1, len(successful_indices)))\n            else:\n                self.F_memory[self.memory_index] = self.F\n                self.CR_memory[self.memory_index] = self.CR\n            \n            self.F = np.clip(np.mean(self.F_memory), 0.1, 1.0) # ensure F is within reasonable bounds\n            self.CR = np.clip(np.mean(self.CR_memory), 0.1, 1.0) # ensure CR is within reasonable bounds\n            self.memory_index = (self.memory_index + 1) % len(self.F_memory) #cycle through the memory\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDESelfPop scored 0.198 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d56a74de-00d6-4a05-9b08-dd65fb513bbe"], "operator": null, "metadata": {"aucs": [0.12030115281981557, 0.19157532811560019, 0.28056753898820075, 0.22960921398730838, 0.2339974177170031, 0.27522237428532215, 0.2562925479977204, 0]}}
{"id": "79dea687-752a-4a22-a5ca-ad70d455d5e4", "fitness": 0.2937815971792407, "name": "GaussianExplorationSearch", "description": "Population-based algorithm with a Gaussian mutation inspired exploration strategy and adaptive parameter control based on fitness improvement.", "code": "import numpy as np\n\nclass GaussianExplorationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, mutation_rate=0.1, exploration_intensity=0.5, adaptive_factor=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.exploration_intensity = exploration_intensity\n        self.adaptive_factor = adaptive_factor\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index].copy()\n\n        previous_best_fitness = global_best_fitness\n\n        while self.budget > 0:\n            new_population = population.copy()\n            for i in range(self.pop_size):\n                if np.random.rand() < self.mutation_rate:\n                    # Gaussian Mutation with adaptive step size\n                    mutation = np.random.normal(0, self.exploration_intensity, self.dim)\n                    new_position = population[i] + mutation\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                else:\n                    # Random Exploration\n                    new_position = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    new_population[i] = new_position.copy()\n\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n            population = new_population.copy()\n\n            # Adaptive Parameter Control: Adjust exploration intensity based on improvement\n            if global_best_fitness < previous_best_fitness:\n                self.exploration_intensity *= (1 + self.adaptive_factor)\n                self.adaptive_factor *= 0.95  # Reduce the adaptive factor over time\n            else:\n                self.exploration_intensity *= (1 - self.adaptive_factor)\n            \n            self.exploration_intensity = np.clip(self.exploration_intensity, 0.01, 1.0)  # Keep intensity within bounds\n            previous_best_fitness = global_best_fitness\n            self.adaptive_factor = np.clip(self.adaptive_factor, 0.01, 0.1)\n           \n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm GaussianExplorationSearch scored 0.294 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["78cd7fda-1767-4676-a713-60e51177b691"], "operator": null, "metadata": {"aucs": [0.13345975771370444, 0.21956143274331763, 0.2763542791962339, 0.22137562312255088, 0.2151028001167623, 0.23986812736549223, 0.24713296203500146, 0.2247034921467258, 0.2025332413508496, 0.16082554993303566, 0.24335774744054106, 0.9981570844916889, 0.2955815177006996, 0.2130084230652466, 0.5561197158516387, 0.277337553419317, 0.24353290505015657, 0.25757055803884354, 0.17341642352727105, 0.4766327492757373]}}
{"id": "10dfb06b-deba-498f-a4e1-5e98a0172193", "fitness": 0.6313705812450345, "name": "DistanceAdaptiveDE", "description": "Self-Adaptive Differential Evolution with a Distance-Based Mutation strategy that encourages exploration in sparsely populated regions.", "code": "import numpy as np\n\nclass DistanceAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, archive_size_factor=0.2):\n        \"\"\"\n        Initialize the Distance Adaptive Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The initial population size. If None, it's set to 10*dim.\n            F (float, optional): The initial mutation factor.\n            CR (float, optional): The initial crossover rate.\n            archive_size_factor (float, optional): The size of the archive relative to the population size.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history_F = []\n        self.success_history_CR = []\n        self.archive = []\n        self.archive_size = int(self.pop_size * archive_size_factor)\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, pop, F, archive):\n        \"\"\"Perform distance-based differential mutation.\"\"\"\n        mutated = np.zeros_like(pop)\n        for i in range(len(pop)):\n            # Select three distinct indices (a, b, c)\n            idxs = np.random.choice(len(pop), 2, replace=False)\n            a, b = idxs[0], idxs[1]\n\n            # Calculate distances to other individuals\n            distances = np.linalg.norm(pop - pop[i], axis=1)\n            \n            # Exclude current individual and selected individuals\n            distances[i] = np.inf\n            distances[a] = np.inf\n            distances[b] = np.inf\n           \n            #Select the most distant individual\n            if len(archive) > 0:\n                archive_distances = np.linalg.norm(np.array(archive) - pop[i], axis=1)\n                c_idx = np.argmax(archive_distances)\n                c = archive[c_idx]\n                mutated[i] = pop[a] + F * (pop[b] - c)\n            else:\n                c_idx = np.argmin(distances)\n                c = pop[c_idx]\n                mutated[i] = pop[a] + F * (pop[b] - c)\n\n        return mutated\n\n    def crossover(self, pop, mutated, CR):\n        \"\"\"Perform binomial crossover.\"\"\"\n        rand_matrix = np.random.rand(*pop.shape)\n        cross_mask = rand_matrix < CR\n        # Ensure at least one component is crossed over\n        for i in range(len(pop)):\n            j = np.random.randint(self.dim)\n            cross_mask[i, j] = True\n        u = np.where(cross_mask, mutated, pop)\n        return u\n\n    def select(self, func, u):\n        \"\"\"Perform selection based on fitness.\"\"\"\n        fitness_u = np.array([func(x) for x in u])\n        self.eval_count += len(u)\n\n        improvements = fitness_u < self.fitness\n\n        successful_F = self.F * np.ones(np.sum(improvements))\n        successful_CR = self.CR * np.ones(np.sum(improvements))\n\n        self.success_history_F.extend(successful_F)\n        self.success_history_CR.extend(successful_CR)\n\n        self.pop = np.where(improvements[:, None], u, self.pop)\n        self.fitness = np.where(improvements, fitness_u, self.fitness)\n\n        for i in np.where(improvements)[0]:\n            self.archive.append(self.pop[i].copy())\n            if len(self.archive) > self.archive_size:\n                self.archive.pop(0)\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n    def adapt_parameters(self):\n        \"\"\"Adapt F and CR based on success history.\"\"\"\n        if self.success_history_F:\n            self.F = np.median(self.success_history_F)\n            self.CR = np.median(self.success_history_CR)\n            self.success_history_F = []\n            self.success_history_CR = []\n        else:\n            self.F = 0.5  # Revert to default if no success\n            self.CR = 0.9\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Adaptive Differential Evolution.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutated = self.mutate(self.pop, self.F, self.archive)\n            u = self.crossover(self.pop, mutated, self.CR)\n\n            # Clip values to respect bounds\n            u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n            self.select(func, u)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm DistanceAdaptiveDE scored 0.631 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["083d0c50-785e-4c1e-9ffb-e977d526f766"], "operator": null, "metadata": {"aucs": [0.31836186297334423, 0.6341888862408698, 0.3649056569377681, 0.8357357120095751, 0.6606093901513063, 0.7383981629418097, 0.538916227092882, 0.5962732925167961, 0.642761735091047, 0.6057890608432603, 0.833193864816512, 0.9898414649470727, 0.47387235400878736, 0.6536901126089263, 0.8892926391268449, 0.7388705441668544, 0.5248296422621234, 0.8022267740363793, 0.2733134169431135, 0.5123408251854171]}}
{"id": "29154d16-1532-45b0-ad94-b4ab40c99abe", "fitness": 0.0, "name": "SelfOrganizingScoutBee", "description": "A self-organizing scout bee algorithm with dynamic population adjustment and Lvy flight exploration.", "code": "import numpy as np\n\nclass SelfOrganizingScoutBee:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=20, scout_bees=5, elite_bees=2, levy_exponent=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.scout_bees = scout_bees\n        self.elite_bees = elite_bees\n        self.levy_exponent = levy_exponent\n\n        self.population = None\n        self.fitness = None\n        self.best_index = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def levy_flight(self, step_size=0.1):\n        \"\"\"Generate a Lvy flight step.\"\"\"\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) /\n                 (np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * (2 ** ((self.levy_exponent - 1) / 2)))) ** (1 / self.levy_exponent)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / (abs(v) ** (1 / self.levy_exponent))\n        return step_size * step\n\n    def initialize_population(self, func):\n         self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n         self.fitness = np.array([func(x) for x in self.population])\n         self.budget -= self.pop_size\n\n         self.best_index = np.argmin(self.fitness)\n         self.global_best_position = self.population[self.best_index].copy()\n         self.global_best_fitness = self.fitness[self.best_index].copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            # Employed Bees Phase (exploitation)\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                neighbor_index = np.random.choice(list(range(0, i)) + list(range(i + 1, self.pop_size)))\n                phi = np.random.uniform(-1, 1, size=self.dim)\n                new_position = self.population[i] + phi * (self.population[i] - self.population[neighbor_index])\n\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.fitness[i]:\n                    self.population[i] = new_position.copy()\n                    self.fitness[i] = new_fitness\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n            # Onlooker Bees Phase (selection and intensification)\n            probabilities = (self.fitness.max() - self.fitness) / (self.fitness.max() - self.fitness.min() + 1e-8) # Avoid division by zero\n            probabilities /= probabilities.sum()\n            \n            for _ in range(self.pop_size): #Each onlooker selects a bee\n              if self.budget <= 0:\n                break\n              selected_bee_index = np.random.choice(self.pop_size, p=probabilities)\n              \n              phi = np.random.uniform(-1, 1, size=self.dim)\n              neighbor_index = np.random.choice(list(range(0, selected_bee_index)) + list(range(selected_bee_index + 1, self.pop_size)))\n              new_position = self.population[selected_bee_index] + phi * (self.population[selected_bee_index] - self.population[neighbor_index])\n              new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n              new_fitness = func(new_position)\n              self.budget -= 1\n\n              if new_fitness < self.fitness[selected_bee_index]:\n                  self.population[selected_bee_index] = new_position.copy()\n                  self.fitness[selected_bee_index] = new_fitness\n                  if new_fitness < self.global_best_fitness:\n                      self.global_best_fitness = new_fitness\n                      self.global_best_position = new_position.copy()\n\n\n            # Scout Bees Phase (diversification with Levy flights)\n            for _ in range(min(self.scout_bees, self.budget)):\n                worst_index = np.argmax(self.fitness)\n                levy_step = self.levy_flight()\n                new_position = self.global_best_position + levy_step\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.fitness[worst_index]:\n                    self.population[worst_index] = new_position.copy()\n                    self.fitness[worst_index] = new_fitness\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n            \n            #Population adjustment\n            if np.random.rand() < 0.1 and self.pop_size < 40:\n              self.pop_size += 1\n              new_bee = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(1, self.dim))\n              new_fitness = func(new_bee[0])\n              self.budget -=1\n              self.population = np.vstack([self.population, new_bee])\n              self.fitness = np.append(self.fitness, new_fitness)\n              if new_fitness < self.global_best_fitness:\n                self.global_best_fitness = new_fitness\n                self.global_best_position = new_bee[0].copy()\n            elif np.random.rand() < 0.05 and self.pop_size > 10:\n                worst_index = np.argmax(self.fitness)\n                self.population = np.delete(self.population, worst_index, axis=0)\n                self.fitness = np.delete(self.fitness, worst_index)\n                self.pop_size -= 1\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm SelfOrganizingScoutBee scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["78cd7fda-1767-4676-a713-60e51177b691"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "fcca0778-ecd7-476d-aef2-ff7d8b32938d", "fitness": 0.0, "name": "CMAES_AdaptivePop", "description": "Covariance Matrix Adaptation Evolution Strategy with adaptive population sizing and mirrored sampling.", "code": "import numpy as np\n\nclass CMAES_AdaptivePop:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, cc=0.3, c_cov_mu=0.2, c_cov_one=0.0):\n        \"\"\"\n        Initialize the CMA-ES algorithm with adaptive population sizing and mirrored sampling.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The initial population size. If None, it's set to 4 + int(3 * np.log(dim)).\n            sigma (float): Initial step-size.\n            cs (float): Cumulation factor for step-size.\n            damps (float): Damping for step-size.\n            cc (float): Cumulation factor for mean.\n            c_cov_mu (float): Learning rate for rank-mu update of covariance matrix.\n            c_cov_one (float): Learning rate for rank-one update of covariance matrix.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps\n        self.cc = cc\n        self.c_cov_mu = c_cov_mu\n        self.c_cov_one = c_cov_one\n        self.m = None  # Mean\n        self.C = None  # Covariance matrix\n        self.pc = None # Evolution path for mean\n        self.ps = None # Evolution path for sigma\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.weights = None\n        self.mu = None\n        self.mirrored_sampling = True\n        self.pop = None\n        self.fitness = None\n        self.archive = []\n\n    def initialize(self, func):\n        \"\"\"Initialize mean, covariance matrix, and other parameters.\"\"\"\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mu - 1)/(self.dim + 1)) - 1) + self.cs\n\n    def sample_population(self):\n        \"\"\"Sample a new population.\"\"\"\n        z = np.random.normal(0, 1, size=(self.pop_size // 2, self.dim))\n        if self.mirrored_sampling and self.pop_size > 1:\n             z = np.vstack([z, -z])\n        elif self.pop_size % 2 == 1:\n            z = np.vstack([z, np.random.normal(0, 1, size=(1, self.dim))])\n\n        C_sqrt = np.linalg.cholesky(self.C)\n        x = self.m + self.sigma * z @ C_sqrt.T\n        return x, z\n\n    def evaluate_population(self, func, x):\n        \"\"\"Evaluate the population and update the best solution.\"\"\"\n        fitness = np.array([func(xi) for xi in x])\n        self.eval_count += len(x)\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = x[np.argmin(fitness)]\n        return fitness\n\n    def update_parameters(self, x, z, fitness):\n        \"\"\"Update mean, covariance matrix, and step-size.\"\"\"\n        idx = np.argsort(fitness)\n        x_sorted = x[idx]\n        z_sorted = z[idx]\n\n        # Mean update\n        delta_m = np.sum(self.weights[:, None] * z_sorted[:self.mu], axis=0)\n        self.m = self.m + self.cc * self.sigma * delta_m\n\n        # Cumulation for covariance matrix\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * delta_m\n        \n        # Covariance matrix update\n        self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc)) * np.linalg.solve(self.C, delta_m)\n        \n        C_temp = (self.c_cov_one * np.outer(self.pc, self.pc) + self.c_cov_mu * np.sum(self.weights[:, None, None] * z_sorted[:self.mu, :, None] * z_sorted[:self.mu, None, :], axis=0))\n        self.C = (1 - self.c_cov_one - self.c_cov_mu) * self.C + C_temp\n        \n        # Step-size update\n        self.sigma = self.sigma * np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n        \n        # Keep C positive definite\n        try:\n            np.linalg.cholesky(self.C)\n        except np.linalg.LinAlgError:\n            self.C = np.eye(self.dim)\n\n    def adjust_population_size(self):\n         \"\"\"Adjust population size based on stagnation.\"\"\"\n         if self.eval_count > self.budget / 2 and self.pop_size > 4 + int(2 * np.log(self.dim)):\n            self.pop_size = max(4 + int(2 * np.log(self.dim)), self.pop_size // 2)\n         elif self.sigma < 1e-6 and self.pop_size < 4 + int(4 * np.log(self.dim)):\n             self.pop_size = min(4 + int(4 * np.log(self.dim)), self.pop_size * 2)\n\n         self.mu = self.pop_size // 2\n         self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n         self.weights = self.weights / np.sum(self.weights)\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using CMA-ES.\"\"\"\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            x, z = self.sample_population()\n            \n            # Clip values to respect bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = self.evaluate_population(func, x)\n            self.update_parameters(x, z, fitness)\n            self.adjust_population_size()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm CMAES_AdaptivePop scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["083d0c50-785e-4c1e-9ffb-e977d526f766"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "ac4c7c59-ec90-475c-968f-a23a1ddb2782", "fitness": -Infinity, "name": "HybridDE_NM", "description": "Hybrid algorithm combining Differential Evolution (DE) for global exploration with a Nelder-Mead Simplex method for local refinement around promising solutions.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_mutation_factor=0.7, de_crossover_rate=0.9, nm_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.nm_iterations = nm_iterations\n\n    def differential_evolution(self, func, population):\n        for i in range(self.pop_size):\n            # Choose three distinct individuals from the population\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n            # Mutation\n            mutant = a + self.de_mutation_factor * (b - c)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            crossover = np.random.rand(self.dim) < self.de_crossover_rate\n            trial = np.where(crossover, mutant, population[i])\n\n            yield trial\n\n    def nelder_mead(self, func, x0, bounds, maxiter):\n        # Wrapper function for bounds\n        def func_wrapper(x):\n            x_clip = np.clip(x, bounds.lb, bounds.ub)\n            return func(x_clip)\n\n        result = minimize(func_wrapper, x0, method='Nelder-Mead', options={'maxiter': maxiter, 'disp': False})\n        return result.fun, result.x\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            # Differential Evolution Step\n            new_population = []\n            for trial in self.differential_evolution(func, population):\n                f = func(trial)\n                self.budget -= 1\n                if f < global_best_fitness:\n                    global_best_fitness = f\n                    global_best_position = trial.copy()\n                new_population.append(trial)\n\n                if self.budget <= 0:\n                  break\n\n            if self.budget <= 0:\n                  break\n\n\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size #Correct the budget consumption after DE\n\n            # Update population based on fitness\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    population[i] = new_population[i]\n                    fitness[i] = new_fitness[i]\n\n            # Local Refinement with Nelder-Mead around best solution\n            best_index = np.argmin(fitness)\n            local_best_fitness, local_best_position = self.nelder_mead(func, population[best_index], func.bounds, self.nm_iterations)\n            self.budget -= self.nm_iterations #Correction\n\n            if local_best_fitness < global_best_fitness:\n                global_best_fitness = local_best_fitness\n                global_best_position = local_best_position.copy()\n\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 2, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["654be784-3b1b-4bef-91ee-f0ac2453ff8a"], "operator": null, "metadata": {}}
{"id": "acb8ee59-2d24-4784-942c-32ae98ec5d62", "fitness": 0.0, "name": "CooperativeSwarm", "description": "Cooperative Swarm with Adaptive Gaussian Perturbation, where multiple swarms explore the landscape collaboratively, adapting their search behavior based on inter-swarm communication and Gaussian perturbations.", "code": "import numpy as np\n\nclass CooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=10, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, perturbation_rate=0.1, adaptive_factor=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.perturbation_rate = perturbation_rate\n        self.adaptive_factor = adaptive_factor\n\n        self.swarms = []\n        self.best_positions = []\n        self.best_fitnesses = []\n        self.velocities = []\n        self.previous_best_fitnesses = []\n\n    def __call__(self, func):\n        # Initialize swarms\n        for i in range(self.num_swarms):\n            swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n            fitness = np.array([func(x) for x in swarm])\n            self.budget -= self.swarm_size\n\n            best_index = np.argmin(fitness)\n            self.best_positions.append(swarm[best_index].copy())\n            self.best_fitnesses.append(fitness[best_index].copy())\n            self.velocities.append(np.zeros_like(swarm))  # Initialize velocities to zero\n            self.swarms.append(swarm)\n            self.previous_best_fitnesses.append(self.best_fitnesses[-1])  # Initialize previous best fitness\n\n        global_best_swarm_index = np.argmin(self.best_fitnesses)\n        global_best_position = self.best_positions[global_best_swarm_index].copy()\n        global_best_fitness = self.best_fitnesses[global_best_swarm_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.num_swarms):\n                swarm = self.swarms[i]\n                velocities = self.velocities[i]\n\n                for j in range(self.swarm_size):\n                    # Update velocity\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    cognitive_component = self.cognitive_coeff * r1 * (self.best_positions[i] - swarm[j])\n                    social_component = self.social_coeff * r2 * (global_best_position - swarm[j])\n                    velocities[j] = self.inertia * velocities[j] + cognitive_component + social_component\n\n                    # Update position\n                    new_position = swarm[j] + velocities[j]\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                    # Gaussian Perturbation\n                    if np.random.rand() < self.perturbation_rate:\n                        mutation = np.random.normal(0, self.adaptive_factor, self.dim)\n                        new_position = new_position + mutation\n                        new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness = func(new_position)\n                    self.budget -= 1\n\n                    if new_fitness < np.array([func(swarm[j])])[0]:\n                        swarm[j] = new_position.copy()\n                        if new_fitness < self.best_fitnesses[i]:\n                            self.best_fitnesses[i] = new_fitness\n                            self.best_positions[i] = new_position.copy()\n\n                            if new_fitness < global_best_fitness:\n                                global_best_fitness = new_fitness\n                                global_best_position = new_position.copy()\n                                global_best_swarm_index = i\n                self.velocities[i] = velocities\n                self.swarms[i] = swarm\n\n            # Adaptive Parameter Control: Adjust perturbation rate based on global improvement\n            if global_best_fitness < self.previous_best_fitnesses[global_best_swarm_index]:\n                self.adaptive_factor *= (1 + self.adaptive_factor)\n                self.adaptive_factor *= 0.95  # Reduce the adaptive factor over time\n                self.perturbation_rate *= (1 + self.adaptive_factor) # Increase perturbation rate\n            else:\n                self.adaptive_factor *= (1 - self.adaptive_factor)\n                self.perturbation_rate *= (1 - self.adaptive_factor) # Decrease perturbation rate\n            \n            self.adaptive_factor = np.clip(self.adaptive_factor, 0.01, 0.1)  # Keep adaptive factor within bounds\n            self.perturbation_rate = np.clip(self.perturbation_rate, 0.01, 0.5)  # Keep perturbation rate within bounds\n            self.previous_best_fitnesses[global_best_swarm_index] = global_best_fitness\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm CooperativeSwarm scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["79dea687-752a-4a22-a5ca-ad70d455d5e4"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "b0059afd-410f-422f-a02b-3fd7e212abac", "fitness": 0.0, "name": "FitnessDistanceRatioDE", "description": "A Differential Evolution variant with a fitness-distance-ratio based mutation and selection scheme to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass FitnessDistanceRatioDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, local_search_prob=0.1):\n        \"\"\"\n        Initialize the Fitness Distance Ratio Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The initial population size. If None, it's set to 10*dim.\n            F (float, optional): The initial mutation factor.\n            CR (float, optional): The initial crossover rate.\n            local_search_prob (float, optional): Probability of performing local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.F = F\n        self.CR = CR\n        self.local_search_prob = local_search_prob\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, pop, F):\n        \"\"\"Perform fitness-distance-ratio based mutation.\"\"\"\n        mutated = np.zeros_like(pop)\n        for i in range(len(pop)):\n            idxs = np.random.choice(len(pop), 3, replace=False)\n            a, b, c = idxs[0], idxs[1], idxs[2]\n\n            # Calculate fitness distance ratio\n            fitness_diff = np.abs(self.fitness[b] - self.fitness[c])\n            distance = np.linalg.norm(pop[b] - pop[c])\n            \n            #Avoid division by zero\n            if distance == 0:\n                distance = 1e-8\n\n            ratio = fitness_diff / distance\n            \n            mutated[i] = pop[a] + F * ratio * (pop[b] - pop[c])\n        return mutated\n\n    def crossover(self, pop, mutated, CR):\n        \"\"\"Perform binomial crossover.\"\"\"\n        rand_matrix = np.random.rand(*pop.shape)\n        cross_mask = rand_matrix < CR\n        # Ensure at least one component is crossed over\n        for i in range(len(pop)):\n            j = np.random.randint(self.dim)\n            cross_mask[i, j] = True\n        u = np.where(cross_mask, mutated, pop)\n        return u\n\n    def local_search(self, func, x):\n        \"\"\"Perform a simple local search around x.\"\"\"\n        delta = np.random.uniform(-0.1, 0.1, size=self.dim)  # Small perturbation\n        x_new = x + delta\n        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n        f_new = func(x_new)\n        self.eval_count += 1\n        if f_new < self.f_opt:\n            self.f_opt = f_new\n            self.x_opt = x_new\n        return f_new, x_new\n\n    def select(self, func, u):\n        \"\"\"Perform selection based on fitness and local search.\"\"\"\n        fitness_u = np.array([func(x) for x in u])\n        self.eval_count += len(u)\n        \n        for i in range(len(u)):\n            if fitness_u[i] < self.fitness[i]:\n                self.pop[i] = u[i]\n                self.fitness[i] = fitness_u[i]\n                if np.random.rand() < self.local_search_prob:\n                    f_local, x_local = self.local_search(func, self.pop[i])\n                    if f_local < self.fitness[i]:\n                        self.fitness[i] = f_local\n                        self.pop[i] = x_local\n            elif np.random.rand() < self.local_search_prob:  # Local search even if not better than parent\n                f_local, x_local = self.local_search(func, self.pop[i])\n                if f_local < self.fitness[i]:\n                    self.fitness[i] = f_local\n                    self.pop[i] = x_local\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Fitness Distance Ratio Differential Evolution.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutated = self.mutate(self.pop, self.F)\n            u = self.crossover(self.pop, mutated, self.CR)\n\n            # Clip values to respect bounds\n            u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n            self.select(func, u)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm FitnessDistanceRatioDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["10dfb06b-deba-498f-a4e1-5e98a0172193"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "4580d3f7-2472-47b2-9b47-1774b7e6b4de", "fitness": 0.31247408303114577, "name": "SimulatedAnnealingPopulation", "description": "A population-based algorithm with a Simulated Annealing-inspired acceptance criterion to balance exploration and exploitation by accepting worse solutions based on a time-varying temperature.", "code": "import numpy as np\n\nclass SimulatedAnnealingPopulation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_temp=1.0, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index].copy()\n\n        temperature = self.initial_temp\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Generate a new candidate solution by perturbing the current one\n                perturbation = np.random.normal(0, temperature, size=self.dim)\n                new_position = population[i] + perturbation\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                # Simulated Annealing acceptance criterion\n                delta_e = new_fitness - fitness[i]\n                if delta_e < 0:\n                    # Accept the new solution if it's better\n                    population[i] = new_position.copy()\n                    fitness[i] = new_fitness\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                else:\n                    # Accept the new solution with a probability based on temperature\n                    acceptance_probability = np.exp(-delta_e / temperature)\n                    if np.random.rand() < acceptance_probability:\n                        population[i] = new_position.copy()\n                        fitness[i] = new_fitness\n\n                if self.budget <= 0:\n                    break\n\n            # Cool down the temperature\n            temperature *= self.cooling_rate\n            temperature = max(temperature, 0.0001)  # Minimum temperature\n\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm SimulatedAnnealingPopulation scored 0.312 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["654be784-3b1b-4bef-91ee-f0ac2453ff8a"], "operator": null, "metadata": {"aucs": [0.16961620046719106, 0.24848813241731127, 0.2676063234319219, 0.30082396294732094, 0.22399604958719577, 0.2417813620652547, 0.2323195896470477, 0.22001059065155892, 0.2360781300401381, 0.18343775288972264, 0.2929447317559546, 0.9984582626819716, 0.35653671707513523, 0.2619167602463043, 0.5928016218707295, 0.2702839704120268, 0.2510761998284917, 0.25856772699741104, 0.19844069566255207, 0.44429687994767564]}}
{"id": "10957b38-6e68-47b5-9a55-5f212fb7febf", "fitness": 0.30325875240445926, "name": "OrthogonalAdaptiveSearch", "description": "A population-based algorithm employing orthogonal learning to generate diverse candidate solutions and adaptive radius adjustment to balance exploration and exploitation.", "code": "import numpy as np\n\nclass OrthogonalAdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_radius=0.5, reduction_factor=0.95, orthogonal_sample_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.radius = initial_radius\n        self.reduction_factor = reduction_factor\n        self.orthogonal_sample_size = orthogonal_sample_size\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            new_population = population.copy()\n            for i in range(self.pop_size):\n                # Orthogonal Learning: Sample points around the current individual\n                orthogonal_samples = np.zeros((self.orthogonal_sample_size, self.dim))\n                for j in range(self.orthogonal_sample_size):\n                    # Generate a random direction\n                    direction = np.random.normal(0, 1, self.dim)\n                    direction /= np.linalg.norm(direction)  # Normalize\n                    \n                    # Create a new sample along the direction within the radius\n                    orthogonal_samples[j] = population[i] + self.radius * direction\n                    orthogonal_samples[j] = np.clip(orthogonal_samples[j], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate orthogonal samples\n                orthogonal_fitness = np.array([func(x) for x in orthogonal_samples])\n                self.budget -= self.orthogonal_sample_size\n\n                # Select the best sample\n                best_sample_index = np.argmin(orthogonal_fitness)\n                if orthogonal_fitness[best_sample_index] < fitness[i]:\n                    fitness[i] = orthogonal_fitness[best_sample_index]\n                    new_population[i] = orthogonal_samples[best_sample_index].copy()\n                    \n                    if fitness[i] < global_best_fitness:\n                        global_best_fitness = fitness[i]\n                        global_best_position = new_population[i].copy()\n\n                if self.budget <= 0:\n                    break\n\n            population = new_population.copy()\n\n            # Adaptive Radius Adjustment: Reduce radius if no improvement\n            if np.min(fitness) >= global_best_fitness:\n                self.radius *= self.reduction_factor\n            else:\n                self.radius = min(0.5, self.radius * (2 - self.reduction_factor)) # increase radius slightly to avoid premature convergence\n\n            self.radius = np.clip(self.radius, 1e-6, 1.0) # keep the radius in a reasonable range\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm OrthogonalAdaptiveSearch scored 0.303 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["79dea687-752a-4a22-a5ca-ad70d455d5e4"], "operator": null, "metadata": {"aucs": [0.107637113771747, 0.2233885881320612, 0.3646437171399889, 0.21853833149870994, 0.22685468659762587, 0.181340215533346, 0.23051094509332337, 0.25167007385464, 0.2111695504884663, 0.13217195203928478, 0.295325712441739, 0.9971975210887792, 0.28357967204975043, 0.17811448188375267, 0.44671598819171054, 0.28952242868380396, 0.2849627954172541, 0.4517892269795396, 0.20152275354408689, 0.4885192936595739]}}
{"id": "395507f6-6c64-4511-993a-7756d54a4f37", "fitness": 0.37095916568021886, "name": "VelocityCauchyPSO", "description": "A population-based algorithm employing a velocity-based update rule inspired by Particle Swarm Optimization (PSO) and a Cauchy mutation to diversify the search.", "code": "import numpy as np\n\nclass VelocityCauchyPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.cauchy_scale = cauchy_scale\n\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Cauchy Mutation to the velocity\n                mutation = np.random.standard_cauchy(size=self.dim) * self.cauchy_scale\n                self.velocity[i] += mutation\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                \n                population[i] = new_position.copy()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm VelocityCauchyPSO scored 0.371 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["79dea687-752a-4a22-a5ca-ad70d455d5e4"], "operator": null, "metadata": {"aucs": [0.1699648615483722, 0.2950727803594415, 0.35810681077378737, 0.44428168996693806, 0.30357153962080186, 0.3457363967920286, 0.28231399460995865, 0.29473860347579606, 0.2776485718322308, 0.21587909270797467, 0.3983523496298498, 0.9992498522499529, 0.2556606571387029, 0.2732952401138633, 0.7291278154280509, 0.35992531333703115, 0.30792478658598843, 0.41484938768219914, 0.1933986221693591, 0.5000849475820501]}}
{"id": "73f6024a-77e8-4ed3-9332-3d94a48bad3c", "fitness": 0.3357616152352352, "name": "VelocityCauchyPSO", "description": "A population-based algorithm that uses a velocity-based update rule inspired by Particle Swarm Optimization, combined with a Cauchy mutation to enhance exploration.", "code": "import numpy as np\n\nclass VelocityCauchyPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.cauchy_scale = cauchy_scale\n\n        self.velocities = None  # Initialize velocities in __call__\n\n    def __call__(self, func):\n        # Initialize population and velocities within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity using PSO formula\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * r2 * (global_best_position - population[i])\n\n                self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n\n                # Cauchy Mutation to the velocity to improve exploration\n                mutation = np.random.standard_cauchy(size=self.dim) * self.cauchy_scale\n                self.velocities[i] += mutation\n\n                # Update position\n                new_position = population[i] + self.velocities[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    population[i] = new_position.copy()\n\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = new_fitness\n                        personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n                if self.budget <=0:\n                    break\n\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm VelocityCauchyPSO scored 0.336 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["79dea687-752a-4a22-a5ca-ad70d455d5e4"], "operator": null, "metadata": {"aucs": [0.12733334636511207, 0.16771694995871245, 0.3483857101053849, 0.37923175423684685, 0.26597094633372487, 0.333915899348766, 0.27300566051214814, 0.29608258792924835, 0.2725832397883132, 0.18977148914853836, 0.2865955353268399, 0.9980603644522255, 0.2915196638483416, 0.2366867282039139, 0.5919383080993726, 0.3536693471657617, 0.2563188953610578, 0.3683479868210775, 0.19532348630413832, 0.48277440539518024]}}
{"id": "db1a4ec1-0e94-493f-ac3c-fe9daadcf5d8", "fitness": 0.3013874332450993, "name": "CovarianceMatrixGaussianExploration", "description": "An enhanced Gaussian exploration search that incorporates a covariance matrix adaptation for better exploration of the search space.", "code": "import numpy as np\n\nclass CovarianceMatrixGaussianExploration:\n    def __init__(self, budget=10000, dim=10, pop_size=20, mutation_rate=0.1, initial_exploration_intensity=0.5, adaptive_factor=0.05, covariance_learning_rate=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.exploration_intensity = initial_exploration_intensity\n        self.adaptive_factor = adaptive_factor\n        self.covariance_learning_rate = covariance_learning_rate\n        self.covariance_matrix = np.eye(dim)  # Initialize covariance matrix\n        self.mean = np.zeros(dim)\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index].copy()\n\n        previous_best_fitness = global_best_fitness\n\n        while self.budget > 0:\n            new_population = population.copy()\n            for i in range(self.pop_size):\n                if np.random.rand() < self.mutation_rate:\n                    # Gaussian Mutation using covariance matrix\n                    mutation = np.random.multivariate_normal(self.mean, self.covariance_matrix) * self.exploration_intensity\n                    new_position = population[i] + mutation\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                else:\n                    # Random Exploration\n                    new_position = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    new_population[i] = new_position.copy()\n\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n            population = new_population.copy()\n\n            # Update covariance matrix\n            diff = population - np.mean(population, axis=0)\n            self.covariance_matrix = (1 - self.covariance_learning_rate) * self.covariance_matrix + \\\n                                     self.covariance_learning_rate * np.cov(diff.T)\n\n            # Adaptive Parameter Control: Adjust exploration intensity based on improvement\n            if global_best_fitness < previous_best_fitness:\n                self.exploration_intensity *= (1 + self.adaptive_factor)\n                self.adaptive_factor *= 0.95  # Reduce the adaptive factor over time\n            else:\n                self.exploration_intensity *= (1 - self.adaptive_factor)\n            \n            self.exploration_intensity = np.clip(self.exploration_intensity, 0.01, 1.0)  # Keep intensity within bounds\n            previous_best_fitness = global_best_fitness\n            self.adaptive_factor = np.clip(self.adaptive_factor, 0.01, 0.1)\n           \n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm CovarianceMatrixGaussianExploration scored 0.301 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["79dea687-752a-4a22-a5ca-ad70d455d5e4"], "operator": null, "metadata": {"aucs": [0.13559974229495964, 0.19575470563922648, 0.3187530097554153, 0.26292902620670844, 0.21350347707464346, 0.2355771006625217, 0.2504730547029729, 0.23366716673863674, 0.22567571829142274, 0.1707003317661554, 0.2531698018110998, 0.9905069468173177, 0.2851976441845855, 0.22022232258693852, 0.5733212762353754, 0.2730563553502098, 0.24155147922094533, 0.2847203064445334, 0.1931279102118889, 0.47024128890642813]}}
{"id": "634c0c58-70d5-4296-b3a2-ef8f2f5ddc66", "fitness": 0.23121966244387576, "name": "DimensionAwareDE", "description": "Differential Evolution with a dynamically adjusted CR based on dimension-wise success rate and a restart mechanism based on stagnation detection.", "code": "import numpy as np\n\nclass DimensionAwareDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, stagnation_threshold=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.stagnation_threshold = stagnation_threshold\n        self.best_fitness_history = []\n        self.restart_iterations = 0 # Track how many times it's restarted\n\n    def __call__(self, func):\n        self.f_opt = np.Inf\n        self.x_opt = None\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        self.best_fitness_history.append(self.f_opt)\n\n\n        dimension_success_counts = np.zeros(self.dim)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                mutant = population[i] + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover - Dimension-Aware CR\n                trial = population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR: #Use global CR\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    dimension_success_counts[np.where(trial != population[i])[0]] += 1 # Count dimension successes\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n\n            #Stagnation Check and Restart\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n              if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-6:  #Stagnation detected\n                #Restart Population\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size  # Recalculate evaluations after restart\n\n                best_index = np.argmin(fitness)\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                self.restart_iterations += 1  # increment restart counter\n                dimension_success_counts = np.zeros(self.dim)  # Reset dimension success counts\n                print(\"Restarting DE\")\n\n            self.best_fitness_history.append(self.f_opt)\n\n            #Adapt CR based on dimension success rate.\n            success_rates = dimension_success_counts / self.pop_size # Dimension Success Rate\n            self.CR = np.mean(success_rates)\n            dimension_success_counts = np.zeros(self.dim) #Reset success counts after each gen.\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm DimensionAwareDE scored 0.231 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["03250e4e-8cfd-4e23-b6f0-2257ad63e8bf"], "operator": null, "metadata": {"aucs": [0.07599051264130685, 0.10557021894408136, 0.2275473569020251, 0.15608734423872395, 0.14864616493361715, 0.19574487634423954, 0.1861609789186508, 0.17528919919523978, 0.1651012806723875, 0.13862664433780414, 0.14673279849141285, 1.0, 0.05737304954051836, 0.16258473316794864, 0.5478740991529547, 0.1998273267503755, 0.19542058770119697, 0.17961890781302958, 0.1363033088243124, 0.4238938603076904]}}
{"id": "453a77c7-5f12-4b31-975b-bb03822110c8", "fitness": 0.623982644938011, "name": "NeighborhoodAdaptiveDE", "description": "An adaptive Differential Evolution strategy with a neighborhood-based mutation operator, adapting mutation strength based on local fitness variance.", "code": "import numpy as np\n\nclass NeighborhoodAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, neighborhood_size=5):\n        \"\"\"\n        Initialize the Neighborhood Adaptive Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The initial population size. If None, it's set to 10*dim.\n            F (float, optional): The initial mutation factor.\n            CR (float, optional): The initial crossover rate.\n            neighborhood_size (int, optional): The size of the neighborhood for mutation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.F = F\n        self.CR = CR\n        self.neighborhood_size = neighborhood_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.archive = []\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, pop, F, neighborhood_size):\n        \"\"\"Perform neighborhood-based differential mutation.\"\"\"\n        mutated = np.zeros_like(pop)\n        for i in range(len(pop)):\n            # Select neighborhood indices\n            indices = np.arange(len(pop))\n            np.random.shuffle(indices)\n            neighborhood_indices = indices[:neighborhood_size]\n\n            # Select three distinct individuals from the neighborhood\n            if len(neighborhood_indices) < 3:\n                a,b,c = np.random.choice(len(pop), 3, replace=False)\n                a_idx = a\n                b_idx = b\n                c_idx = c\n            else:\n                a_idx, b_idx, c_idx = np.random.choice(neighborhood_indices, 3, replace=False)\n            a, b, c = pop[a_idx], pop[b_idx], pop[c_idx]\n            \n            #Adapt F based on local fitness variance\n            neighborhood_fitness = self.fitness[neighborhood_indices]\n            fitness_variance = np.var(neighborhood_fitness)\n            adaptive_F = F * (1 + 0.1 * fitness_variance) #Modulate F\n\n            mutated[i] = a + adaptive_F * (b - c)\n\n        return mutated\n\n    def crossover(self, pop, mutated, CR):\n        \"\"\"Perform binomial crossover.\"\"\"\n        rand_matrix = np.random.rand(*pop.shape)\n        cross_mask = rand_matrix < CR\n        # Ensure at least one component is crossed over\n        for i in range(len(pop)):\n            j = np.random.randint(self.dim)\n            cross_mask[i, j] = True\n        u = np.where(cross_mask, mutated, pop)\n        return u\n\n    def select(self, func, u):\n        \"\"\"Perform selection based on fitness.\"\"\"\n        fitness_u = np.array([func(x) for x in u])\n        self.eval_count += len(u)\n\n        improvements = fitness_u < self.fitness\n        self.pop = np.where(improvements[:, None], u, self.pop)\n        self.fitness = np.where(improvements, fitness_u, self.fitness)\n        \n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Neighborhood Adaptive Differential Evolution.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutated = self.mutate(self.pop, self.F, self.neighborhood_size)\n\n            # Clip values to respect bounds\n            mutated = np.clip(mutated, func.bounds.lb, func.bounds.ub)\n            \n            u = self.crossover(self.pop, mutated, self.CR)\n            \n            # Clip values to respect bounds\n            u = np.clip(u, func.bounds.lb, func.bounds.ub)\n            \n            self.select(func, u)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm NeighborhoodAdaptiveDE scored 0.624 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["10dfb06b-deba-498f-a4e1-5e98a0172193"], "operator": null, "metadata": {"aucs": [0.13999522306802703, 0.573032727660353, 0.6011746877883968, 0.8462223426191763, 0.6633190985678409, 0.7192289835478429, 0.5542158604713843, 0.5465980163194215, 0.6728993573482454, 0.6669559946266912, 0.8279999777176925, 0.9993278665689904, 0.2326294698008149, 0.6477837530219341, 0.9181796575593089, 0.7462376189652802, 0.5262704341610194, 0.8013687681285773, 0.3007420709222035, 0.4954709898970221]}}
{"id": "437dd58f-7938-43fe-97eb-7180e87662c3", "fitness": 0.37732601175308966, "name": "SimulatedAnnealingCauchy", "description": "A population-based algorithm employing a Simulated Annealing-inspired acceptance criterion to balance exploration and exploitation with a Cauchy-distributed perturbation.", "code": "import numpy as np\n\nclass SimulatedAnnealingCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_temp=1.0, cooling_rate=0.95, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.cauchy_scale = cauchy_scale\n\n    def cauchy_mutation(self, size):\n        return self.cauchy_scale * np.random.standard_cauchy(size=size)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index].copy()\n\n        temperature = self.initial_temp\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Generate a candidate solution using Cauchy mutation\n                mutation = self.cauchy_mutation(self.dim)\n                new_position = population[i] + mutation\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                # Accept or reject the new solution based on Simulated Annealing criterion\n                delta_e = new_fitness - fitness[i]\n                if delta_e < 0:\n                    # Accept better solution\n                    population[i] = new_position.copy()\n                    fitness[i] = new_fitness\n                    \n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                else:\n                    # Accept worse solution with probability based on temperature\n                    acceptance_probability = np.exp(-delta_e / temperature)\n                    if np.random.rand() < acceptance_probability:\n                        population[i] = new_position.copy()\n                        fitness[i] = new_fitness\n\n            # Cool down the temperature\n            temperature *= self.cooling_rate\n            temperature = max(temperature, 0.001) # minimum temperature\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm SimulatedAnnealingCauchy scored 0.377 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["654be784-3b1b-4bef-91ee-f0ac2453ff8a"], "operator": null, "metadata": {"aucs": [0.1209276755239369, 0.27783620724049884, 0.38079277888975716, 0.47126997681778315, 0.3151808715591813, 0.39234665196506524, 0.2903702111245131, 0.3339937213274634, 0.30060408251858894, 0.18453583105206295, 0.44148194612092884, 0.9832552909520951, 0.29383117531418734, 0.28144067725518573, 0.6830280637291466, 0.3620618477164539, 0.31390400899089765, 0.46416069125143444, 0.1848493448042292, 0.47064918090838304]}}
{"id": "ee419b74-7f25-416d-b57e-6f84990cb2bc", "fitness": 0.27431561248166475, "name": "CovarianceMatrixAdaptationGaussianExploration", "description": "An enhanced Gaussian Exploration Search that incorporates a covariance matrix adaptation for better exploration and exploitation.", "code": "import numpy as np\n\nclass CovarianceMatrixAdaptationGaussianExploration:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_exploration_intensity=0.5, learning_rate=0.1, decay_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.exploration_intensity = initial_exploration_intensity\n        self.learning_rate = learning_rate\n        self.decay_rate = decay_rate\n        self.covariance_matrix = np.eye(dim) * (self.exploration_intensity**2)  # Initialize covariance matrix\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Generate new samples using the covariance matrix\n                mutation = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n                new_position = population[i] + mutation\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness[i] = func(new_position)\n                self.budget -= 1\n                \n                new_population[i] = new_position.copy()\n\n                if new_fitness[i] < global_best_fitness:\n                    global_best_fitness = new_fitness[i]\n                    global_best_position = new_position.copy()\n\n            # Update population and fitness\n            population = new_population.copy()\n            fitness = new_fitness.copy()\n\n            # Update covariance matrix using CMA-ES like update\n            weights = np.maximum(0, np.log(self.pop_size/2+1) - np.log(np.arange(1, self.pop_size+1)))\n            weights = weights / np.sum(weights)\n            \n            sorted_indices = np.argsort(fitness)\n            weighted_mean = np.sum(weights[:, np.newaxis] * population[sorted_indices], axis=0)\n            \n            C_update = np.zeros_like(self.covariance_matrix)\n            for k in range(self.pop_size):\n                diff = population[sorted_indices[k]] - weighted_mean\n                C_update += weights[k] * np.outer(diff, diff)\n\n            self.covariance_matrix = (1 - self.learning_rate) * self.covariance_matrix + self.learning_rate * C_update\n\n            # Adjust exploration intensity adaptively\n            eigenvalues = np.linalg.eigvalsh(self.covariance_matrix)\n            self.exploration_intensity = np.mean(np.sqrt(eigenvalues))\n            self.exploration_intensity *= self.decay_rate\n            self.exploration_intensity = np.clip(self.exploration_intensity, 0.01, 1.0)\n\n            # Regularize covariance matrix to avoid it becoming singular\n            self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm CovarianceMatrixAdaptationGaussianExploration scored 0.274 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["79dea687-752a-4a22-a5ca-ad70d455d5e4"], "operator": null, "metadata": {"aucs": [0.12717348888472657, 0.1573455665849386, 0.2630088001366787, 0.18887425756749077, 0.20569633522270536, 0.1992040528321336, 0.24066952022773902, 0.19727478375506402, 0.1801325423894392, 0.16232749121508805, 0.23011542425782183, 0.9627640119827502, 0.27948873560863763, 0.19885998604031296, 0.5489042504655759, 0.27404497103996805, 0.2234193242236594, 0.25915942528168123, 0.15009603902880786, 0.4377532428880754]}}
{"id": "b1365132-0e9f-4c5c-819c-e2651eb98535", "fitness": -Infinity, "name": "SobolNelderMeadPSO", "description": "Combines PSO with a Sobol sequence for initialization and a local search refinement based on Nelder-Mead.", "code": "import numpy as np\nfrom scipy.stats import qmc\nfrom scipy.optimize import minimize\n\nclass SobolNelderMeadPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.local_search_iterations = local_search_iterations\n\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def __call__(self, func):\n        # Initialize population using Sobol sequence\n        sampler = qmc.Sobol(d=self.dim, scramble=True)\n        sample = sampler.random(n=self.pop_size)\n        population = func.bounds.lb + (func.bounds.ub - func.bounds.lb) * sample\n\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                \n                # Local search refinement using Nelder-Mead\n                if self.local_search_iterations > 0 and self.budget > self.local_search_iterations:\n                    result = minimize(func, new_position, method='Nelder-Mead', \n                                    options={'maxiter': self.local_search_iterations, 'maxfev': self.local_search_iterations, 'xatol': 1e-4, 'fatol': 1e-4})  # Reduced tolerances\n                    new_position = result.x\n                    new_fitness = result.fun\n                    self.budget -= result.nfev\n\n                else:\n                    new_fitness = func(new_position)\n                    self.budget -= 1\n                    \n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                \n                population[i] = new_position.copy()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 3, "feedback": "An exception occurred: name 'qmc' is not defined.", "error": "", "parent_ids": ["395507f6-6c64-4511-993a-7756d54a4f37"], "operator": null, "metadata": {}}
{"id": "9cf48cf9-3a31-4f02-bc77-562beed1d394", "fitness": 0.0, "name": "AdaptiveGaussianPSO", "description": "A PSO variant that adaptively adjusts inertia weight and uses a Gaussian mutation scaled by the fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveGaussianPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_coeff=1.5, social_coeff=1.5, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.mutation_rate = mutation_rate\n\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        iteration = 0\n        while self.budget > 0:\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (iteration / (self.budget/self.pop_size + iteration))  # adapt inertia\n\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                fitness_improvement = self.personal_best_fitness[i] - new_fitness\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n                # Gaussian Mutation scaled by fitness improvement\n                if np.random.rand() < self.mutation_rate:\n                  mutation_scale = np.abs(fitness_improvement) + 1e-9\n                  mutation = np.random.normal(0, mutation_scale, size=self.dim)\n                  new_position += mutation\n                  new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                  \n                  mutated_fitness = func(new_position)\n                  self.budget -=1\n\n                  if mutated_fitness < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = mutated_fitness\n                        self.personal_best_positions[i] = new_position.copy()\n\n                        if mutated_fitness < self.global_best_fitness:\n                            self.global_best_fitness = mutated_fitness\n                            self.global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n            iteration += 1\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveGaussianPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["395507f6-6c64-4511-993a-7756d54a4f37"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "4b847c91-4f4c-48e3-849a-acd0daf7fb27", "fitness": -Infinity, "name": "OrthogonalAdaptiveDE", "description": "Adaptive Differential Evolution with orthogonal learning and dynamic parameter control, utilizing orthogonal experimental design to enhance search efficiency and adaptively adjust parameters.", "code": "import numpy as np\n\nclass OrthogonalAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9):\n        \"\"\"\n        Initialize the Orthogonal Adaptive Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The initial population size. If None, it's set to 10*dim.\n            F (float, optional): The initial mutation factor.\n            CR (float, optional): The initial crossover rate.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.archive = []\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, pop, F):\n        \"\"\"Perform differential mutation.\"\"\"\n        mutated = np.zeros_like(pop)\n        for i in range(len(pop)):\n            a, b, c = np.random.choice(len(pop), 3, replace=False)\n            mutated[i] = pop[a] + F * (pop[b] - pop[c])\n        return mutated\n\n    def crossover(self, pop, mutated, CR):\n        \"\"\"Perform binomial crossover.\"\"\"\n        rand_matrix = np.random.rand(*pop.shape)\n        cross_mask = rand_matrix < CR\n        # Ensure at least one component is crossed over\n        for i in range(len(pop)):\n            j = np.random.randint(self.dim)\n            cross_mask[i, j] = True\n        u = np.where(cross_mask, mutated, pop)\n        return u\n\n    def orthogonal_learning(self, func, x):\n        \"\"\"Perform orthogonal learning to generate candidate solutions.\"\"\"\n        levels = 3  # Number of levels for each factor\n        L_matrix = self.generate_orthogonal_array(levels, self.dim)\n        candidates = np.zeros((len(L_matrix), self.dim))\n\n        for i, row in enumerate(L_matrix):\n            candidate = np.copy(x)\n            for j, level in enumerate(row):\n                # Map level to a value within the bounds around x[j]\n                range_val = 0.1 * (func.bounds.ub - func.bounds.lb) # 10% range\n                lower_bound = max(func.bounds.lb[j], x[j] - range_val)\n                upper_bound = min(func.bounds.ub[j], x[j] + range_val)\n                candidates[i, j] = lower_bound + (level / (levels - 1)) * (upper_bound - lower_bound)\n                \n            candidates[i] = np.clip(candidates[i], func.bounds.lb, func.bounds.ub)\n        \n        fitness_values = np.array([func(xi) for xi in candidates])\n        best_index = np.argmin(fitness_values)\n        best_candidate = candidates[best_index]\n        best_fitness = fitness_values[best_index]\n        self.eval_count += len(L_matrix)\n        \n        return best_candidate, best_fitness\n\n    def generate_orthogonal_array(self, levels, factors):\n        \"\"\"Generate an orthogonal array using Plackett-Burman design.\"\"\"\n        # This is a simplified version.  For higher levels/factors, use a library \n        # like pyDOE or similar to generate more robust orthogonal arrays.\n\n        if levels == 3 and factors <= 3:\n             if factors == 1:\n                 return np.array([[0],[1],[2]])\n             if factors == 2:\n                 return np.array([[0, 0], [0, 1], [0, 2], [1, 0], [1, 1], [1, 2], [2, 0], [2, 1], [2, 2]])\n             if factors == 3:\n                return np.array([[0, 0, 0], [0, 1, 1], [0, 2, 2], [1, 0, 1], [1, 1, 2], [1, 2, 0], [2, 0, 2], [2, 1, 0], [2, 2, 1]])\n        \n        #Fall back to random design if no array found\n        array = np.random.randint(0,levels, size=(levels*levels, factors))\n        return array\n\n    def select(self, func, u):\n        \"\"\"Perform selection based on fitness and orthogonal learning.\"\"\"\n        fitness_u = np.array([func(x) for x in u])\n        self.eval_count += len(u)\n\n        improvements = fitness_u < self.fitness\n        self.pop = np.where(improvements[:, None], u, self.pop)\n        self.fitness = np.where(improvements, fitness_u, self.fitness)\n        \n        #Apply orthogonal learning to best individual\n        best_index = np.argmin(self.fitness)\n        best_x = self.pop[best_index].copy()\n        \n        learned_x, learned_fitness = self.orthogonal_learning(func, best_x)\n\n        if learned_fitness < self.fitness[best_index]:\n             self.pop[best_index] = learned_x\n             self.fitness[best_index] = learned_fitness\n             improvements[best_index] = True\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n            \n        # Adapt parameters\n        if np.any(improvements):\n            self.F = 0.5 * (self.F + 0.5) # Adapt F if improvement\n            self.CR = 0.5 * (self.CR + 0.9) # Adapt CR if improvement\n        else:\n            self.F = min(self.F * 1.1, 0.9) # Increase if no improvement\n            self.CR = max(self.CR * 0.9, 0.1) # Decrease if no improvement\n\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Orthogonal Adaptive Differential Evolution.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutated = self.mutate(self.pop, self.F)\n\n            # Clip values to respect bounds\n            mutated = np.clip(mutated, func.bounds.lb, func.bounds.ub)\n            \n            u = self.crossover(self.pop, mutated, self.CR)\n            \n            # Clip values to respect bounds\n            u = np.clip(u, func.bounds.lb, func.bounds.ub)\n            \n            self.select(func, u)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["453a77c7-5f12-4b31-975b-bb03822110c8"], "operator": null, "metadata": {}}
{"id": "e0e9b46f-e534-4957-910d-df49ae5fd342", "fitness": 0.35658175667071024, "name": "AdaptiveCauchyPSO", "description": "Adaptive Cauchy scale in Velocity PSO, adjusting exploration based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveCauchyPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, initial_cauchy_scale=0.1, cauchy_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.cauchy_scale = initial_cauchy_scale\n        self.initial_cauchy_scale = initial_cauchy_scale\n        self.cauchy_decay = cauchy_decay\n\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.population = None  # Store the population\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1  # Initialize velocities\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = self.population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            # Calculate population diversity (standard deviation along each dimension)\n            diversity = np.std(self.population, axis=0)\n            # Adjust Cauchy scale based on diversity; if diversity is low, increase exploration\n            self.cauchy_scale = self.initial_cauchy_scale * np.mean(diversity)\n\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - self.population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Cauchy Mutation to the velocity\n                mutation = np.random.standard_cauchy(size=self.dim) * self.cauchy_scale\n                self.velocity[i] += mutation\n\n                # Update position\n                new_position = self.population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                \n                self.population[i] = new_position.copy()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveCauchyPSO scored 0.357 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["395507f6-6c64-4511-993a-7756d54a4f37"], "operator": null, "metadata": {"aucs": [0.1769312587660099, 0.20293703489762704, 0.3264375688408825, 0.4350741524016767, 0.28210921079029194, 0.34124722773352867, 0.2730619594657403, 0.2854211061207347, 0.26402750661472907, 0.22453508331523975, 0.3507374220655767, 0.9976508760780547, 0.29277167350024536, 0.2755709396921855, 0.6941959047033868, 0.3254741683069464, 0.28334164301078846, 0.4331078047898753, 0.18079623279315005, 0.4862063595275353]}}
{"id": "6bcf56cd-5b48-46a5-9c48-55f534966206", "fitness": 0.45806245041358473, "name": "AdaptiveLaplacianPSO", "description": "A PSO variant that dynamically adjusts the inertia weight and introduces a Laplacian mutation to enhance exploration and escape local optima.", "code": "import numpy as np\n\nclass AdaptiveLaplacianPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_coeff=1.4, social_coeff=1.4, laplacian_scale=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.laplacian_scale = laplacian_scale\n\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.generation = 0\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            # Adaptive Inertia Weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (self.generation / (self.budget // self.pop_size + self.generation +1e-6))\n            \n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Laplacian Mutation to the velocity\n                mutation = np.random.laplace(loc=0.0, scale=self.laplacian_scale, size=self.dim)\n                self.velocity[i] += mutation\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                \n                population[i] = new_position.copy()\n            self.generation += 1\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveLaplacianPSO scored 0.458 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["395507f6-6c64-4511-993a-7756d54a4f37"], "operator": null, "metadata": {"aucs": [0.1721637344849003, 0.2744605286505998, 0.5035198923263917, 0.8329636397646099, 0.26367579832699006, 0.5554988708440052, 0.20832025596112325, 0.44705042863334843, 0.1724025972204437, 0.23602964215843103, 0.8645892454170061, 0.9962123793131001, 0.25179245189547717, 0.2794851722509937, 0.9167604779039957, 0.4220276349896521, 0.43972514075840596, 0.5847863536931255, 0.26560861093852495, 0.4741761527405709]}}
{"id": "b30dd6ed-1183-4752-8d0a-0a0de164c857", "fitness": 0.3577588477410571, "name": "AdaptiveLevyPSO", "description": "An adaptive PSO variant that adjusts the cognitive and social coefficients based on the diversity of the swarm and uses a Levy flight for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, levy_exponent=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.levy_exponent = levy_exponent\n        self.velocities = None\n\n    def levy_flight(self, size):\n        # Generate Levy distribution samples\n        u = np.random.randn(size)\n        v = np.random.randn(size)\n        step = u / np.power(np.abs(v), (1 / self.levy_exponent))\n        return step\n\n    def __call__(self, func):\n        # Initialize population and velocities within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            # Calculate swarm diversity\n            diversity = np.std(population)\n\n            # Adaptive adjustment of cognitive and social coefficients\n            adaptive_cognitive = self.cognitive_coeff * (1 + diversity)\n            adaptive_social = self.social_coeff * (1 - diversity)\n            adaptive_cognitive = np.clip(adaptive_cognitive, 0.1, 2.0)\n            adaptive_social = np.clip(adaptive_social, 0.1, 2.0)\n\n            for i in range(self.pop_size):\n                # Update velocity using PSO formula\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                cognitive_component = adaptive_cognitive * r1 * (personal_best_positions[i] - population[i])\n                social_component = adaptive_social * r2 * (global_best_position - population[i])\n\n                self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n\n                # Levy flight for exploration\n                levy_steps = self.levy_flight(self.dim) * 0.01  # Scale down the levy steps\n                new_position = population[i] + self.velocities[i] + levy_steps\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    population[i] = new_position.copy()\n\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = new_fitness\n                        personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                \n                if self.budget <= 0:\n                    break\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveLevyPSO scored 0.358 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["73f6024a-77e8-4ed3-9332-3d94a48bad3c"], "operator": null, "metadata": {"aucs": [0.10243416623169965, 0.18696663148721127, 0.47360578257669317, 0.19070637364353793, 0.2308941188474185, 0.5734502707688314, 0.2760319267036384, 0.27025526967657143, 0.24036675483986947, 0.20254609144573765, 0.27721457426158136, 0.9892042820247037, 0.23595342337614789, 0.19853114891693557, 0.6443584595601605, 0.3445027194909672, 0.2774373821731049, 0.7371129427348408, 0.23390891036862171, 0.4696957256928702]}}
{"id": "ac3d01e3-c613-4f47-8600-7757539e73f1", "fitness": 0.7209315856873474, "name": "AdaptiveDECauchy", "description": "An adaptive population-based algorithm that combines aspects of differential evolution with a self-adjusting probability of either performing a standard DE update or a Cauchy mutation.", "code": "import numpy as np\n\nclass AdaptiveDECauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_prob=0.7, cauchy_scale=0.1, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_prob = de_prob\n        self.cauchy_scale = cauchy_scale\n        self.F = F\n        self.CR = CR\n\n    def cauchy_mutation(self, size):\n        return self.cauchy_scale * np.random.standard_cauchy(size=size)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.de_prob:\n                    # Differential Evolution update\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n\n                    # Mutation\n                    v_i = x_r1 + self.F * (x_r2 - x_r3)\n\n                    # Crossover\n                    u_i = np.zeros(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.CR:\n                            u_i[j] = v_i[j]\n                        else:\n                            u_i[j] = population[i, j]\n                    \n                    u_i = np.clip(u_i, func.bounds.lb, func.bounds.ub)\n                    f_u_i = func(u_i)\n                    self.budget -= 1\n\n                    if f_u_i < fitness[i]:\n                        population[i] = u_i.copy()\n                        fitness[i] = f_u_i\n                        if f_u_i < global_best_fitness:\n                            global_best_fitness = f_u_i\n                            global_best_position = u_i.copy()\n                else:\n                    # Cauchy Mutation\n                    mutation = self.cauchy_mutation(self.dim)\n                    new_position = population[i] + mutation\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                    new_fitness = func(new_position)\n                    self.budget -= 1\n\n                    if new_fitness < fitness[i]:\n                        population[i] = new_position.copy()\n                        fitness[i] = new_fitness\n                        if new_fitness < global_best_fitness:\n                            global_best_fitness = new_fitness\n                            global_best_position = new_position.copy()\n\n            # Adapt de_prob (optional, based on success rate of DE vs Cauchy)\n            # This part is intentionally skipped to maintain simplicity and novelty\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDECauchy scored 0.721 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["437dd58f-7938-43fe-97eb-7180e87662c3"], "operator": null, "metadata": {"aucs": [0.23668897858978044, 0.6893025265192707, 0.6966775953324558, 0.905496127954969, 0.8372948021056756, 0.8491853812327936, 0.7130431347335733, 0.7476086896678593, 0.8189423796636055, 0.724516036330981, 0.8801141974212693, 0.9966673121604342, 0.3254323709571766, 0.792704696476255, 0.8486183511052976, 0.8544239350636047, 0.6494295132126882, 0.9008044784092669, 0.4328650810555048, 0.5188161257544852]}}
{"id": "51092714-0bef-442b-a13a-566ea5e1bf0f", "fitness": 0.36849769519484915, "name": "AdaptiveLevyPSO", "description": "An adaptive PSO algorithm with velocity clamping and a mutation operator based on Lvy flights, adjusting parameters based on success rate.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_start=0.9, inertia_end=0.4,\n                 cognitive_coeff=2.0, social_coeff=2.0, levy_scale=0.01, velocity_clamp=0.5,\n                 success_rate_threshold=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_start = inertia_start\n        self.inertia_end = inertia_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.levy_scale = levy_scale\n        self.velocity_clamp = velocity_clamp\n        self.success_rate_threshold = success_rate_threshold\n\n        self.velocities = None\n        self.success_count = 0\n        self.iteration = 0\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / (np.abs(v) ** (1 / beta))\n        return step\n\n    def __call__(self, func):\n        # Initialize population and velocities within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        self.iteration = 0\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            self.success_count = 0\n            for i in range(self.pop_size):\n                # Adaptive Inertia Weight\n                inertia = self.inertia_start - (self.inertia_start - self.inertia_end) * (self.iteration / (self.budget/self.pop_size+self.iteration))\n\n                # Update velocity using PSO formula\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * r2 * (global_best_position - population[i])\n\n                self.velocities[i] = inertia * self.velocities[i] + cognitive_component + social_component\n\n                # Velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Lvy Flight Mutation to the position to improve exploration\n                mutation = self.levy_flight(size=self.dim) * self.levy_scale\n                new_position = population[i] + self.velocities[i] + mutation\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    population[i] = new_position.copy()\n                    self.success_count +=1\n\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = new_fitness\n                        personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n                if self.budget <= 0:\n                    break\n            \n            # Adaptive parameter adjustment based on success rate\n            success_rate = self.success_count / self.pop_size\n            if success_rate > self.success_rate_threshold:\n                self.levy_scale *= 0.95  # Reduce mutation strength\n            else:\n                self.levy_scale *= 1.05  # Increase mutation strength\n\n            self.iteration += 1\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveLevyPSO scored 0.368 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["73f6024a-77e8-4ed3-9332-3d94a48bad3c"], "operator": null, "metadata": {"aucs": [0.14316740665390904, 0.19071242819779444, 0.4021530426699603, 0.276214646090416, 0.2875854869361355, 0.4044501709135321, 0.279156695845887, 0.344665873113268, 0.31758242782060553, 0.1745336771207736, 0.4257926263460181, 0.9967412592448218, 0.34123236376506316, 0.2793435977298744, 0.7299170174482159, 0.35395383345616616, 0.28530755049767376, 0.5018224069372402, 0.15652330889207844, 0.4790980842175495]}}
{"id": "4f01b838-3dec-48ed-8fb1-b07b75d69848", "fitness": 0.3782787431713115, "name": "AdaptiveDECauchy", "description": "An adaptive Differential Evolution algorithm with a self-adaptive population size and a Cauchy mutation operator, adjusting the population size and mutation strength based on the fitness landscape.", "code": "import numpy as np\n\nclass AdaptiveDECauchy:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F=0.5, Cr=0.9, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.cauchy_scale = cauchy_scale\n\n        self.pop_size_min = 10\n        self.pop_size_max = 100\n\n    def cauchy_mutation(self, size):\n        return self.cauchy_scale * np.random.standard_cauchy(size=size)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        best_fitness = fitness[best_index].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                \n                mutation = self.cauchy_mutation(self.dim)\n                mutant = x_r1 + self.F * (x_r2 - x_r3) + mutation\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial_vector = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                self.budget -= 1\n                if f < fitness[i]:\n                    new_population[i] = trial_vector.copy()\n                    new_fitness[i] = f\n                    if f < best_fitness:\n                        best_fitness = f\n                        best_position = trial_vector.copy()\n                else:\n                    new_population[i] = population[i].copy()\n                    new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n            \n            population = new_population.copy()\n            fitness = new_fitness.copy()\n\n            # Adjust population size\n            if generation % 10 == 0:\n                fitness_std = np.std(fitness)\n                if fitness_std > 1e-6:  # Avoid division by zero\n                    pop_size_factor = np.tanh(1.0 / fitness_std)\n                    self.pop_size = int(self.pop_size_min + (self.pop_size_max - self.pop_size_min) * pop_size_factor)\n                    self.pop_size = max(self.pop_size_min, min(self.pop_size, self.pop_size_max))\n\n                    # Resize population if necessary\n                    if self.pop_size != population.shape[0]:\n                        if self.pop_size < population.shape[0]:\n                             # Reduce the population, keep the best individuals\n                            indices = np.argsort(fitness)[:self.pop_size]\n                            population = population[indices]\n                            fitness = fitness[indices]\n                        else:\n                             # Increase population, initialize new individuals randomly\n                            num_new_individuals = self.pop_size - population.shape[0]\n                            new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new_individuals, self.dim))\n                            new_fitness_values = np.array([func(x) for x in new_individuals])\n                            self.budget -= num_new_individuals\n                            \n                            population = np.vstack((population, new_individuals))\n                            fitness = np.hstack((fitness, new_fitness_values))\n                            \n            self.pop_size = population.shape[0] #update pop_size\n                        \n        return best_fitness, best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDECauchy scored 0.378 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["437dd58f-7938-43fe-97eb-7180e87662c3"], "operator": null, "metadata": {"aucs": [0.17925135386442248, 0.2801326606008733, 0.34362206670064144, 0.42244165029666525, 0.3375892513873139, 0.3667997126937469, 0.2938532261659971, 0.3163416785468872, 0.29759840416627115, 0.22662896345985484, 0.4139282117243215, 0.9996613867231893, 0.2945613363909739, 0.3069690288512351, 0.7097624183255091, 0.3695089753058364, 0.30332120077845315, 0.42796370946380036, 0.189299831554404, 0.4863397964258327]}}
{"id": "741cc2c2-a397-4d1d-b228-acec5144527d", "fitness": 0.4356879450433772, "name": "FitnessWeightedCauchyDE", "description": "An enhanced differential evolution algorithm employing a fitness-weighted sampling strategy for selecting parents, blended with Cauchy mutation and adaptive parameter control.", "code": "import numpy as np\n\nclass FitnessWeightedCauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, cauchy_scale=0.1):\n        \"\"\"\n        Initialize the Fitness Weighted Cauchy Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The initial population size. If None, it's set to 10*dim.\n            F (float, optional): The initial mutation factor.\n            CR (float, optional): The initial crossover rate.\n            cauchy_scale (float, optional): Scale parameter for the Cauchy distribution.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.archive = []\n        self.F_history = []\n        self.CR_history = []\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def weighted_sampling(self, fitness):\n         \"\"\"Sample indices based on fitness weights.\"\"\"\n         # Convert fitness to probabilities (lower fitness = higher probability)\n         probabilities = np.max(fitness) - fitness + 1e-9  # Add a small constant to avoid zero probabilities\n         probabilities = probabilities / np.sum(probabilities)\n         indices = np.arange(self.pop_size)\n         sampled_indices = np.random.choice(indices, size=3, replace=False, p=probabilities)\n         return sampled_indices\n\n\n    def mutate(self, pop, F):\n        \"\"\"Perform differential mutation with fitness-weighted parent selection and Cauchy perturbation.\"\"\"\n        mutated = np.zeros_like(pop)\n        for i in range(len(pop)):\n            #Select parents based on fitness\n            a_idx, b_idx, c_idx = self.weighted_sampling(self.fitness)\n            a, b, c = pop[a_idx], pop[b_idx], pop[c_idx]\n            \n            # Cauchy mutation\n            cauchy_noise = np.random.standard_cauchy(size=self.dim) * self.cauchy_scale\n            mutated[i] = a + F * (b - c) + cauchy_noise\n\n        return mutated\n\n    def crossover(self, pop, mutated, CR):\n        \"\"\"Perform binomial crossover.\"\"\"\n        rand_matrix = np.random.rand(*pop.shape)\n        cross_mask = rand_matrix < CR\n        # Ensure at least one component is crossed over\n        for i in range(len(pop)):\n            j = np.random.randint(self.dim)\n            cross_mask[i, j] = True\n        u = np.where(cross_mask, mutated, pop)\n        return u\n    \n    def adapt_parameters(self):\n        \"\"\"Adapt F and CR based on recent history.\"\"\"\n        if len(self.F_history) > 10:\n            self.F = np.mean(self.F_history[-10:])\n        if len(self.CR_history) > 10:\n            self.CR = np.mean(self.CR_history[-10:])\n\n    def select(self, func, u):\n        \"\"\"Perform selection based on fitness.\"\"\"\n        fitness_u = np.array([func(x) for x in u])\n        self.eval_count += len(u)\n\n        improvements = fitness_u < self.fitness\n        \n        #Store success rate for parameter adaptation\n        successful_F = self.F if np.any(improvements) else 0.5 #Default F\n        successful_CR = self.CR if np.any(improvements) else 0.9 #Default CR\n        self.F_history.append(successful_F)\n        self.CR_history.append(successful_CR)\n\n        self.pop = np.where(improvements[:, None], u, self.pop)\n        self.fitness = np.where(improvements, fitness_u, self.fitness)\n        \n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n            \n        self.adapt_parameters()\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Fitness Weighted Cauchy Differential Evolution.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutated = self.mutate(self.pop, self.F)\n\n            # Clip values to respect bounds\n            mutated = np.clip(mutated, func.bounds.lb, func.bounds.ub)\n            \n            u = self.crossover(self.pop, mutated, self.CR)\n            \n            # Clip values to respect bounds\n            u = np.clip(u, func.bounds.lb, func.bounds.ub)\n            \n            self.select(func, u)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm FitnessWeightedCauchyDE scored 0.436 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["453a77c7-5f12-4b31-975b-bb03822110c8"], "operator": null, "metadata": {"aucs": [0.18994923713305878, 0.3362156225803057, 0.39560255742980666, 0.5124009093786326, 0.3328211222421634, 0.4191546453574313, 0.29940481032009825, 0.34442401399963096, 0.3373622649621917, 0.28214940681278333, 0.8265307433500891, 0.9901071298461518, 0.2823549965693617, 0.3316443269748839, 0.821616711403568, 0.4309930683421773, 0.33294415505073693, 0.4784353338141233, 0.2635384327201036, 0.5061094125802454]}}
{"id": "e699ecc0-8383-4072-a5ef-35e016720e3b", "fitness": 0.0, "name": "AdaptiveGaussianMutation", "description": "A population-based algorithm that integrates a Gaussian mutation with adaptive step size control based on the success rate of mutations and a selection mechanism favoring diversity.", "code": "import numpy as np\n\nclass AdaptiveGaussianMutation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.1, success_rate_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = initial_step_size\n        self.success_rate_memory = success_rate_memory\n        self.success_history = []\n        self.mu = 0.5  # parameter to control step size adaptation\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Generate a candidate solution using Gaussian mutation\n                mutation = self.step_size * np.random.normal(0, 1, size=self.dim)\n                new_position = population[i] + mutation\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness_value = func(new_position)\n                self.budget -= 1\n\n                if new_fitness_value < fitness[i]:\n                    new_population[i] = new_position\n                    new_fitness[i] = new_fitness_value\n                    success = 1\n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n                    success = 0\n\n                if new_fitness_value < global_best_fitness:\n                    global_best_fitness = new_fitness_value\n                    global_best_position = new_position.copy()\n                    \n                self.success_history.append(success)\n                if len(self.success_history) > self.success_rate_memory:\n                    self.success_history.pop(0)\n\n            # Adapt step size\n            success_rate = np.mean(self.success_history) if self.success_history else 0.5\n            self.step_size *= np.exp(self.mu * (success_rate - 0.2))\n            self.step_size = max(self.step_size, 1e-6) # prevent step size from being zero\n\n            # Selection: Favor diversity by replacing the worst individual with a random one\n            worst_index = np.argmax(new_fitness)\n            random_position = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            random_fitness = func(random_position)\n            self.budget -= 1\n            if random_fitness < new_fitness[worst_index]:\n                new_population[worst_index] = random_position\n                new_fitness[worst_index] = random_fitness\n\n            population = new_population\n            fitness = new_fitness\n\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveGaussianMutation scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["437dd58f-7938-43fe-97eb-7180e87662c3"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "105a3c4b-db1d-420a-b4b9-49daec889d08", "fitness": 0.18632052596699467, "name": "SelfOrganizingMigratingCauchy", "description": "A self-organizing migrating algorithm with a Cauchy mutation operator, adapting mutation strength based on the fitness improvement.", "code": "import numpy as np\n\nclass SelfOrganizingMigratingCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=20, migration_rate=0.1, cauchy_scale=0.1, scaling_factor=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.migration_rate = migration_rate\n        self.cauchy_scale = cauchy_scale\n        self.scaling_factor = scaling_factor\n\n    def cauchy_mutation(self, scale, size):\n        return scale * np.random.standard_cauchy(size=size)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            # Sort population based on fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            # Migration: Replace worst individuals with mutated versions of the best\n            num_migrants = int(self.pop_size * self.migration_rate)\n            \n            for i in range(self.pop_size - num_migrants, self.pop_size):\n                # Select a random individual from the top half\n                donor_index = np.random.randint(0, self.pop_size // 2)\n                donor = population[donor_index]\n\n                # Cauchy mutation with adaptive scaling\n                scale = self.cauchy_scale * np.abs(global_best_fitness - fitness[i% (self.pop_size - num_migrants)]) + 1e-6 # ensure it is not zero\n                mutation = self.cauchy_mutation(scale, self.dim)\n\n                new_position = donor + mutation\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < fitness[i]:\n                    population[i] = new_position.copy()\n                    fitness[i] = new_fitness\n\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                else: # replace with best individual\n                    population[i] = population[0].copy()\n                    fitness[i] = fitness[0]\n\n                if self.budget <= 0:\n                    break\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm SelfOrganizingMigratingCauchy scored 0.186 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["437dd58f-7938-43fe-97eb-7180e87662c3"], "operator": null, "metadata": {"aucs": [0.08621058063253406, 0.17746289764511936, 0.22139217431690295, 0.15167649707698294, 0.19508202950212605, 0.15825906240783083, 0.18483727593505261, 0.17574136183838562, 0.1447708231726882, 0.12751148001235213, 0.15246195242471727, 0.2180991393227797, 0.2548416591774998, 0.18879272994889684, 0.1469226978189767, 0.2168206272409623, 0.15678089395818384, 0.19814637012573477, 0.18190953057815518, 0.3886907362040122]}}
{"id": "c77cdeca-bb0e-4946-b729-0f78b70d0a2f", "fitness": 0.0, "name": "ConstrictionCauchyPSO", "description": "A PSO variant that uses a constriction factor to control particle velocities and incorporates a Cauchy mutation on the global best to enhance exploration.", "code": "import numpy as np\n\nclass ConstrictionCauchyPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, constriction_factor=0.72984, cognitive_coeff=2.05, social_coeff=2.05, cauchy_scale=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.constriction_factor = constriction_factor\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.cauchy_scale = cauchy_scale\n\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.constriction_factor * (self.velocity[i] + cognitive_component + social_component)\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n            # Cauchy mutation on the global best position\n            mutation = np.random.standard_cauchy(size=self.dim) * self.cauchy_scale\n            mutated_global_best = self.global_best_position + mutation\n            mutated_global_best = np.clip(mutated_global_best, func.bounds.lb, func.bounds.ub)\n\n            mutated_global_fitness = func(mutated_global_best)\n            self.budget -= 1\n\n            if mutated_global_fitness < self.global_best_fitness:\n                self.global_best_fitness = mutated_global_fitness\n                self.global_best_position = mutated_global_best.copy()\n            \n            for i in range(self.pop_size):\n                population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm ConstrictionCauchyPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6bcf56cd-5b48-46a5-9c48-55f534966206"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "aeba0ba0-368d-430f-9f0c-8c6234d1105f", "fitness": -Infinity, "name": "CovarianceMatrixDE", "description": "Population-based algorithm combining differential evolution with a covariance matrix adaptation strategy for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass CovarianceMatrixDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, learning_rate=0.1):\n        \"\"\"\n        Initialize the Covariance Matrix Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The initial population size. If None, it's set to 10*dim.\n            F (float, optional): The initial mutation factor.\n            CR (float, optional): The initial crossover rate.\n            learning_rate (float, optional): Learning rate for covariance matrix adaptation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.F = F\n        self.CR = CR\n        self.learning_rate = learning_rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.mean = None\n        self.covariance = None\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.mean = np.mean(self.pop, axis=0)\n        self.covariance = np.eye(self.dim) # Identity matrix as initial covariance\n\n    def mutate(self, pop, F):\n        \"\"\"Perform differential mutation.\"\"\"\n        mutated = np.zeros_like(pop)\n        for i in range(len(pop)):\n            idxs = np.random.choice(len(pop), 3, replace=False)\n            a, b, c = pop[idxs]\n            mutated[i] = a + F * (b - c)\n\n            # Sample from multivariate normal distribution using current mean and covariance\n            mutated[i] += np.random.multivariate_normal(np.zeros(self.dim), self.covariance)\n            \n        return mutated\n\n    def crossover(self, pop, mutated, CR):\n        \"\"\"Perform binomial crossover.\"\"\"\n        rand_matrix = np.random.rand(*pop.shape)\n        cross_mask = rand_matrix < CR\n        # Ensure at least one component is crossed over\n        for i in range(len(pop)):\n            j = np.random.randint(self.dim)\n            cross_mask[i, j] = True\n        u = np.where(cross_mask, mutated, pop)\n        return u\n\n    def update_covariance(self, pop, selected_pop):\n        \"\"\"Update the covariance matrix based on selected individuals.\"\"\"\n        delta = selected_pop - self.mean\n        self.mean = (1 - self.learning_rate) * self.mean + self.learning_rate * np.mean(selected_pop, axis=0)\n        self.covariance = (1 - self.learning_rate) * self.covariance + self.learning_rate * np.cov(delta.T)\n\n    def select(self, func, u):\n        \"\"\"Perform selection based on fitness.\"\"\"\n        fitness_u = np.array([func(x) for x in u])\n        self.eval_count += len(u)\n\n        improvements = fitness_u < self.fitness\n        self.pop = np.where(improvements[:, None], u, self.pop)\n        self.fitness = np.where(improvements, fitness_u, self.fitness)\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n        # Update covariance matrix using selected individuals\n        self.update_covariance(self.pop[improvements], self.pop[improvements])\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Covariance Matrix Differential Evolution.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutated = self.mutate(self.pop, self.F)\n\n            # Clip values to respect bounds\n            mutated = np.clip(mutated, func.bounds.lb, func.bounds.ub)\n            \n            u = self.crossover(self.pop, mutated, self.CR)\n\n            # Clip values to respect bounds\n            u = np.clip(u, func.bounds.lb, func.bounds.ub)\n            \n            self.select(func, u)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "An exception occurred: SVD did not converge.", "error": "", "parent_ids": ["741cc2c2-a397-4d1d-b228-acec5144527d"], "operator": null, "metadata": {}}
{"id": "a3906652-b998-46e0-99b2-cfbfbbd8aa86", "fitness": 0.0, "name": "ConstrictionOrthogonalPSO", "description": "A particle swarm optimization variant with a constriction factor to control velocity and a diversity maintenance strategy using orthogonal learning.", "code": "import numpy as np\n\nclass ConstrictionOrthogonalPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, omega=0.729, phi_p=1.49445, phi_g=1.49445, orthogonal_samples=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.omega = omega # constriction factor related\n        self.phi_p = phi_p\n        self.phi_g = phi_g\n        self.orthogonal_samples = orthogonal_samples\n\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity with constriction factor\n                cognitive_component = self.phi_p * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.phi_g * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.omega * (self.velocity[i] + cognitive_component + social_component)\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                \n                population[i] = new_position.copy()\n\n            # Orthogonal learning for diversity maintenance (applied to the worst particle)\n            worst_index = np.argmax(self.personal_best_fitness)\n            orthogonal_matrix = self.latin_hypercube(self.orthogonal_samples, self.dim)\n            orthogonal_positions = self.personal_best_positions[worst_index] + orthogonal_matrix * (func.bounds.ub - func.bounds.lb)\n            orthogonal_positions = np.clip(orthogonal_positions, func.bounds.lb, func.bounds.ub)\n            orthogonal_fitness = np.array([func(x) for x in orthogonal_positions])\n            self.budget -= self.orthogonal_samples\n\n            best_orthogonal_index = np.argmin(orthogonal_fitness)\n\n            if orthogonal_fitness[best_orthogonal_index] < self.personal_best_fitness[worst_index]:\n                 self.personal_best_fitness[worst_index] = orthogonal_fitness[best_orthogonal_index]\n                 self.personal_best_positions[worst_index] = orthogonal_positions[best_orthogonal_index].copy()\n                 population[worst_index] = orthogonal_positions[best_orthogonal_index].copy()\n                 if orthogonal_fitness[best_orthogonal_index] < self.global_best_fitness:\n                     self.global_best_fitness = orthogonal_fitness[best_orthogonal_index]\n                     self.global_best_position = orthogonal_positions[best_orthogonal_index].copy()\n\n\n        return self.global_best_fitness, self.global_best_position\n\n    def latin_hypercube(self, samples, dim):\n        # Generate a Latin Hypercube Sample\n        r = np.random.rand(samples, dim)\n        s = np.zeros((samples, dim))\n        for j in range(dim):\n            idx = np.random.permutation(samples)\n            P = (idx + r[:, j]) / samples\n            s[:, j] = P\n        return s", "configspace": "", "generation": 4, "feedback": "The algorithm ConstrictionOrthogonalPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6bcf56cd-5b48-46a5-9c48-55f534966206"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "02724765-424f-464d-9be1-e654def06794", "fitness": -Infinity, "name": "OrthogonalAdaptiveDE", "description": "An adaptive Differential Evolution strategy that uses orthogonal learning to improve the search efficiency and population diversity.", "code": "import numpy as np\n\nclass OrthogonalAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n\n        self.pop_size_min = 10\n        self.pop_size_max = 100\n        self.levy_exponent = 1.5 #parameter for levy flight\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / (np.abs(v) ** (1 / beta))\n        return step\n\n    def orthogonal_design(self, population, num_levels=3):\n        \"\"\"\n        Generates an orthogonal design matrix for a given population.\n        \"\"\"\n        n = population.shape[0]\n        k = population.shape[1]\n        \n        #L_27(3^13)\n        if k <= 13 and num_levels == 3 and n>= 27:\n            import pyDOE\n            doe = pyDOE.fracfact(\"3 27-1 12-2 24-3\")\n            doe = np.array(doe,dtype=float)\n            doe[doe == -1] = 0\n            doe[doe == 0] = 1\n            doe[doe == 1] = 2\n            doe = doe[:n, :k]\n            return doe\n        \n        # If the dimension is too large for a simple orthogonal array, return None\n        return None\n        \n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        best_fitness = fitness[best_index].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n\n                mutant = x_r1 + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                #Levy Flight\n                levy_steps = self.levy_flight(self.dim)\n                mutant = mutant + 0.01 * levy_steps * (best_position - mutant)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial_vector = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                self.budget -= 1\n                if f < fitness[i]:\n                    new_population[i] = trial_vector.copy()\n                    new_fitness[i] = f\n                    if f < best_fitness:\n                        best_fitness = f\n                        best_position = trial_vector.copy()\n                else:\n                    new_population[i] = population[i].copy()\n                    new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            population = new_population.copy()\n            fitness = new_fitness.copy()\n\n            # Orthogonal Learning\n            if generation % 5 == 0:\n                orthogonal_matrix = self.orthogonal_design(population)\n                if orthogonal_matrix is not None:\n                    for i in range(self.pop_size):\n                         #Create a trial point based on orthogonal design\n                        trial_point = np.zeros(self.dim)\n                        for j in range(self.dim):\n                            level = int(orthogonal_matrix[i,j])\n                            \n                            #Find other individuals with a similar level on this dimension\n                            similar_individuals_indices = np.where(orthogonal_matrix[:,j] == level)[0]\n                            \n                            if len(similar_individuals_indices) > 0:\n                                #Average those individuals on the jth dimension\n                                trial_point[j] = np.mean(population[similar_individuals_indices,j])\n                            else:\n                                trial_point[j] = population[i,j] #No similar individual found\n\n                        trial_point = np.clip(trial_point, func.bounds.lb, func.bounds.ub)\n\n                        f = func(trial_point)\n                        self.budget -= 1\n                        \n                        if f < fitness[i]:\n                            population[i] = trial_point.copy()\n                            fitness[i] = f\n                            if f < best_fitness:\n                                best_fitness = f\n                                best_position = trial_point.copy()\n\n            # Adjust population size\n            if generation % 10 == 0:\n                fitness_std = np.std(fitness)\n                if fitness_std > 1e-6:  # Avoid division by zero\n                    pop_size_factor = np.tanh(1.0 / fitness_std)\n                    self.pop_size = int(self.pop_size_min + (self.pop_size_max - self.pop_size_min) * pop_size_factor)\n                    self.pop_size = max(self.pop_size_min, min(self.pop_size, self.pop_size_max))\n\n                    # Resize population if necessary\n                    if self.pop_size != population.shape[0]:\n                        if self.pop_size < population.shape[0]:\n                             # Reduce the population, keep the best individuals\n                            indices = np.argsort(fitness)[:self.pop_size]\n                            population = population[indices]\n                            fitness = fitness[indices]\n                        else:\n                             # Increase population, initialize new individuals randomly\n                            num_new_individuals = self.pop_size - population.shape[0]\n                            new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new_individuals, self.dim))\n                            new_fitness_values = np.array([func(x) for x in new_individuals])\n                            self.budget -= num_new_individuals\n\n                            population = np.vstack((population, new_individuals))\n                            fitness = np.hstack((fitness, new_fitness_values))\n                            \n            self.pop_size = population.shape[0] #update pop_size\n\n            if self.budget <= 0:\n                break\n\n        return best_fitness, best_position", "configspace": "", "generation": 4, "feedback": "An exception occurred: No module named 'pyDOE'.", "error": "", "parent_ids": ["4f01b838-3dec-48ed-8fb1-b07b75d69848"], "operator": null, "metadata": {}}
{"id": "13646f56-9d29-4538-8c1c-d076625370ad", "fitness": 0.43360617197928847, "name": "ConstrictionCauchyPSO", "description": "A PSO variant with a constriction factor to control velocity and exploration, combined with a Cauchy mutation for diversity.", "code": "import numpy as np\n\nclass ConstrictionCauchyPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, constriction_factor=0.72984, cognitive_coeff=2.05, social_coeff=2.05, cauchy_scale=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.constriction_factor = constriction_factor\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.cauchy_scale = cauchy_scale\n\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity with constriction factor\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.constriction_factor * (self.velocity[i] + cognitive_component + social_component)\n\n                # Cauchy Mutation to the velocity\n                mutation = np.random.standard_cauchy(size=self.dim) * self.cauchy_scale\n                self.velocity[i] += mutation\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                \n                population[i] = new_position.copy()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm ConstrictionCauchyPSO scored 0.434 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6bcf56cd-5b48-46a5-9c48-55f534966206"], "operator": null, "metadata": {"aucs": [0.2094757393231309, 0.18846244443277826, 0.44743524699477244, 0.4914454262751824, 0.4038104956237194, 0.47711867471109204, 0.32076760958043515, 0.38322516790385386, 0.3841821183401595, 0.17175663100262917, 0.8093246757099879, 0.9995726205354497, 0.23410943769521741, 0.37065114679736344, 0.5873895618351748, 0.5202533890367343, 0.370699526696438, 0.5805578386763183, 0.2028026218426534, 0.5190830665726778]}}
{"id": "785a36b5-216b-4e8f-bcfd-468909f40a80", "fitness": 0.7037859461879813, "name": "AdaptiveArchiveDE", "description": "An adaptive differential evolution algorithm that utilizes a combined mutation strategy (DE/rand/1 and DE/current-to-best/1) with probabilistic switching and an archive for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveArchiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, archive_size=50):\n        \"\"\"\n        Initialize the Adaptive Archive Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The population size. If None, set to 10*dim.\n            F (float, optional): The mutation factor.\n            CR (float, optional): The crossover rate.\n            archive_size (int, optional): The size of the archive.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.F = F\n        self.CR = CR\n        self.archive_size = archive_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.archive = []\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, pop, F, best):\n        \"\"\"Perform mutation using a combination of DE/rand/1 and DE/current-to-best/1.\"\"\"\n        mutated = np.zeros_like(pop)\n        for i in range(len(pop)):\n            if np.random.rand() < 0.5:  # Probabilistically switch between mutation strategies\n                # DE/rand/1\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[indices]\n                mutated[i] = pop[i] + F * (x_r1 - x_r2) + F * (x_r3 - pop[i])\n            else:\n                # DE/current-to-best/1\n                indices = np.random.choice(len(pop), 2, replace=False)\n                x_r1, x_r2 = pop[indices]\n                mutated[i] = pop[i] + F * (best - pop[i]) + F * (x_r1 - x_r2)\n        return mutated\n\n    def crossover(self, pop, mutated, CR):\n        \"\"\"Perform binomial crossover.\"\"\"\n        rand_matrix = np.random.rand(*pop.shape)\n        cross_mask = rand_matrix < CR\n        # Ensure at least one component is crossed over\n        for i in range(len(pop)):\n            j = np.random.randint(self.dim)\n            cross_mask[i, j] = True\n        u = np.where(cross_mask, mutated, pop)\n        return u\n\n    def select(self, func, u):\n        \"\"\"Perform selection and update the archive.\"\"\"\n        fitness_u = np.array([func(x) for x in u])\n        self.eval_count += len(u)\n\n        for i in range(len(u)):\n            if fitness_u[i] < self.fitness[i]:\n                # Add replaced individuals to the archive\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.pop[i].copy())\n                else:\n                    # Replace a random element in the archive\n                    idx = np.random.randint(self.archive_size)\n                    self.archive[idx] = self.pop[i].copy()\n\n                self.pop[i] = u[i]\n                self.fitness[i] = fitness_u[i]\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Adaptive Archive Differential Evolution.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            best = self.pop[np.argmin(self.fitness)]\n            mutated = self.mutate(self.pop, self.F, best)\n\n            # Clip values to respect bounds\n            mutated = np.clip(mutated, func.bounds.lb, func.bounds.ub)\n\n            u = self.crossover(self.pop, mutated, self.CR)\n\n            # Clip values to respect bounds\n            u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n            self.select(func, u)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveArchiveDE scored 0.704 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["741cc2c2-a397-4d1d-b228-acec5144527d"], "operator": null, "metadata": {"aucs": [0.3712535817765533, 0.8094997067570877, 0.802376996788063, 0.9139086316933169, 0.262006437450645, 0.8566422481605108, 0.7183810452429777, 0.7824459825381818, 0.8261309665214732, 0.4149325430325508, 0.9179260168396036, 0.998962886719278, 0.7613692421694276, 0.7758760475506324, 0.5857217338692386, 0.8422391043441484, 0.7613349084430546, 0.895473523606244, 0.27382223068153555, 0.5054150895751045]}}
{"id": "824de54f-0de3-4d46-9a65-3985523150db", "fitness": 0.5140881581337979, "name": "PowerLawOrthogonalDE", "description": "A differential evolution strategy that leverages a power law distribution for generating mutation factors and incorporates orthogonal learning to enhance population diversity.", "code": "import numpy as np\n\nclass PowerLawOrthogonalDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F_mean=0.5, CR=0.9, power_law_exponent=2.0, orthogonal_component=0.1):\n        \"\"\"\n        Initialize the Power Law Orthogonal Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The initial population size. If None, it's set to 10*dim.\n            F_mean (float, optional): The mean mutation factor.\n            CR (float, optional): The initial crossover rate.\n            power_law_exponent (float, optional): Exponent for the power law distribution of F.\n            orthogonal_component (float, optional): Weight of the orthogonal learning component.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.F_mean = F_mean\n        self.CR = CR\n        self.power_law_exponent = power_law_exponent\n        self.orthogonal_component = orthogonal_component\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def generate_power_law_mutation_factor(self):\n        \"\"\"Generate mutation factor F from a power law distribution.\"\"\"\n        u = np.random.rand()\n        F = (u ** (-1.0 / (self.power_law_exponent - 1.0))) * self.F_mean\n        return min(F, 1.0)  # Clip to [0, 1]\n\n    def orthogonal_learning(self, pop):\n         \"\"\"Perform orthogonal learning to generate diverse individuals.\"\"\"\n         centroid = np.mean(pop, axis=0)\n         ortho_vector = np.random.normal(0, 1, size=self.dim)\n         ortho_vector /= np.linalg.norm(ortho_vector)  # Normalize\n         new_individual = centroid + self.orthogonal_component * ortho_vector * np.std(pop)\n         return new_individual\n    \n    def mutate(self, pop):\n        \"\"\"Perform differential mutation with power law distributed F and orthogonal learning.\"\"\"\n        mutated = np.zeros_like(pop)\n        for i in range(len(pop)):\n            F = self.generate_power_law_mutation_factor()\n            idxs = np.random.choice(len(pop), 3, replace=False)\n            a, b, c = pop[idxs]\n            mutated[i] = a + F * (b - c)\n\n        # Incorporate orthogonal learning\n        new_individual = self.orthogonal_learning(pop)\n        mutated[np.random.randint(len(pop))] = new_individual  # Replace a random individual\n\n        return mutated\n\n    def crossover(self, pop, mutated, CR):\n        \"\"\"Perform binomial crossover.\"\"\"\n        rand_matrix = np.random.rand(*pop.shape)\n        cross_mask = rand_matrix < CR\n        # Ensure at least one component is crossed over\n        for i in range(len(pop)):\n            j = np.random.randint(self.dim)\n            cross_mask[i, j] = True\n        u = np.where(cross_mask, mutated, pop)\n        return u\n\n    def select(self, func, u):\n        \"\"\"Perform selection based on fitness.\"\"\"\n        fitness_u = np.array([func(x) for x in u])\n        self.eval_count += len(u)\n\n        improvements = fitness_u < self.fitness\n        self.pop = np.where(improvements[:, None], u, self.pop)\n        self.fitness = np.where(improvements, fitness_u, self.fitness)\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Power Law Orthogonal Differential Evolution.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutated = self.mutate(self.pop)\n            \n            # Clip values to respect bounds\n            mutated = np.clip(mutated, func.bounds.lb, func.bounds.ub)\n            \n            u = self.crossover(self.pop, mutated, self.CR)\n            \n            # Clip values to respect bounds\n            u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n            self.select(func, u)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm PowerLawOrthogonalDE scored 0.514 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["741cc2c2-a397-4d1d-b228-acec5144527d"], "operator": null, "metadata": {"aucs": [0.18235221171654048, 0.38459255648767965, 0.4628116080687289, 0.7637775141080754, 0.4829744811435064, 0.6018137439461255, 0.3403311084867374, 0.4434665136745479, 0.4738552279321233, 0.3705546572533812, 0.7296599232637577, 0.9978895633377264, 0.4119233134281476, 0.4470127649993554, 0.8648595825851211, 0.5480162819113462, 0.3960549106728485, 0.6813197271280449, 0.20794229165358025, 0.4905551808785832]}}
{"id": "aa5fd3cd-c8a7-4035-898d-f1a06b1f2107", "fitness": 0.3051768396487465, "name": "MirroredAdaptiveDE", "description": "A self-adaptive differential evolution algorithm with a mirrored sampling strategy and dynamic parameter adaptation based on successful and unsuccessful search steps.", "code": "import numpy as np\n\nclass MirroredAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, F_decay=0.99, Cr_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.F_decay = F_decay\n        self.Cr_decay = Cr_decay\n        self.success_F = []\n        self.success_Cr = []\n        self.memory_size = 10\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        best_fitness = fitness[best_index].copy()\n        \n        archive = []\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mirrored Sampling\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n\n                mutant = population[i] + self.F * (x_r1 - x_r2 + x_r3 - population[i]) # Mirrored sampling\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial_vector = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                self.budget -= 1\n                \n                if f < fitness[i]:\n                    # Successful update\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n                    if len(self.success_F) > self.memory_size:\n                        self.success_F.pop(0)\n                        self.success_Cr.pop(0)\n\n                    population[i] = trial_vector.copy()\n                    fitness[i] = f\n                    if f < best_fitness:\n                        best_fitness = f\n                        best_position = trial_vector.copy()\n                else:\n                    # Unsuccessful update, adapt parameters\n                    self.F *= self.F_decay\n                    self.Cr *= self.Cr_decay\n                    if self.F < 0.05:\n                        self.F = 0.1\n                    if self.Cr < 0.05:\n                        self.Cr = 0.1\n\n                if self.budget <= 0:\n                    break\n\n            # Adaptive Parameter Control (after each generation)\n            if self.success_F:\n                self.F = np.mean(self.success_F)\n                self.Cr = np.mean(self.success_Cr)\n                self.success_F = []\n                self.success_Cr = []\n\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 0.9)\n\n        return best_fitness, best_position", "configspace": "", "generation": 4, "feedback": "The algorithm MirroredAdaptiveDE scored 0.305 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4f01b838-3dec-48ed-8fb1-b07b75d69848"], "operator": null, "metadata": {"aucs": [0.10202315265311424, 0.198329060855432, 0.31755034462157206, 0.24867483311169158, 0.1937839101465445, 0.18395355588522, 0.27685726065928773, 0.21830477483586597, 0.21169113313328403, 0.1718024322534475, 0.24479024083364775, 0.9868265748807091, 0.2737508133446005, 0.22423364749262087, 0.6950803363952265, 0.2947852754496155, 0.26900702341214877, 0.3633891845939503, 0.18081821677860366, 0.44788502163834676]}}
{"id": "fc87b61e-d4d7-4a09-9064-659a32b6214d", "fitness": 0.3466978410864835, "name": "AdaptiveConstrictionPSO", "description": "A particle swarm optimization variant with a constriction factor and a self-adaptive learning strategy based on the success rate of particles.", "code": "import numpy as np\n\nclass AdaptiveConstrictionPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.2, cognitive_coeff=2.05, social_coeff=2.05, constriction_factor=0.72984, success_rate_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.constriction_factor = constriction_factor\n        self.success_rate_memory = success_rate_memory\n\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.generation = 0\n        self.success_rates = np.zeros(self.pop_size)\n        self.success_history = np.zeros((self.pop_size, self.success_rate_memory))\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            # Adaptive Inertia Weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (self.generation / (self.budget // self.pop_size + self.generation + 1e-6))\n            \n            for i in range(self.pop_size):\n                old_fitness = fitness[i]\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.constriction_factor * (inertia * self.velocity[i] + cognitive_component + social_component)\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n                    self.success_history[i] = np.roll(self.success_history[i], 1)\n                    self.success_history[i][0] = 1 # Mark success\n                    \n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                else:\n                    self.success_history[i] = np.roll(self.success_history[i], 1)\n                    self.success_history[i][0] = 0 # Mark failure\n                \n                fitness[i] = new_fitness\n                population[i] = new_position.copy()\n            self.generation += 1\n            self.success_rates = np.mean(self.success_history, axis=1)\n            # Adaptive Adjustment of cognitive/social coefficients based on success rate\n            for i in range(self.pop_size):\n                if self.success_rates[i] > 0.5:  # High success rate\n                    self.cognitive_coeff = min(self.cognitive_coeff + 0.01, 2.5)  # Increase exploration slightly\n                    self.social_coeff = max(self.social_coeff - 0.01, 1.5) #decrease exploitation\n                else:  # Low success rate\n                    self.cognitive_coeff = max(self.cognitive_coeff - 0.01, 1.5)  # Increase exploitation slightly\n                    self.social_coeff = min(self.social_coeff + 0.01, 2.5)  # increase exploration\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveConstrictionPSO scored 0.347 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6bcf56cd-5b48-46a5-9c48-55f534966206"], "operator": null, "metadata": {"aucs": [0.13020962909540157, 0.1637211741092438, 0.5199105846326629, 0.1722010743384933, 0.2634499195756924, 0.27546776678798957, 0.2589316097996137, 0.3839948815447356, 0.3266952161530723, 0.19278640618366993, 0.5615678945942544, 0.9987596674053812, 0.2274565274409288, 0.23831181774463783, 0.5827188001622151, 0.3581256455371705, 0.34239318762996107, 0.29080958512748456, 0.21276697711460069, 0.43367845675246075]}}
{"id": "5fb0edee-c4e6-4d0f-865c-f61815819ece", "fitness": 0.190852504473978, "name": "CMAES_Archive_DE", "description": "A differential evolution strategy with a fitness-based archive and a covariance matrix adaptation strategy to guide mutation.", "code": "import numpy as np\n\nclass CMAES_Archive_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, archive_size=100, initial_sigma=0.1):\n        \"\"\"\n        Initialize the CMA-ES Archive Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The initial population size. If None, it's set to 4 + int(3 * np.log(dim)).\n            archive_size (int): The size of the archive to store successful solutions.\n            initial_sigma (float): Initial step size for CMA-ES.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.archive_size = archive_size\n        self.initial_sigma = initial_sigma\n        self.mean = None\n        self.sigma = None\n        self.C = None  # Covariance matrix\n        self.pc = None # Evolution path for C\n        self.ps = None # Evolution path for sigma\n        self.archive = []\n        self.archive_fitness = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.c_sigma = None\n        self.d_sigma = None\n        self.eigenevaluations = None\n\n    def initialize(self, func):\n        \"\"\"Initialize the population, mean, covariance matrix, and step size.\"\"\"\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.sigma = self.initial_sigma\n        self.C = np.eye(self.dim)  # Identity matrix as initial covariance\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        self.c_sigma = (np.sqrt(self.pop_size) / np.linalg.norm(self.ps)) if np.linalg.norm(self.ps) > 0 else 1.0\n        self.d_sigma = 1 + 2 * np.max([0, (np.linalg.norm(self.ps) / np.sqrt(self.dim) -1)]) + self.c_sigma\n        \n        self.pop = np.random.multivariate_normal(self.mean, self.sigma**2 * self.C, size=self.pop_size)\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def sample_population(self, func):\n        \"\"\"Sample a new population using CMA-ES.\"\"\"\n        z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n        self.pop = self.mean + self.sigma * z\n        self.pop = np.clip(self.pop, func.bounds.lb, func.bounds.ub)\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n\n\n    def update_parameters(self):\n        \"\"\"Update CMA-ES parameters based on the performance of the population.\"\"\"\n        # Sort the population based on fitness\n        sorted_indices = np.argsort(self.fitness)\n        elite_indices = sorted_indices[:self.pop_size // 2]\n        elite_pop = self.pop[elite_indices]\n\n        # Calculate the new mean\n        new_mean = np.mean(elite_pop, axis=0)\n        \n        #Update evolution paths\n        self.ps = 0.8 * self.ps + np.sqrt(0.2 * (2 - 0.2)) * (new_mean - self.mean) / self.sigma\n        self.pc = 0.8 * self.pc + np.sqrt(0.2 * (2 - 0.2)) * ((new_mean - self.mean) / self.sigma) @ np.linalg.inv(np.linalg.cholesky(self.C))\n        \n        #Update covariance matrix\n        self.C = 0.8 * self.C + 0.2 * np.outer(self.pc, self.pc) + 0.02 * np.eye(self.dim)\n\n        # Update step size (sigma)\n        self.sigma *= np.exp(0.2/0.5 * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n        \n        self.mean = new_mean\n\n    def archive_solution(self, x, fitness):\n        \"\"\"Archive successful solutions.\"\"\"\n        if len(self.archive) < self.archive_size:\n            self.archive.append(x)\n            self.archive_fitness.append(fitness)\n        else:\n            max_fitness_index = np.argmax(self.archive_fitness)\n            if fitness < self.archive_fitness[max_fitness_index]:\n                self.archive[max_fitness_index] = x\n                self.archive_fitness[max_fitness_index] = fitness\n\n    def differential_mutation(self):\n         \"\"\"Perform differential mutation using solutions from the archive.\"\"\"\n         if len(self.archive) < 3:\n             return self.pop #Not enough for DE\n         \n         for i in range(self.pop_size):\n             # Sample three indices from the archive\n             indices = np.random.choice(len(self.archive), 3, replace=False)\n             x_r1, x_r2, x_r3 = self.archive[indices[0]], self.archive[indices[1]], self.archive[indices[2]]\n             \n             #Perform mutation\n             mutated_vector = self.pop[i] + 0.5 * (x_r1 - x_r2 + x_r3 - self.pop[i])\n             mutated_vector = np.clip(mutated_vector, -5, 5) #Clip\n             self.pop[i] = mutated_vector #replace pop\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using CMA-ES with Archive and Differential Evolution.\"\"\"\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            self.differential_mutation()\n            self.sample_population(func)\n\n            # Update best solution\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.pop[best_index]\n                self.archive_solution(self.x_opt, self.f_opt)\n            else:\n                self.archive_solution(self.pop[best_index], self.fitness[best_index]) #Archive other potentially good solutions\n\n            self.update_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm CMAES_Archive_DE scored 0.191 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["741cc2c2-a397-4d1d-b228-acec5144527d"], "operator": null, "metadata": {"aucs": [9.999999999998899e-05, 0.17165535976844348, 0.1345759168011591, 0.09966711974416487, 0.06150344874793823, 0.10812100674077751, 0.16564152492629813, 0.19908018772500435, 0.14536970210124622, 0.07721637307202267, 0.18423080020644456, 0.1822596503976952, 0.21292533329496222, 0.14862764477437973, 0.32397098909181454, 0.22782209058542036, 0.19175073693708022, 0.8984846676973323, 0.12459016183216864, 0.1594573750352074]}}
{"id": "ad5ba097-a7d4-47d3-bace-deb83fef6543", "fitness": 0.4666520398014769, "name": "AdaptiveConstrictionPSO", "description": "An adaptive PSO variant with a constriction factor, velocity clamping, and a mutation strategy based on the difference between the global best and a randomly selected particle.", "code": "import numpy as np\n\nclass AdaptiveConstrictionPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, velocity_clamp=0.5, mutation_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.mutation_rate = mutation_rate\n\n        self.inertia = 1.0  # Fixed inertia for simplicity\n        self.constriction_factor = self.calculate_constriction_factor()\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def calculate_constriction_factor(self):\n        phi = self.cognitive_coeff + self.social_coeff\n        if phi <= 4:\n            return 1.0\n        return 2 / np.abs(2 - phi - np.sqrt(phi**2 - 4 * phi))\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.constriction_factor * (self.inertia * self.velocity[i] + cognitive_component + social_component)\n                self.velocity[i] = np.clip(self.velocity[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                \n                # Mutation based on difference between global best and a random particle\n                if np.random.rand() < self.mutation_rate:\n                    random_index = np.random.randint(self.pop_size)\n                    new_position += 0.01 * (self.global_best_position - population[random_index])\n\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveConstrictionPSO scored 0.467 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6bcf56cd-5b48-46a5-9c48-55f534966206"], "operator": null, "metadata": {"aucs": [0.13344910254151943, 0.19780402723677992, 0.7276516553111728, 0.26332918638312575, 0.2817643998359144, 0.887775646235012, 0.24818700117456316, 0.4514167269008633, 0.23827146841055402, 0.1794827209302302, 0.5187026747894445, 0.9835829221146714, 0.2526384358002699, 0.36074532852556385, 0.9537353401480956, 0.6739101015450757, 0.40010810593054147, 0.9134539439317626, 0.1989545288558977, 0.46807747942848077]}}
{"id": "2df0e067-caaf-434f-ac31-7ae6391e592b", "fitness": 0.47052857722421504, "name": "SOM_DE", "description": "Combines differential evolution with a self-organizing map to adapt the mutation strategy based on the landscape characteristics.", "code": "import numpy as np\n\nclass SOM_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, som_grid_size=5):\n        \"\"\"\n        Initialize the Self-Organizing Map Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The initial population size. If None, it's set to 10*dim.\n            F (float, optional): The initial mutation factor.\n            CR (float, optional): The initial crossover rate.\n            som_grid_size (int): Size of the SOM grid (som_grid_size x som_grid_size).\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.som_grid_size = som_grid_size\n        self.som = np.random.rand(som_grid_size, som_grid_size, dim)  # SOM nodes\n        self.som_learning_rate = 0.1\n        self.som_radius = som_grid_size // 2\n\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def find_closest_som_node(self, individual):\n        \"\"\"Find the closest SOM node to an individual.\"\"\"\n        distances = np.sum((self.som - individual)**2, axis=2)\n        row, col = np.unravel_index(np.argmin(distances), distances.shape)\n        return row, col\n\n    def update_som(self, individual, row, col):\n        \"\"\"Update the SOM based on the winning node and its neighbors.\"\"\"\n        for i in range(self.som_grid_size):\n            for j in range(self.som_grid_size):\n                distance = np.sqrt((i - row)**2 + (j - col)**2)\n                if distance <= self.som_radius:\n                    influence = np.exp(-distance**2 / (2 * self.som_radius**2))\n                    self.som[i, j] += self.som_learning_rate * influence * (individual - self.som[i, j])\n\n    def mutate(self, pop, F, func):\n        \"\"\"Perform differential mutation with SOM-guided parameter adaptation.\"\"\"\n        mutated = np.zeros_like(pop)\n        for i in range(len(pop)):\n            # Select three random parents\n            idxs = np.random.choice(len(pop), 3, replace=False)\n            a, b, c = pop[idxs]\n\n            # Find the closest SOM node to the current individual\n            row, col = self.find_closest_som_node(pop[i])\n\n            # Adapt mutation factor based on SOM node values (example adaptation strategy)\n            F_adapted = F * (1 + 0.5 * self.som[row, col, 0])  # Modify F based on SOM\n            F_adapted = np.clip(F_adapted, 0.1, 1.0) #Clip F\n\n            mutated[i] = a + F_adapted * (b - c)\n\n            # Clip values to respect bounds\n            mutated[i] = np.clip(mutated[i], func.bounds.lb, func.bounds.ub)\n\n        return mutated\n\n    def crossover(self, pop, mutated, CR):\n        \"\"\"Perform binomial crossover.\"\"\"\n        rand_matrix = np.random.rand(*pop.shape)\n        cross_mask = rand_matrix < CR\n        # Ensure at least one component is crossed over\n        for i in range(len(pop)):\n            j = np.random.randint(self.dim)\n            cross_mask[i, j] = True\n        u = np.where(cross_mask, mutated, pop)\n        return u\n\n    def select(self, func, u):\n        \"\"\"Perform selection based on fitness and update SOM.\"\"\"\n        fitness_u = np.array([func(x) for x in u])\n        self.eval_count += len(u)\n\n        for i in range(len(u)):\n            if fitness_u[i] < self.fitness[i]:\n                # Update population and fitness\n                self.fitness[i] = fitness_u[i]\n                self.pop[i] = u[i]\n\n                # Update SOM with the improved individual\n                row, col = self.find_closest_som_node(u[i])\n                self.update_som(u[i], row, col)\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using SOM-guided Differential Evolution.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutated = self.mutate(self.pop, self.F, func)\n            u = self.crossover(self.pop, mutated, self.CR)\n\n            # Clip values to respect bounds\n            u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n            self.select(func, u)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm SOM_DE scored 0.471 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["741cc2c2-a397-4d1d-b228-acec5144527d"], "operator": null, "metadata": {"aucs": [0.1977347881456033, 0.6059663000116859, 0.5341976943348328, 0.598886079315531, 0.31133772598999343, 0.3191961860000071, 0.6724276316178014, 0.3816078596914545, 0.324043767281722, 0.24565938586594083, 0.49026844320235297, 0.9944577732601493, 0.39185025328367606, 0.35274902938933794, 0.6679121980403528, 0.44713659321497756, 0.3243745621762424, 0.843751991648211, 0.2136884026415683, 0.49332487937285974]}}
{"id": "66accfeb-8b0c-4904-86bf-613dabf284a0", "fitness": 0.0, "name": "AdaptiveCauchyPSO", "description": "An adaptive PSO variant with dynamic inertia and a Cauchy mutation operator applied to the global best particle to enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveCauchyPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, velocity_clamp=0.5, initial_inertia=0.9, inertia_decay=0.995, cauchy_scale=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.inertia = initial_inertia\n        self.inertia_decay = inertia_decay\n        self.cauchy_scale = cauchy_scale\n\n        self.constriction_factor = self.calculate_constriction_factor()\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def calculate_constriction_factor(self):\n        phi = self.cognitive_coeff + self.social_coeff\n        if phi <= 4:\n            return 1.0\n        return 2 / np.abs(2 - phi - np.sqrt(phi**2 - 4 * phi))\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.constriction_factor * (self.inertia * self.velocity[i] + cognitive_component + social_component)\n                self.velocity[i] = np.clip(self.velocity[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n            \n            # Cauchy mutation on the global best position\n            cauchy_noise = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n            mutated_global_best = self.global_best_position + cauchy_noise\n            mutated_global_best = np.clip(mutated_global_best, func.bounds.lb, func.bounds.ub)\n\n            mutated_fitness = func(mutated_global_best)\n            self.budget -= 1\n            \n            if mutated_fitness < self.global_best_fitness:\n                self.global_best_fitness = mutated_fitness\n                self.global_best_position = mutated_global_best.copy()\n\n            # Update inertia\n            self.inertia *= self.inertia_decay\n            self.inertia = max(0.4, self.inertia)\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveCauchyPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ad5ba097-a7d4-47d3-bace-deb83fef6543"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "897d2574-c0cd-4319-a78d-0a23ae5bc60e", "fitness": 0.0, "name": "DynamicOrthogonalPSO", "description": "A PSO variant with dynamic parameter adaptation using success history and a novel diversity maintenance strategy based on orthogonal opposition.", "code": "import numpy as np\n\nclass DynamicOrthogonalPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, velocity_clamp=0.5, inertia_max=0.9, inertia_min=0.4, opposition_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.opposition_rate = opposition_rate\n\n        self.inertia = self.inertia_max  # Initialize inertia\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n        self.success_history_inertia = []\n\n    def update_inertia(self):\n        if len(self.success_history_inertia) > 5:\n            # Calculate the average success rate over the last 5 iterations\n            success_rate = np.mean(self.success_history_inertia[-5:])\n            # Linearly map success rate to inertia\n            self.inertia = self.inertia_min + (self.inertia_max - self.inertia_min) * (1 - success_rate)\n        else:\n            self.inertia = (self.inertia_max + self.inertia_min) / 2\n\n    def orthogonal_opposition(self, position, bounds):\n        midpoint = 0.5 * (bounds.lb + bounds.ub)\n        opposite_position = midpoint + (midpoint - position)\n        opposite_position = np.clip(opposite_position, bounds.lb, bounds.ub)\n        return opposite_position\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            num_improvements = 0\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n                self.velocity[i] = np.clip(self.velocity[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                \n                # Orthogonal opposition-based learning\n                if np.random.rand() < self.opposition_rate:\n                    opposite_position = self.orthogonal_opposition(new_position, func.bounds)\n                    opposite_fitness = func(opposite_position)\n                    self.budget -= 1\n                    if opposite_fitness < func(new_position):\n                        new_position = opposite_position\n                        # We dont have to recompute the fitness here, we already have it\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n                    num_improvements += 1\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n            \n            self.success_history_inertia.append(num_improvements / self.pop_size)  # Record success rate\n            self.update_inertia() # Adapt inertia based on success history\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm DynamicOrthogonalPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ad5ba097-a7d4-47d3-bace-deb83fef6543"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "10e13cf8-8f4d-4592-860e-8073cf8ae364", "fitness": -Infinity, "name": "SelfAdaptiveDE_LocalSearch", "description": "A differential evolution algorithm with a self-adaptive mutation strategy and a local search phase utilizing a Nelder-Mead simplex.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SelfAdaptiveDE_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F_init=0.5, CR_init=0.9, local_search_frequency=100):\n        \"\"\"\n        Initialize the Self-Adaptive Differential Evolution with Local Search algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The initial population size. If None, it's set to 10*dim.\n            F_init (float, optional): Initial mutation factor.\n            CR_init (float, optional): Initial crossover rate.\n            local_search_frequency (int, optional): How often local search is applied (every n iterations).\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.F = np.full(self.pop_size, F_init)\n        self.CR = np.full(self.pop_size, CR_init)\n        self.local_search_frequency = local_search_frequency\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.generation = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, pop, func):\n        \"\"\"Perform differential mutation with self-adaptive F.\"\"\"\n        mutated = np.zeros_like(pop)\n        for i in range(len(pop)):\n            idxs = np.random.choice(len(pop), 3, replace=False)\n            a, b, c = pop[idxs]\n            mutated[i] = a + self.F[i] * (b - c)\n            \n            # Clip to bounds\n            mutated[i] = np.clip(mutated[i], func.bounds.lb, func.bounds.ub)\n            \n            # Adapt F (simple adaptation)\n            if np.random.rand() < 0.1: # 10% chance to adapt F\n                self.F[i] = np.random.normal(0.5, 0.3) # N(0.5, 0.3)\n                self.F[i] = np.clip(self.F[i], 0.1, 1.0) # Clip to [0.1, 1]\n\n        return mutated\n\n    def crossover(self, pop, mutated):\n        \"\"\"Perform binomial crossover with self-adaptive CR.\"\"\"\n        rand_matrix = np.random.rand(*pop.shape)\n        cross_mask = rand_matrix < self.CR[:, None]\n        # Ensure at least one component is crossed over\n        for i in range(len(pop)):\n            j = np.random.randint(self.dim)\n            cross_mask[i, j] = True\n        u = np.where(cross_mask, mutated, pop)\n        \n        # Adapt CR (simple adaptation)\n        for i in range(len(pop)):\n            if np.random.rand() < 0.1: # 10% chance to adapt CR\n                self.CR[i] = np.random.normal(0.9, 0.2) # N(0.9, 0.2)\n                self.CR[i] = np.clip(self.CR[i], 0.1, 1.0) # Clip to [0.1, 1]\n        \n        return u\n\n    def select(self, func, u):\n        \"\"\"Perform selection based on fitness.\"\"\"\n        fitness_u = np.array([func(x) for x in u])\n        self.eval_count += len(u)\n\n        improvements = fitness_u < self.fitness\n        self.pop = np.where(improvements[:, None], u, self.pop)\n        self.fitness = np.where(improvements, fitness_u, self.fitness)\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n    def local_search(self, func):\n        \"\"\"Apply Nelder-Mead local search to the best individual.\"\"\"\n        best_index = np.argmin(self.fitness)\n        x_best = self.pop[best_index].copy()\n        \n        bounds = [(func.bounds.lb, func.bounds.ub)] * self.dim\n        \n        res = minimize(func, x_best, method='Nelder-Mead', bounds=bounds, options={'maxfev': self.budget - self.eval_count if self.budget > self.eval_count else 1})  # Limit function evaluations\n\n        if res.fun < self.f_opt:\n            self.f_opt = res.fun\n            self.x_opt = res.x\n            self.pop[best_index] = res.x\n            self.fitness[best_index] = res.fun\n        \n        self.eval_count += res.nfev\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Self-Adaptive DE with Local Search.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutated = self.mutate(self.pop, func)\n            u = self.crossover(self.pop, mutated)\n            self.select(func, u)\n            \n            if self.generation % self.local_search_frequency == 0:\n                self.local_search(func)\n            \n            self.generation += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["824de54f-0de3-4d46-9a65-3985523150db"], "operator": null, "metadata": {}}
{"id": "9c2dab66-b19f-495e-a465-ccff47be7447", "fitness": 0.0, "name": "HybridAdaptivePSO", "description": "Hybrid PSO with adaptive exploration-exploitation balance using a sigmoid function and dynamic inertia weight, incorporating orthogonal learning for enhanced diversity.", "code": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, velocity_clamp=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.inertia_max = 0.9\n        self.inertia_min = 0.2\n        self.current_evaluations = 0  # Track function evaluations\n\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def calculate_inertia_weight(self):\n        # Dynamic inertia weight adaptation using sigmoid function\n        progress = self.current_evaluations / self.budget\n        inertia = self.inertia_max - (self.inertia_max - self.inertia_min) / (1 + np.exp(10 * (progress - 0.5)))\n        return inertia\n\n    def orthogonal_learning(self, population):\n        # Perform orthogonal learning to generate new candidate solutions\n        basis_vectors = np.random.randn(self.dim, self.dim)  # Generate a random basis\n        q, r = np.linalg.qr(basis_vectors)  # Orthogonalize the basis\n\n        # Create new solutions by projecting existing ones onto the basis\n        new_population = np.zeros_like(population)\n        for i in range(self.pop_size):\n            projection = np.dot(population[i], q)\n            new_population[i] = np.dot(projection, q.T)\n\n        return new_population\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.current_evaluations += self.pop_size\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            inertia = self.calculate_inertia_weight()\n\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = inertia * self.velocity[i] + cognitive_component + social_component\n                self.velocity[i] = np.clip(self.velocity[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.current_evaluations += 1\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n\n            # Apply orthogonal learning every few iterations\n            if self.current_evaluations % (self.pop_size * 5) == 0:\n                new_population = self.orthogonal_learning(population)\n                new_fitnesses = np.array([func(x) for x in new_population])\n                self.current_evaluations += self.pop_size\n                self.budget -= self.pop_size\n\n                for i in range(self.pop_size):\n                    if new_fitnesses[i] < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = new_fitnesses[i]\n                        self.personal_best_positions[i] = new_population[i].copy()\n\n                        if new_fitnesses[i] < self.global_best_fitness:\n                            self.global_best_fitness = new_fitnesses[i]\n                            self.global_best_position = new_population[i].copy()\n                    population[i] = new_population[i].copy()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm HybridAdaptivePSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ad5ba097-a7d4-47d3-bace-deb83fef6543"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "7ad7659e-868c-4ba5-b3a7-67a05c7ea470", "fitness": 0.0, "name": "AdaptiveDEWithLocalSearch", "description": "Implements a DE variant that adaptively adjusts both mutation factor (F) and crossover rate (CR) based on the success rate of previous generations, coupled with a local search strategy that intensifies the search around promising solutions.", "code": "import numpy as np\n\nclass AdaptiveDEWithLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_F=0.5, initial_CR=0.9, local_search_prob=0.1, local_search_radius=0.1):\n        \"\"\"\n        Initialize the Adaptive Differential Evolution algorithm with Local Search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The initial population size. If None, it's set to 10*dim.\n            initial_F (float, optional): The initial mutation factor.\n            initial_CR (float, optional): The initial crossover rate.\n            local_search_prob (float): Probability of performing local search on an individual.\n            local_search_radius (float): Radius for local search around an individual.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.F = initial_F\n        self.CR = initial_CR\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_F = []\n        self.success_CR = []\n        self.local_search_prob = local_search_prob\n        self.local_search_radius = local_search_radius\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, pop, F, func):\n        \"\"\"Perform differential mutation (DE/rand/1).\"\"\"\n        mutated = np.zeros_like(pop)\n        for i in range(len(pop)):\n            idxs = np.random.choice(len(pop), 3, replace=False)\n            a, b, c = pop[idxs]\n            mutated[i] = a + F * (b - c)\n            mutated[i] = np.clip(mutated[i], func.bounds.lb, func.bounds.ub) # keep inside bounds\n\n        return mutated\n\n    def crossover(self, pop, mutated, CR):\n        \"\"\"Perform binomial crossover.\"\"\"\n        rand_matrix = np.random.rand(*pop.shape)\n        cross_mask = rand_matrix < CR\n        # Ensure at least one component is crossed over\n        for i in range(len(pop)):\n            j = np.random.randint(self.dim)\n            cross_mask[i, j] = True\n        u = np.where(cross_mask, mutated, pop)\n        return u\n\n    def local_search(self, individual, func):\n        \"\"\"Perform local search around an individual.\"\"\"\n        new_individual = individual + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n        new_individual = np.clip(new_individual, func.bounds.lb, func.bounds.ub)\n        new_fitness = func(new_individual)\n        self.eval_count += 1\n        return new_individual, new_fitness\n\n\n    def select(self, func, u):\n        \"\"\"Perform selection and adapt F/CR based on success.\"\"\"\n        successful_F = []\n        successful_CR = []\n        fitness_u = np.array([func(x) for x in u])\n        self.eval_count += len(u)\n\n        for i in range(len(u)):\n            if fitness_u[i] < self.fitness[i]:\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                   local_x, local_f = self.local_search(u[i], func)\n                   if local_f < fitness_u[i]:\n                       fitness_u[i] = local_f\n                       u[i] = local_x\n\n\n                if fitness_u[i] < self.fitness[i]:\n                    successful_F.append(self.F)\n                    successful_CR.append(self.CR)\n                    self.fitness[i] = fitness_u[i]\n                    self.pop[i] = u[i]\n\n        # Adapt F and CR\n        if successful_F:\n            self.F = np.mean(successful_F)\n        else:\n            self.F = np.clip(self.F + np.random.normal(0, 0.1), 0.1, 1.0) #Randomize if no success\n\n        if successful_CR:\n            self.CR = np.mean(successful_CR)\n        else:\n            self.CR = np.clip(self.CR + np.random.normal(0, 0.1), 0.1, 1.0) #Randomize if no success\n\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Adaptive DE with Local Search.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutated = self.mutate(self.pop, self.F, func)\n            u = self.crossover(self.pop, mutated, self.CR)\n            u = np.clip(u, func.bounds.lb, func.bounds.ub)\n            self.select(func, u)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDEWithLocalSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2df0e067-caaf-434f-ac31-7ae6391e592b"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "5b3cf3cd-d225-437c-97c6-b1945eed0b52", "fitness": 0.4676686625654803, "name": "HybridPSOSA", "description": "Hybrid PSO with Simulated Annealing and Lvy flight for enhanced exploration and exploitation, combining the strengths of each method for improved optimization.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, w_max=0.9, w_min=0.4, temp_init=100, temp_min=0.1, cooling_rate=0.95, levy_exponent=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.w_max = w_max\n        self.w_min = w_min\n        self.temp_init = temp_init\n        self.temp_min = temp_min\n        self.cooling_rate = cooling_rate\n        self.levy_exponent = levy_exponent\n\n        self.inertia = self.w_max\n        self.temperature = self.temp_init\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def levy_flight(self, size):\n        \"\"\"\n        Generate Levy distribution samples.\n        \"\"\"\n        u = np.random.normal(0, scale=(np.power(self.sigma, 1)), size=size)\n        v = np.random.normal(0, scale=1, size=size)\n        step = u / np.power(np.abs(v), (1 / self.levy_exponent))\n        return step\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        self.sigma = np.power((np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2)) / (np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * np.power(2, (self.levy_exponent - 1) / 2)), (1 / self.levy_exponent))\n\n        self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0 and self.temperature > self.temp_min:\n            # Update inertia weight linearly\n            self.inertia = self.w_max - (self.w_max - self.w_min) * (self.temp_init - self.temperature) / self.temp_init\n            \n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Simulated Annealing acceptance criterion\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                delta_e = new_fitness - fitness[i]\n                if delta_e < 0:\n                    # Accept the new solution\n                    population[i] = new_position.copy()\n                    fitness[i] = new_fitness\n                    \n                    if new_fitness < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = new_fitness\n                        self.personal_best_positions[i] = new_position.copy()\n\n                        if new_fitness < self.global_best_fitness:\n                            self.global_best_fitness = new_fitness\n                            self.global_best_position = new_position.copy()\n                else:\n                    # Apply Simulated Annealing criterion\n                    acceptance_probability = np.exp(-delta_e / self.temperature)\n                    if np.random.rand() < acceptance_probability:\n                        population[i] = new_position.copy()\n                        fitness[i] = new_fitness\n                        \n                # Lvy flight for diversification\n                if np.random.rand() < 0.05:\n                  levy_steps = self.levy_flight(self.dim)\n                  new_position = population[i] + 0.01 * levy_steps * (func.bounds.ub - func.bounds.lb)\n                  new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                  \n                  new_fitness = func(new_position)\n                  self.budget -= 1\n                  \n                  if new_fitness < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = new_fitness\n                        self.personal_best_positions[i] = new_position.copy()\n\n                        if new_fitness < self.global_best_fitness:\n                            self.global_best_fitness = new_fitness\n                            self.global_best_position = new_position.copy()\n\n                  population[i] = new_position.copy()\n                  fitness[i] = new_fitness\n                    \n\n            # Cool the temperature\n            self.temperature *= self.cooling_rate\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSOSA scored 0.468 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ad5ba097-a7d4-47d3-bace-deb83fef6543"], "operator": null, "metadata": {"aucs": [0.14721999806831731, 0.16781064850406713, 0.532876059528564, 0.9272614486120695, 0.26865911114136165, 0.6783243440710853, 0.3235172072345326, 0.20328675998645973, 0.22707114683042107, 0.19385898750165353, 0.8872926340588275, 0.9953581026559062, 0.35582839320579684, 0.253491300011335, 0.9319394681141191, 0.40241917286395834, 0.2662542770692158, 0.8711922997608862, 0.19966425790272813, 0.5200476341882991]}}
{"id": "b2e9bb00-af31-43ef-8249-d73ed310be9a", "fitness": 0.5856988444912423, "name": "AdaptiveSuccessDE", "description": "An adaptive differential evolution algorithm that dynamically adjusts the mutation factor based on the success rate of previous mutations.", "code": "import numpy as np\n\nclass AdaptiveSuccessDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F_initial=0.5, CR=0.9, F_decay=0.99, F_min=0.1):\n        \"\"\"\n        Initialize the Adaptive Success Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The population size. If None, set to 10*dim.\n            F_initial (float, optional): The initial mutation factor.\n            CR (float, optional): The crossover rate.\n            F_decay (float, optional): The decay rate for the mutation factor.\n            F_min (float, optional): The minimum value for the mutation factor.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.F = F_initial\n        self.CR = CR\n        self.F_decay = F_decay\n        self.F_min = F_min\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_count = 0\n        self.mutation_attempts = 0\n\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, pop, F):\n        \"\"\"Perform mutation using DE/rand/1.\"\"\"\n        mutated = np.zeros_like(pop)\n        for i in range(len(pop)):\n            indices = np.random.choice(len(pop), 3, replace=False)\n            x_r1, x_r2, x_r3 = pop[indices]\n            mutated[i] = pop[i] + F * (x_r1 - x_r2) + F * (x_r3 - pop[i])\n        return mutated\n\n    def crossover(self, pop, mutated, CR):\n        \"\"\"Perform binomial crossover.\"\"\"\n        rand_matrix = np.random.rand(*pop.shape)\n        cross_mask = rand_matrix < CR\n        # Ensure at least one component is crossed over\n        for i in range(len(pop)):\n            j = np.random.randint(self.dim)\n            cross_mask[i, j] = True\n        u = np.where(cross_mask, mutated, pop)\n        return u\n\n    def select(self, func, u):\n        \"\"\"Perform selection and update the success rate.\"\"\"\n        fitness_u = np.array([func(x) for x in u])\n        self.eval_count += len(u)\n\n        for i in range(len(u)):\n            if fitness_u[i] < self.fitness[i]:\n                self.pop[i] = u[i]\n                self.fitness[i] = fitness_u[i]\n                self.success_count += 1\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n    def update_mutation_factor(self):\n        \"\"\"Update the mutation factor based on the success rate.\"\"\"\n        if self.mutation_attempts > 0:\n            success_rate = self.success_count / self.mutation_attempts\n            if success_rate < 0.1:\n                self.F = max(self.F * (2 - self.F_decay), self.F_min)  # Increase F if success rate is low\n            elif success_rate > 0.5:\n                self.F *= self.F_decay # Reduce F if success rate is high\n            self.F = np.clip(self.F, self.F_min, 1.0)\n\n        self.success_count = 0\n        self.mutation_attempts = 0\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Adaptive Success Differential Evolution.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutated = self.mutate(self.pop, self.F)\n\n            # Clip values to respect bounds\n            mutated = np.clip(mutated, func.bounds.lb, func.bounds.ub)\n\n            u = self.crossover(self.pop, mutated, self.CR)\n\n            # Clip values to respect bounds\n            u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n            self.select(func, u)\n\n            self.mutation_attempts += self.pop_size  # Increment the attempts by population size since each individual in the pop undergoes mutation\n\n            self.update_mutation_factor()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveSuccessDE scored 0.586 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["785a36b5-216b-4e8f-bcfd-468909f40a80"], "operator": null, "metadata": {"aucs": [0.21379531344043057, 0.7016351963518173, 0.44515550900436784, 0.8622361494678614, 0.6916828423731225, 0.8110528154589777, 0.6106547269878897, 0.7028972910543307, 0.5317450115610047, 0.20454187843361338, 0.3790396047305481, 0.9883446891240825, 0.5836143124881594, 0.7155018856923162, 0.7852738147560404, 0.41816580545710136, 0.4992242504747404, 0.8624034463685526, 0.21116210295520943, 0.4958502436446822]}}
{"id": "8f77b17d-6064-490b-9e9d-2395ec8917db", "fitness": 0.40360865394931356, "name": "DynamicDE", "description": "A differential evolution strategy employing a dynamically adjusted mutation factor based on population diversity and fitness improvement, combined with a restart mechanism triggered by stagnation.", "code": "import numpy as np\n\nclass DynamicDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F_initial=0.7, CR=0.9, stagnation_limit=50):\n        \"\"\"\n        Initialize the Dynamic Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The population size. If None, set to 10*dim.\n            F_initial (float, optional): Initial mutation factor.\n            CR (float, optional): The crossover rate.\n            stagnation_limit (int, optional): Number of iterations without improvement before restarting.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.F = F_initial\n        self.CR = CR\n        self.stagnation_limit = stagnation_limit\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, pop, F):\n        \"\"\"Perform mutation using DE/rand/1.\"\"\"\n        mutated = np.zeros_like(pop)\n        for i in range(len(pop)):\n            indices = np.random.choice(len(pop), 3, replace=False)\n            x_r1, x_r2, x_r3 = pop[indices]\n            mutated[i] = pop[i] + F * (x_r1 - x_r2) + F * (x_r3 - pop[i])\n        return mutated\n\n    def crossover(self, pop, mutated, CR):\n        \"\"\"Perform binomial crossover.\"\"\"\n        rand_matrix = np.random.rand(*pop.shape)\n        cross_mask = rand_matrix < CR\n        # Ensure at least one component is crossed over\n        for i in range(len(pop)):\n            j = np.random.randint(self.dim)\n            cross_mask[i, j] = True\n        u = np.where(cross_mask, mutated, pop)\n        return u\n\n    def select(self, func, u):\n        \"\"\"Perform selection.\"\"\"\n        fitness_u = np.array([func(x) for x in u])\n        self.eval_count += len(u)\n\n        improved = False\n        for i in range(len(u)):\n            if fitness_u[i] < self.fitness[i]:\n                self.pop[i] = u[i]\n                self.fitness[i] = fitness_u[i]\n                improved = True\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n            self.stagnation_counter = 0  # Reset stagnation counter if improvement found\n            return True\n        else:\n            self.stagnation_counter += 1\n            return False\n\n    def adjust_mutation_factor(self):\n        \"\"\"Adjust the mutation factor based on population diversity and improvement.\"\"\"\n        # Calculate population diversity (e.g., variance)\n        diversity = np.var(self.pop)\n\n        # Calculate average fitness improvement\n        fitness_diff = self.fitness - np.mean(self.fitness)\n        improvement = np.mean(fitness_diff) if np.any(fitness_diff < 0) else 0 # only consider improvement when there are better solutions\n\n        # Dynamically adjust F based on diversity and improvement\n        if diversity > 1e-3:  # High diversity\n            self.F = min(self.F + 0.05, 1.0)  # Increase F to explore\n        elif improvement > 1e-6:  # Good improvement\n            self.F = max(self.F - 0.02, 0.1) # Reduce F to exploit\n        else:\n            self.F = self.F # Keep it as it is. \n\n    def restart_population(self, func):\n         \"\"\"Restart the population randomly.\"\"\"\n         self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n         self.fitness = np.array([func(x) for x in self.pop])\n         self.eval_count += self.pop_size\n         \n         best_index = np.argmin(self.fitness)\n         if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n         self.stagnation_counter = 0\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Dynamic Differential Evolution.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutated = self.mutate(self.pop, self.F)\n\n            # Clip values to respect bounds\n            mutated = np.clip(mutated, func.bounds.lb, func.bounds.ub)\n\n            u = self.crossover(self.pop, mutated, self.CR)\n\n            # Clip values to respect bounds\n            u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n            improved = self.select(func, u)\n\n            self.adjust_mutation_factor()\n\n            if self.stagnation_counter > self.stagnation_limit:\n                self.restart_population(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm DynamicDE scored 0.404 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["785a36b5-216b-4e8f-bcfd-468909f40a80"], "operator": null, "metadata": {"aucs": [0.16188495934489766, 0.24839721121772895, 0.34925280896744915, 0.548416750238494, 0.33576768550873115, 0.44200350433238134, 0.30562794779593083, 0.32460641370948584, 0.3157505117653787, 0.20929883702152485, 0.4652520778662873, 0.996789810832482, 0.2967610145705577, 0.32649188166608234, 0.7967654579808819, 0.43429852568505745, 0.3068958141262489, 0.5115319955643527, 0.2014151158233094, 0.4949647549690087]}}
{"id": "2369d5ed-d65e-42fd-a2b5-d4d84101bde6", "fitness": 0.538940830638502, "name": "EnhancedAdaptivePSO", "description": "An enhanced PSO variant with dynamic inertia weight adaptation based on stagnation detection and a Cauchy mutation operator for improved exploration and escape from local optima.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, velocity_clamp=0.5, initial_inertia=0.9, inertia_decay=0.995, stagnation_threshold=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.inertia = initial_inertia\n        self.inertia_decay = inertia_decay\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n\n        self.constriction_factor = self.calculate_constriction_factor()\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.previous_global_best_fitness = np.inf\n\n    def calculate_constriction_factor(self):\n        phi = self.cognitive_coeff + self.social_coeff\n        if phi <= 4:\n            return 1.0\n        return 2 / np.abs(2 - phi - np.sqrt(phi**2 - 4 * phi))\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n        self.previous_global_best_fitness = self.global_best_fitness\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.constriction_factor * (self.inertia * self.velocity[i] + cognitive_component + social_component)\n                self.velocity[i] = np.clip(self.velocity[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                \n\n                # Cauchy mutation\n                if np.random.rand() < 0.05:\n                    cauchy_mutation = np.random.standard_cauchy(size=self.dim) * 0.01\n                    new_position += cauchy_mutation\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                        \n                population[i] = new_position.copy()\n\n            # Inertia adaptation\n            if self.global_best_fitness >= self.previous_global_best_fitness:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.inertia = min(self.inertia * 1.05, 0.9)  # Increase inertia to explore more\n            else:\n                self.inertia *= self.inertia_decay  # Decay inertia if improving\n\n            self.previous_global_best_fitness = self.global_best_fitness\n            \n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedAdaptivePSO scored 0.539 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ad5ba097-a7d4-47d3-bace-deb83fef6543"], "operator": null, "metadata": {"aucs": [0.12711515996359724, 0.22986240836967886, 0.8427265014792575, 0.9712417732736877, 0.29728294048232495, 0.9222522293545752, 0.2976173721857879, 0.44292254432981637, 0.17710083388534859, 0.18651467064415161, 0.9328300899325154, 0.9860180513708234, 0.2754284183800604, 0.23579932417771943, 0.9489078833601169, 0.8940923646602199, 0.4167762784527418, 0.931009844740382, 0.1924432023597008, 0.4708747213675327]}}
{"id": "36f8dfe7-b803-4652-b181-fa07b92506d8", "fitness": 0.4103334403900639, "name": "EnhancedAdaptivePSO", "description": "An enhanced PSO variant that dynamically adjusts the inertia weight based on the stagnation of the global best solution and incorporates a diversity maintenance strategy using a repulsion factor.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, velocity_clamp=0.5, stagnation_threshold=50, repulsion_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.stagnation_threshold = stagnation_threshold\n        self.repulsion_factor = repulsion_factor\n\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.inertia = self.inertia_max\n        self.constriction_factor = self.calculate_constriction_factor()\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.stagnation_counter = 0\n\n    def calculate_constriction_factor(self):\n        phi = self.cognitive_coeff + self.social_coeff\n        if phi <= 4:\n            return 1.0\n        return 2 / np.abs(2 - phi - np.sqrt(phi**2 - 4 * phi))\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n        previous_global_best_fitness = self.global_best_fitness  # Store initial best fitness\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n\n                # Diversity maintenance: Repulsion from the average position\n                average_position = np.mean(population, axis=0)\n                repulsion_component = self.repulsion_factor * np.random.rand() * (average_position - population[i])\n\n                self.velocity[i] = self.constriction_factor * (self.inertia * self.velocity[i] + cognitive_component + social_component + repulsion_component)\n                self.velocity[i] = np.clip(self.velocity[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                    else:\n                        self.stagnation_counter += 1  # Increment stagnation counter\n\n                population[i] = new_position.copy()\n\n            # Adjust inertia weight based on stagnation\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.inertia = self.inertia_min  # Reduce inertia if stagnating\n            else:\n                self.inertia = self.inertia_max  # Restore inertia if improving\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedAdaptivePSO scored 0.410 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ad5ba097-a7d4-47d3-bace-deb83fef6543"], "operator": null, "metadata": {"aucs": [0.10994617597478484, 0.19058532247632332, 0.5145639186807023, 0.4118465222217337, 0.23085849294376604, 0.9204584601556595, 0.2293605493922909, 0.27591556462397193, 0.3005708351923009, 0.20080076310161488, 0.30616604989480756, 0.9972442381701343, 0.29804450181206976, 0.2385696256700055, 0.7297963231245824, 0.366886107675941, 0.25212924173344586, 0.9255187942974613, 0.19755224859745868, 0.5098550720622228]}}
{"id": "b1e62ac3-38ae-4652-842f-b16248f71717", "fitness": 0.3727609334166771, "name": "AdaptiveDEWithRestart", "description": "An adaptive differential evolution algorithm that dynamically adjusts mutation factor F and crossover rate CR based on the success of previous generations, incorporating a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDEWithRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F_init=0.5, CR_init=0.9, restart_trigger=0.05):\n        \"\"\"\n        Initialize the Adaptive Differential Evolution algorithm with restart mechanism.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The population size. If None, set to 10*dim.\n            F_init (float, optional): Initial mutation factor.\n            CR_init (float, optional): Initial crossover rate.\n            restart_trigger (float, optional): Threshold for fitness improvement to trigger restart.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.F = F_init\n        self.CR = CR_init\n        self.restart_trigger = restart_trigger\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_F = []\n        self.success_CR = []\n        self.archive_F = []\n        self.archive_CR = []\n        self.memory_size = 10  # Size of the memory for successful F and CR values\n        self.min_F = 0.1\n        self.max_F = 0.9\n        self.min_CR = 0.1\n        self.max_CR = 0.9\n        self.last_improvement = 0\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.last_improvement = self.eval_count\n\n\n    def mutate(self, pop, F):\n        \"\"\"Perform mutation using DE/rand/1.\"\"\"\n        mutated = np.zeros_like(pop)\n        for i in range(len(pop)):\n            indices = np.random.choice(len(pop), 3, replace=False)\n            x_r1, x_r2, x_r3 = pop[indices]\n            mutated[i] = pop[i] + F * (x_r1 - x_r2) + F * (x_r3 - pop[i])\n        return mutated\n\n    def crossover(self, pop, mutated, CR):\n        \"\"\"Perform binomial crossover.\"\"\"\n        rand_matrix = np.random.rand(*pop.shape)\n        cross_mask = rand_matrix < CR\n        # Ensure at least one component is crossed over\n        for i in range(len(pop)):\n            j = np.random.randint(self.dim)\n            cross_mask[i, j] = True\n        u = np.where(cross_mask, mutated, pop)\n        return u\n\n    def select(self, func, u, F, CR):\n        \"\"\"Perform selection and update F and CR adaptively.\"\"\"\n        fitness_u = np.array([func(x) for x in u])\n        self.eval_count += len(u)\n        improved = False\n\n        for i in range(len(u)):\n            if fitness_u[i] < self.fitness[i]:\n                self.success_F.append(F)\n                self.success_CR.append(CR)\n\n                self.pop[i] = u[i]\n                self.fitness[i] = fitness_u[i]\n                improved = True\n\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n            self.last_improvement = self.eval_count\n\n        return improved\n\n    def adapt_parameters(self):\n        \"\"\"Adapt F and CR based on the success history.\"\"\"\n        if self.success_F:\n            self.archive_F.extend(self.success_F)\n            self.archive_CR.extend(self.success_CR)\n\n            if len(self.archive_F) > self.memory_size:\n                 self.archive_F = self.archive_F[-self.memory_size:]\n                 self.archive_CR = self.archive_CR[-self.memory_size:]\n\n            self.F = np.clip(np.median(self.archive_F), self.min_F, self.max_F)\n            self.CR = np.clip(np.median(self.archive_CR), self.min_CR, self.max_CR)\n\n        self.success_F = []\n        self.success_CR = []\n\n    def restart(self, func):\n        \"\"\"Restart the population if no improvement is observed for a while.\"\"\"\n        print(\"Restarting population...\")\n        self.initialize_population(func)\n\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Adaptive Differential Evolution with Restart.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            F = np.random.uniform(self.min_F, self.max_F)  # Sample F randomly\n            CR = np.random.uniform(self.min_CR, self.max_CR)  # Sample CR randomly\n            mutated = self.mutate(self.pop, F)\n\n            # Clip values to respect bounds\n            mutated = np.clip(mutated, func.bounds.lb, func.bounds.ub)\n\n            u = self.crossover(self.pop, mutated, CR)\n\n            # Clip values to respect bounds\n            u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n            improved = self.select(func, u, F, CR)\n            self.adapt_parameters()\n\n            if self.eval_count - self.last_improvement > self.restart_trigger * self.budget:\n                self.restart(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDEWithRestart scored 0.373 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["785a36b5-216b-4e8f-bcfd-468909f40a80"], "operator": null, "metadata": {"aucs": [0.1590039325735343, 0.2731221821039531, 0.48695281240540345, 0.6531300750241169, 0.33272184297267593, 0.7043956888370559, 0]}}
{"id": "9e8b43b6-69ec-4b05-8a72-83d2f63c7d6a", "fitness": 0.3034518979266587, "name": "SaCDE", "description": "A self-adjusting differential evolution algorithm with a Cauchy mutation operator and adaptive parameter control via success history.", "code": "import numpy as np\n\nclass SaCDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, memory_size=10, initial_F=0.5, initial_CR=0.9):\n        \"\"\"\n        Initialize the Self-Adjusting Cauchy Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The population size. If None, it's set to 10*dim.\n            memory_size (int): The size of the memory for F and CR.\n            initial_F (float): Initial value for F.\n            initial_CR (float): Initial value for CR.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.memory_size = memory_size\n        self.memory_F = initial_F * np.ones(memory_size)\n        self.memory_CR = initial_CR * np.ones(memory_size)\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_F = []\n        self.success_CR = []\n        self.archive = []\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def generate_cauchy_mutation(self, F):\n        \"\"\"Generate mutation factor F from a Cauchy distribution.\"\"\"\n        return F + 0.1 * np.tan(np.pi * (np.random.rand() - 0.5))\n\n    def mutate(self, pop, F):\n        \"\"\"Perform differential mutation with Cauchy distributed F.\"\"\"\n        mutated = np.zeros_like(pop)\n        for i in range(len(pop)):\n            idxs = np.random.choice(len(pop), 3, replace=False)\n            a, b, c = pop[idxs]\n            mutated[i] = a + F * (b - c)\n        return mutated\n\n    def crossover(self, pop, mutated, CR):\n        \"\"\"Perform binomial crossover.\"\"\"\n        rand_matrix = np.random.rand(*pop.shape)\n        cross_mask = rand_matrix < CR\n        # Ensure at least one component is crossed over\n        for i in range(len(pop)):\n            j = np.random.randint(self.dim)\n            cross_mask[i, j] = True\n        u = np.where(cross_mask, mutated, pop)\n        return u\n\n    def select(self, func, u):\n        \"\"\"Perform selection based on fitness and update memory.\"\"\"\n        fitness_u = np.array([func(x) for x in u])\n        self.eval_count += len(u)\n\n        for i in range(len(u)):\n            if fitness_u[i] < self.fitness[i]:\n                self.success_F.append(self.current_F)\n                self.success_CR.append(self.current_CR)\n                self.archive.append(self.pop[i].copy())\n\n                self.pop[i] = u[i]\n                self.fitness[i] = fitness_u[i]\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n    def update_parameters(self):\n        \"\"\"Update F and CR based on success history.\"\"\"\n        if self.success_F:\n            self.memory_F = np.roll(self.memory_F, 1)\n            self.memory_CR = np.roll(self.memory_CR, 1)\n\n            # Lehmer mean for F\n            self.memory_F[0] = np.sum(np.array(self.success_F)**2) / np.sum(np.array(self.success_F)) if len(self.success_F) > 0 else 0.5\n            self.memory_CR[0] = np.mean(self.success_CR) if len(self.success_CR) > 0 else 0.9\n\n            self.success_F = []\n            self.success_CR = []\n\n        self.current_F = self.memory_F[0]\n        self.current_CR = self.memory_CR[0]\n\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Self-Adjusting Cauchy Differential Evolution.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_parameters()\n            \n            F = self.generate_cauchy_mutation(self.current_F)\n            F = np.clip(F, 0.0, 1.0)\n            self.current_F = F\n            \n            mutated = self.mutate(self.pop, F)\n            mutated = np.clip(mutated, func.bounds.lb, func.bounds.ub)\n            \n            u = self.crossover(self.pop, mutated, self.current_CR)\n            u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n            self.select(func, u)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm SaCDE scored 0.303 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["824de54f-0de3-4d46-9a65-3985523150db"], "operator": null, "metadata": {"aucs": [0.1094983084150053, 0.17225604694688101, 0.2902099133715187, 0.32337174927091383, 0.2777371646756154, 0.23307320886687188, 0.25647730684887515, 0.22284424787986412, 0.20229486774777694, 0.16967454647436242, 0.2582397260641497, 0.9983923574334507, 0.3027456323101575, 0.2700386727706955, 0.6641675605628821, 0.30251851730874324, 0.1970143459574787, 0.1885079396646202, 0.1801719948816668, 0.44980385108164567]}}
{"id": "55b0050e-8bd4-46ec-a7f6-363e8a9f426a", "fitness": 0.0, "name": "AdaptiveConstrictionPSO", "description": "An adaptive PSO with a Cauchy mutation for global best position, and a constriction factor to control particle velocities.", "code": "import numpy as np\n\nclass AdaptiveConstrictionPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, constriction_factor=0.729, cauchy_mutation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.constriction_factor = constriction_factor\n        self.cauchy_mutation_rate = cauchy_mutation_rate\n\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def cauchy_mutation(self, x, scale=0.1):\n        \"\"\"\n        Apply Cauchy mutation to a vector.\n        \"\"\"\n        mutation = scale * np.random.standard_cauchy(size=x.shape)\n        return x + mutation\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.constriction_factor * (self.velocity[i] + cognitive_component + social_component)\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                # Update personal best\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    # Update global best\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n\n            # Apply Cauchy mutation to the global best position\n            if np.random.rand() < self.cauchy_mutation_rate:\n                mutated_global_best = self.cauchy_mutation(self.global_best_position)\n                mutated_global_best = np.clip(mutated_global_best, func.bounds.lb, func.bounds.ub)\n\n                mutated_fitness = func(mutated_global_best)\n                self.budget -= 1\n\n                if mutated_fitness < self.global_best_fitness:\n                    self.global_best_fitness = mutated_fitness\n                    self.global_best_position = mutated_global_best.copy()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveConstrictionPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5b3cf3cd-d225-437c-97c6-b1945eed0b52"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "7ef59898-dcd0-4654-9723-b4f0663e479b", "fitness": 0.0, "name": "AgingGaussianPSO", "description": "A PSO variant with velocity mutation based on a Gaussian distribution, combined with an aging mechanism to promote exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass AgingGaussianPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, velocity_clamp=0.5, mutation_rate=0.1, aging_rate=0.02):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.mutation_rate = mutation_rate\n        self.aging_rate = aging_rate\n        self.age = np.zeros(pop_size)  # Initialize age for each particle\n        self.inertia = 0.7\n\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        velocity = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n\n                velocity[i] = self.inertia * velocity[i] + cognitive_component + social_component\n\n                # Velocity Mutation: Gaussian perturbation\n                if np.random.rand() < self.mutation_rate:\n                    velocity[i] += np.random.normal(0, self.velocity_clamp * 0.1, size=self.dim)  # Small Gaussian noise\n                velocity[i] = np.clip(velocity[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = population[i] + velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                        self.age[i] = 0 # Reset age\n\n                population[i] = new_position.copy()\n                \n                # Aging mechanism: If a particle doesn't improve, increase its age\n                if new_fitness >= self.personal_best_fitness[i]:\n                    self.age[i] += self.aging_rate\n                    \n                    # If the particle is too old, reset it randomly\n                    if self.age[i] > 1.0:\n                        population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                        fitness = func(population[i])\n                        self.budget -=1\n                        velocity[i] = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=self.dim)\n                        self.personal_best_positions[i] = population[i].copy()\n                        self.personal_best_fitness[i] = fitness\n                        self.age[i] = 0\n                        \n                        if fitness < self.global_best_fitness:\n                            self.global_best_fitness = fitness\n                            self.global_best_position = population[i].copy()\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AgingGaussianPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["36f8dfe7-b803-4652-b181-fa07b92506d8"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "3ff9ade0-042d-46b2-a3cc-43884b553140", "fitness": 0.0, "name": "MutatingHyperspherePSO", "description": "An enhanced PSO variant that incorporates a mutation operator based on the difference between the global best and a randomly selected particle to enhance exploration and escape local optima, coupled with a shrinking hypersphere local search around the best solution.", "code": "import numpy as np\n\nclass MutatingHyperspherePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, inertia_max=0.9, inertia_min=0.4, mutation_rate=0.1, hypersphere_radius=0.1, hypersphere_shrink_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.mutation_rate = mutation_rate\n        self.hypersphere_radius = hypersphere_radius\n        self.hypersphere_shrink_rate = hypersphere_shrink_rate\n\n        self.inertia = self.inertia_max\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            # Update inertia weight linearly\n            self.inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (1 - self.budget / 10000)  # Assuming initial budget is 10000\n            \n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Mutation operator\n                if np.random.rand() < self.mutation_rate:\n                    random_particle_index = np.random.randint(self.pop_size)\n                    mutation_vector = self.global_best_position - population[random_particle_index]\n                    new_position = new_position + 0.1 * mutation_vector  # Scale the mutation\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                \n                population[i] = new_position.copy()\n                fitness[i] = new_fitness\n\n            # Hypersphere local search around global best\n            for _ in range(5): # Perform a few local searches per iteration\n                if self.budget <= 0:\n                    break\n                \n                random_direction = np.random.normal(0, 1, size=self.dim)\n                random_direction = random_direction / np.linalg.norm(random_direction)\n                new_position = self.global_best_position + self.hypersphere_radius * random_direction\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness\n                    self.global_best_position = new_position.copy()\n\n            self.hypersphere_radius *= self.hypersphere_shrink_rate # Shrink the radius each iteration\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm MutatingHyperspherePSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5b3cf3cd-d225-437c-97c6-b1945eed0b52"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "85827659-a05d-45d9-a583-cc1f402ba46c", "fitness": -Infinity, "name": "SelfAdaptiveDE", "description": "An adaptive Differential Evolution strategy with self-adaptive population size, where the population size is adjusted based on the algorithm's progress to balance exploration and exploitation.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=None, F=0.5, CR=0.9, pop_size_factor=2, pop_size_reduction=0.5):\n        \"\"\"\n        Initialize the Self-Adaptive Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            initial_pop_size (int, optional): The initial population size. If None, set to 10*dim.\n            F (float, optional): The mutation factor.\n            CR (float, optional): The crossover rate.\n            pop_size_factor (int, optional): Factor to increase the population size\n            pop_size_reduction (float, optional): The reduction factor when reducing pop size\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size if initial_pop_size is not None else 10 * dim\n        self.F = F\n        self.CR = CR\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.pop_size_factor = pop_size_factor\n        self.pop_size_reduction = pop_size_reduction\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, pop, F):\n        \"\"\"Perform mutation using DE/rand/1.\"\"\"\n        mutated = np.zeros_like(pop)\n        for i in range(len(pop)):\n            indices = np.random.choice(len(pop), 3, replace=False)\n            x_r1, x_r2, x_r3 = pop[indices]\n            mutated[i] = pop[i] + F * (x_r1 - x_r2) + F * (x_r3 - pop[i])\n        return mutated\n\n    def crossover(self, pop, mutated, CR):\n        \"\"\"Perform binomial crossover.\"\"\"\n        rand_matrix = np.random.rand(*pop.shape)\n        cross_mask = rand_matrix < CR\n        # Ensure at least one component is crossed over\n        for i in range(len(pop)):\n            j = np.random.randint(self.dim)\n            cross_mask[i, j] = True\n        u = np.where(cross_mask, mutated, pop)\n        return u\n\n    def select(self, func, u):\n        \"\"\"Perform selection.\"\"\"\n        fitness_u = np.array([func(x) for x in u])\n        self.eval_count += len(u)\n\n        improved_indices = fitness_u < self.fitness\n        self.pop[improved_indices] = u[improved_indices]\n        self.fitness[improved_indices] = fitness_u[improved_indices]\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n    def adjust_population_size(self, current_eval):\n        \"\"\"Adjust the population size based on progress.\"\"\"\n        if current_eval > self.budget * 0.75:  # Exploitation phase\n            new_pop_size = int(self.pop_size * self.pop_size_reduction)\n            if new_pop_size < 4: # Minimal pop size\n                new_pop_size = 4\n            if new_pop_size != self.pop_size:\n                self.pop_size = new_pop_size\n                # Keep only the best individuals\n                best_indices = np.argsort(self.fitness)[:self.pop_size]\n                self.pop = self.pop[best_indices]\n                self.fitness = self.fitness[best_indices]\n        elif current_eval < self.budget * 0.25:  # Exploration phase\n            new_pop_size = int(self.pop_size * self.pop_size_factor)\n            if self.eval_count + new_pop_size - self.pop_size > self.budget:\n                new_pop_size = self.pop_size\n            if new_pop_size != self.pop_size:\n                # Create new random individuals and add to the population\n                num_new_individuals = new_pop_size - self.pop_size\n                new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new_individuals, self.dim))\n                new_fitness = np.array([func(x) for x in new_individuals])\n                self.eval_count += num_new_individuals\n\n                self.pop = np.vstack((self.pop, new_individuals))\n                self.fitness = np.concatenate((self.fitness, new_fitness))\n                self.pop_size = new_pop_size\n\n                # Limit population size if exceeds evaluations budget\n                if self.eval_count > self.budget:\n                    best_indices = np.argsort(self.fitness)[:self.pop_size]\n                    self.pop = self.pop[best_indices]\n                    self.fitness = self.fitness[best_indices]\n                    self.eval_count = self.budget\n\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Self-Adaptive Differential Evolution.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.adjust_population_size(self.eval_count)\n\n            mutated = self.mutate(self.pop, self.F)\n            \n            # Clip values to respect bounds\n            mutated = np.clip(mutated, func.bounds.lb, func.bounds.ub)\n            \n            u = self.crossover(self.pop, mutated, self.CR)\n            \n            # Clip values to respect bounds\n            u = np.clip(u, func.bounds.lb, func.bounds.ub)\n            \n            self.select(func, u)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occurred: name 'func' is not defined.", "error": "", "parent_ids": ["b2e9bb00-af31-43ef-8249-d73ed310be9a"], "operator": null, "metadata": {}}
{"id": "e1afaff4-464c-412f-be08-9131e6d4cb89", "fitness": -Infinity, "name": "AdaptivePopulationDE", "description": "An adaptive differential evolution algorithm with a self-adaptive population size based on the improvement rate and orthogonal crossover.", "code": "import numpy as np\n\nclass AdaptivePopulationDE:\n    def __init__(self, budget=10000, dim=10, pop_size_initial=None, F=0.5, CR=0.9, pop_size_min=4, pop_size_max=200):\n        \"\"\"\n        Initialize the Adaptive Population Differential Evolution algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size_initial (int, optional): The initial population size. If None, set to 10*dim.\n            F (float, optional): The mutation factor.\n            CR (float, optional): The crossover rate.\n            pop_size_min (int): The minimum population size.\n            pop_size_max (int): The maximum population size.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_initial if pop_size_initial is not None else 10 * dim\n        self.pop_size = min(self.pop_size, pop_size_max)\n        self.F = F\n        self.CR = CR\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.improvement_history = []\n        self.orthogonal_matrix = None\n\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.orthogonal_matrix = self.generate_orthogonal_matrix(self.dim)\n\n    def generate_orthogonal_matrix(self, dim):\n        \"\"\"Generate an orthogonal matrix using the Hadamard matrix.\"\"\"\n        n = 2**int(np.ceil(np.log2(dim)))\n        H = np.ones((n, n))\n        for i in range(1, int(np.log2(n)) + 1):\n            k = 2**(i-1)\n            H[:k, k:2*k] = H[:k, :k]\n            H[k:2*k, :k] = H[:k, :k]\n            H[k:2*k, k:2*k] = -H[:k, :k]\n        return H[:dim, :dim]\n\n\n    def mutate(self, pop, F):\n        \"\"\"Perform mutation using DE/rand/1.\"\"\"\n        mutated = np.zeros_like(pop)\n        for i in range(len(pop)):\n            indices = np.random.choice(len(pop), 3, replace=False)\n            x_r1, x_r2, x_r3 = pop[indices]\n            mutated[i] = pop[i] + F * (x_r1 - x_r2) + F * (x_r3 - pop[i])\n        return mutated\n\n    def crossover(self, pop, mutated, CR):\n        \"\"\"Perform binomial crossover.\"\"\"\n        rand_matrix = np.random.rand(*pop.shape)\n        cross_mask = rand_matrix < CR\n        # Ensure at least one component is crossed over\n        for i in range(len(pop)):\n            j = np.random.randint(self.dim)\n            cross_mask[i, j] = True\n        u = np.where(cross_mask, mutated, pop)\n        return u\n\n    def orthogonal_crossover(self, pop, mutated):\n        \"\"\"Perform orthogonal crossover.\"\"\"\n        u = np.zeros_like(pop)\n        for i in range(len(pop)):\n            u[i] = np.dot(self.orthogonal_matrix, mutated[i]-pop[i]) + pop[i]\n        return u\n\n    def select(self, func, u):\n        \"\"\"Perform selection.\"\"\"\n        fitness_u = np.array([func(x) for x in u])\n        self.eval_count += len(u)\n\n        improved = False\n        for i in range(len(u)):\n            if fitness_u[i] < self.fitness[i]:\n                self.pop[i] = u[i]\n                self.fitness[i] = fitness_u[i]\n                improved = True\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n        return improved\n\n    def update_population_size(self):\n        \"\"\"Update the population size based on the improvement rate.\"\"\"\n        if len(self.improvement_history) > 5:\n            improvement_rate = np.mean(self.improvement_history[-5:])\n            if improvement_rate > 0.2:\n                self.pop_size = min(int(self.pop_size * 1.2), self.pop_size_max)\n            elif improvement_rate < 0.05:\n                self.pop_size = max(int(self.pop_size * 0.8), self.pop_size_min)\n\n            #Reinitialize population if size changes significantly\n            if self.pop_size != self.pop.shape[0]:\n                 self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.pop])\n                 self.eval_count += self.pop_size\n                 self.f_opt = np.min(self.fitness)\n                 self.x_opt = self.pop[np.argmin(self.fitness)]\n\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Adaptive Population Differential Evolution.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutated = self.mutate(self.pop, self.F)\n\n            # Clip values to respect bounds\n            mutated = np.clip(mutated, func.bounds.lb, func.bounds.ub)\n\n            u = self.crossover(self.pop, mutated, self.CR)\n            # Clip values to respect bounds\n            u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n            # Orthogonal Crossover\n            u_ortho = self.orthogonal_crossover(self.pop, mutated)\n            u_ortho = np.clip(u_ortho, func.bounds.lb, func.bounds.ub)\n            \n            #Evaluate both u and u_ortho and choose the best\n            fitness_u = np.array([func(x) for x in u])\n            fitness_u_ortho =  np.array([func(x) for x in u_ortho])\n            self.eval_count += len(u) + len(u_ortho)\n            u_combined = np.where(fitness_u < fitness_u_ortho, u, u_ortho)\n\n            improved = self.select(func, u_combined)\n            self.improvement_history.append(int(improved))\n\n            self.update_population_size()\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "An exception occurred: operands could not be broadcast together with shapes (20,) (20,2) (20,2) .", "error": "", "parent_ids": ["b2e9bb00-af31-43ef-8249-d73ed310be9a"], "operator": null, "metadata": {}}
{"id": "555d7cb1-b5cd-48ff-876d-8b8343aeb3aa", "fitness": 0.41633863258768533, "name": "AdaptivePSONelderMead", "description": "An adaptive hybrid algorithm that combines Particle Swarm Optimization (PSO) with a Nelder-Mead simplex search, adaptively switching between global exploration and local exploitation based on the population diversity.", "code": "import numpy as np\n\nclass AdaptivePSONelderMead:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, w_max=0.9, w_min=0.4, nelder_mead_iterations=5, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.w_max = w_max\n        self.w_min = w_min\n        self.nelder_mead_iterations = nelder_mead_iterations\n        self.diversity_threshold = diversity_threshold\n\n        self.inertia = self.w_max\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def nelder_mead(self, func, x0, iterations):\n        \"\"\"\n        Performs the Nelder-Mead simplex algorithm.\n        \"\"\"\n        simplex = [x0 + np.random.uniform(-0.1, 0.1, self.dim) for _ in range(self.dim + 1)]  # Initialize simplex close to x0\n        simplex = np.clip(simplex, func.bounds.lb, func.bounds.ub)\n        fitness = np.array([func(x) for x in simplex])\n        \n        for _ in range(iterations):\n            # Order the vertices by fitness\n            order = np.argsort(fitness)\n            simplex = simplex[order]\n            fitness = fitness[order]\n            \n            # Calculate centroid of the best vertices\n            centroid = np.mean(simplex[:-1], axis=0)\n            \n            # Reflection\n            xr = centroid + 1.0 * (centroid - simplex[-1])\n            xr = np.clip(xr, func.bounds.lb, func.bounds.ub)\n            fr = func(xr)\n            \n            if fr < fitness[0]:\n                # Expansion\n                xe = centroid + 2.0 * (centroid - simplex[-1])\n                xe = np.clip(xe, func.bounds.lb, func.bounds.ub)\n                fe = func(xe)\n                \n                if fe < fr:\n                    simplex[-1] = xe\n                    fitness[-1] = fe\n                else:\n                    simplex[-1] = xr\n                    fitness[-1] = fr\n            elif fr < fitness[-2]:\n                simplex[-1] = xr\n                fitness[-1] = fr\n            else:\n                # Contraction\n                xc = centroid + 0.5 * (simplex[-1] - centroid)\n                xc = np.clip(xc, func.bounds.lb, func.bounds.ub)\n                fc = func(xc)\n                \n                if fc < fitness[-1]:\n                    simplex[-1] = xc\n                    fitness[-1] = fc\n                else:\n                    # Shrink\n                    for i in range(1, len(simplex)):\n                        simplex[i] = simplex[0] + 0.5 * (simplex[i] - simplex[0])\n                        simplex[i] = np.clip(simplex[i], func.bounds.lb, func.bounds.ub)\n                        fitness[i] = func(simplex[i])\n\n        best_index = np.argmin(fitness)\n        return fitness[best_index], simplex[best_index]\n\n\n    def calculate_diversity(self, population):\n        \"\"\"\n        Calculates the diversity of the population based on the average distance from the centroid.\n        \"\"\"\n        centroid = np.mean(population, axis=0)\n        distances = np.linalg.norm(population - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            # Update inertia weight linearly\n            self.inertia = self.w_max - (self.w_max - self.w_min) * (1 - self.budget / 10000)\n\n            # Calculate population diversity\n            diversity = self.calculate_diversity(population)\n\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                \n                population[i] = new_position.copy()\n                fitness[i] = new_fitness\n\n            # Apply Nelder-Mead if diversity is low to enhance local search\n            if diversity < self.diversity_threshold and self.budget > self.nelder_mead_iterations * (self.dim + 1):  # Check if enough budget remains\n                best_index = np.argmin(fitness)\n                best_fitness, best_position = self.nelder_mead(func, population[best_index], self.nelder_mead_iterations)\n                self.budget -= self.nelder_mead_iterations * (self.dim+1) #account for function evaluations in nelder mead\n                \n                if best_fitness < self.global_best_fitness:\n                    self.global_best_fitness = best_fitness\n                    self.global_best_position = best_position.copy()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptivePSONelderMead scored 0.416 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5b3cf3cd-d225-437c-97c6-b1945eed0b52"], "operator": null, "metadata": {"aucs": [0.20378038031427304, 0.2861313420709626, 0.5999702280685757, 0.24718217075206916, 0.30120716420454996, 0.6906371256963558, 0.30365723293180125, 0.22191056526045327, 0.6439240473999828, 0.18945401521024463, 0.7976075534838178, 0.9984569776798158, 0.20904413585084058, 0.30270658636660996, 0.5859645769714037, 0.32807167499637857, 0.5544069446754356, 0.19202294987422275, 0.21091226853843814, 0.4597247114074765]}}
{"id": "10b078e1-593a-415a-af38-a7a9ee92df06", "fitness": 0.4288312745966536, "name": "AdaptivePSO", "description": "An adaptive PSO variant with a self-regulating exploration-exploitation balance via dynamically adjusted cognitive and social coefficients and a mutation operator triggered by stagnation.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_cognitive_coeff=2.05, initial_social_coeff=2.05,\n                 velocity_clamp=0.5, stagnation_threshold=50, mutation_rate=0.1, cognitive_scaling=0.99, social_scaling=1.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = initial_cognitive_coeff\n        self.social_coeff = initial_social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.stagnation_threshold = stagnation_threshold\n        self.mutation_rate = mutation_rate\n        self.cognitive_scaling = cognitive_scaling # Scale down cognitive coeff if stagnating, encourage exploration\n        self.social_scaling = social_scaling       # Scale up social coeff if stagnating, encourage exploitation\n\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.inertia = self.inertia_max\n        self.constriction_factor = self.calculate_constriction_factor()\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.stagnation_counter = 0\n\n    def calculate_constriction_factor(self):\n        phi = self.cognitive_coeff + self.social_coeff\n        if phi <= 4:\n            return 1.0\n        return 2 / np.abs(2 - phi - np.sqrt(phi**2 - 4 * phi))\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n        previous_global_best_fitness = self.global_best_fitness  # Store initial best fitness\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n\n                self.velocity[i] = self.constriction_factor * (self.inertia * self.velocity[i] + cognitive_component + social_component)\n                self.velocity[i] = np.clip(self.velocity[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                    else:\n                        self.stagnation_counter += 1  # Increment stagnation counter\n\n                population[i] = new_position.copy()\n\n            # Adjust inertia weight based on stagnation - Remove inertia adaptation. It can conflict with the coefficient adaptation\n            #if self.stagnation_counter > self.stagnation_threshold:\n            #    self.inertia = self.inertia_min  # Reduce inertia if stagnating\n            #else:\n            #    self.inertia = self.inertia_max  # Restore inertia if improving\n\n            # Adapt cognitive and social coefficients\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.cognitive_coeff *= self.cognitive_scaling  # Reduce cognitive influence\n                self.social_coeff *= self.social_scaling       # Increase social influence\n                self.stagnation_counter = 0 # Reset\n\n            # Mutation operator (applied to global best if still stagnating)\n            if self.stagnation_counter > 2 * self.stagnation_threshold:\n                # Mutate global best position\n                mutation_indices = np.random.choice(self.dim, int(self.mutation_rate * self.dim), replace=False)\n                self.global_best_position[mutation_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=len(mutation_indices))\n                self.global_best_fitness = func(self.global_best_position)\n                self.budget -=1 # Function evaluation for the mutated solution\n                self.stagnation_counter = 0 # reset counter\n\n            self.constriction_factor = self.calculate_constriction_factor()\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptivePSO scored 0.429 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["36f8dfe7-b803-4652-b181-fa07b92506d8"], "operator": null, "metadata": {"aucs": [0.17490244260783383, 0.18085346273465586, 0.4483449406519501, 0.2591229247117779, 0.2635292438773502, 0.8562598492939338, 0.2560768482908987, 0.4411982990706548, 0.26858177759104573, 0.17915422495432975, 0.49176659693185065, 0.9891886513002096, 0.3812005169570618, 0.20609250932024736, 0.737052955741004, 0.4112052240646239, 0.412387292984541, 0.9503001210947423, 0.20994397180168145, 0.4594636379526782]}}
{"id": "277871a9-a16f-487c-b2ab-476ad77e3922", "fitness": 0.2553709163200772, "name": "AdaptiveDimensionLearning", "description": "Population-based search with adaptive learning rates for each dimension, exploiting promising directions while maintaining diversity.", "code": "import numpy as np\n\nclass AdaptiveDimensionLearning:\n    def __init__(self, budget=10000, dim=10, pop_size=None, learning_rate_initial=0.1, learning_rate_decay=0.99, learning_rate_min=0.001):\n        \"\"\"\n        Initialize the Adaptive Dimension Learning algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The population size. If None, set to 10*dim.\n            learning_rate_initial (float, optional): The initial learning rate for each dimension.\n            learning_rate_decay (float, optional): The decay rate for the learning rate.\n            learning_rate_min (float, optional): The minimum learning rate.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.learning_rate = np.full(dim, learning_rate_initial)\n        self.learning_rate_decay = learning_rate_decay\n        self.learning_rate_min = learning_rate_min\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        self.best_individual_history = []\n\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def update_population(self, func):\n        \"\"\"Update the population based on individual learning rates for each dimension.\"\"\"\n        for i in range(self.pop_size):\n            # Select a random individual from the population (excluding itself)\n            other_indices = list(range(self.pop_size))\n            other_indices.remove(i)\n            j = np.random.choice(other_indices)\n\n            # Update each dimension with its learning rate\n            new_x = self.pop[i].copy()\n            for d in range(self.dim):\n                # Move towards the other individual in that dimension\n                step = self.learning_rate[d] * (self.pop[j, d] - self.pop[i, d])\n                new_x[d] += step\n\n            # Clip values to respect bounds\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(new_x)\n            self.eval_count += 1\n\n            if f_new < self.fitness[i]:\n                self.pop[i] = new_x\n                self.fitness[i] = f_new\n\n        # Update global best\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n            self.best_individual_history.append(self.f_opt)\n        else:\n             self.best_individual_history.append(self.f_opt)\n\n\n    def update_learning_rates(self):\n        \"\"\"Update the learning rates for each dimension based on the history of the best solution.\"\"\"\n        if len(self.best_individual_history) > 10:  # Ensure enough history to evaluate\n            # Check if the best solution has improved significantly in recent iterations\n            improvement = self.best_individual_history[-10] - self.best_individual_history[-1]\n            if improvement > 1e-6: # If the best solution improved recently, slow down learning in all dimensions\n                 self.learning_rate *= self.learning_rate_decay\n            else: # If the best solution has stagnated, speed up learning in random dimension(s)\n                 num_dimensions_to_increase = np.random.randint(1, self.dim // 2 +1) # Modify random dimensions\n                 dimensions_to_increase = np.random.choice(self.dim, size = num_dimensions_to_increase, replace = False)\n                 self.learning_rate[dimensions_to_increase] /= self.learning_rate_decay\n\n\n        self.learning_rate = np.clip(self.learning_rate, self.learning_rate_min, 1.0)\n\n\n    def __call__(self, func):\n        \"\"\"Optimize the given function using Adaptive Dimension Learning.\"\"\"\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_population(func)\n            self.update_learning_rates()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDimensionLearning scored 0.255 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b2e9bb00-af31-43ef-8249-d73ed310be9a"], "operator": null, "metadata": {"aucs": [0.1059120098121279, 0.20369070748262053, 0.29944668510585004, 0.19347283980534713, 0.18226804307176403, 0.2269235749554266, 0.21727841833499362, 0.1936440733509034, 0.18323460417611048, 0.16823507561944206, 0.18175200093833654, 0.9968213598695931, 0.2561490605024851, 0.18982533627553955, 0.1749207727180938, 0.2745594008600398, 0.21088213229695618, 0.23152922582540125, 0.17843312893561347, 0.438439876464899]}}
{"id": "66b7eb15-6283-4b79-89ce-1c329169cf0d", "fitness": 0.29533416031400506, "name": "RingTopologyAdaptivePSO", "description": "A PSO variant that incorporates a ring topology for social interaction, adaptive velocity clamping based on population diversity, and a polynomial mutation operator for enhanced exploration.", "code": "import numpy as np\n\nclass RingTopologyAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, initial_velocity_clamp=0.5,\n                 diversity_threshold=0.1, polynomial_mutation_rate=0.05, polynomial_mutation_strength=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = initial_velocity_clamp\n        self.initial_velocity_clamp = initial_velocity_clamp\n        self.diversity_threshold = diversity_threshold\n        self.polynomial_mutation_rate = polynomial_mutation_rate\n        self.polynomial_mutation_strength = polynomial_mutation_strength\n\n        self.population = None\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def calculate_diversity(self):\n        \"\"\"Calculates the average distance of each particle from the population mean.\"\"\"\n        mean_position = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - mean_position, axis=1)\n        return np.mean(distances)\n\n    def polynomial_mutation(self, x):\n        \"\"\"Applies polynomial mutation to a particle.\"\"\"\n        for i in range(self.dim):\n            if np.random.rand() < self.polynomial_mutation_rate:\n                u = np.random.rand()\n                if u < 0.5:\n                    delta = (2 * u)**(1 / (self.polynomial_mutation_strength + 1)) - 1\n                else:\n                    delta = 1 - (2 * (1 - u))**(1 / (self.polynomial_mutation_strength + 1))\n                x[i] += delta * (5.0 - (-5.0))  # Assuming bounds are -5 and 5. Adjust if different.\n                x[i] = np.clip(x[i], -5.0, 5.0)\n        return x\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-self.initial_velocity_clamp, self.initial_velocity_clamp, size=(self.pop_size, self.dim))\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = self.population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            diversity = self.calculate_diversity()\n\n            # Adjust velocity clamp based on diversity\n            if diversity < self.diversity_threshold:\n                self.velocity_clamp = min(self.velocity_clamp * 1.05, 1.0)  # Increase to explore more\n            else:\n                self.velocity_clamp = max(self.velocity_clamp * 0.95, 0.1)  # Decrease to exploit more\n\n            for i in range(self.pop_size):\n                # Ring topology: social interaction with neighbors\n                left_neighbor_index = (i - 1) % self.pop_size\n                right_neighbor_index = (i + 1) % self.pop_size\n\n                # Select the best neighbor\n                if self.personal_best_fitness[left_neighbor_index] < self.personal_best_fitness[right_neighbor_index]:\n                    best_neighbor_position = self.personal_best_positions[left_neighbor_index]\n                else:\n                    best_neighbor_position = self.personal_best_positions[right_neighbor_index]\n\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.social_coeff * np.random.rand() * (best_neighbor_position - self.population[i])  # Social interaction with neighbor\n                self.velocity[i] = self.velocity_clamp * (self.velocity[i] + cognitive_component + social_component)\n                self.velocity[i] = np.clip(self.velocity[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = self.population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Polynomial mutation\n                new_position = self.polynomial_mutation(new_position)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n                self.population[i] = new_position.copy()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm RingTopologyAdaptivePSO scored 0.295 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2369d5ed-d65e-42fd-a2b5-d4d84101bde6"], "operator": null, "metadata": {"aucs": [0.11621095204879717, 0.18195277635973195, 0.27604889975376035, 0.24272256047224228, 0.2196366971283894, 0.25569393727382006, 0.23353278874701222, 0.21638593821996788, 0.21210717908901944, 0.16617794411841336, 0.22936316560070735, 0.9879676300842856, 0.2794625863282775, 0.20199525624471215, 0.6191606585443286, 0.27593185276515264, 0.2615082368998477, 0.26937054712039876, 0.19495056690421797, 0.46650303257701875]}}
{"id": "3dc203af-2b52-45d8-8fcf-fd47b135db27", "fitness": 0.3110679129703469, "name": "DynamicNeighborhoodPSO", "description": "A PSO variant with a dynamic neighborhood topology and adaptive learning coefficients based on individual particle performance.", "code": "import numpy as np\n\nclass DynamicNeighborhoodPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, neighborhood_size=5, cognitive_coeff_max=2.5, cognitive_coeff_min=1.5, social_coeff_max=2.5, social_coeff_min=1.5, inertia_weight=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.neighborhood_size = neighborhood_size\n        self.cognitive_coeff_max = cognitive_coeff_max\n        self.cognitive_coeff_min = cognitive_coeff_min\n        self.social_coeff_max = social_coeff_max\n        self.social_coeff_min = social_coeff_min\n        self.inertia_weight = inertia_weight\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        velocity = np.zeros((self.pop_size, self.dim))\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Dynamic neighborhood selection\n                distances = np.linalg.norm(population - population[i], axis=1)\n                neighbors_indices = np.argsort(distances)[1:self.neighborhood_size+1]  # Exclude self\n\n                # Find best neighbor\n                best_neighbor_index = neighbors_indices[np.argmin(fitness[neighbors_indices])]\n                best_neighbor_position = population[best_neighbor_index]\n\n                # Adaptive learning coefficients based on individual performance\n                performance_ratio = (np.max(personal_best_fitness) - personal_best_fitness[i]) / (np.max(personal_best_fitness) - np.min(personal_best_fitness) + 1e-8) # Avoid division by zero\n\n                cognitive_coeff = self.cognitive_coeff_min + (self.cognitive_coeff_max - self.cognitive_coeff_min) * performance_ratio\n                social_coeff = self.social_coeff_min + (self.social_coeff_max - self.social_coeff_min) * (1 - performance_ratio)\n\n                # Update velocity\n                cognitive_component = cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social_component = social_coeff * np.random.rand(self.dim) * (best_neighbor_position - population[i])\n\n                velocity[i] = self.inertia_weight * velocity[i] + cognitive_component + social_component\n\n                # Update position\n                new_position = population[i] + velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n\n            global_best_index = np.argmin(personal_best_fitness)\n            global_best_fitness = personal_best_fitness[global_best_index]\n            global_best_position = personal_best_positions[global_best_index]\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm DynamicNeighborhoodPSO scored 0.311 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["36f8dfe7-b803-4652-b181-fa07b92506d8"], "operator": null, "metadata": {"aucs": [0.1342716934247159, 0.2535049996966122, 0.2695542116455405, 0.2594759194906242, 0.23939971345629063, 0.27479443382425295, 0.2621985817902226, 0.22321711035919278, 0.22013932770905797, 0.1789463909521064, 0.2332432881321277, 0.9974250435644937, 0.3069130214676308, 0.2421754147683639, 0.6347134772230045, 0.3012466976698075, 0.2253349198850847, 0.3241736653409161, 0.17223197217784347, 0.46839837682904994]}}
{"id": "4e826d91-e38c-4e64-8d5a-91a1a64f2cfa", "fitness": 0.0, "name": "AdaptivePSOLocalSearch", "description": "An adaptive PSO variant that incorporates a local search strategy around the personal best positions, combined with velocity scaling to fine-tune exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptivePSOLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, velocity_clamp=0.5, local_search_probability=0.1, velocity_scaling=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.local_search_probability = local_search_probability\n        self.velocity_scaling = velocity_scaling  # Scale the velocity magnitude\n        self.inertia = 0.7  # Fixed inertia weight\n        self.constriction_factor = self.calculate_constriction_factor()\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def calculate_constriction_factor(self):\n        phi = self.cognitive_coeff + self.social_coeff\n        if phi <= 4:\n            return 1.0\n        return 2 / np.abs(2 - phi - np.sqrt(phi**2 - 4 * phi))\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n\n                self.velocity[i] = self.constriction_factor * (self.inertia * self.velocity[i] + cognitive_component + social_component)\n                self.velocity[i] = np.clip(self.velocity[i], -self.velocity_clamp, self.velocity_clamp) * self.velocity_scaling #Scale velocity magnitude\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Local search around personal best\n                if np.random.rand() < self.local_search_probability:\n                    step_size = 0.01 * (func.bounds.ub - func.bounds.lb)  # Small step size\n                    local_position = self.personal_best_positions[i] + np.random.uniform(-step_size, step_size, size=self.dim)\n                    local_position = np.clip(local_position, func.bounds.lb, func.bounds.ub)\n                    local_fitness = func(local_position)\n                    self.budget -= 1\n\n                    if local_fitness < self.personal_best_fitness[i]:\n                        new_fitness = local_fitness\n                        new_position = local_position\n                    else:\n                        new_fitness = func(new_position)\n                        self.budget -=1\n\n                else:\n                     new_fitness = func(new_position)\n                     self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptivePSOLocalSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["36f8dfe7-b803-4652-b181-fa07b92506d8"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "b04a7014-dc92-4ce2-b66c-fda6e52390f2", "fitness": 0.4366211372068399, "name": "ShrinkingNeighborhoodPSO", "description": "A PSO variant with a shrinking exploration radius around the global best and adaptive mutation to escape local optima.", "code": "import numpy as np\n\nclass ShrinkingNeighborhoodPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05,\n                 velocity_clamp=0.5, initial_exploration_radius=1.0, shrinking_rate=0.99, mutation_rate=0.01,\n                 mutation_strength=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.exploration_radius = initial_exploration_radius\n        self.shrinking_rate = shrinking_rate\n        self.mutation_rate = mutation_rate\n        self.mutation_strength = mutation_strength\n\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.particles])\n        self.budget -= self.pop_size\n\n        self.velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = self.particles[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - self.particles[i])\n                self.velocities[i] = self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = self.particles[i] + self.velocities[i]\n\n                # Shrinking Neighborhood: Random exploration within radius around global best\n                exploration_vector = np.random.uniform(-self.exploration_radius, self.exploration_radius, size=self.dim)\n                new_position = self.global_best_position + exploration_vector\n\n                # Adaptive Mutation: Introduce random mutation with probability mutation_rate\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, self.mutation_strength, size=self.dim)\n                    new_position = new_position + mutation\n\n                new_position = np.clip(new_position, lb, ub)  # Clip to bounds\n\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n                self.particles[i] = new_position.copy()\n\n            # Shrink the exploration radius\n            self.exploration_radius *= self.shrinking_rate\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm ShrinkingNeighborhoodPSO scored 0.437 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["36f8dfe7-b803-4652-b181-fa07b92506d8"], "operator": null, "metadata": {"aucs": [0.161520791023803, 0.17060468083963332, 0.4545025062127179, 0.17221312688886792, 0.4160180446765237, 0.4965439754534259, 0.2784520383991069, 0.39342988231235854, 0.41476841858545577, 0.17407902039097933, 0.7340662851500732, 0.9972319915920507, 0.2999917062630064, 0.4193140672033199, 0.8896993638807679, 0.5123090907820287, 0.40363364263537116, 0.601345963387989, 0.23939468064746516, 0.5033034678118542]}}
{"id": "15c062ea-9da2-46d4-896b-199b56c90c60", "fitness": -Infinity, "name": "AdaptiveDifferentialPSO", "description": "Hybrid PSO with adaptive exploration radius based on population diversity and differential evolution for enhanced local search.", "code": "import numpy as np\n\nclass AdaptiveDifferentialPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05,\n                 velocity_clamp=0.5, initial_exploration_radius=1.0, diversity_threshold=0.1,\n                 differential_weight=0.7, crossover_rate=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.exploration_radius = initial_exploration_radius\n        self.diversity_threshold = diversity_threshold\n        self.differential_weight = differential_weight\n        self.crossover_rate = crossover_rate\n\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.particles])\n        self.budget -= self.pop_size\n\n        self.velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = self.particles[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            # Calculate population diversity\n            diversity = np.std(self.particles)\n\n            # Adjust exploration radius based on diversity\n            if diversity > self.diversity_threshold:\n                self.exploration_radius = min(self.exploration_radius * 1.05, (ub - lb)/2)  # Increase exploration\n            else:\n                self.exploration_radius = max(self.exploration_radius * 0.95, 0.01) # Decrease exploration\n\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - self.particles[i])\n                self.velocities[i] = self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = self.particles[i] + self.velocities[i]\n\n                # Exploration: Random exploration within radius\n                exploration_vector = np.random.uniform(-self.exploration_radius, self.exploration_radius, size=self.dim)\n                new_position = new_position + exploration_vector\n\n                # Differential Evolution: Apply differential evolution to enhance local search\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                diff_vector = self.differential_weight * (self.particles[r2] - self.particles[r3])\n                trial_vector = self.particles[r1] + diff_vector\n\n                # Crossover\n                for j in range(self.dim):\n                    if np.random.rand() > self.crossover_rate:\n                        trial_vector[j] = new_position[j]\n\n                new_position = trial_vector\n                new_position = np.clip(new_position, lb, ub)  # Clip to bounds\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n                self.particles[i] = new_position.copy()\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "An exception occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().", "error": "", "parent_ids": ["b04a7014-dc92-4ce2-b66c-fda6e52390f2"], "operator": null, "metadata": {}}
{"id": "71c00acf-17c2-4eec-ae90-deab57181e83", "fitness": -Infinity, "name": "AdaptivePSO_Restart", "description": "An adaptive PSO that dynamically adjusts the population size and restarts the population when stagnation occurs.", "code": "import numpy as np\n\nclass AdaptivePSO_Restart:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=20, min_pop_size=5, max_pop_size=50,\n                 cognitive_coeff=2.05, social_coeff=2.05, velocity_clamp=0.5,\n                 stagnation_threshold=50, stagnation_restart_threshold=100,\n                 mutation_rate=0.1, pop_size_adjust_freq=20, pop_size_increase_factor=1.1, pop_size_decrease_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.max_pop_size = max_pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_restart_threshold = stagnation_restart_threshold\n        self.mutation_rate = mutation_rate\n        self.pop_size_adjust_freq = pop_size_adjust_freq\n        self.pop_size_increase_factor = pop_size_increase_factor\n        self.pop_size_decrease_factor = pop_size_decrease_factor\n\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.inertia = self.inertia_max\n        self.constriction_factor = self.calculate_constriction_factor()\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.stagnation_counter = 0\n        self.iteration = 0\n\n    def calculate_constriction_factor(self):\n        phi = self.cognitive_coeff + self.social_coeff\n        if phi <= 4:\n            return 1.0\n        return 2 / np.abs(2 - phi - np.sqrt(phi**2 - 4 * phi))\n\n    def initialize_population(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        return population, fitness\n\n    def adjust_population_size(self):\n        if self.stagnation_counter > self.stagnation_threshold:\n            new_pop_size = int(self.pop_size * self.pop_size_increase_factor)\n            self.pop_size = min(new_pop_size, self.max_pop_size)\n        else:\n            new_pop_size = int(self.pop_size * self.pop_size_decrease_factor)\n            self.pop_size = max(new_pop_size, self.min_pop_size)\n\n    def __call__(self, func):\n        population, fitness = self.initialize_population(func)\n        previous_global_best_fitness = self.global_best_fitness\n\n        while self.budget > 0:\n            self.iteration += 1\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n\n                self.velocity[i] = self.constriction_factor * (self.inertia * self.velocity[i] + cognitive_component + social_component)\n                self.velocity[i] = np.clip(self.velocity[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                        self.stagnation_counter = 0\n                    else:\n                        self.stagnation_counter += 1\n\n                population[i] = new_position.copy()\n\n            # Mutation operator (applied to global best if still stagnating)\n            if self.stagnation_counter > self.stagnation_restart_threshold:\n                # Restart the population\n                population, fitness = self.initialize_population(func)\n                self.stagnation_counter = 0\n                continue # Skip to the next iteration.\n\n            if self.iteration % self.pop_size_adjust_freq == 0:\n                self.adjust_population_size()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "An exception occurred: index 20 is out of bounds for axis 0 with size 20.", "error": "", "parent_ids": ["10b078e1-593a-415a-af38-a7a9ee92df06"], "operator": null, "metadata": {}}
{"id": "2282dace-c956-4c95-a1e2-600ea00913e4", "fitness": -Infinity, "name": "FuzzyAdaptivePSO", "description": "An adaptive PSO algorithm that dynamically adjusts its exploration-exploitation balance using a fuzzy logic controller based on population diversity and individual particle performance.", "code": "import numpy as np\nimport skfuzzy as fuzz\nfrom skfuzzy import control as ctrl\n\nclass FuzzyAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, velocity_clamp=0.5,\n                 inertia_weight_range=(0.4, 0.9), cognitive_coeff_range=(1.5, 2.5),\n                 social_coeff_range=(1.5, 2.5)):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.velocity_clamp = velocity_clamp\n        self.inertia_weight_range = inertia_weight_weight_range\n        self.cognitive_coeff_range = cognitive_coeff_range\n        self.social_coeff_range = social_coeff_range\n\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n        # Fuzzy Logic Controller Setup\n        self.diversity = ctrl.Antecedent(np.linspace(0, 1, 100), 'diversity')\n        self.individual_performance = ctrl.Antecedent(np.linspace(0, 1, 100), 'individual_performance')\n        self.inertia_weight = ctrl.Consequent(np.linspace(inertia_weight_range[0], inertia_weight_range[1], 100), 'inertia_weight')\n        self.cognitive_coeff = ctrl.Consequent(np.linspace(cognitive_coeff_range[0], cognitive_coeff_range[1], 100), 'cognitive_coeff')\n        self.social_coeff = ctrl.Consequent(np.linspace(social_coeff_range[0], social_coeff_range[1], 100), 'social_coeff')\n\n        # Membership Functions (Triangular) - Can be customized\n        self.diversity['low'] = fuzz.trimf(self.diversity.universe, [0, 0, 0.5])\n        self.diversity['medium'] = fuzz.trimf(self.diversity.universe, [0, 0.5, 1])\n        self.diversity['high'] = fuzz.trimf(self.diversity.universe, [0.5, 1, 1])\n\n        self.individual_performance['poor'] = fuzz.trimf(self.individual_performance.universe, [0, 0, 0.5])\n        self.individual_performance['average'] = fuzz.trimf(self.individual_performance.universe, [0, 0.5, 1])\n        self.individual_performance['good'] = fuzz.trimf(self.individual_performance.universe, [0.5, 1, 1])\n\n        self.inertia_weight['low'] = fuzz.trimf(self.inertia_weight.universe, [inertia_weight_range[0], inertia_weight_range[0], (inertia_weight_range[0] + inertia_weight_range[1])/2])\n        self.inertia_weight['medium'] = fuzz.trimf(self.inertia_weight.universe, [inertia_weight_range[0], (inertia_weight_range[0] + inertia_weight_range[1])/2, inertia_weight_range[1]])\n        self.inertia_weight['high'] = fuzz.trimf(self.inertia_weight.universe, [(inertia_weight_range[0] + inertia_weight_range[1])/2, inertia_weight_range[1], inertia_weight_range[1]])\n\n        self.cognitive_coeff['low'] = fuzz.trimf(self.cognitive_coeff.universe, [cognitive_coeff_range[0], cognitive_coeff_range[0], (cognitive_coeff_range[0] + cognitive_coeff_range[1])/2])\n        self.cognitive_coeff['medium'] = fuzz.trimf(self.cognitive_coeff.universe, [cognitive_coeff_range[0], (cognitive_coeff_range[0] + cognitive_coeff_range[1])/2, cognitive_coeff_range[1]])\n        self.cognitive_coeff['high'] = fuzz.trimf(self.cognitive_coeff.universe, [(cognitive_coeff_range[0] + cognitive_coeff_range[1])/2, cognitive_coeff_range[1], cognitive_coeff_range[1]])\n\n        self.social_coeff['low'] = fuzz.trimf(self.social_coeff.universe, [social_coeff_range[0], social_coeff_range[0], (social_coeff_range[0] + social_coeff_range[1])/2])\n        self.social_coeff['medium'] = fuzz.trimf(self.social_coeff.universe, [social_coeff_range[0], (social_coeff_range[0] + social_coeff_range[1])/2, social_coeff_range[1]])\n        self.social_coeff['high'] = fuzz.trimf(self.social_coeff.universe, [(social_coeff_range[0] + social_coeff_range[1])/2, social_coeff_range[1], social_coeff_range[1]])\n\n        # Rules - Define how diversity and individual performance affect PSO parameters\n        rule1 = ctrl.Rule(self.diversity['low'] & self.individual_performance['poor'], [self.inertia_weight['high'], self.cognitive_coeff['low'], self.social_coeff['high']])\n        rule2 = ctrl.Rule(self.diversity['low'] & self.individual_performance['average'], [self.inertia_weight['high'], self.cognitive_coeff['medium'], self.social_coeff['medium']])\n        rule3 = ctrl.Rule(self.diversity['low'] & self.individual_performance['good'], [self.inertia_weight['medium'], self.cognitive_coeff['high'], self.social_coeff['low']])\n        rule4 = ctrl.Rule(self.diversity['medium'] & self.individual_performance['poor'], [self.inertia_weight['medium'], self.cognitive_coeff['low'], self.social_coeff['high']])\n        rule5 = ctrl.Rule(self.diversity['medium'] & self.individual_performance['average'], [self.inertia_weight['medium'], self.cognitive_coeff['medium'], self.social_coeff['medium']])\n        rule6 = ctrl.Rule(self.diversity['medium'] & self.individual_performance['good'], [self.inertia_weight['low'], self.cognitive_coeff['high'], self.social_coeff['low']])\n        rule7 = ctrl.Rule(self.diversity['high'] & self.individual_performance['poor'], [self.inertia_weight['medium'], self.cognitive_coeff['low'], self.social_coeff['high']])\n        rule8 = ctrl.Rule(self.diversity['high'] & self.individual_performance['average'], [self.inertia_weight['low'], self.cognitive_coeff['medium'], self.social_coeff['medium']])\n        rule9 = ctrl.Rule(self.diversity['high'] & self.individual_performance['good'], [self.inertia_weight['low'], self.cognitive_coeff['high'], self.social_coeff['low']])\n\n        self.parameter_control = ctrl.ControlSystem([rule1, rule2, rule3, rule4, rule5, rule6, rule7, rule8, rule9])\n        self.parameter_simulation = ctrl.ControlSystemSimulation(self.parameter_control)\n\n    def calculate_diversity(self):\n        # Calculate diversity based on the average distance from the centroid\n        centroid = np.mean(self.particles, axis=0)\n        distances = np.linalg.norm(self.particles - centroid, axis=1)\n        avg_distance = np.mean(distances)\n        max_possible_distance = np.linalg.norm(np.ones(self.dim) * 5 - np.ones(self.dim) * -5) # rough estimate\n        diversity = avg_distance / max_possible_distance # Normalize to [0, 1]\n        return diversity\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.particles])\n        self.budget -= self.pop_size\n\n        self.velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = self.particles[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            diversity_value = self.calculate_diversity()\n\n            for i in range(self.pop_size):\n                #Calculate individual particle performance, normalize to [0, 1].\n                performance = (np.max(fitness) - fitness[i]) / (np.max(fitness) - np.min(fitness) + 1e-8) #avoid division by zero\n\n                # Fuzzy Logic Inference\n                self.parameter_simulation.input['diversity'] = diversity_value\n                self.parameter_simulation.input['individual_performance'] = performance\n                self.parameter_simulation.compute()\n\n                inertia_weight = self.parameter_simulation.output['inertia_weight']\n                cognitive_coeff = self.parameter_simulation.output['cognitive_coeff']\n                social_coeff = self.parameter_simulation.output['social_coeff']\n                \n\n                # Update velocity\n                cognitive_component = cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - self.particles[i])\n                social_component = social_coeff * np.random.rand() * (self.global_best_position - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)  # Clip to bounds\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n                self.particles[i] = new_position.copy()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "An exception occurred: No module named 'skfuzzy'.", "error": "", "parent_ids": ["b04a7014-dc92-4ce2-b66c-fda6e52390f2"], "operator": null, "metadata": {}}
{"id": "f7edd57b-299d-4619-a375-13776da4e2aa", "fitness": 0.34974256572986817, "name": "RepulsivePSO", "description": "A PSO variant employing a repulsive force from the worst-performing particles to enhance exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass RepulsivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.0, social_coeff=2.0, inertia_weight=0.7, repulsion_strength=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.inertia_weight = inertia_weight\n        self.repulsion_strength = repulsion_strength\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        velocity = np.zeros((self.pop_size, self.dim))\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        while self.budget > 0:\n            worst_index = np.argmax(fitness)  # Find the worst particle\n            worst_position = population[worst_index].copy()\n            \n            for i in range(self.pop_size):\n                # Repulsion from the worst particle\n                repulsion_component = self.repulsion_strength * np.random.rand(self.dim) * (population[i] - worst_position)\n\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i])\n\n                velocity[i] = self.inertia_weight * velocity[i] + cognitive_component + social_component + repulsion_component\n\n                # Update position\n                new_position = population[i] + velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n                fitness[i] = new_fitness\n\n            global_best_index = np.argmin(personal_best_fitness)\n            global_best_fitness = personal_best_fitness[global_best_index]\n            global_best_position = personal_best_positions[global_best_index]\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm RepulsivePSO scored 0.350 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3dc203af-2b52-45d8-8fcf-fd47b135db27"], "operator": null, "metadata": {"aucs": [0.1678145679310955, 0.2941672518139965, 0.3606416615108413, 0.24255347291910967, 0.26714486898042755, 0.2771255092462489, 0.29992630897744144, 0.33265693022212617, 0.21044688319991245, 0.2161161978173919, 0.4597804635825672, 0.9982566032780879, 0.22871518131009982, 0.24409659528746874, 0.6446530941847461, 0.39118233448604356, 0.2503658145390678, 0.3774981147801212, 0.2543156096779545, 0.4773938508526153]}}
{"id": "bdafd60a-88f4-42df-81e9-605c74097218", "fitness": 0.4448661559733787, "name": "PSO_CMAES", "description": "A hybrid algorithm that combines PSO with a covariance matrix adaptation evolution strategy (CMA-ES) for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass PSO_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, w_max=0.9, w_min=0.4, cmaes_frequency=10, sigma0=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.w_max = w_max\n        self.w_min = w_min\n        self.cmaes_frequency = cmaes_frequency  # How often to run CMA-ES\n        self.sigma0 = sigma0  # Initial step size for CMA-ES\n\n        self.inertia = self.w_max\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.generation = 0\n\n    def cma_es(self, func, x0, sigma, iterations):\n        \"\"\"\n        Performs a simplified CMA-ES.\n        \"\"\"\n        mean = x0.copy()\n        C = np.eye(self.dim)  # Initial covariance matrix\n\n        best_fitness = np.inf\n        best_position = None\n\n        for _ in range(iterations):\n            z = np.random.multivariate_normal(np.zeros(self.dim), C, self.pop_size)\n            x = mean + sigma * z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            fitness = np.array([func(xi) for xi in x])\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < best_fitness:\n                best_fitness = fitness[best_idx]\n                best_position = x[best_idx].copy()\n                \n            # Simple update of the mean (can be improved with selection)\n            mean = np.mean(x, axis=0) \n\n        return best_fitness, best_position\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            # Update inertia weight linearly\n            self.inertia = self.w_max - (self.w_max - self.w_min) * (1 - self.generation / (self.budget+self.generation))\n\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                \n                population[i] = new_position.copy()\n                fitness[i] = new_fitness\n                \n            # Apply CMA-ES every cmaes_frequency generations\n            if self.generation % self.cmaes_frequency == 0 and self.budget > self.pop_size*self.dim: #adjust the budget condition\n                best_fitness_cmaes, best_position_cmaes = self.cma_es(func, self.global_best_position, self.sigma0, self.dim)\n                self.budget -= self.pop_size*self.dim\n\n                if best_fitness_cmaes < self.global_best_fitness:\n                    self.global_best_fitness = best_fitness_cmaes\n                    self.global_best_position = best_position_cmaes.copy()\n            \n            self.generation += 1\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm PSO_CMAES scored 0.445 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["555d7cb1-b5cd-48ff-876d-8b8343aeb3aa"], "operator": null, "metadata": {"aucs": [0.11552194461440235, 0.2216097869816186, 0.4377165441773223, 0.8604044311249637, 0.18732384410103475, 0.24323011618474544, 0.2862182087555655, 0.41759610285647353, 0.32065472148078933, 0.19729312902251162, 0.8573653355750621, 0.9973583692545973, 0.37119532753452644, 0.21635166499024183, 0.5446666479644646, 0.5352426349822269, 0.5182384511329392, 0.8527950820928444, 0.20893720611313515, 0.5076035705281099]}}
{"id": "b4f05c70-462f-49ae-aa5a-fcd1b9daef2f", "fitness": 0.37229610664356855, "name": "HybridPSOCentralForce", "description": "Hybrid optimization using PSO with a central force optimization to enhance exploration and exploitation around promising regions.", "code": "import numpy as np\n\nclass HybridPSOCentralForce:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05,\n                 velocity_clamp=0.5, central_force_magnitude=0.1, central_force_decay=0.99, stagnation_threshold=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.central_force_magnitude = central_force_magnitude\n        self.central_force_decay = central_force_decay\n        self.stagnation_threshold = stagnation_threshold\n\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.particles])\n        self.budget -= self.pop_size\n\n        self.velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = self.particles[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        previous_best_fitness = self.global_best_fitness\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity (PSO component)\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - self.particles[i])\n                self.velocities[i] = self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = self.particles[i] + self.velocities[i]\n\n                # Central Force Optimization component\n                force_vector = self.central_force_magnitude * (self.global_best_position - self.particles[i])\n                new_position = new_position + force_vector\n\n                new_position = np.clip(new_position, lb, ub)  # Clip to bounds\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                        self.stagnation_counter = 0 # Reset stagnation counter\n                else:\n                     self.stagnation_counter += 1\n\n                self.particles[i] = new_position.copy()\n\n\n            # Adaptive Central Force magnitude\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.central_force_magnitude *= self.central_force_decay\n                 self.stagnation_counter = 0\n                 # Optionally perturb the global best to escape local optima\n                 self.global_best_position = np.clip(self.global_best_position + np.random.normal(0, 0.05, size=self.dim), lb, ub)\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSOCentralForce scored 0.372 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b04a7014-dc92-4ce2-b66c-fda6e52390f2"], "operator": null, "metadata": {"aucs": [0.12856202557238483, 0.17946473193306078, 0.4086078073912369, 0.1982083883770811, 0.36124343449447893, 0.2964755939188377, 0.2554921488034363, 0.34067131068192125, 0.3607091566687066, 0.1758094302219705, 0.5030031900590396, 0.9938409142537925, 0.26965093685804, 0.32395148787032135, 0.801111858860603, 0.33223250065939547, 0.34404388504371586, 0.490774955377576, 0.21916285203641794, 0.462905523789354]}}
{"id": "47e08098-b47d-44cd-968e-6ae1b36537e4", "fitness": 0.5722057804669777, "name": "AdaptiveVelocityClampingPSO", "description": "A PSO variant with adaptive velocity clamping and a diversity-based restart mechanism to enhance exploration and avoid premature convergence.", "code": "import numpy as np\n\nclass AdaptiveVelocityClampingPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, clamp_factor=0.5, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.clamp_factor = clamp_factor\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize velocities\n        velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (func.bounds.ub - func.bounds.lb) * self.clamp_factor\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity with clamping\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i])\n\n                velocity[i] = self.inertia_weight * velocity[i] + cognitive_component + social_component\n\n                # Adaptive velocity clamping\n                v_max = self.clamp_factor * (func.bounds.ub - func.bounds.lb)\n                velocity[i] = np.clip(velocity[i], -v_max, v_max)\n\n                # Update position\n                new_position = population[i] + velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n\n            # Check population diversity\n            diversity = np.std(population)\n\n            # Restart if diversity is too low\n            if diversity < self.diversity_threshold:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (func.bounds.ub - func.bounds.lb) * self.clamp_factor\n\n                personal_best_positions = population.copy()\n                personal_best_fitness = fitness.copy()\n\n                global_best_index = np.argmin(fitness)\n                global_best_position = population[global_best_index].copy()\n                global_best_fitness = fitness[global_best_index].copy()\n            else:\n                global_best_index = np.argmin(personal_best_fitness)\n                global_best_fitness = personal_best_fitness[global_best_index]\n                global_best_position = personal_best_positions[global_best_index]\n\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveVelocityClampingPSO scored 0.572 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3dc203af-2b52-45d8-8fcf-fd47b135db27"], "operator": null, "metadata": {"aucs": [0.15801315239702673, 0.20817492611810384, 0.8507449236670479, 0.945447538375901, 0.2591122856611505, 0.9035213981865349, 0.328450256939964, 0.6015992113149868, 0.8726612133652951, 0.35981222463571727, 0.934787668524009, 0.9995734338748473, 0.24615566817932766, 0.2573958206176856, 0.6792456190343434, 0.8920705432735452, 0.32626901818147536, 0.9391069479987396, 0.22217463692053208, 0.4597991220733195]}}
{"id": "10a61bff-6846-41cd-8d0e-4870752e1f2d", "fitness": 0.38154819872259094, "name": "AdaptiveCauchyPSO", "description": "An adaptive PSO that dynamically adjusts its parameters based on population diversity and individual success rates, incorporating a Cauchy mutation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveCauchyPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05,\n                 inertia_weight=0.7, velocity_clamp=0.5, diversity_threshold=0.1, success_rate_threshold=0.2,\n                 cauchy_mutation_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.inertia_weight = inertia_weight\n        self.velocity_clamp = velocity_clamp\n        self.diversity_threshold = diversity_threshold\n        self.success_rate_threshold = success_rate_threshold\n        self.cauchy_mutation_scale = cauchy_mutation_scale\n\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.success_rates = np.zeros(pop_size)\n        self.success_counts = np.zeros(pop_size)\n        self.iteration = 0\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.particles])\n        self.budget -= self.pop_size\n\n        self.velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = self.particles[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            self.iteration += 1\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)  # Clip to bounds\n\n                # Cauchy Mutation\n                cauchy_mutation = self.cauchy_mutation_scale * np.random.standard_cauchy(size=self.dim)\n                new_position = new_position + cauchy_mutation\n                new_position = np.clip(new_position, lb, ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.success_counts[i] += 1\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n                self.particles[i] = new_position.copy()\n\n            # Adaptive Parameter Adjustment based on population diversity and success rates\n            if self.iteration % 10 == 0:\n                # Population Diversity\n                diversity = np.std(self.particles)\n\n                # Update success rates\n                self.success_rates = self.success_counts / 10\n                self.success_counts = np.zeros(self.pop_size)\n\n\n                if diversity < self.diversity_threshold:\n                    self.inertia_weight *= 0.95  # Reduce inertia for exploitation\n                    self.cognitive_coeff *= 0.95\n                    self.social_coeff *= 1.05 # Increase social to converge\n\n                else:\n                    self.inertia_weight *= 1.05  # Increase inertia for exploration\n                    self.cognitive_coeff *= 1.05\n                    self.social_coeff *= 0.95\n\n                # Adjust Cauchy Mutation Scale based on individual success\n                for i in range(self.pop_size):\n                    if self.success_rates[i] < self.success_rate_threshold:\n                        self.cauchy_mutation_scale *= 1.05 #Increase to explore if not succesful\n                    else:\n                        self.cauchy_mutation_scale *= 0.95\n\n                self.inertia_weight = np.clip(self.inertia_weight, 0.4, 0.9) #Keeping inertia in bounds\n                self.cognitive_coeff = np.clip(self.cognitive_coeff, 1.5, 2.5)\n                self.social_coeff = np.clip(self.social_coeff, 1.5, 2.5)\n                self.cauchy_mutation_scale = np.clip(self.cauchy_mutation_scale, 0.01, 0.5)\n\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveCauchyPSO scored 0.382 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b04a7014-dc92-4ce2-b66c-fda6e52390f2"], "operator": null, "metadata": {"aucs": [0.20041591365121547, 0.18253740845610444, 0.3901088557010146, 0.454407926144464, 0.31479247275238553, 0.41413514845671684, 0.2791087720319493, 0.3289134929592554, 0.3248222948404337, 0.19156674961847553, 0.43133944884908026, 0.9993401087677488, 0.2572321182308077, 0.30650629007341434, 0.7192135948676047, 0.3539001504002094, 0.3216927553135188, 0.49189497744486255, 0.17595237198106228, 0.4930831239114959]}}
{"id": "ee03a2d7-2bfd-4dff-ae8f-34b930372b0d", "fitness": 0.43233301507563804, "name": "AgingCauchyPSO", "description": "An adaptive PSO variant with a dynamic aging mechanism for particles, favoring exploration around younger, potentially better solutions, and a Cauchy mutation operator.", "code": "import numpy as np\n\nclass AgingCauchyPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_cognitive_coeff=2.05, initial_social_coeff=2.05,\n                 velocity_clamp=0.5, stagnation_threshold=50, mutation_rate=0.1, cognitive_scaling=0.99, social_scaling=1.01,\n                 age_threshold=50, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = initial_cognitive_coeff\n        self.social_coeff = initial_social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.stagnation_threshold = stagnation_threshold\n        self.mutation_rate = mutation_rate\n        self.cognitive_scaling = cognitive_scaling\n        self.social_scaling = social_scaling\n        self.age_threshold = age_threshold\n        self.cauchy_scale = cauchy_scale\n\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.inertia = self.inertia_max\n        self.constriction_factor = self.calculate_constriction_factor()\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.stagnation_counter = 0\n        self.particle_ages = np.zeros(self.pop_size) # Initialize particle ages\n\n    def calculate_constriction_factor(self):\n        phi = self.cognitive_coeff + self.social_coeff\n        if phi <= 4:\n            return 1.0\n        return 2 / np.abs(2 - phi - np.sqrt(phi**2 - 4 * phi))\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n        previous_global_best_fitness = self.global_best_fitness  # Store initial best fitness\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n\n                # Aging mechanism: Reduce influence of older particles\n                age_factor = 1.0 / (1.0 + self.particle_ages[i] / self.age_threshold)\n                self.velocity[i] = self.constriction_factor * (self.inertia * self.velocity[i] + age_factor * cognitive_component + age_factor * social_component)\n\n                self.velocity[i] = np.clip(self.velocity[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n                    self.particle_ages[i] = 0 # reset age\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                    else:\n                        self.stagnation_counter += 1  # Increment stagnation counter\n                else:\n                     self.particle_ages[i] +=1 # increment age if not improved\n                population[i] = new_position.copy()\n\n            # Adapt cognitive and social coefficients\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.cognitive_coeff *= self.cognitive_scaling  # Reduce cognitive influence\n                self.social_coeff *= self.social_scaling       # Increase social influence\n                self.stagnation_counter = 0 # Reset\n\n            # Mutation operator (applied to global best if still stagnating) - Cauchy mutation\n            if self.stagnation_counter > 2 * self.stagnation_threshold:\n                # Mutate global best position using Cauchy distribution\n                mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n                new_global_best = self.global_best_position + mutation\n                new_global_best = np.clip(new_global_best, func.bounds.lb, func.bounds.ub)\n                new_global_best_fitness = func(new_global_best)\n                self.budget -= 1\n\n                if new_global_best_fitness < self.global_best_fitness:\n                    self.global_best_fitness = new_global_best_fitness\n                    self.global_best_position = new_global_best.copy()\n\n                self.stagnation_counter = 0 # reset counter\n\n            self.constriction_factor = self.calculate_constriction_factor()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm AgingCauchyPSO scored 0.432 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["10b078e1-593a-415a-af38-a7a9ee92df06"], "operator": null, "metadata": {"aucs": [0.11766002987495305, 0.228589443431081, 0.5232291732826257, 0.19038268156140692, 0.27208941684654697, 0.7562411007385192, 0.24205662057334587, 0.438857483001602, 0.3769224676168976, 0.18941429777904084, 0.9400649344552954, 0.9944486439583721, 0.26232396183230056, 0.23064475215130464, 0.9370184495343143, 0.36428256000778614, 0.2986772441795119, 0.8196929331605542, 0.2472592876444183, 0.21680481988288236]}}
{"id": "16798695-c620-466b-adc8-cd2016c6b611", "fitness": 0.3308703480963428, "name": "EnhancedAdaptivePSO", "description": "An enhanced PSO variant featuring a velocity clamping mechanism, adaptive inertia weight based on population diversity, and a Cauchy mutation operator applied with a probability inversely proportional to the particle's fitness rank.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, velocity_clamp=0.5, cognitive_coeff=2.0, social_coeff=2.0, inertia_weight_max=0.9, inertia_weight_min=0.4, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.velocity_clamp = velocity_clamp\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.inertia_weight_max = inertia_weight_max\n        self.inertia_weight_min = inertia_weight_min\n        self.mutation_rate = mutation_rate\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        velocity = np.zeros((self.pop_size, self.dim))\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        while self.budget > 0:\n            # Calculate population diversity (variance of positions)\n            diversity = np.mean(np.var(population, axis=0))\n\n            # Adaptive inertia weight based on diversity\n            inertia_weight = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (diversity / (np.abs(func.bounds.ub[0] - func.bounds.lb[0])**2 + 1e-8))\n\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i])\n\n                velocity[i] = inertia_weight * velocity[i] + cognitive_component + social_component\n                velocity[i] = np.clip(velocity[i], -self.velocity_clamp * (func.bounds.ub[0] - func.bounds.lb[0]), self.velocity_clamp * (func.bounds.ub[0] - func.bounds.lb[0]))\n\n                # Update position\n                new_position = population[i] + velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                \n                # Cauchy mutation based on fitness rank\n                rank = np.argsort(fitness)[i] #get index of particle i in terms of fitness, after sorting the fitnesses\n                mutation_prob = 1.0 / (rank + 1) #Inversely proportional to rank\n                if np.random.rand() < mutation_prob * self.mutation_rate:\n                    mutation = np.random.standard_cauchy(size=self.dim) * (func.bounds.ub[0] - func.bounds.lb[0]) * 0.01 # scale Cauchy distribution\n                    new_position = np.clip(new_position + mutation, func.bounds.lb, func.bounds.ub)\n                \n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n\n            global_best_index = np.argmin(personal_best_fitness)\n            global_best_fitness = personal_best_fitness[global_best_index]\n            global_best_position = personal_best_positions[global_best_index]\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedAdaptivePSO scored 0.331 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3dc203af-2b52-45d8-8fcf-fd47b135db27"], "operator": null, "metadata": {"aucs": [0.15043586550765486, 0.22101797441343385, 0.32728073100590005, 0.3380674599889256, 0.2302454611754955, 0.269558521930243, 0.2713688008355237, 0.29364956217215055, 0.20968126813600574, 0.2058043364679496, 0.2676861590367814, 0.9971761831568694, 0.31035354604182674, 0.2442574001808192, 0.6717682498298903, 0.3251026747883953, 0.273123606813368, 0.36592175935258153, 0.1740382000419297, 0.4708692010511112]}}
{"id": "2d7990e2-1eab-4058-afc2-fe7a717931b7", "fitness": 0.45722675399073615, "name": "AdaptivePSOCauchyRestart", "description": "An adaptive PSO variant that uses a Cauchy mutation to enhance exploration and a restart mechanism when stagnation is detected.", "code": "import numpy as np\n\nclass AdaptivePSOCauchyRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, w_max=0.9, w_min=0.4, cauchy_scale=0.1, stagnation_threshold=1e-5, stagnation_iterations=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.w_max = w_max\n        self.w_min = w_min\n        self.cauchy_scale = cauchy_scale\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_iterations = stagnation_iterations\n\n        self.inertia = self.w_max\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.stagnation_counter = 0\n        self.previous_best_fitness = np.inf\n\n    def cauchy_mutation(self, x):\n        \"\"\"\n        Applies Cauchy mutation to a vector.\n        \"\"\"\n        mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n        self.previous_best_fitness = self.global_best_fitness\n\n        while self.budget > 0:\n            # Update inertia weight linearly\n            self.inertia = self.w_max - (self.w_max - self.w_min) * (1 - self.budget / 10000)\n\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Apply Cauchy mutation with a small probability\n                if np.random.rand() < 0.1:\n                    new_position = self.cauchy_mutation(new_position)\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n                fitness[i] = new_fitness\n\n            # Stagnation detection and restart mechanism\n            if abs(self.global_best_fitness - self.previous_best_fitness) < self.stagnation_threshold:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter >= self.stagnation_iterations:\n                # Restart: Re-initialize the population around the global best\n                population = np.random.normal(loc=self.global_best_position, scale=0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n                population = np.clip(population, func.bounds.lb, func.bounds.ub)\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size  # Account for new evaluations\n\n                self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n                self.personal_best_positions = population.copy()\n                self.personal_best_fitness = fitness.copy()\n\n                best_index = np.argmin(fitness)\n                self.global_best_position = population[best_index].copy()\n                self.global_best_fitness = fitness[best_index].copy()\n                \n                self.stagnation_counter = 0  # Reset stagnation counter\n\n            self.previous_best_fitness = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptivePSOCauchyRestart scored 0.457 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["555d7cb1-b5cd-48ff-876d-8b8343aeb3aa"], "operator": null, "metadata": {"aucs": [0.18505231368467334, 0.31828750960095087, 0.4540660906810625, 0.7568829397860801, 0.42433977091645503, 0.5092101261079074, 0.3027760767729848, 0.4054593240057752, 0.3481226676274122, 0.24615529583826135, 0.6564397476931565, 0.9994919232054991, 0.30426072806394, 0.4091315223197255, 0.7358452648215226, 0.4955897422919536, 0.36646517311924864, 0.5592339915372087, 0.1899787417124703, 0.47774613002843347]}}
{"id": "d4ddb961-3a17-490a-bec6-ebebaa1141cf", "fitness": 0.2536160099964658, "name": "AdaptivePSODE", "description": "An adaptive hybrid algorithm using PSO with a velocity clamping mechanism based on the current best solution and differential evolution (DE) for mutation.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, w_max=0.9, w_min=0.4, de_rate=0.1, velocity_clamp_factor=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.w_max = w_max\n        self.w_min = w_min\n        self.de_rate = de_rate\n        self.velocity_clamp_factor = velocity_clamp_factor\n\n        self.inertia = self.w_max\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def differential_evolution(self, population, best_position, F=0.5, Cr=0.7):\n        \"\"\"\n        Applies differential evolution mutation to the population.\n        \"\"\"\n        mutated_population = np.copy(population)\n        for i in range(self.pop_size):\n            # Choose three random indices, distinct from each other and i\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n\n            # Mutation\n            mutant = population[a] + F * (population[b] - population[c])\n\n            # Crossover\n            for j in range(self.dim):\n                if np.random.rand() > Cr:\n                    mutant[j] = population[i, j]\n\n            mutated_population[i] = mutant\n        return mutated_population\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            # Update inertia weight linearly\n            self.inertia = self.w_max - (self.w_max - self.w_min) * (1 - self.budget / 10000)\n\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Velocity clamping based on global best (adaptive clamping)\n                v_max = self.velocity_clamp_factor * np.abs(self.global_best_position - population[i])\n                self.velocity[i] = np.clip(self.velocity[i], -v_max, v_max)\n\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                \n                population[i] = new_position.copy()\n                fitness[i] = new_fitness\n\n            # Apply Differential Evolution with probability de_rate\n            if np.random.rand() < self.de_rate:\n                mutated_population = self.differential_evolution(population, self.global_best_position)\n                mutated_population = np.clip(mutated_population, func.bounds.lb, func.bounds.ub)\n                mutated_fitness = np.array([func(x) for x in mutated_population])\n                self.budget -= self.pop_size\n                \n                # Replace individuals if the mutant is better\n                for i in range(self.pop_size):\n                    if mutated_fitness[i] < fitness[i]:\n                        population[i] = mutated_population[i].copy()\n                        fitness[i] = mutated_fitness[i]\n                        if fitness[i] < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = fitness[i]\n                            self.personal_best_positions[i] = population[i].copy()\n                            if fitness[i] < self.global_best_fitness:\n                                self.global_best_fitness = fitness[i]\n                                self.global_best_position = population[i].copy()\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptivePSODE scored 0.254 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["555d7cb1-b5cd-48ff-876d-8b8343aeb3aa"], "operator": null, "metadata": {"aucs": [0.13283325301537885, 0.16769595002051085, 0.2805052629699364, 0.15882060995408886, 0.19153043415601156, 0.19084417259927, 0.2773666810311365, 0.23517960593993914, 0.1778378063396987, 0.18491735581780933, 0.18466547322827653, 0.9998266471388262, 0.28829409267714523, 0.15258186989479017, 0.18720417643450749, 0.2563310399360532, 0.2157177808882479, 0.176644106136855, 0.1618950650322165, 0.4516288167186162]}}
{"id": "5e7e549e-13fc-4293-97f8-01da2782f7b8", "fitness": -Infinity, "name": "PSOSimplex", "description": "A PSO variant incorporating a local search strategy based on Nelder-Mead simplex method to intensify the search around promising solutions found by PSO.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PSOSimplex:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, w_max=0.9, w_min=0.4, simplex_frequency=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.w_max = w_max\n        self.w_min = w_min\n        self.simplex_frequency = simplex_frequency\n        self.inertia = self.w_max\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.generation = 0\n\n    def local_search(self, func, x0):\n        \"\"\"\n        Performs a local search using the Nelder-Mead simplex method.\n        \"\"\"\n        bounds = func.bounds\n        res = minimize(func, x0, method='Nelder-Mead', bounds=list(zip(bounds.lb, bounds.ub)), options={'maxfev': self.dim})\n        return res.fun, res.x\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            # Update inertia weight linearly\n            self.inertia = self.w_max - (self.w_max - self.w_min) * (1 - self.generation / (self.budget+self.generation))\n\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                \n                population[i] = new_position.copy()\n                fitness[i] = new_fitness\n                \n            # Apply local search (Nelder-Mead) every simplex_frequency generations\n            if self.generation % self.simplex_frequency == 0:\n                \n                local_fitness, local_position = self.local_search(func, self.global_best_position)\n                self.budget -= self.dim\n\n                if local_fitness < self.global_best_fitness:\n                    self.global_best_fitness = local_fitness\n                    self.global_best_position = local_position.copy()\n            \n            self.generation += 1\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["bdafd60a-88f4-42df-81e9-605c74097218"], "operator": null, "metadata": {}}
{"id": "ae1cd9b9-5554-4d98-8ce2-47d00e1d2457", "fitness": -Infinity, "name": "PSO_NelderMead", "description": "Integrates a Nelder-Mead simplex method as a local search operator within PSO, periodically refining the best particle to improve exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PSO_NelderMead:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, w_max=0.9, w_min=0.4, nm_frequency=10, nm_max_iter=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.w_max = w_max\n        self.w_min = w_min\n        self.nm_frequency = nm_frequency  # How often to run Nelder-Mead\n        self.nm_max_iter = nm_max_iter\n\n        self.inertia = self.w_max\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.generation = 0\n\n    def nelder_mead(self, func, x0, bounds, max_iter):\n        \"\"\"\n        Performs Nelder-Mead optimization.\n        \"\"\"\n        result = minimize(func, x0, method='Nelder-Mead', bounds=bounds, options={'maxiter': max_iter, 'maxfev': self.budget})\n        return result.fun, result.x, result.nfev\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n\n        while self.budget > 0:\n            # Update inertia weight linearly\n            self.inertia = self.w_max - (self.w_max - self.w_min) * (1 - self.generation / (self.budget+self.generation))\n\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                \n                population[i] = new_position.copy()\n                fitness[i] = new_fitness\n\n            # Apply Nelder-Mead every nm_frequency generations\n            if self.generation % self.nm_frequency == 0 and self.budget > self.dim+1:\n                best_fitness_nm, best_position_nm, nfev = self.nelder_mead(func, self.global_best_position, bounds, self.nm_max_iter)\n                self.budget -= nfev\n\n                if best_fitness_nm < self.global_best_fitness:\n                    self.global_best_fitness = best_fitness_nm\n                    self.global_best_position = best_position_nm.copy()\n            \n            self.generation += 1\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["bdafd60a-88f4-42df-81e9-605c74097218"], "operator": null, "metadata": {}}
{"id": "90c1f7b4-39dd-414d-9809-762cc08796da", "fitness": -Infinity, "name": "PSO_NelderMead", "description": "A PSO variant incorporating a local search operator using Nelder-Mead simplex method applied probabilistically to promising particles, enhancing exploitation around potential optima.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PSO_NelderMead:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05,\n                 inertia_weight=0.7, velocity_clamp=0.5, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.inertia_weight = inertia_weight\n        self.velocity_clamp = velocity_clamp\n        self.local_search_prob = local_search_prob\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.particles_position = None\n        self.particles_velocity = None\n        self.personal_best_position = None\n        self.personal_best_fitness = None\n        self.func = None\n\n    def initialize_particles(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles_position = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.particles_velocity = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))\n        self.personal_best_position = self.particles_position.copy()\n        self.personal_best_fitness = np.array([func(x) for x in self.particles_position])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.personal_best_fitness)\n        if self.personal_best_fitness[best_index] < self.best_fitness:\n            self.best_fitness = self.personal_best_fitness[best_index]\n            self.best_position = self.personal_best_position[best_index].copy()\n\n    def optimize_particle(self, particle_index):\n        result = minimize(self.func, self.particles_position[particle_index], method='Nelder-Mead',\n                            bounds=[(self.func.bounds.lb, self.func.bounds.ub)] * self.dim,\n                            options={'maxfev': min(50, self.budget)}) # Limit FE to a reasonable value\n        \n        if result.success:\n            fitness = result.fun\n            position = result.x\n            fevals = result.nfev\n            self.budget -= fevals\n\n            if fitness < self.personal_best_fitness[particle_index]:\n                self.personal_best_fitness[particle_index] = fitness\n                self.personal_best_position[particle_index] = position.copy()\n\n                if fitness < self.best_fitness:\n                    self.best_fitness = fitness\n                    self.best_position = position.copy()\n        else:\n            # If Nelder-Mead fails, reduce local search probability next time\n            self.local_search_prob = max(0.01, self.local_search_prob * 0.9)  # Reduce LS prob\n\n    def __call__(self, func):\n        self.func = func\n        self.initialize_particles(func)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_position[i] - self.particles_position[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (self.best_position - self.particles_position[i])\n                self.particles_velocity[i] = self.inertia_weight * self.particles_velocity[i] + cognitive_component + social_component\n                self.particles_velocity[i] = np.clip(self.particles_velocity[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = self.particles_position[i] + self.particles_velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                self.particles_position[i] = new_position\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_position[i] = new_position.copy()\n\n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_position = new_position.copy()\n                \n                # Apply local search with probability\n                if np.random.rand() < self.local_search_prob and self.budget > 0:\n                    self.optimize_particle(i)\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 8, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["ee03a2d7-2bfd-4dff-ae8f-34b930372b0d"], "operator": null, "metadata": {}}
{"id": "0f2d40c4-c8dd-4ea9-8115-1c10a34f4384", "fitness": -Infinity, "name": "PSO_NelderMead", "description": "A hybrid optimization algorithm combining PSO with a Nelder-Mead simplex method for local search and a random restart strategy to escape local optima.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PSO_NelderMead:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, w_max=0.9, w_min=0.4, nelder_mead_frequency=10, restart_frequency=50, stagnation_tolerance=1e-6):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.w_max = w_max\n        self.w_min = w_min\n        self.nelder_mead_frequency = nelder_mead_frequency\n        self.restart_frequency = restart_frequency\n        self.stagnation_tolerance = stagnation_tolerance\n        self.inertia = self.w_max\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.generation = 0\n        self.last_improvement = 0\n\n    def nelder_mead(self, func, x0):\n        \"\"\"\n        Performs Nelder-Mead optimization.\n        \"\"\"\n        res = minimize(func, x0, method='Nelder-Mead', options={'maxfev': self.dim * 5, 'maxiter': self.dim}) #adjust maxfev\n        return res.fun, res.x\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n        self.last_improvement = 0\n\n        while self.budget > 0:\n            # Update inertia weight linearly\n            self.inertia = self.w_max - (self.w_max - self.w_min) * (1 - self.generation / (self.budget+self.generation))\n\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                        self.last_improvement = self.generation\n                \n                population[i] = new_position.copy()\n                fitness[i] = new_fitness\n            \n            # Apply Nelder-Mead every nelder_mead_frequency generations\n            if self.generation % self.nelder_mead_frequency == 0 and self.budget > self.dim * 5:\n                best_fitness_nm, best_position_nm = self.nelder_mead(func, self.global_best_position)\n                self.budget -= self.dim * 5\n                if best_fitness_nm < self.global_best_fitness:\n                    self.global_best_fitness = best_fitness_nm\n                    self.global_best_position = best_position_nm.copy()\n                    self.last_improvement = self.generation\n                    \n            # Restart if stagnated\n            if self.generation - self.last_improvement > self.restart_frequency:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n                self.personal_best_positions = population.copy()\n                self.personal_best_fitness = fitness.copy()\n\n                best_index = np.argmin(fitness)\n                self.global_best_position = population[best_index].copy()\n                self.global_best_fitness = fitness[best_index].copy()\n                self.last_improvement = self.generation # Reset last improvement after restart\n\n            self.generation += 1\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["bdafd60a-88f4-42df-81e9-605c74097218"], "operator": null, "metadata": {}}
{"id": "2cc7b658-362b-45f2-99ca-334b8c03c6cc", "fitness": -Infinity, "name": "PSO_NelderMead", "description": "Combines PSO with a Nelder-Mead simplex algorithm for local search, adaptively adjusting the Nelder-Mead frequency based on stagnation detection in PSO.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PSO_NelderMead:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, w_max=0.9, w_min=0.4, nm_frequency=10, stagnation_threshold=1e-5, stagnation_iterations=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.w_max = w_max\n        self.w_min = w_min\n        self.nm_frequency = nm_frequency  # How often to run Nelder-Mead\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_iterations = stagnation_iterations\n        self.stagnation_counter = 0\n\n        self.inertia = self.w_max\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.generation = 0\n        self.previous_best_fitness = np.inf\n\n    def nelder_mead(self, func, x0):\n        \"\"\"\n        Performs Nelder-Mead optimization.\n        \"\"\"\n        bounds = func.bounds\n        def wrapper(x):\n            x_clipped = np.clip(x, bounds.lb, bounds.ub)\n            return func(x_clipped)\n        \n        result = minimize(wrapper, x0, method='Nelder-Mead', options={'maxfev': self.dim*5}) # Limit FE to avoid budget exhaustion\n        \n        self.budget -= result.nfev\n\n        if result.success:\n             return result.fun, result.x\n        else:\n            return func(result.x), result.x\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            # Update inertia weight linearly\n            self.inertia = self.w_max - (self.w_max - self.w_min) * (1 - self.generation / (self.budget+self.generation))\n\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                \n                population[i] = new_position.copy()\n                fitness[i] = new_fitness\n            \n            # Stagnation check\n            if abs(self.global_best_fitness - self.previous_best_fitness) < self.stagnation_threshold:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            self.previous_best_fitness = self.global_best_fitness\n            \n            # Adaptive Nelder-Mead frequency: increase if stagnation is detected.\n            current_nm_frequency = self.nm_frequency\n            if self.stagnation_counter > self.stagnation_iterations:\n                 current_nm_frequency = 1  # Run NM every generation if stagnant\n                \n            # Apply Nelder-Mead every current_nm_frequency generations\n            if self.generation % current_nm_frequency == 0 and self.budget > self.dim*5:\n                best_fitness_nm, best_position_nm = self.nelder_mead(func, self.global_best_position)\n\n                if best_fitness_nm < self.global_best_fitness:\n                    self.global_best_fitness = best_fitness_nm\n                    self.global_best_position = best_position_nm.copy()\n            \n            self.generation += 1\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["bdafd60a-88f4-42df-81e9-605c74097218"], "operator": null, "metadata": {}}
{"id": "d416fb38-5905-4727-82a6-0242eddae451", "fitness": 0.0, "name": "SelfAdaptivePSODE", "description": "A hybrid PSO algorithm with a self-adaptive learning rate and a local search operator based on differential evolution to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass SelfAdaptivePSODE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, de_crossover_rate=0.7, de_scaling_factor=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.de_crossover_rate = de_crossover_rate\n        self.de_scaling_factor = de_scaling_factor\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize velocities\n        velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (func.bounds.ub - func.bounds.lb) * 0.1\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize learning rate\n        learning_rate = np.ones(self.pop_size) * 0.1\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i])\n\n                velocity[i] = self.inertia_weight * velocity[i] + cognitive_component + social_component\n\n                # Update position\n                new_position = population[i] + learning_rate[i] * velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n\n                # Differential Evolution Local Search\n                if np.random.rand() < 0.1: # Apply DE with probability 0.1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n\n                    # Mutation\n                    mutant = x1 + self.de_scaling_factor * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover\n                    trial_vector = np.zeros(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.de_crossover_rate or j == np.random.randint(self.dim):\n                            trial_vector[j] = mutant[j]\n                        else:\n                            trial_vector[j] = population[i][j]\n                    \n                    trial_fitness = func(trial_vector)\n                    self.budget -= 1\n\n                    if trial_fitness < fitness[i]:\n                        population[i] = trial_vector.copy()\n                        fitness[i] = trial_fitness\n\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best_fitness[i] = trial_fitness\n                            personal_best_positions[i] = trial_vector.copy()\n\n                            if trial_fitness < global_best_fitness:\n                                global_best_fitness = trial_fitness\n                                global_best_position = trial_vector.copy()\n                \n                # Adaptive learning rate update\n                if new_fitness < fitness[i]:\n                    learning_rate[i] *= 1.1\n                else:\n                    learning_rate[i] *= 0.9\n                learning_rate[i] = np.clip(learning_rate[i], 0.01, 0.5) # Clip to reasonable values\n\n            global_best_index = np.argmin(personal_best_fitness)\n            global_best_fitness = personal_best_fitness[global_best_index]\n            global_best_position = personal_best_positions[global_best_index]\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm SelfAdaptivePSODE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["47e08098-b47d-44cd-968e-6ae1b36537e4"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "7d719498-ba75-4c75-b324-7cb568aef5ef", "fitness": -Infinity, "name": "OrthogonalPSO", "description": "A hybrid algorithm that combines PSO with orthogonal learning to improve exploration and convergence by learning from orthogonal experimental designs.", "code": "import numpy as np\nfrom scipy.stats import norm\n\nclass OrthogonalPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, w_max=0.9, w_min=0.4, orthogonal_frequency=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.w_max = w_max\n        self.w_min = w_min\n        self.orthogonal_frequency = orthogonal_frequency  # How often to apply orthogonal learning\n\n        self.inertia = self.w_max\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.generation = 0\n\n    def generate_orthogonal_array(self, n_factors, levels):\n        \"\"\"\n        Generates an orthogonal array using Plackett-Burman design (for 2 levels)\n        and a simple factorial design for > 2 levels. For simplicity, we assume\n        all factors have the same number of levels.\n\n        For n_factors > number of PB columns, a full factorial design is implemented.\n        \"\"\"\n\n        if levels == 2:\n            # Plackett-Burman design (only for 2 levels)\n            pb_columns = [3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47]  # Supported columns\n\n            if n_factors <= pb_columns[-1]:\n                # Find the smallest supported column size\n                for c in pb_columns:\n                    if n_factors <= c:\n                        pb_size = c\n                        break\n\n                # Generate the PB matrix\n                H = np.ones((pb_size, pb_size))\n                for i in range(1, pb_size):\n                    for j in range(1, pb_size):\n                        if j > i:\n                            H[i, j] = -1\n                        else:\n                            H[i, j] = H[j, i]\n\n                # Take only the required factors\n                oa = H[:-1, :n_factors]\n\n                # Convert -1 to 0 to represent levels 0 and 1\n                oa = (oa + 1) / 2\n\n            else:\n                # Full factorial design if PB not sufficient\n                levels_array = [levels] * n_factors\n                grid = np.meshgrid(*[np.arange(l) for l in levels_array])\n                oa = np.vstack([g.ravel() for g in grid]).T\n                oa = oa[:pb_columns[-1], :n_factors]\n\n        else:\n            # Full factorial design for levels > 2\n            levels_array = [levels] * n_factors\n            grid = np.meshgrid(*[np.arange(l) for l in levels_array])\n            oa = np.vstack([g.ravel() for g in grid]).T\n\n        return oa\n\n    def orthogonal_learning(self, func, position, levels=3): # increased levels from 2 to 3\n        \"\"\"\n        Performs orthogonal learning around a given position.\n        \"\"\"\n        n_factors = self.dim\n        oa = self.generate_orthogonal_array(n_factors, levels)\n        n_combinations = oa.shape[0]\n\n        best_fitness = np.inf\n        best_position = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        for i in range(n_combinations):\n            # Generate a new position based on the orthogonal array\n            new_position = position.copy()\n            for j in range(n_factors):\n                level = oa[i, j]\n                new_position[j] = lb + (ub - lb) * level / (levels - 1) # changed 1 to levels-1\n\n            new_position = np.clip(new_position, lb, ub)\n            new_fitness = func(new_position)\n            self.budget -= 1\n\n            if new_fitness < best_fitness:\n                best_fitness = new_fitness\n                best_position = new_position.copy()\n\n        return best_fitness, best_position\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            # Update inertia weight linearly\n            self.inertia = self.w_max - (self.w_max - self.w_min) * (1 - self.generation / (self.budget+self.generation))\n\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                \n                population[i] = new_position.copy()\n                fitness[i] = new_fitness\n                \n            # Apply orthogonal learning every orthogonal_frequency generations\n            if self.generation % self.orthogonal_frequency == 0 and self.budget > self.dim*5 : # Adjust budget condition. Assuming levels=3, then oa shape is at least dim*2.\n                best_fitness_orthogonal, best_position_orthogonal = self.orthogonal_learning(func, self.global_best_position) # level=3 by default\n                #The number of function evaluation is oa.shape[0]\n\n                if best_fitness_orthogonal < self.global_best_fitness:\n                    self.global_best_fitness = best_fitness_orthogonal\n                    self.global_best_position = best_position_orthogonal.copy()\n            \n            self.generation += 1\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "An exception occurred: setting an array element with a sequence..", "error": "", "parent_ids": ["bdafd60a-88f4-42df-81e9-605c74097218"], "operator": null, "metadata": {}}
{"id": "1cd4b769-32b8-4782-b68f-c4a8c1f38e63", "fitness": 0.0, "name": "PSO_Orthogonal_LocalSearch", "description": "A hybrid algorithm that combines PSO with orthogonal learning and local search, enhancing both exploration and exploitation.", "code": "import numpy as np\n\nclass PSO_Orthogonal_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, w_max=0.9, w_min=0.4, local_search_frequency=10, local_search_radius=0.1, orthogonal_learning_frequency=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.w_max = w_max\n        self.w_min = w_min\n        self.local_search_frequency = local_search_frequency\n        self.local_search_radius = local_search_radius\n        self.orthogonal_learning_frequency = orthogonal_learning_frequency\n\n        self.inertia = self.w_max\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.generation = 0\n\n    def local_search(self, func, x, radius):\n        \"\"\"Performs a simple local search around a given point.\"\"\"\n        best_fitness = func(x)\n        best_x = x.copy()\n        self.budget -= 1\n\n        for _ in range(self.dim * 2):  # Sample 2*dim points in the neighborhood\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_fitness = func(new_x)\n            self.budget -= 1\n\n            if new_fitness < best_fitness:\n                best_fitness = new_fitness\n                best_x = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n        return best_fitness, best_x\n\n    def orthogonal_learning(self, func, population, num_samples=5):\n        \"\"\"\n        Performs orthogonal learning to generate new candidate solutions.\n        \"\"\"\n        dim = self.dim\n        pop_size = self.pop_size\n\n        # Select two parents randomly\n        parent1_idx = np.random.randint(0, pop_size)\n        parent2_idx = np.random.randint(0, pop_size)\n\n        parent1 = population[parent1_idx]\n        parent2 = population[parent2_idx]\n\n        # Create orthogonal array (simple example: 2-level full factorial design)\n        orthogonal_array = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]]) # 4x2 orthogonal array\n\n        # Generate new solutions based on orthogonal array\n        new_solutions = np.zeros((orthogonal_array.shape[0], dim))\n        for i in range(orthogonal_array.shape[0]):\n            new_solution = np.zeros(dim)\n            for j in range(dim):\n                if orthogonal_array[i % orthogonal_array.shape[0], (j % 2)] == -1:\n                    new_solution[j] = parent1[j]\n                else:\n                    new_solution[j] = parent2[j]\n            new_solutions[i] = new_solution\n        new_solutions = np.clip(new_solutions, func.bounds.lb, func.bounds.ub)\n\n        fitness_values = np.array([func(x) for x in new_solutions])\n        self.budget -= len(fitness_values)\n\n        best_idx = np.argmin(fitness_values)\n        best_solution = new_solutions[best_idx]\n        best_fitness = fitness_values[best_idx]\n\n        return best_fitness, best_solution\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            # Update inertia weight linearly\n            self.inertia = self.w_max - (self.w_max - self.w_min) * (1 - self.generation / (self.budget+self.generation))\n\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                \n                population[i] = new_position.copy()\n                fitness[i] = new_fitness\n\n            # Apply local search every local_search_frequency generations\n            if self.generation % self.local_search_frequency == 0 and self.budget > self.dim*2:\n                best_fitness_ls, best_position_ls = self.local_search(func, self.global_best_position, self.local_search_radius)\n\n                if best_fitness_ls < self.global_best_fitness:\n                    self.global_best_fitness = best_fitness_ls\n                    self.global_best_position = best_position_ls.copy()\n                    \n            #Apply orthogonal learning every orthogonal_learning_frequency generations\n            if self.generation % self.orthogonal_learning_frequency == 0 and self.budget > 4:\n                best_fitness_ol, best_solution_ol = self.orthogonal_learning(func, population)\n\n                if best_fitness_ol < self.global_best_fitness:\n                    self.global_best_fitness = best_fitness_ol\n                    self.global_best_position = best_solution_ol.copy()\n\n            self.generation += 1\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm PSO_Orthogonal_LocalSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["bdafd60a-88f4-42df-81e9-605c74097218"], "operator": null, "metadata": {"aucs": [0]}}
{"id": "e27e1502-3d17-4cde-a757-7083b3550472", "fitness": 0.4561109090859201, "name": "AdaptivePSODifferentialMutation", "description": "An improved adaptive PSO with a self-adaptive learning rate and a mutation strategy based on differential evolution to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptivePSODifferentialMutation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05,\n                 w_max=0.9, w_min=0.4, diff_mutation_rate=0.1, stagnation_threshold=1e-5,\n                 stagnation_iterations=50, learning_rate_initial=0.1, learning_rate_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.w_max = w_max\n        self.w_min = w_min\n        self.diff_mutation_rate = diff_mutation_rate\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_iterations = stagnation_iterations\n        self.learning_rate = learning_rate_initial\n        self.learning_rate_decay = learning_rate_decay\n\n        self.inertia = self.w_max\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.stagnation_counter = 0\n        self.previous_best_fitness = np.inf\n\n    def differential_mutation(self, population, target_index):\n        \"\"\"\n        Applies differential mutation to a particle.\n        \"\"\"\n        indices = list(range(self.pop_size))\n        indices.remove(target_index)\n        np.random.shuffle(indices)\n        \n        r1, r2, r3 = indices[:3]\n\n        mutant = population[r1] + 0.5 * (population[r2] - population[r3])\n        return mutant\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n        self.previous_best_fitness = self.global_best_fitness\n\n        while self.budget > 0:\n            # Update inertia weight linearly\n            self.inertia = self.w_max - (self.w_max - self.w_min) * (1 - self.budget / 10000)\n\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Apply differential mutation with a certain probability\n                if np.random.rand() < self.diff_mutation_rate:\n                    mutant = self.differential_mutation(population, i)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                    \n                    # Blend mutant with current position\n                    new_position = (1 - self.learning_rate) * new_position + self.learning_rate * mutant\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n                fitness[i] = new_fitness\n                \n            # Adaptive learning rate decay\n            self.learning_rate *= self.learning_rate_decay\n\n            # Stagnation detection and restart mechanism\n            if abs(self.global_best_fitness - self.previous_best_fitness) < self.stagnation_threshold:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter >= self.stagnation_iterations:\n                # Restart: Re-initialize the population around the global best with some added noise\n                population = np.random.normal(loc=self.global_best_position, scale=0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n                population = np.clip(population, func.bounds.lb, func.bounds.ub)\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size  # Account for new evaluations\n\n                self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n                self.personal_best_positions = population.copy()\n                self.personal_best_fitness = fitness.copy()\n\n                best_index = np.argmin(fitness)\n                self.global_best_position = population[best_index].copy()\n                self.global_best_fitness = fitness[best_index].copy()\n                \n                self.stagnation_counter = 0  # Reset stagnation counter\n                self.learning_rate = 0.1 # Reset Learning Rate\n\n            self.previous_best_fitness = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptivePSODifferentialMutation scored 0.456 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2d7990e2-1eab-4058-afc2-fe7a717931b7"], "operator": null, "metadata": {"aucs": [0.1859659182624992, 0.2676689452385018, 0.5584908233263937, 0.3620333174392857, 0.5371939778776444, 0.6474958086751317, 0.2556510963459344, 0.333253046309979, 0.5491251551148316, 0.5916171409098959, 0.6633337761274771, 0.9984421466069522, 0.3030324859016563, 0.3242719643175628, 0.839680647834169, 0.49261628965635607, 0.33286967197078066, 0.1917348162397251, 0.19742914600150252, 0.4903120075621238]}}
{"id": "3704d31b-ef53-47c8-8a6c-630d513a63f8", "fitness": 0.31677544157309623, "name": "RepulsiveAdaptivePSO", "description": "An adaptive PSO with a repulsive operator based on the worst particle to encourage exploration and escape local optima.", "code": "import numpy as np\n\nclass RepulsiveAdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_cognitive_coeff=2.05, initial_social_coeff=2.05,\n                 velocity_clamp=0.5, stagnation_threshold=50, repulsion_strength=0.1, cognitive_scaling=0.99, social_scaling=1.01,\n                 inertia_max = 0.9, inertia_min = 0.4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = initial_cognitive_coeff\n        self.social_coeff = initial_social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.stagnation_threshold = stagnation_threshold\n        self.repulsion_strength = repulsion_strength\n        self.cognitive_scaling = cognitive_scaling\n        self.social_scaling = social_scaling\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n\n        self.inertia = self.inertia_max\n        self.constriction_factor = self.calculate_constriction_factor()\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.stagnation_counter = 0\n        self.worst_particle_index = None\n\n    def calculate_constriction_factor(self):\n        phi = self.cognitive_coeff + self.social_coeff\n        if phi <= 4:\n            return 1.0\n        return 2 / np.abs(2 - phi - np.sqrt(phi**2 - 4 * phi))\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n        self.worst_particle_index = np.argmax(fitness)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n\n                # Repulsion component\n                repulsion_component = self.repulsion_strength * np.random.rand() * (population[i] - population[self.worst_particle_index])\n\n                self.velocity[i] = self.constriction_factor * (self.inertia * self.velocity[i] + cognitive_component + social_component + repulsion_component)\n                self.velocity[i] = np.clip(self.velocity[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                    else:\n                        self.stagnation_counter += 1  # Increment stagnation counter\n\n                population[i] = new_position.copy()\n\n            # Update worst particle index\n            self.worst_particle_index = np.argmax(self.personal_best_fitness)\n\n            # Adapt cognitive and social coefficients\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.cognitive_coeff *= self.cognitive_scaling  # Reduce cognitive influence\n                self.social_coeff *= self.social_scaling       # Increase social influence\n                self.stagnation_counter = 0 # Reset\n            \n            self.inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (self.budget / 10000)\n            self.constriction_factor = self.calculate_constriction_factor()\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm RepulsiveAdaptivePSO scored 0.317 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ee03a2d7-2bfd-4dff-ae8f-34b930372b0d"], "operator": null, "metadata": {"aucs": [0.1501470548029047, 0.1999570960159721, 0.3537147830666073, 0.1898118719648152, 0.19299856253417813, 0.16628567205656986, 0.25707371211165964, 0.3102550078825025, 0.17086539262580935, 0.17333321559299308, 0.22173993309015094, 0.9845118456473758, 0.27234149041725364, 0.23076226010013157, 0.7296670821665022, 0.2957017268603128, 0.25329931287816976, 0.5267460463823448, 0.18114937161215716, 0.4751473936535131]}}
{"id": "902054bc-79ca-4605-8371-b4c7febfb98e", "fitness": -Infinity, "name": "PSO_NelderMead", "description": "A hybrid algorithm that combines PSO with a Nelder-Mead simplex method to refine the global best solution and enhance local exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PSO_NelderMead:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, w_max=0.9, w_min=0.4, nelder_mead_frequency=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.w_max = w_max\n        self.w_min = w_min\n        self.nelder_mead_frequency = nelder_mead_frequency  # How often to run Nelder-Mead\n\n        self.inertia = self.w_max\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.generation = 0\n\n    def nelder_mead(self, func, x0):\n        \"\"\"\n        Performs Nelder-Mead optimization to refine a solution.\n        \"\"\"\n        result = minimize(func, x0, method='Nelder-Mead', options={'maxfev': self.dim*2}) # Reduced maxfev to fit into budget\n        \n        if result.success:\n            return result.fun, result.x\n        else:\n            return np.inf, x0\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n\n        while self.budget > 0:\n            # Update inertia weight linearly\n            self.inertia = self.w_max - (self.w_max - self.w_min) * (1 - self.generation / (self.budget+self.generation))\n\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n                \n                population[i] = new_position.copy()\n                fitness[i] = new_fitness\n                \n            # Apply Nelder-Mead every nelder_mead_frequency generations\n            if self.generation % self.nelder_mead_frequency == 0 and self.budget > self.dim*2: #adjust the budget condition\n                best_fitness_nm, best_position_nm = self.nelder_mead(func, self.global_best_position)\n                self.budget -= self.dim*2\n\n                if best_fitness_nm < self.global_best_fitness:\n                    self.global_best_fitness = best_fitness_nm\n                    self.global_best_position = best_position_nm.copy()\n            \n            self.generation += 1\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "An exception occurred: name 'minimize' is not defined.", "error": "", "parent_ids": ["bdafd60a-88f4-42df-81e9-605c74097218"], "operator": null, "metadata": {}}
{"id": "fe0a0f29-c628-4474-8fe4-2a0481dbb4ad", "fitness": -Infinity, "name": "OrthogonalLearningPSO", "description": "An adaptive PSO variant that incorporates orthogonal learning to enhance both exploration and exploitation of the search space, coupled with a stagnation detection mechanism and re-initialization strategy.", "code": "import numpy as np\n\nclass OrthogonalLearningPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cognitive_coeff=2.05, social_coeff=2.05, w_max=0.9, w_min=0.4, stagnation_threshold=1e-5, stagnation_iterations=50, orthogonal_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.w_max = w_max\n        self.w_min = w_min\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_iterations = stagnation_iterations\n        self.orthogonal_scale = orthogonal_scale  # Scale for orthogonal learning\n\n        self.inertia = self.w_max\n        self.velocity = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.stagnation_counter = 0\n        self.previous_best_fitness = np.inf\n\n    def orthogonal_learning(self, x):\n        \"\"\"\n        Applies orthogonal learning to a vector to generate a new candidate solution.\n        \"\"\"\n        orthogonal_vector = np.random.normal(0, self.orthogonal_scale * (func.bounds.ub - func.bounds.lb), size=self.dim)\n        return x + orthogonal_vector\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index].copy()\n        self.global_best_fitness = fitness[best_index].copy()\n        self.previous_best_fitness = self.global_best_fitness\n\n        while self.budget > 0:\n            # Update inertia weight linearly\n            self.inertia = self.w_max - (self.w_max - self.w_min) * (1 - self.budget / 10000)\n\n            for i in range(self.pop_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - population[i])\n                social_component = self.social_coeff * np.random.rand() * (self.global_best_position - population[i])\n                self.velocity[i] = self.inertia * self.velocity[i] + cognitive_component + social_component\n\n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Apply orthogonal learning with a small probability\n                if np.random.rand() < 0.1:\n                    new_position = self.orthogonal_learning(new_position)\n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n                fitness[i] = new_fitness\n\n            # Stagnation detection and restart mechanism\n            if abs(self.global_best_fitness - self.previous_best_fitness) < self.stagnation_threshold:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter >= self.stagnation_iterations:\n                # Restart: Re-initialize the population around the global best with some added noise\n                population = np.random.normal(loc=self.global_best_position, scale=0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n                population = np.clip(population, func.bounds.lb, func.bounds.ub)\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size  # Account for new evaluations\n\n                self.velocity = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n                self.personal_best_positions = population.copy()\n                self.personal_best_fitness = fitness.copy()\n\n                best_index = np.argmin(fitness)\n                self.global_best_position = population[best_index].copy()\n                self.global_best_fitness = fitness[best_index].copy()\n\n                self.stagnation_counter = 0  # Reset stagnation counter\n\n            self.previous_best_fitness = self.global_best_fitness\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "An exception occurred: name 'func' is not defined.", "error": "", "parent_ids": ["2d7990e2-1eab-4058-afc2-fe7a717931b7"], "operator": null, "metadata": {}}
