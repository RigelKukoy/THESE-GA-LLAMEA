{"id": "80add1fe-78d3-4c25-82e0-1a52bfde86de", "fitness": 0.2367328736335082, "name": "SocialForagingOptimization", "description": "Population-based algorithm inspired by social foraging, where individuals (solutions) are influenced by their own best experience, the best experience of their neighbors, and a random element to encourage exploration.", "code": "import numpy as np\n\nclass SocialForagingOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, neighborhood_size=5, inertia_weight=0.7, social_confidence=1.4, exploration_rate=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.neighborhood_size = neighborhood_size\n        self.inertia_weight = inertia_weight\n        self.social_confidence = social_confidence\n        self.exploration_rate = exploration_rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population within bounds\n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        while self.budget > 0:\n            for i in range(self.population_size):\n                # Select neighborhood (random subset of the population)\n                neighbors = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                \n                # Find best neighbor\n                best_neighbor_index = neighbors[np.argmin(fitness[neighbors])]\n                best_neighbor_position = population[best_neighbor_index].copy()\n                \n                # Update position\n                inertia = self.inertia_weight * population[i]\n                social_influence = self.social_confidence * (best_neighbor_position - population[i])\n                exploration = self.exploration_rate * np.random.uniform(lb, ub, size=self.dim)\n\n                new_position = inertia + social_influence + exploration\n                \n                # Clip to bounds\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < fitness[i]:\n                    population[i] = new_position.copy()\n                    fitness[i] = new_fitness\n                    \n                    # Update personal best\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = new_fitness\n                        personal_best_positions[i] = new_position.copy()\n\n                        # Update global best\n                        if new_fitness < global_best_fitness:\n                            global_best_fitness = new_fitness\n                            global_best_position = new_position.copy()\n\n                if self.budget <= 0:\n                    break\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm SocialForagingOptimization scored 0.237 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.12458471714195218, 0.24085827886267985, 0.3204275119856378, 0.2576913168491851, 0.2354430645073382, 0.2720587005896177, 0.25535688169039306, 0.2639599411526383, 0.2240352850964621, 0.1729130384591776]}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "6172a647-ed25-4555-9451-184d042cd6ef", "fitness": "-inf", "name": "AdaptiveSocialForagingOptimization", "description": "Adaptive Social Foraging Optimization with dynamic parameter adjustment and enhanced exploration using LÃ©vy flights, aiming to balance exploration and exploitation more effectively.", "code": "import numpy as np\nfrom scipy.stats import levy\n\nclass AdaptiveSocialForagingOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, neighborhood_size=5,\n                 inertia_weight_start=0.9, inertia_weight_end=0.4,\n                 social_confidence_start=1.2, social_confidence_end=2.0,\n                 exploration_rate_start=0.4, exploration_rate_end=0.05, levy_scale=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.neighborhood_size = neighborhood_size\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.social_confidence_start = social_confidence_start\n        self.social_confidence_end = social_confidence_end\n        self.exploration_rate_start = exploration_rate_start\n        self.exploration_rate_end = exploration_rate_end\n        self.levy_scale = levy_scale\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population within bounds\n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size if self.population_size > 0 else 1\n\n        while self.budget > 0:\n            # Adaptive parameter adjustment\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (iteration / max_iterations)\n            social_confidence = self.social_confidence_start + (self.social_confidence_end - self.social_confidence_start) * (iteration / max_iterations)\n            exploration_rate = self.exploration_rate_start - (self.exploration_rate_start - self.exploration_rate_end) * (iteration / max_iterations)\n\n            for i in range(self.population_size):\n                # Select neighborhood (random subset of the population)\n                neighbors = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                \n                # Find best neighbor\n                best_neighbor_index = neighbors[np.argmin(fitness[neighbors])]\n                best_neighbor_position = population[best_neighbor_index].copy()\n                \n                # Update position\n                inertia = inertia_weight * population[i]\n                social_influence = social_confidence * (best_neighbor_position - population[i])\n                # Levy flight for enhanced exploration\n                levy_flight = self.levy_scale * levy.rvs(0.5, loc=0, scale=1, size=self.dim)\n                exploration = exploration_rate * levy_flight * np.random.uniform(-1, 1, size=self.dim) # Add randomness to direction\n\n                new_position = inertia + social_influence + exploration\n                \n                # Clip to bounds\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < fitness[i]:\n                    population[i] = new_position.copy()\n                    fitness[i] = new_fitness\n                    \n                    # Update personal best\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = new_fitness\n                        personal_best_positions[i] = new_position.copy()\n\n                        # Update global best\n                        if new_fitness < global_best_fitness:\n                            global_best_fitness = new_fitness\n                            global_best_position = new_position.copy()\n\n                if self.budget <= 0:\n                    break\n            \n            iteration += 1\n            if max_iterations == 0:\n               break\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 1, "feedback": "In the code, line 1111, in rvs, the following error occurred:\nTypeError: _parse_args_rvs() got multiple values for argument 'loc'", "error": "In the code, line 1111, in rvs, the following error occurred:\nTypeError: _parse_args_rvs() got multiple values for argument 'loc'", "parent_ids": ["80add1fe-78d3-4c25-82e0-1a52bfde86de"], "operator": null, "metadata": {}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "ac63f791-d611-4d25-86bc-64be8f8e7865", "fitness": 0.0, "name": "AdaptiveSocialForaging", "description": "An enhanced social foraging algorithm with adaptive parameters, local search, and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveSocialForaging:\n    def __init__(self, budget=10000, dim=10, population_size=20, neighborhood_size=5, initial_inertia_weight=0.7, social_confidence=1.4, exploration_rate=0.3, local_search_probability=0.1, restart_probability=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.neighborhood_size = neighborhood_size\n        self.inertia_weight = initial_inertia_weight\n        self.social_confidence = social_confidence\n        self.exploration_rate = exploration_rate\n        self.local_search_probability = local_search_probability\n        self.restart_probability = restart_probability\n\n        self.initial_inertia_weight = initial_inertia_weight\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population within bounds\n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n            \n            # Adaptive Inertia Weight\n            self.inertia_weight = self.initial_inertia_weight * (1 - (iteration / (self.budget / self.population_size)))\n\n            for i in range(self.population_size):\n                # Select neighborhood (random subset of the population)\n                neighbors = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                \n                # Find best neighbor\n                best_neighbor_index = neighbors[np.argmin(fitness[neighbors])]\n                best_neighbor_position = population[best_neighbor_index].copy()\n                \n                # Update position\n                inertia = self.inertia_weight * population[i]\n                social_influence = self.social_confidence * (best_neighbor_position - population[i])\n                exploration = self.exploration_rate * np.random.uniform(lb, ub, size=self.dim)\n\n                new_position = inertia + social_influence + exploration\n                \n                # Clip to bounds\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Local Search\n                if np.random.rand() < self.local_search_probability:\n                    step_size = 0.01 * (ub - lb)  # Small step size for local exploration\n                    random_direction = np.random.uniform(-1, 1, size=self.dim)\n                    local_position = new_position + step_size * random_direction\n                    local_position = np.clip(local_position, lb, ub) # keep within bounds\n                    local_fitness = func(local_position)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if local_fitness < func(new_position):\n                        new_position = local_position\n                    \n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < fitness[i]:\n                    population[i] = new_position.copy()\n                    fitness[i] = new_fitness\n                    \n                    # Update personal best\n                    if new_fitness < personal_best_fitness[i]:\n                        personal_best_fitness[i] = new_fitness\n                        personal_best_positions[i] = new_position.copy()\n\n                        # Update global best\n                        if new_fitness < global_best_fitness:\n                            global_best_fitness = new_fitness\n                            global_best_position = new_position.copy()\n                            \n                # Restart Mechanism\n                if np.random.rand() < self.restart_probability:\n                    population[i] = np.random.uniform(lb, ub, size=self.dim)\n                    fitness[i] = func(population[i])\n                    self.budget -= 1\n                    if fitness[i] < personal_best_fitness[i]:\n                        personal_best_fitness[i] = fitness[i]\n                        personal_best_positions[i] = population[i].copy()\n                    if fitness[i] < global_best_fitness:\n                        global_best_fitness = fitness[i]\n                        global_best_position = population[i].copy()\n\n                if self.budget <= 0:\n                    break\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveSocialForaging scored 0.000 on AOCC (higher is better, 1.0 is the best). The algorithm exhausted the budget. Ensure you stop optimization when budget is 0.", "error": "", "parent_ids": ["80add1fe-78d3-4c25-82e0-1a52bfde86de"], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "8cd99ef8-2247-47e3-a0b8-54fadfe31d18", "fitness": 0.25292170592750074, "name": "AdaptiveSlimeMoldOptimization", "description": "A population-based metaheuristic inspired by the collective behavior of slime mold, dynamically adjusting search strategies based on fitness landscape characteristics and incorporating adaptive parameters for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSlimeMoldOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, c=0.1, a=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.c = c  # Convergence factor\n        self.a = a  # Adaptive parameter\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population within bounds\n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Initialize best position and fitness\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        best_fitness = fitness[best_index]\n\n        def update_weight(r, best_fitness, fitness):\n            return 1 + abs(np.random.normal(0, 1) * (best_fitness - fitness[r]) / (fitness[r] + np.finfo(float).eps))\n\n        while self.budget > 0:\n            weights = np.array([update_weight(i, best_fitness, fitness) for i in range(self.population_size)])\n            weights = weights / np.sum(weights)\n\n            for i in range(self.population_size):\n                if np.random.rand() < self.c:  #Exploitation phase\n                    r1 = np.random.randint(0, self.population_size)\n                    new_position = best_position + np.random.uniform(lb, ub, size=self.dim) * self.a * weights[i] * (population[i] - population[r1])\n\n                else: #Exploration phase\n                    p = np.random.rand()\n                    if p < 0.5:\n                        new_position = population[i] + np.random.uniform(lb, ub, size=self.dim) * (best_position - population[i])\n                    else:\n                        new_position = lb + np.random.rand(self.dim) * (ub - lb)  # Random exploration\n\n                # Clip to bounds\n                new_position = np.clip(new_position, lb, ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < fitness[i]:\n                    population[i] = new_position.copy()\n                    fitness[i] = new_fitness\n\n                    # Update best\n                    if new_fitness < best_fitness:\n                        best_fitness = new_fitness\n                        best_position = new_position.copy()\n\n                if self.budget <= 0:\n                    break\n\n            # Adaptive Adjustment of 'a'\n            self.a = 0.9 * self.a + 0.1  # Gradually decrease exploration rate\n            self.c = 0.95 * self.c #Reduce Convergence factor to allow finer changes after some time\n        return best_fitness, best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveSlimeMoldOptimization scored 0.253 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["80add1fe-78d3-4c25-82e0-1a52bfde86de"], "operator": null, "metadata": {"aucs": [0.12803200046760033, 0.20228565587806202, 0.3399459111024633, 0.23000592074773307, 0.26516129538419597, 0.3490104717915188, 0.27326968686978703, 0.3470993497445214, 0.2244283356526965, 0.16997843163642934]}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "70a668bd-2fff-4272-85a3-60d1f629b7b7", "fitness": 0.27464970162559, "name": "EnhancedSlimeMoldOptimization", "description": "Enhanced Slime Mold Optimization with adaptive parameters, dynamic exploration-exploitation balance, and a self-learning search strategy based on fitness landscape features.", "code": "import numpy as np\n\nclass EnhancedSlimeMoldOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, c1=0.1, c2=0.05, a=0.3, b=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.c1 = c1  # Exploration factor\n        self.c2 = c2  # Exploitation factor\n        self.a = a  # Adaptive parameter 1 (exploration scaling)\n        self.b = b  # Adaptive parameter 2 (exploitation scaling)\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population within bounds\n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Initialize best position and fitness\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        best_fitness = fitness[best_index]\n\n        def update_weight(r, best_fitness, fitness, mean_fitness):\n            #Weight calculation with added sensitivity to fitness differences\n            return 1 + abs(np.random.normal(0, 1) * (best_fitness - fitness[r]) / (abs(fitness[r] - mean_fitness) + np.finfo(float).eps))\n\n        while self.budget > 0:\n            mean_fitness = np.mean(fitness)\n            weights = np.array([update_weight(i, best_fitness, fitness, mean_fitness) for i in range(self.population_size)])\n            weights = weights / np.sum(weights)\n\n            for i in range(self.population_size):\n                if np.random.rand() < self.c1:  #Exploitation phase\n                    r1 = np.random.randint(0, self.population_size)\n                    r2 = np.random.randint(0, self.population_size)\n                    new_position = best_position + np.random.uniform(0, self.b, size=self.dim) * weights[i] * (population[r1] - population[r2])\n\n                else: #Exploration phase\n                    p = np.random.rand()\n                    if p < 0.5:\n                        # Guided exploration towards best\n                        new_position = population[i] + np.random.uniform(-self.a, self.a, size=self.dim) * (best_position - population[i])\n                    else:\n                        #Random exploration with a focus on promising regions\n                         new_position = population[i] + np.random.uniform(-self.a, self.a, size=self.dim) * (np.random.uniform(lb, ub, size=self.dim) - population[i])\n\n                # Clip to bounds\n                new_position = np.clip(new_position, lb, ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < fitness[i]:\n                    population[i] = new_position.copy()\n                    fitness[i] = new_fitness\n\n                    # Update best\n                    if new_fitness < best_fitness:\n                        best_fitness = new_fitness\n                        best_position = new_position.copy()\n\n                if self.budget <= 0:\n                    break\n\n            # Adaptive Adjustment of parameters\n            self.a = max(0.01, 0.98 * self.a)  # Gradually decrease exploration range\n            self.b = min(0.5, 1.02 * self.b) #Gradually increase exploitation range\n            self.c1 = max(0.01, 0.99 * self.c1) # Reduce exploration factor\n            self.c2 = min(0.2, 1.01 * self.c2) # Increase exploitation factor\n\n        return best_fitness, best_position", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedSlimeMoldOptimization scored 0.275 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["8cd99ef8-2247-47e3-a0b8-54fadfe31d18"], "operator": null, "metadata": {"aucs": [0.10325336329490242, 0.20682235886899958, 0.43012472216815234, 0.24388175896049957, 0.18525148818518, 0.4262202743369079, 0.29723034031141715, 0.3677706348241808, 0.2678775731026455, 0.21806450220301488]}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "3d469335-ca83-4b71-885a-609cedb6b7d2", "fitness": "-inf", "name": "EnhancedSlimeMoldOptimization", "description": "An enhanced Slime Mold Optimizer with dynamic parameter adaptation based on success rates, a diversity-preserving mechanism using a clustering-based approach, and a local search intensification strategy.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedSlimeMoldOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, c1=0.1, c2=0.05, a=0.3, b=0.1, cluster_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.c1 = c1  # Exploration factor\n        self.c2 = c2  # Exploitation factor\n        self.a = a  # Adaptive parameter 1 (exploration scaling)\n        self.b = b  # Adaptive parameter 2 (exploitation scaling)\n        self.cluster_ratio = cluster_ratio # Ratio of population to cluster for diversity\n        self.success_rate = 0.5 #Initial success rate for parameter adaptation\n        self.success_history = [] # History of success rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population within bounds\n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Initialize best position and fitness\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        best_fitness = fitness[best_index]\n\n        def update_weight(r, best_fitness, fitness, mean_fitness):\n            #Weight calculation with added sensitivity to fitness differences\n            return 1 + abs(np.random.normal(0, 1) * (best_fitness - fitness[r]) / (abs(fitness[r] - mean_fitness) + np.finfo(float).eps))\n\n        def local_search(position, fitness_value, lb, ub, step_size=0.1):\n            \"\"\"Performs a local search around a given position.\"\"\"\n            new_position = position.copy()\n            for i in range(self.dim):\n                # Perturb each dimension with a small step\n                delta = np.random.uniform(-step_size, step_size) * (ub - lb)\n                new_position[i] = np.clip(position[i] + delta, lb, ub)\n\n            new_fitness = func(new_position)\n            self.budget -= 1\n\n            if new_fitness < fitness_value:\n                return new_position, new_fitness\n            else:\n                return position, fitness_value\n\n        while self.budget > 0:\n            mean_fitness = np.mean(fitness)\n            weights = np.array([update_weight(i, best_fitness, fitness, mean_fitness) for i in range(self.population_size)])\n            weights = weights / np.sum(weights)\n\n            successful_moves = 0 # Counter for successful moves in this iteration\n\n            for i in range(self.population_size):\n                old_fitness = fitness[i]\n                if np.random.rand() < self.c1:  #Exploitation phase\n                    r1 = np.random.randint(0, self.population_size)\n                    r2 = np.random.randint(0, self.population_size)\n                    new_position = best_position + np.random.uniform(0, self.b, size=self.dim) * weights[i] * (population[r1] - population[r2])\n\n                else: #Exploration phase\n                    p = np.random.rand()\n                    if p < 0.5:\n                        # Guided exploration towards best\n                        new_position = population[i] + np.random.uniform(-self.a, self.a, size=self.dim) * (best_position - population[i])\n                    else:\n                        #Random exploration with a focus on promising regions\n                         new_position = population[i] + np.random.uniform(-self.a, self.a, size=self.dim) * (np.random.uniform(lb, ub, size=self.dim) - population[i])\n\n                # Clip to bounds\n                new_position = np.clip(new_position, lb, ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < fitness[i]:\n                    population[i] = new_position.copy()\n                    fitness[i] = new_fitness\n                    successful_moves += 1 # Count this as a successful move\n\n                    # Update best\n                    if new_fitness < best_fitness:\n                        best_fitness = new_fitness\n                        best_position = new_position.copy()\n\n                #Local search intensification\n                if np.random.rand() < 0.1: # Apply local search with a probability\n                    population[i], fitness[i] = local_search(population[i], fitness[i], lb, ub)\n                    if fitness[i] < best_fitness:\n                        best_fitness = fitness[i]\n                        best_position = population[i].copy()\n\n                if self.budget <= 0:\n                    break\n\n            #Diversity Preservation using Clustering\n            if self.budget > 0:\n                n_clusters = max(2, int(self.population_size * self.cluster_ratio)) # Ensure at least 2 clusters\n                kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=10)\n                cluster_labels = kmeans.fit_predict(population)\n\n                for j in range(n_clusters):\n                    cluster_indices = np.where(cluster_labels == j)[0]\n                    if len(cluster_indices) > 1:\n                        # Replace a member of the cluster with a random solution to increase diversity\n                        index_to_replace = np.random.choice(cluster_indices)\n                        population[index_to_replace] = np.random.uniform(lb, ub, size=self.dim)\n                        fitness[index_to_replace] = func(population[index_to_replace])\n                        self.budget -=1\n                        if fitness[index_to_replace] < best_fitness:\n                            best_fitness = fitness[index_to_replace]\n                            best_position = population[index_to_replace].copy()\n\n            # Adaptive Adjustment of parameters based on success rate\n            self.success_history.append(successful_moves / self.population_size)\n            if len(self.success_history) > 10:\n                self.success_history.pop(0)  # Keep a window of the last 10 success rates\n\n            self.success_rate = np.mean(self.success_history) # Current success rate is the mean of the history\n\n            if self.success_rate > 0.3: # High success means exploit more\n                self.a = max(0.01, 0.95 * self.a)  # Gradually decrease exploration range faster\n                self.b = min(0.5, 1.05 * self.b) # Gradually increase exploitation range faster\n                self.c1 = max(0.01, 0.98 * self.c1) # Reduce exploration factor more aggressively\n                self.c2 = min(0.2, 1.02 * self.c2) # Increase exploitation factor more aggressively\n            else: # Low success means explore more\n                self.a = min(0.5, 1.05 * self.a)  # Increase exploration range\n                self.b = max(0.01, 0.95 * self.b) # Reduce exploitation range\n                self.c1 = min(0.5, 1.02 * self.c1) # Increase exploration factor\n                self.c2 = max(0.01, 0.98 * self.c2) # Reduce exploitation factor\n\n            if self.budget <= 0:\n                break\n\n        return best_fitness, best_position", "configspace": "", "generation": 5, "feedback": "In the code, line 41, in local_search, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: new_position[i] = np.clip(position[i] + delta, lb, ub)", "error": "In the code, line 41, in local_search, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: new_position[i] = np.clip(position[i] + delta, lb, ub)", "parent_ids": ["70a668bd-2fff-4272-85a3-60d1f629b7b7"], "operator": null, "metadata": {}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "84f6f902-e09b-4e24-9cca-6d46adee9299", "fitness": 0.2702621267384552, "name": "AdaptiveSlimeMoldOptimization", "description": "Adaptive Slime Mold Optimization with fitness-based parameter adaptation, dynamic topology, and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveSlimeMoldOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, c1=0.1, c2=0.05, a=0.3, b=0.1, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.c1 = c1  # Exploration factor\n        self.c2 = c2  # Exploitation factor\n        self.a = a  # Adaptive parameter 1 (exploration scaling)\n        self.b = b  # Adaptive parameter 2 (exploitation scaling)\n        self.restart_prob = restart_prob # Probability of restarting a mold's position\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population within bounds\n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Initialize best position and fitness\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        best_fitness = fitness[best_index]\n\n        def update_weight(r, best_fitness, fitness, mean_fitness):\n            #Weight calculation with added sensitivity to fitness differences\n            return 1 + abs(np.random.normal(0, 1) * (best_fitness - fitness[r]) / (abs(fitness[r] - mean_fitness) + np.finfo(float).eps))\n\n        def adaptive_parameter(current_value, best_fitness, current_fitness, initial_value, adaptation_rate=0.05):\n            # Adapt parameter based on fitness improvement\n            if current_fitness < best_fitness:\n                return current_value + adaptation_rate * (initial_value - current_value)\n            else:\n                return current_value - adaptation_rate * (current_value - initial_value)\n\n        while self.budget > 0:\n            mean_fitness = np.mean(fitness)\n            weights = np.array([update_weight(i, best_fitness, fitness, mean_fitness) for i in range(self.population_size)])\n            weights = weights / (np.sum(weights) + np.finfo(float).eps) # Normalize\n\n            for i in range(self.population_size):\n                # Dynamic topology: random connections based on fitness\n                neighbors = np.random.choice(self.population_size, size=2, replace=False)\n                if np.random.rand() < self.c1:  #Exploitation phase\n                    r1 = neighbors[0]\n                    r2 = neighbors[1]\n                    new_position = best_position + np.random.uniform(0, self.b, size=self.dim) * weights[i] * (population[r1] - population[r2])\n\n                else: #Exploration phase\n                    p = np.random.rand()\n                    if p < 0.5:\n                        # Guided exploration towards best\n                        new_position = population[i] + np.random.uniform(-self.a, self.a, size=self.dim) * (best_position - population[i])\n                    else:\n                        #Random exploration with a focus on promising regions\n                         new_position = population[i] + np.random.uniform(-self.a, self.a, size=self.dim) * (np.random.uniform(lb, ub, size=self.dim) - population[i])\n\n                # Restart mechanism\n                if np.random.rand() < self.restart_prob:\n                    new_position = np.random.uniform(lb, ub, size=self.dim)\n\n                # Clip to bounds\n                new_position = np.clip(new_position, lb, ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < fitness[i]:\n                    population[i] = new_position.copy()\n                    fitness[i] = new_fitness\n\n                    # Update best\n                    if new_fitness < best_fitness:\n                        best_fitness = new_fitness\n                        best_position = new_position.copy()\n\n                if self.budget <= 0:\n                    break\n\n            # Adaptive Adjustment of parameters based on fitness improvement\n            self.a = adaptive_parameter(self.a, best_fitness, np.mean(fitness), 0.3)\n            self.b = adaptive_parameter(self.b, best_fitness, np.mean(fitness), 0.1)\n            self.c1 = adaptive_parameter(self.c1, best_fitness, np.mean(fitness), 0.1)\n            self.c2 = adaptive_parameter(self.c2, best_fitness, np.mean(fitness), 0.05)\n\n            self.a = max(0.01, min(self.a, 0.5))\n            self.b = max(0.01, min(self.b, 0.5))\n            self.c1 = max(0.01, min(self.c1, 0.2))\n            self.c2 = max(0.01, min(self.c2, 0.2))\n\n        return best_fitness, best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveSlimeMoldOptimization scored 0.270 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["70a668bd-2fff-4272-85a3-60d1f629b7b7"], "operator": null, "metadata": {"aucs": [0.12896679211326123, 0.200126667224774, 0.3584623813937625, 0.36209023826878584, 0.2675457862289511, 0.35082036006848627, 0.27788738057141227, 0.28240045647894585, 0.30524888306643705, 0.16907232196973543]}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "def537b8-4eef-4950-b6cf-2acd2019e191", "fitness": "-inf", "name": "AdaptiveSlimeMoldOptimization", "description": "Adaptive Slime Mold Optimization with enhanced exploration, dynamic parameter adaptation based on fitness landscape analysis, and a self-adaptive mutation strategy.", "code": "import numpy as np\n\nclass AdaptiveSlimeMoldOptimization:\n    def __init__(self, budget=10000, dim=10, population_size=20, c1=0.1, c2=0.05, a=0.3, b=0.1, initial_mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.c1 = c1  # Exploration factor\n        self.c2 = c2  # Exploitation factor\n        self.a = a  # Adaptive parameter 1 (exploration scaling)\n        self.b = b  # Adaptive parameter 2 (exploitation scaling)\n        self.mutation_rate = initial_mutation_rate\n        self.initial_mutation_rate = initial_mutation_rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population within bounds\n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Initialize best position and fitness\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        best_fitness = fitness[best_index]\n\n        def update_weight(r, best_fitness, fitness, mean_fitness):\n            #Weight calculation with added sensitivity to fitness differences\n            return 1 + abs(np.random.normal(0, 1) * (best_fitness - fitness[r]) / (abs(fitness[r] - mean_fitness) + np.finfo(float).eps))\n\n        def mutate(x, lb, ub, mutation_rate):\n            mask = np.random.rand(len(x)) < mutation_rate\n            x[mask] = np.random.uniform(lb, ub, size=np.sum(mask))\n            return x\n\n        while self.budget > 0:\n            mean_fitness = np.mean(fitness)\n            weights = np.array([update_weight(i, best_fitness, fitness, mean_fitness) for i in range(self.population_size)])\n            weights = weights / np.sum(weights)\n\n            for i in range(self.population_size):\n                if np.random.rand() < self.c1:  #Exploitation phase\n                    r1 = np.random.randint(0, self.population_size)\n                    r2 = np.random.randint(0, self.population_size)\n                    new_position = best_position + np.random.uniform(0, self.b, size=self.dim) * weights[i] * (population[r1] - population[r2])\n\n                else: #Exploration phase\n                    p = np.random.rand()\n                    if p < 0.5:\n                        # Guided exploration towards best\n                        new_position = population[i] + np.random.uniform(-self.a, self.a, size=self.dim) * (best_position - population[i])\n                    else:\n                        #Random exploration with a focus on promising regions\n                         new_position = population[i] + np.random.uniform(-self.a, self.a, size=self.dim) * (np.random.uniform(lb, ub, size=self.dim) - population[i])\n\n                # Clip to bounds\n                new_position = np.clip(new_position, lb, ub)\n\n                # Apply mutation\n                new_position = mutate(new_position, lb, ub, self.mutation_rate)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < fitness[i]:\n                    population[i] = new_position.copy()\n                    fitness[i] = new_fitness\n\n                    # Update best\n                    if new_fitness < best_fitness:\n                        best_fitness = new_fitness\n                        best_position = new_position.copy()\n\n                if self.budget <= 0:\n                    break\n\n            # Adaptive Adjustment of parameters\n            self.a = max(0.01, 0.98 * self.a)  # Gradually decrease exploration range\n            self.b = min(0.5, 1.02 * self.b) #Gradually increase exploitation range\n            self.c1 = max(0.01, 0.99 * self.c1) # Reduce exploration factor\n            self.c2 = min(0.2, 1.01 * self.c2) # Increase exploitation factor\n\n            # Adaptive Mutation Rate\n            if np.std(fitness) < 1e-6:  #Stagnation detection\n                self.mutation_rate = min(0.5, self.mutation_rate * 1.1)  # Increase mutation\n            else:\n                self.mutation_rate = max(0.01, self.mutation_rate * 0.95)  # Decrease mutation\n\n        return best_fitness, best_position", "configspace": "", "generation": 7, "feedback": "In the code, line 784, in numpy.PyArray_MultiIterNew3, the following error occurred:\nValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (0,) and arg 1 with shape (2,).", "error": "In the code, line 784, in numpy.PyArray_MultiIterNew3, the following error occurred:\nValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (0,) and arg 1 with shape (2,).", "parent_ids": ["70a668bd-2fff-4272-85a3-60d1f629b7b7"], "operator": null, "metadata": {}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "fe152535-975b-4d1b-8d92-ef098798329f", "fitness": "-inf", "name": "EnhancedSlimeMoldOptimizationSA", "description": "Adaptive Slime Mold Optimization with fitness-based population diversity control and a self-adaptive strategy for balancing exploration and exploitation, further enhanced by a Simulated Annealing-inspired acceptance criterion for uphill moves.", "code": "import numpy as np\n\nclass EnhancedSlimeMoldOptimizationSA:\n    def __init__(self, budget=10000, dim=10, population_size=20, c1=0.1, c2=0.05, a=0.3, b=0.1, initial_temperature=1.0, cooling_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.c1 = c1  # Exploration factor\n        self.c2 = c2  # Exploitation factor\n        self.a = a  # Adaptive parameter 1 (exploration scaling)\n        self.b = b  # Adaptive parameter 2 (exploitation scaling)\n        self.initial_temperature = initial_temperature\n        self.cooling_rate = cooling_rate\n        self.temperature = initial_temperature\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population within bounds\n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Initialize best position and fitness\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        best_fitness = fitness[best_index]\n\n        def update_weight(r, best_fitness, fitness, mean_fitness):\n            #Weight calculation with added sensitivity to fitness differences\n            return 1 + abs(np.random.normal(0, 1) * (best_fitness - fitness[r]) / (abs(fitness[r] - mean_fitness) + np.finfo(float).eps))\n\n        def calculate_diversity(population):\n            # Calculate average distance from each individual to the centroid\n            centroid = np.mean(population, axis=0)\n            distances = np.linalg.norm(population - centroid, axis=1)\n            return np.mean(distances)\n\n\n        while self.budget > 0:\n            mean_fitness = np.mean(fitness)\n            weights = np.array([update_weight(i, best_fitness, fitness, mean_fitness) for i in range(self.population_size)])\n            weights = weights / np.sum(weights)\n\n            diversity = calculate_diversity(population)\n            diversity_threshold = 0.1 * (ub - lb) #Dynamic threshold related to search space\n\n            for i in range(self.population_size):\n                if np.random.rand() < self.c1:  #Exploitation phase\n                    r1 = np.random.randint(0, self.population_size)\n                    r2 = np.random.randint(0, self.population_size)\n                    new_position = best_position + np.random.uniform(0, self.b, size=self.dim) * weights[i] * (population[r1] - population[r2])\n\n                else: #Exploration phase\n                    p = np.random.rand()\n                    if p < 0.5:\n                        # Guided exploration towards best\n                        new_position = population[i] + np.random.uniform(-self.a, self.a, size=self.dim) * (best_position - population[i])\n                    else:\n                        #Random exploration with a focus on promising regions\n                         new_position = population[i] + np.random.uniform(-self.a, self.a, size=self.dim) * (np.random.uniform(lb, ub, size=self.dim) - population[i])\n\n                # Clip to bounds\n                new_position = np.clip(new_position, lb, ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                # Simulated Annealing acceptance criterion\n                delta_fitness = new_fitness - fitness[i]\n                if delta_fitness < 0:\n                    population[i] = new_position.copy()\n                    fitness[i] = new_fitness\n\n                    # Update best\n                    if new_fitness < best_fitness:\n                        best_fitness = new_fitness\n                        best_position = new_position.copy()\n                else:\n                    #Acceptance probability based on temperature\n                    acceptance_probability = np.exp(-delta_fitness / self.temperature)\n                    if np.random.rand() < acceptance_probability:\n                        population[i] = new_position.copy()\n                        fitness[i] = new_fitness\n\n\n\n                if self.budget <= 0:\n                    break\n\n            # Adaptive Adjustment of parameters\n            self.a = max(0.01, 0.98 * self.a)  # Gradually decrease exploration range\n            self.b = min(0.5, 1.02 * self.b) #Gradually increase exploitation range\n            self.c1 = max(0.01, 0.99 * self.c1) # Reduce exploration factor\n            self.c2 = min(0.2, 1.01 * self.c2) # Increase exploitation factor\n\n            #Adaptive population diversity control\n            if diversity < diversity_threshold:\n                #Introduce new random individuals to increase diversity\n                num_new = int(0.1 * self.population_size)\n                new_individuals = np.random.uniform(lb, ub, size=(num_new, self.dim))\n                new_fitnesses = np.array([func(x) for x in new_individuals])\n                self.budget -= num_new\n\n                worst_indices = np.argsort(fitness)[-num_new:]\n                population[worst_indices] = new_individuals.copy()\n                fitness[worst_indices] = new_fitnesses.copy()\n\n                best_index = np.argmin(fitness)\n                best_position = population[best_index].copy()\n                best_fitness = fitness[best_index]\n\n\n            #Cool the temperature\n            self.temperature *= self.cooling_rate\n\n        return best_fitness, best_position", "configspace": "", "generation": 8, "feedback": "In the code, line 101, in __call__, the following error occurred:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\nOn line: if diversity < diversity_threshold:", "error": "In the code, line 101, in __call__, the following error occurred:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\nOn line: if diversity < diversity_threshold:", "parent_ids": ["70a668bd-2fff-4272-85a3-60d1f629b7b7"], "operator": null, "metadata": {}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
