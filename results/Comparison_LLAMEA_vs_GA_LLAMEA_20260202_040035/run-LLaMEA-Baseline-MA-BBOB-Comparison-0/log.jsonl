{"id": "232c9c32-f930-478f-bf14-9c9cd0fb59f1", "fitness": 0.3082022878732344, "name": "AntColonyOptimization", "description": "A population-based algorithm inspired by the foraging behavior of ants, incorporating local search and pheromone-inspired communication to guide the search process.", "code": "import numpy as np\n\nclass AntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, colony_size=50, evaporation_rate=0.1, alpha=1.0, beta=2.0, local_search_iterations=5):\n        \"\"\"\n        Initializes the Ant Colony Optimization algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            colony_size (int): The number of ants in the colony.\n            evaporation_rate (float): The rate at which pheromone trails evaporate.\n            alpha (float): Influence of pheromone on decision making.\n            beta (float): Influence of heuristic information on decision making.\n            local_search_iterations (int): Number of iterations for local search around the best ant.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.colony_size = colony_size\n        self.evaporation_rate = evaporation_rate\n        self.alpha = alpha\n        self.beta = beta\n        self.local_search_iterations = local_search_iterations\n        self.pheromone = np.ones(dim)  # Initialize pheromone trails for each dimension\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black box function using Ant Colony Optimization.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        evaluations = 0\n\n        # Initialize ant positions randomly\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.colony_size, self.dim))\n        fitness = np.zeros(self.colony_size)\n\n        for i in range(self.colony_size):\n            fitness[i] = func(ants[i])\n            evaluations += 1\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = ants[i]\n                \n            if evaluations >= self.budget:\n                return self.f_opt, self.x_opt\n\n        while evaluations < self.budget:\n            # Construct solutions for each ant\n            for i in range(self.colony_size):\n                # Probabilistically select the next position based on pheromone and heuristic information\n                probabilities = (self.pheromone**self.alpha) / np.sum(self.pheromone**self.alpha)\n                movements = np.random.normal(0, probabilities, self.dim) #Normal distribution centered around pheromone-influenced directions\n                new_ant = ants[i] + movements\n                new_ant = np.clip(new_ant, func.bounds.lb, func.bounds.ub) # Clip to bounds\n                \n                f = func(new_ant)\n                evaluations += 1\n                if f < fitness[i]:\n                    ants[i] = new_ant\n                    fitness[i] = f\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_ant\n                \n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n            # Local search around the best ant\n            for _ in range(self.local_search_iterations):\n                perturbation = np.random.uniform(-0.1, 0.1, self.dim)  # Small random perturbation\n                new_x = self.x_opt + perturbation\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                f = func(new_x)\n                evaluations += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_x\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n            # Update pheromone trails\n            self.pheromone *= (1 - self.evaporation_rate)  # Evaporation\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.colony_size):\n                delta_pheromone += (self.f_opt / fitness[i]) * np.abs(ants[i] - self.x_opt) # deposit pheromone proportional to the improvement and closeness to the best.\n            self.pheromone += delta_pheromone\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AntColonyOptimization scored 0.308 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1416376381455715, 0.37812085975435994, 0.3703405100887074, 0.5941520210594697, 0.20552540163364108, 0.4356196857717457, 0.24257364371707968, 0.3166454607279724, 0.23402840115763124, 0.1633792566761656]}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "95fff9f4-77ac-44e1-8263-cb0eb07ff475", "fitness": 0.3247126737743978, "name": "AdaptiveAntColonyOptimization", "description": "A modified Ant Colony Optimization with adaptive pheromone update, dynamic exploration-exploitation balance, and a Cauchy mutation-based local search.", "code": "import numpy as np\n\nclass AdaptiveAntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, colony_size=50, evaporation_rate=0.1, alpha=1.0, beta=2.0, local_search_iterations=5, q=1.0):\n        \"\"\"\n        Initializes the Adaptive Ant Colony Optimization algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            colony_size (int): The number of ants in the colony.\n            evaporation_rate (float): The rate at which pheromone trails evaporate.\n            alpha (float): Influence of pheromone on decision making.\n            beta (float): Influence of heuristic information on decision making.\n            local_search_iterations (int): Number of iterations for local search.\n            q (float): Parameter for pheromone update based on solution quality.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.colony_size = colony_size\n        self.evaporation_rate = evaporation_rate\n        self.alpha = alpha\n        self.beta = beta\n        self.local_search_iterations = local_search_iterations\n        self.pheromone = np.ones(dim)  # Initialize pheromone trails for each dimension\n        self.q = q\n        self.exploration_rate = 0.7  # Initial exploration rate, dynamically adjusted\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black box function using Adaptive Ant Colony Optimization.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        evaluations = 0\n\n        # Initialize ant positions randomly\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.colony_size, self.dim))\n        fitness = np.zeros(self.colony_size)\n\n        for i in range(self.colony_size):\n            fitness[i] = func(ants[i])\n            evaluations += 1\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = ants[i]\n\n            if evaluations >= self.budget:\n                return self.f_opt, self.x_opt\n\n        best_fitness_history = [self.f_opt]\n\n        while evaluations < self.budget:\n            # Construct solutions for each ant\n            for i in range(self.colony_size):\n                # Probabilistically select the next position based on pheromone and heuristic information\n                probabilities = (self.pheromone**self.alpha) / np.sum(self.pheromone**self.alpha)\n                # Exploration vs. Exploitation: Use exploration_rate to control random movement\n                if np.random.rand() < self.exploration_rate:\n                     movements = np.random.uniform(-1, 1, self.dim)  # Explore: Random movements\n                else:\n                     movements = np.random.normal(0, probabilities, self.dim)  # Exploit: Pheromone-guided movements\n                \n                new_ant = ants[i] + movements\n                new_ant = np.clip(new_ant, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                f = func(new_ant)\n                evaluations += 1\n                if f < fitness[i]:\n                    ants[i] = new_ant\n                    fitness[i] = f\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_ant\n\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n            # Cauchy mutation-based Local search around the best ant\n            for _ in range(self.local_search_iterations):\n                # Apply Cauchy mutation\n                cauchy_mutation = np.random.standard_cauchy(size=self.dim) * 0.05  # Scale Cauchy distribution\n                new_x = self.x_opt + cauchy_mutation\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                f = func(new_x)\n                evaluations += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_x\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n            # Adaptive Pheromone Update\n            self.pheromone *= (1 - self.evaporation_rate)  # Evaporation\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.colony_size):\n                delta_pheromone += (self.q / (1 + abs(fitness[i] - self.f_opt))) * np.abs(ants[i] - self.x_opt) # deposit pheromone proportional to the improvement and closeness to the best. The quality of solution is now explicitly considered via the abs(fitness[i] - self.f_opt term)\n            self.pheromone += delta_pheromone\n\n            # Adaptive Exploration Rate Adjustment\n            best_fitness_history.append(self.f_opt)\n            if len(best_fitness_history) > 10:\n                if abs(best_fitness_history[-1] - best_fitness_history[-10]) < 1e-5:  #Stagnation detection\n                    self.exploration_rate = min(1.0, self.exploration_rate + 0.1)  # Increase exploration\n                else:\n                    self.exploration_rate = max(0.1, self.exploration_rate - 0.05)  # Decrease exploration if improving\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveAntColonyOptimization scored 0.325 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["232c9c32-f930-478f-bf14-9c9cd0fb59f1"], "operator": null, "metadata": {"aucs": [0.15255209246850043, 0.22764732946693678, 0.3827120862471677, 0.546493145513276, 0.3436638444647053, 0.4165692373816592, 0.2798079428593091, 0.35608456779123365, 0.333793575599867, 0.20780291595132272]}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "94bf2952-3b08-4740-80f2-03c871cac290", "fitness": "-inf", "name": "EnhancedAdaptiveAntColonyOptimization", "description": "An enhanced Adaptive Ant Colony Optimization with dynamic parameter adaptation, levy flight exploration, and a refined pheromone update strategy based on solution diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveAntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, colony_size=50, evaporation_rate=0.1, alpha=1.0, beta=2.0, local_search_iterations=5, q=1.0, levy_exponent=1.5):\n        \"\"\"\n        Initializes the Enhanced Adaptive Ant Colony Optimization algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            colony_size (int): The number of ants in the colony.\n            evaporation_rate (float): The rate at which pheromone trails evaporate.\n            alpha (float): Influence of pheromone on decision making.\n            beta (float): Influence of heuristic information on decision making.\n            local_search_iterations (int): Number of iterations for local search.\n            q (float): Parameter for pheromone update based on solution quality.\n            levy_exponent (float): Exponent for Levy flight distribution.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.colony_size = colony_size\n        self.evaporation_rate = evaporation_rate\n        self.alpha = alpha\n        self.beta = beta\n        self.local_search_iterations = local_search_iterations\n        self.pheromone = np.ones(dim)  # Initialize pheromone trails for each dimension\n        self.q = q\n        self.exploration_rate = 0.7  # Initial exploration rate, dynamically adjusted\n        self.levy_exponent = levy_exponent\n        self.pheromone_influence = 0.5 # Dynamically adjusted influence of pheromone\n\n    def levy_flight(self, size):\n        \"\"\"\n        Generates Levy flight steps.\n\n        Args:\n            size (int or tuple): The size of the output array.\n\n        Returns:\n            numpy.ndarray: An array of Levy flight steps.\n        \"\"\"\n        u = np.random.normal(0, 1, size=size)\n        v = np.random.normal(0, 1, size=size)\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) / (np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * (2 ** ((self.levy_exponent - 1) / 2)))) ** (1 / self.levy_exponent)\n        step = sigma * u / (np.abs(v) ** (1 / self.levy_exponent))\n        return step\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black box function using Enhanced Adaptive Ant Colony Optimization.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        evaluations = 0\n\n        # Initialize ant positions randomly\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.colony_size, self.dim))\n        fitness = np.zeros(self.colony_size)\n\n        for i in range(self.colony_size):\n            fitness[i] = func(ants[i])\n            evaluations += 1\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = ants[i]\n\n            if evaluations >= self.budget:\n                return self.f_opt, self.x_opt\n\n        best_fitness_history = [self.f_opt]\n\n        while evaluations < self.budget:\n            # Construct solutions for each ant\n            for i in range(self.colony_size):\n                # Probabilistically select the next position based on pheromone and heuristic information\n                probabilities = (self.pheromone**self.alpha) / np.sum(self.pheromone**self.alpha)\n                # Exploration vs. Exploitation: Use exploration_rate to control random movement\n                if np.random.rand() < self.exploration_rate:\n                     movements = self.levy_flight(self.dim) * (func.bounds.ub - func.bounds.lb) * 0.01  # Explore: Levy flight movements\n                else:\n                     movements = np.random.normal(0, probabilities, self.dim) * self.pheromone_influence # Exploit: Pheromone-guided movements\n                \n                new_ant = ants[i] + movements\n                new_ant = np.clip(new_ant, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                f = func(new_ant)\n                evaluations += 1\n                if f < fitness[i]:\n                    ants[i] = new_ant\n                    fitness[i] = f\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_ant\n\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n            # Cauchy mutation-based Local search around the best ant\n            for _ in range(self.local_search_iterations):\n                # Apply Cauchy mutation\n                cauchy_mutation = np.random.standard_cauchy(size=self.dim) * 0.05  # Scale Cauchy distribution\n                new_x = self.x_opt + cauchy_mutation\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                f = func(new_x)\n                evaluations += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_x\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n            # Adaptive Pheromone Update\n            self.pheromone *= (1 - self.evaporation_rate)  # Evaporation\n            delta_pheromone = np.zeros(self.dim)\n            \n            # Refined Pheromone Deposit: Encourage diversity\n            distances_to_best = np.linalg.norm(ants - self.x_opt, axis=1)\n            diversity_factor = np.std(distances_to_best) # Compute population diversity\n            \n            for i in range(self.colony_size):\n                delta_pheromone += (self.q / (1 + abs(fitness[i] - self.f_opt))) * np.abs(ants[i] - self.x_opt) * (1 + diversity_factor) # deposit pheromone proportional to the improvement and closeness to the best. The quality of solution and population diversity is now explicitly considered.\n            self.pheromone += delta_pheromone\n\n            # Adaptive Exploration Rate Adjustment\n            best_fitness_history.append(self.f_opt)\n            if len(best_fitness_history) > 10:\n                if abs(best_fitness_history[-1] - best_fitness_history[-10]) < 1e-5:  #Stagnation detection\n                    self.exploration_rate = min(0.9, self.exploration_rate + 0.1)  # Increase exploration\n                    self.pheromone_influence = max(0.1, self.pheromone_influence - 0.05)  # Reduce pheromone influence\n                else:\n                    self.exploration_rate = max(0.2, self.exploration_rate - 0.05)  # Decrease exploration if improving\n                    self.pheromone_influence = min(0.9, self.pheromone_influence + 0.02)  # Increase pheromone influence\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "In the code, line 805, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'math'. Did you mean: 'emath'?", "error": "In the code, line 805, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'math'. Did you mean: 'emath'?", "parent_ids": ["95fff9f4-77ac-44e1-8263-cb0eb07ff475"], "operator": null, "metadata": {}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "447a000b-db8e-4a86-8fcf-bfd90f355a4c", "fitness": "-inf", "name": "HybridAdaptiveAntColonyOptimization", "description": "A hybrid ACO with dynamic parameter adaptation, employing a multi-strategy approach including a Sobol-sequence-based initialization, rank-based pheromone update, and a differential evolution-based local search, balancing exploration and exploitation effectively.", "code": "import numpy as np\nfrom scipy.stats import cauchy\nfrom scipy.stats import rankdata\n\nclass HybridAdaptiveAntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, colony_size=50, evaporation_rate=0.1,\n                 alpha=1.0, beta=2.0, local_search_iterations=5, q=1.0,\n                 exploration_rate=0.7, de_mutation_factor=0.5, de_crossover_rate=0.7):\n        \"\"\"\n        Initializes the Hybrid Adaptive Ant Colony Optimization algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            colony_size (int): The number of ants in the colony.\n            evaporation_rate (float): The rate at which pheromone trails evaporate.\n            alpha (float): Influence of pheromone on decision making.\n            beta (float): Influence of heuristic information on decision making.\n            local_search_iterations (int): Number of iterations for local search.\n            q (float): Parameter for pheromone update based on solution quality.\n            exploration_rate (float): Initial exploration rate.\n            de_mutation_factor (float): Mutation factor for differential evolution.\n            de_crossover_rate (float): Crossover rate for differential evolution.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.colony_size = colony_size\n        self.evaporation_rate = evaporation_rate\n        self.alpha = alpha\n        self.beta = beta\n        self.local_search_iterations = local_search_iterations\n        self.pheromone = np.ones(dim)  # Initialize pheromone trails for each dimension\n        self.q = q\n        self.exploration_rate = exploration_rate\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.best_fitness_history = []\n\n        self.sobol_engine = None # Placeholder\n\n    def _initialize_sobol(self):\n        try:\n            from scipy.stats import qmc\n            self.sobol_engine = qmc.Sobol(d=self.dim, scramble=True)\n        except ImportError:\n            self.sobol_engine = None\n            print(\"Sobol sequence initialization requires scipy >= 1.7.0. Falling back to random initialization.\")\n\n\n    def _sobol_sample(self, n_samples, bounds):\n         if self.sobol_engine is None:\n              return np.random.uniform(bounds.lb, bounds.ub, size=(n_samples, self.dim))\n         else:\n            samples = self.sobol_engine.random(n=n_samples)\n            return bounds.lb + (bounds.ub - bounds.lb) * samples\n\n\n    def differential_evolution_local_search(self, func, x, bounds):\n        \"\"\"\n        Performs differential evolution-based local search around a given solution.\n        \"\"\"\n        mutated = x + self.de_mutation_factor * (self.x_opt - x) #Simplified DE\n        mutated = np.clip(mutated, bounds.lb, bounds.ub)\n\n        # Crossover\n        crossover_mask = np.random.rand(self.dim) < self.de_crossover_rate\n        trial_vector = np.where(crossover_mask, mutated, x)\n\n        return trial_vector\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black box function using Hybrid Adaptive Ant Colony Optimization.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n        evaluations = 0\n        self._initialize_sobol() # Initialize Sobol engine\n\n        # Initialize ant positions using Sobol sequence\n        ants = self._sobol_sample(self.colony_size, func.bounds)\n\n        fitness = np.zeros(self.colony_size)\n\n        for i in range(self.colony_size):\n            fitness[i] = func(ants[i])\n            evaluations += 1\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = ants[i]\n\n            if evaluations >= self.budget:\n                return self.f_opt, self.x_opt\n\n        self.best_fitness_history = [self.f_opt]\n\n        while evaluations < self.budget:\n            # Construct solutions for each ant\n            for i in range(self.colony_size):\n                # Probabilistically select the next position based on pheromone and heuristic information\n                probabilities = (self.pheromone**self.alpha) / np.sum(self.pheromone**self.alpha) if np.sum(self.pheromone**self.alpha) > 0 else np.ones(self.dim) / self.dim  # Handle potential division by zero\n                # Exploration vs. Exploitation: Use exploration_rate to control random movement\n                if np.random.rand() < self.exploration_rate:\n                     movements = np.random.uniform(-1, 1, self.dim)  # Explore: Random movements\n                else:\n                     movements = np.random.normal(0, probabilities, self.dim)  # Exploit: Pheromone-guided movements\n\n                new_ant = ants[i] + movements\n                new_ant = np.clip(new_ant, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                f = func(new_ant)\n                evaluations += 1\n                if f < fitness[i]:\n                    ants[i] = new_ant\n                    fitness[i] = f\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_ant\n\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n\n            # Differential Evolution Local Search around the best ant\n            for _ in range(self.local_search_iterations):\n                new_x = self.differential_evolution_local_search(func, self.x_opt, func.bounds)\n                f = func(new_x)\n                evaluations += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_x\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n\n            # Adaptive Pheromone Update - Rank-Based\n            ranks = rankdata(fitness)\n            self.pheromone *= (1 - self.evaporation_rate)  # Evaporation\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.colony_size):\n                delta_pheromone += (self.q * ranks[i] / self.colony_size) * np.abs(ants[i] - self.x_opt) # Deposit pheromone based on rank and distance to best\n            self.pheromone += delta_pheromone\n\n\n            # Adaptive Exploration Rate Adjustment\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > 10:\n                if abs(self.best_fitness_history[-1] - self.best_fitness_history[-10]) < 1e-5:  # Stagnation detection\n                    self.exploration_rate = min(1.0, self.exploration_rate + 0.1)  # Increase exploration\n                else:\n                    self.exploration_rate = max(0.1, self.exploration_rate - 0.05)  # Decrease exploration if improving\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "Evaluation timed out after 600 seconds.", "error": "Evaluation timed out after 600 seconds.", "parent_ids": ["95fff9f4-77ac-44e1-8263-cb0eb07ff475"], "operator": null, "metadata": {}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "b4c46c26-d1d3-4854-949c-8e4c819fb384", "fitness": "-inf", "name": "AdaptiveAntColonyOptimizationV2", "description": "A self-tuning Adaptive Ant Colony Optimization with dynamic parameter control, enhanced pheromone update, and a more robust local search strategy to balance exploration and exploitation effectively.", "code": "import numpy as np\n\nclass AdaptiveAntColonyOptimizationV2:\n    def __init__(self, budget=10000, dim=10, colony_size=50, evaporation_rate=0.1, alpha=1.0, beta=2.0, local_search_iterations=5, q=1.0, initial_exploration_rate=0.7):\n        \"\"\"\n        Initializes the Adaptive Ant Colony Optimization algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            colony_size (int): The number of ants in the colony.\n            evaporation_rate (float): The rate at which pheromone trails evaporate.\n            alpha (float): Influence of pheromone on decision making.\n            beta (float): Influence of heuristic information on decision making.\n            local_search_iterations (int): Number of iterations for local search.\n            q (float): Parameter for pheromone update based on solution quality.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.colony_size = colony_size\n        self.evaporation_rate = evaporation_rate\n        self.alpha = alpha\n        self.beta = beta\n        self.local_search_iterations = local_search_iterations\n        self.pheromone = np.ones(dim) * 0.001  # Initialize pheromone trails for each dimension with a small value\n        self.q = q\n        self.exploration_rate = initial_exploration_rate  # Initial exploration rate, dynamically adjusted\n        self.initial_exploration_rate = initial_exploration_rate\n        self.best_fitness_history = []\n        self.stagnation_counter = 0\n        self.pheromone_min = 0.00001  # Minimum pheromone value\n        self.pheromone_max = 10.0 #Maximum pheromone value\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black box function using Adaptive Ant Colony Optimization.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        evaluations = 0\n\n        # Initialize ant positions randomly\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.colony_size, self.dim))\n        fitness = np.zeros(self.colony_size)\n\n        for i in range(self.colony_size):\n            fitness[i] = func(ants[i])\n            evaluations += 1\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = ants[i]\n\n            if evaluations >= self.budget:\n                return self.f_opt, self.x_opt\n\n        self.best_fitness_history.append(self.f_opt)\n\n        while evaluations < self.budget:\n            # Construct solutions for each ant\n            for i in range(self.colony_size):\n                # Probabilistically select the next position based on pheromone and heuristic information\n                probabilities = (self.pheromone**self.alpha) / np.sum(self.pheromone**self.alpha) if np.sum(self.pheromone**self.alpha) > 0 else np.ones(self.dim) / self.dim # Handle zero division\n\n                # Exploration vs. Exploitation: Use exploration_rate to control random movement\n                if np.random.rand() < self.exploration_rate:\n                     movements = np.random.uniform(-1, 1, self.dim)  # Explore: Random movements\n                else:\n                     movements = np.random.normal(0, probabilities, self.dim)  # Exploit: Pheromone-guided movements\n\n                new_ant = ants[i] + movements\n                new_ant = np.clip(new_ant, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                f = func(new_ant)\n                evaluations += 1\n                if f < fitness[i]:\n                    ants[i] = new_ant\n                    fitness[i] = f\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_ant\n\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n            # Cauchy mutation-based Local search around the best ant - Enhanced version\n            for _ in range(self.local_search_iterations):\n                # Apply Cauchy mutation with adaptive scaling\n                cauchy_mutation = np.random.standard_cauchy(size=self.dim) * (0.05 + 0.05 * self.exploration_rate)  # Scale Cauchy distribution adaptively\n                new_x = self.x_opt + cauchy_mutation\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                f = func(new_x)\n                evaluations += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_x\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n            # Adaptive Pheromone Update - Enhanced version\n            self.pheromone *= (1 - self.evaporation_rate)  # Evaporation\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.colony_size):\n                # Deposit pheromone proportional to the improvement and closeness to the best.\n                delta_pheromone += (self.q / (1 + abs(fitness[i] - self.f_opt))) * np.exp(-np.linalg.norm(ants[i] - self.x_opt) / self.dim) # Gaussian-like weighting based on distance\n\n            self.pheromone += delta_pheromone\n            self.pheromone = np.clip(self.pheromone, self.pheromone_min, self.pheromone_max) # Clip pheromone values\n\n            # Adaptive Exploration Rate Adjustment - Enhanced version\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > 10:\n                if abs(self.best_fitness_history[-1] - self.best_fitness_history[-10]) < 1e-5:  # Stagnation detection\n                    self.stagnation_counter +=1\n                    if self.stagnation_counter > 5:\n                         self.exploration_rate = min(1.0, self.exploration_rate + 0.2)  # Increase exploration more aggressively\n                         self.stagnation_counter = 0 #Reset counter\n                         self.pheromone = np.ones(self.dim) * 0.001 # Reset pheromones to encourage exploration\n                else:\n                    self.exploration_rate = max(0.1, self.exploration_rate - 0.05)  # Decrease exploration if improving\n                    self.stagnation_counter = 0 #Reset stagnation counter\n            #Dynamic Evaporation Rate\n            self.evaporation_rate = 0.1 + 0.4 * self.exploration_rate  # Evaporation rate linked to exploration\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "Evaluation timed out after 600 seconds.", "error": "Evaluation timed out after 600 seconds.", "parent_ids": ["95fff9f4-77ac-44e1-8263-cb0eb07ff475"], "operator": null, "metadata": {}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "2a973bde-0ef4-44c9-aca2-27a969f60077", "fitness": "-inf", "name": "HybridAntColonyOptimization", "description": "A hybrid Ant Colony Optimization with dynamic parameter adaptation, Lévy flight exploration, and a Nelder-Mead local search to balance exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridAntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, colony_size=50, evaporation_rate=0.1, alpha=1.0, beta=2.0, local_search_iterations=3, q=1.0, levy_exponent=1.5):\n        \"\"\"\n        Initializes the Hybrid Ant Colony Optimization algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            colony_size (int): The number of ants in the colony.\n            evaporation_rate (float): The rate at which pheromone trails evaporate.\n            alpha (float): Influence of pheromone on decision making.\n            beta (float): Influence of heuristic information on decision making.\n            local_search_iterations (int): Number of iterations for local search.\n            q (float): Parameter for pheromone update based on solution quality.\n            levy_exponent (float): Exponent for Lévy flight distribution.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.colony_size = colony_size\n        self.evaporation_rate = evaporation_rate\n        self.alpha = alpha\n        self.beta = beta\n        self.local_search_iterations = local_search_iterations\n        self.pheromone = np.ones(dim)  # Initialize pheromone trails for each dimension\n        self.q = q\n        self.exploration_rate = 0.7  # Initial exploration rate, dynamically adjusted\n        self.levy_exponent = levy_exponent\n\n    def levy_flight(self, size):\n        \"\"\"\n        Generates Lévy flight steps.\n\n        Args:\n            size (int or tuple): The size of the output array.\n\n        Returns:\n            numpy.ndarray: An array of Lévy flight steps.\n        \"\"\"\n        u = np.random.normal(0, 1, size=size)\n        v = np.random.normal(0, 1, size=size)\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) / (np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * (2 ** ((self.levy_exponent - 1) / 2)))) ** (1 / self.levy_exponent)\n        step = sigma * u / (np.abs(v) ** (1 / self.levy_exponent))\n        return step\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black box function using Hybrid Ant Colony Optimization.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        evaluations = 0\n\n        # Initialize ant positions randomly\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.colony_size, self.dim))\n        fitness = np.zeros(self.colony_size)\n\n        for i in range(self.colony_size):\n            fitness[i] = func(ants[i])\n            evaluations += 1\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = ants[i]\n\n            if evaluations >= self.budget:\n                return self.f_opt, self.x_opt\n\n        best_fitness_history = [self.f_opt]\n\n        while evaluations < self.budget:\n            # Construct solutions for each ant\n            for i in range(self.colony_size):\n                # Probabilistically select the next position based on pheromone and heuristic information\n                probabilities = (self.pheromone**self.alpha) / np.sum(self.pheromone**self.alpha)\n                # Exploration vs. Exploitation: Use exploration_rate to control random movement\n                if np.random.rand() < self.exploration_rate:\n                     movements = self.levy_flight(self.dim) * 0.1  # Explore: Lévy flight movements\n                else:\n                     movements = np.random.normal(0, probabilities, self.dim)  # Exploit: Pheromone-guided movements\n                \n                new_ant = ants[i] + movements\n                new_ant = np.clip(new_ant, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                f = func(new_ant)\n                evaluations += 1\n                if f < fitness[i]:\n                    ants[i] = new_ant\n                    fitness[i] = f\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_ant\n\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n            # Nelder-Mead Local search around the best ant\n            for _ in range(self.local_search_iterations):\n                res = minimize(func, self.x_opt, method='Nelder-Mead', bounds=[(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)], options={'maxfev': max(1, int((self.budget - evaluations) / (self.local_search_iterations * 2)))} )  # Limit FE calls\n                evaluations += res.nfev\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n            # Adaptive Pheromone Update\n            self.pheromone *= (1 - self.evaporation_rate)  # Evaporation\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.colony_size):\n                delta_pheromone += (self.q / (1 + abs(fitness[i] - self.f_opt))) * np.abs(ants[i] - self.x_opt) # deposit pheromone proportional to the improvement and closeness to the best. The quality of solution is now explicitly considered via the abs(fitness[i] - self.f_opt term)\n            self.pheromone += delta_pheromone\n\n            # Adaptive Exploration Rate Adjustment\n            best_fitness_history.append(self.f_opt)\n            if len(best_fitness_history) > 10:\n                if abs(best_fitness_history[-1] - best_fitness_history[-10]) < 1e-5:  #Stagnation detection\n                    self.exploration_rate = min(0.9, self.exploration_rate + 0.1)  # Increase exploration\n                else:\n                    self.exploration_rate = max(0.2, self.exploration_rate - 0.05)  # Decrease exploration if improving\n\n            # Adaptive Evaporation Rate Adjustment\n            if len(best_fitness_history) > 10:\n                if best_fitness_history[-1] < best_fitness_history[-2]:\n                    self.evaporation_rate = min(0.5, self.evaporation_rate + 0.01)\n                else:\n                    self.evaporation_rate = max(0.01, self.evaporation_rate - 0.01)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "In the code, line 805, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'math'. Did you mean: 'emath'?", "error": "In the code, line 805, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'math'. Did you mean: 'emath'?", "parent_ids": ["95fff9f4-77ac-44e1-8263-cb0eb07ff475"], "operator": null, "metadata": {}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "02590efe-d2fa-43e9-bf47-0ff5d6928188", "fitness": "-inf", "name": "RingTopologyAdaptiveAntColonyOptimization", "description": "A hybrid Ant Colony Optimization with dynamic parameter adaptation, a ring topology for enhanced exploration, and a differential evolution-based local search for fine-tuning solutions.", "code": "import numpy as np\n\nclass RingTopologyAdaptiveAntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, colony_size=50, evaporation_rate=0.1, alpha=1.0, beta=2.0, local_search_iterations=5, q=1.0, de_mutation_factor=0.5, de_crossover_rate=0.7):\n        \"\"\"\n        Initializes the Ring Topology Adaptive Ant Colony Optimization algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            colony_size (int): The number of ants in the colony.\n            evaporation_rate (float): The rate at which pheromone trails evaporate.\n            alpha (float): Influence of pheromone on decision making.\n            beta (float): Influence of heuristic information on decision making.\n            local_search_iterations (int): Number of iterations for local search.\n            q (float): Parameter for pheromone update based on solution quality.\n            de_mutation_factor (float): Mutation factor for differential evolution.\n            de_crossover_rate (float): Crossover rate for differential evolution.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.colony_size = colony_size\n        self.evaporation_rate = evaporation_rate\n        self.alpha = alpha\n        self.beta = beta\n        self.local_search_iterations = local_search_iterations\n        self.pheromone = np.ones(dim)  # Initialize pheromone trails for each dimension\n        self.q = q\n        self.exploration_rate = 0.7  # Initial exploration rate, dynamically adjusted\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black box function using Ring Topology Adaptive Ant Colony Optimization.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        evaluations = 0\n\n        # Initialize ant positions randomly\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.colony_size, self.dim))\n        fitness = np.zeros(self.colony_size)\n\n        for i in range(self.colony_size):\n            fitness[i] = func(ants[i])\n            evaluations += 1\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = ants[i]\n\n            if evaluations >= self.budget:\n                return self.f_opt, self.x_opt\n\n        best_fitness_history = [self.f_opt]\n\n        while evaluations < self.budget:\n            # Construct solutions for each ant\n            for i in range(self.colony_size):\n                # Ring Topology: Interact with neighbors\n                neighbor_index = (i + 1) % self.colony_size\n                neighbor_ant = ants[neighbor_index]\n\n                # Probabilistically select the next position based on pheromone and heuristic information\n                probabilities = (self.pheromone**self.alpha) / np.sum(self.pheromone**self.alpha)\n\n                # Exploration vs. Exploitation: Use exploration_rate to control random movement\n                if np.random.rand() < self.exploration_rate:\n                    movements = np.random.uniform(-1, 1, self.dim)  # Explore: Random movements\n                else:\n                    # Combine pheromone-guided movement with neighbor influence\n                    pheromone_movement = np.random.normal(0, probabilities, self.dim)\n                    neighbor_influence = (neighbor_ant - ants[i]) * self.beta # Influence from neighbor\n                    movements = pheromone_movement + neighbor_influence\n\n                new_ant = ants[i] + movements\n                new_ant = np.clip(new_ant, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                f = func(new_ant)\n                evaluations += 1\n                if f < fitness[i]:\n                    ants[i] = new_ant\n                    fitness[i] = f\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_ant\n\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n            # Differential Evolution-based Local Search around the best ant\n            for _ in range(self.local_search_iterations):\n                # Select three random ants\n                indices = np.random.choice(self.colony_size, 3, replace=False)\n                a, b, c = ants[indices]\n\n                # Mutation\n                mutated_vector = a + self.de_mutation_factor * (b - c)\n                mutated_vector = np.clip(mutated_vector, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.de_crossover_rate\n                trial_vector = np.where(crossover_mask, mutated_vector, self.x_opt) # Blend with the best\n\n                f = func(trial_vector)\n                evaluations += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = trial_vector\n\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n\n            # Adaptive Pheromone Update\n            self.pheromone *= (1 - self.evaporation_rate)  # Evaporation\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.colony_size):\n                delta_pheromone += (self.q / (1 + abs(fitness[i] - self.f_opt))) * np.abs(ants[i] - self.x_opt) # deposit pheromone proportional to the improvement and closeness to the best. The quality of solution is now explicitly considered via the abs(fitness[i] - self.f_opt term)\n            self.pheromone += delta_pheromone\n\n            # Adaptive Exploration Rate Adjustment\n            best_fitness_history.append(self.f_opt)\n            if len(best_fitness_history) > 10:\n                if abs(best_fitness_history[-1] - best_fitness_history[-10]) < 1e-5:  #Stagnation detection\n                    self.exploration_rate = min(1.0, self.exploration_rate + 0.1)  # Increase exploration\n                else:\n                    self.exploration_rate = max(0.1, self.exploration_rate - 0.05)  # Decrease exploration if improving\n\n            # Adaptive Parameter Control: Adjust evaporation rate based on search progress\n            if len(best_fitness_history) > 20:\n                if best_fitness_history[-1] < best_fitness_history[-20]:\n                    self.evaporation_rate = max(0.01, self.evaporation_rate - 0.01)  # Reduce evaporation if improving\n                else:\n                    self.evaporation_rate = min(0.5, self.evaporation_rate + 0.02) # Increase evaporation if stagnating\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "Evaluation timed out after 600 seconds.", "error": "Evaluation timed out after 600 seconds.", "parent_ids": ["95fff9f4-77ac-44e1-8263-cb0eb07ff475"], "operator": null, "metadata": {}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "b20f7ae9-47c2-4ca8-b129-d648c1eb8524", "fitness": "-inf", "name": "EnhancedAntColonyOptimization", "description": "An enhanced Ant Colony Optimization with dynamic parameter adaptation, elitist strategy, and a gradient-based local search to refine solutions.", "code": "import numpy as np\n\nclass EnhancedAntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, colony_size=50, evaporation_rate=0.1, alpha=1.0, beta=2.0, local_search_iterations=5, q=1.0, elitism_factor=0.1):\n        \"\"\"\n        Initializes the Enhanced Ant Colony Optimization algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            colony_size (int): The number of ants in the colony.\n            evaporation_rate (float): The rate at which pheromone trails evaporate.\n            alpha (float): Influence of pheromone on decision making.\n            beta (float): Influence of heuristic information on decision making (not directly used).\n            local_search_iterations (int): Number of iterations for local search.\n            q (float): Parameter for pheromone update based on solution quality.\n            elitism_factor (float): Proportion of best ants to contribute to pheromone update.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.colony_size = colony_size\n        self.evaporation_rate = evaporation_rate\n        self.alpha = alpha\n        self.beta = beta  # Not directly used in current implementation but kept for potential future enhancements\n        self.local_search_iterations = local_search_iterations\n        self.pheromone = np.ones(dim) * 0.001  # Initialize pheromone trails for each dimension, with a small value to avoid division by zero\n        self.q = q\n        self.exploration_rate = 0.7  # Initial exploration rate, dynamically adjusted\n        self.elitism_factor = elitism_factor\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black box function using Enhanced Ant Colony Optimization.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        evaluations = 0\n\n        # Initialize ant positions randomly\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.colony_size, self.dim))\n        fitness = np.zeros(self.colony_size)\n\n        for i in range(self.colony_size):\n            fitness[i] = func(ants[i])\n            evaluations += 1\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = ants[i]\n\n            if evaluations >= self.budget:\n                return self.f_opt, self.x_opt\n\n        best_fitness_history = [self.f_opt]\n\n        while evaluations < self.budget:\n            # Construct solutions for each ant\n            new_ants = np.zeros((self.colony_size, self.dim))\n            new_fitness = np.zeros(self.colony_size)\n\n            for i in range(self.colony_size):\n                # Probabilistically select the next position based on pheromone\n                probabilities = (self.pheromone**self.alpha) / np.sum(self.pheromone**self.alpha)\n                # Exploration vs. Exploitation\n                if np.random.rand() < self.exploration_rate:\n                    movements = np.random.uniform(-1, 1, self.dim)  # Explore: Random movements\n                else:\n                    movements = np.random.normal(0, probabilities, self.dim)  # Exploit: Pheromone-guided movements\n\n                new_ant = ants[i] + movements\n                new_ant = np.clip(new_ant, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                f = func(new_ant)\n                evaluations += 1\n                new_ants[i] = new_ant\n                new_fitness[i] = f\n                \n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_ant\n\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n            # Gradient-based Local search around the best ant\n            for _ in range(self.local_search_iterations):\n                # Estimate gradient (simplified version)\n                gradient = np.zeros(self.dim)\n                delta = 1e-4  # Small perturbation\n                for j in range(self.dim):\n                    x_plus_delta = self.x_opt.copy()\n                    x_plus_delta[j] += delta\n                    x_plus_delta = np.clip(x_plus_delta, func.bounds.lb, func.bounds.ub)\n                    f_plus_delta = func(x_plus_delta)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        return self.f_opt, self.x_opt\n                    gradient[j] = (f_plus_delta - self.f_opt) / delta\n\n                # Move in the opposite direction of the gradient\n                learning_rate = 0.01\n                new_x = self.x_opt - learning_rate * gradient\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                f = func(new_x)\n                evaluations += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_x\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n            \n            # Elitist Pheromone Update: Select top ants to deposit pheromone\n            sorted_indices = np.argsort(new_fitness)\n            num_elites = int(self.colony_size * self.elitism_factor)\n            elite_indices = sorted_indices[:num_elites]\n\n            self.pheromone *= (1 - self.evaporation_rate)  # Evaporation\n            delta_pheromone = np.zeros(self.dim)\n            for i in elite_indices:\n                delta_pheromone += (self.q / (1 + abs(new_fitness[i] - self.f_opt))) * np.abs(new_ants[i] - self.x_opt)\n            self.pheromone += delta_pheromone\n\n            ants = new_ants.copy()\n            fitness = new_fitness.copy()\n\n            # Adaptive Exploration Rate Adjustment\n            best_fitness_history.append(self.f_opt)\n            if len(best_fitness_history) > 10:\n                if abs(best_fitness_history[-1] - best_fitness_history[-10]) < 1e-5:  #Stagnation detection\n                    self.exploration_rate = min(0.99, self.exploration_rate + 0.1)  # Increase exploration\n                else:\n                    self.exploration_rate = max(0.01, self.exploration_rate - 0.05)  # Decrease exploration if improving\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "Evaluation timed out after 600 seconds.", "error": "Evaluation timed out after 600 seconds.", "parent_ids": ["95fff9f4-77ac-44e1-8263-cb0eb07ff475"], "operator": null, "metadata": {}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "db8dad97-62be-4114-9e42-2459951fec45", "fitness": "-inf", "name": "EnhancedAntColonyOptimization", "description": "Population-based Ant Colony Optimization with dynamic parameter adaptation, local search based on fitness landscape analysis, and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass EnhancedAntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, colony_size=50, evaporation_rate=0.1, alpha=1.0, beta=2.0, local_search_iterations=5, q=1.0, restart_trigger=0.1):\n        \"\"\"\n        Initializes the Enhanced Ant Colony Optimization algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            colony_size (int): The number of ants in the colony.\n            evaporation_rate (float): The rate at which pheromone trails evaporate.\n            alpha (float): Influence of pheromone on decision making.\n            beta (float): Influence of heuristic information on decision making.\n            local_search_iterations (int): Number of iterations for local search.\n            q (float): Parameter for pheromone update based on solution quality.\n            restart_trigger (float): Threshold for triggering a population restart.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.colony_size = colony_size\n        self.evaporation_rate = evaporation_rate\n        self.alpha = alpha\n        self.beta = beta\n        self.local_search_iterations = local_search_iterations\n        self.pheromone = np.ones(dim)  # Initialize pheromone trails for each dimension\n        self.q = q\n        self.exploration_rate = 0.7  # Initial exploration rate, dynamically adjusted\n        self.restart_trigger = restart_trigger\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black box function using Enhanced Ant Colony Optimization.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        evaluations = 0\n\n        # Initialize ant positions randomly\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.colony_size, self.dim))\n        fitness = np.zeros(self.colony_size)\n\n        for i in range(self.colony_size):\n            fitness[i] = func(ants[i])\n            evaluations += 1\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = ants[i]\n\n            if evaluations >= self.budget:\n                return self.f_opt, self.x_opt\n\n        best_fitness_history = [self.f_opt]\n\n        while evaluations < self.budget:\n            # Construct solutions for each ant\n            for i in range(self.colony_size):\n                # Probabilistically select the next position based on pheromone and heuristic information\n                probabilities = (self.pheromone**self.alpha) / np.sum(self.pheromone**self.alpha)\n                # Exploration vs. Exploitation: Use exploration_rate to control random movement\n                if np.random.rand() < self.exploration_rate:\n                     movements = np.random.uniform(-1, 1, self.dim)  # Explore: Random movements\n                else:\n                     movements = np.random.normal(0, probabilities, self.dim)  # Exploit: Pheromone-guided movements\n                \n                new_ant = ants[i] + movements\n                new_ant = np.clip(new_ant, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                f = func(new_ant)\n                evaluations += 1\n                if f < fitness[i]:\n                    ants[i] = new_ant\n                    fitness[i] = f\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_ant\n\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n            # Local search around each ant\n            for i in range(self.colony_size):\n                for _ in range(self.local_search_iterations):\n                    # Sample a random dimension to perturb\n                    dim_index = np.random.randint(0, self.dim)\n                    # Perturb the ant's position in the chosen dimension using a small random step\n                    step_size = np.random.uniform(-0.1, 0.1)  # Adjust the step size as needed\n                    new_ant = ants[i].copy()\n                    new_ant[dim_index] += step_size\n                    new_ant = np.clip(new_ant, func.bounds.lb, func.bounds.ub)\n\n                    f = func(new_ant)\n                    evaluations += 1\n                    if f < fitness[i]:\n                        ants[i] = new_ant\n                        fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_ant\n\n                    if evaluations >= self.budget:\n                        return self.f_opt, self.x_opt\n            # Adaptive Pheromone Update\n            self.pheromone *= (1 - self.evaporation_rate)  # Evaporation\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.colony_size):\n                delta_pheromone += (self.q / (1 + abs(fitness[i] - self.f_opt))) * np.abs(ants[i] - self.x_opt) # deposit pheromone proportional to the improvement and closeness to the best. The quality of solution is now explicitly considered via the abs(fitness[i] - self.f_opt term)\n            self.pheromone += delta_pheromone\n\n            # Adaptive Exploration Rate Adjustment\n            best_fitness_history.append(self.f_opt)\n            if len(best_fitness_history) > 10:\n                if abs(best_fitness_history[-1] - best_fitness_history[-10]) < 1e-5:  #Stagnation detection\n                    self.exploration_rate = min(1.0, self.exploration_rate + 0.1)  # Increase exploration\n                    self.stagnation_counter +=1\n\n                else:\n                    self.exploration_rate = max(0.1, self.exploration_rate - 0.05)  # Decrease exploration if improving\n                    self.stagnation_counter = 0\n            \n            # Restart mechanism\n            if self.stagnation_counter > self.budget * self.restart_trigger:\n                # Reset ant positions randomly\n                ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.colony_size, self.dim))\n                fitness = np.zeros(self.colony_size)\n\n                for i in range(self.colony_size):\n                    fitness[i] = func(ants[i])\n                    evaluations += 1\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = ants[i]\n\n                    if evaluations >= self.budget:\n                        return self.f_opt, self.x_opt\n\n                self.pheromone = np.ones(self.dim)  # Reset pheromone trails\n                self.exploration_rate = 0.7  # Reset exploration rate\n                self.stagnation_counter = 0 # Reset counter\n\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "Evaluation timed out after 600 seconds.", "error": "Evaluation timed out after 600 seconds.", "parent_ids": ["95fff9f4-77ac-44e1-8263-cb0eb07ff475"], "operator": null, "metadata": {}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "fcadf0d3-8771-4a53-8782-e330512270d2", "fitness": "-inf", "name": "EnhancedAntColonyOptimization", "description": "An enhanced Ant Colony Optimization with dynamic parameter adaptation, Lévy flight exploration, and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass EnhancedAntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, colony_size=50, evaporation_rate=0.1, alpha=1.0, beta=2.0, local_search_iterations=5, q=1.0, levy_exponent=1.5):\n        \"\"\"\n        Initializes the Enhanced Ant Colony Optimization algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            colony_size (int): The number of ants in the colony.\n            evaporation_rate (float): The rate at which pheromone trails evaporate.\n            alpha (float): Influence of pheromone on decision making.\n            beta (float): Influence of heuristic information on decision making.\n            local_search_iterations (int): Number of iterations for local search.\n            q (float): Parameter for pheromone update based on solution quality.\n            levy_exponent (float): Exponent for Lévy flight distribution.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.colony_size = colony_size\n        self.evaporation_rate = evaporation_rate\n        self.alpha = alpha\n        self.beta = beta\n        self.local_search_iterations = local_search_iterations\n        self.pheromone = np.ones(dim)  # Initialize pheromone trails for each dimension\n        self.q = q\n        self.exploration_rate = 0.7  # Initial exploration rate, dynamically adjusted\n        self.levy_exponent = levy_exponent\n        self.restart_trigger = 20 # Number of iterations without improvement to trigger a restart.\n        self.stagnation_counter = 0\n\n    def levy_flight(self, size):\n        \"\"\"\n        Generates Lévy flight steps.\n\n        Args:\n            size (int or tuple): The size of the output.\n\n        Returns:\n            numpy.ndarray: An array of Lévy flight steps.\n        \"\"\"\n        u = np.random.randn(size)\n        v = np.random.randn(size)\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) / (np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * (2 ** ((self.levy_exponent - 1) / 2)))) ** (1 / self.levy_exponent)\n        step = sigma * u / (np.abs(v) ** (1 / self.levy_exponent))\n        return step\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black box function using Enhanced Ant Colony Optimization.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        evaluations = 0\n\n        # Initialize ant positions randomly\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.colony_size, self.dim))\n        fitness = np.zeros(self.colony_size)\n\n        for i in range(self.colony_size):\n            fitness[i] = func(ants[i])\n            evaluations += 1\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = ants[i]\n                self.stagnation_counter = 0 # Reset stagnation counter upon improvement\n\n            if evaluations >= self.budget:\n                return self.f_opt, self.x_opt\n\n        best_fitness_history = [self.f_opt]\n\n        while evaluations < self.budget:\n            # Construct solutions for each ant\n            for i in range(self.colony_size):\n                # Probabilistically select the next position based on pheromone and heuristic information\n                probabilities = (self.pheromone**self.alpha) / np.sum(self.pheromone**self.alpha)\n                # Exploration vs. Exploitation: Use exploration_rate to control random movement\n                if np.random.rand() < self.exploration_rate:\n                     movements = self.levy_flight(self.dim)  # Explore: Lévy flight movements\n                else:\n                     movements = np.random.normal(0, probabilities, self.dim)  # Exploit: Pheromone-guided movements\n                \n                new_ant = ants[i] + movements\n                new_ant = np.clip(new_ant, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                f = func(new_ant)\n                evaluations += 1\n                if f < fitness[i]:\n                    ants[i] = new_ant\n                    fitness[i] = f\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_ant\n                    self.stagnation_counter = 0 # Reset stagnation counter upon improvement\n\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n            # Cauchy mutation-based Local search around the best ant\n            for _ in range(self.local_search_iterations):\n                # Apply Cauchy mutation\n                cauchy_mutation = np.random.standard_cauchy(size=self.dim) * 0.05  # Scale Cauchy distribution\n                new_x = self.x_opt + cauchy_mutation\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                f = func(new_x)\n                evaluations += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_x\n                    self.stagnation_counter = 0 # Reset stagnation counter upon improvement\n\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n            # Adaptive Pheromone Update\n            self.pheromone *= (1 - self.evaporation_rate)  # Evaporation\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.colony_size):\n                delta_pheromone += (self.q / (1 + abs(fitness[i] - self.f_opt))) * np.abs(ants[i] - self.x_opt) # deposit pheromone proportional to the improvement and closeness to the best. The quality of solution is now explicitly considered via the abs(fitness[i] - self.f_opt term)\n            self.pheromone += delta_pheromone\n\n            # Adaptive Exploration Rate Adjustment\n            best_fitness_history.append(self.f_opt)\n            if len(best_fitness_history) > 10:\n                if abs(best_fitness_history[-1] - best_fitness_history[-10]) < 1e-5:  #Stagnation detection\n                    self.exploration_rate = min(1.0, self.exploration_rate + 0.1)  # Increase exploration\n                else:\n                    self.exploration_rate = max(0.1, self.exploration_rate - 0.05)  # Decrease exploration if improving\n\n            # Restart mechanism\n            self.stagnation_counter += 1\n            if self.stagnation_counter > self.restart_trigger:\n                # Reset ant positions randomly\n                ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.colony_size, self.dim))\n                fitness = np.zeros(self.colony_size)\n                for i in range(self.colony_size):\n                    fitness[i] = func(ants[i])\n                    evaluations += 1\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = ants[i]\n                self.stagnation_counter = 0\n                self.exploration_rate = 0.7 # Reset exploration rate\n                self.pheromone = np.ones(self.dim) # Reset pheromone trails\n\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "In the code, line 805, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'math'. Did you mean: 'emath'?", "error": "In the code, line 805, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'math'. Did you mean: 'emath'?", "parent_ids": ["95fff9f4-77ac-44e1-8263-cb0eb07ff475"], "operator": null, "metadata": {}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
