{"method_name": "LLaMEA-Baseline", "problem_name": "MA-BBOB-Comparison", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-Baseline", "budget": 10, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected algorithm to improve it."], "n_parents": 1, "n_offspring": 1, "elitism": true}}, "problem": {"name": "MA-BBOB-Comparison", "dims": [5], "training_instances": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "test_instances": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "95fff9f4-77ac-44e1-8263-cb0eb07ff475", "fitness": 0.3247126737743978, "name": "AdaptiveAntColonyOptimization", "description": "A modified Ant Colony Optimization with adaptive pheromone update, dynamic exploration-exploitation balance, and a Cauchy mutation-based local search.", "code": "import numpy as np\n\nclass AdaptiveAntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, colony_size=50, evaporation_rate=0.1, alpha=1.0, beta=2.0, local_search_iterations=5, q=1.0):\n        \"\"\"\n        Initializes the Adaptive Ant Colony Optimization algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            colony_size (int): The number of ants in the colony.\n            evaporation_rate (float): The rate at which pheromone trails evaporate.\n            alpha (float): Influence of pheromone on decision making.\n            beta (float): Influence of heuristic information on decision making.\n            local_search_iterations (int): Number of iterations for local search.\n            q (float): Parameter for pheromone update based on solution quality.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.colony_size = colony_size\n        self.evaporation_rate = evaporation_rate\n        self.alpha = alpha\n        self.beta = beta\n        self.local_search_iterations = local_search_iterations\n        self.pheromone = np.ones(dim)  # Initialize pheromone trails for each dimension\n        self.q = q\n        self.exploration_rate = 0.7  # Initial exploration rate, dynamically adjusted\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black box function using Adaptive Ant Colony Optimization.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        evaluations = 0\n\n        # Initialize ant positions randomly\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.colony_size, self.dim))\n        fitness = np.zeros(self.colony_size)\n\n        for i in range(self.colony_size):\n            fitness[i] = func(ants[i])\n            evaluations += 1\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = ants[i]\n\n            if evaluations >= self.budget:\n                return self.f_opt, self.x_opt\n\n        best_fitness_history = [self.f_opt]\n\n        while evaluations < self.budget:\n            # Construct solutions for each ant\n            for i in range(self.colony_size):\n                # Probabilistically select the next position based on pheromone and heuristic information\n                probabilities = (self.pheromone**self.alpha) / np.sum(self.pheromone**self.alpha)\n                # Exploration vs. Exploitation: Use exploration_rate to control random movement\n                if np.random.rand() < self.exploration_rate:\n                     movements = np.random.uniform(-1, 1, self.dim)  # Explore: Random movements\n                else:\n                     movements = np.random.normal(0, probabilities, self.dim)  # Exploit: Pheromone-guided movements\n                \n                new_ant = ants[i] + movements\n                new_ant = np.clip(new_ant, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                f = func(new_ant)\n                evaluations += 1\n                if f < fitness[i]:\n                    ants[i] = new_ant\n                    fitness[i] = f\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_ant\n\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n            # Cauchy mutation-based Local search around the best ant\n            for _ in range(self.local_search_iterations):\n                # Apply Cauchy mutation\n                cauchy_mutation = np.random.standard_cauchy(size=self.dim) * 0.05  # Scale Cauchy distribution\n                new_x = self.x_opt + cauchy_mutation\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                f = func(new_x)\n                evaluations += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_x\n                if evaluations >= self.budget:\n                    return self.f_opt, self.x_opt\n\n            # Adaptive Pheromone Update\n            self.pheromone *= (1 - self.evaporation_rate)  # Evaporation\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.colony_size):\n                delta_pheromone += (self.q / (1 + abs(fitness[i] - self.f_opt))) * np.abs(ants[i] - self.x_opt) # deposit pheromone proportional to the improvement and closeness to the best. The quality of solution is now explicitly considered via the abs(fitness[i] - self.f_opt term)\n            self.pheromone += delta_pheromone\n\n            # Adaptive Exploration Rate Adjustment\n            best_fitness_history.append(self.f_opt)\n            if len(best_fitness_history) > 10:\n                if abs(best_fitness_history[-1] - best_fitness_history[-10]) < 1e-5:  #Stagnation detection\n                    self.exploration_rate = min(1.0, self.exploration_rate + 0.1)  # Increase exploration\n                else:\n                    self.exploration_rate = max(0.1, self.exploration_rate - 0.05)  # Decrease exploration if improving\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveAntColonyOptimization scored 0.325 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["232c9c32-f930-478f-bf14-9c9cd0fb59f1"], "operator": null, "metadata": {"aucs": [0.15255209246850043, 0.22764732946693678, 0.3827120862471677, 0.546493145513276, 0.3436638444647053, 0.4165692373816592, 0.2798079428593091, 0.35608456779123365, 0.333793575599867, 0.20780291595132272]}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}, "log_dir": "run-LLaMEA-Baseline-MA-BBOB-Comparison-0", "seed": 0}
{"method_name": "GA-LLAMEA-0.9-0.2", "problem_name": "MA-BBOB-Comparison", "llm_name": "gemini-2.0-flash", "method": {"method_name": "GA-LLAMEA-0.9-0.2", "budget": 10, "n_parents": 4, "n_offspring": 8, "elitism": true, "bandit_state": {"mutation": {"count": 0.0, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": 0.006431886241860903, "pulls": 0}, "crossover": {"count": 2.439, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": -0.08725252805013398, "pulls": 3}, "random_new": {"count": 2.2465900000000003, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": 0.10676259281136276, "pulls": 3}}}, "problem": {"name": "MA-BBOB-Comparison", "dims": [5], "training_instances": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "test_instances": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "8ad06f06-d90c-4651-8a1f-6f13659b2931", "fitness": 0.0, "name": "AdaptiveDifferentialEvolutionLocalSearch", "description": "A population-based algorithm with adaptive exploration and exploitation, using a combination of differential evolution and local search.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, f=0.5, cr=0.7, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr # Crossover rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size # Update budget\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                mutant = np.clip(a + self.f * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.budget -= 1 # Update budget\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n            if self.budget <= 0:\n                break\n\n            # Local Search (applied to the best individual)\n            for _ in range(self.local_search_iterations):\n                # Generate a small perturbation around the best solution\n                perturbation = np.random.normal(0, 0.01, size=self.dim)  # Smaller step size\n                local_x = np.clip(self.x_opt + perturbation, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the perturbed solution\n                local_f = func(local_x)\n                self.budget -= 1 # Update budget\n                if self.budget <= 0:\n                    break\n\n                # Accept if it's better\n                if local_f < self.f_opt:\n                    self.f_opt = local_f\n                    self.x_opt = local_x.copy()\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A population-based algorithm with adaptive exploration and exploitation, using a combination of differential evolution and local search.\n\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, f=0.5, cr=0.7, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr # Crossover rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size # Update budget\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                mutant = np.clip(a + self.f * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.budget -= 1 # Update budget\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n            if self.budget <= 0:\n                break\n\n            # Local Search (applied to the best individual)\n            for _ in range(self.local_search_iterations):\n                # Generate a small perturbation around the best solution\n                perturbation = np.random.normal(0, 0.01, size=self.dim)  # Smaller step size\n                local_x = np.clip(self.x_opt + perturbation, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the perturbed solution\n                local_f = func(local_x)\n                self.budget -= 1 # Update budget\n                if self.budget <= 0:\n                    break\n\n                # Accept if it's better\n                if local_f < self.f_opt:\n                    self.f_opt = local_f\n                    self.x_opt = local_x.copy()\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt\n```", "generation": 0, "operator": "init"}, "task_prompt": ""}, "log_dir": "run-GA-LLAMEA-0.9-0.2-MA-BBOB-Comparison-0", "seed": 0}
