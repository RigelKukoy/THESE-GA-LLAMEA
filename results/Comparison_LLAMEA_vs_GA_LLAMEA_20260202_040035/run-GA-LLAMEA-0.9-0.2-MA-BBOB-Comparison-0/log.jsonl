{"id": "8ad06f06-d90c-4651-8a1f-6f13659b2931", "fitness": 0.7610501667276391, "name": "AdaptiveDifferentialEvolutionLocalSearch", "description": "A population-based algorithm with adaptive exploration and exploitation, using a combination of differential evolution and local search.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, f=0.5, cr=0.7, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr # Crossover rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size # Update budget\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                mutant = np.clip(a + self.f * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.budget -= 1 # Update budget\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n            if self.budget <= 0:\n                break\n\n            # Local Search (applied to the best individual)\n            for _ in range(self.local_search_iterations):\n                # Generate a small perturbation around the best solution\n                perturbation = np.random.normal(0, 0.01, size=self.dim)  # Smaller step size\n                local_x = np.clip(self.x_opt + perturbation, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the perturbed solution\n                local_f = func(local_x)\n                self.budget -= 1 # Update budget\n                if self.budget <= 0:\n                    break\n\n                # Accept if it's better\n                if local_f < self.f_opt:\n                    self.f_opt = local_f\n                    self.x_opt = local_x.copy()\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolutionLocalSearch scored 0.761 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A population-based algorithm with adaptive exploration and exploitation, using a combination of differential evolution and local search.\n\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, f=0.5, cr=0.7, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr # Crossover rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size # Update budget\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                mutant = np.clip(a + self.f * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.budget -= 1 # Update budget\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n            if self.budget <= 0:\n                break\n\n            # Local Search (applied to the best individual)\n            for _ in range(self.local_search_iterations):\n                # Generate a small perturbation around the best solution\n                perturbation = np.random.normal(0, 0.01, size=self.dim)  # Smaller step size\n                local_x = np.clip(self.x_opt + perturbation, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the perturbed solution\n                local_f = func(local_x)\n                self.budget -= 1 # Update budget\n                if self.budget <= 0:\n                    break\n\n                # Accept if it's better\n                if local_f < self.f_opt:\n                    self.f_opt = local_f\n                    self.x_opt = local_x.copy()\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt\n```", "generation": 0, "operator": "init", "aucs": [0.3357066249707935, 0.637867922444735, 0.8122621098342067, 0.9194795646001723, 0.8458709670212098, 0.8974899833312393, 0.7985955606394717, 0.7726374051874547, 0.8386384666406261, 0.7519530626064821]}, "task_prompt": ""}
{"id": "4aeeb7a2-79b1-49ab-b9f4-2bb454e1de87", "fitness": 0.2800749716041642, "name": "AdaptiveGaussianRestart", "description": "Population-based algorithm with Gaussian mutation and adaptive step size control, incorporating a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveGaussianRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=20, sigma_init=0.5, sigma_decay=0.99, restart_trigger=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sigma_init = sigma_init\n        self.sigma_decay = sigma_decay\n        self.restart_trigger = restart_trigger\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index].copy()\n        \n        sigma = self.sigma_init\n        no_improvement_count = 0\n        \n        while self.eval_count < self.budget:\n            # Mutation\n            mutation = np.random.normal(0, sigma, size=(self.pop_size, self.dim))\n            new_population = population + mutation\n            new_population = np.clip(new_population, self.lb, self.ub)\n            \n            new_fitness = np.array([func(x) for x in new_population])\n            self.eval_count += self.pop_size\n            \n            # Selection\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i].copy()\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                no_improvement_count = 0\n            else:\n                no_improvement_count += self.pop_size\n            \n            # Adaptive step size control\n            sigma *= self.sigma_decay\n            \n            # Restart mechanism\n            if no_improvement_count > self.restart_trigger:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.pop_size\n\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index].copy()\n                sigma = self.sigma_init\n                no_improvement_count = 0\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveGaussianRestart scored 0.280 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Population-based algorithm with Gaussian mutation and adaptive step size control, incorporating a restart mechanism to escape local optima.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveGaussianRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=20, sigma_init=0.5, sigma_decay=0.99, restart_trigger=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sigma_init = sigma_init\n        self.sigma_decay = sigma_decay\n        self.restart_trigger = restart_trigger\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index].copy()\n        \n        sigma = self.sigma_init\n        no_improvement_count = 0\n        \n        while self.eval_count < self.budget:\n            # Mutation\n            mutation = np.random.normal(0, sigma, size=(self.pop_size, self.dim))\n            new_population = population + mutation\n            new_population = np.clip(new_population, self.lb, self.ub)\n            \n            new_fitness = np.array([func(x) for x in new_population])\n            self.eval_count += self.pop_size\n            \n            # Selection\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i].copy()\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                no_improvement_count = 0\n            else:\n                no_improvement_count += self.pop_size\n            \n            # Adaptive step size control\n            sigma *= self.sigma_decay\n            \n            # Restart mechanism\n            if no_improvement_count > self.restart_trigger:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.pop_size\n\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index].copy()\n                sigma = self.sigma_init\n                no_improvement_count = 0\n        \n        return self.f_opt, self.x_opt\n```", "generation": 0, "operator": "init", "aucs": [0.12021119494710297, 0.21813757827802194, 0.37645236190260467, 0.45201344886108097, 0.23823238228212462, 0.3653088091023967, 0.2594606064052096, 0.3326626331427335, 0.2765535978512127, 0.161717103269154]}, "task_prompt": ""}
{"id": "fe8f3d17-54eb-476d-acc1-dd191fc1c831", "fitness": "-inf", "name": "SelfAdaptiveDifferentialEvolutionWithLocalSearch", "description": "A population-based algorithm employing a combination of differential evolution's mutation and crossover, with a self-adaptive learning rate and a local search component using Nelder-Mead Simplex for refinement.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SelfAdaptiveDifferentialEvolutionWithLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, local_search_iterations=5):\n        \"\"\"\n        Initialize the Self-Adaptive Differential Evolution with Local Search algorithm.\n\n        Args:\n            budget (int): The total budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The size of the population.\n            F (float): The mutation factor.\n            Cr (float): The crossover rate.\n            local_search_iterations (int): Number of Nelder-Mead iterations\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.local_search_iterations = local_search_iterations\n\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.eval_count += 1  # Increment the evaluation counter\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n    def mutate(self):\n        \"\"\"Perform differential evolution mutation.\"\"\"\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutated_population[i] = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        \"\"\"Perform binomial crossover.\"\"\"\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n        return crossed_population\n    \n    def repair(self, population, func):\n        \"\"\"Repair individuals to lie within bounds.\"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        for i in range(population.shape[0]):\n            population[i] = np.clip(population[i], lb, ub)\n        return population\n\n    def local_search(self, func, x0):\n        \"\"\"Perform local search using Nelder-Mead Simplex.\"\"\"\n        bounds = func.bounds\n        res = minimize(func, x0, method='Nelder-Mead', bounds=list(zip(bounds.lb, bounds.ub)), options={'maxiter': self.local_search_iterations})\n        return res.fun, res.x\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the black box function using Self-Adaptive Differential Evolution with Local Search.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.repair(crossed_population, func)\n\n            for i in range(self.pop_size):\n                f = func(crossed_population[i])\n                self.eval_count += 1\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = crossed_population[i]\n\n                    # Local search refinement\n                    f_local, x_local = self.local_search(func, self.population[i])\n                    self.eval_count += self.local_search_iterations  # Account for the local search evaluations\n\n                    if f_local < self.fitness[i]:\n                        self.fitness[i] = f_local\n                        self.population[i] = x_local\n\n\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.population[i]\n                \n                if self.eval_count >= self.budget:\n                    break  # Stop if budget is exceeded\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "Evaluation timed out after 600 seconds.", "error": "Evaluation timed out after 600 seconds.", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A population-based algorithm employing a combination of differential evolution's mutation and crossover, with a self-adaptive learning rate and a local search component using Nelder-Mead Simplex for refinement.\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass SelfAdaptiveDifferentialEvolutionWithLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, local_search_iterations=5):\n        \"\"\"\n        Initialize the Self-Adaptive Differential Evolution with Local Search algorithm.\n\n        Args:\n            budget (int): The total budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The size of the population.\n            F (float): The mutation factor.\n            Cr (float): The crossover rate.\n            local_search_iterations (int): Number of Nelder-Mead iterations\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.local_search_iterations = local_search_iterations\n\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population randomly.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.eval_count += 1  # Increment the evaluation counter\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n    def mutate(self):\n        \"\"\"Perform differential evolution mutation.\"\"\"\n        mutated_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutated_population[i] = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutated_population\n\n    def crossover(self, mutated_population):\n        \"\"\"Perform binomial crossover.\"\"\"\n        crossed_population = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    crossed_population[i, j] = mutated_population[i, j]\n                else:\n                    crossed_population[i, j] = self.population[i, j]\n        return crossed_population\n    \n    def repair(self, population, func):\n        \"\"\"Repair individuals to lie within bounds.\"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        for i in range(population.shape[0]):\n            population[i] = np.clip(population[i], lb, ub)\n        return population\n\n    def local_search(self, func, x0):\n        \"\"\"Perform local search using Nelder-Mead Simplex.\"\"\"\n        bounds = func.bounds\n        res = minimize(func, x0, method='Nelder-Mead', bounds=list(zip(bounds.lb, bounds.ub)), options={'maxiter': self.local_search_iterations})\n        return res.fun, res.x\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the black box function using Self-Adaptive Differential Evolution with Local Search.\n\n        Args:\n            func (callable): The black box function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutated_population = self.mutate()\n            crossed_population = self.crossover(mutated_population)\n            crossed_population = self.repair(crossed_population, func)\n\n            for i in range(self.pop_size):\n                f = func(crossed_population[i])\n                self.eval_count += 1\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = crossed_population[i]\n\n                    # Local search refinement\n                    f_local, x_local = self.local_search(func, self.population[i])\n                    self.eval_count += self.local_search_iterations  # Account for the local search evaluations\n\n                    if f_local < self.fitness[i]:\n                        self.fitness[i] = f_local\n                        self.population[i] = x_local\n\n\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.population[i]\n                \n                if self.eval_count >= self.budget:\n                    break  # Stop if budget is exceeded\n\n        return self.f_opt, self.x_opt\n```", "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "1a9f947d-ea11-4ada-b4fd-f9491b022094", "fitness": 0.6157296376320608, "name": "AdaptiveSelfOrganizingDE", "description": "An adaptive differential evolution strategy with a population that self-organizes based on success rates.", "code": "import numpy as np\n\nclass AdaptiveSelfOrganizingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim  # Adaptive population size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.archive_size = int(self.pop_size * 0.2)  # Archive size (20% of population)\n        self.archive = []\n        self.success_rates = np.ones(self.pop_size) / self.pop_size  # Initialize success rates equally\n        self.learning_rate = 0.1 #Learning rate for success rates\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size  # initial population evaluation\n\n        while self.eval_count < self.budget:\n            # Selection based on success rates: roulettewheel\n            probabilities = self.success_rates / np.sum(self.success_rates)\n            indices = np.random.choice(self.pop_size, size=self.pop_size, replace=True, p=probabilities)\n            \n            for i in range(self.pop_size):\n                \n                # Ensure distinct indices for mutation\n                indices_mutation = np.random.choice(self.pop_size, size=3, replace=False)\n\n                x_1, x_2, x_3 = self.population[indices_mutation]\n\n                # Mutation\n                v = x_1 + self.F * (x_2 - x_3)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u = np.array([v[j] if (np.random.rand() < self.CR or j == j_rand) else self.population[i, j] for j in range(self.dim)])\n\n\n                f_u = func(u)\n                self.eval_count += 1\n\n                if f_u < self.fitness[i]:\n                    # Update success rates\n                    self.success_rates[i] = (1 - self.learning_rate) * self.success_rates[i] + self.learning_rate\n                    \n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Decrease success rates\n                     self.success_rates[i] = (1 - self.learning_rate) * self.success_rates[i]\n\n                if self.eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSelfOrganizingDE scored 0.616 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An adaptive differential evolution strategy with a population that self-organizes based on success rates.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveSelfOrganizingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim  # Adaptive population size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.archive_size = int(self.pop_size * 0.2)  # Archive size (20% of population)\n        self.archive = []\n        self.success_rates = np.ones(self.pop_size) / self.pop_size  # Initialize success rates equally\n        self.learning_rate = 0.1 #Learning rate for success rates\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size  # initial population evaluation\n\n        while self.eval_count < self.budget:\n            # Selection based on success rates: roulettewheel\n            probabilities = self.success_rates / np.sum(self.success_rates)\n            indices = np.random.choice(self.pop_size, size=self.pop_size, replace=True, p=probabilities)\n            \n            for i in range(self.pop_size):\n                \n                # Ensure distinct indices for mutation\n                indices_mutation = np.random.choice(self.pop_size, size=3, replace=False)\n\n                x_1, x_2, x_3 = self.population[indices_mutation]\n\n                # Mutation\n                v = x_1 + self.F * (x_2 - x_3)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u = np.array([v[j] if (np.random.rand() < self.CR or j == j_rand) else self.population[i, j] for j in range(self.dim)])\n\n\n                f_u = func(u)\n                self.eval_count += 1\n\n                if f_u < self.fitness[i]:\n                    # Update success rates\n                    self.success_rates[i] = (1 - self.learning_rate) * self.success_rates[i] + self.learning_rate\n                    \n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                else:\n                    # Decrease success rates\n                     self.success_rates[i] = (1 - self.learning_rate) * self.success_rates[i]\n\n                if self.eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "generation": 0, "operator": "init", "aucs": [0.2246642594685352, 0.5208358375858604, 0.5963149301767539, 0.8472564759196355, 0.7093071560483828, 0.7645728309218441, 0.5826027870403894, 0.613113435578216, 0.697485590134128, 0.6011430734468635]}, "task_prompt": ""}
{"id": "832c2c9e-ef24-4d88-a53a-489f1470738b", "fitness": "-inf", "name": "CMA_ESOS", "description": "Covariance Matrix Adaptation Evolution Strategy with Orthogonal Sampling (CMA-ESOS) enhances exploration by generating offspring using orthogonal sampling in the eigenspace of the covariance matrix.", "code": "import numpy as np\nfrom numpy.linalg import eig, norm\n\nclass CMA_ESOS:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=None, c_cov=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = None\n        self.sigma = 0.5\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n\n        self.cs = cs\n        self.damp = damp if damp is not None else 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.cs\n        self.c_cov = c_cov if c_cov is not None else 2 / ((self.dim + np.sqrt(2))**2 + self.mu)\n        self.c_cov_mu = self.c_cov\n        self.c_cov_mu = min(1, self.c_cov_mu * (self.mu / (np.sum(self.weights**2))))\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n        while self.eval_count < self.budget:\n            # Generate orthogonal sample matrix\n            z = np.random.randn(self.dim, self.popsize)\n            Q, R = np.linalg.qr(z)  # Orthogonalize the samples\n            x = self.m + self.sigma * np.dot(self.C**(1/2), Q)\n            \n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            f = np.array([func(xi) for xi in x.T])\n            self.eval_count += self.popsize\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[:, np.argmin(f)]\n\n            # Sort by fitness\n            idx = np.argsort(f)\n            x_sorted = x[:, idx]\n\n            # Update mean\n            x_mu = x_sorted[:, :self.mu]\n            y = (x_mu - self.m) / self.sigma\n            self.m += self.sigma * np.sum(self.weights * y, axis=1)\n\n            # Update evolution path\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * np.sum(self.weights * y, axis=1)\n            \n            # Update covariance matrix\n            rank_one = self.c_cov * np.outer(self.ps, self.ps)\n            rank_mu = self.c_cov_mu * np.dot(y, np.diag(self.weights)).dot(y.T)\n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + rank_one + rank_mu\n\n            # Ensure C is positive definite\n            try:\n                eigvals = np.linalg.eigvalsh(self.C)\n                if np.any(eigvals < 0):\n                    self.C += (np.abs(np.min(eigvals)) + 1e-9) * np.eye(self.dim)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)  # Reset if singular\n            \n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damp) * (norm(self.ps) / np.sqrt(self.dim) - 1))\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 52, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (3,) (2,2) \nOn line: self.m += self.sigma * np.sum(self.weights * y, axis=1)", "error": "In the code, line 52, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (3,) (2,2) \nOn line: self.m += self.sigma * np.sum(self.weights * y, axis=1)", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Covariance Matrix Adaptation Evolution Strategy with Orthogonal Sampling (CMA-ESOS) enhances exploration by generating offspring using orthogonal sampling in the eigenspace of the covariance matrix.\n# Code: \n```python\nimport numpy as np\nfrom numpy.linalg import eig, norm\n\nclass CMA_ESOS:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damp=None, c_cov=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = None\n        self.sigma = 0.5\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n\n        self.cs = cs\n        self.damp = damp if damp is not None else 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.cs\n        self.c_cov = c_cov if c_cov is not None else 2 / ((self.dim + np.sqrt(2))**2 + self.mu)\n        self.c_cov_mu = self.c_cov\n        self.c_cov_mu = min(1, self.c_cov_mu * (self.mu / (np.sum(self.weights**2))))\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n        while self.eval_count < self.budget:\n            # Generate orthogonal sample matrix\n            z = np.random.randn(self.dim, self.popsize)\n            Q, R = np.linalg.qr(z)  # Orthogonalize the samples\n            x = self.m + self.sigma * np.dot(self.C**(1/2), Q)\n            \n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            f = np.array([func(xi) for xi in x.T])\n            self.eval_count += self.popsize\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[:, np.argmin(f)]\n\n            # Sort by fitness\n            idx = np.argsort(f)\n            x_sorted = x[:, idx]\n\n            # Update mean\n            x_mu = x_sorted[:, :self.mu]\n            y = (x_mu - self.m) / self.sigma\n            self.m += self.sigma * np.sum(self.weights * y, axis=1)\n\n            # Update evolution path\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * np.sum(self.weights * y, axis=1)\n            \n            # Update covariance matrix\n            rank_one = self.c_cov * np.outer(self.ps, self.ps)\n            rank_mu = self.c_cov_mu * np.dot(y, np.diag(self.weights)).dot(y.T)\n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + rank_one + rank_mu\n\n            # Ensure C is positive definite\n            try:\n                eigvals = np.linalg.eigvalsh(self.C)\n                if np.any(eigvals < 0):\n                    self.C += (np.abs(np.min(eigvals)) + 1e-9) * np.eye(self.dim)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)  # Reset if singular\n            \n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damp) * (norm(self.ps) / np.sqrt(self.dim) - 1))\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.18754340523674368, "generation": 1}, "task_prompt": ""}
{"id": "8eaecbd9-48bd-4276-a60a-1e597dd8f8ec", "fitness": 0.0, "name": "GradientFreeBFGS", "description": "A gradient-free optimization algorithm that combines a simplified version of the BFGS update with random restarts and adaptive step size control.", "code": "import numpy as np\n\nclass GradientFreeBFGS:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        H = np.eye(self.dim)  # Approximate inverse Hessian\n        step_size = self.initial_step_size\n        \n        f_current = func(x)\n        self.budget -= 1\n        \n        if f_current < self.f_opt:\n            self.f_opt = f_current\n            self.x_opt = x\n        \n        for i in range(self.budget):\n            # Compute search direction\n            direction = -H @ self.approximate_gradient(func, x, step_size)\n            \n            # Line search (simplified: fixed step size)\n            x_new = x + step_size * direction\n            \n            # Check bounds\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(x_new)\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n            \n            # BFGS update (simplified)\n            s = x_new - x\n            y = self.approximate_gradient(func, x_new, step_size) - self.approximate_gradient(func, x, step_size)\n            \n            if s @ y > 0:  # Ensure positive curvature\n                rho = 1.0 / (s @ y)\n                H = (np.eye(self.dim) - rho * np.outer(s, y)) @ H @ (np.eye(self.dim) - rho * np.outer(y, s)) + rho * np.outer(s, s)\n            \n            # Update variables\n            x = x_new\n            f_current = f_new\n            \n            # Adaptive step size\n            if f_new < f_current:\n                step_size *= 1.1\n            else:\n                step_size *= 0.9\n\n            # Restart with probability\n            if np.random.rand() < self.restart_prob:\n                x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                H = np.eye(self.dim)\n                step_size = self.initial_step_size\n                f_current = func(x)\n                if f_current < self.f_opt:\n                    self.f_opt = f_current\n                    self.x_opt = x\n        \n        return self.f_opt, self.x_opt\n\n    def approximate_gradient(self, func, x, step_size):\n        grad = np.zeros_like(x)\n        for i in range(self.dim):\n            x_plus = x.copy()\n            x_minus = x.copy()\n            x_plus[i] += step_size\n            x_minus[i] -= step_size\n            x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n            x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n            grad[i] = (func(x_plus) - func(x_minus)) / (2 * step_size)\n        return grad", "configspace": "", "generation": 0, "feedback": "The algorithm GradientFreeBFGS scored 0.000 on AOCC (higher is better, 1.0 is the best). The algorithm exhausted the budget. Ensure you stop optimization when budget is 0.", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A gradient-free optimization algorithm that combines a simplified version of the BFGS update with random restarts and adaptive step size control.\n# Code: \n```python\nimport numpy as np\n\nclass GradientFreeBFGS:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        H = np.eye(self.dim)  # Approximate inverse Hessian\n        step_size = self.initial_step_size\n        \n        f_current = func(x)\n        self.budget -= 1\n        \n        if f_current < self.f_opt:\n            self.f_opt = f_current\n            self.x_opt = x\n        \n        for i in range(self.budget):\n            # Compute search direction\n            direction = -H @ self.approximate_gradient(func, x, step_size)\n            \n            # Line search (simplified: fixed step size)\n            x_new = x + step_size * direction\n            \n            # Check bounds\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(x_new)\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n            \n            # BFGS update (simplified)\n            s = x_new - x\n            y = self.approximate_gradient(func, x_new, step_size) - self.approximate_gradient(func, x, step_size)\n            \n            if s @ y > 0:  # Ensure positive curvature\n                rho = 1.0 / (s @ y)\n                H = (np.eye(self.dim) - rho * np.outer(s, y)) @ H @ (np.eye(self.dim) - rho * np.outer(y, s)) + rho * np.outer(s, s)\n            \n            # Update variables\n            x = x_new\n            f_current = f_new\n            \n            # Adaptive step size\n            if f_new < f_current:\n                step_size *= 1.1\n            else:\n                step_size *= 0.9\n\n            # Restart with probability\n            if np.random.rand() < self.restart_prob:\n                x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                H = np.eye(self.dim)\n                step_size = self.initial_step_size\n                f_current = func(x)\n                if f_current < self.f_opt:\n                    self.f_opt = f_current\n                    self.x_opt = x\n        \n        return self.f_opt, self.x_opt\n\n    def approximate_gradient(self, func, x, step_size):\n        grad = np.zeros_like(x)\n        for i in range(self.dim):\n            x_plus = x.copy()\n            x_minus = x.copy()\n            x_plus[i] += step_size\n            x_minus[i] -= step_size\n            x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n            x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n            grad[i] = (func(x_plus) - func(x_minus)) / (2 * step_size)\n        return grad\n```", "operator": "random_new", "theta_sampled": 0.2746936468961806, "generation": 1, "aucs": [0]}, "task_prompt": ""}
{"id": "64f65ba2-7935-4bcc-8a9e-022fecf4addf", "fitness": "-inf", "name": "HybridDEGaussianRestart", "description": "Combines Adaptive Differential Evolution with Local Search and Adaptive Gaussian Restart, using self-adaptive parameters and dynamic allocation of budget to DE, local search, and restarts.", "code": "import numpy as np\n\nclass HybridDEGaussianRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=20, f_init=0.5, cr_init=0.7, sigma_init=0.5, sigma_decay=0.99, local_search_iterations=5, restart_trigger=500, ls_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f_init  # Differential weight\n        self.cr = cr_init # Crossover rate\n        self.sigma_init = sigma_init\n        self.sigma_decay = sigma_decay\n        self.local_search_iterations = local_search_iterations\n        self.restart_trigger = restart_trigger\n        self.lb = -5.0\n        self.ub = 5.0\n        self.ls_prob = ls_prob  # Probability of local search\n\n        self.f_history = []\n        self.cr_history = []\n        self.sigma_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        \n        # Initialize population within bounds\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        sigma = self.sigma_init\n        no_improvement_count = 0\n\n        while self.eval_count < self.budget:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                mutant = np.clip(a + self.f * (b - c), self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.eval_count += 1\n                if self.eval_count >= self.budget:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                        no_improvement_count = 0\n                    \n                    # Update F and CR adaptively (simple average of successful values)\n                    self.f = 0.9 * self.f + 0.1 * np.random.normal(0.5, 0.1)\n                    self.cr = 0.9 * self.cr + 0.1 * np.random.normal(0.7, 0.1)\n                    self.f = np.clip(self.f, 0.1, 0.9)\n                    self.cr = np.clip(self.cr, 0.1, 0.9)\n\n            # Local Search (applied to the best individual with probability)\n            if np.random.rand() < self.ls_prob and self.eval_count < self.budget:\n                for _ in range(self.local_search_iterations):\n                    if self.eval_count >= self.budget:\n                        break\n                    # Generate a small perturbation around the best solution\n                    perturbation = np.random.normal(0, 0.01, size=self.dim)  # Smaller step size\n                    local_x = np.clip(self.x_opt + perturbation, self.lb, self.ub)\n\n                    # Evaluate the perturbed solution\n                    local_f = func(local_x)\n                    self.eval_count += 1\n                    if self.eval_count >= self.budget:\n                        break\n\n                    # Accept if it's better\n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_x.copy()\n                        no_improvement_count = 0\n            \n            # Adaptive step size control\n            sigma *= self.sigma_decay\n            \n            # Restart mechanism\n            no_improvement_count += self.pop_size\n            if no_improvement_count > self.restart_trigger and self.eval_count < self.budget:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.pop_size\n\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index].copy()\n                    no_improvement_count = 0\n                sigma = self.sigma_init\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "Evaluation timed out after 600 seconds.", "error": "Evaluation timed out after 600 seconds.", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Combines Adaptive Differential Evolution with Local Search and Adaptive Gaussian Restart, using self-adaptive parameters and dynamic allocation of budget to DE, local search, and restarts.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEGaussianRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=20, f_init=0.5, cr_init=0.7, sigma_init=0.5, sigma_decay=0.99, local_search_iterations=5, restart_trigger=500, ls_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f_init  # Differential weight\n        self.cr = cr_init # Crossover rate\n        self.sigma_init = sigma_init\n        self.sigma_decay = sigma_decay\n        self.local_search_iterations = local_search_iterations\n        self.restart_trigger = restart_trigger\n        self.lb = -5.0\n        self.ub = 5.0\n        self.ls_prob = ls_prob  # Probability of local search\n\n        self.f_history = []\n        self.cr_history = []\n        self.sigma_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        \n        # Initialize population within bounds\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        sigma = self.sigma_init\n        no_improvement_count = 0\n\n        while self.eval_count < self.budget:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                mutant = np.clip(a + self.f * (b - c), self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.eval_count += 1\n                if self.eval_count >= self.budget:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                        no_improvement_count = 0\n                    \n                    # Update F and CR adaptively (simple average of successful values)\n                    self.f = 0.9 * self.f + 0.1 * np.random.normal(0.5, 0.1)\n                    self.cr = 0.9 * self.cr + 0.1 * np.random.normal(0.7, 0.1)\n                    self.f = np.clip(self.f, 0.1, 0.9)\n                    self.cr = np.clip(self.cr, 0.1, 0.9)\n\n            # Local Search (applied to the best individual with probability)\n            if np.random.rand() < self.ls_prob and self.eval_count < self.budget:\n                for _ in range(self.local_search_iterations):\n                    if self.eval_count >= self.budget:\n                        break\n                    # Generate a small perturbation around the best solution\n                    perturbation = np.random.normal(0, 0.01, size=self.dim)  # Smaller step size\n                    local_x = np.clip(self.x_opt + perturbation, self.lb, self.ub)\n\n                    # Evaluate the perturbed solution\n                    local_f = func(local_x)\n                    self.eval_count += 1\n                    if self.eval_count >= self.budget:\n                        break\n\n                    # Accept if it's better\n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_x.copy()\n                        no_improvement_count = 0\n            \n            # Adaptive step size control\n            sigma *= self.sigma_decay\n            \n            # Restart mechanism\n            no_improvement_count += self.pop_size\n            if no_improvement_count > self.restart_trigger and self.eval_count < self.budget:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.pop_size\n\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index].copy()\n                    no_improvement_count = 0\n                sigma = self.sigma_init\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.3970213230354055, "generation": 1}, "task_prompt": ""}
{"id": "889eb514-3ab7-402c-93be-3342fd519e23", "fitness": "-inf", "name": "HybridDEGaussianRestart", "description": "Combines Adaptive Differential Evolution with Local Search and Adaptive Gaussian Restart for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEGaussianRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=20, f=0.5, cr=0.7, local_search_iterations=5,\n                 sigma_init=0.5, sigma_decay=0.99, restart_trigger=500, ls_probability=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr # Crossover rate\n        self.local_search_iterations = local_search_iterations\n        self.sigma_init = sigma_init\n        self.sigma_decay = sigma_decay\n        self.restart_trigger = restart_trigger\n        self.lb = -5.0\n        self.ub = 5.0\n        self.ls_probability = ls_probability # Probability of applying local search\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        \n        # Initialize population within bounds\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        sigma = self.sigma_init\n        no_improvement_count = 0\n        generation = 0\n        \n        while self.eval_count < self.budget:\n            generation += 1\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                mutant = np.clip(a + self.f * (b - c), self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.eval_count += 1\n                if self.eval_count >= self.budget:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                        no_improvement_count = 0 #reset no improvement count\n                \n            if self.eval_count >= self.budget:\n                break\n\n            # Local Search (applied to the best individual with a probability)\n            if np.random.rand() < self.ls_probability:\n                for _ in range(self.local_search_iterations):\n                    # Generate a small perturbation around the best solution\n                    perturbation = np.random.normal(0, 0.01, size=self.dim)  # Smaller step size\n                    local_x = np.clip(self.x_opt + perturbation, self.lb, self.ub)\n\n                    # Evaluate the perturbed solution\n                    local_f = func(local_x)\n                    self.eval_count += 1\n                    if self.eval_count >= self.budget:\n                        break\n\n                    # Accept if it's better\n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_x.copy()\n                        no_improvement_count = 0 #reset no improvement count\n                        \n                if self.eval_count >= self.budget:\n                    break\n\n\n            # Adaptive step size control (Gaussian Perturbation) and selection\n            mutation = np.random.normal(0, sigma, size=(self.pop_size, self.dim))\n            new_population = population + mutation\n            new_population = np.clip(new_population, self.lb, self.ub)\n            \n            new_fitness = np.array([func(x) for x in new_population])\n            self.eval_count += self.pop_size\n            \n            # Selection between DE mutated population and Gaussian mutated population\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i].copy()\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                no_improvement_count = 0\n            else:\n                no_improvement_count += self.pop_size\n            \n            # Adaptive step size control\n            sigma *= self.sigma_decay\n            \n            # Restart mechanism\n            if no_improvement_count > self.restart_trigger:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.pop_size\n\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index].copy()\n                sigma = self.sigma_init\n                no_improvement_count = 0\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "Evaluation timed out after 600 seconds.", "error": "Evaluation timed out after 600 seconds.", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Combines Adaptive Differential Evolution with Local Search and Adaptive Gaussian Restart for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEGaussianRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=20, f=0.5, cr=0.7, local_search_iterations=5,\n                 sigma_init=0.5, sigma_decay=0.99, restart_trigger=500, ls_probability=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr # Crossover rate\n        self.local_search_iterations = local_search_iterations\n        self.sigma_init = sigma_init\n        self.sigma_decay = sigma_decay\n        self.restart_trigger = restart_trigger\n        self.lb = -5.0\n        self.ub = 5.0\n        self.ls_probability = ls_probability # Probability of applying local search\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        \n        # Initialize population within bounds\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        sigma = self.sigma_init\n        no_improvement_count = 0\n        generation = 0\n        \n        while self.eval_count < self.budget:\n            generation += 1\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                mutant = np.clip(a + self.f * (b - c), self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.eval_count += 1\n                if self.eval_count >= self.budget:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                        no_improvement_count = 0 #reset no improvement count\n                \n            if self.eval_count >= self.budget:\n                break\n\n            # Local Search (applied to the best individual with a probability)\n            if np.random.rand() < self.ls_probability:\n                for _ in range(self.local_search_iterations):\n                    # Generate a small perturbation around the best solution\n                    perturbation = np.random.normal(0, 0.01, size=self.dim)  # Smaller step size\n                    local_x = np.clip(self.x_opt + perturbation, self.lb, self.ub)\n\n                    # Evaluate the perturbed solution\n                    local_f = func(local_x)\n                    self.eval_count += 1\n                    if self.eval_count >= self.budget:\n                        break\n\n                    # Accept if it's better\n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_x.copy()\n                        no_improvement_count = 0 #reset no improvement count\n                        \n                if self.eval_count >= self.budget:\n                    break\n\n\n            # Adaptive step size control (Gaussian Perturbation) and selection\n            mutation = np.random.normal(0, sigma, size=(self.pop_size, self.dim))\n            new_population = population + mutation\n            new_population = np.clip(new_population, self.lb, self.ub)\n            \n            new_fitness = np.array([func(x) for x in new_population])\n            self.eval_count += self.pop_size\n            \n            # Selection between DE mutated population and Gaussian mutated population\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i].copy()\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                no_improvement_count = 0\n            else:\n                no_improvement_count += self.pop_size\n            \n            # Adaptive step size control\n            sigma *= self.sigma_decay\n            \n            # Restart mechanism\n            if no_improvement_count > self.restart_trigger:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.pop_size\n\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index].copy()\n                sigma = self.sigma_init\n                no_improvement_count = 0\n            \n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.18861677379716957, "generation": 1}, "task_prompt": ""}
{"id": "4b775556-a6ab-4771-95fb-e57d7ce382bb", "fitness": "-inf", "name": "HybridDEGaussianRestart", "description": "Combines Adaptive Differential Evolution with Local Search and Adaptive Gaussian Restart for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEGaussianRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=20, f=0.5, cr=0.7, local_search_iterations=3, sigma_init=0.5, sigma_decay=0.99, restart_trigger=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.local_search_iterations = local_search_iterations\n        self.sigma_init = sigma_init\n        self.sigma_decay = sigma_decay\n        self.restart_trigger = restart_trigger\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        sigma = self.sigma_init\n        no_improvement_count = 0\n\n        while self.eval_count < self.budget:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                mutant = np.clip(a + self.f * (b - c), self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.eval_count += 1\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                        no_improvement_count = 0 # Reset no_improvement_count\n\n            # Local Search (applied to the best individual)\n            for _ in range(self.local_search_iterations):\n                perturbation = np.random.normal(0, 0.01, size=self.dim)\n                local_x = np.clip(self.x_opt + perturbation, self.lb, self.ub)\n\n                local_f = func(local_x)\n                self.eval_count += 1\n\n                if local_f < self.f_opt:\n                    self.f_opt = local_f\n                    self.x_opt = local_x.copy()\n                    no_improvement_count = 0  # Reset no_improvement_count\n\n            # Adaptive Gaussian Mutation (applied to the population)\n            mutation = np.random.normal(0, sigma, size=(self.pop_size, self.dim))\n            new_population = population + mutation\n            new_population = np.clip(new_population, self.lb, self.ub)\n\n            new_fitness = np.array([func(x) for x in new_population])\n            self.eval_count += self.pop_size\n\n            # Selection for Gaussian Mutation\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i].copy()\n            \n            # Update best solution after Gaussian Mutation\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                no_improvement_count = 0 # Reset no_improvement_count\n            else:\n                no_improvement_count += self.pop_size\n            \n            # Adaptive step size control\n            sigma *= self.sigma_decay\n\n            # Restart mechanism\n            if no_improvement_count > self.restart_trigger:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.pop_size\n\n                best_index = np.argmin(fitness)\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                sigma = self.sigma_init\n                no_improvement_count = 0\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "Evaluation timed out after 600 seconds.", "error": "Evaluation timed out after 600 seconds.", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Combines Adaptive Differential Evolution with Local Search and Adaptive Gaussian Restart for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEGaussianRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=20, f=0.5, cr=0.7, local_search_iterations=3, sigma_init=0.5, sigma_decay=0.99, restart_trigger=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.local_search_iterations = local_search_iterations\n        self.sigma_init = sigma_init\n        self.sigma_decay = sigma_decay\n        self.restart_trigger = restart_trigger\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        sigma = self.sigma_init\n        no_improvement_count = 0\n\n        while self.eval_count < self.budget:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                mutant = np.clip(a + self.f * (b - c), self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.eval_count += 1\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                        no_improvement_count = 0 # Reset no_improvement_count\n\n            # Local Search (applied to the best individual)\n            for _ in range(self.local_search_iterations):\n                perturbation = np.random.normal(0, 0.01, size=self.dim)\n                local_x = np.clip(self.x_opt + perturbation, self.lb, self.ub)\n\n                local_f = func(local_x)\n                self.eval_count += 1\n\n                if local_f < self.f_opt:\n                    self.f_opt = local_f\n                    self.x_opt = local_x.copy()\n                    no_improvement_count = 0  # Reset no_improvement_count\n\n            # Adaptive Gaussian Mutation (applied to the population)\n            mutation = np.random.normal(0, sigma, size=(self.pop_size, self.dim))\n            new_population = population + mutation\n            new_population = np.clip(new_population, self.lb, self.ub)\n\n            new_fitness = np.array([func(x) for x in new_population])\n            self.eval_count += self.pop_size\n\n            # Selection for Gaussian Mutation\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i].copy()\n            \n            # Update best solution after Gaussian Mutation\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                no_improvement_count = 0 # Reset no_improvement_count\n            else:\n                no_improvement_count += self.pop_size\n            \n            # Adaptive step size control\n            sigma *= self.sigma_decay\n\n            # Restart mechanism\n            if no_improvement_count > self.restart_trigger:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.pop_size\n\n                best_index = np.argmin(fitness)\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                sigma = self.sigma_init\n                no_improvement_count = 0\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.12871850621862765, "generation": 1}, "task_prompt": ""}
{"id": "29652e57-cac6-47b6-99ab-ef0592f38946", "fitness": 0.0, "name": "AdaptiveSimplexSearch", "description": "A gradient-free optimization algorithm that combines a simplex-based search with adaptive shrinking and expansion based on success rates and a random mutation to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveSimplexSearch:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.simplex_size = initial_simplex_size\n        self.alpha = 1.0  # Reflection\n        self.beta = 0.5   # Contraction\n        self.gamma = 2.0  # Expansion\n        self.mutation_rate = 0.05 # Probability of mutation\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize simplex randomly\n        simplex = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim + 1, self.dim))\n        values = np.array([func(simplex[i]) for i in range(self.dim + 1)])\n        \n        eval_count = self.dim + 1\n\n        while eval_count < self.budget:\n            # 1. Order\n            order = np.argsort(values)\n            best_idx = order[0]\n            worst_idx = order[-1]\n\n            # 2. Centroid\n            centroid = np.mean(simplex[order[:-1]], axis=0)\n\n            # 3. Reflection\n            x_r = centroid + self.alpha * (centroid - simplex[worst_idx])\n            x_r = np.clip(x_r, func.bounds.lb, func.bounds.ub)\n            f_r = func(x_r)\n            eval_count += 1\n\n            if f_r < values[best_idx]:\n                # 4. Expansion\n                x_e = centroid + self.gamma * (x_r - centroid)\n                x_e = np.clip(x_e, func.bounds.lb, func.bounds.ub)\n                f_e = func(x_e)\n                eval_count += 1\n                if f_e < f_r:\n                    simplex[worst_idx] = x_e\n                    values[worst_idx] = f_e\n                else:\n                    simplex[worst_idx] = x_r\n                    values[worst_idx] = f_r\n            elif f_r < values[order[-2]]:\n                simplex[worst_idx] = x_r\n                values[worst_idx] = f_r\n            else:\n                # 5. Contraction\n                x_c = centroid + self.beta * (simplex[worst_idx] - centroid)\n                x_c = np.clip(x_c, func.bounds.lb, func.bounds.ub)\n                f_c = func(x_c)\n                eval_count += 1\n                if f_c < values[worst_idx]:\n                    simplex[worst_idx] = x_c\n                    values[worst_idx] = f_c\n                else:\n                    # 6. Shrink\n                    for i in range(self.dim + 1):\n                        if i != best_idx:\n                            simplex[i] = simplex[best_idx] + 0.5 * (simplex[i] - simplex[best_idx])\n                            simplex[i] = np.clip(simplex[i], func.bounds.lb, func.bounds.ub)\n                            values[i] = func(simplex[i])\n                            eval_count += 1\n\n            # Optional: Mutation to escape local optima\n            if np.random.rand() < self.mutation_rate:\n                idx_to_mutate = np.random.randint(0, self.dim + 1)\n                simplex[idx_to_mutate] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                values[idx_to_mutate] = func(simplex[idx_to_mutate])\n                eval_count += 1\n\n            # Update best solution\n            best_f = np.min(values)\n            best_x = simplex[np.argmin(values)]\n            if best_f < self.f_opt:\n                self.f_opt = best_f\n                self.x_opt = best_x\n                \n            if eval_count > self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSimplexSearch scored 0.000 on AOCC (higher is better, 1.0 is the best). The algorithm exhausted the budget. Ensure you stop optimization when budget is 0.", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A gradient-free optimization algorithm that combines a simplex-based search with adaptive shrinking and expansion based on success rates and a random mutation to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveSimplexSearch:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.simplex_size = initial_simplex_size\n        self.alpha = 1.0  # Reflection\n        self.beta = 0.5   # Contraction\n        self.gamma = 2.0  # Expansion\n        self.mutation_rate = 0.05 # Probability of mutation\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize simplex randomly\n        simplex = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim + 1, self.dim))\n        values = np.array([func(simplex[i]) for i in range(self.dim + 1)])\n        \n        eval_count = self.dim + 1\n\n        while eval_count < self.budget:\n            # 1. Order\n            order = np.argsort(values)\n            best_idx = order[0]\n            worst_idx = order[-1]\n\n            # 2. Centroid\n            centroid = np.mean(simplex[order[:-1]], axis=0)\n\n            # 3. Reflection\n            x_r = centroid + self.alpha * (centroid - simplex[worst_idx])\n            x_r = np.clip(x_r, func.bounds.lb, func.bounds.ub)\n            f_r = func(x_r)\n            eval_count += 1\n\n            if f_r < values[best_idx]:\n                # 4. Expansion\n                x_e = centroid + self.gamma * (x_r - centroid)\n                x_e = np.clip(x_e, func.bounds.lb, func.bounds.ub)\n                f_e = func(x_e)\n                eval_count += 1\n                if f_e < f_r:\n                    simplex[worst_idx] = x_e\n                    values[worst_idx] = f_e\n                else:\n                    simplex[worst_idx] = x_r\n                    values[worst_idx] = f_r\n            elif f_r < values[order[-2]]:\n                simplex[worst_idx] = x_r\n                values[worst_idx] = f_r\n            else:\n                # 5. Contraction\n                x_c = centroid + self.beta * (simplex[worst_idx] - centroid)\n                x_c = np.clip(x_c, func.bounds.lb, func.bounds.ub)\n                f_c = func(x_c)\n                eval_count += 1\n                if f_c < values[worst_idx]:\n                    simplex[worst_idx] = x_c\n                    values[worst_idx] = f_c\n                else:\n                    # 6. Shrink\n                    for i in range(self.dim + 1):\n                        if i != best_idx:\n                            simplex[i] = simplex[best_idx] + 0.5 * (simplex[i] - simplex[best_idx])\n                            simplex[i] = np.clip(simplex[i], func.bounds.lb, func.bounds.ub)\n                            values[i] = func(simplex[i])\n                            eval_count += 1\n\n            # Optional: Mutation to escape local optima\n            if np.random.rand() < self.mutation_rate:\n                idx_to_mutate = np.random.randint(0, self.dim + 1)\n                simplex[idx_to_mutate] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                values[idx_to_mutate] = func(simplex[idx_to_mutate])\n                eval_count += 1\n\n            # Update best solution\n            best_f = np.min(values)\n            best_x = simplex[np.argmin(values)]\n            if best_f < self.f_opt:\n                self.f_opt = best_f\n                self.x_opt = best_x\n                \n            if eval_count > self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.10676259281136276, "generation": 1, "aucs": [0]}, "task_prompt": ""}
