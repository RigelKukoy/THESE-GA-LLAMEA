{"id": "461e4635-3a63-4009-992f-38420b3c6f6e", "fitness": "-inf", "name": "HybridPSO_DE", "description": "Population-based algorithm that combines particle swarm optimization with differential evolution mutation and crossover operators to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        \"\"\"\n        Initialize the Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The size of the population.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr (float): Crossover rate for DE.\n            f (float): Mutation factor for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n\n        self.particles = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population of particles.\"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), size=(self.pop_size, self.dim)) # Ensure initial velocities span the search space\n        self.fitness = np.array([func(x) for x in self.particles])\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.particles[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_global_best(self):\n        \"\"\"Update the global best solution.\"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.particles[best_index].copy()\n\n    def update_particles(self, func):\n        \"\"\"Update the position and velocity of each particle.\"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        for i in range(self.pop_size):\n            # PSO update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.particles[i]))\n            self.particles[i] = self.particles[i] + self.velocities[i]\n\n            # Differential Evolution Mutation and Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.particles[idxs]\n            v = x1 + self.f * (x2 - x3)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.cr or j == j_rand:\n                    self.particles[i][j] = v[j]\n\n\n            # Bound handling (clip values)\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n            \n            # Evaluation and personal best update\n            new_fitness = func(self.particles[i])\n            self.fitness[i] = new_fitness\n            if new_fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = new_fitness\n                self.personal_best_positions[i] = self.particles[i].copy()\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n\n        Args:\n            func (callable): The black-box function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best fitness value and the corresponding solution.\n        \"\"\"\n        self.initialize_population(func)\n        eval_count = self.pop_size #Initial population evaluation\n        while eval_count < self.budget:\n            self.update_particles(func)\n            self.update_global_best()\n            eval_count += self.pop_size #Each particle in the population is evaluated each generation.\n            remaining_evals = self.budget - eval_count + self.pop_size\n            if remaining_evals < self.pop_size:\n                indices = np.random.choice(self.pop_size, remaining_evals, replace = False)\n                for i in indices:\n                    #PSO update\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    self.velocities[i] = (self.w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n                    self.particles[i] = self.particles[i] + self.velocities[i]\n\n                    # Differential Evolution Mutation and Crossover\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.particles[idxs]\n                    v = x1 + self.f * (x2 - x3)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.cr or j == j_rand:\n                            self.particles[i][j] = v[j]\n\n                     # Bound handling (clip values)\n                    lb = func.bounds.lb\n                    ub = func.bounds.ub\n                    self.particles[i] = np.clip(self.particles[i], lb, ub)\n            \n                    # Evaluation and personal best update\n                    new_fitness = func(self.particles[i])\n                    self.fitness[i] = new_fitness\n                    if new_fitness < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = new_fitness\n                        self.personal_best_positions[i] = self.particles[i].copy()\n                self.update_global_best()\n                eval_count = self.budget # Terminate after using the budget\n                break\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 0, "feedback": "Evaluation timed out after 600 seconds.", "error": "Evaluation timed out after 600 seconds.", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "c13b03e1-c68a-4635-8b3c-885ec7b75e0f", "fitness": 0.33597814183626695, "name": "AdaptiveDifferentialEvolution", "description": "An adaptive Differential Evolution strategy that dynamically adjusts mutation and crossover rates based on population diversity and search progress, incorporating a local search refinement step.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7 # Initial crossover rate\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.pop[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            # Adaptive F and CR (based on population diversity - a simplified approach)\n            diversity = np.std(self.fitness)\n            self.F = np.clip(self.F + 0.1 * (diversity - 0.5), 0.1, 0.9)\n            self.CR = np.clip(self.CR + 0.1 * (diversity - 0.5), 0.1, 0.9)\n\n            # Local Search around the best solution (optional, and use budget carefully)\n            for _ in range(min(self.local_search_iterations, self.budget)): # limit local search iterations to budget\n                \n                perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                local_point = np.clip(self.x_opt + perturbation, func.bounds.lb, func.bounds.ub)\n                local_f = func(local_point)\n                self.budget -= 1\n\n                if local_f < self.f_opt:\n                    self.f_opt = local_f\n                    self.x_opt = local_point\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.336 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.14545408247991087, 0.2255264722491177, 0.4453386821051448, 0.5605353238503212, 0.3067048727718694, 0.45684159330040075, 0.32045551761862257, 0.32508423430350675, 0.37897227231614394, 0.19486836736763158]}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "17989e38-88bb-4343-b1ed-8bb830114405", "fitness": 0.0, "name": "AdaptiveMutationES", "description": "Population-based algorithm that adapts the mutation strength based on the success rate of recent mutations, combined with a restart strategy to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveMutationES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_sigma=0.5, success_history=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_sigma = initial_sigma\n        self.sigma = initial_sigma * np.ones(pop_size)\n        self.success_history = success_history\n        self.successes = np.zeros(pop_size)\n        self.generation = 0\n        self.best_f_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.f_opt = np.min(self.fitness)\n        self.best_f_history.append(self.f_opt)\n\n        while self.budget > 0:\n            self.generation += 1\n            offspring = self.population + self.sigma[:, None] * np.random.normal(size=(self.pop_size, self.dim))\n            offspring = np.clip(offspring, func.bounds.lb, func.bounds.ub) # Ensure offspring stay within bounds\n\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n\n            success = offspring_fitness < self.fitness\n            self.successes += success\n\n            self.population[success] = offspring[success]\n            self.fitness[success] = offspring_fitness[success]\n\n            # Update best solution\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n            self.best_f_history.append(self.f_opt)\n\n            # Adapt sigma based on success rate\n            success_rate = self.successes / self.generation\n            self.sigma[success_rate > 0.2] *= 1.1\n            self.sigma[success_rate < 0.1] *= 0.9\n            self.sigma = np.clip(self.sigma, self.initial_sigma/10, self.initial_sigma*10) # Limit sigma for stability\n\n            # Reset population if stuck: Check if the best fitness hasn't improved much recently\n            if self.generation > self.success_history * 5 and np.std(self.best_f_history[-self.success_history:]) < 1e-6:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.sigma = self.initial_sigma * np.ones(self.pop_size)  # Reset sigma too\n                self.best_f_history.append(np.min(self.fitness))  # record value after reset\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveMutationES scored 0.000 on AOCC (higher is better, 1.0 is the best). The algorithm exhausted the budget. Ensure you stop optimization when budget is 0.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "ae91cce6-d07f-40c4-a119-c13ad3143589", "fitness": 0.6831901120855575, "name": "AdaptiveDifferentialEvolution", "description": "An adaptive differential evolution algorithm that adjusts its parameters based on the success rate of mutation strategies.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Adaptive parameters\n        self.mutation_strategies = ['rand1', 'best2']  # Possible mutation strategies\n        self.strategy_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies) # Initialize strategy probabilities equally.\n        self.successful_strategies = []\n        self.success_history = []\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, strategy, pop, func):\n        if strategy == 'rand1':\n            idxs = np.random.choice(self.pop_size, size=3, replace=False)\n            x_r1, x_r2, x_r3 = pop[idxs]\n            return x_r1 + self.F * (x_r2 - x_r3)\n        elif strategy == 'best2':\n            best_idx = np.argmin(self.fitness)\n            idxs = np.random.choice(self.pop_size, size=2, replace=False)\n            x_r1, x_r2 = pop[idxs]\n            return pop[best_idx] + self.F * (x_r1 - x_r2)\n        else:\n            raise ValueError(\"Invalid mutation strategy\")\n\n    def crossover(self, mutant, target):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True  # Ensure at least one crossover\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def update_strategy_probabilities(self):\n        # Update strategy probabilities based on success history\n        if self.success_history:\n            success_counts = {strategy: self.success_history.count(strategy) for strategy in self.mutation_strategies}\n            total_successes = sum(success_counts.values())\n            if total_successes > 0: # avoid division by zero\n                self.strategy_probs = np.array([success_counts[strategy] / total_successes for strategy in self.mutation_strategies])\n            else:\n                 self.strategy_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        else:\n            self.strategy_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_strategy_probabilities()\n\n            for i in range(self.pop_size):\n                # Select mutation strategy based on adaptive probabilities\n                strategy = np.random.choice(self.mutation_strategies, p=self.strategy_probs)\n\n                mutant = self.mutate(strategy, self.population, func)\n\n                # Handle boundary constraints\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                trial = self.crossover(mutant, self.population[i])\n\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial\n                    self.successful_strategies.append(strategy)\n                    self.success_history.append(strategy)\n\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                if self.eval_count >= self.budget:\n                    break # Exit loop if budget is reached\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.683 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.3450302903808633, 0.8321632264497413, 0.8129377322638278, 0.8961190272443692, 0.8353576244590908, 0.8614612502525741, 0.33600125276708026, 0.7720703789891806, 0.8196238661266629, 0.32113647192218464]}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "661918c5-d8dd-4dc6-8648-dd340cb666c1", "fitness": "-inf", "name": "AdaptiveHybridPSO_DE", "description": "Adaptively combines PSO and DE operators based on their recent success in improving the global best solution, incorporating a restart mechanism if stagnation is detected.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.5, cr_end=0.9, f=0.8, pso_prob=0.5, stagnation_threshold=50, stagnation_reset_scale=2.0):\n        \"\"\"\n        Initialize the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The size of the population.\n            w_init (float): Initial inertia weight for PSO.\n            w_end (float): Final inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr_init (float): Initial crossover rate for DE.\n            cr_end (float): Final crossover rate for DE.\n            f (float): Mutation factor for DE.\n            pso_prob (float): Initial probability of applying PSO update.\n            stagnation_threshold (int): Number of iterations without improvement before triggering restart.\n            stagnation_reset_scale (float): Scaling factor for resetting the population range after stagnation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr_init = cr_init\n        self.cr_end = cr_end\n        self.f = f\n        self.pso_prob = pso_prob\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_reset_scale = stagnation_reset_scale\n\n        self.particles = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.last_improvement_eval = 0\n\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population of particles.\"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), size=(self.pop_size, self.dim)) # Ensure initial velocities span the search space\n        self.fitness = np.array([func(x) for x in self.particles])\n        self.eval_count += self.pop_size\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.particles[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.last_improvement_eval = self.eval_count\n\n\n    def update_global_best(self):\n        \"\"\"Update the global best solution.\"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.particles[best_index].copy()\n            self.stagnation_counter = 0\n            self.last_improvement_eval = self.eval_count\n        else:\n            self.stagnation_counter += 1\n\n    def update_particles(self, func, iteration):\n        \"\"\"Update the position and velocity of each particle.\"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Anneal PSO parameters\n        w = self.w_init - (self.w_init - self.w_end) * (iteration / self.budget)\n        cr = self.cr_init + (self.cr_end - self.cr_init) * (iteration / self.budget)\n\n\n        for i in range(self.pop_size):\n            # Adaptive PSO/DE selection\n            if np.random.rand() < self.pso_prob:\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = (w * self.velocities[i] +\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n                self.particles[i] = self.particles[i] + self.velocities[i]\n            else:\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.particles[idxs]\n                v = x1 + self.f * (x2 - x3)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        self.particles[i][j] = v[j]\n\n\n            # Bound handling (clip values)\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n            \n            # Evaluation and personal best update\n            new_fitness = func(self.particles[i])\n            self.eval_count += 1\n            self.fitness[i] = new_fitness\n            if new_fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = new_fitness\n                self.personal_best_positions[i] = self.particles[i].copy()\n\n    def restart_population(self, func):\n        \"\"\"Restart the population to escape stagnation.\"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        range_val = (ub - lb) * self.stagnation_reset_scale\n        center = self.global_best_position\n        new_lb = np.maximum(lb, center - range_val / 2)\n        new_ub = np.minimum(ub, center + range_val / 2)\n\n\n        self.particles = np.random.uniform(new_lb, new_ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-abs(new_ub-new_lb), abs(new_ub-new_lb), size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.particles])\n        self.eval_count += self.pop_size\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        \n        # Update global best only if the new population contains a better solution\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.particles[best_index].copy()\n            self.last_improvement_eval = self.eval_count\n        self.stagnation_counter = 0 # Reset stagnation counter\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n\n        Args:\n            func (callable): The black-box function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best fitness value and the corresponding solution.\n        \"\"\"\n        self.initialize_population(func)\n        iteration = self.pop_size\n\n        while self.eval_count < self.budget:\n            self.update_particles(func, iteration)\n            self.update_global_best()\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.restart_population(func)\n                \n            iteration += self.pop_size\n\n            if self.eval_count >= self.budget:\n                 break\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 1, "feedback": "Evaluation timed out after 600 seconds.", "error": "Evaluation timed out after 600 seconds.", "parent_ids": ["461e4635-3a63-4009-992f-38420b3c6f6e"], "operator": null, "metadata": {}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "94537d1b-6ba7-41dc-83b5-6bfd2c94bfe0", "fitness": 0.45703172038638656, "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with Ensemble of Mutation Strategies and Dynamic Parameter Control via Reinforcement Learning.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.learning_rate = learning_rate\n\n        # Adaptive parameters\n        self.mutation_strategies = ['rand1', 'best2', 'current_to_rand1']  # Possible mutation strategies\n        self.strategy_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies) # Initialize strategy probabilities equally.\n        self.successful_strategies = []\n        self.rewards = np.zeros(len(self.mutation_strategies))  # Rewards for each strategy\n        self.strategy_counts = np.zeros(len(self.mutation_strategies)) #Number of times each strategy is used.\n        self.min_F = 0.1\n        self.max_F = 0.9\n        self.min_CR = 0.1\n        self.max_CR = 0.9\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, strategy, pop, func, current_idx):\n        if strategy == 'rand1':\n            idxs = np.random.choice(self.pop_size, size=3, replace=False)\n            x_r1, x_r2, x_r3 = pop[idxs]\n            return x_r1 + self.F * (x_r2 - x_r3)\n        elif strategy == 'best2':\n            best_idx = np.argmin(self.fitness)\n            idxs = np.random.choice(self.pop_size, size=2, replace=False)\n            x_r1, x_r2 = pop[idxs]\n            return pop[best_idx] + self.F * (x_r1 - x_r2)\n        elif strategy == 'current_to_rand1':\n             idxs = np.random.choice(self.pop_size, size=2, replace=False)\n             x_r1, x_r2 = pop[idxs]\n             return pop[current_idx] + self.F * (x_r1 - x_r2)\n        else:\n            raise ValueError(\"Invalid mutation strategy\")\n\n    def crossover(self, mutant, target):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True  # Ensure at least one crossover\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def update_strategy_probabilities(self):\n        # Softmax action selection based on rewards\n        exp_rewards = np.exp(self.rewards)\n        self.strategy_probs = exp_rewards / np.sum(exp_rewards)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_strategy_probabilities()\n\n\n            for i in range(self.pop_size):\n                # Select mutation strategy based on adaptive probabilities\n                strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.strategy_probs)\n                strategy = self.mutation_strategies[strategy_idx]\n                self.strategy_counts[strategy_idx] +=1\n                mutant = self.mutate(strategy, self.population, func, i)\n\n                # Handle boundary constraints\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                trial = self.crossover(mutant, self.population[i])\n\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    reward = (self.fitness[i] - f_trial) #Reward is the improvement\n                    self.rewards[strategy_idx] += self.learning_rate * reward\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    reward = 0 # No improvement\n                    self.rewards[strategy_idx] -= self.learning_rate * 0.1 #Small penality\n                    #Ensure probabilities stay positive\n                    self.rewards = np.clip(self.rewards, -1, 1)\n\n\n\n                # Adapt F and CR (optional - can be removed if it doesn't help)\n                self.F = np.clip(self.F + np.random.normal(0, 0.01), self.min_F, self.max_F)\n                self.CR = np.clip(self.CR + np.random.normal(0, 0.01), self.min_CR, self.max_CR)\n\n\n\n                if self.eval_count >= self.budget:\n                    break # Exit loop if budget is reached\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.457 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ae91cce6-d07f-40c4-a119-c13ad3143589"], "operator": null, "metadata": {"aucs": [0.2001656497096973, 0.220104483022053, 0.558452432198061, 0.831903331439996, 0.483155182193444, 0.5020032984605627, 0.2853402194435839, 0.35502304571215604, 0.5578074398148694, 0.5763621218694417]}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "6e406c62-407b-4560-9ea0-ad5d17c00ab1", "fitness": 0.0, "name": "AdaptiveDifferentialEvolution", "description": "An enhanced Adaptive Differential Evolution with covariance matrix adaptation for mutation and a more robust local search strategy.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7 # Initial crossover rate\n        self.archive = []  # Archive for successful solutions\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            archive_size = min(self.pop_size, len(self.archive))\n            for i in range(self.pop_size):\n                # Mutation using CMA-ES adaptation\n                if len(self.archive) > 2:\n                  archive_samples = np.array(self.archive)\n                  covariance_matrix = np.cov(archive_samples.T)\n                  try:\n                    mutant = self.pop[i] + self.F * np.random.multivariate_normal(np.zeros(self.dim), covariance_matrix)\n                  except:\n                    # Fallback in case covariance matrix is not positive semi-definite\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = a + self.F * (b - c)\n\n\n                else:\n                  idxs = [idx for idx in range(self.pop_size) if idx != i]\n                  a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n                  mutant = a + self.F * (b - c)\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.pop[i] = trial\n                    self.archive.append(trial) # Add to archive\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n\n            # Adaptive F and CR (based on population diversity - a more robust approach)\n            diversity = np.std(self.fitness)\n            self.F = np.clip(self.F + 0.2 * (diversity - 0.5), 0.1, 0.9)\n            self.CR = np.clip(self.CR + 0.2 * (diversity - 0.5), 0.1, 0.9)\n\n\n            # Enhanced Local Search around the best solution - CMA-ES inspired\n            for _ in range(min(self.local_search_iterations, self.budget // 2)): # limit local search iterations to half the remaining budget\n                # Adaptive step size for local search\n                step_size = 0.1 * np.abs(self.x_opt)  # Smaller step size for exploitation\n                perturbation = np.random.normal(0, step_size, size=self.dim)\n                local_point = np.clip(self.x_opt + perturbation, func.bounds.lb, func.bounds.ub)\n                local_f = func(local_point)\n                self.budget -= 1\n\n                if local_f < self.f_opt:\n                    self.f_opt = local_f\n                    self.x_opt = local_point\n                    self.archive.append(local_point) #Add to archive\n                    #Further refine the search: Perform a targeted search in a smaller hypersphere around the new best\n                    for _ in range(min(3, self.budget // 5)):\n                      step_size_refined = 0.01 * np.abs(self.x_opt)\n                      perturbation_refined = np.random.normal(0, step_size_refined, size=self.dim)\n                      local_point_refined = np.clip(self.x_opt + perturbation_refined, func.bounds.lb, func.bounds.ub)\n                      local_f_refined = func(local_point_refined)\n                      self.budget -= 1\n\n                      if local_f_refined < self.f_opt:\n                          self.f_opt = local_f_refined\n                          self.x_opt = local_point_refined\n                          self.archive.append(local_point_refined)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.000 on AOCC (higher is better, 1.0 is the best). The algorithm exhausted the budget. Ensure you stop optimization when budget is 0.", "error": "", "parent_ids": ["c13b03e1-c68a-4635-8b3c-885ec7b75e0f"], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
{"id": "760edf61-d1c6-4272-8561-292336137ebe", "fitness": "-inf", "name": "AdaptiveHybridPSO_DE_LS", "description": "Integrates PSO with a self-adaptive DE, where DE mutation factor and crossover rate are dynamically adjusted based on the success history of previous generations, alongside a local search phase using Nelder-Mead Simplex.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridPSO_DE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, cr_init=0.5, f_init=0.7, ls_freq = 10):\n        \"\"\"\n        Initialize the Adaptive Hybrid PSO-DE algorithm with Local Search.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The size of the population.\n            w (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            cr_init (float): Initial crossover rate for DE.\n            f_init (float): Initial mutation factor for DE.\n            ls_freq (int): Frequency of local search application.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr_init\n        self.f = f_init\n        self.ls_freq = ls_freq\n\n        self.particles = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n        self.cr_history = []\n        self.f_history = []\n        self.success_history = []\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population of particles.\"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.particles])\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.particles[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_global_best(self):\n        \"\"\"Update the global best solution.\"\"\"\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.particles[best_index].copy()\n\n    def update_adaptive_params(self):\n        \"\"\"Update DE parameters based on success history.\"\"\"\n        if self.success_history:\n            successful_cr = np.array([cr for cr, success in zip(self.cr_history, self.success_history) if success])\n            successful_f = np.array([f for f, success in zip(self.f_history, self.success_history) if success])\n\n            if successful_cr.size > 0:\n                self.cr = np.mean(successful_cr)\n            else:\n                self.cr = 0.5  # Reset if no success\n\n            if successful_f.size > 0:\n                 self.f = np.mean(successful_f)\n            else:\n                self.f = 0.7  # Reset if no success\n        \n        self.cr = np.clip(self.cr, 0.1, 0.9)\n        self.f = np.clip(self.f, 0.5, 1.0)\n\n\n\n    def update_particles(self, func):\n        \"\"\"Update the position and velocity of each particle.\"\"\"\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        for i in range(self.pop_size):\n            # Store old fitness for success rate calculation\n            old_fitness = self.fitness[i]\n            \n            # PSO update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.particles[i]))\n            self.particles[i] = self.particles[i] + self.velocities[i]\n\n            # Differential Evolution Mutation and Crossover\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.particles[idxs]\n            v = x1 + self.f * (x2 - x3)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.cr or j == j_rand:\n                    self.particles[i][j] = v[j]\n\n\n            # Bound handling (clip values)\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n            \n            # Evaluation and personal best update\n            new_fitness = func(self.particles[i])\n            self.fitness[i] = new_fitness\n            if new_fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = new_fitness\n                self.personal_best_positions[i] = self.particles[i].copy()\n                self.success_history.append(True) # DE produced a better solution.\n            else:\n                self.success_history.append(False) # DE did not produce a better solution\n\n            self.cr_history.append(self.cr) #Record current cr and f\n            self.f_history.append(self.f)\n            \n    def local_search(self, func):\n        \"\"\"Apply Nelder-Mead local search to the global best solution.\"\"\"\n        bounds = func.bounds\n        result = minimize(func, self.global_best_position, method='Nelder-Mead', bounds=[(bounds.lb, bounds.ub)] * self.dim)\n        if result.fun < self.global_best_fitness:\n            self.global_best_fitness = result.fun\n            self.global_best_position = result.x.copy()\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n\n        Args:\n            func (callable): The black-box function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best fitness value and the corresponding solution.\n        \"\"\"\n        self.initialize_population(func)\n        eval_count = self.pop_size\n        generation = 0\n\n        while eval_count < self.budget:\n            self.update_particles(func)\n            self.update_global_best()\n            self.update_adaptive_params()  # Adapt DE parameters\n            eval_count += self.pop_size\n            generation += 1\n\n            if generation % self.ls_freq == 0:\n                self.local_search(func)\n                eval_count += self.dim + 1  # Rough estimate of evaluations in Nelder-Mead\n                \n            remaining_evals = self.budget - eval_count\n            if remaining_evals <= 0:\n                break\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 1, "feedback": "Evaluation timed out after 600 seconds.", "error": "Evaluation timed out after 600 seconds.", "parent_ids": ["461e4635-3a63-4009-992f-38420b3c6f6e"], "operator": null, "metadata": {}, "task_prompt": "\nYou are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\n\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more.\n"}
